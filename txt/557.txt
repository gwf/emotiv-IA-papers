[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

IJESRT
INTERNATIONAL JOURNAL OF ENGINEERING SCIENCES & RESEARCH
TECHNOLOGY
BRAIN MACHINE INTERFACE SYSETM WITH ARTIFICIAL INTELLIGENT FOR A
PERSON WITH DISABILITY
Ujwala Marghade*, Vinay Keswani
* M.Tech ,Electronics Engg(communication), Vidarbha Institute of Technology, Nagpur University,
India.
Assistant Professor (M. Tech ECE),Vidarbha Institute of Technology, Nagpur University, India.
ABSTRACT
Brain Machine Interface (BMI) system is very useful modus operandi for the disabled or the crippled person to express
his emotions and feelings to someone else with the help of EEG signals coming out of the brain. We know that, the
human brain is made up of billions of interconnected neurons about the size of a pinhead. As neurons interact with
each other, patterns manifest as singular thoughts such as a math calculation. As a by-product, every interaction
between neurons creates a miniscule electrical discharge, measurable by EEG (electroencephalogram) machines. This
system enables people with severe motor disabilities to send command to electronic devices with the help of their
brain waves. These signals can be used to control any electronic devices like mouse cursor of the computer, a wheel
chair, a robotic arm etc. The research in the area of BMI system uses the sequence of 256 channel EEG data for the
analysis of the EEG signals coming out of the brain by using traditional gel based multi sensor system, which is very
bulky and not convenient to use in real time application. So this particular work proposes a convenient system to
analyze the EEG signals, which uses few dry sensors as compared to the traditional gel based multi sensor system
with wireless transmission technique for capturing the brain wave patterns and utilizing them for this application.
In this paper, different brain signals are captured by EEG headset that is EMOTIVE EPOC headset. After that this
signal is processed and used for various command to application. Here the EEG signal is used to control the robotic
arm, also we introducing artificial intelligence in robotic arm for error proofing of system. The goal of this research
is to improve quality of life for those with severe disabilities.
KEYWORDS: Brain machine interface, BMI, EEG signals, EOTIVE EPOC, Artificial intelligent, Robotic arm.

INTRODUCTION
Brain-Machine interface (BMI) is a fast-growing emergent technology in which researchers aims to build a direct
channel between the human brain and the computer. This system enables people with severe motor disabilities to send
command to electronic devices by help of their brain waves. The brain waves are nothing but the electrical discharge
generated by the interaction of neurons. We are aware that the human head is made up of billions of interconnected
neurons. As neurons interact, patterns manifest as singular thoughts such as watching movie. Every interaction
between neurons creates a miniscule electrical discharge, measurable by EEG. These charges are impossible to
measure from outside the skull. But in a dominant mental state, driven by hundreds of thousands concurrent
discharges, can be measured.The average human thinks 70,000 thoughts each day.These electrical signals are useful
for the recognition of different emotional state of a person captured through EEG (Electroencephalogram).
Electroencephalograms (EEG) can be used for implicit communication. It allows paralyzed patients to express their
thoughts and a person to control devices using only his/her mind. Potential uses of EEGs are to detect individuals with
negative intentions such as hijacking or committing crimes and to assist authorities in investigation. The study of EEG
signals is very important for the detection of cerebral rhythmic and any abnormalities. Brain waves are classified with
respect to human activity; these signals represent an extremely low dynamic range (5– 200 μv), in a frequency band
of 0.5 – 40 Hz. Brain electrical potentials are acquired through the use of special surface electrodes, with a monopolar
mounting: sensing electrode is placed over the skull of interest, while along the mid line a second electrode is
positioned for reference electrode. This work describes the single electronic stage for the conditioning of the analog
http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[708]

[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

acquired signal. Sequences of 256 channel EEG data captured by applying appropriate stimuli patterns are analyzed
to establish the spatiotemporal relationships of the signals for different emotional states. The signal sequence in each
channel of the EEG data is decomposed into five specific spectral bands (delta, theta, alpha, beta and gamma bands)
by a series of discrete wavelet transformations.
BMI (Brain–machine Interface)
The very aim of BMI is to translate brain activity into a command for a computer. To achieve this goal, EEG based
Brain Machine Interface system is the most suitable method. Traditionally, EEG-based technology has been used in
medical applications. Currently, new wireless headsets that meet consumer criteria for wear ability, price, portability
and ease-of-use are coming to the market.It makes possible to spread the technology to the areas such as entertainment,
e-learning, virtual worlds, cyber worlds, etc. Automatic emotion recognition from EEG signals is receiving more
attention with the development of new forms of human-centric and human-driven interaction with digital media. An
Electroencephalogram (EEG) is a painless procedure that uses small, flat metal discs (electrodes) attached to your
scalp to detect electrical activity in your brain. Your brain cells communicate via electrical impulses and are active all
the time, even when you're asleep. This activity shows up as wavy lines on an EEG recording. These wavy lines are
nothing but the Brain Waves, as explained earlier. These components are highlighted in this section.

Fig 1: (a) Examples of alpha, beta, theta and delta rhythms. (b) Effect of eye opening in the alpha rhythm

EEG Signal Classification
EEG signal classified into different categories according to the different mental states and frequency range, detailed
in below table 1.

http: // www.ijesrt.com

Sr.
no
.

Brain
wave
type

1.

Delta
wave

Freque
ncy
range(
Hz)
0-3.5
Hz

2.

Theta
wave

4-7.5
Hz

3.

Alpha
wave

8-12
Hz

Mental
states
conditions

&

Deep, dreamless sleep,
nonREP
sleep,
unconscious
Intuitive,
creative,
recall,
fantasy,
imaginary, dream
Relaxed,
but
not
drowsy,
tranquil,
conscious

© International Journal of Engineering Sciences & Research Technology

[709]

[Marghade*, 4.(7): July, 2015]

4.
4.1

4.2

4.3

5.

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785
Beta
wave
Low
Beta
wave
Midran
ge Beta
wave
High
Beta
wave
Gamm
a wave

12-30
Hz
12-15
Hz

Formerly SMR, relaxed
yet focused, integrated

16-20
Hz

Thinking, aware of self
and surroundings

21 to 30
Hz

Alertness, agitation

30 to
100 Hz

Motor functions, higher
mental activity

Table 1.1: EEG Signal Classification

BLOCK DIAGRAM OF SYSTEM

Fig 2. Block diagram of BMI system.

The main idea of the current work is to use a wireless EEG headset such as the one designed by NeuroSky EMOTIVE
EPOC headset as a remote control for any motor application and the computer applications. As depicted in Fig. 1, the
captured EEG signals have to be pre-processed to filter out the unwanted content and then the content of interest has
to be represented using some features that can be inputted into machine learning algorithms. The outcome of this
process is a collection of decision rules that can be translated, as required, into PC command.
After that it will this signal given to Arduino (microcontroller). Microcontroller will convert that digital signal to
analog form to controller the robotic arm.

EEG DATA ACQUISITION DESIGN

Fig.3. Data acquisition Design Options

http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[710]

[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

For the data acquisition, there were many commercial options for EEG headsets and headcaps. Single electrode
headsets, such as the Neurosky Mindwave, were inexpensive and simple. Most had an accessible SDK so development
would be relatively simple. However, a downside to the simple single electrode set up is the lack of channels. For this
reason, more expensive, multiple-electrode headsets were also considers. Their advantages included the ability to do
spatial filtering and accessibility to more than one location of brain. Figure 3 shows an illustration of all of the options
for data acquisition devices
Finally, for the linear actuator, there were a multitude of options online for purchase. All devices performed essentially
the same. The big differences from option to option were the size, power, and cost of the actuator. Finally, the Emotiv
EPOC was chosen as the data acquisition device. This was for a number of reasons. The device was a low cost
consumer headset, yet it had multiple electrodes, so there was more capability for feature extraction. Additionally, the
device came with an easy to use SDK which had been adapted to work with BCI2000 in a BCI2000 module.

Fig.4. EEG EMOTIVE EPOC headset

Number of

14 (plus CMS/DRL references, P3/P4

Channels

locations)

Channel names

AF3, F7, F3, FC5, T7, P7, O1, O2, P8,
T8, FC6, F4, F8, AF4

Sampling

Sequential sampling. Single ADC

Method

Sampling rate

Resolution

128 SPS (2048 Hz internal)

14 bits 1 LSB = 0.51μV (16 bit ADC, 2
bits instrumental noise
floor discarded)

Bandwidth

0.2 - 45Hz, digital notch filters at 50Hz
and 60Hz

http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[711]

[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

Dynamic
range

8400μV (pp)

(input referred)

Connectivity

Proprietary wireless, 2.4GHz band

Power

Battery
(typical)

LiPoly

life

12 hours

Table 3.1 Emotiv EEG Neuroheadset Specification

WORKING PROCEDURE SYSTEM
In this project the BMI is used to control the robotic arm for a disabled person. The robotic limb is designed using 5
motor to control the movement of limb that is the start , stop, rotate, up and down movement.
All this movement will controlled using Brain machine interface system. One new idea introduces in this project is
,we are including artificial intelligence in robotic arm to reduces interferences occur due to multiple brain signal
commands. Because of using artificial intelligence, we are error proofing the overall system.
Design of Brain Controlled Robotic arm

Fig. 5: Process Flow of Robotic arm

The step which are to be followed are show in process diagram above
Step 1: The acquisition of EEG signals is to be done with the help of EMOTIV EPOC headset shown in the first block.
After the EEG signals ate captured, the signal processing is done with the help of EMOTIV tool by providing training
to it for the different facial expression of the different users.

http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[712]

[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

Step 2: Once the training is completed, define the condition and rules in Emokeys to send key strokes to serially to
‘serial monitor’ of Arduino UNO with 9600 Baud rate.
Step3: When the serial data is received by the Arduino it will have to take the decision according to the input character
received serially that which motor is to drive and in what direction. The table above shows the direction of rotation of
both the motor according to the input character received.
Step4: After the commands are detected by the Arduino, it will send the controlling command to the relay board
attached between Arduino and DC motors. Relay board is use here because of the output of Arduino is no sufficient
to drive high torque DC motor operating at 24v and 7.Amp current so here four channel relay board is use as a
switching device to start and stop the motor.
The relay circuit is operating at 12v and has a driver IC ULN2803 to boost the output of Arduino so that it can operate
the relay.

Figure 6: Block Diagram of Brain Controlled Robotic Arm.

EEG Signal Detection
The first step of my project is to capture the different EEG signals by the use of EMOTIV EEG NEUROHEADSET,
and transmit these signals wirelessly to the system or laptop. A dongle is attached to the system which receives digital
signal from headset and display these signals into the EMOTIV TestBench Software. After this we will have to analyze
the raw EEG signals captured by the headset into the Test Bench software with respect to the different facial activity
like eye blink, lip moment, teeth clench, smile, left/right wink etc. After detecting these activity on the waveform I’ll
have to use these signals to send different commands to the system.
The system looks like the picture shown below.
The snapshot of Test Bench software is shown below.

Fig.7.Use of Test bench software

http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[713]

[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

With the help of Emokey application the facial feature can be converted to any key stroke, these key stroke can further
be used as a command to motor for wheelchair. These keystrokes can be sent serially to the Arduino Uno board which
is here used as a decision making device to operated the motors on the basis of the specific character received by the
system.

RESULT ANALYSIS
The raw EEG Signal can be observed into the EMOTIV Test bench software and can be analyzed. By the Hit & Trial
method we have observed some of expression and there corresponding EEG trace on the Test Bench.
The below figure 6.2 shows the graph of single channel of Emotiv headset out of 14 nodes, in which the eye blink
event can be easily visible as a spike or fluctuation in the waveform.as shown below from figure 6 It is more easy to
understand teeth clench event.

Fig. 8: Single channel Emotiv TestBench signal for teeth clench

In the same way the detection of Look Right is shown in figure 6.4 below as indicated.

Fig.9. Look right activity

http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[714]

[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

Fig 10. Rise eyebrow movement

Fig.11 Left Clench activity

Above figure shows the various recording of facial activity recorded by EEG Emotiv EPOC headset in Test bench
software and apply as various commands to the different applications of BMI.

APPLICATION DEVELOPED
1.Robotic Arm Movement:
This Robotic arm is designed for handicapped , paralyzed person who cannot use their hand because of some disability.
Using their facial expression ,the person can control the motion of robotic arm.

Fig12: Upward movement of robotic arm

http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[715]

[Marghade*, 4.(7): July, 2015]

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

Fig12: Downward movement of robotic arm

CONCLUSION
This project deals with developing BMI system using EEG based on specific sensor which is controlled robotic arm
by uniform way and not depend on analog signal which is totally non-invasive method. This helps in efficient use of
Emotiv EPOC headset Module for developing any application based on real time system for disable person. Addition
of Artificial intelligent in BMI gives system more efficient & error free. EEG based BMI system is faster, more
accurate with low artifacts system. This system work to improve the quality of life and speed of communication for
disabled person.

REFERENCE
[1] Alexandre O.G. Barbosa, David R. Achanccaray and Macro A. Meggiolaro, “Activation of Mobile Robot
through a Brain Computer Interface ”, 2010 IEEE International Conference on Robotics and Automation.
[2] Kazuki Yanagisawa, Kyohei Asaka, Hideyuki Sawai, Hitoshi Tsunashima, Takafumi Nagaoka, Takeo Tsujii
and Kaoru Sakatani, “Brain- Computer Interface using Near- Infrared Spectroscopy for Rehabilitation”,
International Conference on Control , Application and systems 2010.
[3] G. Schalk, P. Brunner, L.A. Gerhardt, H. Bischof, J.R. Wolpaw, “Brain- computer interfaces(BCIs):
Detection instead of classification”, Journal of Neuroscience Methods 167 (2008).
[4] L. Mayaud, S. Filipe, L. Petegnief, O. Rochecouste, M. Congedo, “Robust Brain- computer Interface for
virtual Keyboard (RoBIK): Project results”, IRBM 34 (2013).
[5] Mohammad H. Alomari, Ayman Abubaker, Aiman Turani, Ali M. Baniyounes, Adnan Manasreh, “EEG
Mouse: A Machine Learning- Based Brain Computer Interface”, (IJACSA) International Journal of
Advanced Computer Science and Applications Vol. 5, No.4,2014
[6] Gerwin Schalk, Member, IEEE, and Eric C. Leuthardt, Member, IEEE,” Brain-Computer Interfaces Using
Electrocorticographic Signals”, IEEE REVIEWS IN BIOMEDICAL ENGINEERING, VOL. 4, 2011.
[7] YI Fang, LI Hao, JIN Xiaojie, “Improved Classification Methods for Brain Computer Interface System”, I.
J. Computer Network and Information Security, 2012, 2, 15-21.
[8] Jonathan S. Brumberg, Alfonso Nieto-Castanon, Philip R.Kennedy, Frank H. Guenther “Brain computer
interfaces for speed communication”, Speech communication ,52(2010) 367-379.
[9] Sergei L. Shishkin, Ilya P. Ganin, Alexander Ya. Kaplan “Event related potentials in a moving matrix
modification of the P300 brain computer interface paradigm”, Neuroscience Letters 496 (2011) 95- 99
[10] Eric C. Leuthardt, Kai J. Miller, Gerwin Schalk, Rajesh P. N. Rao, and Jeffrey G.
Ojemann,“Electrocorticography-Based Brain Computer Interface—The Seattle Experience”, IEEE
TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING, VOL. 14, NO.
2, JUNE 2006.
http: // www.ijesrt.com

© International Journal of Engineering Sciences & Research Technology

[716]

[Marghade*, 4.(7): July, 2015]

http: // www.ijesrt.com

ISSN: 2277-9655
(I2OR), Publication Impact Factor: 3.785

© International Journal of Engineering Sciences & Research Technology

[717]

