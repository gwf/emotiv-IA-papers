This is the author’s version of a work that was submitted/accepted for publication in the following source:
Senadeera, Manisha, Maire, Frederic, & Rakotonirainy, Andry
(2015)
Turning gaming EEG peripherals into trainable brain computer interfaces.
In
Maher, Michael & Thiebaux, Sylvie (Eds.)
28th Australasian Joint Conference on Artificial Intelligence (AI 2015), 30
November – 4 December 2015, Canberra, A.C.T. (In Press)
This file was downloaded from: http://eprints.qut.edu.au/89489/

c Copyright 2015 [Please consult the author]

Notice: Changes introduced as a result of publishing processes such as
copy-editing and formatting may not be reflected in this document. For a
definitive version of this work, please refer to the published source:

Turning Gaming EEG Peripherals into Trainable
Brain Computer Interfaces
Manisha Senadeera1 , Frederic Maire1 , and Andry Rakotonirainy2
1

Science and Engineering Faculty,
2
Faculty of Health,
Queensland University of Technology,
2 George Street Brisbane 4078, Australia
manisha.senadeera@connect.qut.edu.au
f.maire,r.andry@qut.edu.au

Abstract. Companies such as NeuroSky and Emotiv Systems are selling non-medical EEG devices for human computer interaction. These devices are significantly more affordable than their medical counterparts,
and are mainly used to measure levels of engagement, focus, relaxation
and stress. This information is sought after for marketing research and
games. However, these EEG devices have the potential to enable users to
interact with their surrounding environment using thoughts only, without activating any muscles. In this paper, we present preliminary results
that demonstrate that despite reduced voltage and time sensitivity compared to medical-grade EEG systems, the quality of the signals of the
Emotiv EPOC neuroheadset is sufficiently good in allowing discrimination between imaging events. We collected streams of EEG raw data and
trained different types of classifiers to discriminate between three states
(rest and two imaging events). We achieved a generalisation error of less
than 2% for two types of non-linear classifiers.
Keywords: EEG, Machine Learning, Device Control, BCI, K-nearest
Neighbors, SVM

1

Introduction

Attempts to decipher the brain and interface it with hardware can be traced
back to the 1970’s when Brain Computer Interface (BCI) research started [18].
BCI devices and methods enable their users to have their brain activity monitored. These devices were in the past confined to the medical arena however in
recent years, technological advances have significantly lowered the price of these
devices and allowed for the development of non-medical applications [10,11]. An
important factor in the usability of EEG devices is their setup and calibration
time. New EEG biosensors are easier to operate to the point that they are even
used in games to offer novel experience to players [11].
In this paper, we investigate the capabilities of one such device, the Emotiv
EPOC neuroheadset [1]. This headset comes with the ability to extract raw EEG

2

Machine Learning for EEG Peripherals

Fig. 1. Left: the Emotiv EPOC headset. Right: the location of its electrodes. The CMS
and DRL electrodes act as reference nodes [1].

data from 14 sensors, positioned according to the 10/20 International System,
as pictured in Figure 1.
We tried a variety of classifiers using standard machine learning techniques
to determine whether it was possible to discriminate between three different
mental states. Section 2 retraces briefly the evolution of BCI technology. Section 3 describes the experimental methodology. Section 4 presents experimental
results.

2

Related Work

Although EEG has been primarily used for medical applications such as diagnosing sleep disorders or epilepsy, they have also enabled BCI applications [13, 17].
EEG waves are obtained using electrodes attached to the scalp. These sensitive
electrodes pick up postsynaptic potentials, created by inhibitory and excitatory
potentials in the dendrites of neurons in the cerebral cortex [16]. Berger suggested that the complex EEG was composed of two fundamental waveforms: the
larger α waves correlated with mental activity, and the smaller β waves associated with the metabolic activities of cortical tissue [6]. This observation was
refined and led to the identification of five frequency ranges [12]. Each range
corresponds to a particular state of mind.
The simplest form of BCI is switching. This can be achieved through blinking,
or the acts of having the eyes open or closed [14]. EEG-based BCI can also
be controlled by means of steady state visual evoked potentials, P300 evoked
potentials and motor imagery. Many BCI systems share the architecture shown
in Figure 2 where an EEG data stream is fed to a classifier whose output is then
used to generate control commands.
P300 Evoked Potentials P300 brainwaves were first discovered by Sutton in
1965 and are evoked via a visual stimulus that a user concentrates upon while
different non-target stimuli are also presented [15]. The P300 signal is evoked

EEG Machine Learning Techniques

3

Fig. 2. Architecture of a BCI with feedback loop. The generated output command is
displayed to the user as feedback.

250 to 500 ms after the subject detects the target stimulus among the several
non-target stimuli [2, 9]. The P300 speller is a device that operates on the P300
evoked potentials. The device presents 36 letters in a 6 x 6 matrix. Each row
or column flashes up in turn and the subject concentrates on a particular letter
that they wish to write. When the selected letter is lit up, a signal is evoked in
the brain and appears in the EEG data [2].
Steady State Visual Evoked Potentials Steady State Visual Evoked Potentials (SSVEP) are the responses evoked from visual stimulus at different frequencies. The SSVEP characteristic increases activity in the EEG signal at the
stimulus frequency. An example of SSVEP applications in BCI are demonstrated
by Guneysu and Akin who used the SSVEP induced by observing LED lights
flashing at different frequencies to control a humanoid robot to draw a square [3].
Motor Imagery Motor imagery is the act of mentally imagining a particular action. Imagining the movement of limbs induces significant changes in the cortical
area [5]. This in turn results in changes in potentials allowing for measurements
to be made with electrodes. A key component of utilising motor imagery for BCI
control is training. Within a few days a tetraplegic patient can learn to control
a hand orthosis with mental imaging of left and right hand movements as was
demonstrated by Pfurtscheller and Neuper [8].

3

Stimulus Classification with the Emotiv EPOC

In order to test the suitability of the Emotiv EPOC headset as a BCI device with
multiple control outputs, an experiment was set up to record EEG signals from
three subjects (the authors of this paper). Subjects were shown three different
types of visual stimuli and data were collected with an Emotiv EPOC headset.
Several classifiers were investigated as will be explained in the following sections.

4

3.1

Machine Learning for EEG Peripherals

Experimental Setup

The three tasks the subjects performed were watching a white screen for 10
seconds, watching a blue cube being pushed away from the subject for 5 seconds,
and watching a blue cube being pulled towards the subject for 5 seconds. Screen
shots of the cube being pushed and pulled are displayed in Figure 3. The cube
animation starts at the same size and then becomes either larger (Pull) or smaller
(Push).

Fig. 3. Animation of the Cube Pull

The processing pipeline for exploiting the trained classifiers is illustrated in
Figure 2. Upon receiving the data packets from the Emotiv headset, all raw EEG
data for each subject was extracted and loaded into the Python workspace as
a Numpy matrix. From these concatenated task data from each subject, information which was not relevant to the study, like the inertial measurement unit
(IMU) data, was removed. This created a data matrix with 14 columns with
each row corresponding to a time sample (at a rate of 128 samples per second).

4

Experimental Results

All classifiers tested benefited from centering and scaling the data to unit variance. All results reported are on the dataset centered and scaled to unit variance.
Scaling was essential for the success of non-linear SVM classifiers. PCA preprocessing did not help.
4.1

Support Vector Machine

There is a parameter C, common to all SVM kernels, that controls how smooth
the decision surface between classes is. This parameter trades off misclassification
of training examples against the simplicity of the decision surface. The larger
C is, the more emphasis is put on classifying all training examples correctly,
whereas a smaller C will make the decision surface smoother.
The accuracy results for a SVM with a linear kernel trained on the dataset of
Subject B with a 3 fold cross-validation for different values of the regularisation

EEG Machine Learning Techniques

5

parameter C did not exceed 54%. A random classifier would score around 33%
because we have three classes. The same procedure was repeated for the other
subjects and led to very similar results. The performance of other classifiers
based on linear frontiers like linear discriminant analysis and logistic regression
was slightly worse (around 50%).
Table 1 displays the accuracy for a SVM with a Gaussian kernel trained on
the data of Subject B for different values of the regularisation parameter C. The
best choice of C is 1000, giving an accuracy rate of 97%.
Table 1. Subject B - SVM (Gaussian Kernel)
C = 0.1 C = 1.0
Score 1 0.754766 0.865313
Score 2 0.756406 0.865234
Score 3 0.752578 0.863047

C = 10
0.926875
0.930547
0.931016

C = 100
0.959609
0.959297
0.960703

C = 1000
0.971354
0.972786
0.969661

C = 10000
0.967839
0.969531
0.969141

The experiment was repeated for the other subjects and led to the same
choice for C. Gaussian SVM’s were then trained for all three subjects with a
10 fold cross validation. The average accuracy values were 99.76%, 97.30% and
98.13% for Subject’s A, B and C respectively.
4.2

Decision Tree

The decision trees performed better than the linear classifiers, but not as well as
the Gaussian SVM. Pruning the trees, and limiting the size of their leaves did
not help significantly. Using a 10 fold cross validation, the accuracy values were
on average 97% for Subject A, 84.8% for Subject B and 88.9% for Subject C.
4.3

K-Nearest Neighbors

The best performance was obtained with the conceptually simplest classifier.
The idea behind the nearest neighbor method is to find a predefined number k
of training samples closest in distance to the unlabeled query point, and predict
the most common label of these k neighbors as the class label of the query point.
Table 2 shows the accuracy values of different k-Nearest Neighbors classifiers
using 10 fold cross validation. We observed that that k = 1 provides the best
results.

5

Discussion

Collecting data and training classifiers can be time consuming. A natural question to ask is whether a classifier trained on one person generalizes well to other
people. The answer is unfortunately negative. For example, the SVM classifier
built from Subject B data achieved an accuracy of 97% on this person’s test data.

6

Machine Learning for EEG Peripherals
Table 2. k Nearest Neighbors

Subject
Subject
Subject
Subject
Subject
Subject

A Avg
A Std
B Avg
B Std
C Avg
C Std

k=1
0.99996875
9.375e-05
0.991432292
0.0011076
0.99199218
0.00088277

k=3
0.9995625
0.0004677
0.987526042
0.00131478
0.98858817
0.00143063

k=5
0.99946875
0.0004204
0.984375
0.00159259
0.9863560
0.00265419

k=7
0.9993125
0.0004146
0.98145833
0.00145833
0.98334263
0.002260045

However when applied to Subject A and Subject C, the accuracy of the same
SVM dropped to 26% and 36% respectively. That is, the classifier performed as
badly as random guessing. This observation leads to the conclusion that trained
classifiers are not transferable between subjects.
In the future, we would like also to assess the suitability of the Emotiv EPOC
neuroheadset for classifying mental workloads. Our interest in assessing mental
workloads stems from the road transport field where it is consistently shown that
high mental workloads (e.g conversation on a mobile phone) distracts drivers
and causes crashes. Identifying the most representative objective measures of
mental workload whilst driving is a complex and significant area of research
in transport as cognitive workload is a function of situation complexity and
driving experience [4, 7]. Mental workload influences the driving performance
and its measure can be used to tailor BCI based interventions which will reduce
crashes related to driver distractions.

6

Conclusion

In this paper, we demonstrated that the Emotiv EPOC neuroheadset which was
primarily designed for use in entertainment, market research and neurotherapy,
is also suitable for BCI control systems. We showed that using the sensor values
of its 14 electrodes, we can train classifiers to discriminate between three mental states with high accuracy. The best results were obtained with a 1-nearest
neighbor classifier achieving a generalisation error of less than 1% across all
the subjects. Our experiments on the collected EEG data show that non-linear
classifiers perform substantially better than linear classifiers with the highest
accuracy of a linear classifier being only 54%. More details are provided in an
extended version of this paper available at http://eprints.qut.edu.au/view/
person/Maire,_Frederic.html.
In the future, we plan to explore further the capabilities of the device to
determine what is the maximum number of classes that can be discriminated at
a given level of accuracy. Our preliminary results are encouraging because they
show that the difficult classification task of distinguishing between an object
moving closer or moving away can be performed with high accuracy.

EEG Machine Learning Techniques

7

References
1. Emotiv Systems: Emotiv EPOC / EPOC+ (2014), https://emotiv.com/epoc.php
2. Farwell, L.A., Donchin, E.: Talking off the top of your head: toward a mental
prosthesis utilizing event-related brain potentials. Electroen. Clin. Neuro. 70(6),
510–523 (1988)
3. Guneysu, A., Akin, H.L.: An SSVEP based BCI to control a humanoid robot by
using portable EEG device. vol. 2013, pp. 6905–6908. IEEE, United States (2013)
4. Hood, D., Joseph, D., Rakotonirainy, A., Sridharan, S., Fookes, C.: Use of Brain
Computer Interface to Drive: Preliminary Results. In: Proceedings of the 4th International Conference on Automotive User Interfaces and Interactive Vehicular
Applications. pp. 103–106. AutomotiveUI ’12, ACM (2012), http://doi.acm.org/
10.1145/2390256.2390272
5. Jeannerod, M.: The representing brain: Neural correlates of motor intention and
imagery. Behav.Brain Sci. 17(2), 187–202 (1994)
6. Millett, D.: Hans Berger: From Psychic Energy to the EEG. Perspect. Biol. Med.
44(4), 522–542 (2001)
7. Paxion, J., Galy, E., Berthelon, C.: Mental workload and driving. Front. Psychol.
5, 1344 (2014)
8. Pfurtscheller, G., Neuper, C.: Motor imagery and direct brain-computer communication. P. IEEE 89(7), 1123–1134 (2001)
9. Polich, J.: Updating P300: An integrative theory of P3a and P3b. Clin. Neurophysiol. 118(10), 2128–2148 (2007)
10. Prindle, D.: Thoughts into motion: Amazing brain-controlled devices
that are already here (2012), http://www.digitaltrends.com/cool-tech/
brain-control-the-user-interface-of-the-future/
11. Raajan, N.R., Jayabhavani, G.N.: A smart way to play using brain machine interface (BMI). pp. 1130–1135. IEEE (2013)
12. Sanei, S, C.J.: EEG Signal Processing: Fundamentals of EEG signal processing.
John Wiley & Sons Ltd (2007)
13. Sheth, D., Benbadis, R.: EEG in common epilepsy syndromes (2014), http://
emedicine.medscape.com/article/1138154-overview
14. Singla, R., Chambayil, B., Khosla, A., Santosh, J.: Comparison of SVM and ANN
for classification of eye events in EEG. J. Biomed. Sci. Eng. 4(1), 62–69 (2011)
15. Sutton, S., Braren, M., Zubin, J., John, E.R.: Evoked-Potential Correlates of Stimulus Uncertainty. Science 150(3700), 1187–1188 (1965)
16. Szafir, D.: Non-Invasive BCI through EEG: An Exploration of the Utilization
of Electroencephalography to create Thought-Based Brain-Computer Interfaces
(2010)
17. Vidal, J.J.: Toward Direct Brain-Computer Communication. Annu. Rev. Biophys.
Bio. 2(1), 157–180 (1973)
18. Wolpaw, J.R., Birbaumer, N., Heetderks, W.J., McFarland, D.J., Peckham, P.H.,
Schalk, G., Donchin, E., Quatrano, L.A., Robinson, C.J., Vaughan, T.M.: Braincomputer interface technology: a review of the first international meeting. IEEE
T. Rehabil. Eng. 8(2), 164–173 (2000)

