Aﬀective, Natural Interaction Using EEG:
Sensors, Application and Future Directions
Charline Hondrou and George Caridakis
Image, Video and Multimedia Systems Lab, NTUA
{charline,gcari}@image.ntua.gr

Abstract. ElectroEncephaloGraphy signals have been studied in relation to emotion even prior to the establishment of Aﬀective Computing as a research area. Technological advancements in the sensor and
network communication technology allowed EEG collection during interaction with low obtrusiveness levels as opposed to earlier work which
classiﬁed physiological signals as the most obtrusive modality in aﬀective
analysis. The current article provides a critical survey of research work
dealing with broadly aﬀective analysis of EEG signals collected during
natural or naturalistic interaction. It focuses on sensors that allow such
natural interaction (namely NeuroSky and Emotiv), related technological features and aﬀective aspects of applications in several application
domains. These aspects include emotion representation approach, induction method and stimuli and annotation chosen for the application. Additionally, machine learning issues related to aﬀective analysis (such as
incorporation of multiple modalities and related issues, feature selection
for dimensionality reduction and classiﬁcation architectures) are revised.
Finally, future directions of EEG incorporation in aﬀective and natural
interaction are discussed.
Keywords: EEG, Aﬀective Computing, Natural Interaction, Aﬀect
aware applications.

1

Introduction

The use of ElectroEncephaloGraphy (EEG) to study electrical activity in the
human brain was demonstrated for the ﬁrst time approximately 80 years ago.
This development has had far-reaching implications for the study of the human
brain’s activity changes in response to changes in emotion. Numerous studies
have taken place in the last years aiming to understand the correlation between
brain signals and emotional states. In EEG, the electrical activity of the brain
is observed through scalp electrodes. The 10-20 system [19] is an internationally
recognised method to describe and apply the location of the nineteen electrodes
used originally. The “10” and “20” refer to the fact that the actual distances
between adjacent electrodes are either 10% or 20% respectively of the total
front-back or right-left length of the surface of the skull.
I. Maglogiannis, V. Plagianakos, and I. Vlahavas (Eds.): SETN 2012, LNAI 7297, pp. 331–338, 2012.
c Springer-Verlag Berlin Heidelberg 2012


332

C. Hondrou and G. Caridakis

Brain signals are classiﬁed in ﬁve frequency bands, associated with diﬀerent
mental states. Delta waves (0-3.5 Hz) occur in deep sleep [9]. Theta waves (3.57.5 Hz) have been associated with drowsiness, daydreaming, creative inspiration
and meditation, arousal [6], sensorimotor processing and mechanisms of learning
and memory [10]. Alpha waves (7.5-12 Hz) are present during wakeful relaxation
with closed eyes and are reduced with open eyes, drowsiness and sleep. Mu
waves (8-13 Hz) are diminished with movement or an intent to move, or when
others are observed performing actions. Beta waves (12-30 Hz) are associated
with focus, concentration, high alertness, agitation and anxiety. Gamma waves
(30-100 Hz) are associated with very high states of consciousness, focus and
intellectual acuity, and have a strong presence during meditation.
Finally another important feature measured in EEG studies are Event-Related
Potentials (ERP), which are brain responses as a direct result of a thought or
perception, and more speciﬁcally the P300 signal which is one of the components
of an ERP elicited by task-relevant stimuli.

2

Sensors Technology Overview

The ﬁrst human EEG recording was obtained by Hans Berger in 1924. Since then
numerous electroencephalographic studies have taken place using, until a few
years ago, caps which were complicated to position on the subject due to their
many wires. Recently, the wireless sensors’ technology has evolved, making it
possible for various systems to be developed. These sensors are inexpensive, easy
to set up and are accompanied with out-of-the-box applications or easy to use
SDK’s, and provide freedom of movement for the user. Industry has shown strong
interest in this ﬁeld. Some examples are Imec, Neurofocus, OCZ, SmartBrain
Technologies and QUASAR. Here we will focus on the two most popular, in terms
of integration in EEG studies: Emotiv and Neurosky. Depending on the version
of these sensors and their SDK there are some variations in the characteristics
and properties provided. Here we are presenting the ones that are relative to our
theme without separating them according to the edition.
The Neurosky sensor is able to measure frequencies in the range of 0.5-50 Hz
and the Emotiv sensor measures frequencies in the range of 0.2-43 Hz. Through
both sensors’ simple interface the raw EEG, its Fast Fourier Transform and
the alpha, beta, gamma, delta and theta waves can be displayed as well as the
user’s mental state: attention, meditation, anxiety and drowsiness for Neurosky,
and long-term excitement, instantanious excitement, engagement, frustration,
meditation, boredom for Emotiv. With Emotiv there is also the possibility to
monitor the facial expressions (look left/right, blink, left/right wink, raise brow,
clench teeth, smile) and the movements of the head calculated from the headset’s
gyroscope, whereas an animation of “explosions” simulates the action of blinking
in Neurosky. The 10-20 system doesn’t apply to Neurosky due to the fact that
there is only one sensor on the forehead and one “ground” sensor on the earlobe
whereas Emotiv is considered partially compliant to the 10-20 system.

Aﬀective, Natural Interaction Using EEG

3
3.1

333

Aﬀective Aspects of EEG Application
Emotion Representation

Because of the user-friendly interface these sensors provide, the emotion representation is often quite straightforward. Emotiv provides as direct output frustration and excitement in [11], long-term excitement, instantaneous excitement
and engagement in [4, 13] and excitement, engagement, boredom, meditation and
frustration in [5] through its simple interface. In some cases information from
the Emotiv sensor about the raw EEG and wave variations are combined with
the information provided by other biological or non biological sensors, resulting
in diﬀerent types of emotion representation: anger, disgust, fear, happiness, sadness, joy, despisal, stress, concentration and excitement in [8], positive, negative
and neutral state of mind in [3, 20]. In cases where the cognitive load of the
subject is being studied during a task [7], changes in power of lower frequency
(alpha, theta) brain waves detected by Emotiv are analysed in order to determine
whether the cognitive load is low, medium or high. Finally, a diﬀerent approach
is adopted when attention or the wink movement is detected. In this case the
raw EEG provided by the sensor is processed in order to detect the P300 signal
[1, 21] or the signal caused by the winking [1]. The Neurosky sensor outputs,
through its intuitive interface as well, attention and meditation in [2], attention
level in [22], and relaxation and irritation in [14]. In a fatigue detection system
in [12], when three conditions are met simultaneously the user is considered fatigued: a) attention decreases below a certain threshold, b) meditation increases
above a threshold and c) either of the delta or theta wave signals maintain the
highest value of all frequency bands.
3.2

Annotation

The most common process for annotating experimental corpora is self assessment. This includes questionaires or tasks prior to and/or after the experiment
concerning the emotion or the cognitive feature examined [2, 7, 14, 17]. More
speciﬁcally, certain well-known tasks are given to the subject in order to evaluate
the results. As seen in [8, 20], International Aﬀective Picture System (IAPS) is
incorporated in order to provide a set of normative emotional stimuli for experimental investigation of emotion and attention. The goal is to develop a large set
of standardized, emotionally-evocative, internationally accessible, color images
which includes contents across a wide range of semantic categories [15]. In order
to measure engagement in [4] the Independent Television Commission-Sense of
Presence Inventory (ITC-SOPI) [16] questionnaire was used. This questionnaire
oﬀers a valid method of measuring cross-media presence which allows results
from diﬀerent laboratories to be compared. It studies four factors: Sense of Physical Space, Engagement, Ecological Validity, and Negative Eﬀects. In the same
study the Self-Assessment Manikin (SAM) is used as well. SAM is a non-verbal
pictorial assessment technique that directly measures the pleasure, arousal, and
dominance [18] associated with a person’s aﬀective reaction to a wide variety

334

C. Hondrou and G. Caridakis

of stimuli [15]. Sometimes annotation is provided by the experiment itself. An
example of that is [3] where positive, negative and neutral state of mind are
measured. During this experiment the participants are asked to control a robot
in a maze by thinking about the direction it must take (in reality they can’t).
The direction in which the robot should move is shown with an arrow. The
robot follows a predeﬁned path, sometimes the right one, sometimes the wrong
one. When it follows the right path the participant is assumed to be satisﬁed
(positive), when it follows the wrong path the participant is assumed to be unsatisﬁed (negative) and while the participant is looking at the arrow (before the
robot moves) a neutral state is assumed. Another example is [21] where the P300
signal responding to a visual stimulus is measured. In this case the subject is
asked to press a button when the stimulus appears. Another article [22] where
attention is measured, builds on results from previous studies which suggest that
attention is correlated with the errors made and the speed of the activity, as well
as whether the participant gave-up or not.
3.3

Stimuli/Induction

The induction of the diﬀerent mental states detected in EEG studies can be
obtained by audio stimuli such as the sounds of a game in a CAVE environment
[13] or wind, sea waves and a composition of slow violins, tinkling bells and oboes
to induce a positive feeling and musical pop tracks which the subject strongly
dislikes to induce a negative feeling like in the case of [14]. Visual stimuli can include displaying pleasant, neutral and unpleasant pictures from the International
Aﬀective Picture System [20], visuals in game-playing [13] or a robot’s movement
[3]. If the P300 signal is to be detected, examples of stimuli can be found in [21]
where the subject is looking at a monitor where a ship appears intermittently
or in [1] where the photo of each person in a mobile phone’s addressbook ﬂashes
and when the photo of the person we want to call ﬂashes the signal is detected.
Furthermore, examples of interactive Brain Computer Interfaces (BCI) used to
induce diﬀerent emotions are encountered in [4, 8, 11]. Finally, learning activities
and tasks such as the Stroop Test, Hanoi Towers, Berg’s Card Sorting Task, and
seeking information on the web can also be used as stimuli [2, 7, 17, 22].

4
4.1

Machine Learning Aspect
Multimodality

Biomedical studies, in their eﬀort to be more accurate, combine multiple biological signals as well as information coming from the subject’s face, voice, body
movements and actions on the computer.
EEG information is combined with information taken from the subject’s face
using visual input or observations in [2, 5, 8, 11, 17]. For the latter, “MindReader”
- a system developed at MIT Media Lab - infers emotions from facial expressions
and head movements in real-time.

Aﬀective, Natural Interaction Using EEG

335

Often EEG is studied in combination with Galvanic Skin Response (GSR),
which is a method of measuring the electrical conductance of the skin, which
varies with its moisture level. This is of interest because the sweat glands are
controlled by the sympathetic nervous system, so skin conductance is used as
an indication of psychological or physiological arousal. Examples can be found
in [5, 7, 13, 14].
Heart rate measurement is another way to index state of mind and the fusion
of it with EEG has been studied in [8, 13, 14].
The eyes’ movement is another cue that provides information about the user’s
attention or focus point. In [5] “Tobii Eye Tracking System” was incorporated
in the system, providing data about the user’s attention and focus time while
performing a task on the computer. This information is combined with the information provided by the EEG sensor. In the case of [7], the eyes’ movements and
the EEG were used to predict mental states of a person engaged in interactive
seeking of information.
Other inputs used to determine mental states can be mouse clicks, keyboard
strokes, screen cam recordings [7], body posture, ﬁnger pressure (usually on the
mouse) [5] and acoustic features [8].
4.2

Feature Processing

Due to the huge variability of features collected in biometric studies, in order to reduce the dimensionality of the problem, eliminate the noise or extract
particular characteristics from the signal, the need to preprocess them is common. [20, 21] use Independent Component Analysis (ICA). [14, 20] use Principal
Component Analysis (PCA). Noise reduction is also a very important issue in
biosignal processing. The use of Notch ﬁlters (50 and 60 Hz) and bandpass ﬁlters
(for example 1-20 Hz in order to isolate the P300) are commonly used.
4.3

Classification

An abundance of classiﬁcation approaches is being used in EEG research.
K-nearest neighbor algorithm and Support Vector Machines (SVM) are incorporated in [11] in order to create predictive models of frustration and excitement,
and in [17] to classify numerous features of raw EEG in order to create a model
of human academic emotion (boredom, confusion, engagement and frustration).
[17] also makes use of a multilayer perceptron (MLP). All of the above classiﬁers
have been used in [14] along with Logistic Regression, Decision Trees, Naı̈ve
Bayes and ensemble classiﬁers.
[11] uses Linear Regression as well and [20] uses the K-means algorithm. [3]
makes use of Linear Discriminant Analysis (LDA) to determine the satisfaction
level as categorical representation (satisﬁed, neutral, unsatisﬁed) and in [21] the
Adaptive Neuro Fuzzy Inference System (ANFIS) is used to detect P300-rhythm.
At this point it is worth mentioning that diﬀerent types of open-source data
mining software with embedded algorithms have been a very useful tool for EEG
studies. Important examples are “RapidMiner” in [11, 17], and “Weka” in [14].

336

5

C. Hondrou and G. Caridakis

Application Domains

For research purposes various systems have been created in order to study emotion recognition in BCI’s [2, 5, 14] as well as attention detection [21]. The main
ﬁelds in which the wireless EEG sensors ﬁnd application are games (subsection
5.1), learning (subsection 5.2) and health (subsection 5.3). They are also used
in mobile phones [1, 20], Human-Robot Interaction (HRI) [3] and interactive
information seeking [7].
5.1

Games

One of the most common ﬁelds of use of wireless EEG sensors is game play. The
EEG signal is used as feedback to the game so that the game scenario adjusts
to the player’s needs. For example, detection of boredom will cause changes in
the game to make it more challenging whereas detection of anxiety will cause
the game to slow down or decrease the levels of diﬃculty. The portability of
these devices is even more useful in cases where they are combined with games
played in virtual reality environments. In these cases the player’s immersion is
augmented further. A good example can be seen in [13] where the environment
used is “CAVE” (projectors are directed to three, four, ﬁve or six of the walls of
a room-sized cube).
5.2

E-Learning

E-Learning is an application domain aiming to create virtual learning environments that will simulate and enhance conventional learning environments [4, 17].
In [11] a tutoring system predicts the student’s appraisal of the feedback given
and in [22] the system adapts and modiﬁes the learning activity according to
the student’s level of attention. [8] is proposing a virtual environment for job
interview training that senses the applicant’s emotions.
5.3

Health and Universal Access

Wireless sensors are now being introduced to the P300 Speller, contributing to its
portability. The P300 Speller is a 6x6 matrix of alphanumeric characters where
one of its rows or columns ﬂashes randomly. When the character the subject
wants ﬂashes, the P300 signal is measured. In this domain we can also ﬁnd a
fatigue detection system proposed by [12].

6

Conclusions and Future Directions

The current article provides a critical survey of research work dealing with
broadly aﬀective analysis of EEG signals collected during natural or naturalistic
interaction by wireless sensors. EEG analysis in relation to emotion, while having
a long history, has always been considered an extremely obtrusive emotional cue

Aﬀective, Natural Interaction Using EEG

337

capture technique, establishing it as unsuitable for natural interaction. Recent
releases of sensors enabling wireless collection of EEG signals enable aﬀect-aware
applications using natural interaction. It is expected that application domains
such as gaming and e-learning will dominate the ﬁeld. A related milestone could
be the release of a gaming platform with EEG sensors included or at least available as an add-on. As Microsoft’s Kinect sensor and OpenNI framework boosted
research and applications on Natural Interaction, a similar explosion could follow if a major industry released a gaming platform (similar to the Xbox 360)
which would collect EEG data. On the other hand, enabling low-cost and widely
available collection of EEG activity during learning activities through e-learning
applications would boost research on correlation of brain and cognitive functions
as well as adaptive, educational interfaces.

References
[1] Campbell, A., Choudhury, T., Hu, S., Lu, H., Mukerjee, M.K., Rabbi, M., Raizada,
R.D.S.: Neurophone: brain-mobile phone interface using a wireless eeg headset. In:
Proceedings of the Second ACM SIGCOMM Workshop on Networking, Systems,
and Applications on Mobile Handhelds, pp. 3–8. ACM (2010)
[2] Crowley, K., Sliney, A., Pitt, I., Murphy, D.: Evaluating a brain-computer interface
to categorise human emotional response. In: 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT), pp. 276–278. IEEE (2010)
[3] Esfahani, E.T., Sundararajan, V.: Using brain–computer interfaces to detect human satisfaction in human–robot interaction. Int. J. Human. Robot. 8(01), 87–101
(2011)
[4] Goldberg, B.S., Sottilare, R.A., Brawner, K.W., Holden, H.K.: Predicting Learner
Engagement during Well-Deﬁned and Ill-Deﬁned Computer-Based Intercultural
Interactions. In: D’Mello, S., Graesser, A., Schuller, B., Martin, J.-C. (eds.) ACII
2011, Part I. LNCS, vol. 6974, pp. 538–547. Springer, Heidelberg (2011)
[5] Gonzalez-Sanchez, J., Chavez-Echeagaray, M.E., Atkinson, R., Burleson, W.: Abe:
An agent-based software architecture for a multimodal emotion recognition framework. In: Proc. of 9th Working IEEE/IFIP Conference on Software Architecture,
WICSA 2011 (2011)
[6] Green, J.D., Arduini, A.: Hippocampal activity in arousal. Journal of Neurophysiology (1954)
[7] Gwizdka, J., Cole, M.J.: Inferring cognitive states from multimodal measures in
information science (2011)
[8] Hamdi, H., Richard, P., Suteau, A., Saleh, M.: Virtual reality and aﬀective computing techniques for face-to-face communication
[9] Hammond, D.C.: What is neurofeedback? Journal of Neurotherapy 10(4), 25
(2006)
[10] Hasselmo, M.E., Eichenbaum, H.: Hippocampal mechanisms for the contextdependent retrieval of episodes. Neural Networks 18(9), 1172–1190 (2005)
[11] Inventado, P.S., Legaspi, R., Bui, T.D., Suarez, M.: Predicting student’s appraisal
of feedback in an its using previous aﬀective states and continuous aﬀect labels
from eeg data. In: Proceedings of the 18th International Conference on Computers
in Education, Putrajaya, Malaysia (2010)
[12] Junjian, W., Shujun, X.: Fatigue detecting system. Master’s thesis, Linnaeus University (2011)

338

C. Hondrou and G. Caridakis

[13] Koutepova, T., Liu, Y., Lan, X., Jeong, J.: Enhancing video games in real time
with biofeedback data. In: ACM SIGGRAPH ASIA 2010 Posters, p. 56. ACM
(2010)
[14] Kuncheva, L.I., Christy, T., Pierce, I., Mansoor, S.P.: Multi-modal Biometric Emotion Recognition Using Classiﬁer Ensembles. In: Mehrotra, K.G., Mohan, C.K.,
Oh, J.C., Varshney, P.K., Ali, M. (eds.) IEA/AIE 2011, Part I. LNCS, vol. 6703,
pp. 317–326. Springer, Heidelberg (2011)
[15] Lang, P.J., Bradley, M.M., Cuthbert, B.N.: International aﬀective picture system
(iaps): Technical manual and aﬀective ratings (1999)
[16] Lessiter, J., Freeman, J., Keogh, E., Davidoﬀ, J.: A cross-media presence questionnaire: The itc-sense of presence inventory. Presence: Teleoperators & Virtual
Environments 10(3), 282–297 (2001)
[17] Mampusti, E.T., Ng, J.S., Quinto, J.J.I., Teng, G.L., Suarez, M.T.C., Trogo, R.S.:
Measuring academic aﬀective states of students via brainwave signals. In: 2011
Third International Conference on Knowledge and Systems Engineering (KSE),
pp. 226–231. IEEE (2011)
[18] Mehrabian, A.: Pleasure-arousal-dominance: A general framework for describing
and measuring individual diﬀerences in temperament. Current Psychology 14(4),
261–292 (1996)
[19] Niedermeyer, E., Da Silva, F.H.L.: Electroencephalography: basic principles, clinical applications, and related ﬁelds. Lippincott Williams & Wilkins (2005)
[20] Petersen, M.K., Stahlhut, C., Stopczynski, A., Larsen, J.E., Hansen, L.K.: Smartphones Get Emotional: Mind Reading Images and Reconstructing the Neural
Sources. In: D’Mello, S., Graesser, A., Schuller, B., Martin, J.-C. (eds.) ACII
2011, Part II. LNCS, vol. 6975, pp. 578–587. Springer, Heidelberg (2011)
[21] Ramirez-Cortes, J.M., Alarcon-Aquino, V., Rosas-Cholula, G., Gomez-Gil, P.,
Escamilla-Ambrosio, J.: P-300 rhythm detection using anﬁs algorithm and wavelet
feature extraction in eeg signals. In: Proceedings of the World Congress on Engineering and Computer Science, vol. 1 (2010)
[22] Rebolledo-Mendez, G., De Freitas, S.: Attention modeling using inputs from a
brain computer interface and user-generated data in second life. In: The Tenth
International Conference on Multimodal Interfaces (ICMI 2008), Crete, Greece
(2008)

