IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

Classificação do estado de atenção do estudante: detectando a
mensuração cerebral e as expressões faciais
Andreia Solange Bos1,2, Milton Antônio Zaro2, Michelle Câmara Pizzato1
1

2

Instituto Federal de Educação Ciência e Tecnologia do Rio Grande do Sul (IFRS)
Porto Alegre- RS – Brasil

Universidade Federal do Rio Grande do Sul (UFRGS) – Porto Alegre- RS – Brasil
andreia.bos@gmail.com, zaro@ufrgs.br, michelle.pizzato@poa.ifrs.edu.br

Classification of the student's state of attention: detecting brain measurement and
facial expressions
Abstract. This article includes an analysis of capture captured by the system from
a set of emotional data and an analysis of brain activities. The experiment was
conducted with a sample of ten university students. Each student received two
videos lasting five minutes with random images of different emotions
(educational video and public video). As recorded by the FER system and the
Emotional EEG sensor (Electroencephalogram). The results of the experiment
show different brain activities collected by the sensor and no facial expression
analysis system. The system classifies emotions and facial expressions during a
video recreation activity.
Keywords: emotions. facial expression, brain activity.
Resumo. Este artigo destaca a análise de reações capturadas pelo sistema de
um conjunto de dados emocionais e a análise das atividades cerebrais. O
experimento foi conduzido com uma amostra de dez estudantes universitários.
Cada aluno recebeu dois vídeos com duração de cinco minutos com imagens
aleatórias de diferentes emoções (vídeo educacional e vídeo publicitário). As
reações foram registradas pelo sistema FER e pelo sensor EMOTIV de EEG
(Eletroencefalograma). Os resultados do experimento mostraram diferentes
atividades cerebrais coletadas pelo sensor e no sistema de análise de expressões
faciais. O sistema classifica as emoções e expressões faciais durante a atividade
de apreciação dos vídeos.
Palavras chave: emoções. expressão facial, atividade cerebral.

DOI: 10.5753/cbie.wie.2020.469

469

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

1. Introdução
Atualmente, os sistemas de expressões faciais são amplamente utilizados em diversas
pesquisas no processo educacional. Os pesquisadores começaram a utilizar essa tecnologia
para ajudar no processo de aprendizagem (Ekman, 1993). Entender o estado mental e as
atividades cerebrais do estudante é fundamental para ajudar o professor a entender melhor a
eficiência do seu método de aprendizado. O rastreamento do conjunto das expressões faciais
é o aspecto utilizado para identificar as sete emoções básicas (Ekman,1969). A classificação
da extração pode ser visualizada pelo pesquisador em tempo real durante o estudo, dessa
forma é possível visualizar os resultados mais relevantes e até interferir no processo
educacional. Algumas técnicas de detecção de expressões faciais fizeram progressos
significativos nos últimos anos (ASLAN et al, 2014).
Atualmente, essas técnicas existem e são aplicadas como por exemplo; em dispositivos de
câmeras digitais, softwares de reconhecimento facial do facebook etc. (Bos et al., 2020g).
Ainda não existe uma precisão relacionada a captura de sentimentos reais e a classificação
de estados emocionais específicos (Barret et al, 2019). Segundo Ekman, a classificação
captura as expressões de situações em escala. Neste experimento é utilizado o conjunto de
dados denominado de FER 2013 da Microsoft 1 , que é um dos sistemas de análise de
expressões faciais mais utilizados por pesquisadores. A medição das emoções com o uso da
tecnologia educacional é um estereótipo que une a educação baseada em computador (Barret
et al, 2019). Com isso tem se um efeito positivo e uma melhora gradual na atividade do
processo educacional. Essa técnica será muito importante no ambiente educacional medindo
as emoções, ativando técnicas de inteligência emocional e reconhecimento de emoções.
O professor mediador poderá ter acesso a dados biológicos do aluno durante uma exposição
de uma atividade por exemplo e podendo encontrar métodos para um melhor desempenho
(Aslan et al, 2014). É importante destacar que ao adotar essas tendências eminentes de
tecnologias o professor poderá enfrentar alguns desafios. Para alguns desses desafios incluem
se a aquisição de dados com o uso das ferramentas fisiológicas e psicológicas. Esse campo
de estudo é ainda embrionário e os pesquisadores precisam adaptar as instruções para
desenvolver a resposta do estado afetivo de um aluno. Com evidências do uso dessa
tecnologia educacional gradualmente o aluno terá um melhor desempenho em sua atuação
com o instrumento e, ou objeto educacional (BOS et al, 2019a).
O objetivo do experimento é analisar as expressões faciais juntamente com as atividades
cerebrais através da coleta de dados em um dispositivo de EEG2 (eletroencefalograma). As
pesquisas sobre os estudos do cérebro ainda são embrionárias e incipientes (Bos et al.,2020e).
Não há evidências definitivas que relacionam posições do cérebro com as funções cognitivas
e a atenção do estudante (LIU, 2010). Algoritmos e coleta de dados auxiliam e amenizam o
problema, mas não o soluciona por completo.
O artigo está estruturado da seguinte forma. A seção 2 apresenta a literatura e os trabalhos
relacionados. Na seção 3 são apresentadas as tecnologias envolvidas durante o estudo. Na
seção 4 é descrita a metodologia e os resultados do experimento e suas análises. Ainda na
última seção é abordada as considerações finais.

1

FER 2013: disponível em: https://github.com/Microsoft/FERPlus
EEG: Eletroencefalografia é um método de monitoramento eletrofisiológico que é utilizado para
registrar a atividade elétrica do cérebro.

2

470

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

2. Trabalhos relacionados
Expressão facial e reconhecimento de emoções com métodos de aprendizado profundo
“Deep Learning” foram relatados em (Kahou, 2013; Tang, 2013; Liu et al, 2014). Tang
trabalhou com um método que alcançou o primeiro lugar em dados públicos de validação e
privados no desafio FER-2013. Propuseram uma estrutura de reconhecimento de expressão
facial com restrições de peças deformáveis para localização conjunta de partes faciais e
aprendizado baseado em reconhecimento de expressões. Além disso, Liu et al, 2014
incluíram os modelos pré-treinados para extrair recursos no nível da imagem. Finalmente o
trabalho de Kahou et tal, 2013 é provavelmente o mais relacionado à nossa proposta. O
método deles seria o mais similar ao FER 2013 para o uso com vídeos.
Em 1924, Hans Berger, neurologista, capturou o primeiro eletroencefalograma (EEG) usando
um eletrodo de um cérebro humano. O EEG revelou sinais elétricos em cérebros humanos
mostrado em padrões de ondas. Com o avanço do poder da computação e a melhoria do
equipamento de EEG, o sinal de EEG pode ser melhor utilizado para interpretar os estados
do processo cognitivo e do comportamento, como atenção seletiva, memória de trabalho e
cálculos mentais. Os sistemas de EEG podem ser usados para detectar emoções humanas e
formar uma área importante na pesquisa de Interface cérebro-computador (KUMAR, 2016).
Existem muitos processos para o sistema de classificação emocional do EEG. Em primeiro
lugar, as emoções dos participantes são provocadas usando estímulos externos. Alguns
materiais são fornecidos para provocar emoções humanas, como sons, filmes e imagens (LIU,
2010).
Exemplos de sistemas comumente usados são EMOTIV e o MindWave da NEUROSKY. O
número de canais e posições entre esses sistemas são diferentes, de acordo com cada
dispositivo (BOS et al, 2019b); (BOS et al, 2020g) ;(BOS et al.,2020) h.
No entanto, muitos estudos (Coan,2004; Costafreda,2008; Holgraves,2011), sugeriram que
o lobo frontal humano é uma área informativa e afetiva para medir atividades de EEG. Em
seguida, algumas técnicas de pré-processamento de sinal digital são usadas para processar
sinais brutos de EEG, a fim de reduzir a complexidade e remover ruídos.
CÎMPANU et al. (2017) recomendaram um estudo para avaliar os níveis de memória de
trabalho, dez pessoas participaram do estudo fazendo tarefas enquanto dados de EEG foram
gravados. A seguir será exposta as tecnologias utilizadas durante o estudo.

3. Tecnologias utilizadas
3.1 Emotion FER
A tecnologia educacional utilizada durante o estudo foi arquivo de etiqueta FER 2013 da
Microsoft. Os dados consistem em imagens de faces em escala de cinza de 48x48 pixels. Os
rostos foram registrados automaticamente para que o rosto fique mais ou menos centralizado.
A tarefa é categorizar cada rosto com base na emoção mostrada na expressão facial em uma
das sete categorias (0 = Raiva, 1 = Nojo, 2 = Medo, 3 = Feliz, 4 = Triste, 5 = Surpresa, 6 =
Neutro).
O conjunto de treinamento consiste em 28.709 exemplos. Quando os computadores olham
para uma imagem, o que eles 'veem' é simplesmente uma matriz de valores de pixel (COAN,
2004). Para classificar uma imagem, o computador precisa descobrir e classificar padrões
numéricos na matriz da imagem. O reconhecimento automático de expressão facial é um

471

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

campo ativo de pesquisa. Em geral o sistema de reconhecimento de expressões consiste em
quatro principais passos. Primeiro o rosto é localizado e extraído do fundo (KAHOU, 2013).
Então, a geometria facial é estimada. Com base nisso, métodos de alinhamento podem ser
usados para reduzir a variação rígida e não rígida. Finalmente, as representações da face são
computadas. A Figura 1 mostra a imagem representativa do banco de dados do FER 2013 da
Microsoft.

Figura 1. Imagem do conjunto de dados FER; Fonte Microsoft/FERPlus

3.2 EMOTIV EPOC
Os dispositivos EPOC e EPOC+ são tendências tecnológicas na educação em pesquisas
científicas, sendo citados em mais de 900 artigos científicos, segundo base da scopus. O
sensor EMOTIV é um dispositivo não invasivo e complexo que existe para o uso em
pesquisas. Foi criado pela empresa australiana EMOTIV como um eletroencefalógrafo
portátil (EMOTIV, 2020). É uma espécie de capacete que possui 14 eletrodos fixados no
couro cabeludo. A utilização do EMOTIV na quantificação dos sinais neurais se dá pelo fato
de possibilitar a sua utilização em ambiente não invasivo, não hospitalar, no qual o meio não
será um fator de influência nos dados analisados (EMOTIV, 2020). Detecta movimentos de
cabeça com sensores de movimentos em nove eixos, trabalha com detecção de EEG bruto,
comandos mentais, métricas de desempenho e expressões faciais. O sinal é usado em nível
profissional, a qualidade do EEG registrada pelo EMOTIV é estatisticamente equivalente aos
dispositivos tradicionais de nível de pesquisa que tem um custo bastante alto e o uso
hospitalar. O EMOTIV transmite dados sem fio a 128 ou 256 Hz, para gravação de dados
cerebrais de alta resolução (EMOTIV, 2020).
As métricas de desempenho são excitação, engajamento, relaxamento, interesse, estresse e
foco. As expressões faciais são detectadas no piscar, surpresa e sorriso (Bos et al, 2019d). As
definições de marcador podem ser salvas e carregadas. Os marcadores são exibidos em tempo
real e modos de reprodução. Na Figura 2 é mostrada o display do EEG na coleta de dados.

472

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

Figura 2. Display da coleta do EEG do software do EMOTIV. Fonte;(EMOTIV, 2020)

4. Metodologia
Os testes foram realizados para dez estudantes, sendo cinco homens e cinco mulheres de uma
Universidade Federal em que foram convidados a não estar sob a influência de qualquer
estímulo como cafeína ou qualquer outro medicamento no momento do experimento. Os
participantes foram da faixa etária entre vinte anos e trinta anos de idade e cursando curso de
nível superior. Todos os participantes assinaram um termo de consentimento livre e
esclarecido. Em seguida descrevemos as etapas usadas para gerar o banco de dados. Primeiro
realizamos o experimento no conjunto de dados FER com um modelo de rede única.
Durante o experimento também foi utilizado o sensor da EMOTIV EPOC para capturar as
atividades cerebrais durante o estudo. Na execução dos testes, foi observado que o ambiente
estava livre de ruídos e perturbação nos testes com os participantes. Registramos várias
realizações para cada experimento, a fim de obter resultados confiáveis. Cada realização dura
cinco minutos, mais o tempo de preparação para o experimento com uma média de dois
minutos.
4.1. Etapa 1
O método consistiu que todos os participantes foram orientados a apreciarem dois diferentes
tipos de vídeos. Um vídeo foi com a temática de material educacional básico, sem muitas
oscilações durante o conteúdo abordado. O segundo vídeo consistiu em ter imagens mais
impactantes em animações gráficas, interações em material publicitário, ambos com cinco
minutos de visualização.
Durante o estudo o participante recebe a seguinte informação “Bem- vindos, estamos prestes
a reproduzir um vídeo para você. Enquanto o vídeo estiver sendo reproduzido, usaremos sua
webcam para determinar seu envolvimento emocional. Após o gráfico plotará seu
envolvimento com o vídeo ao longo do tempo usando várias métricas. Você pode se
concentrar em uma métrica específica clicando em um rótulo à esquerda”. Após a análise o
participante recebeu a seguinte mensagem “Análise concluída, agora que sua análise
terminou você pode reproduzir o vídeo e ver suas reações emocionais a ele ao longo do
tempo”.

473

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

4.2. Etapa 2
Enquanto isso eles foram monitorados com o dispositivo EMOTIV descrito acima. Antes de
colocar o dispositivo no couro cabeludo, os eletrodos são levemente umedecidos com uma
solução salina que melhora o contato com a pele (maior condutividade) com gravação de
sinais de EEG a uma taxa de amostragem de 512Hz com 14 canais após a conclusão de cada
apreciação do vídeo. Realizamos dois tipos de medidas: atividade cerebral fazendo o uso do
vídeo 1 e após do vídeo 2. As colunas de dados para as métricas de desempenho são ao total
de seis. Cada uma marcada com os seguintes sufixos; ENG - Engajamento; VAL - Interesse;
MED- Relaxamento; FRU- Stress; FOC - Foco; EXC- Excitação. As colunas de dados para
as bandas de frequências fornecidas pelo sensor são as seguintes: THETA - 4-8Hz, ALPHA
- 8-12 Hz, LOW BETA - 12-16 Hz, HIGH BETA - 16-25 Hz, GAMA - 25-45 Hz.

5. Resultados e discussão
Pode se observar nas figuras 3 e 4 que, ambas as experiências medidas, os resultados são
muito semelhantes, porém teve maior predominância para a categoria “Foco” na Figura 3
que apresenta as métricas de desempenho do vídeo publicitário em relação ao vídeo
educacional. O objetivo foi extrair os sinais cerebrais mais predominantes durante a execução
do experimento com o uso dos vídeos apreciados pelos estudantes. Baseados nas categorias
utilizadas pelo sensor da EMOTIV, que são: ENG - Engajamento; VAL - Interesse; MEDRelaxamento; FRU- Stress; FOC - Foco; EXC- Excitação. Na análise de desempenho de
VAL- “Interesse” na comparação com as duas medidas observa-se que a Figura 3 apresenta
uma maior oscilação positiva em Interesse com todos os estudantes voluntários. Na análise
também foi possível observar que a categoria MED - “medo” foram muito similares em
ambos os vídeos. Todo o conjunto de canais medidos foram avaliados com os métodos
descritos acima com o uso do algoritmo do sensor e suas métricas.
A computação do sinal e do algoritmo de desempenho nos permitiu avaliar as curvas
correspondentes apresentadas nos gráficos das figuras 3 e 4. Verificamos que os ritmos
coletivos extraídos no mapeamento cerebral são mais precisos ao escolher os métodos de
mídias audiovisuais. Por uma questão de clareza na apresentação, mostramos os resultados
em duas etapas, sendo os primeiros resultados com os sinais cerebrais e no segundo momento
nas Figuras 5 e 6 as expressões faciais. A seguir é apresentada a Figura 3 que mostra as
métricas de desempenho do vídeo publicitário.

Figura 3. Métrica de desempenho Vídeo Publicitário

474

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

Figura 4. Métrica de desempenho Vídeo Educacional

Nosso objetivo nessa etapa foi extrair as métricas de desempenho das categorias de
expressões faciais com base nas seguintes categorias. (0 = Raiva, 1 = Nojo, 2 = Medo,
3 = Feliz, 4 = Triste, 5 = Surpresa, 6 = Neutro). Conforme é mostrada na legenda ao lado
do resultado observado. Será discutido os principais resultados obtidos a partir dos dados
experimentais. Mostramos os resultados para o experimento a seguir apresentado nas
Figuras 5 e 6. Conforme descrito nas seções anteriores, essa fase é obtida a partir do
sinal das categorias apresentadas.
Os participantes apresentaram resultados
semelhantes em termos das propriedades e dos métodos de extração usados. Ao
observarem o vídeo publicitário em relação ao vídeo educacional oscilaram
predominantemente na categoria 5 “surpresa”. Em ambos os experimentos também foi
observada a categoria 3= “Feliz” que foi dominante. A categoria 6= “Neutro” no vídeo
publicitário teve uma percentagem de 50% entre os participantes. Já no vídeo
educacional a mesma categoria pontuou em cinco dos participantes sendo 50% deles
estar no estado “neutro” durante a exibição do vídeo. Na figura 5 apenas um dos
participantes pontuou na categoria 4= “Triste”. Já na figura 6 dois participantes
pontuaram nesta categoria. A seguir são mostradas as figuras 5 com as métricas de
desempenho do vídeo publicitário e na figura 6 com as métricas de desempenho do vídeo
educacional.

Figura 5. Métrica de desempenho Vídeo Publicitário

475

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

Figura 6. Métrica de desempenho Vídeo Educacional

Comparando as figuras 5 e 6, nota-se que o método mais consistente quando utilizado os
sinais das categorias foi a observação do tempo dos vídeos, conteúdo abordado de diferentes
categorias e o público pesquisado. Por outro lado, comparar os métodos de leitura de
atividade cerebral com a captura das expressões faciais não parece tão simples, apenas
observando as figuras mencionadas acima, por se tratar de dados biológicos e biofeedbacks
humanos que têm ciclos de oscilações, condições e ritmos diferentes e em constante
mudanças.

6. Considerações Finais
Acredita-se que a disponibilidade de um software com a detecção de emoções e a captura de
expressões faciais terá um impacto significativo nas tecnologias educacionais emergentes
para dispositivos e interfaces conectadas para o uso no ensino.
Pode se pensar que no futuro em que as tecnologias avançadas nessa área permitem que as
pessoas construam seus perfis emocionais para que possam levar consigo os dispositivos e
as experiências digitais usadas em sua vida cotidiana. Será como um passaporte emocional
que tornará as jornadas digitais mais personalizadas, autênticas e eficazes, principalmente no
âmbito educacional.
Pesquisas anteriores da psicologia sugerem que existem sentimentos ou intenção oculta por
trás das expressões faciais que ainda não há evidências dessa habilidade bem dominada.
Como trabalho futuro, pretende-se testar o desempenho das expressões faciais juntamente as
atividades cerebrais com outros recursos educacionais. Formulários poderiam ser anexados
para obter mais informações sobre as emoções do estudante no momento do experimento.
Como os sensores precisam apenas de algumas técnicas de uso, pretende-se continuar
realizando pesquisas nessa área de tecnologia. No futuro muitos aplicativos de Interface
cérebro-computador poderão se beneficiar da adoção do EPOC para ajudar nas investigações
e oferecendo mobilidade devido à sua tecnologia sem fio.
Agradecimentos: Ao IFRS (Instituto Federal do Rio Grande do Sul) e a UFRGS
(Universidade Federal do Rio Grande do Sul).

7. Referências
ASLAN, SINEM, et al. "Learner engagement measurement and classification in 1: 1
learning." 2014 13th International Conference on Machine Learning and Applications.
IEEE, 2014.
BARRETT, LISA FELDMAN, et al. "Emotional expressions reconsidered: challenges to
inferring emotion from human facial movements." Psychological Science in the Public
Interest 20.1 (2019): 1-68.

476

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

BOS, A.S; PIZZATO, M. C; ZARO, M.A. Experimento de medição do nível de Atenção do
Estudante: o uso da Mídia Interativa como Estímulo Resposta. RENOTE-Revista Novas
Tecnologias na Educação, v. 17, n. 3, 2019a.
BOS, A. S., HERPICH, F., KUHN, I., GUARESE, R. L. M., TAROUCO, L. M. R., ZARO,
M. A., WIVES, L. (2019b). Educational Technology and Its Contributions in Students’ Focus
and Attention Regarding Augmented Reality Environments and the Use of Sensors. Journal
vol.57,
n.7
of
Educational
Computing
Research.
https://doi.org/10.1177/0735633119854033
BOS, A. S.; PIZZATO, M.; ZARO, M.A. “REVISÃO DA TECNOLOGIA INTERFACE
CÉREBRO COMPUTADOR: UMA PERSPECTIVA EDUCACIONAL”. Redin-Revista
Educacional Interdisciplinar, v. 8, n. 1, 2019c.
BOS, Andreia S. et al. Student’s attention: The use of Brain Waves Sensors in Interactive
Videos. International Journal of Advanced Engineering Research and Science, v. 6, n.
4, 2019d.
BOS, A.S.; ZARO, M. A; PIZZATO, M. “Investigação da Atenção do Estudante com
técnicas de EEG: o uso da Realidade Virtual no Ensino”. In: Anais dos Workshops do
Congresso Brasileiro de Informática na Educação. 2019e. p. 1397.
BOS, A.S; PIZZATO, M.; ZARO, M.A; Investigação da atenção do estudante: o uso da
realidade virtual no ensino de computação. Tear: Revista de Educação, Ciência e
vol
8,
n.
2,
Dez,
2019f.
Disponível
em:
Tecnologia,
https://periodicos.ifrs.edu.br/index.php/tear/index
BOS, A. S., DONATO, L. G., VETTORI, M., & ZARO, M. A. (2020) g. Effects of the
binaural wave as a stimulus for student hyperattention: brain frequency records without
interactive media context. International Journal of Advanced Engineering Research and
Science,
7(9).
Retrieved
from
http://journalrepository.com/index.php/ijaers/article/view/2491
BOS A.S., VETTORI, M., PIZZATO, M., ZARO, M.A. (2020) h. “Recognition of facial
expressions: active emotions during the use of audiovisuals”, International Journal of
Development Research, 10, (08), 39779-39783.
CÎMPANU, C. et al. A Comparative Study on Classification of Working Memory Tasks
Using EEG Signals. 2017 21st International Conference on Control Systems and
Computer Science (CSCS), Bucharest, 2017, pp. 245-251.
COAN J. A. AND J. J. ALLEN, "Frontal EEG asymmetry as a moderator and mediator of
emotion," Biological psychology, vol. 67, no. 1, pp. 7-50, 2004.
COSTAFREDA S.G., M. J. BRAMMER, A. S. DAVID, AND C. H. FU, "Predictors of
amygdala activation during the processing of emotional stimuli: a meta-analysis of 385 PET
and fMRI studies," Brain research reviews, vol. 58, no. 1, pp. 57-70, 2008.
EKMAN P., SORENSON E.R., FRIESEN W. V pan-cultural elements in facial displays of
emotion. Science. 1969; 164:86–88. doi: 10.1126/science.164.3875.86.
EKMAN, P. (1993) Facial expression and emotion. American Psychologist 48(4): 384–392.
EMOTIV EPOC specifications, Emotiv, 2020. Emotiv Software Development Kit User
Manual for Release.

477

IX Congresso Brasileiro de Informática na Educação (CBIE 2020)
Anais do XXVI Workshop de Informática na Escola (WIE 2020)

FERREIRA, Valter A. et al. Operatoriedade cognitiva e experimentação virtual imersiva de
Eletricidade. RENOTE-Revista Novas Tecnologias na Educação, v. 17, n. 1, p. 375-384,
2019.
HOLTGRAVES T. AND A. FELTON, "Hemispheric asymmetry in the processing of
negative and positive words: A divided field study," Cognition and Emotion, vol. 25, no. 4,
pp. 691- 699, 2011.
IZQUIERDO I., C.R.G. FURINI, J.C. Myskiw Fear memory Physiological Reviews, 96 (2)
(2016), pp. 695-750, 10.1152/physrev.00018.2015
J. KUMAR, "Affective modelling of users in HCI using EEG," Procedia Computer
Science,vol. 84, pp. 107-114, 2016
KAHOU S.E., C. PAL, X. BOUTHILLIER, P. FROUMENTY, ¸C. GUL¸CEHRE, R.
MEMISEVIC, P. VINCENT, A. COURVILLE, ¨ Y. Bengio, R. C. Ferrari, et al. Combining
modality specific deep neural networks for emotion recognition in video. In Proceedings of
the 15th ACM on International conference on multimodal interaction, pages 543–550.
ACM, 2013
LENT, R. (2015) Neuroplasticidade. In: LENT, Roberto (Org.). Neurociência da mente e
do comportamento. Rio de Janeiro: Guanabara Koogan. p. 241-252.
LIU Y, O. Sourina, and M. K. Nguyen, "Real-time EEG-based human emotion recognition
and visualization," in Cyberworlds (CW), 2010 International Conference on, 2010, pp.
262-269: IEEE
LIU P., S. HAN, Z. MENG, AND Y. TONG. Facial expression recognition via a boosted
deep belief network. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE
Conference on, pages 1805–1812. IEEE, 2014
MAYER R. (2008). Applying the science of learning: Evidence-based principles for the
design of multimedia instruction. Cognition and Instruction 19, 177-213.
POSNER MI, PETERSEN SE. The Attention System of the Human Brain. Annual Review
of Neuroscience. 1990;13(1):25–42. pmid:2183676
SONGA G., SLABBINCK H., VERMEIR I. How do implicit/explicit attitudes and
emotional reactions to sustainable logo relate? A neurophysiological study. Food Qual.
Prefer. 2019; 71:485–496. doi: 10.1016/j.foodqual.2018.04.008
TANG Y. Deep learning using linear support vector machines. arXiv preprint
arXiv:1306.0239, 2013.
TOKUHAMA-ESPINOSA, T. N. (2008). The scientifically substantiated art of teaching: A
study in the development of standards in the new academic field of neuroeducation (mind,
brain, and education science). Capella University, MN, USA.

478

