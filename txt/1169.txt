BRAIN-COMPUTER INTERFACE VIRTUAL KEYBOARD
FOR ACCESSIBILITY
Jonathan Corley, Dustin Heaton, Jeff Gray, Jeffrey C. Carver, Randy Smith
Department of Computer Science
University of Alabama
{corle001, dwheaton}@crimson.ua.edu {gray, carver, rsmith}@cs.ua.edu

ABSTRACT
This paper describes our experiences in building a virtual
keyboard implemented using a Brain-Computer Interface
(BCI) that interacts with the eMotiv EPOC Neural
Headset. The contribution of the work is an alternative
input device for those who have a motor disability and are
challenged by traditional input devices. The advantages of
a virtual keyboard based on BCI are summarized and we
describe its design and implementation. We also present
the results of a preliminary study that has suggested
several improvements for enhancing the effectiveness of
the virtual keyboard.

KEY WORDS
Brain-Computer Interface; BCI; Virtual Keyboard;
Accessibility; Accommodating People with Disabilities;
User Interface Development; Emotiv; End-User
Development

1. Introduction
General computing skills continue to be an important
workforce need, and the inability to use such a common
instrument as the physical keyboard alienates certain
individuals from a significant portion of the workforce,
and society in general. In order to provide an accessibility
option for those who are unable to use a physical
keyboard (e.g., those with a motor disability), we have
created a Brain-Computer Interface (BCI) Virtual
Keyboard. We believe a large majority of the population
that is unable to use a keyboard or mouse will be able to
use a BCI in a meaningful way. This belief is supported
by other studies in the area of accessibility, such as
Neuper et al. [5].
We utilized the eMotiv EPOC neural headset
(hereafter referred to as the eMotiv headset) [1] as our
physical input device for several reasons. The eMotiv
headset is a consumer-ready and relatively inexpensive
option for end-users. Use of consumer-ready systems has
been suggested to provide a practically portable solution
for recording EEG signals [2]. In addition, if our virtual
keyboard proves to be successful, Emotiv provides an
application store for developers using the eMotiv headset
that would enable us to easily distribute our software. The

eMotiv headset detects sensorimotor signals, which are
neurological signals related to motor control. This
approach differs from many other implementations. For
example, P300-based systems rely on a signal from the
brain that is generated as a response to outside stimuli [4].
Systems that rely on outside stimuli force the selection
rate to be determined by the stimuli, as opposed to the
user. The eMotiv headset does not rely on any outside
stimuli, which we believe will give users a greater sense
of control.
In the remainder of this paper, we present a novel
system designed with the goal of producing a viable
alternative input device for those unable to use a physical
keyboard. We will first identify a number of challenges
that must be overcome for our system to be a useful
keyboard alternative, and then we will outline how we
addressed those challenges. We will then present a
preliminary study that evaluates the current
implementation of our system. The study compares our
results to those obtained from several other similar BCI
systems. Finally, we will discuss lessons learned from
both the user study and the design.

2. Design of a BCI Virtual Keyboard
This section outlines some of the challenges encountered
and the design approaches that we considered while
building our BCI virtual keyboard.
2.1. Challenges in using a BCI Virtual Keyboard
When considering the intended user base of the system
(i.e., those with a motor disability), we identified the
following challenges that guided our design:
1. Not all users will be capable of producing each
input signal with the same consistency;
2. Not all users will be capable of producing the full
range of input signals;
3. The design should be reusable with different
languages;
4. User familiarity, or lack thereof, with keyboard
layouts could affect user experience;
5. The large number of inputs available on a modern
keyboard could be overwhelming if presented to
the user all at once;

6.

The device we are using has a limited number of
available inputs that is greatly exceeded by the
number of inputs available with a traditional
keyboard.

In addition to the listed challenges and design
objectives, we considered the effect of requiring users to
train with the eMotiv headset. A new user will need to
spend an initial period of training time to configure the
eMotiv headset reliably and accurately. This training time
may be a burden to some users upon first use. However,
we believe our target user base will have the motivation to
endure a period of training. Although we would like to
study the effect of varying training times in the future, we
currently are not certain about the optimal amount of
training that will be required from users. Therefore, to
mediate the impact of this unknown factor, a user is only
required to produce a subset of the full range of input
signals the eMotiv headset is capable of processing. In our
most recent interactions with experimental users, we
observed that a 10 minute training time was sufficient. We
plan to investigate this issue further in future works.
2.2. Details of the Design and Implementation
This project was developed in Java using Eclipse. Java
was chosen because of our past experience and the
relative ease of designing a graphical user interface in
Java. The eMotiv API is provided as a native C++ DLL.
However, Emotiv provides a wrapper that utilizes the Java
Native Access library to enable Java developers to utilize
the eMotiv API. Additionally, the project uses the Java

Robot class to send keyboard input from the virtual
keyboard. The Robot class allows programmatic control
of the mouse and keyboard (e.g., directing the mouse to a
specific location of the screen or programmatically
generating keyboard button events).
The overall architecture of the design focuses on an
implementation of the Model-View-Controller design
pattern. In this implementation, the model is the Virtual
Keyboard, the view is the Graphical Display, and the
controller handles the mapping of headset inputs to
functions we designed in the model. We believe this
architecture allows for flexibility in our implementation.
This flexibility can be realized by altering the controller to
allow for different devices to utilize the same model and
display. Additionally, the display could be tailored to
various user expectations dependent on platform-specific
or societal conventions.
During the initial design phase, we identified a
number of challenges that were used to guide our design.
We overcame several of these challenges through user
customization. First, in order to address Challenge 1 (i.e.,
that not all users will be capable of producing each signal
with the same consistency), we allowed the headset inputs
to be mapped to functions based on an XML configuration
file. The input mapping allows a user to choose the most
appropriate inputs for his or her ability (e.g., left- or rightwink). To address Challenges 2 and 6, our system is
designed to only require at least two distinct input signals.
Each available input signal maps to one of the following
actions that are ordered by an initial assessment of
usefulness (most useful to least useful):

Figure 1. Annotated Screen Shot of the BCI Virtual Keyboard

1.
2.
3.
4.
5.
6.

Select
Move Right
Move Out
Move Down
Move Left
Move Up

To realize this limited number of inputs, we created a
model of the keyboard where the user navigates through
the keys to make a selection. Because of Challenge 5, we
needed to minimize the average number of movements
required to navigate to each key. We accomplished this by
utilizing a drill-down approach in which the user starts at
a high-level and selects a set of keys and then navigates
within this reduced set, selecting increasingly smaller sets
until the current set contains only a single key. At this
point, the user selects the desired key and the system
simulates the user pressing that key. In addition, each
movement utilizes a wrapping implementation to allow
the ability to reach any key. Also, in order to address
Challenges 3 and 4, we allow the keyboard layout to be
mapped from an XML file. This allows the keyboard to be
tailored to the layout most comfortable to the user and to
utilize the appropriate keys for the language(s) of the user.
A screenshot of the current graphical interface of the
system is shown in Figure 1, where the three levels of the
drill-down approach are indicated: group, section, and
key. In this architecture, a group contains sections and a
section contains keys. The user begins at the group level,
selects a group, then selects a section from within that
group, and finally selects a particular key.
The eMotiv headset provides several recognition
suites: the Expressiv and Cognitiv suites. The Expressiv
suite detects neural signals related to facial feature
movements (e.g., a blink). The Cognitiv suite allows the
user to train the system to recognize custom neural states.
The Expressiv suite provides enough available input
signals to satisfy the needs of our virtual keyboard.
However, we recognized that not all users are capable of
utilizing the full suite. The Cognitiv suite provides the
freedom to define inputs that are tailored to an individual.
Unfortunately, as more custom inputs are added, the
difficulty for the user to reproduce a specific signal
increases significantly, as stated in the eMotiv SDK
documentation [1]. Therefore, we allow the user to utilize
a combination of inputs from both suites in order to
ensure that the capability of the full system is available to
all users.

3. Empirical Evaluation of the Keyboard
In this section, we present the design and results of an
empirical user study that was used to evaluate the current
implementation of our system.

3.1. User Study Details and Experimental Context
In order to evaluate the effectiveness of our system to
assist a user in entering text without a physical keyboard,
we performed a user study with seven participants. The
user tests were set up as follows:
1. We utilized the eMotiv EPOC Control Panel to
familiarize each participant with the facial
feature recognition system (Expressiv).
2. We configured a user profile for each participant,
including
the
training
and
sensitivity
adjustments, the input mappings, and the
keyboard layout.
3. We allowed each participant approximately 10
minutes to become familiar with the keyboard
layout and navigation scheme.
4. We tasked each participant with typing a
selection of text using the virtual keyboard
utilizing only the Expressiv suite. Each
participant had 5 minutes to complete this task.
5. We utilized the eMotiv EPOC Control Panel to
train each participant to perform one input from
the mental state recognition system (Cognitiv).
Each subject was given approximately 10
minutes to complete this training task.
6. We updated each user profile based on the
feedback from steps 4 and 5.
7. We allowed participants to familiarize
themselves with utilizing the Cognitiv input in
the context of the virtual keyboard.
8. We tasked each participant with typing a
selection of text using the virtual keyboard
utilizing both the Expressiv and Cognitiv suites.
Each participant had 5 minutes to complete this
task.
9. We asked each participant to complete a brief
survey composed of the following questions that
were measured on a 5-point scale:
a. How would you rate the responsiveness of
the keyboard without Cognitiv input?
b. How would you rate the responsiveness of
the keyboard with Cognitiv input?
c. How would you rate the accuracy of the
keyboard without Cognitiv input?
d. How would you rate the accuracy of the
keyboard with Cognitiv input?
e. In a scenario involving daily use, assuming a
standard keyboard is not available, how
comfortable would you be with using this
device?
f. In a scenario involving occasional use,
assuming a standard keyboard is not an
option, how comfortable would you be with
using this device?
g. The device met your expectations
h. Overall Satisfaction

User

Average
Inputs per
Selection

Average
seconds /
selection

user1

75.11

84.50

100.00

user2

30.97

27.20

90.00

user3

37.36

27.43

85.71

user5

67.84

16.50

100.00

user6

42.37

34.50

83.33

user7

37.76

46.20

0.00

AVG.

48.57

39.39

76.51

user4

312.46

332.00

100.00

took the same participants 39 seconds to make each input
when using Cognitiv input. Additionally, the average error
rate when participants were not using Cognitiv input was
38.7%, which increased to 76.5% when participants
performed the same task while using Cognitiv input. One
participant was excluded from the analysis of the Cognitiv
input because their average selection time suggested that
they were unable to control the system properly to provide
meaningful input.
Participants rated the responsiveness when they were
not using Cognitiv as 3.7. When Cognitiv input was
added, the responsiveness rating dropped to 2.7.
Participants rated their comfort using the system in an
occasional use scenario with an average of 2.3. In a daily
use scenario, the average comfort rating dropped to 1.7.
The majority of users felt that the device met their
expectations, with all but one user rating this criterion a 3
or better. However, the average overall satisfaction was a
2.7, indicating the participants were slightly unsatisfied
with the system. Details of the results of the user survey
can be found in Table 3.

Error Rate
(%)

Table 1. Results with Cognitiv Input
(user 4 excluded due to inability to use system)

User

Avgerage
Inputs per
Selection

Average
seconds /
selection

user1

15.99

6.16

57.89

user2

43.91

24.43

28.57

user3

18.30

13.13

6.25

user4

22.73

9.29

71.43

user5

50.29

26.50

66.67

user6

32.51

20.45

18.18

user7

16.64

10.89

22.22

AVG.

28.62

15.83

38.75

Error Rate
(%)

4. Related Works
There are several BCI applications described in the
literature. We found similar systems that provide context
and comparison with our own virtual keyboard. These
previous results are summarized in Table 4 along with
relevant system details.
After reviewing similar works, we found that the
studies with the highest number of input selections
possible had between 25 and 40 available selections. Our
system possesses 128 distinct inputs before considering
key combinations. However, we believe this will not be a
significant hindrance from achieving similar results. The
study performed by Sellers and Donchin demonstrated
that the technique they utilized (P300-based speller)
required extending the time per selection to an
unreasonable rate in order to improve the accuracy to an
acceptable level [6]. Thompson et al. presented an
evaluation of a plug-and-play BCI interface which
included an evaluation of three P300-based spelling
interfaces [7]. The three interfaces evaluated were
BCI2000, DynaWrite, and Compass. They found that the
BCI2000 environment resulted in a 13% mean error rate
but had an 11% standard deviation. DynaWrite had a 13%

Table 2. Results without Cognitiv Input
3.2. Results of our User Evaluation
As shown in Table 1 and Table 2, every measured
criterion was improved significantly when using the
system without Cognitiv input (as compared to when
using it with Cognitiv input). In particular, the average
time it took the participants to make a selection when not
using Cognitiv input was 15.8 seconds. On average, it
User/Question
1
2

a
3
4

b
2
4

c
2
3

d
3
1

e
2
1

f
4
2

3
4
5
6
Average

3
4
4
4
3.67

1
3
1
2
2
3
4
3
1
1
1
3
1
2
2
5
3
1
2
3
2.67
3.00
1.67
1.67
2.33
Table 3. Results from User Survey

g
4
3

h
4
3

3
1
3
3
2.83

2
2
2
3
2.67

Sellers and Donchin [6]

System
Type
P300

Number of Available
Selections
36

Error
Rate (%)
25

Selection Rate
(seconds per selection)
22.4

Sellers and Donchin [6]
Yue et al. [3]
Neuper et al. [5]
Thompson, et al. [7]
Thompson, et al. [7]
Thompson, et al. [7]

P300
Sensorimotor
Sensorimotor
P300
P300
P300

36
40
26
36
36
36
Table 4. Related Works

8
15
15-30
11
13
13

106
NA
~60
3.5
3.5
3.5

Reference

mean error rate, but a 9% standard deviation, meaning
that it was equal to BCI2000 in a worst-case scenario.
Compass again had a 13% mean error rate but only a 5%
standard deviation. The accuracy reported by Thompson
et al. was obtained with a selection interval of 3.5s.
The technique used by Yue et al. demonstrated a
comparable accuracy rate using a sensorimotor rhythmsbased speller [3]. In addition, Neuper et al. presented a
study with accuracy rates similar to those proved by Yue
et al., also using a sensorimotor rhythm-based speller. The
study conducted by Neuper et al. is particularly
noteworthy, because the participants were patients
suffering from neurological diseases affecting various
functional components of the nervous system [5]. This
study showed that users with damage to their nervous
system were able to utilize a BCI that recognized
sensorimotor signals at a comparable level to those
without nervous system damage. Our goal is to provide an
accessibility option to individuals unable to use a physical
keyboard. From our target group, we expect a significant
portion of users will have nervous system damage.
While our error rate is higher than the studies
mentioned previously, our selection rate without using
Cognitiv input is lower than three of the techniques used
in the related studies. However, our implementation must
be improved to achieve a lower error rate and selection
rate in order to realize our goal of providing a viable
accessibility option for users unable to use a physical
keyboard. We suggest a goal of 10 seconds per selection
and an error rate of no more than 15%.

5. Discussion of Lessons Learned
In this section, we discuss lessons learned regarding both
the results of the user study as well as the design of the
virtual keyboard.
5.1. Lessons Learned Regarding the User Study
We believe the limited amount of time allotted for training
the participants was a significant hindrance to the
participants’ ability to accurately and quickly make
selections. This belief is strongly supported by the
immediate feedback from users during the testing and on

the follow-up survey. Providing additional training time
has the potential to increase both the accuracy and
responsiveness, along with the user’s overall satisfaction.
Though this increase in training time may seem
detrimental to the eventual adoption of our system or a
similar implementation, we believe the target user-base
will have the motivation to endure the training times,
which are also limited to the first use of the keyboard.
Another significant factor was the lack of direction
given to the participants during the training process. The
participants were introduced to the device and the virtual
keyboard through basic descriptions of functionality. In
order to judge the intuitiveness of our system, the
participants were not given a significant amount of
guidance regarding how to utilize the system effectively.
They also were not given any specific training tasks. We
believe this led to most participants failing to gain a
complete understanding of the system. The Cognitiv input
particularly was ineffective due to the training not
reflecting actual usage. The Cognitiv training focused on
using the eMotiv EPOC Control Panel rather than using
the virtual keyboard. The significant difference is that the
participants were not required to utilize Cognitiv and
Expressiv inputs concurrently during training. We believe
a structured training process would improve both
accuracy and responsiveness significantly. Furthermore, a
structured training process would provide participants
with a more thorough understanding of the system, which
should increase the participants’ comfort in using our
virtual keyboard.
5.2. Lessons Learned Regarding the System Design
Several potential improvements to the design were
uncovered. The simplest of these was altering the display
to convey to the users that the modifier keys utilized a
sticky key implementation (i.e., when a modifier key is
pressed, the modifier would remain active until the
modifier key was pressed again). This could be achieved
by highlighting the modifier keys while they are active. A
more complex improvement uncovered was revealed by
user frustration with the movement feature; specifically,
the implementation where any movement key can be used
to access any key on the keyboard if it is the only
movement key available. The current implementation
causes a movement key to produce a wrapping effect (i.e.,

when the current key is at the end of a row or column, the
movement key moves the current key to the beginning of
the next row or column). The wrapping effect was found
to be disorienting for users when they bypassed the key
they wished to select. The users generally responded to
this situation by backing out of a section and restarting the
selection process. This response led most users to increase
the number of movements required to make the next
selection and increased user frustration.
Other potential improvements were suggested
directly by users. The suggested improvements include:
 Adding support for macro keys to streamline the
selection of common key sequences.
 Changing the Shift key to not utilize the sticky
key implementation due to the high number of
situations that called for the Shift key to be
activated and then immediately deactivated (e.g.,
when capitalizing letters).
 Some users suggested the addition of an input
that deactivates and reactivates the system to
prevent users from making unintended selections
during periods where the user is not actively
utilizing the system.

6. Threats to Validity
In this section, we present the identified threats to the
validity of our study.

7. Conclusion and Future Work
We presented a novel system with the goal of producing a
viable alternative input device for those unable to use a
physical keyboard. Our system is implemented using a
BCI device; in particular, the eMotiv headset. We began
by identifying a number of challenges that needed to be
overcome for our system to be a viable keyboard
alternative, and outlined how our design overcame these
challenges. We then presented a preliminary study that
evaluated the current implementation of our system. The
study was followed by a user survey that gauged the
users’ satisfaction. The results of our preliminary study
were very promising, but demonstrated a need for
improvement in the current implementation. We then
presented several studies of similar BCI systems and
compared our results to those found in the related studies.
We then discussed our lessons learned. Finally, we
discussed the threats to the validity of our study.
We believe our virtual keyboard, or a similar
implementation, can achieve our stated goal of an
accessibility option for users incapable of using a physical
keyboard. Our current plans are to implement the
improvements outlined in the lessons learned section and
to perform a more thorough study that incorporates the
lessons learned. We expect the enhancements to the
system and an improved training procedure will increase
the selection rate and accuracy significantly.

6.1. Internal Validity

Acknowledgements

Users were required to first test the system with only the
Expressiv suite active, followed immediately by testing
the system using both the Expressiv and Cognitiv suites.
This repeated testing could cause a fatigue effect that may
have contributed to the increased selection and error rates.
We accepted this threat because each participant was only
available for a brief time. Alternatively, the users could
have gained experience from the first test that would have
carried over to the second test, therefore decreasing
selection and error rates. With the limited number of
subjects, the study asked all participants to use the same
ordering of tasks. The group size would be too small to
determine significance if the subjects had been separated
into different orderings.

The authors would like to thank the participants in our
user study. This work was largely supported by a
Department of Education GAANN grant (P200A100182).

6.2. Construct Validity
The participants in our study were not from within the
target audience (i.e., our participants are able to use a
traditional keyboard, but participated in our study by
using only the virtual keyboard). We believe this is an
acceptable threat. Comparing our results to those of
Neuper et al. [5] demonstrates our results are similar to
those of the target audience. Furthermore, given the
timeframe and emergent sensitivity of the device, it was
infeasible to involve users from the target demographic.

References
[1] Emotiv | EEG System | Electroencephalography. ().
[2] H. Cecotti, Spelling with non-invasive Brain-Computer
Interfaces - Current and future trends. Journal of
Physiology - Paris, 105, 1-3 (2011-01-00 2011), 106-114.
[3] J. Yue, J. Jiang, Z. Zhou & D. Hu, SMR-Speller: A novel
Brain-Computer Interface spell paradigm. In Anonymous
Computer Research and Development (ICCRD), 2011 3rd
International Conference on. (). , 2011, 187-190.
[4] D. J. McFarland & J. R. Wolpaw, Brain-Computer
Interfaces for Communication and Control Commun ACM,
54, 5 ( 2011), 60-66.
[5] C. Neuper, G. R. Muller-Putz, R. Scherer, & G.
Pfurtscheller, Motor imagery and EEG-based control of
spelling devices and neuroprostheses Prog. Brain Res., 159(
2006), 393-409. 6123(06)59025-9.
[6] E. W. Sellers, and E. Donchin, A P300-based braincomputer interface: initial tests by ALS patients Clin.
Neurophysiol., 117, 3 (Mar 2006), 538-548.
[7] D. E. Thompson, J. J. Baker, W. A. Sarnacki, & J. E.
Huggins, Plug-and-play brain-computer interface keyboard
performance. In Anonymous Neural Engineering, 2009.
NER '09. 4th International IEEE/EMBS Conference on. (). ,
2009, 433-435.

