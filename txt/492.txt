35th Annual International Conference of the IEEE EMBS
Osaka, Japan, 3 - 7 July, 2013

Hybrid EEG and Eye Movement Interface to Multi-Directional
Target Selection
Minho Kim, Yongwook Chae, and Sungho Jo, Member, IEEE


Abstract— This work addresses the development of a low-cost
hybrid interface with eye tracking and brain signals. Eye
movement detection is used for search task and EEG-based
brain computer interface (BCI) for selection task.
Multi-directional target selection experiments with the hybrid
interface device were conducted with five subjects to evaluate
the proposed hybrid interface scheme. The task asked each user
to move a cursor onto a circular target among twelve possible
positions and select it. Using the Fitts’ law, the interface
performance was compared with the computer mouse. With two
BCI selection confirmation schemes, the hybrid interface
attained 2-2.7 bit/s overall. Based on the results, the potential of
the proposed hybrid interface was discussed.

I. INTRODUCTION
EEG-based BCIs have been of huge interest because of
their potentials [1-2]. The sensors are noninvasive, therefore,
users feel convenience relatively and the recording procedure
is safer. Many interesting studies have demonstrated the
feasibility of EEG-based BCI as applications to improve the
quality of life of either physically disabled or healthy people.
Although EEG-based BCI techniques have significantly been
improved, its practical real-life usage is yet in reality. The
techniques have limited bandwidth, and mostly require
intensive training for the system to be tuned optimally for a
specific user.
As an approach to overcome the limitations, hybrid BCI
has been paid attention to [3-5]. The concept of hybrid BCI
suggests to use different brain signal protocols together or to
combine BCI with non-brain signal-based protocols. In the
way, more extended control capacity is realized. Among
various possible combinations of signals, integrating simple
interfaces together, which asks little training, can be thought
to enhance the adaptability of users with respect to practical
purpose, while increasing the number of commands.
This work aims to evaluate the promising hybrid interface
scheme of eye movement and EEG-based BCI, especially,
with an inexpensively built comfortable system. Instead of
focusing on advancing the performance of the hybridization,
this work attempts to examine its feasibility as a potential
approach to real-world applications through quantitative
performance evaluation. The Fitts’ law has been widely
* This research was supported by the Agency for Defense Development
under Grant UD1100511D, and by the Korean government (MKE) under
Human Resources Development Program for Convergence Robot
Specialists.
Authors are with the Department of Computer Science, Korea Advanced
Institute of Science and Technology (KAIST), Daejeon, Korea
(corresponding author to provide phone: 82-42-350-3540; fax:
82-42-350-3501; e-mail: shjo@kaist.ac.kr).

978-1-4577-0216-7/13/$26.00 ©2013 IEEE

adopted in human computer interaction (HCI) as a description
of a frequent elemental task such as pointing and target
selection as well as a predictive model to estimate the
response time [6]. In most cases of BCI studies, evaluation
was conducted based on some quantities such as accuracy and
information transfer rate [7-10]. However, those may not be
enough to express synthetic assessment especially with
respect to practical HCI. Previously, an investigation applied
the Fitts’ law for BCI evaluation [11]. However, no attempt of
quantitative evaluation of a hybrid interface case has been
reported. This work uses the Fitts’ law for overall assessment
of the proposed hybrid interface system.
II. HYBRID INTERFACE
A. System Overview
This work uses both low cost BCI and eye tracking systems:
Emotiv Epoc EEG recording headset [12], and hand-made
eye tracking equipment. The EEG recording headset consists
of fourteen electrode channels plus CMS/DRL references
around the sensorimotor cortex (see Fig. 1). The headset was
designed as personal interface system for HCI. Its cost is very
cheap ($299) relatively compared with standard EEG
recording systems (at least $5000). Its potential as a reliable
recording system has been studied in some previous
investigations [10, 13].

Figure 1. Hybrid interface system.

Fig. 1 also shows the eye tracking system. The total cost to
build it was less than $40. An eye tracker was built based on
previous studies [14-15]. It consisted of two components: an
infrared camera, and light-emitting diodes (LEDs). Five
LEDs was fixed around the lens of the infrared camera that
was connected to a glasses frame at about 8 cm away from a
left eye. When a subject wore the glasses frame, the camera

763

was toward human left eye to capture its image. LEDs
illuminated an eye to enhance the contrast between the pupil
and the iris. The eye tracking system applied standard image
processing methods for pupil detection based on the open
source [16].
The combination of the two low cost BCI and eye tracking
systems comprised a hybrid BCI system used for this work.
Each system modules for data acquisition and processing
were developed separately, but integrated using the .NET
framework to realize synchronous operation of the two
systems. Performance measurement and calibration modules
for each system were also programmed.
B. Data Acquisition
The data sets in this pilot study were recorded from ten
healthy subjects (age 24.60 ± 3.38 (mean±SD) years) without
any prior experience with eye tracking and EEG-based BCI.
They all gave the written informed consent. The KAIST
Institutional Review Board approved the proposed
experimental protocol of this study. Each participant was
seated comfortably in a chair facing the monitor screen,
which was placed about 1 m in front of the subject on a table.
Each subject wore the hybrid interface system. The head
mounted eye tracker captured images of eye movement with a
spatial resolution of 640 320 pixels at sampling rate of 60 Hz.
Using the Emotiv Epoc headset, EEG data were recorded at
sampling frequency of 128 Hz from fourteen channel layout
(AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4
in international 10-20 standard locations). The recorded EEG
data were band-pass filtered between 1 and 50 Hz.
C. Signal Processing and Decision Making
1) BCI
Before the experiment, each user was asked to go through a
set of training sessions, which recorded the user’s EEG
signals in two different phases. These phases represented
“neutral state” and “concentration state”, and were presented
36 times, 6 seconds each with visual instructions. During the
“concentration phase”, the user was asked to gather his
attention to a certain point on the screen, while he was asked
to stay calm during the “neutral phase”. Using the acquired
data, the detection of the concentration state implemented the
selection of a current cursor position. For the two class
classification problem, which classifies to one of “neutral
state” or “concentration state”, a popular technique for feature
extraction in EEG-based BCI, Common Spatial Patterns
(CSP) algorithm [17], was used to find spatial filters which
extract features for classification. Let
and
represent a
set of signals during neutral state and concentration state
respectively. Then, CSP found spatial filters
that
extremized the following function.

Each
indicates the spatial covariance matrix of an
associated class assuming a zero mean for EEG signals. The
zero mean assumption was met by preprocessing when EEG
signals are band-pass filtered. Using the Lagrange multiplier

method, the optimization problem was transformed to be a
standard eigenvalue problem. The eigenvectors of
which corresponded to its largest and lowest principal
eigenvectors respectively are selected as the spatial filters for
extremization. Then, the EEG signals from the whole
channels were projected onto the filters. The power spectrum
of projected signals was estimated using the Burg method
based on an autoregressive (AR) model of order p (p=12 in
this work). The power values between 7 and 13 Hz from each
EEG signal were assigned to be extracted features. Then, an
optimal classifier based on the features acquired from EEG
signals was determined by Support Vector Machines (SVM)
algorithm. The MATLAB SVM functions were used to
implement the computation of the SVM-based classification.
In real-time, data points acquired from every 1 s time
window with 125 ms increment were used to classify a
selection state. To finalize selection robustly, two selection
confirmation schemes were designed: the first scheme, short
selection confirmation, required detection of two consecutive
selection states to confirm final selection. The second scheme,
long selection confirmation, enforced the final confirmation
by requesting four consecutive selection states instead of two.
2) Eye tracking
Points in the contour between pupil and iris from each
binarized image were extracted, and then, were fitted to an
ellipse to estimate the center of the pupil. The RANSAC
algorithm was applied to eliminate outliers among the
extracted points. Using a second-order polynomial for each
axis, horizontal and vertical, a gaze point was interpolated.
The coefficients of the polynomials were calculated through
the calibration procedure.
D. Experiment Design
This work evaluated the proposed hybrid interface through
multidirectional cursor control tasks. Among twelve possible
circular target placements in a circular arrangement, any one
appeared on the 48 inch screen. There were two task modes:
search and selection. At the beginning of each trial, a cursor
was placed at the center of the circular arrangement and no
circular target was visible. When a red circular target at an
arbitrary location appeared, a subject had to move the cursor
to the target circle as quick as possible. This is the search task
mode. Then, each subject had to select the target. This is the
selection task mode. A successful target selection was
complete when any point in the target circle was selected
within a limited time of 6 s since a trial begins. If selection
was not rightly performed within the time limit, the trial was
regarded to be failed. Each target appeared exactly one time
in a random order during a sequence of twelve trials, therefore
each subject tried all the twelve target selections one time per
each. Three different (large, middle, small) sizes of circular
targets, and two different (short, long) distances were
assigned so that cases were differentiated to classify the task
difficulty levels. Experiments were repeated at different task
difficulty levels.
E. Performance Evaluation
Fitts’ index of difficulty (ID) describes the relative
difficulty of a particular movement used in a task, and is

764

based on the distance ( ) from a starting point to a target point,
and the width ( ) of the target [6]. In the general Fitts’ law,
movement time (MT) is set to a function of ID. In our
experiment tasks, not only pointing a target point but also
selecting the point should be accomplished. Therefore, we
define task completion time (T), which indicates the total
time taken during tracking and selecting. The index of
performance (IP) (bits/s) is calculated by taking the reciprocal
of the slope b in the linear regression equation.

is illustrated in Fig. 2 with averaged estimation across
subjects. The results of two selected subjects, best and worst
performers, using the proposed hybrid interfaces are shown in
Figs. 3 and 4 respectively. With both short and long selection
confirmations, the subject S3 performed relatively evenly over
the different difficulty levels. He completed tasks within 1.5 s
and 2 s with short and long selection confirmations
respectively. Meanwhile, the subjects S1 and S4 achieved
lowest IP values with short and long selection confirmations
respectively. Their performances depended on the difficulty
levels.

In this study, experiment parameters were set to
120,
80, 40 pixels (7.8, 5.2, 2.6 cm) and
320, 480 pixels
(20.8, 31.2 cm) respectively. The combination of the
parameters resulted in five different difficulty levels totally.
Using the Fitts’ law, it can be shown how quickly tasks at
different difficult levels can be performed and how much
information the interface can transfer.
III. EXPERIMENT
Five subjects conducted the multi-directional search and
select tasks using the proposed hybrid interface with two
different selection confirmation schemes mentioned in section
II.D.1). The performances were compared with them using a
commercial computer mouse. With the short selection
confirmation scheme, the success rate of the task performance
averaged across subjects was 96.67(±4.08) % and
78.33(±22.11) % at the lowest and highest ID levels
respectively. With the long selection confirmation scheme, it
was 96.67(±4.08) % and 73.33(±25.50) % at the lowest and
highest ID levels respectively. In this experiment, the highest
ID was 4.6 (bit). It indicates quite a difficult task generally.

Figure 2. Relationship between T and ID with the developed interface and
the mouse averaged across subjects

TABLE I.

INDEX OF PERFORMANCE ON CURSOR CONTROL USING THE
DEVELOPED INTERFACE AND THE MOUSE WITH FIVE SUBJECTS
subjects

S1

S2

S3

S4

S5

Overal
l

Hybrid

IP (bit/s)

1.28

1.32

5.00

1.35

3.03

2.70

Short

R2

0.71

0.87

0.58

0.93

0.54

0.58

Hybrid

IP (bit/s)

2.22

6.67

7.14

1.16

2.00

2.00

Long

R2

0.35

0.16

0.18

0.88

0.75

0.81

IP (bit/s)

3.13

9.09

20.00

5.88

33.33

11.11

R2

0.42

0.92

0.42

0.79

0.22

0.97

Mouse

Figure 3. Relationship between T and ID with the developed interface for
two selected subjects using the hybrid interface with short selection
confirmation.

(Hybrid Short: hybrid interface with short selection confirmation, Hybrid Long: hybrid
interface with long selection confirmation, R2: correlation coefficient)

Table 1 summarizes the experimental result. The overall IP
of the proposed hybrid interface was 2.7 bit/s and 2 bits with
short and long selection confirmation schemes respectively,
whereas the overall IP of the mouse was 11.11 bit/s. The short
selection confirmation case obtained a bit higher IP in average
than the long selection confirmation case. However, some
subjects achieved higher IP with the long selection
confirmation scheme. A specific subject S3 performed the
tasks with the proposed interfaces at IP of 5 – 7.14 bit/s. Every
subject achieved IPs above 1 bit/s. The Fitts’ law relationship

765

Figure 4. Relationship between T and ID with the developed interface for
two selected subjects using the hybrid interface with long selection
confirmation.

[5]

IV. DISCUSSION AND CONCLUSION
During the task implementation using the proposed hybrid
interface, some subjects tended to feel difficult to maintain
the point still in a target circle while the BCI protocol
operated selection. However, although there is a clear
difference over the adeptness in the system usage, subjects
could complete tasks successfully most times within the time
limit.
The overall IPs of the proposed hybrid interfaces were
lower than that of the mouse interface (11.11 bit/s). However,
they were higher than that (0.541 bit/s) of the BCI only
interface reported in [11]. An interesting comparison is with
the EMG interface. According to a previous report [18], the
overall IP of the EMG interface was 1.299 bit/s, which is
lower than them of the proposed hybrid interfaces. Therefore,
the performance of the proposed hybrid interface was
approximately twice better than that of the EMG interface,
and five times better than that of the BCI only interface.
Although the proposed hybrid interface could not perform as
well as a mouse, the current results show that the proposed
hybrid interface may be an appropriate choice for physically
disabled people.
Cursor movement is controlled by eye tracking. Therefore,
any directional cursor movement in the two dimensional plan
is possible, and cursor speed can be controlled as a user
wishes. The point selection or click is decided by a simple
BCI protocol. It is much more intuitive and natural than the
eye dwell time clicking interface mainly used in typical eye
tracking methods, because the selection is triggered by an
intuitive imagination such as that of attention focusing. The
BCI protocol, which the developed interface relies on,
requires no serious training session. Therefore, a user can
easily be accustomed to the proposed interface device. As a
user gets more familiar with the device, the performance
would be dramatically more improved than the current results
in this study.
This study presents important implications for future work
on developing hybrid interface devices especially at low cost.
The hybrid eye tracking and BCI interface system will be
effective to any people as long as they have no degradation on
the ocular-motor system and motor planning and decision
making brain areas. In addition, its operation scheme is
natural and intuitive. The proposed interface system should
be tested with people with motor disabilities in the future to
further confirm its feasibility.

[6]
[7]
[8]
[9]
[10]

[11]

[12]
[13]
[14]
[15]

[16]
[17]
[18]

ACKNOWLEDGMENT
The authors appreciate anonymous reviewers for valuable
comments.
REFERENCES
[1]
[2]
[3]
[4]

D. McFarland, and J. Wolpaw, “Brain-computer interfaces for
communication and control”, Commun. ACM, Vol. 54, pp. 60-66, 2002.
G. Dornhege, J. del R. Millan, T. Hinterberger, D. Farland, and K.-R.
Müller, Toward Brain-computer interfacing, Cambridge, MA: MIT
Press.
G. Pfurtscheller, et al, “The hybrid BCI “, Front. Neurosci. , Vol. 4,
No. 30, pp.1-11, 2010.
B.Z. Allision, et al, “Toward smarter BCIs: extending BCIs through
hybridization and intelligent control”, J. Neural Eng, Vol. 9, 2012.

766

J. del R. Millan, “Combining brain-computer interfaces and assistive
technologies: state-of-the-art and challenges”, Front. Neurosci., Vol. 4,
161, 2010.
R.W. Soukoreff, and I.S. MacKenzie, “Towards a standard for pointing
device evaluation, perspectives on 27 years of Fitts’ law research in
HCI”, Int. J. Hum.-Comput. Studies, Vol. 61, pp. 751-789, 2004.
J. Park, K.E. Kim, and S. Jo, “A POMDP approach to P300-based
brain-computer interfaces”, in Proc. of Int. Conf. Intell. User Interfaces
(IUI), 2010, pp. 1-10.
Y. Chae, J. Jeong, and S. Jo, “Toward brain-actuated humanoid robots:
asynchronous direct-control using an EEG-based BCI”, IEEE Trans.
Robotics, Vol. 28, No. 4, 2012.
G.R. Müller-Putz, and G. Pfurtscheller, “Control of an electrical
prosthesis with an SSVEP-based BCI”, IEEE Trans. Biomed. Eng.,
Vol. 55, No. 1, pp. 361-364, 2008.
A.T. Campbell, et al, “NeuroPhone: brain-mobile phone interface using
a wireless EEG headset”, in Proc. of ACM SIGCOM workshop on
Networking, Systems, and applications on mobile handhelds, 2010, pp.
3-8.
E.A. Felton, R.G. Radwin, J.A. Wilson, and J.C. Williams, “Evaluation
of a modified Fitts law brain-computer interface target acquisition task
in able and motor disabled individuals”, J Neural Eng., Vol. 6, No. 5,
2009.
EmotivSystems. Emotiv - brain computer interface technology.
http://emotiv.com.
P. Bobrov, et al, “Brain-computer interface based on generation of
visual images”, PLoS ONE, Vol. 6, No. 6, 2011.
D. Li, J. Babcock, and D.J. Parkhurst, “OpenEyes: a low-cost
head-mounted eye-tracking solution”, in Proc. Symp. Eye Tracking Res.
& Appl. (ETRA), 2006, pp. 95-100.
J. San Agustin, H. Skovsgaard, J.P. Hansen, and D.W. Hansen,
“Low-cost gaze interaction: ready to deliver the promises”, in Proc. of
Int. Conf. Extended Abstracts on Human Factor in Computing Systems
CHI EA’09 (New YorkL ACM), 2009, pp. 95-100.
ITU
gaze
tracker.
http://www.gazegroup.org/downloads/23-gazetracker
F. Lotte, and C. Guan, “Regularizing common spatial patterns to
improve BCI designs: unified theory and new algorithms”, IEEE Trans.
Biomed. Eng., Vol. 58, No. 2, pp.355-362, 2011.
C. Choi, S. Micera, J. Carpaneto, and J. Kim, “Development and
Quantitative Performance Evaluation of a Noninvasive EMG Computer
Interface”, IEEE Trans. Biomed. Eng., Vol. 56, No. 1, pp. 188-191,
2009.

