Biofeedback Game Design: Using Direct and Indirect
Physiological Control to Enhance Game Interaction
Lennart E. Nacke

Michael Kalyn
Calvin Lough
Regan L. Mandryk
Department of Computer Science
University of Saskatchewan, Saskatoon, Saskatchewan, Canada
lennart.nacke@acm.org, michael.kalyn@usask.ca, calvin.lough@usask.ca, regan.mandryk@usask.ca
ABSTRACT

Prior work on physiological game interaction has focused
on dynamically adapting games using physiological sensors. In this paper, we propose a classification of direct and
indirect physiological sensor input to augment traditional
game control. To find out which sensors work best for
which game mechanics, we conducted a mixed-methods
study using different sensor mappings. Our results show
participants have a preference for direct physiological control in games. This has two major design implications for
physiologically controlled games: (1) Direct physiological
sensors should be mapped intuitively to reflect an action in
the virtual world; (2) Indirect physiological input is best
used as a dramatic device in games to influence features
altering the game world.
Author Keywords

Psychophysiology, affective computing, affective gaming,
entertainment, physiological input, biofeedback, games.
ACM Classification Keywords

K.8.0 [General]: Games; H.5.2 [Information Systems]: User
Interfaces; J.3 [Life and Medical Sciences].
General Terms

Design, Experimentation, Human Factors, Measurement.
INTRODUCTION

Computer games have evolved considerably since the initial
days of Pong (Atari, 1972) and Space Invaders (Midway,
1978). Computer graphics techniques have advanced the
realism of graphics, rendering, and simulation; artificial
intelligence systems have improved the vividness of virtual
worlds; and hardware has evolved. New game input devices
have seen commercial success, (e.g., Nintendo Wiimote,
Microsoft Kinect), which provide natural and realistic interaction and experiences. Throughout this evolution of digital games, researchers and developers have also been exploring physiologically controlled game interfaces.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise,
or republish, to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
CHI 2011, May 7–12, 2011, Vancouver, BC, Canada.
Copyright 2011 ACM 978-1-4503-0267-8/11/05....$10.00.

Since the early 1980s, researchers have been exploring physiological input in biofeedback games for stress reduction
(see Related Work). In the last decade, there has been increased commercial interest in using physiological input in
digital games, not only for biofeedback training, but also to
enhance immersion and engagement for players. Yet even
with all of the technical advances surrounding physiological
game input, and all of the ludological advances surrounding
game design, physiological input in gameplay is still limited mainly to relaxation games using indirectly controlled physiological signals, such as heart rate (HR), galvanic skin response (GSR), or brain waves as a replacement
for the game controller.
The indirectly controlled forms of physiological input previously used, such as GSR, are excellent at helping users
train themselves to relax precisely because they are indirectly controlled. For example, GSR – which measures skin
conductance as a proxy for psychological arousal – is a
commonly used physiological input in biofeedback applications that is not directly controlled by the user. To raise or
lower their GSR, players must try and relax or excite themselves, which is good for training people to relax, but limiting in terms of gameplay. To date, there has been very little
work on directly controlled physiological input. In this paper, we define direct physiological control as measures that
a user can manipulate and control directly (e.g., muscle
flexion, eye gaze). In contrast, indirect physiological control refers to measures that cannot be explicitly influenced
and changes as an indirect result of other direct bodily activation (e.g., HR, GSR).
Replacing traditional controllers with physiological sensors
has been a good approach for initial testing of physiological
game input. However, traditional game controllers are very
good for certain game-related interaction tasks such as
pointing and clicking. In addition, traditional controls may
be superior in terms of performance, may be preferred by
users, or may produce a better user experience (UX).
To make physiological input more desirable for the mainstream computer and video games market, we need to answer two main questions:
1. How do users respond when physiological sensors are
used to augment rather than replace game controllers?
2. Which types of physiological sensors (indirect versus
direct) work best for which in-game tasks?

In addition, we were interested in exploring how we could
effectively integrate gaze location as a game input (using a
monitor-based eye tracker) without negatively affecting the
game through unintentional activation of game events from
users looking at the display simply to play.
To investigate our research questions, we designed a sidescrolling platform shooter game that uses a traditional game
controller as primary input. We augmented this traditional
interaction with physiological sensors. Physiological input
was considered to be either directly or indirectly controlled
by the user although we acknowledge that this distinction
can be fuzzy and dynamic in practice. Directly-controlled
sensors included muscle flexion, breathing patterns, and
temperature change (through blowing hot air). Indirectlycontrolled sensors included HR and GSR. Gaze location
was also integrated to augment controller input. Using our
game, we conducted a study where participants played with
three combinations of physiological and traditional input.
Through a combination of participant observation and survey data, we discovered: that players enjoy using physiological input; that they prefer directly-controlled physiological input; that indirectly-controlled input is best used for
altering background variables; and that gaze input can be
effectively integrated into game play. As game design and
development continues to press for more novel and thrilling
experiences for players, our work can help by informing the
design of physiologically controlled games.
RELATED WORK

Prior related work on physiological game interaction has
focused on adapting games to a user’s physiological state
[4] and on developing emotional models to understand the
psychophysiological input from a user [9].
Physiological control and adaptive gameplay

Recent research in human-computer interaction (HCI) has
explored the potential of physiological computing to tailor
user experience to players’ cognitive, motivational, and
emotional responses (see [3] for an overview). Computer
games are an excellent application area in which to explore
the benefits and drawbacks of physiological HCI as they are
a low-risk domain – if a game misinterprets a physiological
signal or adapts incorrectly, there is less fallout than if a
critical command-and-control system did the same.
Industry manufacturers have investigated physiologicallycontrolled biofeedback techniques for gaming since the late
1970s and early 1980s. For example, Canadian biofeedback
equipment manufacturer Thought Technology investigated
physiological input in their CalmPute 1 software packaged
with a modified GSR2 sensor (i.e., an Apple II mouse with
GSR electrodes) and the racing game CalmPrix in 1984.

1

http://www.thoughttechnology.com/thewall2.htm

Other attempts at integrating biofeedback into gaming systems included the unreleased Atari Mindlink in 1983, The
Journey to Wild Divine in 2001, and the Nintendo 64 biosensor included in the Japanese version of Tetris 64 in 1998.
This electrocardiographic (EKG) sensor measured users’
HR and adapted game speed. Eventually, it was taken off
the market, but Nintendo recently revisited this idea by announcing its Wii Vitality sensor, a pulse oximeter connected
to the Wiimote designed to be used in relaxation games.
Similarly, Ubisoft has announced a similar product for
2011, called Innergy, another pulse oximeter, which was
demonstrated with a stress relaxation game 2 .
Additionally, many hardware manufacturers are aiming at
providing cheap input solutions that use brain signals to
interact with a computer, such as Emotiv EPOC, Neurosky
Mindset, or OCZ Neural Impulse Actuator (NIA).
Game Design for Physiological Game Interaction

Physiological game interaction is generally called affective
gaming by the academic community. A definition of affective gaming was proposed by Gilleade et al. [5] as an activity where “the player’s current emotional state is used to
manipulate gameplay.” Thus, an affective gaming system
should sense a player’s emotion and arousal, and loop this
information back into the system. However, the simple replacement of user controls with biofeedback information
does not make a game effective. A popular example for this
is the unreleased Bionic Breakthrough game (a clone of the
Breakout game) for the Atari Mindlink, which used forehead EMG sensors to replace the conventional joystick input device. Mindlink players frequently reported headaches
as a result of moving their eyebrows in an attempt to control the game.
Part of the reason why game publishers are targeting biofeedback control as a replacement of traditional input devices is that learning to control biofeedback consciously or
subconsciously can be challenging and fun for some players. Games are rule-based formal interactive systems geared
toward teaching a player how to interact with the simulated
world and its entities. Part of the fun of gaming is figuring
out these interactions. However, not every game design and
mechanic can (or should be) supported through physiological interaction (e.g., using brain signals for quick-reaction
events). An alternative approach to affective gaming is to
adapt games based on physiological input [4].
Adaptive affective games [4, 5] change either technical
parameters or user preferences based on recordable user
behavior such as error-rates, button pressure, controller
movement, or physiological responses. It is important to
correctly distinguish affective states of the user, such as atgame or in-game frustration [4]. Physical failures, (e.g.,
inability to execute a command), will result in at-game fru2

http://www.physiologicalcomputing.net/?p=389

stration and mental failures (e.g., not recognizing game
objectives), will result in in-game frustration. Physiologically adaptive games must propagate affective feedback [1].
Replacing conventional execution of input commands is
regarded by Gilleade et al. [5] as “straight-forward biofeedback.”
Direct or Indirect Physiological Control

Most examples of prior research on physiologicallycontrolled games use indirect control – that is, the game
uses a player’s affective state without giving players the
option of controlling it directly. For example, consider physiological games such as the relax-to-win racing game [1]
or the Brainball game [6]. In these games, winning conditions are controlled by a player’s ability to relax – in the
former by allowing a dragon to race faster, and in the latter
by rolling a physical ball across a table towards an opponent. These games demonstrate how physiological input is
not directly controlled, but mediated by some other player
interaction, such as meditation or deep breathing. This is
different from “implicit commands” or indirectly controlled
brain-computer interfaces (BCIs). Zander et al. [15] introduced this concept of directly and indirectly controlled
BCIs, where indirect control refers to modulation of brain
activity in response to external stimulation.
Players can get satisfaction out of learning to control their
biofeedback through indirect physiological control. Playing
the game AlphaWoW, in which players trigger their shapeshifting ability using electroencephalography (EEG) [11],
provides players with the satisfaction of learning to control
their brainwaves. In all of these cases, biofeedback is
trained competitively in order to gain advantage and win
the game, whereas an alternative approach would aim to
improve player experience rather than chances of winning.
For example, Dekker et al. developed a game modification
using the Source SDK and Half-Life 2, GSR and HR were
used to control game shader graphics, screen shaking, and
enemy spawn points (i.e., number of locations in which
enemies are put into the game world) [2].

tions more and their conscious control of the respiratory
sensor led to a better game experience.
Physiological studies of gameplay experience

Instead of being used as input to a game, physiological sensors such as GSR, cardiovascular measures, and EMG, have
been used to objectively quantify user emotion during interactions with gaming systems [9]. An overview of game
research using psychophysiological measures [7] notes two
general approaches having emerged from previous work:
Studying phasic psychophysiological responses to game
events [12] and research studies of tonic responses to variations in game design dubbed affective ludology [10].
A Primer of Used Physiological Measures

For a synopsis of physiological measures in games, see [7].
Gaze Interaction. Tracking the location of a user’s gaze
(GAZE) supports analysis of visual attention. Gaze-related
data includes the position and movement of gaze on the
screen, and pupil dilation. Eye trackers, which can be integrated into a computer monitor, record patterns and distributions of gaze fixations and saccadic eye motion. Gaze
input is considered as direct physiological control.
Electromyography (EMG) describes the measurement of
electrical activation of muscle tissue. While facial EMG is
used in emotion detection, EMG has also been used to
sense muscle activation as a more direct form of input [13].
Electrodermal activity (EDA, also: skin-conductance level
or SCL) or galvanic skin response (GSR) is a common psychophysiological measurement with easy application. EDA
is regulated by production of sweat in the eccrine glands,
where increased activity is associated with psychological
arousal. GSR is an indirect form of input.
Electrocardiography (EKG) is the sensing of heart activity
through physiological sensors on the body. It is hard to control directly, but hyperventilation or increased physical activity often results in an increased HR. HR is an indirect
input mechanism for a game.

Although most games have used indirectly-controlled physiological sensors, there is an unexplored opportunity for
direct physiological control to map directly to specific game
mechanics, or to enhance the player experience.

A respiration (RESP) sensor is stretched across an individual’s chest to measure breathing rate and volume. Strain
sensors can be directly controlled.

Awareness of Control

A temperature sensor (TEMP) is directly controlled in our
experiment, through blowing hot air on it; TEMP could also
be an indirect measure if placed on the surface of the skin.

In all previous examples, players were aware that their physiological input controlled some aspect of the game or experience. Kuikanniemi et al. [8] explored the difference
between players that are aware of and not aware of their
biofeedback when playing a first-person shooter (FPS)
game and referred to this as implicit and explicit biofeedback. The biofeedback modulated player-character-related
game mechanics including walking and turning speed, aiming direction, recoil amount, and firing rate. The results
show that people enjoyed the explicit biofeedback condi-

A GAMING SYSTEM FOR AFFECTIVE INPUT

To investigate direct and indirect physiological control, we
developed a single-player 2D side-scrolling shooter game
that used standard controller mappings in Xbox360 shooter
games. Physiological input was controlled separately.
Building a Game for Physiological Input

The single-player 2D side-scrolling shooter, features many
obstacles, including increasingly difficult enemies, moving

platforms, and a final boss. Players can save their progress
by reaching checkpoints. If a player’s character dies after
that, they are returned to the most recent checkpoint that
they reached and given half their health back. To encourage
players to interact with enemies and have a more challenging experience, a checkpoint is only registered if a player
has killed all enemies leading up to that checkpoint.
Game Mechanics under Variable Control Schemes

To explore different variations of traditional game control
and physiological input, we implemented five game mechanics that could be controlled using different physiological sensors. We describe the game mechanics here and
present the control mappings in the study section.

Final boss battle: weather conditions and boss speed

At the end of our test game level, the player enters an icy
area, eventually leading to the final game boss. Gentle falling snow was implemented throughout this area. In heavy
snowfall (see Figure 3), it was more difficult for players to
see platforms and enemies, thus affecting the accuracy of
their shots. The rate of snowfall was under variable control.
In addition, the boss behavior was linked to the snowfall
rate – with lighter snowfall, the boss would get warmer,
would start to steam (a visual effect only) and would also
move more slowly (thus being easier to target).

Enemy Target Size

Because performance in 2D shooting games is primarily
about the accuracy of aiming at targets, we manipulated the
enemy target size through physiological control. Rather
than increasing the size of the entire sprite, we displayed a
shadow of the enemy that grew (See Figure 1). Pilot testing
showed that increasing the enemy size directly was counterintuitive, since easier-to-hit enemies looked more threatening. Hitting an enemy shadow counted as a hit.

Figure 3. Behavior of the final boss (a yeti) and the snow effect
were controlled together in a variable.
Eye tracker feature: Medusa’s gaze

We implemented one game mechanic under physiological
control that was designed specifically to use gaze control.
Gaze control can be difficult to implement well because
players should not inadvertently activate gaze-controlled
features simply by looking around the display.

Figure 1. Target enemies increase in size.
Flamethrower weapon: Flame length

The game featured three weapons: a regular projectile weapon, an ice projectile weapon, and a flamethrower weapon
with unlimited ammunition. To avoid deadlocks in a game
when a player runs out of ammunition, many games feature
a fallback weapon (e.g., the crowbar in Half-Life 2). We
made our fallback weapon more interesting by placing the
flame length under variable control (see Figure 2).

Figure 2. Flamethrower weapon: flame length was increased
Speed and jump height

Many side-scrolling platform games employ power ups that
increase avatar speed and jump height temporarily. We
linked this to a single variable which was controlled using
physiological input.

Figure 4. The Medusa’s Gaze feature in the game.

We used gaze control as a power-up that temporarily froze
enemies and moving platforms, called Medusa’s Gaze. To
acquire this power-up, users needed to pick up a special
item, which would then display a blue circle at the location
of their gaze (see Figure 4). Looking at enemies and moving platforms would freeze them temporarily. Frozen enemies and platforms turned green and then transitioned back
to their normal color, indicating the amount of time left in
their frozen state. To keep the game balanced and avoid
eyestrain, Medusa’s Gaze was only available for 20 seconds
after picking up the special item.
Game Implementation and Architecture

To integrate physiological sensors, we wrote a custom C#
library called SensorLib, which is a multi-threaded library
written in C# that provides an interface for external thirdparty sensors. It handles the connection to the sensors, the

data-buffering, digital signal processing, and offers the data
through a high-level .NET interface. It aggregates third party SDKs into a single interface so programmers can create
sensor-dependent applications.

Mechanic

Cond. 1

Target size

RESP

GSR

Speed/jump

EKG

EMG

Weather/boss

TEMP

EKG

Sensor
Audio
Gaze

Flamethrower

GSR

RESP

Avatar control

Gamepad

Gamepad

Medusa’s Gaze

Gaze

Gaze

BVP
GSR
EKG
EMG
RESP

SDK
DirectX 10
TobiiSDK

TTLAPI

Measure
Amplitude of sound waves.
Tracks where user is looking on
computer screen.
Blood flow through a finger.
Skin conductance
Senses heart beats.
Contraction of muscles.
Amount of strain on a chest strap.

TEMP

Temperature change.

Raw

Receives data from any TTL
sensor with no processing.

Processing
None
None
Downsampled by 64
Downsampled by 64
Heartbeat Detection
Smoothing; Normalized
Downsampled by 64;
Normalized
Downsampled by 64;
Normalized
None

Table 1. Digital signal processing in SensorLib.

Table 1 shows the SDKs used by each sensor in SensorLib
and the digital signal processing each sensor does. All digital filters are Chebyshev type II filters with lower filter
length and no ripple in the passband. The game architecture,
implemented in C# using XNA and SensorLib is shown in
Figure 5.

Figure 5. Game Architecture
STUDY

To evaluate the relative appeal of direct and indirect physiological control, participants played three versions of a
game, two augmented with physiological input and one
control condition. The sensor mappings and their respective
thresholds for each game mechanic were developed using
iterative prototype testing for five months, gathering feedback from more than 50 individuals before this study.

Cond. 2

Table 2. Game conditions. Direct sensors are shaded in dark
blue, and indirect in light blue. Gaze tracking is a special case
of direct sensor control; the gamepad was used in all cases.

Medusa’s gaze was available in both physiological conditions, but not in the control condition. The third control
condition used only the gamepad for avatar control and did
not make use of the game mechanics implemented for the
physiological sensors.
Experimental Procedure

The study used a three-condition (2 physiological variations, 1 control with gamepad only) within-subjects design.
All participants played all three conditions, which were
presented using a randomized ordering. Each participant
played through an initial training level to get accustomed to
the game controls before the trial started. EMG, RESP, and
gaze tracking were recalibrated before each game condition.
After providing informed consent, the participants completed a demographics questionnaire, which also asked
questions about their gameplay experience. Participants
were then fitted with the physiological sensors and briefed
on how to control them both directly and indirectly. For
example, to increase their GSR, players were advised to
laugh, bite their lip, flick themselves, or think about exciting things 3 , whereas they were told to flex their foot to increase their EMG response. Participants played each game
condition for 10 minutes or until they completed the level
(10-35 min.), a common playing time in game research [7].
After each game, players completed a survey, rating their
gameplay experience using game-specific questions. Following completion of all conditions, players completed a
final survey soliciting their opinions of physiological control in video games.
Apparatus

Game Conditions

Two of the game conditions mapped two direct and two
indirect sensors to the four game mechanics under variable
control described previously, while the third condition used
no physiological input. Although it would have been useful
to include only direct physiological input in one condition
and indirect in the other, this was not possible as the indirect sensors are difficult to control independently.
The physiological sensors used as direct control were respiration, EMG on the leg, and temperature. The indirectlycontrolled sensors included GSR and EKG. Mappings of the
sensors to the game mechanics for each condition are
shown in Table 2.

The game was played on a Dell computer running Windows
XP. The monitor was a 24’’ TFT display running at a resolution of 1080p (1920x1200), with an integrated Tobii T60
XL eyetracker running at 60 Hz (see Figure 6). Physiological data was collected using the Flexcomp Infinity hardware
by Thought Technology, and integrated into the game using
our custom sensor library SensorLib, described briefly in
the previous section.
3

While it might be argued that biting one’s lip is a somewhat direct physiological influence, the directness of the
action here is the biting, but the resulting change in GSR is
still indirect. For example, in contrast measuring lip-biting
pressure would be a direct measure.

game, and gave a greater sense of involvement.” (P2, Female). This involvement and enjoyment seemed to be especially strong when “more parts of the body are involved in
the game.” (P1, Male)
With the increase of immersion came also a greater sense of
challenge, a feeling of greater “variation, and more enjoyment while playing because there are always new skills to
improve on.” (P4, Male)
Figure 6. A participant playing the game using the
physiological sensors and the eye tracker
Participants

Ten participants (7 male), aged 21 to 40 (M=25.8, SD=5.5)
completed the study. Six of the participants played video
games at least monthly; the others played only a few times
a year. Participants were not very experienced with sidescrolling shooter games, indicating an average expertise of
2.5 on a scale of 1 (novice) to 5 (expert). When asked about
their experience with novel forms of input to games, participants primarily reported having used the Nintendo DS and
Wii, with fewer participants having experience with the
WiiFit balance board and the Rock Band controllers.
RESULTS

Ratings data were analyzed with non-parametric techniques, while open-ended survey responses were clustered
into overarching themes. We present results on fun and novelty ratings, followed by sensor preference.
Physiological Control: Fun Ratings

We asked players to rate their fun in each condition on a
scale of 1 (not much fun) to 5 (very fun). A Friedman test
for 3-related samples showed differences in players’ fun
ratings depending on game condition (χ22=7.3, p=.026).
Pairwise Wilcoxon Signed Ranks tests showed that players
found both physiological control conditions to be more fun
than the no physiological control condition (both Z=2.1,
both p=.033, see Figure 7), but no difference between the
physiological control conditions was found (Z=0, p=1.0).
5

Fun Ratings Results Across Conditions
C1 (RESP, Temp, EKG, GSR)

C2 (GSR, EMG, EKG, RESP)

C Control

4
3
2
1

Figure 7. Mean (CI:95%) fun rating (higher is more fun).

When asked at the end of the experiment whether they preferred to play with or without sensors, 9 of 10 players preferred to use physiological control.
The players who enjoyed physiological control commented
that having to use more than one input device “made for a
very immersive game, out of what is basically just a very
simple platform shooter.” (P7, Male). In line with this
statement, “the sensors added a new dimension to the

The controls were usually perceived as best when they
matched a natural input, such as thawing snow with temperature increase, freezing enemies by staring at them, or
running faster by flexing the leg muscle.
“Jumping higher and running faster by flexing the leg is so
intuitive. I'm sure many do it instinctively anyway.” (P5,
Male)
The one dissenting participant commented that the “sensors
[made the] game complicated. (P3, Female)”.
Novelty of Physiological Control

We asked participants how they would rate the novelty of
physiological control on a scale from 1 (not novel) to 5 (extremely novel). Participants agreed that the physiological
control was novel (M=4.2, SD=0.79). To better understand
their view of the novelty of physiological control, we asked
if there was something special about using their body to
control the game, or whether it was more like a new type of
game controller.
“At times it felt like a new type of controller that I had to
actively think about, but other times it felt like more than
that—almost that I was physically part of the game.” (P2,
Female)
Some players mentioned that there was a learning curve
involved in learning to use the sensor, but once they learned
to use it, the experience was more rewarding. Additionally,
players mentioned that they were more aware of some sensors than others and that some felt more like controllers:
“The breathing sensor and GSR sensor felt like controllers
though, because I was very aware they were attached to me.
The EKG and EMG were completely unnoticeable and fun
to use…” (P4, Male)
“[The] muscle and breathing sensors were simple enough
that they were practically like a new button on the controller for me, but very awesome ones since rather than tapping
a button, it was an instinctive action.” (P7, Male)
Sensor Preference

After each game, we asked participants which sensor they
preferred to all others. Over the course of the two games,
12/20 votes were for gaze input, 5 were for RESP, and one
for each of TEMP, EMG and GSR. Although these choices
are also affected by controlled game mechanic, only 1/20
votes was for an indirect sensor. We also asked players to
rate their enjoyment of the five game mechanics explored.

5

One participant also mentioned the close relationship of the
control of GSR to control of EKG, saying he was “not even
sure what this one controlled in the second game.” (P4,
Male)

Gameplay Mechanics Ratings
Target Size

Speed/Jump

Weather/Boss

Flamethrower

Medusa's Gaze

4
3

Opinions about the EKG Sensor (Indirect)

Similar to participant response to the other indirect sensor
(GSR), participants felt that EKG was hard to control and
therefore was not perceived as working accurately.

2
1
C1 (RESP,EKG,TEMP,GSR,GAZE)

C2 (GSR,EMG,EKG,RESP,GAZE)

Figure 8. Game mechanic ratings (CI:95%) for each condition.

Figure 8 shows how participants rated the direct controls
higher than the indirect controls for target size increases,
speed/jumps, and weather/boss speed, but not for the flamethrower. In the post-game questionnaire, we asked participants about their preferred sensors (see Figure 9).
GSR

GSR

“[…] I couldn't control as instantly as the others—the effect from it tended to last over longer periods of time.” (P2,
Female)
Players also thought that because EKG seemed slow to respond, it might be “better suited to changing the game context than what the character is doing.” (P5, Male)

EKG

EKG

Opinions about the EMG Sensor (Direct)
RESP
Target Size

RESP
Flamethrower

EMG
Speed/Jump

TEMP
Weather/Boss

Figure 9. Player choices for physiological control by game
mechanic. Dark wedges are direct sensors, light are indirect.

Comments on the direct control using EMG were split between positive and negative experiences. Some noted that
they were “wishing it was a bit more sensitive or easier to
trigger [the sensor by flexing the muscles].” (P2, Female),
while others felt that it was easy to use:

For target size increases and flamethrower length, players
preferred RESP to GSR. For speed and jump height they
preferred EMG to EKG. For controlling the weather and
speed of the yeti, players preferred TEMP to EKG.

“It was fairly easy to use. It was effective and worked.”
(P8, Male)

As shown in Figure 9, for each game mechanic more participants preferred the direct control than the indirect control.
We also asked players which they would choose if they
could
only
play
with
one
combination
of
RESP/EMG/TEMP (direct) or EKG/GSR (indirect). Eight
of the ten participants chose the direct sensors combination.
We present participant comments for each of the physiological controls individually.

“I really liked this one. Flexing your leg to move faster or
jump higher? Definitely cool.” (P7, Male)
“[…] having this sensor tied to jumping/speed felt natural”
(P2, Female)

Opinions about GSR Sensor (Indirect)

Many participants reported problems with controlling the
GSR sensors, because it only responded indirectly. Some
perceived the indirect control as unnoticeable or “not working.” Players used different strategies for trying to control
GSR, and some of them not pleasant:
“I liked that it was always a challenge to control just with
my thoughts […] and forced me to use a part of my brain I
wouldn't normally use in a video game.” (P4, Male)
“I disliked the fact that one of the only ways that I found I
was able to use the GSR was by biting my lip which isn't
actually all that fun after it starts hurting.” (P8, Male)
Another issue for participants was the location of the GSR
sensor on the pinkie and ring finger of the left hand during
controller-based gameplay, which one participant found
“uncomfortable and awkward.” (P4, Male)
“I didn't like that it got in the way a bit with holding the
controller. After I got used to it I was fine though.” (P9,
Male)

Players generally liked the mappings of the EMG sensor:

It was also noted that the muscle could become strained if
the sensor is used continuously for input, but some players
liked the idea of a physical workout by playing a video
game.
Opinions about the RESP Sensor (Direct)

This sensor was praised for its very easy controllability and
the immediate feedback it provided to participants’ actions.
“It was neat to see the immediate reaction from my body to
the game.” (P10, Female)
“This was also cool, as it was very easy to activate, didn't
really have to put much thought into it.” (P7, Male)
Due to its responsive nature, participants also noted that
they felt “it got you more into the game.” (P8, Male)
“[It] felt very natural, particularly when it was tied to target size in the game […]. It's one I felt I could control to a
fine degree.” (P2, Female).
Opinions about the TEMP Sensor (Direct)

This sensor was initially experienced as easy-to-use; however, using it over longer periods of time became tedious,
since the participants had to remember to keep on blowing
on it.

“It was easy to use for short periods of time but hard to
remember to breathe deep into the sensor […].” (P8, Male)
“It was easy to control but the effect didn't last long in the
game so I [had] to constantly breathe out […].” (P6, Male)
The natural mapping to control the snow in the environment
by the heat of the sensor was perceived positively although
some players noted the limited applicability in games.
“I like […] when it was tied to weather […], because it felt
like a natural thing to do. […]” (P2, Female)
“I'm not sure how many games you could actually include
it in […] Limited applicability would be the only thing I
dislike about it.” (P7, Male)
One participant found that controlling TEMP would cross
activate HR, because she was breathing rapidly.
“Breathing rapidly to increase temperature also brought my
heart rate up.” (P2, Female)
Opinions about the Gaze Sensor (Direct)

Gaze was chosen by many players as their favorite input
control, because many found that it was easy to control and
worked well.
“Now that was just cool […] I liked being able to roast one
frozen combatant while immobilizing another.” (P5, Male)
“It worked remarkably well and was easy to control. I
found the effect useful in the game.” (P6, Male)
Some noted that it became inaccurate if posture was
changed rapidly during gaming. Another participant noted
that it obscured her intended gameplay at some parts.
“I loved the eye tracking input. It was cool, and unique! It
worked pretty well, but if I changed my posture it didn't
work as well.” (P9, Male)
“I found it frustrating when you would look at a platform
intending to jump on it and end up freezing it.” (P2, Female)
Additional comments from participants

Many participants noted that direct control was their preferred way of controlling the game mechanics as they felt it
provided direct feedback to them and made the game more
responsive. The eye tracker was a favorite of many, because
it did not require the application of a sensor on the body of
the participant, making it incredibly easy to use.
The idea of having multiple modes of input in an extended
(or augmented) controller struck a chord with many players.
“I like the idea of using multiple physiological inputs. Distributing the functions around the body is intuitive in some
cases.” (P5, Male)
“[It] basically boils down to an "extended controller"
where the buttons are not buttons but other actions, similar
to waving a Wii remote.” (P7, Male)

DISCUSSION

We investigated the use of direct and indirect physiological
control in games. Our main results were:
• The physiological augmentation of game controls provided a more fun experience than using only a traditional
control scheme for game interaction.
• Physiological control was a fun game mechanic in itself
because it provided enjoyment by adding an additional
challenging dimension to gameplay.
• Participants preferred physiological sensors that were
directly controlled because of the visible responsiveness.
• Physiological controls worked most effectively and were
most enjoyable when they were appropriately mapped to
game mechanics.
• Indirect control was perceived as slow and inaccurate,
and was not preferred; however, users recognized its potential to show passive reactions of the game world (e.g.,
atmospheric changes) or as a dramatic device.
We explore these main findings further and discuss the relative advantages of direct and indirect control, the relevance
of appropriate mappings, and how to best integrate physiological sensors into traditional control schemes. In addition,
we address the limitations of our work and present future
research opportunities.
Indirect versus Direct Physiological Control in Games

It is not surprising that players preferred direct physiological control, since the benefits of directly controlled physiological input are compatible with the nature of many action
games requiring a quick reaction to a presented stimulus.
The feeling of control over the game world is an important
factor in gameplay enjoyment. Direct physiological input
was easier for players to activate and provided better and
instantaneous feedback, which was likely perceived as more
or better playing control.
Indirect physiological control does not have a 1:1 mapping
of player action and game reaction and is therefore not
equally suited as game input for fast-paced action games.
This was made evident in participants’ comments noting the
slow response of indirect physiological sensors to their actions. However, this disadvantage could be turned into a
strength if indirect physiological control was used to affect
slow-changing environmental variables of the game that
could allow these sensors to function as a dramatic device.
This would be in line with prior work on affective feedback
games [1,5], which intelligently respond to players’ physiological states, or games that dynamically adjust to provide
player satisfaction [14]. Our work suggests that indirect
control may be best used for peripheral environmental variables (i.e., features altering the game world to change
player experience) or as a dramatic or aesthetic or artistic
device that does not directly influence game mechanics.

Another important game enjoyment factor related to the
feeling of control is the feeling of action accomplishment.
The disproportionally positive feedback for a simple action
is one of the reward mechanics used in games. For example,
pressing the right combination of buttons (a fairly simple
task) could result in a special action that moves a player’s
avatar in unrealistic and exciting ways, such as flying or
jumping over a building. The greater feeling of control that
resulted from direct physiological input could have enhanced a player’s sense of accomplishment. In addition,
since the in-game actions using direct sensors were triggered using the body as input (e.g., flexing leg) rather than
the traditional controller (e.g., pressing button), the sense of
accomplishment may have been heightened and made the
experience more immediate and personal.
The distinction between direct and indirect physiological
control may change with increased use. One could argue
that initially indirect measures become direct with exposure
over time since a user’s intuitive ability to control their
physiological response would increase. This is the basic
premise of biofeedback training, and presents interesting
questions and challenges for physiological game designers
over the long term. As users learn to intentionally manipulate indirect physiological measures, it opens the door to
physiological cheats and exploits. For example, in Tokimeki
Memorial Oshiete Your Heart (Konami, 1997) players
cheated by going for a jog before playing to increase their
body sweat and the resulting success of a virtual animated
date [4].
Relevance of Control to Game Context

Many participants mentioned that they most enjoyed using
the sensors when they felt their physiological actions
mapped naturally to the in-game reaction. For example,
when breathing out triggered a longer flame of the flamethrower, blowing hot air on the temperature sensor decreased
the amount of snow, or flexing the leg muscle increased
speed and jump height. Natural mappings create an intuitive
method for interacting with the game world.
For example, in some game contexts, it might be difficult to
find natural mappings, or multiple mappings may exist. Our
participants show this in their ratings and rankings of RESP
versus GSR for the flamethrower length. When asked directly, participants preferred the RESP to GSR input, but
the rating of the game mechanic was equal across conditions, indicating that both sensors were suitable for controlling the game mechanic. Natural mappings may present
more intuitive game interfaces, but also limit the flexibility
and generality of the sensors for game control. This tension
between innovating new uses of physiological controls and
sticking with standard mappings will present future challenges for physiological game designers.
Replacing or Augmenting Traditional Game Controllers

Most previous work has focused on replacing direct control
with a physiological sensor [1], and this trend is still evi-

dent in the game industry with the announcement of the Wii
Vitality and the Ubisoft Innergy. Physiological input—
whether direct or indirect—will not be suitable for all tasks.
For example, playing a button-mashing game with brain
signals does not seem like a good design choice. In our approach, we focus on augmenting traditional input devices
with physiological information to reward players with a
richer experience. In addition, we feel that augmenting traditional game controllers with physiological input will allow for a gentle learning curve as players become used to
physiological control. Having the possibility to enter the
game world using a common interaction modality such as
the game controller would allow players to feel more competent in the game and would facilitate trying out the “new
powers” they gain through physiological control.
Integrating Physiological Sensing into Controllers

Augmenting traditional controllers with physiological input
will be a challenge for industrial designers. In addition,
cooperation is needed between the hardware manufacturers
who make the devices and the game developers, who include physiological input in their game controllers. The
recent collaboration between Ubisoft and MindMedia, a
Dutch biofeedback company, for the development of Innergy demonstrates that this can successfully be done. PC
games can draw upon the availability of physiological input
devices in the consumer market, such as the Lightstone
from The Journey to Wild Divine, the Neurosky Mindset,
and the Emotiv EPOC, which all use indirect physiological
input. Direct sensors, such as GAZE, RESP, and EMG were
preferred by our participants, but there are currently no consumer-level sensors available. Both RESP and EMG use
standard components and would be inexpensive to produce.
Game and hardware designers must also consider the willingness of players to adopt wearable technology. In our
work, we have found that players are very comfortable
wearing sensors if they perceive the added value in gameplay. The broad consumer acceptance of fitness games that
require wearing sensors also suggests that this is not an
issue for players. Our participants mentioned they were
fully aware of using muscle activation as control in the
game and some entertained the thought that this might be a
great way to improve their fitness. Because the combination
of several sensors was mentioned as a positive feature by
many participants, there are great opportunities to integrate
physiological sensors (e.g., EMG) with fitness game input.
Limitations

Our study shows support for augmenting game control with
direct and indirect physiological input; however, it was a
preliminary investigation and therefore is limited in its
generalizability. First, we explored a small number of
specific game mechanics in a certain genre. Choosing
different gameplay mechanics, interaction mappings, or
game genres would likely result in different player
experiences. Second, our participants played for a short

REFERENCES

time; as with any new technology, it will be interesting to
see how user experience changes over long-term repeated
use. Third, our participants were mostly casual game
players. To fully explore the range of possibilities with
physiological input, it will be important to involve players
of all experience levels into the game design process. And
finally, as this is an initial explorative study, we must
acknowledge both the role of novelty in our results and the
small number of participants. Large-scale, long-term
deployment to address these issues will be feasible after
additional small-scale targeted studies.

3.

FUTURE WORK

4.

Our initial investigation into direct and indirect physiological control opens many future research opportunities. One
of our participants noted that triggering one physiological
control (i.e., breathing warm air on the temperature sensor)
co-activated another physiological response (i.e., increasing
HR). As many indirect physiological sensors are triggered
as a result of a more direct action, using this co-activation
as a game mechanic has great potential. For example, for
fitness games, an objective could be to flex a muscle a certain amount of time, but only within a certain arousal threshold to make sure the exercise is being performed within a
healthy range. This would combine the power of using direct physiological control and indirectly influencing the
game state and come in the appealing marketing package of
a fitness game fostering exercise and mobility.
Our players also mentioned that physiological sensors could
be integrated into an extended version of a controller that
uses multiple physiological inputs simultaneously. The coactivation of multiple direct physiological sensors could
provide new gameplay challenges such as using gaze to
unlock a door and then slowly breathing out to push it open.
CONCLUSION

1.

2.

5.
6.
7.

8.

9.

10.

As we create new forms of input, we need to consider
whether these will replace or augment well-established methods of interaction. Traditional interaction forms may be
superior in terms of performance, may be preferred by users, or may produce a better experience, while new forms
may provide additional capabilities or be more immersive.
We propose augmenting traditional controller input with
physiological input. Therefore, we investigated this combination in an exploratory study, and have two main results
for designing a game for physiological input: first, direct
physiological sensors should be mapped naturally to reflect
an action in the virtual world; and second, indirect physiological control is best used as a dramatic device in games to
influence environmental variables.

11.

ACKNOWLEDGMENTS

15.

We thank Kiel Gilleade, Jaymie Koroluk, Jörg Niesenhaus,
and our CHI reviewers who provided helpful comments on
previous versions of this document, and we thank NSERC
and the GRAND NCE for funding and all participants.

12.

13.

14.

Bersak, D., McDarby, G., Augenblick, N., McDarby, P.,
McDonnell, D., McDonal, B., Karkun, R. Intelligent
Biofeedback using an Immersive Competitive Environment. Online Proceedings for the Designing Ubiquitous Computing Games Workshop at Ubicomp'01
(2001).
Dekker, A. and Champion, E. Please Biofeed the Zombies: Enhancing the Gameplay and Display of a Horror
Game Using Biofeedback. Proc. of DiGRA, (2007).
Fairclough, S.H. Fundamentals of Physiological Computing. Interact Comput 21, 1–2 (2008), 133–145.
Gilleade, K. and Dix, A. Using frustration in the design
of adaptive videogames. Proc. of ACE, ACM (2004),
228–232.
Gilleade, K., Dix, A., and Allanson, J. Affective Videogames and Modes of Affective Gaming: Assist Me,
Challenge Me, Emote Me. Proc. of DiGRA, (2005).
Hjelm, S.I. Research + design: the making of Brainball. interactions 10, 1 (2003), 26–34.
Kivikangas, J. M., Ekman, I., Chanel, G., Järvelä, S.,
Salminen, M., Cowley, B., Henttonen, P., Ravaja, N.
Review on psychophysiological methods in game research. Proc. of 1st Nordic DiGRA, DiGRA (2010).
Kuikkaniemi, K., Laitinen, T., Turpeinen, M., Saari, T.,
Kosunen, I., and Ravaja, N. The influence of implicit
and explicit biofeedback in first-person shooter games.
Proc. of CHI'10, ACM (2010), 859–868.
Mandryk, R. and Atkins, M. A Fuzzy Physiological
Approach for Continuously Modeling Emotion During
Interaction with Play Environments. Int J HumComput St 65, 4 (2007), 329–347.
Nacke, L.E., Stellmach, S., and Lindley, C.A. Electroencephalographic Assessment of Player Experience:
A Pilot Study in Affective Ludology. Simulation &
Gaming, ahead of print (2010).
Nijholt, A., Plass-Oude Bos, D., and Reuderink, B.
Turning shortcomings into challenges: Brain-computer
interfaces for games. Entertainment Computing 1, 2
(2009), 85–94.
Ravaja, N., Turpeinen, M., Saari, T., Puttonen, S., and
Keltikangas-Järvinen, L. The Psychophysiology of
James Bond: Phasic Emotional Responses to Violent
Video Game Events. Emotion 8, 1 (2008), 114–120.
Saponas, T.S., Tan, D.S., Morris, D., and Balakrishnan,
R. Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces. Proc. of
CHI'08, ACM (2008), 515–524.
Yannakakis, G.N. and Hallam, J. Towards Optimizing
Entertainment in Computer Games. Applied Artificial
Intelligence 21, 10 (2007), 933–971.
Zander, T.O., Kothe, C., Jatzev, S., and Gaertner, M.
Enhancing Human-Computer Interaction with Input
from Active and Passive Brain-Computer Interfaces. In
D.S. Tan and A. Nijholt, eds., Brain-Computer Interfaces. Springer London, 2010, 181–199.

