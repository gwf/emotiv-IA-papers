Prototyping Potential Control Systems to Assist
Complete Quadriplegics
Yaya Lu
Ogilvie School,
Hobart, Tasmania, Australia.
Yaya.Lu@live.com

Abstract—This paper discusses a versatile wheelchair control
system of potential use to complete quadriplegics. This system
employs plug-in components using a common control protocol
between the distributed computers. Two headset plug-in units
have been developed together with two prototype wheelchairs
and an automatic shopping trolley. The trolley would be of most
use to a paraplegic, but suggestions are made to show how this
could potentially be developed to plug into the control system as a
type of “personal assistant”. The system has been prototyped
using language-independent commands so that it can potentially
be used by quadriplegics speaking any of the approximately
7,000 languages spoken on Earth. LEGO MindStorms NXT
equipment has been used to prototype this system.
Index Terms—Control systems, wheelchairs, assistive
technologies for people with disabilities, prototype, quadriplegics.

I. INTRODUCTION
Complete quadriplegics are people who have breaks in their
spinal columns above the C7 vertebra [1] and “having no
voluntary motor or conscious sensory function below the injury
site” [2] are only able to move their head. They are
consequently confined to wheelchairs in order to get around,
mostly with the assistance of other human beings.
There have been many attempts to help these people by
focusing on developing wheelchair devices.
One project involved using a magnet glued to the
quadriplegic’s tongue to determine the movement of the
wheelchair in relation to the direction the tongue is moving [3],
while others involved mouth-controlled joysticks [4][5]. These
could be inconvenient for the quadriplegics, causing
restrictions when eating or talking. Magnets can cause
problems if more than one is accidentally swallowed [6].
Voice recognition is a common method for wheelchair
control. Either a powerful computer or continuous reliable
internet access is required for the voice recognition software to
work effectively [7][8][9]. Voice control without internet
access is a good idea in theory, however if no internet
connection is available, educating the software to cope with
every individual person’s language, accent and word
preference can be quite fiddly and time-consuming (and in
some cases, quite expensive) to implement properly.

Ying Chen
School of Computing and Information Systems,
University of Tasmania,
Hobart, Tasmania.
Ying.Chen@utas.edu.au

The electrical signals produced by muscles can be detected
by an electromyograph (EMG) and used to control a
wheelchair [10][11][12].
There have also been projects to control a wheelchair by
thought. When humans change their thoughts the change in the
electrical signals in the brain can be detected. There are two
main implementation methods for this approach. One is using a
headset from companies such as Emotiv [13] and the other
involves surgically implanting a sensor on to the surface of the
human brain itself.
The Emotiv headset is a portable electroencephalograph
(EEG) that picks up electrical signals from the surface of the
head. This signal is complex and reliability is further
complicated by the fact that a person’s thoughts can be easily
distracted. This complexity limits the number of reliably useful
commands for wheelchair controls, two or three commands
being the limit often reported [14][15][16].
A recent report shows a woman controlling a robotic arm to
allow her to drink coffee through a straw from a thermos [17].
The arm was controlled by thought alone, using an implant that
had been surgically placed directly on the surface of her brain
some 5 years earlier. While the future possibilities of this
approach would seem large, the training time and expense
involved would appear to limit this option for wider
application. This subject had head movements, and perhaps
less expensive options could also have been possible.
Felzer & Freisleben [10] commented that the EEG
command recognition rate (70%) and the slow recognition time
make these systems “totally unacceptable for practical ...
applications” involving moving users. They commented that
voice control systems do not allow conversation while the chair
is being controlled, that EMG signals are falsified if the chair
travels over bumps, and that if traditional joysticks could be
used, they would allow faster point-to-point wheelchair travel.
The authors of this paper wanted to investigate a
wheelchair control system that addresses some of the issues
raised in the existing approaches mentioned above. We wanted
the final product to meet the criteria of being user-friendly,
inexpensive, non-intrusive, easy and quick to implement and to
be language independent so that a complete quadriplegic
speaking any of the 7,000 or so languages used on Earth could
adopt it.

II. METHOD
Two input control systems, two wheelchairs, and a
shopping trolley were prototyped (Fig. 1). The system’s
distributed computer layout allows for easy future expansion
indicated by dotted outlines.

Fig.1 Plug-in wheelchair control system.
A. Head Movements Control Prototype Plug-in.
In this prototype, eyebrows, nose and ears were possible
sensor targets. Eyebrows could be independently controlled,
and could be used for wheelchair control. LEGO light sensors
could be used for detecting eyebrow movements for people
with dark eyebrows. Distance-measuring Electro Optical
Proximity Detectors (EOPD) sensors from HiTechnic [18]
could be used to measure changes in position of fair, bushy
eyebrows.
Some people can move their ears. The movement can be
small (about 5mm) but distinct enough for a distancemeasuring EOPD sensor to detect and use as a command.
Nostril movements were also considered. The original
intention was to measure nostril dilation; however it was found
that the indent above the nostril showed a greater movement.
An EOPD sensor was used, but it only worked marginally well,
as the movement of the nose surface was quite small. Figure 2
shows the system with LEGO sensors taking facial movements
as commands to control a prototype wheelchair.

Fig. 2: Prototype wheelchair control with head movements.
The exclusion of mouth and chin areas was deliberate to
avoid interfering with the quadriplegic’s eating or speaking.
Testing of the system on volunteers showed that these
chosen head movements can be mastered with practice. We

could not find any evidence of pure genetic inheritance of these
traits on the internet, so these movements could be considered
latent, but trainable.
B. Sound Control Prototype Plug-in
A sound control system could be used if a quadriplegic has
limited facial or head movements. The preferred voice control
system had to be easy for the quadriplegic to use and calibrate,
and hopefully easy for Y.L. to implement.
Typical internet-independent voice recognition systems
available nowadays are complex to program due to variations
of languages, accents, and personal idiosyncrasies creating
challenges for recognition. A universal voice control system
could be an innovative and attractive alternative option.
A program was written to test the functionality using a
LEGO Sound Sensor, to see if long and short sounds could be
accurately distinguished. This was tested with multiple people
to ensure its reliability and accuracy. It worked.
Morse Code was investigated. It used sequences of dots and
dashes to represent letters (Fig.3). Its varying command lengths
proved a problem, and an additional challenge for quadriplegic
use lies in the exact reproduction of the three different exactly
delineated wait times between commands. Our experiments
implementing the Morse Code showed that this required signal
precision made using it impractical in practice.

Fig. 3: Morse Code.
The Chinese Telegraph System (Fig. 4) was investigated.
This code had a set number of commands (code book page
number, row number, column number) per character. This
meant there were no varying lengths of codes, and so there was
an obvious place where the command would end.

Fig. 4: Portion of a Chinese Telegraph System page.
The ideas behind the Morse Code and the Chinese
Telegraph System were combined to create a code which used
a fixed number of long and short sounds to represent different
commands. This provides a universal method of control.

Using 3 short and long sound commands (hereafter known
as “Dits” and “Dahs”) per sequence creates a total of eight
unique commands including sideways left and right, which are
rarely possible in conventional wheelchairs (Table 1).
Table 1: Command sound signals.
Control
Signal
Command
Protocol
F
Dah Dah Dah
Go Forwards
A
Dah Dit Dit
Left Turn
L
Dah Dah Dit
Left Sideways
C
Dit Dit Dah
Turn Right
R
Dit Dah Dah
Sideways Right
B
Dit Dah Dit
Go Backwards
S
Dit Dit Dit
Immediate Stop
Dah Dit Dah
Spare Command
This system is versatile, and could be easily adapted for
ANY command signal that can be short or long (e.g. head rolls,
eye blinks etc.).
C. Wheelchair plug-ins
Two wheelchair prototypes, one featuring a chair-lift (Fig.
2) and one using holonomic wheels [19] to enable sideways
movements (Fig. 5), were built to test this system concept.

wheelchair around in the supermarket (Fig. 6). This would be
better suited for a paraplegic than a quadriplegic. But a robotic
arm could in the future be added to this trolley to transform it
into a “personal assistant”, with the capability of (e.g.)
grabbing and lifting objects, switching services on and off.

Fig. 6: A shopping trolley prototype.
F. Safety Considerations
The command “Dit Dit Dit”, which took the least time to
speak, was used for immediate stops. It would also be possible
to use face movements (e.g. an eyebrow raise or head roll) to
toggle the voice control system on and off.
An automatic warning system was also prototyped, to detect
sudden drops in the pavement, or obstacles behind the
wheelchair. The idea was to stop the wheelchair, give a
warning signal, and move away in order to avoid the
obstacle/cliff. These worked well, and could be extended quite
inexpensively to all sides of the wheelchair in the future.

Fig. 5: A holonomic wheelchair prototype.
D. Radio Signals for Common Control Protocol
The head movements detected by the Headset Plug-in, and
the three-sound sequences detected by the Voice Plug-in were
then translated into the control protocol codes by their local
NXT computer bricks. These control codes were needed by the
wheelchair computers for processing into wheelchair
movements. Since cables directly linking the headset to the
wheelchair would be very restricting, the head and voice plugins were sent to the wheelchairs using NXTBee Pro radio links.
The common control characters were then translated by the
wheelchair’s NXT computer program into forwards,
backwards, left or right movements for the wheelchair.
E. Prototype Personal Assistant
A LEGO shopping trolley, or potential “personal assistant”
was also designed and prototyped to autonomously follow a

G. Personal Considerations
To allow a paraplegic to reach higher shelves in the
supermarket, a chair-lifting device was added onto the
wheelchair. This also aims to provide the often-requested
ability for a quadriplegic to talk to others at eye-level.
An on/off switch (e.g. actuated by a head roll) could be
added to enable speech while the wheelchair is moving.
H. Future Headset Sensor Placements

Fig. 7: Glasses with sensors.

The sensors which come with the NXT set are quite large,
but the electronic components inside are relatively small. In the
future, the components could be fitted into a pair of thickrimmed glasses, rather than onto a headset (Fig. 7).
I. Prototype System Costs
These systems are relatively inexpensive, costing a few
hundred dollars to buy a LEGO Mindstorms NXT set. In the
future it may be possible to use even less expensive processors
such as the Raspberry Pi [20] or Arduino [21], providing a
more affordable control option for quadriplegic wheelchair
control systems than other methods that either require a
powerful computer processor or physically intrusive devices.
III. RESULTS
The experiments obtained good results in each of three
areas. They did this by demonstrating through the use of
prototypes that:
 Control of a wheelchair by a complete quadriplegic would
be possible if existing movable features of the head were
used;
 Control of a wheelchair by a complete quadriplegic would
be possible using a short sequence of sounds of varying
length;
 An automatic wheelchair-following shopping trolley for
use by a paraplegic would be feasible.
Regarding future work, an attached robot arm could be
built to enable the conversion of the “trolley” into a “personal
assistant” (Fig. 6) controlled by the complete quadriplegic.
The same control system could potentially be switched
between these devices, allowing a complete quadriplegic to
control all three devices (wheelchair, personal assistant, robot
arm) using a similar set of commands to save re-learning the
commands. Only one device would be controlled at a time.

A major problem with using the NXT LEGO light sensor
was that it is very sensitive to changes in ambient light levels.
This made a huge difference when we were testing it indoors
and then outdoors, day and night, or even in shadows. By
contrast, the HiTechnic EOPD sensor used pulsed light, and is
far less sensitive to variations in ambient light. In the real-life
wheelchair, the sensor needs to be sensitive enough so that the
quadriplegic’s movements can be detected, but not so sensitive
that its reliability would be compromised by moving between
different geographic locations.
Not many humans have developed the ability to move their
ears, but it seems to be a latent ability. The muscles and nerves
are present in humans, and we could find no evidence of major
genetic variations that affected only this ability. We feel that
this type of control could be achievable with practice.
Even though the sensors that come with the NXT set are
quite large, the electronic components inside are relatively
small. Consequently, a real system could be implemented with
the electronic components built into a pair of thick-rimmed
glasses (Fig. 7), rather than onto a separate headset.

A. Choice of Materials to Build the Prototypes
The prototypes were built using LEGO Mindstorms NXT
sets that are quite inexpensive compared to some of the
wheelchairs designed specifically for quadriplegics today [22].
Previous experience [23] with the LEGO NXT MindStorms set
established it as versatile prototyping system. Y.L. has had
experience with several NXT languages and chose to use
RobotC because it is the fastest NXT language [24] with the
best debugging facilities.

C. Voice Control System Plug-in
A voice control system is an alternative solution if the
quadriplegic was unable to move areas of the head. Typical
voice recognition systems available nowadays are mostly
language dependent which limits adoption by minority
populations. They are also complex to program due to varieties
of accents and personal idiosyncrasies. A simple universal
voice control system is proposed in this paper, using a
combination of some of the ideas behind Morse Code and the
Chinese Telegraph System to provide a possible solution.
The authors expected to have to calibrate the LEGO sound
sensor to deal with different background noise levels. We
calibrated this for indoor use, and found that, if the sound
sensor was held reasonably close to the mouth, the system
responded quite reliably without having to change the initial
calibration when moving around the house, even when TV is
blaring out at a volume suitable for people in need of hearing
aids. We expected to have to calibrate the “dits” and “dahs”
individually for each person. However after testing the system
with a variety of English and non-English-speaking people, we
found that the lengths of the “dits” and “dahs” were
surprisingly similar, and that an initial long/short “decision
point” built into the software worked for most of the people
who tried the system. If necessary, this “decision point” can be
easily changed.

B. Choice of Sensors for Headset Plug-in.
After much experimentation, it was decided that the LEGO
light sensors could be used for detecting eyebrow movements
for people with dark eyebrows. Distance-measuring HiTechnic
EOPD sensors could be used to measure changes in position of
fair, bushy eyebrows, and could also be successfully used to
detect ear movements. An EOPD sensor was also used to
measure nose dilation, but it only worked marginally well, as
the movement of the nose surface was quite small (Fig. 1). Eye
areas were intentionally excluded to avoid possible retinal
damage from the infrared sensors.

D. Shopping Trolley Prototype
The prototype automatic shopping trolley worked well. If a
full-size system was made, careful adjustment of the way the
trolley approached the wheelchair would be necessary.
We used a HiTechnic IRSeeker sensor on the trolley in
combination with a HiTechnic Electronic Ball mounted on the
wheelchair to reliably find the direction of the wheelchair. This
worked well, as long as there was a clear line of sight between
the shopping trolley and the wheelchair.
We then tested two sensors in an effort to stop the shopping
trolley from banging into the wheelchair.

IV. DISCUSSION

A touch sensor worked quite reliably, but the touching part
of the sensor had to be very carefully placed, otherwise the
trolley would hit the wheelchair before the touch sensor was
activated. This often happened if the trolley met the wheelchair
at an angle.
To attempt to obtain a more reliable approach, we tried a
LEGO ultrasonic sensor that detects sound echoes. This has
two advantages. The first is that the trolley does not have to
bump into the wheelchair, because it can be stopped at a certain
distance from the wheelchair. The second is that the speed of
the trolley can be decreased as the trolley nears the wheelchair.
The only problem with the ultrasonic sensor was that, if the
wheelchair was at an angle to the trolley, the reflected sound
waves could be weak because most were reflected sideways by
the flat surfaces on the wheelchair (Fig. 7).

Fig. 7: Ultrasonic sensor signal scatter.
This could be easily fixed in a full-size version of this
system if a ridged zig-zag wheelchair outer surface was used.
The automatic shopping trolley would be better suited for a
paraplegic than a quadriplegic. But if a robotic arm was added,
and the proposed extensions of the wheelchair control system
were used to control both the trolley and the robotic arm, the
shopping trolley could be converted into a “personal assistant”
for a quadriplegic. This “assistant” could (e.g.) obtain items, or
switch services on and off, to assist the quadriplegic.
There were problems with the Linear Actuator [25] used to
raise the wheelchair’s chair; our initial units had manufacturing
faults. The manufacturer claims a 1 km. radio range and 65,000
network addresses for the NXTBee Pro. [26], but the battery
ran down very quickly (no on/off switch) and the battery
connections were fragile. In both cases replacement versions
corrected these faults.
E. Conclusion
We successfully prototyped an easily-extended system
using plug-in components that could be of potential assistance
to complete quadriplegics. The system currently used both
facial movement controls and voice controls to show that it was
possible for a complete quadriplegic to control a wheelchair.
For particular quadriplegics, the plug-in design of this
wheelchair control system should make it relatively easy to
combine additional elements into this system to overcome a
particular quadriplegic’s individual handicaps.
The automatic shopping trolley could assist a paraplegic; it
had the potential (with further work) to act as a “personal
assistant” to quadriplegics.

The simple hardware requirements of this system enabled it
to be both easily implemented and extended. Most importantly,
the control system is language independent, making it a
universally adoptable system.
ACKNOWLEDGMENT
We are very grateful for the help provided by Dr. Graeme
Faulkner with his RobotC sensor tutorials [27]; his knowledge
of robotics and dedicated supervision have highly inspired us.
REFERENCES
[1] http://www.apparelyzed.com/support/functionality/c4.html
[2] http://www.thinkbeforeyoudrink.net/quadriplegia.htm
[3] http://www.wired.com/wiredscience/2008/07/tongue-drive-sy/
[4] J. Aylor, R. Ramey, J. Schaddegg & S. Reger, “Versatile wheelchair
control system” in Medical and Biological Engineering and Computing,
Vol 17, No 1, 1979, pp. 110-114.
[5] N. Pellegrini, B. Guillon, H.Prigent, M. Pellegrini, D. Orlikovski, J.
Raphael & F. Lofaso, “Optimization of power wheelchair control for
patients with severe Duchenne muscular dystrophy” Neuromuscular
Disorders, Vol 14, Issues 5, May 2004, pp. 297-300.
[6] http://www.usatoday.com/money/industries/retail/story/2012-0725/buckyballs-ban/56481316/1
[7] http://www.pcworld.com/article/251752/apple_sued_over_siris_
shortcomings.html
[8] http://www.macworld.com/article/1163404/siri_outage_leaves_
iphone_4s_owners_bereft.html
[9]http://www.slate.com/articles/technology/technology/2011/04/now_you
re_talking.html
[10] T. Felzer & B. Freisleben, “HaWCos: the ‘hands-free’ wheelchair
control system” Assets ’02 Proceedings of the Fifth International ACM
Conference on Assistive Technologies 2002, pp. 127-134.
[11] M. A. Oskoei & H. Hu, “Myoelectric control systems – A survey” in
Biomedical Signal Processing and Control, Vol 2, Issues 4. Oct 2007, pp.
275-294.
[12] C.S.L Tsui, J. Pei, J. Q. Gan, H. Hu & K. Yuan, “EMG-based handsfree wheelchair control with EOG attention shift detection” in IEEE
International Conference on Robotics and Biomimetics, 2007, pp. 12661271.
[13] http://emotiv.com/store/
[14] http://www.heraldsun.com.au/technology/brain-power-you-coulddrive-with-your-mind/story-fn7celvh-1226454401257
[15] F. Galan, M. Nuttin, E. Lew, P.W. Ferrez, G. Vanacker, J Phillips. &
J. Millan, “A brain-actuated wheelchair: Asynchronous and non-invasive
Brain-computer interfaces for continuous control of robots” in Clinical
Neurophysiology, Vol 119, Issue 9, September 2008, pp. 2159-2169.
[16] J. Philips, J. Millan, G. Vanacker, E. Lew, F. Galan, P.W. Ferrez, H
Van Brussel and M. Nuttin, “Adaptive Shared Control of a Brain-Actuated
Simulated Wheelchair” in IEEE 10th International Conference on
Rehabilitation Robotics 2007, pp. 408-414.
[17] http://blog.amsvans.com/55319-paralyzed-woman-uses-thoughtcontrol-to-move-robotic-arm-drink-coffee/
[18] http://www.HiTechnic.com/
[19] http://www.rotacaster.com.au/robotics-wheels.html
[20] http://www.RaspberryPi.org/
[21] http://www.arduino.cc/
[22] http://www.mobsol.com.au/c/7438/1/electric-wheelchairs.html
[23] http://www.YayaLu.net
[24] http://www.teamhassenplug.org/NXT/NXTSoftware.html
[25] http://www.firgelli.com/products.php?id=43
[26] http://dexterindustries.com/NXTBee_Pro.html
[27] http://www.DrGraeme.net
All web references checked 10th September 2012.

