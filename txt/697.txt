Emotion in Games
Georgios N. Yannakakis and Ana Paiva
Abstract
Emotion has been investigated from various perspectives and across several domains
within human computer interaction (HCI) including intelligent tutoring systems,
interactive web applications, social media and human-robot interaction. One of the
most promising and, nevertheless, challenging applications of affective computing (AC)
research is within computer games. This chapter focuses on the study of emotion in the
computer games domain, reviews seminal work at the crossroads of game technology,
game design and affective computing and details the key phases for efficient affectbased interaction in games.
Keywords
Computer games, affective loop, game content, non-player characters, emotion
elicitation, emotion modelling, emotion expression

1. Introduction
People choose to play games as a “voluntary attempt to overcome unnecessary obstacles” (Suits,
2005) as play is amongst the main motivators for learning, mental and physical development, and
an essential element of evolution (Deci & Ryan, 2000). Arguably, players seek games for
enjoyment and for emotional experiences and pursue in-game challenges that – when achieved –
do not necessarily result to immediate, tangible, rewards. What is fascinating is that players
willingly engage in an experience that is likely to even involve negative emotions such as
frustration and fear (Salen & Zimmerman, 2003). So, while games can be utilised as an arena for
eliciting, evaluating, expressing and even synthesising emotions, we argue that one of the
primary aims of the study of emotion in games is the understanding of players’ emotions and its
link with their experience. Indeed, by the nature of what constitutes a game, one cannot
dissociate games from emotions. Emotions are not only the trigger for the positive game

experiences, but also one of the main targets for game design. For this purpose, this chapter
focuses on emotions that can be detected, modelled from, and expressed in games with human
players.
Computer games are dynamic media which embed rich forms of user interactivity.
Collectively, such HCI attributes allow for high levels of player incorporation (Calleja, 2011)
and yield dynamic and complex emotion manifestations. The potential that games have to
influence players is mainly due to their ability of placing the player in a continuous mode of
interaction (loop) with the game which develops complex cognitive, affective and behavioural
responses. Undoubtedly, the study of emotion in games not only advances our knowledge about
human emotions but also contributes to the design of better human computer interaction.
Moreover, affect-based game interaction can drive players in particular emotional patterns
which, in turn, can enhance game-based training and educational activities (McQuiggan,
Robison, & Lester, 2010), (McQuiggan & Lester, 2009), (Yannakakis G. N., et al., 2010).
Arguably, as we will see in this chapter, games offer the best and most meaningful domain of
affective interaction for the realisation of the affective loop which defines a system that is able to
successfully elicit, detect and respond to the emotions of its user (Sundstrom, 2005).
Every game features a user (i.e. player) – or a number of users – which control an avatar
or a group of miniature entities in a virtual/simulated environment (Calleja, 2011). The
interaction between the player and the game context (i.e. the game state containing all pieces of
game content) is of key importance for affective computing (AC) research and modern game
development as it breeds emotional stimuli and yields emotional manifestations to the player –
those manifestations, however, cannot trivially be captured by standard methods in AC research.
Given the particularities of emotion research in games we both discuss what games can offer to
emotion research but also what emotion research can bring to game design and game technology
research.

1.1 What Games can do for Emotion Research
As mentioned earlier in this section, games can offer contextual building blocks (i.e. game
content) that can elicit a broad spectrum of emotional responses and emotional patterns. Games –
as a medium – have unique properties that make this possible as they incorporate rich forms of
interaction with the player within a virtual world, provide a direct placement of a player onto an

avatar and a player detachment from reality, and finally allow for a direct control of the context
presented to the player. For these unique features, games can be used (and have been used quite
extensively) from emotion researchers as handy and off-the-shelf emotion elicitors.
More importantly, games can offer the most meaningful realization of the affective loop
(Sundstrom, 2005). As games are by definition both entertaining (whether used for pure
satisfaction, training or education) and interactive activities that are played within fantasy worlds
any limitations of affective interaction (such as justifiability of affective-based game decisions)
are absorbed. Games are designed to offer affective experiences which are influenced by player
feedback and players are willing to go through e.g. frustrating, anxious, and fearful episodes of
play for experiencing involvement and powerful emotional gaming. To that end, a user under
gaming conditions – more than any other form of HCI – is generally open to affective-based
alterations of the interaction and influences of his/her emotional state.

1.2 What Emotion Research can do for Games?
The use of AC research and development in games is beneficial for the design of better games
for various reasons. First, emotions can drive the design process of most game genres. Game
designers usually explore and test a palette of mechanics and game dynamics that yield
emotional states and emotional state sequences they desire to put the player through. Emotional
states such as engagement, fear and stress, frustration, and anticipation but also cognitive states
such as challenge define critical aspects of the design of player experience which is dependent on
the genre, the narrative and the objectives of the game. Second, the holy grail of game design,
that is player experience, can be improved and tailored to each player but also augmented via
richer and more affective-based interaction. As we will see in the following section and in the
discussion of this chapter, emotion-driven game adaptation primarily targets the personalisation
of the playing experience. Third, as a direct consequence of better and faster design, the whole
game development process is boosted and improved. Fourth, games that incorporate rich
emotion-based interaction which is further tailored to the needs of the player can enhance
learning in training or educational (game-based learning) settings as indicated by numerous
studies in the literature (McQuiggan & Lester, 2009), (McQuiggan, Robison, & Lester, 2010),
(Yannakakis G. N., et al., 2010).

Research on emotion in games is nowadays becoming increasingly important in research
and development departments of top-class (i.e. AAA) and indie game developers (Yannakakis G.
N., 2012). More specifically, there exist several commercial-standard games that incorporate
emotion as a core (or peripheral) part of gameplay including the arousal-driven appearance of
non-player characters (NPCs) in Left 4 Dead 2 (Valve Corporation, 2009), the fearful combat
skills of the opponent NPCs in F.E.A.R. (Monolith, 2005), the avatars’ emotion expression in the
Sims series (Maxis, 2000) and Black and White (Lionhead Studios, 2001), the emotional playthrough for characters in Psychonauts (Double Fine Productions, 2005), the emotional responses
of game characters in Prom Week (McCoy, et al., 2010) and Façade (Mateas & Stern, 2003), the
emotion-driven narrative building system in Storybricks (Namaste Entertainment, 2012), the
personality-based adaptation in Silent Hill: Shattered Memories (Konami, 2010), the affect-based
cinematographic representation of multiple cameras in Heavy Rain (Quantic Dream, 2010), the
aesthetically pleasing locations of World of Warcraft (Blizzard Entertainment, 2004) and affectcentred game narratives such as the one of Final Fantasy VII (Square Product, 1997).
Ultimately, all above-mentioned intelligible benefits from the coupling of games and
emotion research can be revealed as long as phases of the affective loop (or the affective loop as
whole) are successfully realised within a game.

1.3 The Affective Loop in Games
Within games, emotions are elicited via stimuli offered during the interaction. Emotions can then
be detected and modelled, assessing the responses of the player to the corresponding game
stimuli. Such detection can then affect the game responses that may involve emotions expressed
in several ways via game adjustable elements such as game content and non-player characters;
and finally, controllable game elements can be adapted dynamically to cater for the current
emotional state of the player and the specific game context. The affective loop (Sundstrom,
2005) when applied to games can be viewed as comprised of three sequential key phases
organised in a closed-loop: (see Figure 1).
1) the player expresses her emotions through the interaction with a game;
2) the game then detects the emotional reactions of the player, and interprets those reactions
according to the context of the game;

3) based on that interpretation, the game makes adjustments that can be achieved via
emotional modelling and expression of NPCs or via affect-driven content generation
adapting the game to the player. This in turn affects the player (both her mind and body)
making her respond through game actions and emotional reactions (step 1 again).

The remaining three sections of this chapter discuss the three affective loop phases in detail
under the games domain. The chapter ends with a discussion about the open questions and the
future of research on emotion in games.

Figure 1: The realisation of the affective loop in games

2. Games as Emotion Elicitors
Emotion elicitation in games can be achieved primarily through the interaction with particular
game elements (such as game characters and the rest of the game content). While social
interaction (shared involvement (Calleja, 2011)) may have a clear impact on a player’s emotional
state it cannot be directly controlled via an affective loop mechanism and thereby is not included
in the list of emotional stimuli considered in this chapter. On that basis, we may define two key
clusters of possible emotion elicitors in games:

1) Game content: beyond any narrative or player-agent interaction there is game content
that can influence the emotional state of the player. Game content refers to the game
environment (i.e. spatial involvement according to (Calleja, 2011)) but also refers to
fundamental game design building blocks such as game mechanics (i.e. ludic
involvement according to (Calleja, 2011)), story plot points and reward systems. More
specifically, beyond the game environment itself – such as a game level/map (Hullett &
Whitehead, 2010), (Togelius, et al., 2010) – game content includes audiovisual settings
such as lighting (Seif, Vasilakos, C., & Zupko, 2009), saturation, and music (Eladhari,
Nieuwdorp, & Fridenfalk, The soundtrack of your mind: mind music-adaptive audio for
game characters , 2006) and sound effects (Plans & Morelli, 2012) but also virtual
camera profiles and effects (Picardi, Burelli, & Yannakakis, 2011), (Yannakakis,
Martinez, & Jhala, 2010) and game rules (Togelius & Schmidhuber, 2008). All abovementioned types of content can be adjusted to affect the playing experience and influence
player emotions.
The environment is linked to stories and narratives as a form of their
representation and it is also linked to NPCs (if existent in the game) as it forms their
context, living habitats and surroundings. In a broader sense, both agents and narratives
can be viewed as game content that can be parameterised and altered (Yannakakis &
Togelius, 2011). Stories play an essential part in creating the ambience, style, climax and
feelings of a game – whether games can tell stories (Juul, 2001) or games are instead a
form of narrative (Aarseth, 2004) is still, however, an open research question in game
studies. Players seek the moment-to-moment experiences they build in a game and the
climax and relief moments created by pre-scripted story elements. Some games such as
World of Warcraft (Blizzard Entertainment, 2004) take advantage of the story
components and in particular cut scenes to raise the climax and lead the player to
particular emotional states. Other systems, in particular in the area of interactive
storytelling, use the story as an evolving and adaptive mechanism that in itself varies
according to the actions of the players, and adjusts the story to different players and
actions, offering variant emotional experiences (see e.g. the work of Roberts et al. (2009)
among others). Further, by breaking the game narrative into subareas of game content
(and perhaps according to the different plot phases) we can find core game content

elements such as the game’s plotline (Riedl, 2012), (Giannatos, Nelson, Cheong, &
Yannakakis, 2012), but also the ways this story/plot is represented in the game
environment
In summary, all game content surrounding NPCs (whether those are existent in
the game or not) including game mechanics, rules, story-nodes and reward systems may
have an effect on the experience of the player (Yannakakis & Togelius, 2011).
2) Game non-player characters: complex, social and emotional non-player characters
(NPCs) can be used as triggers of desired emotions for the player. The main goal of these
characters is to be believable in a manner that players establish relations with them, thus
leading to particular emotional reactions when something good or bad happen in the
game. To achieve that, agents may embed computational models of cognition, behaviour
and emotion and attempt to react in a believable and human-like fashion to human player
actions. Typical agent architectures rely on particular theories of emotion, such as the
OCC theory (Ortony, Clore, & Collins, 1988) or Lazarus theory (Lazarus, Emotion and
Adaptation, 1994) as the basis for their emotional processing and simulation. One of such
architectures, the FAtiMA architecture (Dias & Paiva, 2005) is based on OCC and
extends the typical the belief-desire-intention (BDI) (Georgeff, Pell, Pollack, Tambe, &
Wooldridge, 1999) model with emotional processing capabilities. A non-inclusive list of
games that make use of emotion-driven NPCs includes the kittens in Kinectimals (MS
Game Studios, 2010), the complex social agents in FearNot! (Paiva, et al., 2004), the
emotional opponents in iterative prisoner’s dilemma (De Melo, Zheng, & Gratch, 2009)
and the agents of Prom Week (McCoy, et al., 2010).

3. Emotion Detection and Modelling in Games
The detection and modelling of emotion in games is, primarily, the study and use of artificial and
computational intelligence (AI and CI) techniques for the construction of computational models
of emotion of players. Emotion detection and emotion modelling place an AI umbrella to the
multidisciplinary intersection of the fields of user (player) modelling, affective computing,
experimental psychology and human-computer interaction. Emotion detection in games is an
area that has provided the most research studies thus far leaving, however, large unexplored
spaces.

One can detect the emotion of either a human player or a non-player game character.
While the challenges faced in the latter case are substantial, the issues raised from emotion
detection on human players define a far more complex and important problem for the realization
of the affective loop in games. By clustering the available approaches for emotion modelling we
are faced with either model-based or model-free approaches (Yannakakis & Togelius, 2011) as
well as potential hybrids between them. The space between a completely model-based and a
completely model-free approach can be viewed as a continuum along which any emotion
modelling approach might be placed. While a completely model-based approach relies solely on
a theoretical framework that maps player’s responses to affect, a completely model-free
approach assumes there is an unknown function between modalities of user input and affect that
a machine learner (or a statistical model) may discover, but does not assume anything about the
structure of this function. Relative to these extremes, all approaches may be viewed as hybrids
between the two ends of the spectrum, containing elements of both approaches.
The rest of this section presents the key elements of both model-based and model-free
approaches and discusses the core components of a derived computational model (i.e. model
input, model output and common modelling tools).

3.1 Model-Based (top-down) approaches
According to a model-based (Yannakakis & Togelius, 2011) approach a model of emotion is
usually built on a theoretical framework or is entirely based on a theory of emotion. Such a topdown approach to emotion detection and modelling refers to emotional models derived from
emotion theories (e.g. cognitive appraisal theory (Frijda, 1986)) such as the emotional
dimensions of arousal and valence (Feldman, 1995) and Russell's circumplex model of affect
(Russell, 1980), in which emotional manifestations are mapped directly to specific emotional
states — e.g. the increased heart rate of a player corresponds to high arousal and therefore to
player excitement. Within game studies examples include the theoretical model of incorporation
(Calleja, 2011) proposed as an approach to capture player immersion in games composed of six
types of player involvement: affective, kinaesthetic, spatial, shared, ludic, and narrative. Seminal
work in psychology-based approaches to player emotion includes the concepts of challenge,
curiosity and fantasy of Malone (1980) which collectively contribute to high entertainment, and
the theory of flow (Csikszentmihalyi, 1990) incorporated in games (Sweetser & Wyeth, 2005).

Within game design the theory of ‘fun’ by Koster (2005), the notion of the ‘magic circle’ in
games (Salen & Zimmerman, 2003) and the four “fun” factor model of Lazzaro (2004) constitute
popular views that place players’ emotions at the centre of player’s experience. Model-based
approaches can also be inspired by a general theoretical framework of behavioural analysis
and/or cognitive modelling such as usability theory (Isbister & Schaffer, 2008), the belief-desireintention (BDI) model, the cognitive theory by Ortony, Clore, & Collins (1988), Skinner’s model
(1938), and Scherer’s theory (1993).
Even though the literature is rich of theories on emotion one needs to be cautious with the
application of such theories to games (and game players) as their majority has not been derived
from or tested on ergodic (i.e. interactive) media such as games. Calleja (2011), for instance,
reflects on the inappropriateness of the concepts of ‘flow’, ‘fun’ and ‘magic circle’ (among
others) for games. Finally, while ad-hoc designed emotion models can be an extremely powerful
and expressive way of representing emotions those need to be cross-validated empirically, which
is rare practice in AC research.

3.2 Model-free (bottom-up) approaches
Model-free approaches refer to the construction of an unknown mapping (model) between
(player) input and an emotional state representation. Player data and annotated affective states
are collected and used to derive the model. Classification, regression and preference learning
techniques adopted from machine learning or statistical approaches are commonly used for the
construction of the computational model. This approach is very common, for instance, for facial
expression and head pose recognition since subjects are asked to annotate facial (or head pose)
images of users with particular affective states (see (Shaker, Asteriadis, Yannakakis, &
Karpouzis, 2011) among others) in a crowdsourcing fashion. Bottom-up is also common in
studies of psychophysiology in games (see (Tognetti, Garbarino, Bonarini, & Mateucci, 2010),
(Yannakakis, Martinez, & Jhala, 2010) among others).
The model-free approach to emotion modelling offers the tremendous advantages of data-driven
(and even large-scale crowdsourced) model building but it also limits itself to the quantity and
quality of the data gathered.

3.3 The model’s input
The model’s input can be of three main types: a) anything a human player (or an agent) is doing
in a game environment gathered from gameplay data (i.e. behavioural data); b) objective data
collected as bodily responses to game stimuli such as physiology and body movements; and c)
the game context which comprises of any player-agent interactions but also any type of game
content viewed, played through, and/or created. The three input types are detailed in the
remaining of this section.
Gameplay (behavioural) input: The main assumption behind the use of behavioural
(gameplay-based) player input is that player actions and real-time preferences are linked to
player experience as games may affect the player’s cognitive processing patterns and cognitive
focus. On the same basis, cognitive processes may influence emotions; one may infer the
player’s emotional state by analysing patterns of the interaction and associating user emotions
with context variables (Gratch & Marsella, 2005), (Conati, 2002). Any element derived from the
interaction between the player and the game forms the basis for gameplay-based emotion
detection and modelling. This includes detailed attributes from the player’s behaviour (i.e. game
metrics) derived from responses to system elements (i.e. non-player characters, game levels or
embodied conversational agents). Game metrics are statistical spatio-temporal features of game
interaction (Drachen, Thurau, Togelius, Yannakakis, & Bauckhage, 2013). Such data is usually
mapped to levels of cognitive states such as attention, challenge and engagement (Conati, 2002),
(Shaker, Asteriadis, Yannakakis, & Karpouzis, 2011). In addition, both general measures (such
as performance and time spent on a task) and game-specific measures (such as the weapons
selected in a shooter game) are relevant.
Objective input: Games can elicit player emotional responses which, in turn, may affect
changes in the player’s physiology, reflect on the player’s facial expression, posture and speech,
and alter the player’s attention and focus level. Monitoring such bodily alterations may assist in
recognizing and synthesising the emotional responses of the player. The objective approach to
emotion modelling (i.e. the second type of objective model input) incorporates access to multiple
modalities of player input.
Within objective emotion modelling, a number of real-time recordings of the player may
be investigated. There are several studies that explore the interplay between physiology and

gameplay by investigating the impact of different gameplay stimuli to dissimilar physiological
signals. Such signals are usually obtained through electrocardiography (ECG) (Yannakakis,
Martinez, & Jhala, 2010), photoplethysmography (Yannakakis, Martinez, & Jhala, 2010),
(Tognetti, Garbarino, Bonarini, & Mateucci, 2010), galvanic skin response (GSR) (Mandryk &
Inkpen,

2004),

respiration

(Tognetti,

Garbarino,

Bonarini,

&

Mateucci,

2010),

electroencephalography (EEG) (Nijholt, 2009) and electromyography (EMG).
In addition to physiology one may track the player’s bodily expressions (motion tracking)
at different levels of detail and infer the real-time affective responses from the gameplay stimuli.
The core assumption of such input modalities is that particular bodily expressions are linked to
basic emotions and cognitive processes. Motion tracking may include body posture (Savva,
Scarinzi, & Bianchi-Berthouze, 2012) and head pose (Shaker, Asteriadis, Yannakakis, &
Karpouzis, 2011) as well as gaze (Asteriadis, Karpouzis, & Kollias, 2008) and facial expression
(Pantic & Caridakis, 2011).
Game context input: in addition to gameplay and objective data, the context of the game is a
necessary input for emotion modelling. Game context refers to the real-time parameterised state
of the game. Without the game context input, affective player models run into the risk of
inferring erroneous affective states for the player. For example, an increase in galvanic skin
response (GSR) can be linked to a set of dissimilar high-arousal affective states such as
frustration and excitement; thus, the cause of the GSR increase (e.g. a player’s death or level
completion) needs to be fused within the GSR signal and embedded in the model.

3.4 The model’s output
The model’s output is usually a set of particular affective states (i.e. classes), a scalar (or a vector
of numbers) that maps to an emotion such as the emotional dimensions of arousal and valence, or
a relative strength of an emotion (i.e. rank or preference). The output of the model is provided
through an annotation process which can either be driven by first person reports (self-reports) or
by reports expressed indirectly by experts or external observers (Yannakakis & Togelius, 2011).
The most direct way to annotate an emotion is to ask the players themselves about their
playing experience and build a model based on these annotations. Subjective emotion annotation
can be based on either players’ free-response during play or on forced data retrieved through
questionnaires. Alternatively, experts or external observers may annotate the playing experience

in a similar fashion. Third-person emotion annotation entails the identification of particular
affective states (given in various types of representation as we will see below) by user experience
and game design experts. The annotation is usually based on the triangulation of multiple
modalities of player and game input such as the player’s head pose, in-game behaviour and game
context (Shaker, Asteriadis, Yannakakis, & Karpouzis, 2011).
Annotations (either forced self-reports or third-person) can be classified as rating
(scalar), class and preference. In rating, annotators are asked to answer questionnaire items
given in a rating/scaling form (e.g. in (Mandryk & Inkpen, 2004)) – such as the affective aspects
of the Game Experience Questionnaire (Poels & IJsselsteijn, 2008) – which labels affective
states with a scalar value (or a vector of values). In a class-based format subjects are asked to
pick an affective state from a particular representation which could vary from a simple boolean
question (was that game level frustrating or not? is this a sad facial expression?) to an affective
state selection from e.g. the Geneva Emotion Wheel (Scherer, What are emotions? And how can
they be measured?, 2005). Finally, subjects are able to provide answers in a preference format, in
which they are asked to compare an affective experience in two or more variants/sessions of the
game (e.g. (Yannakakis G. N., Preference Learning for Affective Modeling, 2009) among others)
(was that level more engaging that this level? Which facial expression looks happier?). A recent
comparative study has exposed the limitations of rating approaches over ranking questionnaire
schemes (e.g. pairwise preference) which include increased order of play and inconsistency
effects (Yannakakis & Hallam, Rating vs. Preference: a comparative study of self-reporting,
2011).

3.5 Modelling Tools
The tools for constructing models of emotion rely on the modelling approach followed: modelbased or model-free. For the model-based approach components of the model and any
parameters that describe them are constructed in an ad-hoc manner and, sometimes, tested for
validity in a trial and error basis. No machine learning or sophisticated computational tools are
required for model-based approaches even though one could envisage the optimization of the
parameter space to yield more accurate models; that, however, would require empirical studies
which brings the approach closer to a model-free perspective.
Model-free tools for creating models of emotion, on the other hand, are dependent on the
type of model output available. If data recorded includes either a scalar representation of affect

(e.g. via ratings) or classes of annotated labels of affective states any of a large number of
machine learning (regression and classification) algorithms can be used to build affective
models. Available methods include artificial neural networks, Bayesian networks, decision trees,
support vector machines and standard linear regression. Alternatively, if affect is annotated in a
preference (i.e. ranked) format standard supervised learning techniques are inapplicable, as the
problem becomes one of preference learning (Yannakakis G. N., 2009). Neuro-evolutionary
preference learning (Yannakakis G. N., 2009) and rank-based support vector machines
(Joachims, 2002) but also simpler methods such as linear discriminant analysis (Tognetti,
Garbarino, Bonarini, & Mateucci, 2010) are some of the available approaches for learning
preferences. Finally, unsupervised methods such as self-organizing maps, neural gas and
sequence mining (Martinez & Yannakakis, 2011) can be used to identify clusters within the
model’s input space and profile players accordingly. Empirical studies suggest that the model
accuracy is improved when such clusters are fed as complementary input to the model (Martinez,
Hullett, & Yannakakis, 2010).

4. Emotional Adaptation and Expression in Games
Emotions are fundamental for players to deeply engage with games. Players’ responses in a
game are affected by their emotional states which if, in turn, could affect the way the game
responds the player-game interaction could be augmented and enriched by magnitudes realizing
affective loop-enabled games. Games may evolve and adapt to the player in many different ways
and convey emotions through a variety of techniques and effects. In this section we will discuss
emotion adaptation and emotion expression, placing it in the context of the affective loop
discussed earlier. The adaptation module of the affective loop should be able to provide
satisfactory answers to – at least some – of the following questions: which stimulus (or playful
experience) should be presented next? When should it be presented? Which game elements
should be adjusted and how?
Arguably, we can achieve meaningful adaptation in games because players are prepared
for personalised experiences more than in any other form of human computer interaction. The
players’ relationship to game adaptation is dependent on their playing style, experience,
personality etc. and the form of adaptation (e.g. implicitly or explicitly) needs to comply with the

player needs. So, when creating and designing emotional games, one needs to consider all the
processes involved, starting with the game design process itself. Further, while emotion models
can be used to inform game designers in a mixed-initiative design fashion (see (Smith, et al.,
2011), (Liapis, et al., 2012) among others) we argue that a semi- of fully-automated approach to
emotion-driven game design can ultimately lead to improved playing experience. But as the
game design entails the definition of many aspects of a game, when referring to emotional game
adaptation one fundamental question to ask is what game elements one can adjust? In other
words: what does emotional adaptation entail? A high-level observation of available game
elements derives two key classes of adaptable game features: game agents (and NPCs) and game
content (see Figure 1). Both of these can be manipulated to convey emotional responses and
adaptation, in a manner that leads the player to become more emotionally involved with the
game.

4.1 Adapting and Expressing Emotion through Agents and NPCs
One of the two main ways by which emotions can be manifested in games is through their game
characters (see Figure 1). Characters in a game need to act, and their actions should be
determined by emotional reactions to events occurring in the game. This can be achieved in a
completely scripted manner, or through an automatic, autonomous approach, by using emotion
agent architectures (Gratch & Marsella, 2004) underlying cognitive models to generate
behaviour of the characters. Such architectures are usually model-based as they seek inspiration
in psychological or physiological models of humans, and other species, and embed features that
allow them to go beyond the pure “rational” behaviour. Emotional agent architectures naturally
include a way to capture emotions or other affective states, such as moods or even personality
(Doce, Dias, Prada, & Paiva, 2010). These affective states often have symbolic representations,
or can be the resulting pattern of behaviour arising from a variety of different processes
embedded in the agent. Examples of these architectures are EMA (Gratch & Marsella, 2004) and
FAtiMA, used for research on serious games in the areas of social and emotional training (Paiva,
et al., 2004), (Aylett, et al., 2009), (Lim, Dias, Aylett, & Paiva, 2012), ALMA (Gebhard, 2005),
or the MindModule (Eladhari & Mateas, 2008) for player characters. Further, these characters
may portray social roles and have different personalities leading the users to raise expectations
concerning the characters actions, and as such triggering emotional reactions by the players when
those expectations are not met. A game character that plays an ally or a mentor (see (Isbister K. ,

2006)) will lead to certain emotional reactions when for example the character deceives the
player. The personality of a game character can be established by the nature and strength of the
emotions that the character portrays in different situations, and its tendency to act in a certain
manner. For example, an extrovert character will use more speech acts and more expressive
actions than an introvert character. These features of personality may be achieved by the
appropriate parameterization of the agents (see (Doce, Dias, Prada, & Paiva, 2010)).
Characters will not only trigger emotional states as a response to a given situation, but
they also need to express emotions in a way that conveys their “internal” emotional state. Thus,
emotions not only guide the decision making of the characters, but also the expressions they will
portray, which again can be generated in an automatic manner. Expressions of different
emotional states, such as for example fear, surprise, sadness or happiness may blend handcrafted
animations to express both strong and subtle emotions with procedural animation techniques to
achieve real-time behaviour animated characters (Perlin & Goldberg, 1996).
Characters provide a rich medium to express emotions, trigger emotions and adapt to the
emotions of players. Further, these emotional manifestations can be augmented via adaptive
narrative and camera profiles (Picardi, Burelli, & Yannakakis, 2011) allowing for the emphasis
on particular emotional states or features, and combining it with game content adaptation (see
Figure 1). We should, however, stress the research oriented nature of these early systems
acknowledging that autonomous emotional NPCs are still in the realm of a few exploratory
research projects. However, we believe that by addressing this challenge, this area will become
one of the major pillars of AI in games.

4.2 Adapting and Expressing Emotion through Game Content
Yet, games may or may not include agents. Games, however, definitely include a form of virtual
environment where agents “live” (if existent) and the interaction is taking place. There are a
number of elements (i.e. game content) from the game world that an adaptive process can alter in
order to drive the player to particular affective patterns. As mentioned already, game content
may include every aspect of the game design such as game rules (Togelius & Schmidhuber,
2008), reward systems, lighting (de Melo & Paiva, 2007), camera profiles (Yannakakis,
Martinez, & Jhala, 2010), maps (Togelius, et al., 2010), levels, tracks (Togelius, Yannakakis,
Stanley, & Browne, 2011), story plot points (Riedl, 2012), and music (Eladhari, Nieuwdorp, &

Fridenfalk, 2006). Even behavioural patterns of NPCs such as their navigation meshes, their
parameterised action space and their animations can be viewed as content.
The adaptive process in this case is referred to as procedural content generation (PCG)
which is the generation of game content via the use of algorithmic means. According to the
taxonomy presented in (Togelius, Yannakakis, Stanley, & Browne, 2011) game content can be
necessary (e.g. game rules) or optional (e.g. trees in a level or flying birds on the background).
Further, PCG can be either offline or online, random or based on a parameterised space,
stochastic or deterministic and finally it can be either constructive (i.e. content is generated once)
or generate-and-test (i.e. content is generated and tested). The Experience-driven PCG
framework (Yannakakis & Togelius, 2011) views game content as an indirect building block of
player affect and proposes adaptive mechanisms for synthesizing personalised game experiences.

4.3

Integration in the Affective Loop: When and How to Adapt

Once sufficient amounts of appropriate game stimuli (which include the actions of the game
characters and in the environment) have been presented to the player, aspects of the playing
experience can be detected and modelled. For the affective loop to close effectively the game
logic needs to adapt to the current state of the game-player interaction. Whether agent behaviour
or parameterised game content, a mapping is required linking a user’s affective state to the game
context. That mapping is available as it is essentially the outcome of the emotion modelling
phase. Any search algorithm (varying from local and global search to exhaustive search) is
applicable for searching in the parameterised search space and finding particular game states
(context) that are appropriate for a particular affective state of a specific player. For example,
one can envisage the optimization of agent behaviour attributes for maximizing engagement,
frustration or empathy towards a player (Leite, et al., 2010). As another example, the study of
Shaker et al. (2010) presents the application of exhaustive search for generating Super Mario
Bros (Nintendo, 1985) levels that are maximally frustrating, engaging or challenging for any
player. In that study parameterised game levels are linked to in-game player behaviour attributes
and a set of affective states inferred from crowdsourced player reports. The model-free affective
model is built via evolving neural networks that learn the crowdsourced pairwise preferences
(i.e. neuro-evolutionary preference learning) .

A critical question once an adaptation mechanism is designed is how often particular
attributes should be adjusted. The frequency can vary from simple pre-determined or dynamic
time windows (Yannakakis & Hallam, 2009) but adaptation can also be activated every time a
new level (Shaker, Yannakakis, & Togelius, 2010) or a new game (Yannakakis & and Hallam,
2007) starts, or even after a set of critical player actions – such as in Façade (Mateas & Stern,
2003). The time window of adaptation is heavily dependent on the game under examination and
the desires of the game designer. Regardless of the time window adopted, adaptation needs to be
interwoven well with design if is to be successful.
One approach for assessing the appropriate time window for game adaptation is to test
the validity of the emotion models in different time windows and then make a compromise
between adaptation frequency and model performance (Yannakakis & Hallam, 2009)). As
models are expected to yield lower accuracies the more deviant they are from the interaction
time window they were built on, one needs to evaluate their accuracy with respect to different
time windows. A good compromise between accuracy and performance would yield sensible
decisions about the length of the adaptation time windows. In general, those can be either static
across all gameplay or dynamic (dependent on e.g. different levels).

4.4

Evaluating Adaptation

Affective game adaptation can lead to personalised experiences for the player. A key research
question, however, is how do we appropriately evaluate the efficacy of the adaptation
mechanism. While several different methods from human factors research are available, all seem
to converge to control-based experiments where games are usually evaluated with and without
the adaptation module (e.g. see (Yannakakis & Hallam, 2009) among others). The outcome of
such an experimental protocol usually allows concluding whether adaptation seems to have an
impact on the player’s engagement (or any other relevant emotional state). The efficacy of
adaptation can be indirectly measured from standard usability metrics (such as response time), or
more directly from the output of the emotional model itself (i.e. testing if adaptation yields
higher values for the model’s output). In addition, one may perform a user survey that asks
players to evaluate the adaptation experience (e.g. see (Yannakakis & Hallam, 2009)).

5 The road ahead
In this final section we list a number of promising research directions for the area of emotion in
games that, we believe, will contribute to the advancement of the field in the near future.
-

Mixed-initiative experience design: the mixed-initiative (i.e. human-machine cocreation) approach to design and creativity is getting increasingly important for game
design. Innovative projects such as Sentient Sketchbook (Liapis, Yannakakis, &
Togelius, 2013), Sketchaworld (Smelik, 2011) and Tanagra (Smith, Whitehead, &
Mateas, 2011) have focused on aspects of level design. However, the potential of
emotion-driven, mixed-initiative design has not been investigated in depth yet. We
believe that co-creative environments which are affected by emotion, intention and
preference models (of players and/or designers) may enhance creative thinking in
game design.

-

Emotion in the game pipeline: the impact of emotion in game development can be
evident and in all phases of game production. Future research needs to focus at
establishing protocols for the integration of emotion research in the pipeline of game
production. Placing emotion research as the driving force of game production can
ultimately lead to better game design, more efficient development, more reliable
testing and richer quality assurance.

-

Links to adjacent fields of study: the study of emotion in games as represented by
the AC community can only benefit from stronger links to and collaborations with
adjacent research fields which include the areas of game studies, game design, user
and user experience research, and experimental psychology. In that way, advances in
a field can inform relevant research areas for the better understanding of player
emotion and its particularities.

-

Content creation is automated: the use of procedural content generation techniques
for the design of better games has reached a peak of interest in commercial and indie
game development which is showcased by successful (almost entirely procedurally
generated) games such as Minecraft (Mojang, 2011) and Love (Eskil Steenberg,
2010). Future games, in general, are expected to contain less manual and more useror procedurally-generated content as the cost of content creation and the content

creation bottleneck are key challenges for commercial game production. As the
number of games that are (partially or fully) automatically generated grows the
challenge of detecting and monitoring emotion in never-ending open worlds of
infinite replayability value increases substantially. The automation of content
creation, however, offers a unique opportunity towards realizing affect-driven
content generation in games (Yannakakis & Togelius, 2011).
-

Multimodal game interaction: several modalities or player input are still nowadays
implausible within commercial game development. For instance, existing techniques
for physiological recording require the contact of body parts (e.g. head or fingertips)
to the sensors making physiological signals such as EEG, respiration and skin
conductance rather impractical and highly intrusive. Modalities such as facial
expression and speech could be technically plausible in games even though the
majority of the vision-based affect-detection systems currently available cannot
operate in real-time (Zeng, Pantic, Roisman, & Huang, 2009). On a positive note,
recent advances in sensor technology have resulted in low-cost unobtrusive
biofeedback devices appropriate for gaming applications (such as Emotiv1 EEG
system and Empatica2 bracelet). In addition, top game developers have recently
started to experiment with multiple modalities of player input (e.g. physiological and
behavioural patterns) for the personalization of experience of popular AAA games
such as Left 4 Dead (Valve, 2008) (Ambinder, 2011). Finally, recent technology
advances in gaming peripherals such as the PrimeSense3 camera showcase a
promising future for multimodal natural interaction in games.

-

General emotions across games: after sufficient research has been put in the study
of emotion in different game genres, methods for recognising emotional
manifestations across game genres would be required. Such methods could focus on
the inference of generic emotions that are linked to reward systems and game
mechanics across game genres.

-

Game data mining: massive sets of player metrical data (metrics) is currently
available and analysed, thus, empowering the design of future games (Drachen,

1

http://emotiv.com
http://www.emoticalab.com
3
http://www.primesense.com
2

Thurau, Togelius, Yannakakis, & Bauckhage, 2013). While such data usually contain
behavioural aspects of playing experience data mining and data analysis research will
need to focus on inferring the relationship between detailed player metrics, and
cognitive and affective maps of experience. Making sense of massive game data sets
is amongst the largest challenges from both and analysis and an algorithmic
perspective.

Acknowledgements
The authors would like to thank Mirjam P. Eladhari for insightfull disssusions. This work was
supported, in part, by the FP7 ICT project SIREN (project no: 258453).

References
Aarseth, E. (2004). Genre Trouble. In First Person: New Media as Story, Performance, and Game.
Cambridge: MIT Press.
Ambinder, M. (2011). Biofeedback in Gameplay: How Valve Measures Physiology to Enhance Gaming
Experience. Game Developers Conference.
Asteriadis, S., Karpouzis, K., & Kollias, S. D. (2008). A neuro-fuzzy approach to user attention
recognition. Proceedings of ICANN, pp. 927–936.
Aylett, R., Vannini, N., Andre, E., Paiva, A., Enz, S., & Hall, L. (2009). But that was in another country:
agents and intercultural empathy. Proceedings of The 8th International Conference on
Autonomous Agents and Multiagent Systems.
Bates, J. (1994). The role of emotion in believable agents. Communications of the ACM, 122-125.
Bhuman, S., & Hingston, P. (2008). Bots trained to play like a human are more fun . Neural Networks,
2008. IJCNN 2008. IEEE World Congress on Computational Intelligence.
Calleja, G. (2011). In-Game: From Immersion to Incorporation. The MIT Press.
Conati, C. (2002). Probabilistic Assessment of User’s Emotions in Educational Games. Journal of
Applied Artificial Intelligence, special issue on “Merging Cognition and Affect in HCI”, 16, 555575.
Csikszentmihalyi, M. (1990). Flow: the Psychology of Optimal Experience. Harper Collins.
de Melo, C., & Paiva, A. (2007). Expression of emotions in virtual humans using lights, shadows,
composition and filters. Affective Computing and Intelligent Interaction, pp. 546-557.

De Melo, C., Zheng, L., & Gratch, J. (2009). Expression of Moral Emotions in Cooperating Agents. 9th
International Conference on Intelligent Virtual Agents.
Deci, E. L., & Ryan, R. M. (2000). The 'what' and 'why' of goal pursuits: Human needs and the selfdetermination of behavior. Psychological Inquiry, 11, 227-268.
Dias, J., & Paiva, A. (2005). Feeling and Reasoning: A Computational Model for Emotional Characters .
Advances in Artificial Intelligence, EPIA, pp. 127-140.
Doce, T., Dias, J., Prada, R., & Paiva, A. (2010). Creating individual agents through personality traits.
Intelligent Virtual Agents.
Drachen, A., Thurau, C., Togelius, J., Yannakakis, G., & Bauckhage, C. (2013). Game Data Mining. In
Game Analytics. Springer-Verlag.
Ekman, P., & Friesen, W. (1978). Facial Action Coding System: A Technique for the Measurement of
Facial Movement. Palo Alto: Consulting Psychologists Press.
Eladhari, M., & Mateas, M. (2008). Semi-autonomous avatars in World of Minds: A case study of AIbased game design . Proceedings of the 2008 International Conference on Advances in Computer
Entertainment Technology.
Eladhari, M., Nieuwdorp, R., & Fridenfalk, M. (2006). The soundtrack of your mind: mind musicadaptive audio for game characters . Proceedings of the 2006 ACM SIGCHI international
conference on Advances in computer entertainment technology.
Feldman, L. (1995). Valence focus and arousal focus: Individual differences in the structure of affective
experience. Journal of Personality and Social Psychology(69), 53-166.
Frijda, N. (1986). The Emotions. Engelwood cliffs, NJ: Cambridge University Press.
Gebhard, P. (2005, July). ALMA: a layered model of affect. Proceedings of the fourth international joint
conference on Autonomous agents and multiagent systems , pp. 29-36.
Georgeff, M., Pell, B., Pollack, M., Tambe, M., & Wooldridge, M. (1999). The Belief-Desire-Intention
Model of Agency. Intelligent Agents V: Agents Theories, Architectures, and Languages, pp. 1-10.
Giannatos, S., Nelson, M., Cheong, Y., & Yannakakis, G. N. (2012). Generating Narrative Action
Schemas for Suspense. Proceedings of the 5th Workshop on Intelligent Narrative Technologies,
AIIDE.
Gomes, P. F., Segura, E. M., Cramer, H., Paiva, T., Paiva, A., & Holmquist, L. E. (2011, November).
Vipleo and phypleo: Artificial pet with two embodiments. Proceedings of the 8th International
Conference on Advances in Computer Entertainment.
Gratch, J., & Marsella, S. ( 2005). Evaluating a computational model of emotion. Autonomous Agents and
Multi-Agent Systems, 11(1), 23-43.

Gratch, J., & Marsella, S. (2004). A domain-independent framework for modeling emotion . Cognitive
Systems Research, 5(4), 269-306.
Hingston, P. (2009). A Turing Test for Computer Game Bots. IEEE Transactions on Computational
Intelligence and AI in Games, I.
Hullett, K., & Whitehead, J. (2010). Design patterns in FPS levels. Proceedings of the Fifth International
Conference on the Foundations of Digital Games, pp. 78-85.
Isbister, K. (2006). Better game characters by design: A psychological approach. Morgan Kaufmann
Pub.
Isbister, K., & Schaffer, N. (2008). Game Usability: Advancing the Player Experience. Morgan Kaufman.
Joachims, T. (2002). Optimizing Search Engines using Clickthrough Data . Proceedings of the ACM
Conference on Knowledge Discovery and Data Mining.
Juul, J. (2001). Games Telling Stories? A brief note on Games and Narratives. Game Studies, I(1).
Koster, R. (2005). A theory of fun for game design. Paraglyph press.
Lazarus, R. (1994 ). Emotion and Adaptation. Oxford University Press.
Lazzaro, N. (2004). Why we play games: Four keys to more emotion without story. Game Developers
Conference.
Leite, I., Mascarenhas, S., Pereira, A., Martinho, C., Prada, R., & Paiva, A. (2010). Why Can’t We Be
Friends? An Empathic Game Companion for Long-Term Interaction. . In Intelligent Virtual
Agents, pp. 315-321.
Liapis, A., Yannakakis, G. N., & Togelius, J. (2012). Adapting Models of Visual Aesthetics for
Personalized Content Creation. IEEE Transactions on Computational Intelligence and AI in
Games, Special Issue on Computational Aesthetics in Games.
Liapis, A., Yannakakis, G. N., & Togelius, J. (2013). Sentient Sketchbook: Computer-Aided Game Level
Authoring. Proceedings of ACM Conference on Foundations of Digital Games, pp. 213-220.
Lim, M. Y., Dias, J., Aylett, R., & Paiva, A. (2012). Creating adaptive affective autonomous NPCs.
Autonomous Agents and Multi-Agent Systems, pp. 1-25.
Malone, T. W. (1980). What makes things fun to learn? heuristics for designing instructional computer
games. Proceedings of the 3rd ACM SIGSMALL symposium and the first SIGPC symposium on
Small systems, pp. 162-169.
Mandryk, R., & Inkpen, K. (2004). Physiological indicators for the evaluation of co-located collaborative
play. Proceedings of the 2004 ACM conference on Computer supported cooperative work. ACM.

Martinez, H. P., & Yannakakis, G. N. (2011). Mining Multimodal Sequential Patterns: A Case Study on
Affect Detection. Proceedings of the 13th International Conference on Multimodal Interaction
(ICMI) .
Martinez, H. P., Hullett, K., & Yannakakis, G. N. (2010). Extending Neuro-evolutionary Preference
Learning through Player Modeling. Proceedings of the 2010 IEEE Conference on Computational
Intelligence and Games, pp. 313-320.
Mateas, M., & Stern, A. (2003). Façade: An Experiment in Building a Fully-Realized Interactive Drama.
Game Developers Conference, Game Design track.
McCoy, J., Treanor, M., Samuel, B., Tearse, B., Mateas, M., & N., W.-F. (2010). Comme il Faut 2: a
fully realized model for socially-oriented gameplay. INT3 ’10: Proceedings of the Intelligent
Narrative Technologies III Workshop, pp. 1-8.
McQuiggan, S., & Lester, J. (2009). Modeling Affect Expression and Recognition in an Interactive
Learning Environment. International Journal of Learning Technology, IV(3), 216-233.
McQuiggan, S., Robison, J., & Lester, J. (2010). Affective Transitions in Narrative-Centered Learning
Environments. Educational Technology & Society, I(13), 40-53.
Nijholt, A. (2009). BCI for Games: A State of the Art Survey. Proceedings of Entertainment Computing ICEC, pp. 225–228.
Ortony, A., Clore, G., & Collins, A. (1988). The Cognitive Structure of Emotions. Cambridge University
Press.
Paiva, A., Dias, J., Sobral, S., Aylett, R., Sobreperez, S., Woods, S., . . . Hall, L. E. (2004). Caring for
Agents and Agents that Care: Building Empathic Relations with Synthetic Agents. Autonomous
Agents and Multi-agent Systems, AAMAS.
Pantic, M., & Caridakis, G. (2011). Image and Video Processing for Affective Applications. In EmotionOriented Systems: The Humaine Handbook (pp. 101–117). Springer-Verlag Berlin Heidelberg.
Perlin, K., & Goldberg, A. (1996). Improv: A system for scripting interactive actors in virtual worlds.
Proceedings of the 23rd annual conference on Computer graphics and interactive techniques, pp.
205-216.
Picardi, A., Burelli, P., & Yannakakis, G. N. (2011). Modelling virtual camera behaviour through player
gaze. Proceedings of the 6th International Conference on Foundations of Digital Games, pp. 107114.
Plans, D., & Morelli, D. (2012). Experience-Driven Procedural Music Generation for Games. IEEE
Transactions on Computational Intelligence and AI in Games, IV(3), 192-198.
Poels, K., & IJsselsteijn, W. (2008). Development and validation of the game experience questionnaire.
FUGA Workshop mini-symposium.

Riedl, M. O. (2012). Interactive Narrative: A Novel Application of Artificial Intelligence for Computer
Games. Proceedings of the 26th AAAI Conference on Artificial Intelligence.
Roberts, D., H., N., & C., I. (2009). Learning to Influence Emotional Responses for Interactive
Storytelling. AAAI Symposium on Intelligent Narrative Technologies.
Russell, J. A. (1980). A circumplex model of affect. Journal of Personality and Social Psychology, 39(6),
1161-1178.
Salen, K., & Zimmerman, E. (2003). Rules of Play: Game Design Fundamentals. MIT Press.
Savva, N., Scarinzi, A., & Bianchi-Berthouze, N. (2012). Continuous Recognition of Player’s Affective
Body Expression as Dynamic Quality of Aesthetic Experience. IEEE Transactions on CI and AI
in Games, Special Issue on Computational Creativity, 199 - 212.
Scherer, K. R. (1993). Studying the emotion-antecedent appraisal process: An expert system approach .
Cognition and Emotion, VII, 325-355.
Scherer, K. R. (2005). What are emotions? And how can they be measured? Social Science Information,
IV(44), 693-727.
Seif, E.-N. M., Vasilakos, T., C., R., & Zupko, J. (2009). Dynamic Intelligent Lighting for Directing
Visual Attention in Interactive 3D Scenes. IEEE Transactions on Computational Intelligence and
AI in Games, I(2).
Shaker, N., Asteriadis, S., Yannakakis, G. N., & Karpouzis, K. (2011). A Game-based Corpus for
Analysing the Interplay between Game Context and Player Experience. Proceedings of the 2011
Affective Computing and Intelligent Interaction Conference; Emotion in Games Workshop.
Shaker, N., Yannakakis, G. N., & Togelius, J. (2010). Towards automatic personalized content generation
for platform games. AAAI Conference on Artificial Intelligence and Interactive Digital
Entertainment (AIIDE).
Skinner, B. F. (1938). The Behavior of Organisms: An Experimental Analysis. Cambridge,
Massachusetts: B. F. Skinner Foundation.
Smelik, R. M. (2011). A Declarative Approach to Procedural Generation of Virtual Worlds. PhD Thesis,
Delft University of Technology, Delft.
Smith, G., Whitehead, J., & Mateas, M. (2011). Tanagra: Reactive Planning and Constraint Solving for
Mixed-Initiative Level Design. IEEE Transactions on Computational Intelligence and AI in
Games.
Suits, B. (2005). The Grasshopper: Games, Life and Utopia. Broadview Press.
Sundstrom, P. (2005). Exploring the affective loop. Stockholm University.
Sweetser, P., & Wyeth, P. (2005). GameFlow: A Model for Evaluating Player Enjoyment in Games. ACM
Computers in Entertainment, III(3).

Thomas, F., & Johnston, O. (1995). The illusion of life: Disney animation. . Hyperion.
Togelius, J., & Schmidhuber, J. (2008). An Experiment in Automatic Game Design. Proceedings of the
IEEE Symposium on Computational Intelligence and Games (CIG), pp. 111-118.
Togelius, J., Preuss, M., Beume, N., Wessing, S., Hagelback, J., & Yannakakis, G. N. (2010).
Multiobjective exploration of the starcraft map space. 2010 IEEE Conference on In
Computational Intelligence and Games (CIG), pp. 265-272.
Togelius, J., Yannakakis, G. N., Stanley, K. O., & Browne, C. (2011). Search-based Procedural Content
Generation: A Taxonomy and Survey. IEEE Transactions on Computational Intelligence and AI
in Games, Special Issue on Procedural Content Generation, III(3), 172-186.
Tognetti, S., Garbarino, M., Bonarini, A., & Mateucci, M. (2010). Modeling enjoyment preferecne from
physiological responses in a car racing game. Proceedings of the IEEE Conference on
Computational Intelligence and Games, pp. 321-328.
Yannakakis, G. N. (2009). Preference Learning for Affective Modeling. Proceedings of the Int. Conf. on
Affective Computing and Intelligent Interaction, pp. 126-131.
Yannakakis, G. N. (2012). Game AI Revisited. ACM Computing Frontiers Conference, pp. 285-292.
Yannakakis, G. N., & and Hallam, J. (2007). Towards Optimizing Entertainment in Computer Games.
Applied Artificial Intelligence(21), 933-971.
Yannakakis, G. N., & Hallam, J. (2009, June). Real-time Game Adaptation for Optimizing Player
Satisfaction. IEEE Transactions on Computational Intelligence and AI in Games, I(2), 121-133.
Yannakakis, G. N., & Hallam, J. (2011). Rating vs. Preference: a comparative study of self-reporting.
Affective Computing and Intelligent Interaction, pp. 437-446.
Yannakakis, G. N., & Togelius, J. (2011). Experience-driven Procedural Content Generation. IEEE
Transactions on Affective Computing, II(3), 147-161.
Yannakakis, G. N., Martinez, H. P., & Jhala, A. (2010). Towards Affective Camera Control in Games.
User Modeling and User-Adapted Interaction, IV(20), 313-340.
Yannakakis, G. N., Togelius, J., Khaled, R., Jhala, A., Karpouzis, K., Paiva, A., & Vasalou, A. (2010).
Siren: Towards adaptive serious games for teaching conflict resolution. Proceedings of the 4th
European Conference on Games Based Learning.
Zeng, Z., Pantic, M., Roisman, G., & Huang, T. (2009). A survey of affect recognition methods: Audio,
visual, and spontaneous expressions. IEEE Trans. Pattern Analysis and Machine Intelligence,
I(31), 39-58.

