Multiagent and Grid Systems – An International Journal 8 (2012) 329–347
DOI 10.3233/MGS-120198
IOS Press

329

FRIENDs: Brain-monitoring agents for
adaptive socio-technical systems
Alexis Morris∗ and Mihaela Ulieru

PY

Adaptive Risk Management Lab, Faculty of Computer Science, The University of New Brunswick,
Fredericton, NB, Canada

OR

CO

Abstract. Brain-monitoring is quickly becoming an important field of research, with potentially significant impacts on how
people will interact with technology. As understandings of the inner-workings of the brain become more accurate technologies
are becoming more advanced, smaller, cheaper, and ubiquitous. It is expected that new forms of computing that take advantage
of brain states will be developed. This will enable systems to be highly aware of user mental contexts (emotions, intentions, and
moods). These systems would display higher autonomic behavior and would streamline user-interaction while managing the use
of brain context data for applications and services. There are few studies of how to develop and make use of agent architectures
in this new domain. Current approaches target a single user and application situation. To be ubiquitous it is unrealistic for
applications to have specialized overhead for individual users. Personalizable, but distributed approaches are needed.
To realize a general purpose agent for brain-monitoring and management of brain context is the goal of this work. This involves the selection of a brain-monitoring paradigm, the selection of an agent architecture paradigm, an inferencing mechanism,
and the combination of the three towards a unified framework. Core motivations are discussed, and an early agent framework
design (FRIEND) is presented, along with proposed proof-of-concept applications for using brain context.
Keywords: Ambient intelligence, cognitive inference, context awareness, multi-agent systems

1. Introduction

AU

TH

The inner-workings of the human brain remains one of the great frontiers that could further the advancement of technology. Brain data has largely been unavailable to developers of computing systems.
How and what people think, as well as their states of mind, mood, focus, and intentions represent sensitive, yet important, data elements. Access to brain data would be useful for novel software that could be
streamlined to a particular user; an aid in a host of applications. A driver falling asleep at the wheel could
be detected and awakened before an incident. A nurse overworked and unable to focus well could be
given rest breaks before administering incorrect medicine or dosages to patients. An important interface
could filter away non-critical information from a pressured worker. These kinds of automated control
actions were once fiction, but can be realizable today, because of brain data.
Technologies, like electroencephalogram (EEG), functional near infrared spectroscopy (fNIRS), and
even functional magnetic resonance imaging (fMRI), are becoming smaller, cheaper, and easier to work
with [7,19,55]. This means that mobile brain scanning for commercial everyday applications is on the
horizon, and with it is a host of interesting research problems.
∗
Corresponding author: Alexis Morris, Adaptive Risk Management Lab, Faculty of Computer Science, The University of
New Brunswick, Fredericton, NB, Canada. E-mail: alexis.morris@unb.ca.

c 2012 – IOS Press and the authors. All rights reserved
ISSN 1574-1702/12/$27.50 

330

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

Making sense of brain context on the fly (states and patterns of activity) requires adequate measurement methods, inferencing techniques, and a control architecture that captures these signals and makes
use of them. The measurement methods are available, as well as inferencing methods [7], but robust
control architectures that are flexible, fast, autonomous, and applicable in multiple scenarios remain to
be explored. At present individual researchers are developing custom solutions for handling brain measurements [24,55,56] but no general-purpose architecture has emerged. This research aims to fill this
gap by exploring architectures and developing a novel agent-oriented approach to brain-monitoring and
brain context management systems.
2. Motivation

PY

2.1. Socio-technical systems gaps

AU

TH

OR

CO

This work aims to seamlessly bridge the gap between people and technology from a techno-centric
viewpoint, through smarter, human-context-aware computing. Its purpose is to augment social systems
with more dynamic and flexible technology. At a high level there are three key issues. First, there are
significant failures due to the misfit between technology and social context (i.e., the socio-technical gap
between users and technologies). Second is that although these gaps can be minimized, there is only so
much that can be done by modifying social systems to fit better with technologies. Third, there is a real
challenge in designing, developing, and testing technologies that minimize the socio-technical gap.
Failures due to socio-technical disharmony have been discussed by Vicente [75], as stemming from
five core layers (physical, psychological, social-team, organizational, and political), and range from being simply annoying to catastrophic. These result from flaws in both human social systems and supporting technologies, in particular computing technologies. On the human side there are limits, task overloads, attention overloads, and mismatched mental models [39], each contributing to potential failure
points wherein people make mistakes due to excess demands, improper understanding of system states,
tasks, and situations. On the technological side these problems are compounded by interface complexity
and inefficiency [10], tasks out of context with situations, and the sheer increase of speed, data volume,
and ubiquity.
Socio-technical gaps can be minimized through development of either smarter social systems, or
smarter technology. Since social systems are limited in terms of human cognitive and physical capacities (such as stress, situational, or relational limits), it is realistic to focus on the development of smarter
technologies to bridge the gap. Technologies like this would perform tasks related to monitoring human
limits, predicting the state of the social (human) system, protecting the social system through useful
interventions/actions, and assisting the social system through anticipatory actions where possible.
There is a need for software systems, as technology progresses, to understand human social systems,
which are not well defined, yet highly dynamic, in many contexts and multiple environments, involved in
potentially large complex and also multi-dimensional social networks (see [47,75] for more on dimensionality of social systems). In order to succeed in this task these systems must themselves be highly
dynamic, autonomic (self-*, [36]), and context-sensitive (especially for human-context, device-context,
and situation-contexts). In this work these capabilities are considered as “human-awareness”.
2.2. Brain cognitive context awareness
Developing high human-awareness systems is a big challenge, and remains a novel problem related to
the overarching goal of improving the socio-technical gap. Human-aware systems must understand and

331

CO

PY

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

Fig. 1. Literature for the project involves a merger of context-awareness and intelligent agents.

AU

TH

OR

react to human contexts. This refers to cognitive contexts (and emotional contexts), as well as physical,
relational (social), and situational contexts. Of all these kinds of contexts to keep track of one of the
most difficult to explore has been the cognitive context.
The cognitive domain remains fuzzy and interdisciplinary, a subject which is still in disagreement
by the main proponents (i.e., knowing precisely where cognition comes from and how emotions and
consciousness arise from the activities of the brain). Despite this, systems that could make sense of
this kind of context could prove useful for understanding users at a level that would make significant
applications possible. Cars that would be able to alert drivers of dangerous energy levels, or brake if
attention is not focused. Hospital workers that could know their level of overload to a high degree could
prevent casualties due to stress related mistakes in treatment, improving the “visibility” of stressful
situations. Understanding the cognitive states of others is valuable information which has been largely
unavailable to the general public for a host of reasons. Technologies are finally cheap enough, small
enough, noise resilient enough, and power-efficient enough to be useful in everyday applications.
In a ubiquitous/pervasive system the cognitive context aware system would be a smart user assistant
or a service for other applications. Architectures are needed to monitor, infer, learn, make decisions, and
take actions on behalf of users, based on their cognitive and emotional states. Approaches to make sense
of these cognitive contexts are needed to bridge the socio-technical gap in an important way, making
software more aware of users in an intimate and deep way. This is the problem being addressed in this
work.
3. Background
This research targets the intersection between the general disciplines of awareness modelling/monitoring and intelligent systems paradigms (see Fig. 1). The development of the agent architecture for brain

332

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

monitoring centers around four themes, i) ubiquitous brain sensing technologies, ii) cognitive state estimation, iii) hybrid control architectures for context awareness, and iv) application specific uses of brain
context. This literature summary is ordered as such; the final analysis is that a) research on brain sensing
for ubiquitous domains is new, b) generally applicable approaches are unavailable, and d) hybrid BDI
and soft-computing agents are not common for brain context management.
3.1. Ubiquitous brain-sensing technologies

AU

TH

OR

CO

PY

Technologies that make use of the brain are still actively being researched, but can be divided based on
their input and output interaction with the brain itself. Brain computer interfaces (BCI), for instance, are
defined according to the following definition: “A BCI is a communication system in which messages or
commands that an individual sends to the external world do not pass through the brain’s normal output
pathways of peripheral nerves and muscles” [7]. Sending commands intentionally as output to control a
device distinguishes a BCI from other similar technologies. Passively monitoring the brain, and making
actions based on non-intentional signals, represents a slightly different domain [7]. Both make use of
inputs from the brain, but intentionality is the distinguishing factor. This work fits in the second category
of sensing non-intentional, non-control signals from the brain.
However, there have been very significant advances in the field of brain sensing and BCI that relate to
this work. The development of non-invasive brain sensing techniques have advanced to the point where
it is arguably on equal footing with invasive brain sensing techniques [7], when enough sensors are
used. Invasive brain sensing (for BCI or otherwise) is among the earliest techniques, involving surgical
implantations of sensing devices directly into the brain, either on the surface with electrocortigrams
(ECOG), or within the tissue with intracortical sensors [25]. The results have been high fidelity signal
detection. Recently, instead of sensing only, activators/stimulators (i.e., brain stimulator chips) have been
implanted [52]. These kinds of devices have been shown useful for providing feedback to the brain (for
controlling devices, etc) through intra-cortical stimulations [57].
Non-invasive brain sensing operates on a surface/scalp level, detecting brain activities according to
signals emitted by the brain during operation. These signals are captured in several ways. One technique involves electroencephalography (EEG) waves; electronic signals detectable from the scalp with
various sensor technologies. This is an established method that is very common in literature [26], despite being subject to noisy signals from muscle movement and eyeblinks. A second approach involves
measuring brain activity according to the change in blood oxygenation levels. Functional near-infrared
spectroscopy, fNIRS, performs this kind of detection using light-wave reflections to distinguish between
blood oxygenation levels near the brain, which has been shown to correlate with brain activity [55,73].
These two approaches, EEG and fNIRS, have minimized equipment, involving sensors that are now
wearable. In recent work they have been attached to headbands [2,55], and wireless headsets, such as
the Emotiv Epoc [1], and the Neurosky Mindset [2]. However, only the EEG headsets are currently
commercially available, and low-cost.
Other non-invasive brain sensing techniques require large devices such as magnetic resonance imaging (MRI) equipment, and positronic emissions topography and cat-scans (CT/PET). These provide high
resolution images of the brain, but are not useful in a ubiquitous setting since the equipment is large [77].
This is important to mention, since in the past most brain sensing was primarily for research and rehabilitative purposes, such as disabled and locked-in patients [26], and have only recently been targetted
towards everyday, non-rehabilitative uses. Ubiquitous brain sensing technologies are just becoming the
focus of BCI research, as seen in surveys like [7]. For instance, brain data has recently been combined

333

CO

PY

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

Fig. 2. The brain-computer-interface process, as seen in [26].

OR

with mobile phone applications, although these are primarily only for showing states of relaxation, or
activity [56]. These applications are very few but, with recent commercial availability of headsets, are
becoming more practical [7].
3.2. Biosignals and cognitive state estimation

AU

TH

Understanding human behavior is a large and open research area in artificial intelligence, particularly
for anticipation of affective and cognitive states, and approaches are still early, as seen in [54]. In terms
of biosignals, various sensors may be used such as cardiovascular activity, electrodermal activity, skin
temperature, respiration, and muscle activity, in order to classify features associated with emotional
and cognitive states [14]. However brain monitoring allows for signals classification directly from the
cognitive source.
The procedure for making use of data read from the brain has become a common process found in
many BCI projects [26]. This involves stages of signal acquisition, signal processing, and some form of
signal results usage. Signal acquisition has been discussed above. Signal processing for brain information
involves pre-processing, feature extraction, and classification (or translation of signal features into state
patterns) for use in system decisions/commands. These are standard techniques, and have been described
in works like [28,41,66]. See Fig. 2 for an overview of the brain computer interfacing process.
As mentioned, in this work the focus is not on command and control of devices via a BCI, but rather
decision making and shared control of devices based on brain data. Hence it is the stages of signal
acquisition, and signal processing that are relevant from this field. Cognitive metrics are available based
on spiking brain signal patterns known as evoked potentials, or sensorimotor rhythms [25], such as
the steady state visually evoked potential (SSVEP) (based on visual attention), the P300 wave (based on

334

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

CO

PY

selective attention), slow cortical potentials (SCP) and others (based on training), as well as event related
(de)synchronization (ERD/ERS), based on imagined movement. These can be seen in more detail in [25],
and classification algorithms are developed [21].
For instance the field of augmented cognition is based on the notion of using “cognitive state gauges”
as estimates of user cognitive loads for different applications [34,67]. There has been much research on
augmented cognition [61,62,67,68], and a number of gauges of cognitive load have been investigated.
Among these, EEG and fNIRS are found to have statistically significant effects on relating cognitive
workload to tasks [34]. The EEG measures considered in this study [34], were percentage high vigilance,
probability low vigilance, executive load, and several event-related potentials. Also, in [21], cognitive
load was assessed according to power spectral density analysis (PSD) of EEG channels at different frequency bands. Relaxation, communication, counting, navigating and visual search tasks were classified
successfully, despite environmental/situational noise. Frequency bands have been associated with brain
states such as attention, and working memory [9].
Also, in [22], error related potentials have been identified, both feedback errors, as well as observed
errors, as particular spikes that take place only when a user discovers a mistake while controlling a
device such as a shared BCI controlled wheelchair. In [74], fNIRS is used to detect mental states during
multi-tasking as a foundation for brain-based adaptive user interfaces. In [27], working memory load
was classified using EEG while performing cognitive tasks. In [38], task classification is conducted
using EEG data for classifying rest, mental arithmetic and mental rotation tasks. These and other studies
show that it is possible to classify several user cognitive states from brain activity.
3.3. Hybrid control architectures for context awareness

OR

In this work the focus is on the development of a hybrid control architecture that acts as a broker
and intermediary for EEG related cognitive state information between user and application; the core
component in a cognitive context awareness system.

AU

TH

3.3.1. Context and context awareness
Context has increased as an area of study since the 1990’s, and is generally defined according to
Dey and Abowd [5], as “any information that can be used to characterize the situation of an entity”.
Context includes location, identity, activity, and time, as a means of describing the situation, essentially
“what the user is doing” [5]. Systems that display context awareness are those which use any form of
context data to assist a user in their tasks [5]. Context awareness research aims at providing systems with
structures and concepts required in order to process information related to its operational environment,
and the objects and people within that environment. This focuses on the improved understanding of
situational states, and system user states of body and states of mind. These systems can then be more
autonomic and adaptive, having a higher “resolution” of a situation as it develops. Research in this area
is vast (see [32] for a survey, and [23,42,44] for further definitions. Figure 3 shows the context awareness
problem graphically, highlighting the mental states as the target aspect.
In the last decade there has been a significant trend towards the development of context awareness in a
range of scenarios. In [32] the authors survey the field from 2000 to 2007 and show that research in this
area has increased steadily, and is divided towards four layers of, core concepts and research, network
infrastructures and sensing, middleware (various kinds), applications, and user infrastructures and interfaces. The general need for context in applications is accepted and well discussed as a continuing field. It
is noted particularly, that context modelling and reasoning requires specialized techniques, as presented
recently in [11]. Such systems are required to deal with heterogeneity in information sources, mobility

335

OR

CO

PY

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

Fig. 3. The context awareness of states involve situational states, body, and mind states. The dashed line shows the focus area
on mental context.

AU

TH

of users, relationships between different data sources, timeliness of data (context history), imperfection
and incompleteness in data sources, reasoning for adequate decision-making, usability (for modelling
formalisms), and efficiency in providing context information.
These works show that researchers have centered on approaches to context awareness that are based
on object-role models, spatial models, and ontological models, as well as a number of abstraction mechanisms. Context must abstract from low-level sensory data, to higher level semantic interpretations, and
further deduce situational relationships. Finally these systems must handle uncertainty, and a host of
techniques have been developed which make use of fuzzy logic, probabilistic logic, Bayesian networks,
Hidden Markov models, and Dempster-Shafer evidence theories [11]. Particularly expressed is that hybrid approaches are needed that can leverage advantages of multiple approaches towards meeting the
large set of requirements for context awareness systems.
3.3.2. Hybrid soft-computing for context awareness
One approach to context modelling that has been proven is that of soft computing. Soft computing
involves the combined research domains of Fuzzy Logic, Artificial Neural Networks, and Evolutionary
Algorithms. These are well established fields that have been described in detail [45,71], particularly
for purposes of classification, inference, and pattern recognition (such as speech analysis, image and

336

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

CO

PY

facial recognition). Hybrid Fuzzy Inferencing Systems involve combinations of these fields resulting in
improved capabilities. For instance, artificial neural networks provide machine learning capabilities as
universal classifiers, while fuzzy systems act as problem solving agents that work well with uncertainty
in data through rule-based logic and membership functions that take on a range of acceptable values [45,
70]. Evolutionary algorithms are useful for evolving an optimum architecture for a neural network [45].
Hence these three provide mechanisms that are a good fit for the context awareness problem, and have
been employed in this direction with the recent increase in context awareness research. Classification of
biometric signals is one type of context problem that has been shown to use hybrid neuro-fuzzy techniques [45]. In [8] the authors show a fuzzy inference engine for situation awareness using semantic
hierarchies, fuzzy rules, and neurofuzzy classifiers. In [13] fuzzy classification is shown for dynamic environments that rely on fuzzy min-max neural networks. In particular the author provides an algorithm
for incremental fuzzy classification allowing systems to adapt internal fuzzy rules over time based on situational inputs. This implies that hybrid neurofuzzy systems can remain in synch with current contexts.
One relevant study involves [31], where fuzzy clustering of EEG data with a neural network was found
to correlate with five mental tasks, and a fuzzy inference system was presented. Finally, in [80], dynamic
fuzzy logic is presented for the development of a context awareness agent system for inferencing stock
market fluctuations. These all highlight the usefulness of soft-computing approaches, particularly hybrid
approaches, for context awareness problems very recently.

AU

TH

OR

3.3.3. Hybrid agents for context awareness
Agents are largely considered as hardware or software control paradigms that have degrees of autonomic, social, reactive, and proactive behavior [78]. Although this is a general definition, it is extended
with the addition of notions of belief, desires, and intentions [60,78]. These systems have been developed, in the 1990’s, concurrent to context awareness research and represent a significant field with
contributions to distributed artificial intelligence, robot control, modelling and simulation, human-agent
teamwork, and even wireless sensor networks [6,18,46,47,50,72]. The field targets theoretical developments for reasoning with agents, agent architectures for designing such agents, and agent languages for
programming and implementation [78].
Agent theories have roots in modal logics, particularly possible worlds theory, as discussed in [59,60,
78], which led to the development of popular agent architecture research. In [15], agent architectures
are defined as design methodologies that must continuously “transform perception into a useful mental
representation R; apply a cognitive process f to R to create R’, a representation of desired actions; and
transform R’ into the necessary motor or neural effects.” The author also reviews four core architectural
paradigms based on research trends: the behavior-based AI, two and three layered systems, belief-desire
and intention (BDI) architectures, and Soar/Act-R. Hybrid approaches, as well as architectures. The
work highlights that agent design methodologies, although different, may be considered according to
modularity of design and control, hierarchically organized action selection, and a parallel environment
monitoring system. The work is relevant as a general overview that highlights the development of the
BDI architecture, which is a selected framework for this research proposal.
BDI agents, have been proposed in [60], as a “Pneulian reactive system” based on modal logics and
the subsequent development of a BDI agent language, Agentspeak [59]. The work in this area has been
accepted by the community and has been translated into agent programming languages such as JASON [12], Brahms [17], and AgentFactory [53]. There are a host of logic-based languages that have
been developed for programming agent systems. These have been recently surveyed in [49,64].

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

337

OR

CO

PY

Context aware applications are closely intertwined with agent technology since the development of
Dey, et al’s, conference assistant [20], and in general a context-aware application fits the previous definitions of an agent application [15,78]. As such, hybrid soft computing approaches to context can benefit
from agent architectural developments, particularly when multiple distributed agents are involved, as
is the case for a ubiquitous context management system. Hybrid soft-computing systems are partially
autonomous, and reactive inference systems, whereas agents must be also be proactive (goal oriented)
and social. Also, many context problems can be described/modeled easily based on higher level BDI
languages such as Agentspeak [12]. However, BDI agent systems have proven to have large overhead
costs in development, as they must track large amounts of belief data, active goals, and active plans
(sequences of actions already in progress but not necessarily complete). They could benefit from the
efficiencies of the soft-computing approaches.
There have been several works which demonstrate mixed agent-oriented and soft-computing approaches, such as [80], where an agent is combined with a fuzzy logic approach towards predicting
the stock market. These have been presented as early as 2004 where, in [69], the agent fuzzy decisionmaking framework is presented and the authors highlight that agent decision-making is an inherently
fuzzy process and propose a fuzzy-bdi agent interpreter. In [63], an agent’s model of uncertainty is
presented using fuzzy set theory to provide the uncertainty-handling benefits of fuzzy logic to agent
systems. In [29], a neurofuzzy BDI agent model is applied to the problem of controlling a simulation of
an autonomous underwater vehicle. In [43], a neurofuzzy BDI agent has been presented for scheduling
and assigning berths for vessels in container terminals, based on changing environment data. In [37], a
neurofuzzy controller is combined with a BDI agent architecture for plan automation.
Although the benefits for crossovers between hybrid soft-computing-agents is clear, there remains
the need for an architecture that provides these capacities and can be implemented and generally applied/programmed. Also, the use of such an agent in an active context management system is still an open
area of exploration. This work fits in this domain by targetting the development of a hybrid-neurofuzzyBDI-agent for context awareness of brain EEG data.
3.4. Related work on uses of brain context

AU

TH

In this work the applications of interest are those related to passive monitoring and alert, noise and
distraction filtering, and shared control, all based on EEG context and cognitive state estimates. These
general uses, see Fig. 4, range from safety calculations for monitoring, intervention, interruption, and
filtering information for a user, in various domains.
Research in this area is only just beginning to be actively realized, with the development of the bodynet [79], where the miniaturization of wireless sensing technologies have enabled wearable wireless
sensing devices. Today large projects such as the EU Guardian Angels initiative [3], are beginning to
target the goal of personal smart agent assistants. Similarly the emoBAN work of [76], aims to develop
methods of psycho-physiological mobile computing, although agent approaches are not a focus. Further,
the augmented cognition (Aug-Cog) field has a related vision for adaptive systems based on brain and
body information and has shown a number of related works towards these systems [61,62,67,68], but a
general-purpose and hybrid agent approach remains an open area of research [35,51].
In terms of mobile devices and EEG waves, the work of [56], develops an EEG system involving
the Emotiv EPOC wireless headset [1], for emotion measurement using spectral analysis and Bayesian
systems as a classification method.
In the work of [55,73], a mobile fNIRS system is used to adjust visual representation of data to fit user
cognitive strengths, and also for real-time task classification. Also, in [33], a real-time BCI is developed
on PDA hardware and used for game control.

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

PY

338

AU

TH

OR

CO

Fig. 4. General target applications and general uses for brain context.

Fig. 5. An overview of the FRIEND brain context awareness agent system. A user of multiple applications has an intermediary
to manage context.

339

PY

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

Fig. 6. FRIEND agents autonomously interface between a user and a system application, as a brain-context management service.

OR

CO

In terms of driving and shared control, there has been successful work on detecting driver’s intention
to brake before actions become observable [30]. Also, in [40], drowsy driving states were detected with
EEG data. Both studies were on driving simulators. Finally, in [16], an architecture is proposed for a
bodynet system for remote monitoring of EEG.
None of these representative approaches make use of hybrid soft-computing-agents for control or
context management with brain data. This work proposes that these kinds of agents are a logical next
step for work on EEG classification and targets this direction. The following section will discuss the
proposed solution in more detail.
4. FRIEND: A unification of concepts towards brain-context in adaptive socio-technical systems

TH

4.1. Overview

AU

The FRIEND (Fuzzy Reactive Intelligent Everyday Neuro-sensing Device) architecture has been outlined in [48] and the architecture overview is seen in Figs 5 and 6. The framework consists of 1) a user, 2)
a mobile EEG headset, 3) a mobile computer, 4) a FRIEND agent, and 5) an application or set of applications. The FRIEND agent performs brain-monitoring of the user in real-time, processing EEG signal
data on a mobile platform, and uses this data to perform inferencing and make human-aware decisions
for external applications. The combination of user state and situation state (obtained from applications
registered with the agent beforehand) allow for the selection of plans which match both situation and
application contexts. Effectively, the agent intermediary sends directives to existing applications that are
already registered with the system. In this way the system as a whole becomes human-aware, without
each application needing to specialize in brain context. Such a hybrid architecture enables the development of future socio-technical software systems that adapt to brain context.
4.2. Users of brain context management systems
Users are considered as having goals (for which they make use of an application) and performing
tasks according to their roles. This information is largely available to existing systems, for instance, at

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

OR

CO

PY

340

TH

Fig. 7. The human-awareness agent cycle showing an individual performing explicit and implicit communication through the
FRIEND architecture. See [48] for more details.

4.3. Mobile EEG headset

AU

design-time a system is coded to handle specific roles via login, and enable certain tasks which may
be performed by someone of that role. However, the state of body and mind of that user are rarely
available to systems at either design or run-time. So users perform tasks and receive feedback from
systems, but those systems cannot adapt to individual mental and physical contexts; the present state of
human-machine interaction.
With the FRIEND medium, however, this is augmented with an agent intermediary to provide context
related commands to systems. Figures 6 and 7 depict this new relationship.

A mobile EEG acquisition device is required and both the Neurosky Mindset [2], and the Emotiv
EPOC [1] are targets for this system. The requirements for selecting a headset are that they be fast,
portable, reliable, noise minimizing, commercially available, and simple to install and program. Both
these headsets fit these requirements, with one key difference. The neurosky headset is a single channel
device, while the other is a multi-channel device (12 channels).

341

CO

PY

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

Fig. 8. The FRIEND architecture monitors incoming passive and explicit inputs, infers state based on signal data, fuzzy rules,
and encoded knowledge models, before updating beliefs and selecting a response action on behalf of the user, depending on the
system’s active goals [48].

AU

4.4. Mobile computing platform

TH

OR

The single channel device will be used for the early settings of cognitive state estimation, providing for
testing and development, (signal processing on a single channel is simpler). Also the device is inexpensive, providing access to features such as attention, meditation, and frequency band signals. However,
the single channel device can only account for activity in the pre-frontal (forehead) region of the brain.
The multi-channel device will be used in later stages of the FRIEND project, where it will be useful
to gain data for more features about the user. Its use of standard 10–20 positioning (coverage of multiple
brain regions) [25] is an advantage, as different states are decipherable across different brain regions
(e.g, prefrontal versus occipital regions when considering attention).

In this work, a sufficiently powerful mobile platform is needed for 1) handling the agent architecture, 2) processing the brain information (and storage where needed), as well as 3) its communication
with other applications needing brain context. Fortunately, the current generation of mobile phones have
increased in processing power, and satisfy these requirements [56]. The Google Android operating system [4], is a target platform that provides a programming framework, for handling these as well. In the
event that the platform is not powerful enough another mobile architecture may be used.
4.5. FRIEND agent: Initial architecture designs
Early work on the methodology for developing human-context-aware agents is seen in the Figs 7, 8
and 9, as taken from [48]. The agent architecture consists of sensors, a BDI interpreter, a neurofuzzy
classifier, and a model of cognitive features as baselines. Using an internal neuro-fuzzy classifier, the

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

TH

OR

CO

PY

342

Fig. 9. The FRIEND architecture scenario expanded to the use of multiple applications [48].

AU

agent is able to obtain and store classified state data as as beliefs about the user state within a standard BDI agent architecture, effectively combining explicit situation information and implicit user state
information. In terms of implementation of the design, existing frameworks will be combined (using
Python as the programming language, and the selected mobile computer platform). Table 1 shows an
early selection of potential components and design tools. It is envisioned that the FRIEND architecture
would prove useful for managing context for a single user of one or more applications, and also for future problems related to the sharing of contextual information between FRIEND agents, across different
users and groups.
4.6. Application set
The FRIEND architecture is aimed towards servicing multiple applications with user brain context.
This is seen in Fig. 9. In particular the applications are 1) Passive Monitoring, 2) Noise-Filtering, and 3)
Shared Control.

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

343

Table 1
The programming tools in consideration for each module. Primarily the Python language is targetted for this work
Tools

EEG signal acquisition
EEG signal processing
BDI agent
BDI agent language
Soft-computing (Neurofuzzy)
Middleware communication
Cognitive state gauges
Mobile platform code
Application 1: Passive monitoring
Application 2: Noise filtering
Application 3: Shared control

Neurosky/Emotiv EPOC
Python PyEEG, NumPy, SciPy libraries
AgentFactory, with JPython support
AgentSpeak via AgentFactory
Peach (Python)
AgentScape/Spade (Python)
Peach (Python soft-computing)
Google android (SL4A-Python environment)
Custom app (Python)
Browser app (Python)
Second life app (Mixed)

PY

Task module

CO

4.6.1. Application 1: Passive-monitoring
This approach considers the FRIEND agent as a passive monitor tool for a manager of a team, such
as a hospital nursing officer who must be aware of the state of her workers. It simply alerts whenever
an individual (wearing a FRIEND agent) has a cognitive load level below a certain threshold. Such an
application would be useful in practical situations to detect stress/load levels of employees, for instance.
In this work, of course, the focus is more on the usefulness of the general agent than on the cognitive
load metric.

OR

4.6.2. Application 2: Noise-filtering
The Noise Filtering application is a general one that removes interface features (such as text sizes,
or active windows), based on cognitive load. It has the job of either filtering information away from
the screen if too noisy, i.e., the user is overloaded, as well as adding more information if the user is
disengaged. This application represents a simple use of brain context that is also extensible to more
important situations where concentration is crucial, such as driving on a highway.

AU

TH

4.6.3. Application 3: Shared-control
The Shared-control application makes use of brain context (cognitive load) to determine when to
take over an object from the user. This is a relevant area of research in driving applications, where an
intelligent vehicle can take over if its user is in a drowsy state, or is not paying attention to task, or is
in an overloaded state. It is similar to the second application in this respect, but has the added condition
that the device must return functionality to the user in an unobtrusive fashion. As such devices are
not available this application will be simulated through the use of virtual software objects, such as in
Second-Life [65], where in-world objects can be scripted. This has already been evidenced in [58], for
interacting with Jason agents.
5. Conclusion
Agents for brain-monitoring are on the horizon, and the advancement of technologies makes this research timely. The use of the agent paradigm as a robust framework for autonomous control based on
dynamic brain-context information is worthwhile for many situations. This technique aims at minimizing
failures in systems due to human-factor issues by improving and streamlining technologies to social context. This fosters improved adaptability in systems, effectively becoming human-context-aware systems

344

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

(specifically brain-context-management systems). This proposed work contributes to the development of
such systems by outlining the central motivations, literature, and a path towards such systems, presenting an early architecture design (FRIEND) and proposed experimental applications. Future work will
advance with implementations of these designs, and experimental applications of high-functioning, and
practical brain-monitoring agent assistants.
References

[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]
[24]

PY

CO

[8]

OR

[7]

TH

[6]

Emotiv epoc, http://www.emotiv.com/.
Neurosky mindset, http://www.neurosky.com/.
Eu guardian angels project, guardian angels for a smarter life, downloaded from http://www.ga-project.eu/, 2011.
Google android operating system, http://www.android.com/, 2011.
G. Abowd, A. Dey, P. Brown, N. Davies, M. Smith and P. Steggles, Towards a better understanding of context and
context-awareness, in: Handheld and Ubiquitous Computing, Springer, 1999, pp. 304–307.
F. Aiello, G. Fortino, R. Gravina and A. Guerrieri, A java-based agent platform for programming wireless sensor networks, The Computer Journal 54(3) (2011), 439.
B. Allison, Toward ubiquitous bci’s, Brain-Computer Interfaces: Revolutionizing Human-Computer Interaction, The
Frontiers Collection, ISBN 978-3-642-02090-2, Springer-Verlag Berlin Heidelberg, 2010, pp. 357–387.
C. Anagnostopoulos and S. Hadjiefthymiades, Advanced fuzzy inference engines in situation aware computing, Fuzzy
Sets and Systems 161(4) (2010), 498–521.
W. Anderson, G. Preston, C. Silva et al., Using python for signal processing and visualization, Computing in Science and
Engineering 12(4) (2010), 90–95.
G. Baxter and I. Sommerville, Socio-technical systems: From design methods to systems engineering, Submitted to The
Journal of Human-Computer Studies, 2008.
C. Bettini, O. Brdiczka, K. Henricksen, J. Indulska, D. Nicklas, A. Ranganathan and D. Riboni, A survey of context
modelling and reasoning techniques, Pervasive and Mobile Computing 6(2) (2010), 161–180.
R. Bordini, J. Hübner and M. Wooldridge, Programming multi-agent systems in AgentSpeak using Jason, vol. 8, WileyInterscience, 2008.
A. Bouchachia, Fuzzy classification in dynamic environments, Soft Computing-A Fusion of Foundations, Methodologies
and Applications 15(5) (2011), 1009–1022.
E. Broek, V. Lisỳ, J. Janssen, J. Westerink, M. Schut and K. Tuinenbreijer, Affective man-machine interface: Unveiling
human emotions through biosignals, Biomedical Engineering Systems and Technologies (2010), 21–47.
J. Bryson, Cross-paradigm analysis of autonomous agent architecture, Journal of Experimental and Theoretical Artificial
Intelligence 12(2) (2000), 165–190.
H. Chen, W. Wu and J. Lee, A wban-based real-time electroencephalogram monitoring system: Design and implementation, Journal of Medical Systems 34(3) (2010), 303–311.
W. Clancey, P. Sachs, M. Sierhuis and R. Van Hoof, Brahms: Simulating practice for work systems design, International
Journal of Human Computer Studies 49(6) (1998), 831–866.
U. Corrêa, F. Vasques, J. Hübner and C. Montez, Using bdi-agents with coordination without communication to increase
lifetime, preserving autonomy and flexibility in wireless sensor networks, Agent and Multi-Agent Systems: Technologies
and Applications (2010), 243–252.
E. Cutrell and D. Tan, BCI for passive input in HCI, in: ACM CHI, vol. 8, Citeseer, 2008, pp. 1–3. http://citeseerx.ist.
psu.edu/viewdoc/download?doi=10.1.1.160.3241.
A. Dey, D. Salber, G. Abowd and M. Futakawa, The conference assistant: Combining context-awareness with wearable
computing, in: Wearable Computers, Digest of Papers, The Third International Symposium on, IEEE, 1999, pp. 21–28.
D. Erdogmus, A. Adami, M. Pavel, T. Lan, S. Mathan, S. Whitlow and M. Dorneich, Cognitive state estimation based
on eeg for augmented cognition, in: Neural Engineering, 2005, Conference Proceedings, 2nd International IEEE EMBS
Conference on, IEEE, 2005, pp. 566–569.
P. Ferrez, Error-related eeg potentials generated during simulated brain–computer interaction, Biomedical Engineering,
IEEE Transactions on 55(3) (2008), 923–929.
H. Gellersen, A. Schmidt and M. Beigl, Multi-sensor context-awareness in mobile devices and smart artifacts, Mobile
Networks and Applications 7(5) (2002), 341–351.
A. Girouard, E. Solovey, R. Mandryk, D. Tan, L. Nacke and R. Jacob, Brain, body and bytes: Psychophysiological
user interaction, in: Proceedings of the 28th of the International Conference Extended Abstracts on Human Factors in
Computing Systems, ACM, 2010, pp. 4433–4436.

AU

[1]
[2]
[3]
[4]
[5]

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

[30]
[31]
[32]
[33]
[34]
[35]
[36]
[37]
[38]
[39]
[40]
[41]
[42]
[43]
[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]

PY

[29]

CO

[28]

OR

[27]

TH

[26]

B. Graimann, B. Allison and G. Pfurtscheller, Brain–computer interfaces: A gentle introduction, Brain-Computer Interfaces: Revolutionizing Human-Computer Interaction, The Frontiers Collection, ISBN 978-3-642-02090-2, SpringerVerlag Berlin Heidelberg, 2010, pp. 1–27.
B. Graimann, G. Pfurtscheller and B. Allison, Brain-Computer Interfaces: Revolutionizing Human-Computer Interaction, The Frontiers Collection, ISBN 978-3-642-02090-2, Springer-Verlag Berlin Heidelberg, 2010, p. 1.
D. Grimes, D. Tan, S. Hudson, P. Shenoy and R. Rao, Feasibility and pragmatics of classifying working memory load
with an electroencephalograph, in: Proceeding of the Twenty-sixth Annual SIGCHI Conference on Human Factors in
Computing Systems, ACM, 2008, pp. 835–844.
C. Guger and G. Edlinger, The first commercial brain–computer interface environment, Brain-Computer Interfaces:
Revolutionizing Human-Computer Interaction, 2010, pp. 281–303.
L. Hai-Bo, G. Guo-Chang, S. Jing and F. Yan, Auv fuzzy neural bdi, Journal of Marine Science and Application 4(3)
(2005), 37–41.
S. Haufe, M. Treder, M. Gugler, M. Sagebaum, G. Curio and B. Blankertz, Eeg potentials predict upcoming emergency
brakings during simulated driving, Journal of Neural Engineering 8 (2011), 056001.
C. Hema, M. Paulraj, R. Nagarajan, S. Yaacob and A. Adom, Fuzzy based classification of eeg mental tasks for a
brain machine interface, Intelligent Information Hiding and Multimedia Signal Processing, 2007, IIHMSP 2007, Third
International Conference on (2007), 53–56.
J. Hong, E. Suh and S. Kim, Context-aware systems: A literature review and classification, Expert Systems with Applications 36(4) (2009), 8509–8522.
D. Jiang and J. Yin, A realtime brain-computer interface based on pda, in: Industrial Mechatronics and Automation
(ICIMA), 2010 2nd International Conference on, vol. 1, IEEE, 2010, pp. 188–192.
M. John, D. Kobus, J. Morrison and D. Schmorrow, Overview of the darpa augmented cognition technical integration
experiment, International Journal of Human-Computer Interaction 17(2) (2004), 131–149.
M. Johnson, K. Kulkarni, A. Raj, R. Carff and J. Bradshaw, Ami: An adaptive multi-agent framework for augmented
cognition, in: Proceedings of the 11th International Conference in Human Computer Interaction, AUGCOG Conference
(2005), 22–27.
J. Kephart and D. Chess, The vision of autonomic computing, Computer 36(1) (2003), 41–50.
R. Laza, R. Pavón and J. Corchado, A reasoning model for cbr_bdi agents using an adaptable fuzzy inference system,
Current Topics in Artificial Intelligence (2004), 96–106.
J. Lee and D. Tan, Using a low-cost electroencephalograph for task classification in hci research, in: Proceedings of the
19th Annual ACM Symposium on User Interface Software and Technology, ACM, 2006, 81–90.
N. Leveson, M. Daouk, N. Dulac and K. Marais, Applying STAMP in accident analysis, in: NASA Conference Publication, NASA, 2003, pp. 177–198.
M. Li, C. Zhang and J. Yang, An eeg-based method for detecting drowsy driving state, in: Fuzzy Systems and Knowledge
Discovery (FSKD), Seventh International Conference on, vol. 5, IEEE, 2010, pp. 2164–2167.
Y. Li, K. Ang and C. Guan, Digital signal processing and machine learning, Brain-Computer Interfaces: Revolutionizing
Human-Computer Interaction (2010), pp. 305–330.
H. Lieberman and T. Selker, Out of context: Computer systems that adapt to, and learn from, context, IBM Systems
Journal 39(3.4) (2000), 617–632.
P. Lokuge and D. Alahakoon, Hybrid bdi agents with improved learning capabilities for adaptive planning in a container
terminal application, in: Intelligent Agent Technology, 2004, (IAT 2004), Proceedings, IEEE/WIC/ACM International
Conference on, IEEE, 2004, pp. 120–126.
R. Mayrhofer, An architecture for context prediction, Citeseer (2005), http://citeseerx.ist.psu.edu/viewdoc/download?
doi=10.1.1.1.7379&amp;rep=rep1&amp;type=pdf.
P. Melin and O. Castillo, Hybrid intelligent systems for pattern recognition using soft computing: An evolutionary approach for neural networks and fuzzy systems, vol. 172, Springer Verlag, 2005.
A. Morris, P. Giorgini and S. Abdel-Naby, Simulating bdi-based wireless sensor networks, in: Proceedings of the 2009
IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology-Volume 02, IEEE
Computer Society, 2009, pp. 78–81.
A. Morris, W. Ross and M. Ulieru, Modelling culture in multi-agent organizations, AMPLE Workshop Proceedings, Tenth
International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), Taiwan, 2–6 May 2011.
A. Morris and M. Ulieru, FRIEND: A human-aware BDI agent architecture, in: Systems Man and Cybernetics (SMC),
2011 IEEE International Conference on, IEEE, 2011.
C. Muldoon, G. OHare, R. Collier and M. OGrady, Towards pervasive intelligence: Reflections on the evolution of the
agent factory framework, Multi-Agent Programming (2009), 187–212.
C. Muldoon, R. Tynan, G. Hare and M. Grady, Agent-based coordination for the sensor web, in: Proceedings of the 2010
ACM Symposium on Applied Computing, ACM, 2010, 2019–2023.
M. Neef, P. van Maanen, P. Petiet and M. Spoelstra, Adaptive work-centered and human-aware support agents for aug-

AU

[25]

345

346

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems

AU

TH

OR

CO

PY

mented cognition in tactical environments, Foundations of Augmented Cognition, Neuroergonomics and Operational
Neuroscience (2009), 68–77.
[52] J. ODoherty, M. Lebedev, P. Ifft, K. Zhuang, S. Shokur, H. Bleuler and M. Nicolelis, Active tactile exploration using a
brain-machine-brain interface, Nature (2011).
[53] G. O’Hare, Agent factory: An environment for the fabrication of multi-agent systems, vol. 19, John Wiley and Sons, Inc.,
New York, 1996.
[54] M. Pantic, A. Pentland, A. Nijholt and T. Huang, Human computing and machine understanding of human behavior: A
survey, in: Proceedings of the 8th International Conference on Multimodal Interfaces, ACM, 2006, pp. 239–248.
[55] E. Peck, E. Solovey, K. Chauncey, A. Sassaroli, S. Fantini, R. Jacob, A. Girouard and L. Hirshfield, Your brain, your
computer, and you, Computer 43(12) (2010), 86–89.
[56] M. Petersen, C. Stahlhut, A. Stopczynski, J. Larsen and L. Hansen, Smartphones get emotional: Mind reading images
and reconstructing the neural sources, Affective Computing and Intelligent Interaction (2011), 578–587.
[57] J.R. Millan and J. Carmena, Invasive or noninvasive: Understanding brain-machine interface technology [conversations
in bme], Engineering in Medicine and Biology Magazine, IEEE 29(1) (2010), 16–22.
[58] S. Ranathunga, S. Cranefield and M. Purvis, Interfacing a cognitive agent platform with second life, Proceedings of the
2011 International Conference on Agents for Educational Games and Simulations Springer-Verlag, (2011), 1–21.
[59] A. Rao, AgentSpeak (L): BDI agents speak out in a logical computable language, Agents Breaking Away (1996), 42–55.
[60] A. Rao and M. Georgeff, BDI agents: From theory to practice, in: Proceedings of the First International Conference on
Multi-agent Systems (ICMAS-95), San Francisco, CA, 1995, pp. 312–319.
[61] L. Reeves, D. Schmorrow and K. Stanney, Augmented cognition and cognitive state assessment technology–near-term,
mid-term, and long-term research objectives, Foundations of Augmented Cognition (2007), 220–228.
[62] L. Reeves and D. Schmorrow, Augmented cognition foundations and future directions: Enabling anyone, anytime, anywhere applications, in: Proceedings of the 4th International Conference on Universal Access in Human Computer Interaction: Coping with Diversity, Springer-Verlag, 2007, pp. 263–272.
[63] G. Resconi and B. Kovalerchuk, Agents model of uncertainty, Knowledge and Information Systems 18(2) (2009), 213–
229.
[64] S. Russell, H. Jordan, G. OHare and R. Collier, Agent factory: A framework for prototyping logic-based aop languages,
Multiagent System Technologies (2011), 125–136.
[65] M. Rymaszewski, W. Au and M. Wallace, Second life: The official guide, Sybex (2007).
[66] A. Schlögl, C. Vidaurre and K. Müller, Adaptive methods in bci research-an introductory tutorial, Brain-Computer
Interfaces: Revolutionizing Human-Computer Interaction (2010), 331–355.
[67] D. Schmorrow, Foundations of augmented cognition, vol. 11, CRC, 2005.
[68] D. Schmorrow and C. Fidopiastis, Foundations of augmented cognition, in: Directing the Future of Adaptive Systems: 6th
International Conference, FAC 2011, vol. 6780, Held as Part of HCI International 2011, Orlando, FL, USA, Proceedings,
Springer, 9–14 July 2011.
[69] S. Shen, G. O’Hare and R. Collier, Decision-making of bdi agents, a fuzzy approach, in: Computer and Information
Technology, 2004, CIT’04, The Fourth International Conference on, IEEE, 2004, pp. 1022–1027.
[70] A. Shukla, R. Tiwari and R. Kala, Hybridizing neural and fuzzy systems (chapter 15), Towards Hybrid and Adaptive
Computing (2010), 337–359.
[71] A. Shukla, R. Tiwari and R. Kala, Towards hybrid and adaptive computing: A perspective, vol. 307, Springer Verlag,
2010.
[72] M. Sierhuis, J. Bradshaw, A. Acquisti, R. van Hoof, R. Jeffers and A. Uszok, Human-agent teamwork and adjustable
autonomy in practice, in: Proceedings of the Seventh International Symposium on Artificial Intelligence, Robotics and
Automation in Space (i-SAIRAS), 2003.
[73] E. Solovey, A. Girouard, K. Chauncey, L. Hirshfield, A. Sassaroli, F. Zheng, S. Fantini and R. Jacob, Using fNIRS brain
sensing in realistic HCI settings: Experiments and guidelines, in: Proceedings of the 22nd Annual ACM Symposium
on User Interface Software and Technology, ACM, 2009, pp. 157–166, http://portal.acm.org/citation.cfm?id=1622176.
1622207.
[74] E. Solovey, F. Lalooses, K. Chauncey, D. Weaver, M. Parasi, M. Scheutz, A. Sassaroli, S. Fantini, P. Schermerhorn, A.
Girouard et al., Sensing cognitive multitasking for a brain-based adaptive user interface, in: Proceedings of the 2011
Annual Conference on Human Factors in Computing Systems, ACM, 2011, pp. 383–392.
[75] K. Vicente, The human factor: Revolutionizing the way people live with technology, Routledge (2004).
[76] K. Wac and A.K. Dey, EmoBAN: Improving quality of life via psychophysiological mobile computing (position paper),
Interfaces (2010).
[77] J. Wolpaw and C. Boulay, Brain signals for brain–computer interfaces, Brain-Computer Interfaces: Revolutionizing
Human-Computer Interaction (2010), 29–46.
[78] M. Wooldridge and N. Jennings, Intelligent agents: Theory and practice, Knowledge Engineering Review 10(2) (1995),
115–152.

A. Morris and M. Ulieru / FRIENDs: Brain-monitoring agents for adaptive socio-technical systems
[79]
[80]

347

G. Yang, Body sensor networks, Springer-Verlag, New York Inc, 2006.
Y. Zhang and F. Li, A model of context awareness agent system based on dynamic fuzzy logic, in: Proceedings of the
Fourth International Conference on Fuzzy Systems and Knowledge Discovery-Volume 01, IEEE Computer Society, 2007,
pp. 555–561.

Authors’ Bios

AU

TH

OR

CO

PY

Professor Mihaela Ulieru is a seasoned expert in ICT-enabled innovation and President of the IMPACT Institute for the Digital Economy, aiming to capitalize on her achievements as the Canada Research Chair in Adaptive Information Infrastructures for the eSociety which she held for five years since
July 2005. Along her over 25 years career Professor Ulieru led several large scale projects targeting
the management of complex situations through more organic ways of governance, attacking very challenging problems from original perspectives which require a high level of interdisciplinarity. Among the
highlights her large scale international collaborative projects aiming to make ICTs an integral component of policy making for a healthier, safer, more sustainable, and innovation-driven world are: Future
of Medicine, Living Technologies and Emulating the Mind. In 2007 she was appointed to the Science,
Technology and Innovation Council of Canada by the Minister of Industry, to advise the government and
provide foresight on innovation issues related to the ICT impact on Canada’s economic development and
social well-being against international standards of excellence. In 2006 she was appointed to the Science
and Engineering Research Council of Singapore, and in 2010 she was appointed Expert in ICT-Enabled
Innovation at the Executive Authority for Scientific Research and Innovation of Romania, and as Adjunct Research Professor at Carleton University, in Ottawa. Frequent invited speaker at most prestigious
venues, Professor Ulieru was on the Governing Board of IEEE-IES and on the Scientific Board of several
EC Networks of Excellence in the Future and Emerging Technologies ICT Directorate. As a tenured professor at the University of New Brunswick (2005–2012) she founded the Adaptive Risk Management
Laboratory with Canada Foundation for Innovation sponsorship, and led multi-million dollar projects
with NSERC, CANARIE and DRDC.
Alexis Morris is a PhD. Candidate in computer science at the University of New Brunswick (Canada),
specializing in human-context-aware software systems through the merger of brain-computer interfaces
and agent architectures. He is also a research assistant at the Adaptive Risk Management Lab (ARMLab),
led by his supervisor, Dr. Mihaela Ulieru. He has been involved in multiple research initiatives including
the modelling and simulation of socio-technical systems, human factors, organizational culture as a
complex system, and agent-oriented approaches to wireless sensor networks. He holds a joint European
Master of Informatics degree from the University of Edinburgh (UK) and the University of Trento (Italy),
a Bachelor’s degree in Computer Science from Acadia University (Canada), and an Associates degree
in Accounting from the College of the Bahamas.

