EVALUATION OF VARIOUS STRATEGIES TO IMPROVE THE TRAINING
OF A BRAIN COMPUTER INTERFACE SYSTEM
Luis D. Jiménez1, Alejandro Velásquez2, Helmuth Trefftz3
1, 2. Product Design Engineering Research Group, 3. Virtual Reality Research Lab
Universidad EAFIT
Medellín, Colombia
ljimen19@eafit.edu.co, avelasq9@eafit.edu.co, htrefftz@eafit.edu.co
ABSTRACT
Brain-computer interfaces (BCI) allow for communication
between the human brain and computers. They have been
used to create systems able to generate control over a
software or mechatronic device, becoming an important
tool for the rehabilitation of handicapped people,
especially for patients with quadriplegia. Due to the
importance of BCIs, any attempt to improve their
response has a great value. The work described in this
paper consists of the evaluation of various stimuli applied
to improve the training of a BCI based system. The device
is the Emotiv® EPOC which includes a Software
Development Kit (SDK) to train the system. During the
usual training of the SDK; images, videos, thoughts,
movements and gestures were used as stimuli to improve
the users’ skills for accomplishing specific actions. After
the evaluation of these stimuli, they were ranked
according to their effectiveness. Finally, a powered
wheelchair was controlled using the Emotiv® EPOC by
applying the best-ranked stimulus and an assessment
protocol was used in order to evaluate the performance of
users driving the wheelchair with the BCI, with
satisfactory results.
KEY WORDS
Brain-computer interfaces, Emotiv®, Sense stimulation,
Powered wheelchairs, Human-computer interfaces, Brainmachine interface, Skill rating, Brain signals.

1. Introduction
Brain-Computer Interfaces (BCIs) are devices that are
able to read the human brain electric signals and translate
them into control signals for a computer [1]. One of the
most important uses of BCIs is their application for the
rehabilitation of handicapped patients.
According to the World Health Organization, in 2010
around 15% of world’s population lives with some form
of disabilities, which means there were over 1 billion
persons in this difficult situation [2]. In United States, for
instance, approximately 265.000 persons had spinal cord
injury (SCI) and nearly 55% of the people registered with
disabilities suffered some form of tetraplegia [3].
Thanks
to
technological
and
neurological
developments, new possibilities arise of improving the

condition of handicapped people. In particular, the
emergence of more efficient BCIs, allow for the
development of diverse systems to improve the mobility,
communication, comfort and lifestyle of quadriplegic
patients.
Due to the importance of the BCIs for the
rehabilitation of patients with severe handicaps, any
attempt to improve the response of these systems and
reduce the efforts to successfully use them has a great
value.

2. Related Work
Research on applications for BCIs to control different
kinds of systems is increasing. Among the works
developed with a BCI, the following can be found:
• Bin et al. [4], report the creation of a high-speed
word spelling system based on a BCI, which allows
users to choose a character from a matrix in a
monitor by the use of a binary code. By this way, the
user is able to complete entire words with a speed of
15-20 characters per minute.
• BCIs were used as a feedback by Ang et al. [5] to
facilitate the rehabilitation of stroke patients. By the
use of this method, the achieved results were
comparable with those obtained by the use of a robot
for the rehabilitation.
• A system based on a BCI which allows the patient to
paint by the use of a matrix, similar to the spelling
matrix used in [4], was created by George et al. [6].
Their system contains various tools allowing the
user to draw.
• The use of a BCI to recognize the thoughts and
therefore determine the word that a person is
thinking about when a recorded image is shown was
reported by Palatucci et al. [7].
• Szafir and Signorile [8] successfully controlled a
Parallax Scribbler Robot using a BCI.
• Khar et al. [9] report accomplishing the control of a
powered wheelchair using a BCI based system using
Wavelet Packet Transform (WPT) and Radial Basis
Function neural networks.

• Galan et al. [10] controlled a virtual wheelchair
using a BCI in which the patient has to follow a
specific route in a graphic environment
environment.
• More recent advances include the control of a
robotic prosthesis with seven degrees of freedom
freedom, as
reported by Collinger et al. [11], by the use of a
Brain-Machine
Machine Interface (BMI), which is similar to a
BCI but having the signals from the brain received
directly by a machine instead of thee computer
computer.
ther kind of works have been develop
developed in order
Another
to improve the response of the BCI-based
based system
systems, as
those reported by Choi et al. [12] who combined some
audio-visual cues so as to improve the training of aan
electroencephalogram (EEG)-BCI
BCI based system; and the
one presented by Jin et al. [13] where some visual
strategies were applied in order to increase the accuracy
and diminish the calibration time for event-related
potential (ERP)-based BCIs.
BCIs, along
This wide range of applications with BC
with the efforts to improve the response of such systems,
demonstrate the importance of the BCIs in the scientific
world and specifically in the field of the rehabilitation for
severely handicapped patients. Still many fields are
currently objects of active research such as sensors, signal
acquisition, user´s comfort, data processing, electr
electrode
positioning, among others; in order to improve the
response and reliability of BCIs. This paper focuses
mainly on the evaluation of different stimu
stimuli and its
effectiveness within a state of the art BCI. Similar work
can be found in [1] where the steady state visual evoke
evoked
potential (SSVEP) is evaluated as feedback to determine
the mental state of a user.

3. Our Proposal
st stage of the work reported in this paper, the use
In the first
a BCI to control a mechatronic device was tested as a first
approach to create a system that could help handicapped
people, particularly tetraplegic patients.
The selected BCI was the Emotiv® EPOC and the
mechatronic device was built with a LEGO
LEGO® Mindstorm
kit. To reach our
ur purpose, we used the available APIs
(Application Programming Interface) supplied by
Emotiv® to extract the signals from the SDK and later,
these signals were sent via Bluetooth
tooth to the mechatronic
device in order to control it in different directions
(forward, backward, left turn and right turn).
After following the instructions given by the
Emotiv® SDK user manual [14] to train the system with
the Cognitive Suite (CS), which is the detection suite that
recognizes the user’s conscious thoughts [14
[14], we tried to
control the mechatronic device but it didn’t respond
according to the user’s will most of the times
times.
Due to these poor results, we implemented some
strategies to improve the correspondence between the

user’s will and the actions executed by the mechatronic
device using the Cognitive Suite of the SDK.
The strategies consisted of exposing the user to
stimuli in order to get more consistent brain signals. Thus
the signals could be easier to identify by the SDK, and
could lead to more accurate instructions for the
mechatronic device.
The proposed strategies to train the SDK with the
Cognitive Suite were:
• Use of thoughts: according to the Emotiv® SDK
user manual, the training
ining has to be made via the
thoughts, i.e.,, trying to move a 3D virtual cube
within
in a graphical environment as if the user had
“superpowers”.
• Use of images: based on the theory that familiar
images can produce variations in the electrical
signals of the brain,, proposed by Gorman [15],
images related to the action being trained were used.
In this way, for instance,, while
wh
training the lift
action, three arrows pointing up,
up were used (Fig. 1).
A variation of this stimulus was the use of 3D
images obtained by stereogram (Fig. 2); with this
stimulus the intention was to keep the focus on the
image in order to get more consistent brain signals;
signals
since it requires the user to focus her sight on the
image without any movement. The results obtained
with flat images and stereograms were similar, thus
they are presented together in results.

brain
Fig. 1. Arrows (flat image) used to stimulate the brain.

(
from
Fig. 2.. Stereogram used to keep the focus (taken
www.magiceye.com on December 27th 2012).
• Use of videos: moving images were used in the
direction of the action being trained. For example, if
the action to be trained was Left, then we used
arrows moving towards the left. This same stimulus
is used by the SDK if the option of move cube
according to training action is active.
• Use of movements:: the use of physical movements to
stimulate the brain was used
us
also. In particular,

movements of the hand were chosen, due to its
electrical activity, according to Cardona [16]. This
kind of stimulus was applied in different ways.
Dynamic movements were used, on which the user
kept moving a limb following certain patterns. Static
tension, on which the user applied force
continuously over a particular limb, was also used.
Furthermore, unilateral movements and bilateral
movements were used. The results obtained with all
the trials with movements were similar, so they are
together in the results.
• Use of gestures: Although the Emotiv® SDK user
manual in the part of CS reads explicitly otherwise,
we tried to train the system with gestures, due to the
fact that facial expressions have high electrical
activity in the outer layer of the head [16], and the
Emotiv® EPOC uses the electric signals of the
cortical layer, that is the more superficial layer of the
brain.
• Use of smells: The sense of smell is directly
processed by the deep limbic system of the brain,
according to Amen [17], the same place in the brain
where the remembrances are processed. Since the
Emotiv® works with superficial signals, it was
decided not to use this stimulus.

his/her time availability. The trained actions were used to
control the mechatronic device.
From the four possible actions, only three were
tested. Each added action is more difficult to train than the
previous ones, as reported by Emotiv® [14]. This means
that it is expected for the first action to obtain better
results than the second one, and the second action better
than the third one.
The strategies mentioned above were tested with 12
different healthy users from 20 to 35 years old of both
genders. Each stimulus was evaluated with at least 4 users
in the first action and with at least 3 users in the second
action.
In order to evaluate the different stimuli, important
information about the trials was recorded, such as the
maximum Skill Rating (SR), number of trials required to
reach at least 75% of SR, number of users that didn’t
reach at least 75% of SR, among others.
The results of the different stimuli are presented
using graphs and adding a sixth order polynomial
tendency line which is darker than the raw data. A graphic
of the average results is also shown to understand the
general behavior of each stimulus.

The bar of Skill Rating (SR), present in the SDK, was
used as indication to evaluate all the stimuli applied when
trying to improve the correspondence between the
intention of movement produced by the brain and the
action executed by the device. The SR bar provides a
measure of how consistently the user can mentally
perform the intended action [14].

Following, the graphics with the results obtained by the
training of a single action using the BCI with the
Cognitive Suite are presented. The results are based on
the application of the suggested stimuli and intend to
demonstrate the different responses for each stimulus.

In order to get enough and good sensitive results, the
SR bar was read every two trials until either reaching 50
trials, or until observing that the user reached a good level
of training.
After the evaluation of the different stimuli, a
powered wheelchair was controlled using the BCI with
the stimulus that obtained the best results. In order to
control the wheelchair, the joystick was replaced by the
commands interpreted by BCI-based software. The ability
of a user to drive the wheelchair using the BCI was
evaluated by the application of the Power-Mobility Indoor
Driving Assessment (PIDA), proposed by Dawson et al.
[18]. This evaluation gave us a score of the controllability
of the wheelchair with the BCI, which is shown in section
4.3.

4.1 Graphical Results

Fig. 3. Results using the Cognitive Suite with Thoughts.

4. Results
The SDK allows for the training of up to four different
actions for each user when the CS is used. The actions to
be trained were chosen by each user (according to his/her
will) between a list of 13 possible actions such as push,
pull, lift, left and right, among others. In our case, users
chose either one, two or three actions, depending on

Fig. 4. Results using the Cognitive Suite with Videos.

Fig. 5. Results using the Cognitive Suite with Images.

Fig. 6. Results using the Cognitive Suite with body
Movements.

From the previous graphic representation of the
results, it is possible to conclude that the average
behaviours across the stimuli are different, especially in
the peak value and in the initial upslope, which suggests
that some stimuli are better than others. The best stimulus
could be used to improve the level of the training and the
correspondence between the user’s will and the system´s
response. According to the results presented in Fig. 8,
Gestures stimuli had a superior average behaviour,
whereas Thoughts stimuli present the worse results with
the Cognitive Suite.
It can also be observed, from most of the figures, that
the response of the users to the same stimulus varies
widely, implying that the response of applying a specific
stimulus depends on each particular user. The graphic
with the most similar behaviour across the users was
Gestures (Fig. 7).
Another important observation is the fluctuating
behavior of almost all the curves, showing periods of
focus and lack of it. According to this, a period of focus is
followed by a period of lack of focus, but later the focus is
recovered. The periods of focus and lack of focus are
almost similar in duration in the most of the cases.
Although not shown explicitly in the previous
graphics, the results also showed that users do not respond
in the same way to different stimuli. Some stimuli could
improve the results while some could worsen it. The
clearest case is user 11, a healthy 20 year old male user
with a thin build, abundant straight hair and an
Engineering degree, who had outstanding results with the
Images stimulus but poor results with Videos, which can
be seen in Fig. 9.

Fig. 7. Results using the Cognitive Suite with Gestures.

Fig. 9. Results of user 11 with Images and Videos using
the Cognitive Suite.

4.2 Statistical Results
To generate a point of comparison between the
different stimuli, relevant information about the results of
the users training three actions is presented next. Table 1,
Table 2 and Table 3 show some statistics about the
different stimuli in each trained action.
Fig. 8. Average results of each stimulus using the
Cognitive Suite.

Table 1. Training of first action using different stimuli
with the Cognitive Suite.
First action
Indicator
Min. Trials to Reach 75% SR
Max. Trials to Reach 75% SR
Avg. Trials to Reach 75% SR
% Users not Reaching 75% SR
Max. SR reached
Trials to reach Max. SR
Avg. Max. SR
Avg. Trials to reach Max. SR
Max. Trials to reach Max. SR
Users

Stimulus
Thg. Vid. Img. Mov. Gest.
4
6
4
4
4
110 12
30
16
8
27
9
13
8
6
17% 25% 0%
0%
0%
100 100 100 100 100
10
16
4
12
10
89
82
95
96
100
71
46
19
21
22
172 116 30
34
26
6
4
4
5
5

Table 2. Training of second action using different stimuli
with the Cognitive Suite.
Second action
Stimulus
Thg. Vid. Img. Mov.
Min. Trials to Reach 75% SR
N.R. N.R. N.R.
N.R.
Max. Trials to Reach 75% SR
N.R. N.R. N.R.
N.R.
Avg. Trials to Reach 75% SR
N.R. N.R. N.R.
N.R.
% Users not Reaching 75% SR 100% 100% 100% 100%
Max. SR reached
53
25
35
36
Trials to reach Max. SR
4
2
8
22
Avg. Max. SR
30
16
17
13
Avg. Trials to reach Max. SR
47
4
6
10
Max. Trials to reach Max. SR
136
6
8
22
Users
6
4
4
3
Indicator

Gest.
6
32
12
0%
100
14
95
33
64
5

The third action was evaluated only with Gestures
due to the fact that the other stimuli didn´t reach the 75%
of SR in the second action, and the next action (the third
action in this case) is more difficult than the previous one
as it was indicated previously.
It’s not explicit in the tables but the graphics show it
slightly; more than 73% of the maximum SRs were
reached in the first 30 trials and nearly 85% in the first 50
trials. This suggested that training with more than 50 trials
could be a waste of time and an overtraining which could
decrease the accuracy, as reported by Emotiv® [14].
In order to facilitate the comparison between the
stimuli and rank them, we extracted the most
representative indicators such as the average number of
trials required to reach 75% of SR in the first action,
average of the maximum SR reached in the first action,
average of the maximum SR reached in the second action
and the percentage of users that couldn´t reach a 75% SR.;
and graph them as follows.

Fig. 10. Average number of trails to reach 75% of SR in
first action.

N.R: Not reached
Table 3. Training of third action using different stimuli
with the Cognitive Suite
Third action
Indicator

Stimulus
Thg. Vid. Img. Mov. Gest.

Min. Trials to Reach 75% SR

N.A. N.A. N.A.

N.A.

8

Max. Trials to Reach 75% SR

N.A. N.A. N.A.

N.A.

30

Avg. Trials to Reach 75% SR

N.A. N.A. N.A.

N.A.

16

% Users not Reaching 75% SR N.A. N.A. N.A.

N.A.

0%

Max. SR reached

N.A. N.A. N.A.

N.A.

96

Trials to reach Max. SR

N.A. N.A. N.A.

N.A.

26

Avg. Max. SR

N.A. N.A. N.A.

N.A.

91

Avg. Trials to reach Max. SR

N.A. N.A. N.A.

N.A.

32

Max. Trials to reach Max. SR

N.A. N.A. N.A.

N.A.

32

Users

N.A. N.A. N.A.

N.A.

3

Fig. 11. Average maximum SR in first action.

N.A: Not applied
According to Tables 1, 2 and 3, the only stimulus that
obtained good results in the second action and third
action was Gestures, while the other stimuli didn’t reach
the 75% of SR either in the second action or in the third
action. Obtaining good results with Gestures using the
Cognitive Suite demonstrates that the trials were done in
the correct way.

Fig. 12. Average maximum SR in second action.

circuit managed by a microcontroller was modified, so
that each of the 3 actions was converted into a
correspondent order for the wheelchair. Given that only 3
actions could be performed, as concluded in the previous
sections, combinations of these actions were used to
generate the necessary movements to control the
wheelchair. The equivalence between the 3 actions and
the instructions to the wheelchair is shown in Table 6.

Fig. 13. Percentage of users that didn't reach the 75% SR.
These comparative bar diagrams allowed a visual
evaluation of every stimulus in order to score each one in
each figure from 1 to 5, 5 being the maximum score. The
evaluations were collected in Table 4.
Table 4. Comparative evaluation of each stimulus based
on statistics.
Stimulus
Fig. 10 Fig. 11 Fig. 12 Fig. 13 Total
Thoughts
1
2
4
2
9
Videos
3
1
2
1
7
Images
2
3
3
4
12
Movements
4
4
1
4
13
Gestures
5
5
5
4
19
The results given by Table 4 are consistent with the
observations made in the section 4.1, where Gestures
seemed to be the best stimulus while Thoughts among the
worst ones. Based on these graphic and statistic results, a
ranking of the stimuli in order to improve the SR of the
training with an Emotiv® EPOC is shown in Table 5.
Table 5. Rank of stimuli in order to improve the SR using
the Cognitive Suite.
Rank
Stimulus
st
1
Gestures
2nd
Movements
3rd
Images
th
4
Thoughts
5th
Videos

Table 6. Equivalence between actions and instructions to
the wheelchair.
Action
Interpretation
First action

Forward/Backward

Second action

Turn left/right

Third action

Invert

Neutral

Stop

The third action corresponds to the Invert order
which is used to change the direction of the current
instruction being performed. Thus, if the wheelchair went
forward and the invert order was received, the wheelchair
drove backwards.
After having a defined way to control the powered
wheelchair, the PIDA protocol, proposed by Dawson et al.
[18] to evaluate the driving of the wheelchair, was
applied. This protocol includes activities in a bathroom, in
a bedroom, with doors, in an elevator, with ramps,
parking tests and manoeuvrability activities. Among the
27 tests performed, only six presented difficulties,
especially in the bathroom, and only one couldn’t be
performed, unexpected obstacles, which suggests that
there is a high latency in the response of the system. The
rest of the activities were achieved in an easily and
successfully. The general evaluation gave a total score of
79%, which is acceptable. The score obtained performing
the test with the joystick was 99%.

Due to the results, and considering that only Gestures
had a good performance in the three actions using the
Cognitive Suite, the mechatronic devices were controlled
by the Gestures. The fact that the other stimuli didn’t
respond satisfactorily in the second action and in the third
action, made them unsafe to control the powered
wheelchair which could represent a hazard for the user’s
health.
4.3 Result of Driving Assessment with Emotiv® EPOC
After choosing Gestures as the stimulus for the Emotiv®
EPOC to control a powered wheelchair, a Pride Jazzy®
Select Elite wheelchair was selected to perform the tests
on. For this purpose the joystick of the wheelchair with a

Fig. 14. Healthy user controlling the powered wheelchair
with the BCI using Gestures with the Cognitive Suite
(picture taken on Dec 20th 2012).

5. Conclusions and Future Work

Acknowledgement(s)

After the evaluation of the different stimuli proposed for
the use of Emotiv® EPOC with the Cognitive Suite, the
best results were obtained by Gestures. This is a singular
result given that the Emotiv® SDK user manual [14]
reads explicitly that the user has to avoid dramatic
expressions during the training with the Cognitive Suite.
This result was confirmed with the successful control of a
powered wheelchair using the Emotiv® EPOC with
Gestures and the Cognitive Suite. Users controlling the
powered wheelchair completed a series of tests that
evaluate driving skills. In these tests, users reached a
score of 79% when it was controlled by the BCI trained
with Gestures. This proved the effectiveness in the pursuit
of a successful control of a mechatronic device through a
BCI.
Based on the presented results, it is possible to
conclude that different stimuli produced variations in the
response of the user to the SDK training with BCI. This
suggests that the use of a particular stimulus, depending
on each user, could improve the reliability of the systems
controlled by BCI. Furthermore, different users responded
in different ways to the same stimulus. A similar behavior
takes place when the same user is stimulated with
different stimuli, while one of them could help to improve
the performance of the trials, another one could be an
obstacle to the training. The graphs show oscillations in
the curves, which suggests alternating periods of focus
and lack of focus.
Several observations were made during the process of
trials with the Emotiv® EPOC. The first one is that the
SDK has a latency period which forces the user to get in
focus before the start of each trial; otherwise the Skill
Rating would be affected. It is also difficult to keep the
focus for a period longer than eight seconds in each trail,
which could bring trials with a lack of focus affecting the
Skill Rating which is difficult to recover. Another fact
that was observed after this evaluation was that the system
is hard to be trained with more than one action; at least
through our approach; from all the stimuli applied, only
Gestures obtained satisfactory results with more than one
action.
As future work we plan to evaluate different BCIs,
applying the stimuli mentioned in this paper and
comparing them with the Emotiv® EPOC. Furthermore,
we plan to perform the same tests with tetraplegic patients
with the purpose verifying whether they are able to
control the powered wheelchair or not.
Last but not least, depending on the final function it
might not be worth dealing with the big signal analysis
required for cognitive recognition, when by gestures
recognition a similar function can be obtained. Therefore
the superficial electrical signals above the human’s neck
should all be considered as useful as the electrical signals
from thoughts.

Hereby the authors express their gratitude to Universidad
EAFIT, the Virtual Reality Research Group and the
Product Design Engineering Research Group (GRID) for
their support throughout the development of this project.
Furthermore to all the members of the team especially
Gustavo Peláez, Juan David Roldán, Susana Navarro,
Juan David Castrillón, Mateo Carvajal and Daniel
Calderón; and to all the other assistants and users that
participated during the development of the brain stimuli
sessions.

References
[1] S. Wang, E.T. Esfahani, & V. Sundararajan, Evaluation of
SSVEP as Passive Feedback for Improving the Performance of
Brain Machine Interfaces, Proc. of the ASME 2012 IDETC/CIE,
Chicago, IL, 2012.
[2] World Health Organization, World report on disability
2011 (Geneva, Switzerland, WHO, 2011).
[3] National Spinal Cord Injury Statistical Center, Spinal Cord
Injury Facts and Figures at a Glance (Birmingham, AL,
NSCISC, 2011).
[4] G. Bin, X. Gao, Y. Wang, Y. Li, B. Hong, & S. Gao, A
high-speed BCI based on code modulation VEP, Journal of
Neural Engineering, 8(2), 2011, 025015.
[5] K. K. Ang, C. Guan, K. S. G. Chua, B. T. Ang, C. W. K.
Kuah, C. Wang, K. S. Phua, Z. Y. Chin, & H. Zhang, A Large
Clinical Study on the Ability of Stroke Patients to Use an EEGBased Motor Imagery Brain-Computer Interface, Clinical EEG
and Neuroscience, 42(4), 2011, 253–258.
[6] H. George, A. Hosle, D. Franz, & A. Kubler, Brain
Painting – BCI Meets Patients and Artists in the Field, BCI
Meeting, Asilomar, CA, 2010, D-3.
[7] M. Palatucci, D. Pomerleau, G. E. Hinton, & T. M.
Mitchell, Zero-shot Learning with semantic Output Codes, 23rd
Annual Conference on Neural Information Processing Systems,
Vancouver, Canada, 2009, 1410-1418.
[8] D. Szafir, & R. Signorile, An Exploration of the Utilization
of Electroencephalography and Neural Nets to Control Robots,
INTERACT (4) - 13th IFIP TC13 International Conference,
Lisbon, Portugal, 2011, 186-194.
[9] V. Khare, J. Santhosh, S. Anand, & M. Bhatia, Brain
Computer Interface Based Real Time Control of Wheelchair
Using Electroencephalogram, International Journal of Soft
Computing and Engineering, 1(5), 2011, 41-45.
[10] F. Galán, M. Nuttin, E. Lew, P. W. Ferrez, G. Vanacker, J.
Philips, & J. del R. Millán, A brain-actuated wheelchair:
Asynchronous and non-invasive Brain–computer interfaces for
continuous control of robots, Clinical Neurophysiology, 119(9),
2008, 2159-2169.
[11] J. L. Collinger, B. Wodlinger, J. E. Downey, W. Wang, E.
C. Tyler-Kabara, D. J. Weber, A. JC McMorland, M. Velliste,
M. Boninger, & A. B. Schwartz, High-performance
neuroprosthetic control by an individual with tetraplegia, The
Lancet, Early Online Publication, December 17, 2012.
[12] D. Choi, Y. Ryu, Y. Lee, & M. Lee, Performance
evaluation of a motor-imagery-based EEG-Brain computer
interface using a combined cue with heterogeneous training data
in BCI-Naive subjects, BioMedical Engineering OnLine, 10(1),
2011, 91.

[13] J. Jin, E. W. Sellers, Y. Zhang, I. Daly, X. Wang, & A.
Cichocki, Whether generic model works for rapid ERP-based
BCI calibration, Journal of Neuroscience Methods, 212(1),
2013, 94-99.
[14] Emotiv® Software Development Kit, User Manual for
Release, Version 1.0.0.4, 29-33.
[15] C. Gorman, The Mind-Reading Machine, IEEE Spectrum,
July, 2012.

[16] Edgar A. Cardona, Clinical Neurologist, SaludCoop Clinic,
Personal Communication, Medellin, June 23, 2012.
[17] D. G. Amen, Cambia tu Cerebro, Cambia tu Vida, Spanish
Pubs Llc, 2011.
[18] D. Dawson, E. Kaiserman-Goldenstein, R. Chan, & J.
Gleason, Power-Mobility Indoor Driving Assessment manual,
2006.

