5375

Brazilian Journal of Development
Generando música a través de la Actividad Cerebral
Generating music through Brain Activity
DOI:10.34117/bjdv5n6-077
Recebimento dos originais: 11/03/2019
Aceitação para publicação: 15/04/2019

Ricardo Andres Diaz Rincon
Estudiante de Ingeniería de Sistemas en la Universidad del Valle.
Calle 13 # 100-00 Melendez Cali, Valle
E-mail: ricardo.andres.diaz@correounivalle.edu.co
Javier Mauricio Reyes Vera
Profesor Universidad del Valle
Magister en Ingeniería de Sistemas por la Universidad del Valle
Calle 13 # 100 -00 Melendez, Cali, Valle, Colombia.
E-mail: javier.reyes@correounivalle.edu.co
Paola J. Rodriguez C
Profesor Universidad del Valle
Doctora en Ingeniería enfasis Sistemas y Computacion por la Universidad Nacional de
Colombia.
Calle 13 # 100-00 Melendez Cali, Valle
E-mail: paola.ridriguez@correounivalle.edu.co
RESUMEN
El presente artículo muestra la forma en que las interfaces cerebro computador (BCI) pueden
ser utilizadas para generar música. Para lograr lo anterior, se realiza una revisión de fuentes
académicas que contienen definiciones esenciales relacionadas con ambas áreas del
conocimiento; de esta forma se podrá establecerse un puente que permita la descripción de
una herramienta computacional que permita cumplir con el objetivo planteado.
Palabras clave: Interfaces Cerebro Computador, Música, Interacción Humano Computador.
ABSTRACT
This article shows how brain computer interfaces (BCI) can be used to generate music. Thus,
a review of academic sources that contains essential definitions related to both areas of
knowledge is carried out in order to create a bridge that allows describing a computational
tool that fulfills the raised objective.
Keywords: Brain Computer Interfaces, Music, Human Computer Interaction.

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5376

Brazilian Journal of Development
1 INTRODUCCIÓN
Durante mucho tiempo la actividad cerebral asociada con procesos de la vida cotidiana
ha sido ampliamente estudiada. Años de investigación y arduo trabajo han acercado a los
seres humanos a la compresión de uno de los órganos másfascinantes de los seres vivos: el
cerebro.
En las últimas dos décadas, el éxito de estudios relacionados con fenómenos cerebrales
ha cobrado gran relevancia debido al abaratamiento del hardware y el software, también
debido al auge de empresas especializadas como Neurosky® y Emotiv® que han
desarrollado algunas aplicaciones orientadas al público general. Un ejemplo de lo anterior es
el dispositivo de experimentación MindWave, que posee herramientas que permiten la
recolección de datos relacionados con los niveles de Atención y Meditación del usuario.
Desde los últimos siglos, la manera en la que nos relacionamos con el entorno ha cambiado.
El uso constante de las nuevas tecnologías emergentes ha configurado una nueva forma de
interacción cuyo auge es cada vez mayor. De allí la iniciativa planteada en el trabajo descrito
en el presente artículo, cuya organización está definida de la siguiente manera: el siguiente
apartado explica conceptualmente como se entienden las interfaces cerebro computador y la
manera como se conecta el cerebro con una aplicación. Luego un acercamiento a los
conceptos básicos de la música con el objetivo de entender las variables que serán tenidas en
cuenta en el desarrollo de la aplicación.
2

INTERFACES CEREBRO - COMPUTADOR

Las Interfaces Cerebro Computador son sistemas de comunicación hardware y software
cuyo fin es ayudar al usuario a interactuar con el medio externo prediciendo sus intenciones
a partir de datos relacionados con su actividad cerebral. Este tipo de sistemas han sido
fundamentalmente estudiados y usados como herramientas de asistencia para personas con
movilidad reducida debido a que no involucran el uso de canales musculares para la
interacción del usuario [1].Una BCI se concibe como un sistema de inteligencia artificial que
puede reconocer un conjunto de patrones en las señales del cerebro siguiendo cinco etapas
consecutivas a saber: Adquisición de la señal, Pre-procesamiento de la señal, Extracción de
características, Clasificación e Interfaz de control.
La primera etapa capta las señales neuronales empleando algoritmos para minimizar el
ruido externo.

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5377

Brazilian Journal of Development
La segunda etapa prepara los datos de manera adecuada para su posterior
procesamiento.
La etapa de Extracción de características identifica la información discriminando aquella
que ha sido grabada en el cerebro.
La clasificación e Interfaz de control corresponde una etapa más lógica y de inferencia.
3 CARACTERIZACIÓN
Los sistemas BCI son aplicaciones que permiten comunicar el cerebro con dispositivos
mecánicos externos e involucran aspectos importantes como el control voluntario de las
señales electroencefalográficas, la sincronización de ritmos cerebrales y la medición,
interpretación y clasificación de la actividad neuronal. Los movimientos – reales o
imaginarios – de una persona involucran de manera considerable la actividad cerebral, lo
cual genera respuestas endógenas y exógenas. Los sistemas endógenos se basan en el
reconocimiento de patrones cerebrales sin la necesidad de un estímulo externo, sino que se
producen por la voluntad del usuario; por su parte los sistemas exógenos basan su control en
los estímulos externos de los que obtienen su respuesta cerebral.
3.1 ONDAS CEREBRALES Y SU CLASIFICACIÓN
Las ondas cerebrales son producidas cuando las células cerebrales (neuronas) se activan
y producen flujos de corriente locales que son traducidas en impulsos y cambios eléctricos.
La encefalografía o EEG mide principalmente las corrientes que fluyen durante las
excitaciones sinápticas de las dendritas de muchas neuronas piramidales en la corteza
cerebral [2]. Los patrones cerebrales forman gráficas sinusoidales que oscilan comúnmente
entre 0.5 y 100 μV en amplitud, es decir, casi 100 veces menos que las señales de ECG
(Electrocardiogramas). La transformada de Fourier permite tomar estas señales en bruto y
amplificarlas para obtener un mayor volumen de información. Las ondas cerebrales son
medidas en ciclos por segundo (Hz), a mayor número de Hz, mayor será la frecuencia o
actividad cerebral.El primer acercamiento a las ondas cerebrales fue realizado por el alemán
Hans Berger en 1924 [3]. Entre 1930 y 1940 las ondas cerebrales lograron clasificarse en 5
grupos que están resumidas en la Tabla 1:
Ondas
Delta (δ)

Rangos
< 4 Hz

Theta (θ)

4Hz a 7Hz

Estados Mentales
Inconsciencia,
sueño profundo.
Relajación,
intuición,

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5378

Brazilian Journal of Development

Alpha
(α)

8Hz a 12Hz

Low
Beta (β)
Mid
Beta (β)
High
Beta (β)
Gamma
(γ)

12Hz a
15Hz
16Hz a
20Hz
21Hz a
30Hz
30Hz a
100Hz

creatividad,
recordación,
Imaginación.
Esfuerzo mental,
relajación sin
dormir, quietud,
consciencia.
Relajación y
enfoque.
Pensar, autoconsciencia.
Alerta, agitación.
perturbación.
Funciones motoras
y alta actividad
mental.

Tabla 1. Rangos de frecuencias y estados mentales.

Cincuenta años después del descubrimiento realizado por Berger, se encontró un
comportamiento oscilatorio e intrínseco en las neuronas de los vertebrados, pero su rol
funcional aún no se entiende totalmente[4]. Muchas de las áreas del cerebro humano y su
comportamiento no han sido descubiertos y/o entendidos en su totalidad, sin embargo, la
comunidad científica sigue trabajando para descubrir los secretos que este aguarda.
4

MINDWAVE
Neurosky® es un sistema de BCI que captura las señales cerebrales a partir del

Mindwave Headset el cual tiene un sensor ubicado en la parte frontal de la cabeza y un clip
que va en la oreja izquierda del usuario, convierte las señales cerebrales en acciones. Tiene
la propiedad de reportar los estados mentales del usuario, es decir Atención y Meditación
utilizando unos algoritmos propios denominados eSense. Este dispositivo se utiliza para el
soporte de video juegos, investigación de software y otras aplicaciones que favorecen la
experiencia de usuario.

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5379

Brazilian Journal of Development
Figura 1. Dispositivo BCI (MindWave).

4.1 APLICACIONES BCI
Neurosky® es una tecnología accesible y fiable para desarrollar proyectos que necesiten
la adquisición de señales cerebrales. Con el paso del tiempo, se han realizado diversos
trabajos que lo han usado a nivel práctico[5], [6], [7], [8]. La utilización de Neurosky® para
proveer adaptatividad tiene un desarrollo escaso o casi nulo. Los trabajos se centran
fundamentalmente en medir los estados cerebrales para establecer criterios que permitan
establecer estados cognitivos o afectivos respecto a la interacción y mejorar procesos
(pedagógicos, psicológicos o sociales).
4.2 MÚSICA: UNA LIGERA DESCRIPCIÓN
La palabra música se deriva del griego mousike (μουσική) que significa “arte de las
musas” [9]. La definición provista por el diccionario de Oxford establece que música es “el
arte de combinar sonidos vocales, instrumentales (o ambos) para producir belleza de forma,
armonía y expresión de emoción”[10]. La música es también ampliamente definida como
“sonido organizado”; este término fue originalmente acuñado por el compositor modernista
Edgard Varèse en relación a su propia estética musical [11]. Sin embargo, muchos autores
han expresado distintas opiniones respecto de lo que se considera o na música.

4.3 DIFERENCIACIÓN ENTRE MÚSICA Y RUIDO
No sería posible hablar de música sin introducir el concepto de ruido, el cual es definido
– desde las prácticas musicales convencionales – como todos aquellos sonidos que carecen
de musicalidad[12]. Sin embargo, en algunas ocasiones lo que consideramos “musical”
corresponde a una apreciación expresamente subjetiva.En su artículo ''Noise as Permanent
Revolution'' Ben Watson manifiesta que incluso una pieza maestra como Große Fuge de
Ludwing Van Beethoven “sonó como ruido” para la audiencia de ese momento
(1825).[13]Los sonidos que percibimos en una pieza musical son el resultado de las
alteraciones vibratorias que se producen en la atmosfera y en los objetos que se encuentran a
nuestro alrededor.El ruido es producido cuando las ondas sonoras resultan caóticas, confusas
o irregulares en contraste con aquellas ordenadas, periódicas y regulares generadas por los
instrumentos musicales [14]. En la figura 3 se muestran las diferencias entre las ondas.
“Oscillations and Waves” define el ruido como las vibraciones irregulares de un objeto, en
contraste con la periódica y modelada estructura de la música [15].
Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5380

Brazilian Journal of Development

Figura 2. Diferencia entre las ondas producidas por el ruido y la música.

Los instrumentos musicales producen y comunican vibraciones a través de la atmosfera
circundante en forma de ondas de sonido que son regulares y periódicas, las cuales llamamos
tonos. En consecuencia, es la presencia del tono lo que generalmente distingue a la música
del ruido. Una gran parte de nuestra música se crea a partir de combinaciones de tonos
(melodía y armonía).Para comprender mejor la definición y el lenguaje de la música, es
necesario familiarizarse con otras definiciones fundamentales, como son: tono (altura),
duración, intensidad, y timbre [16]. La figura presentada a continuación muestra la relación
entre los conceptos previamente mencionados.

Figura 3. Pilares de la teoría musical.

4.4 TONO
El tono es una característica esencial que nos permite distinguir entre sonidos agudos y
graves [17]. La frecuencia de cada sonido – medida usualmente en Hertz(Hz) –

denota el

número de ondas sonoras por segundo y permite identificar la nota musical a la que
corresponde. Los sonidos agudos se encuentran a frecuencias más altas, sin embargo, tienen
una longitud de onda más corta; de manera análoga, los sonidos graves se encuentran a bajas
frecuencias, pero tienen una longitud de onda más prolongada. La figura 5 muestra las
frecuencias en las que se encuentran algunos instrumentos musicales.

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5381

Brazilian Journal of Development

Figura 4. Rango de algunos instrumentos musicales.

Aunque el tono es cuantificado por medio de frecuencias, no corresponde a una
propiedad física netamente objetiva, sino que es un atributo subjetivo psicoacústico del
sonido, por lo que la percepción auditiva de cada persona puede variar. El rango general de
la audición humana se encuentra entre 20 Hz y 20 kHz, aunque esto puede variar
dependiendo de la sensibilidad de cada oído[14]. Los sonidos encontrados por fuera de este
rango son imperceptibles para los seres humanos, pero perceptiblespara otras especies.

4.5

DURACIÓN

En música, la duración es el tiempo en el que se mantienen las vibraciones producidas
por un sonido, es decir, el periodo o intervalo de tiempo en el que suena una nota
específica[18]. La representación gráfica se realiza por medio de figuras musicales asignadas
a diferentes sonidos, donde la redonda es la unidad de referencia y cada subdivisión (figura
musical) dura en tiempo la mitad de la nota anterior. A continuación, se muestran las figuras
musicales junto con su representación gráfica, sonido y duración:

I.
Figura 5. Figuras musicales.

4.6 INTENSIDAD
También conocida como volumen, es la propiedad que permite identificar cuán fuerte o
suave se percibe un sonido. Los niveles de volumen son medidos en decibeles (dB) y el
Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5382

Brazilian Journal of Development
rango de audición humana se encuentra aproximadamente entre 0 y 120 dB. Sonidos por
encima del límite superior – como el producido por el despegue de los aviones – pueden
causar daños irreversibles en la audición. Si bien la frecuencia se rige por la longitud de las
ondas de sonido, la intensidad se rige por su altura, un ejemplo de ello se muestra en la
figura 7. La altura de la ola también puede denominarse amplitud de onda [14].

Figura 6. Amplitud de onda.Timbre

El timbre es una propiedad intrínseca que le permite al odio humano diferenciar entre
los sonidos emitidos por diversas fuentes, incluso cuando éstas no pertenecen a la misma
categoría. Por ejemplo: el sonido emitido por una guitarra y un bajo eléctrico o una misma
nota musical tocada por diferentes instrumentos. Cada una de las anteriores definiciones
constituyen la estructura y el fundamento de lo que conocemos como música.

4.7 GENERANDO MÚSICA
A continuación, se describe el proceso que permite crear música a partir de la actividad
cerebral:

5 ASPECTOS TÉCNICOS: DEFINICIÓN DEL LENGUAJE DE PROGRAMACIÓN
Y EL DISPOSITIVO BCI
La etapa preliminar se concentra en definir el lenguaje de programación y el dispositivo
BCI a utilizar. Respecto de lo anterior, es necesario decir que, para que la experiencia fuera
lo más satisfactoria posible para el usuario, decidimos utilizar dispositivos BCI no invasivos;
también descartamos aquellos que utilizan solución salina para fijar los electrodos debido a
dos razones: La primera es que estamos interesados en tomar lecturas de las ondas cerebrales
y asociar estas a los estados mentales del usuario, por lo que en un principio, basta con
obtener la información presente en el lóbulo frontal; la otra razón es que el contacto con la
solución salina es poco placentera para muchos usuarios con cabello abundante.Por estas
razones el dispositivo Mindwave fue el adecuado para llevar a cabo esta investigación.Se
escogió Processing como ambiente de programación debido a dos razones: La primera es su
Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5383

Brazilian Journal of Development
fácil integración con JavaScript/Java y las librerías existentes para manejo de datos MIDI
(Musical Instrument Digital Interface) de los que hablaremos más adelante. La segunda
razón es la facilidad que posee para el despliegue de la información y la creación de
interfaces de usuario.

6

EXPLORACIÓN SONORA
Luego de definir el dispositivo BCI y el lenguaje de programación, nos concentramos en

la exploración sonora, es decir, indagamos acerca de las opciones disponibles con respecto
de las potenciales notas musicales que darán estructura al sonido general. En este sentido,
cada nota musical posee una representación MIDI asociada, la cual se define por medio de
un número entero, como se muestra en la figura presentada a continuación.

Figura 7. Conjunto de notas musicales.

7 SELECCIÓN DETONALIDAD
Del conjunto de notasmusicales disponibles, se seleccionan aquellas que pertenezcan a
una tonalidad definida. Durante el desarrollo de esta investigación se seleccionó Sol mayor
como una tonalidad apropiada, cuyas notas componentes son: sol, la, si, do, re, mi, fa# y sol
como se muestra en la figura presentada a continuación:

Figura 8. Tonalidad de Sol mayor.

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5384

Brazilian Journal of Development
Luego de escoger la totalidad, se seleccionan aquellas notas que constituyen la triada, es
decir, aquellas notas que forman el acorde.

Figura 9. Triada de Sol mayor.

A continuación, se declaranlas notasseleccionadas como variables, las cuales serán
posteriormente enviadas a través de un canal MIDI. La siguiente figura muestra las notas de
la triada de sol mayor (sol, si y re) ubicadas en las octavas 2-5 y su representación MIDI.

Figura 10. Notas musicales utilizadas.

8

CREACIÓN DE LA ESTRUCTURA MUSICAL

Luego de tener las notas declaradasse asigna una duración y un tempoespecífico a cada
una de ellas. De esta forma, se crea una estructura musical, compuesta por notas que se
encuentran en la misma escala y tienen una duración específica.

9 ASIGNACIÓN DE ONDAS CEREBRALES
Posteriormente, las notas son asignadas a cada onda cerebral como se muestra en la
tabla a continuación:
NOTA MUSICAL
G4

(Sol,

ONDA CEREBRAL

cuarta

Theta

cuarta

Alpha

quinta

Beta

octava)
B4(Si,
octava)
D5

(Re,

octava)
G5Flat

(Sol

bemol,

quinta

Gamma

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5385

Brazilian Journal of Development
octava)
G2 (Sol, segunda

Delta

octava)
D3(Re,

tercera

High Alpha

octava)
G3 (Sol, , tercera

AVG

octava)

(Low

Gamma
+

High

gamma)
Tabla 2. Notas musicales y su correspondiente ondacerebral asignada.

Se utiliza una lista de patrones para usar como secuencias de notas. Cada número en el
patróndeterminará la ocurrencia de una nota en una secuencia de 8 (la cantidad de notas
musicales en una escala). Las frecuencias (valores de las ondas cerebrales) determinarán que
patrón se toca.

10 FLUCTUACIÓN DEL SONIDO GENERAL
Con el objetivo de aumentar la expresividad, se utilizan los niveles de atención y
relajación para modificar el sonido general: Niveles altos de relajación disminuirán la
intensidad del sonido mientras que los niveles altos de atención aumentarán la intensidad.La
fluctuación de ambos niveles (que no son complementarios en un principio) y de las
emociones del usuario serán un rasgo característico de la música generada por cada usuario
en particular.

11 AÑADIENDO EXPRESIVIDAD
Si bien Processing permite usar la salida MIDI del ordenador para reproducir los datos
enviados, la utilización de un DAW (Digital Audio Workstation) permite elegir entre tipos
de instrumentos musicales y efectos de audio.Sin embargo, para que lo anterior sea posible,
es necesario crear un enlace entre la aplicación y el DAW, por lo cual se utiliza un puerto
MIDI virtual que permita la comunicación entre ambas.

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5386

Brazilian Journal of Development

Figura 11. Arquitectura de software.

Una vez que el puerto MIDI está en ejecución, es posible establecer la comunicación
entre la aplicación y el DAW.

Figura 12. Lista de puertos MIDI de salida.

12 USO EN PROCESOS EDUCATIVOS
La música ha demostrado tener propiedades útiles en los contextos clínicos y
terapéuticos[19]. Sus usos no solamente se limitan a estas áreas, sino que también pueden ser
aplicadosen contextos académicos y/o educativos. De esta forma el prototipo diseñado
puedeutilizarsepara potenciar el proceso de aprendizaje[20], al exponer a los estudiantes a la
música generada por sus propias ondas cerebrales y estudiar la forma en que esta cambia
cuando realizan distintos tipos de actividades académicas.Otro de los usos potenciales tiene
que ver con utilizar los niveles de atención y relajación para inferir qué tan satisfactorio es el
proceso de aprendizaje de un estudiante al realizar una actividad. De igual forma, el
prototipo puede ser utilizado por docentes para explicar conceptos musicales básicos, tales
como los mostrados en este paper.

13

CONCLUSIONES Y TRABAJO FUTURO

Si bien el trabajo realizado hasta el momento ha sido satisfactorio, en el futuro se busca
generar una base musical más sólida al aumentar la expresividad del sonido exportado. Sin
duda alguna, la meta es procesar la unicidad provista por quien utilice el dispositivo y
generar música que responda de manera distinta a cada individuo. De manera análoga, se
busca aprovechar aún más el elemento humano, de forma que el sonido generado cambie
respecto de la ausencia o presencia de ciertos estados mentales.
Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

Gracias a la
ISSN 2525-8761

5387

Brazilian Journal of Development
retroalimentación recibida, se podría, por ejemplo, generar cierto conjunto de sonidos que
ayuden a reforzar el estado mental actual o conducir a la persona a uno totalmente diferente.

REFERENCIAS
[1]

L. F. Nicolas-Alonso and J. Gomez-Gil, “Brain computer interfaces, a review,”

Sensors. 2012.
[2]

M. Teplan, “Fundamentals of EEG measurement,” Meas. Sci. Rev., 2002.

[3]

R. Jung and W. Berger, “Hans Bergers Entdeckung des Elektrenkephalogramms und

seine ersten Befunde 1924-1931,” Arch. Psychiatr. Nervenkr., 1979.
[4]

R. R. Llinas, “Intrinsic electrical properties of mammalian neurons and CNS

function: a historical perspective,” Front. Cell. Neurosci., 2014.
[5]

M. E. and A. Fernandez, “ReadGoGo! : Towards Real-Time Notification on Readers’

State of Attention.,” in XXIV International Conference on Information, Communication and
Automation Technologies (ICAT) October 30 – November 01, 2013, Sarajevo, Bosnia and
Herzegovina., 2013.
[6]

S. H.-G. Francisco Javier Landa-Torres, Nery Sofía Huerta-Pacheco, Genaro

Rebolledo-Mendez, Automatización de Estados Afectivos durante una situación de
aprendizaje Facultad de Estadística e Informática. 2012.
[7]

S. de F. Candy Obdulia Sosa Jimenez, Héctor Gabriel Acosta Mesa1, Genaro

Rebolledo-Mendez, “Classification of cognitive states of attention and relaxation using
supervised learning algorithms.,” in IEEE International Games Innovation Conference
(IGIC), 2011.
[8]

and I.-H. L. Kwang-Ok An, Jong-Bae Kim, Won-Kyoung Song, “Development of an

Emergency Call System using a Brain Computer Interface (BCI),” in Proceedings of the
2010 3rd IEEE RAS & EMBS International Conference on Biomedical Robotics and
Biomechatronics, The University of Tokyo, Tokyo, Japan, September 26-29, 2010., 2010.
[9]

H. G. Liddell and R. Scott, A Greek-English Lexicon with a revised supplement.

Oxford University Press, 1843.
[10]

R. Allen, H. Fowler, and F. Fowler, “The Concise Oxford dictionary of current

English,” Oxford Clarendon Press, 1990.
Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

5388

Brazilian Journal of Development
[11]

R. F. GOLDMAN, “REVIEWS OF RECORDS,” Music. Q., vol. XLVII, no. 1, pp.

133–134, 1961.
[12]

A. Latham, “The Oxford Companion to Music,” Music Educ. J., 2003.

[13]

H. Noise, S. L. Gallery, and N. York, “Noise & Capitalism,” no. M, p. 197, 2010.

[14]

Michael Hewitt, Music Theory for Computer Musicians. 2008.

[15]

K Rama Reddy, Sb Badami, Balasubramanian V, Oscillations And Waves.

Universities Press (India) Limited, 1994.
[16]

R. D. Patterson, E. Gaudrain, and T. C. Walters, “The Perception of Family and

Register in Musical Tones,” in Music Perception, 2010.
[17]

C. Plack and A. Oxenham, Pitch: Neural Coding and Perception. 2005.

[18]

B. Benward and M. Saker, Music in theory and practice. 2008.

[19]

B. J. Crowe and R. Rio, “Implications of technology in music therapy practice and

research for music therapy education: A review of literature,” J. Music Ther., 2004.
[20]

M. S. Widerman, “Study habits and music: How they affect attention and academic

performance,” Georg. Mason Univ. FairFax, VA, 2013.

Braz. J. of Develop., Curitiba, v. 5, n. 6, p. 5375-5388, jun. 2019

ISSN 2525-8761

