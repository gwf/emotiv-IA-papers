UWS Academic Portal

Affect Detection for Human-Horse Interaction
Althobaiti, Turke; Katsigiannis, Stamos; West, Daune; Bronte-Stewart, Malcolm; Ramzan,
Naeem
Published in:
21st Saudi Computer Society National Computer Conference (NCC’2018)
DOI:
10.1109/NCG.2018.8593113
Published: 31/12/2018

Document Version
Peer reviewed version
Link to publication on the UWS Academic Portal

Citation for published version (APA):
Althobaiti, T., Katsigiannis, S., West, D., Bronte-Stewart, M., & Ramzan, N. (2018). Affect Detection for HumanHorse Interaction. In 21st Saudi Computer Society National Computer Conference (NCC’2018)
https://doi.org/10.1109/NCG.2018.8593113

General rights
Copyright and moral rights for the publications made accessible in the UWS Academic Portal are retained by the authors and/or other
copyright owners and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with
these rights.

Take down policy
If you believe that this document breaches copyright please contact pure@uws.ac.uk providing details, and we will remove access to the
work immediately and investigate your claim.

Download date: 07 May 2020

Affect Detection for Human-Horse Interaction
Turke Althobaiti, Stamos Katsigiannis, Daune West, Malcolm Bronte-Stewart, Naeem Ramzan
School of Engineering and Computing
University of The West of Scotland
Paisley, United Kingdom
{Turke.Althobaiti, Stamos.Katsigiannis, Daune.West, Malcolm.Bronte-Stewart, Naeem.Ramzan}@uws.ac.uk

Abstract—In this work, we aim to study the potential
use of affect recognition techniques for examining the
interaction between humans and horses using qualitative
and quantitative methods. To this end, we propose a
multi-modal portable system for physiological signal
acquisition such as the electrocardiogram (ECG), electromyogram (EMG), and electroencephalogram (EEG).
The proposed system is used to acquire signals while users
are interacting with horses. The captured signals will
then be used in order to quantitatively evaluate human
and equine interaction by mapping the signals to the
emotional state of the subjects using machine learning
techniques. In this preliminary study, ECG based features
were utilised in order to create a supervised classification model that can identify emotions elicited during
human-horse interaction. Experimental results provide
evidence about the efficiency of the proposed approach
in distinguishing between negative and positive emotions,
reaching a classification accuracy of 74.21%.
Index Terms—Emotion recognition, physiological signals, human/horse interaction, EEG, ECG, EMG.

I. I NTRODUCTION
The relationship between humans and horses has
been well documented throughout the history and has
been studied extensively. Many recent studies focus
on using the interaction with horses for treating mental health issues, such as anxiety and post-traumatic
stress symptoms [1], and learning difficulties [2]. Other
studies have been undertaken measuring brain activity
(electroencephalography - EEG) for specific purposes,
such as treating children with autism [3], while the
heart rate measurement has also been employed to
estimate the interaction between human and horses [4],
[5]. Emotional cues may be seen in humans through
different channels, such as voice, posture, and expression pheromones [6]. The use of analytical methods for
measuring the effect of the interaction with horses on
humans has the potential to offer a powerful insight
on the benefits of such interaction in psychotherapy
intervention.
Affect recognition is the task of detecting the emotional state of humans under various conditions. The
development of efficient and robust algorithms for
automated emotion (affect) recognition is a major
challenge and may have great implications on the way

users interact with computers, as well as on fields like
medicine, education, multimedia, etc. Human emotion
can be recognised through various means such as
facial images, gesture, neuro-imaging methods, and
physiological signals [1]. Various theories and methods for emotion recognition have been proposed and
developed, but their limited performance renders affect
recognition as an open research problem. Physiological
signals have been widely exploited for the task of affect
recognition [7]. Amongst them, the Electroencephalogram (EEG), the Electrocardiogram (ECG), and the
Electromyogram (EMG) are some of the most widely
used. The EEG is the recording of the electrical activity
on the scalp, the ECG is the recording of electrical
activity created in the heart, and the EMG is the
recording of electrical activity produced by muscle
contraction.
In this work, we aim to exploit physiological signals
in order to study the potential use of affect recognition
techniques for examining the interaction between human and horses. To this end, we propose a multi-modal
system and an experimental procedure for acquiring
physiological signals in order to detect the human
emotion toward different horses. The proposed system
was used in order to acquire EEG, ECG, and EMG
recordings from people that were interacting with two
different horses. Feedback about the interaction was
also acquired in the form of video-recorded interviews
which were used in order to conduct a qualitative
analysis of the emotional responses elicited to the
people by their interaction with each of the horses.
In this preliminary study, features extracted from the
ECG recordings were used in supervised classification experiments for the task of mapping people’s
descriptions of their own emotions onto their ECG
signals. Experimental results provided evidence about
the efficiency of the proposed approach, achieving a
classification accuracy of 74.21%.
The rest of this paper is organised in four sections. Section II provides an overview of the current
state-of-the-art in the examined field. The proposed
methodology is described in Section III, while results
are presented and discussed in Section IV. Finally,

conclusions are drawn in Section V.
II. BACKGROUND
Emotion is defined as a psycho-physiological process which is elicited by cognisant and/or incognisant
grasp of such an article or situation [8]. Personality, mood, behaviour, and inspiration correlate with
emotion. Emotions are evident in personal or social
communication and can be presented by expressive
words orally, or expressed by non-verbal signs such as
facial expressions and gestures. Human emotion varies
depending on the stimuli that a person is exposed to.
Wioleta [9] argues that emotion is affected by many
aspects of everyday life: peoples emotions can change
according to environment, mood, time, and memory,
the same stimuli may create different emotions for
different people, and the same emotion may be seen at
different intensities, and conclude that it is impossible
to have a specific emotion or even any emotion you
want. Detecting and measuring the felt emotions is an
arduous task.
Physiological signal is one of the tools that can
describe human emotions [10]. Physiological signals
are attracting research attention as a way of mapping
peoples emotions. For example, studies have shown
that there is a relation between physiological signals
and the arousal and valence dimensions of a felt
emotion, and multiple studies have examined the use
of multi-modal systems for capturing physiological
signals and mapping them to an emotional state, e.g.
[7], [8].
While various studies have been conducted for examining equine assisted therapy, e.g. [11], [12], relatively few academic studies have focused on understanding the complex emotional response that horses
seem to elicit to human riders, handlers and even
artists. Emotional response to human/horse interaction
dates back at least to the earliest existing writing
about horsemanship. Xenophon [13] advised on how
to train the horse with gentleness so as to develop and
enjoy his natural beauty and power. Duarte [14] wrote
about the way in which horse riding forces the rider
to master one’s fear, anger, frustration, and the ego
and to develop judgement, tranquillity, and wisdom.
Similarly, De Pluvinel [15] advised his student (the
Dauphin of France) that the study of horsemanship
taught kingly virtues and wisdom in life, an opinion
echoed by Podhajsky [16], dressage Olympic medallist
and one time Director of the Spanish Riding School
more than three hundred years later [17]. De Kunffy
[18] discusses the ultimate aim of becoming one with
the horse and the overpowering sensation of emotion
to be experienced with this attainment.

A qualitative study into the personal reasons for
dedicating a life to classical dressage describes the
rider/trainers search for “brilliance”, an emotion and
feeling that once experienced is addictive [19]. In
addition to such recorded descriptions of the ability of the horse to evoke powerful emotions in
their riders/handlers, proponents of Natural Horsemanship attempt to enhance the emotional satisfaction
riders/handlers experience in their relationship with
the horse. The particular emotional relationship that
women and girls experience with horses has also been
recorded, e.g. [20], [21]. As a counter to what has
sometimes been described as more anecdotal evidence,
advocates of evidenced-based research in the form
of Equitation Science have posited ideas of learning
theory to help riders/handlers improve both horse
welfare and enhance the quality of the human/horse
relationship, e.g. [22].
Given the emotional richness of the human/horse
relationship it is perhaps not surprising that therapists
value the contributions that horses can make to the psychotherapy process. Thus, horses have been considered
as one of human beings best friends. One of the goals
of the research about horse-human relationship is to
try to enhance the development and maintenance of a
solid positive relationship that can be elicited in a short
action and seen in a short time [23].
Recently, researchers have been trying to explore
the interaction between human and horses using physiological signals. Lanata et al.’s [24] study focuses
on human-horses interaction by using ECG signals.
The signals were captured in three phases, before
interaction, visual-olfactory interaction, and grooming.
In this study, ECG-based features were used with
a Support Vector Machine (SVM) classifier for the
task of identifying the interaction activity between the
human and the horse, reaching a classification accuracy
of 90.95%. Another study by the same researchers on
the same topic, using the same activities, but with a
different classifier (Nearest Mean classifier), reached
an accuracy of 70.87% [25].
III. M ETHODOLOGY
A. Participants
Two healthy horses, chosen by the handler, were
involved in this study (Max, Appaloosa stallion, 19
years old, and Braga, Lusitano stallion, 7 years old),
and eleven participants with different experiences with
horses, enrolled in this experiment (see Fig. 2). Their
ages were between 16 and 64 years old (µ = 36.45,
σ = 16.84). It must be noted that for conducting this
study and for publishing the results and acquired data,
ethical approval was acquired from University of the
West of Scotland, University Ethics Committee.

Fig. 1: The signal acquisition system

2
6

Experienced (Owners)
Experienced (Non-owners)
No experience

3

Fig. 2: Division of participants based on their previous
experience with horses. The owners of the horses used
in this study are referred as “Owners”.

B. Procedure
Before starting the experiment, a consent form was
distributed, and instructions were given to the subjects individually. The duration of the experiment was
approximately ten minutes for each horse, divided to
three phases relating to performed activities (looking,
grooming, and leading the horses). Phase 1 (looking)
lasted four minutes. Its purpose was to let the subject
and horse become comfortable with each other. The
subject was asked to sit down while the horse was
free to move for four minutes in a small indoor sand
arena. This process allowed the horse to explore the
changes to their familiar environment caused by the
experiment [4]. Next, the participant was asked to start
the second activity which was grooming (touching) the
horse. Touching horses has been shown to result to a
decrease in human and horse heart rates when they are
both comfortable [5]. The subject spent two minutes
grooming the horse. Finally, for Phase 3, the subject

was asked to lead the horse around a predetermined
path. The duration of this activity depended on the
subject’s movement and the subject’s confidence and
ability in controlling the horse’s movement. The above
procedures were repeated two times for each subject,
one for each of the two horses used in the study.
Between each iteration of the experiment, there was a
ten minutes break in order to allow the handler to bring
the next horse to the arena and prepare the subject for
the next experiment. The whole experiment, as well as
an interview with each subject about their interaction
with the horses was video-recorded for reference and
validation purposes.
C. Data collection
In order to examine the relation between physiological signals and human and horse interaction, EEG,
ECG, and EMG data were captured for each subject
during the three phases of the experiment. EEG was
recorded at a sampling rate of 128 Hz using the Emotiv
EPOC+ wireless EEG headset [26] that has 16 goldplated contact sensors that are fixed to flexible plastic
arms of the Emotiv EPOC wireless headset and are
placed against the head in locations aligned with the
following locations according to the International 1020 system: AF3, F7, F3, FC5, T7, P7, O1, O2, P8,
T8, FC6, F4, F8, AF4, M1 and M2. ECG and EMG
were recorded at a sampling rate of 256 Hz using two
wireless Shimmer sensors [27], and using four standard
electrodes placed on both lower ribs and clavicle for

TABLE I: Keywords associated with positive and negative emotion

TABLE II: Classification performance
Classifier

Keyword
Comfortable, Calm, Impressed, Relaxed, Happy

Emotion
Positive

Nice, Great, Enjoyed, Proud
Afraid, Scared, Wary, Uneasy, Aware

Negative

ECG, and three standard electrodes placed on the upper
trapezius muscles for EMG [28].
All devices were connected to a Raspberry Pi
portable mini-computer that was powered by a standard
off-the-shelf USB power bank, and the acquired signals
were recorded and stored on the Raspberry Pi’s micro
SD memory card. The use of the aforementioned
computing device as the control and capturing module
of the proposed system ensured that the necessary
portability for conducting equine related studies on
outdoors environments was achieved. An outline of the
proposed system and setup is shown on Fig. 1. When
all the activities were completed, a video-recorded
interview was conducted with each participant in which
they were asked to reflect upon their experience with
each of the two horses.
D. Data pre-processing and preparation
Using the timestamps from the video recordings of
each experiment, the acquired signals were divided into
segments referring to each phase of the experiment.
Following this procedure, each of the EEG, ECG, and
EMG recordings was divided into six segments, one
referring to each phase and horse. Furthermore, each
segment was further divided into 10 sec segments
with 25% overlap. Then, each sample was labelled as
referring to positive or negative emotion by using the
participants’ interviews to detect keywords about how
they felt during each phase of the experiment. Russel’s
[29] circumplex model of affect was used in order
to associate the expressed felt emotion as negative of
positive, depending on whether it was associated with
negative or positive valence respectively. For example,
if a participant stated that he felt fear during a phase
of the experiment, then the signal segments referring
to this phase were labelled as referring to a negative
emotion. Table I shows all the detected keywords
associated with negative and positive emotion.
This labelling process led to a highly unbalanced
dataset, with 77.08% of the samples referring to positive emotion and only 22.92% of samples referring
to negative emotion. To address this issue and balance
the class ratios within the dataset, samples referring
to positive emotion were randomly discarded while

Accuracy

F1-score

1-NN

0.6528

0.6449

DT

0.7163

0.6943

LDA

0.6667

0.6518

SVM (Linear)

0.7361

0.7170

SVM (RBF)

0.7421

0.7218

the ratio of samples referring to each phase of the
experiment were kept constant. The final balanced
dataset contained 504 samples, with 43.06% of them
belonging to the negative class and 56.94% belonging
to the positive class due to the constraint of maintaining
the ratio of samples referring to each phase of the
experiment.

E. Feature extraction
In this preliminary study, we then attempted to use
statistical features extracted from the ECG recordings
in order to train a machine learning model for detecting
the affective state of the participants during their interaction with the horses. Features extracted from ECG
signals have been shown to correlate with changes in
the affective state of a person [30], [31], [32]. The most
commonly used ECG features are heart rate (HR) and
heart rate variability (HRV) specific parameters in the
time and frequency domain respectively. Rainville et al.
[33] showed that heart rate variability may decrease
with fear, sadness and happiness, while pleasantness
may lead to an increase in the peak heart rate [34].
To this end, HR and HRV features derived from
the recorded signals were computed for use in the
proposed machine learning approach. QRS complexes
and R-peaks within the ECG signals were detected
using the Pan-Tompkins QRS detection algorithm [35]
and the Augsburg Biosignal Toolbox (AuBT) [36] was
used in order to compute 84 statistical features from
each part of the PQRST complexes. The extracted
features were the maxima, minima, mean, median,
standard deviation and range from the raw signal
and the derivative of PQ, QS and ST complexes, the
number of intervals with latency > 50 ms from HRV,
the Power Spectral Density (PSD) from HRV between
the intervals [0, 0.2], [0.2, 0.4], [0.4, 0.6] and [0.6, 0.8],
and the maxima, minima, mean, median, standard
deviation and range from the HRV histogram. The
computed features were then concatenated into a single
feature vector FECG to be used for the classification
experiments.

IV. R ESULTS

Actual

1-NN

Actual

(a)

Decision Tree
Predicted
Positive Negative
Positive
248
39
Negative
104
113
(b)

Linear Discriminant Analysis
Predicted
Positive Negative
Positive
220
67
Negative
101
116
(c)

Actual

V. C ONCLUSION

SVM (Linear)
Predicted
Positive Negative
Positive
251
36
97
120
Negative
(d)

Actual

In this work, the authors proposed an approach for a
quantitative study of the complex emotional response
that horses seem to elicit in humans, using physiological signals. To this end, the proposed quantitative
approach consisted of the use of a portable system that
is able to acquire various physiological signals (EEG,
ECG, EMG) concurrently, while the users interact with
the horses, and store them for further processing. The
proposed system is a fully wireless and portable system
that allows signal acquisition in remote environments
while having a minimal effect on the subjects’ ability
to move. Furthermore, the use of a low cost computing
device (Raspberry Pi) for gathering and storing the
signals further reduces the requirements for power
consumption, while having minimum weight.
The use of statistical features extracted from the
ECG recordings of people interacting with horses was
evaluated in this preliminary study for the task of identifying their emotional responses. Recordings were annotated as referring to positive or negative emotions by
identifying relevant keywords from the video-recorded
interviews of the participants. Supervised classification
experiments showed that the proposed approach is
suitable for identifying the emotional responses elicited
by human-horse interaction, achieving a maximum
classification accuracy of 74.21% and an F1-score
of 72.18% when a Support Vector Machine classifier

Positive
Negative

Predicted
Positive Negative
202
85
90
127

Actual

After constructing the feature vectors for all the
samples in the dataset, supervised classification experiments were conducted in order to examine the suitability of the proposed approach for the task of emotion
recognition during human-horse interaction. Five classification algorithms were used in order to evaluate
the performance of the examined features, namely
Decision Trees (DT), Linear Discriminant Analysis
(LDA), linear Support Vector Machines (SVM), SVM
with the Radial Basis Function (RBF) kernel (γ = 8.9),
and the k-Nearest Neighbour classifier for k = 1.
In order to avoid over-fitting the trained models and
to obtain a fair evaluation of the examined classifiers
performance, a 10-fold cross validation process was
followed. Classification performance for all the classifiers in terms of classification accuracy and the F1score is provided in Table II, whereas the respective
confusion matrices for each examined classification
algorithm are shown in Fig. 3. It is evident that the
SVM classifiers perform better than the 1-NN, the
decision tree, and the LDA classifiers, both in terms of
classification accuracy and the F1-score, with the SVM
with the RBF kernel achieving the highest performance
(74.21% accuracy and 72.18% F1-score).

SVM (RBF)
Predicted
Positive Negative
Positive
255
32
Negative
98
119
(e)

Fig. 3: Confusion matrices for the examined classification algorithms: (a) 1-NN, (b) Decision Trees, (c)
LDA, (d) SVM (Linear), and (e) SVM (RBF).

with the RBF kernel is used. The experimental results
provide evidence about the suitability of the proposed
approach for the task of affect detection for humanhorse interaction.
Future work will include the use of the EEG and
EMG recordings in combination with the ECG recordings in order to examine and evaluate the performance
of a multi-modal approach for the task of affect recognition for human-horse interaction. Furthermore, the
use of neural networks and deep learning techniques

will also be examined in order to increase the classification performance of the proposed approach.
R EFERENCES
[1] J. L. Earles, L. L. Vernon, and J. P. Yetz, “Equine-assisted therapy for anxiety and posttraumatic stress symptoms,” Journal
of traumatic stress, vol. 28, no. 2, pp. 149–152, 2015.
[2] C. M. Holmes, D. Goodwin, E. S. Redhead, and K. L.
Goymour, “The benefits of equine-assisted activities: An exploratory study,” Child and Adolescent Social Work Journal,
vol. 29, no. 2, pp. 111–122, 2012.
[3] C.-C. J. Chen, D. Crews, S. Mundt, and S. D. Ringenbach,
“Effects of equine interaction on eeg asymmetry in children
with autism spectrum disorder: a pilot study,” International
Journal of Developmental Disabilities, vol. 61, no. 1, pp. 56–
59, 2015.
[4] A. Guidi, A. Lanata, P. Baragli, G. Valenza, and E. P. Scilingo,
“A wearable system for the evaluation of the human-horse
interaction: A preliminary study,” Electronics, vol. 5, no. 4,
p. 63, 2016.
[5] H. Hama, M. Yogo, and Y. Matsuyama, “Effects of stroking
horses on both humans’ and horses’ heart rate responses,”
Japanese Psychological Research, vol. 38, no. 2, pp. 66–73,
1996.
[6] I. Robinson, “The human-horse relationship: how much do we
know?” Equine Veterinary Journal, vol. 31, no. S28, pp. 42–45,
1999.
[7] S. Katsigiannis and N. Ramzan, “DREAMER: A database for
emotion recognition through EEG and ECG signals from wireless low-cost off-the-shelf devices,” IEEE Journal of Biomedical and Health Informatics, vol. 22, no. 1, pp. 98–107, Jan
2018.
[8] N. Ramzan, S. Palke, T. Cuntz, R. Gibson, and A. Amira,
“Emotion recognition by physiological signals,” Electronic
Imaging, vol. 2016, no. 16, pp. 1–6, 2016.
[9] S. Wioleta, “Using physiological signals for emotion recognition,” in Human System Interaction (HSI), 2013 The 6th
International Conference on. IEEE, 2013, pp. 556–561.
[10] W. Szwoch, “Emotion recognition using physiological signals,”
in Proceedings of the Mulitimedia, Interaction, Design and
Innnovation. ACM, 2015, p. 15.
[11] W. Benda, N. H. McGibbon, and K. L. Grant, “Improvements in muscle symmetry in children with cerebral palsy
after equine-assisted therapy (hippotherapy),” The Journal of
Alternative & Complementary Medicine, vol. 9, no. 6, pp. 817–
825, 2003.
[12] B. T. Klontz, A. Bivens, D. Leinart, and T. Klontz, “The
effectiveness of equine-assisted experiential therapy: Results
of an open clinical trial,” Society & Animals, vol. 15, no. 3,
pp. 257–267, 2007.
[13] Xenophon and M. H. Morgan, The art of horsemanship. Dover
Publications Inc., 2006.
[14] D. Duarte, The Royal Book of Jousting, Horsemanship, and
Knightly Combat: A Translation Into English of King Dom
Duarte’s 1438 Treatise Livro Da Ensinança de Bem Cavalgar
Toda Sela (The Art of Riding in Every Saddle), A. F. Preto,
Ed. The Chivalry Bookshelf, 2010.
[15] A. De Pluvinel, Le maneige royal, 1969.
[16] A. Podhajsky, The complete training of horse and rider.
Doubleday, 2013.
[17] C. De Kunffy, The ethics and passions of dressage. Half Halt
Press, 1993.
[18] P. Belasik, Exploring Dressage Technique: Journeys into the
Art of Classical Riding. J. A. Allen, 1994.
[19] D. West and D. F. de Bragança, “A systemic approach to eliciting and gathering the expertise of a “knowledge guardian”:
An application of the appreciative inquiry method to the study
of classical dressage,” Systemic Practice and Action Research,
vol. 25, no. 3, pp. 241–260, 2012.
[20] G. P. Boy, Of Women and Horses. BowTie, 2005.

[21] H. E. Elgåker, “The new equine sector and its influence on
multifunctional land use in peri-urban areas,” GeoJournal,
vol. 77, no. 5, pp. 591–613, 2012.
[22] P. D. McGreevy and A. N. McLean, “Roles of learning theory
and ethology in equitation,” Journal of Veterinary Behavior:
Clinical Applications and Research, vol. 2, no. 4, pp. 108–
118, 2007.
[23] M. Hausberger, H. Roche, S. Henry, and E. K. Visser, “A
review of the human–horse relationship,” Applied Animal Behaviour Science, vol. 109, no. 1, pp. 1–24, 2008.
[24] A. Lanata, A. Guidi, G. Valenza, P. Baragli, and E. P. Scilingo,
“The role of nonlinear coupling in human-horse interaction: A
preliminary study,” in Engineering in Medicine and Biology
Society (EMBC), 2017 39th Annual International Conference
of the IEEE. IEEE, 2017, pp. 1320–1323.
[25] A. Lanata, A. Guidi, G. Valenza, P. Baragli, and E. P. Scilingo,
“Quantitative heartbeat coupling measures in human-horse interaction,” in 2016 38th Annual International Conference of the
IEEE Engineering in Medicine and Biology Society (EMBC),
Aug 2016, pp. 2696–2699.
[26] N. A. Badcock, P. Mousikou, Y. Mahajan, P. deLissa,
J. Thie, and G. McArthur, “Validation of the Emotiv EPOC R
EEG gaming system for measuring research quality auditory
ERPs,” PeerJ, vol. 1, p. e38, Feb. 2013. [Online]. Available:
https://doi.org/10.7717/peerj.38
[27] A. Burns, B. R. Greene, M. J. McGrath, T. J. O’Shea, B. Kuris,
S. M. Ayer, F. Stroiescu, and V. Cionca, “SHIMMERTM : A
wireless sensor platform for noninvasive biomedical research,”
IEEE Sensors Journal, vol. 10, no. 9, pp. 1527–1534, Sept
2010.
[28] P. Arnau-Gonzalez, T. Althobaiti, S. Katsigiannis, and
N. Ramzan, “Perceptual video quality evaluation by means of
physiological signals,” in Quality of Multimedia Experience
(QoMEX), 2017 Ninth International Conference on. IEEE,
2017, pp. 1–6.
[29] J. A. Russel, “A circumplex model of affect,” Journal of
Personality and Social Psychology, vol. 39, no. 6, pp. 1161–
1178, 1980.
[30] M. Soleymani, J. Lichtenauer, T. Pun, and M. Pantic, “A multimodal database for affect recognition and implicit tagging,”
IEEE Transactions on Affective Computing, vol. 3, no. 1, pp.
42–55, Jan 2012.
[31] M. K. Abadi, R. Subramanian, S. M. Kia, P. Avesani, I. Patras,
and N. Sebe, “DECAF: MEG-based multimodal database for
decoding affective physiological responses,” IEEE Transactions on Affective Computing, vol. 6, no. 3, pp. 209–222, July
2015.
[32] S. Koelstra, C. Muhl, M. Soleymani, J.-S. Lee, A. Yazdani,
T. Ebrahimi, T. Pun, A. Nijholt, and I. Patras, “DEAP: A
database for emotion analysis ;using physiological signals,”
IEEE Trans. Affect. Comput., vol. 3, no. 1, pp. 18–31, Jan.
2012.
[33] P. Rainville, A. Bechara, N. Naqvi, and A. R. Damasio, “Basic
emotions are associated with distinct patterns of cardiorespiratory activity,” Int J Psychophysiol, vol. 61, no. 1, pp. 5–18,
Jul 2006.
[34] P. J. Lang, M. K. Greenwald, M. M. Bradley, and A. O. Hamm,
“Looking at pictures: affective, facial, visceral, and behavioral
reactions,” Psychophysiology, vol. 30, no. 3, pp. 261–273, May
1993.
[35] J. Pan and W. J. Tompkins, “A real-time QRS detection
algorithm,” IEEE Trans Biomed Eng, vol. 32, no. 3, pp. 230–
236, Mar 1985.
[36] J. Wagner, “Augsburg Biosignal Toolbox (AuBT),” University
of Augsburg, 2005.

