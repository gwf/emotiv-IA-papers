Hindawi
Computational and Mathematical Methods in Medicine
Volume 2020, Article ID 2801015, 10 pages
https://doi.org/10.1155/2020/2801015

Research Article
EEG Signal and Feature Interaction Modeling-Based Eye Behavior
Prediction Research
Pengcheng Ma and Qian Gao
School of Computer Science and Technology, Qilu University of Technology (Shandong Academy of Sciences),
Jinan Shandong 250353, China
Correspondence should be addressed to Qian Gao; qiangao0603@163.com
Received 25 February 2020; Accepted 20 April 2020; Published 16 May 2020
Guest Editor: Yi-Zhang Jiang
Copyright ¬© 2020 Pengcheng Ma and Qian Gao. This is an open access article distributed under the Creative Commons Attribution
License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is
properly cited.
In recent years, with the development of brain science and biomedical engineering, as well as the rapid development of
electroencephalogram (EEG) signal analysis methods, using EEG signals to monitor human health has become a very popular
research Ô¨Åeld. The innovation of this paper is to analyze the EEG signal for the Ô¨Årst time by building a depth factorization
machine model, so that on the basis of analyzing the characteristics of user interaction, we can use EEG data to predict the
binomial state of eyes (open eyes and closed eyes). The signiÔ¨Åcance of the research is that we can diagnose the fatigue and the
health of the human body by detecting the state of eyes for a long time. On the basis of this inference, the proposed method can
make a further useful auxiliary support for improving the accuracy of the recommendation system recommendation results. In
this paper, we Ô¨Årst extract the features of EEG data by wavelet transform technology and then build a depth factorization
machine model (FM+LSTM) which combines factorization machine (FM) and Long Short-Term Memory (LSTM) in parallel.
Through the test of real data set, the proposed model gets more eÔ¨Écient prediction results than other classiÔ¨Åer models. In
addition, the model proposed in this paper is suitable not only for the determination of eye features but also for the acquisition
of interactive features (user fatigue) in the recommendation system. The conclusion obtained in this paper will be an important
factor in the determination of user preferences in the recommendation system, which will be used in the analysis of interactive
features by the graph neural network in the future work.

1. Introduction
The electrical activity of the cerebral cortex is recorded by
detecting electrodes, and the potential amplitude is taken as
the vertical axis and the time as the horizontal axis to form
a map that can reÔ¨Çect the spontaneous and rhythmic electrical activity of diÔ¨Äerent parts of the brain with time, which is
called EEG [1]; its full name is electroencephalogram. In
1924, Hans Bergen, a German psychiatrist, Ô¨Årst discovered
and recorded the regular electrical activity of the human
brain [2]. In 1933, Berger‚Äôs research was aÔ¨Érmed by the
famous British physiologist E.D. Adrian. Since then, EEG
has developed rapidly, and the detection methods which
include multilead regular electroencephalogram (spontaneous EGG and evoked EGG), sleep EEG, dynamic EEG, video
EEG, and other detection methods have occurred [3‚Äì5]. The

structure of the human brain is very complex and sophisticated. From the microscopic point of view, it is mainly composed of billions of neurons. The EEG signal consists of two
parts, one is the pyramidal neurons in the cortex and the
other one is the postsynaptic potential diÔ¨Äerence of the vertical dendrites. The bioelectric signal of the central nervous
system is used to transmit, store, and process various physiological activity information, so as to control the human
behavior [6]. As an action related to EEG, the eye state (open
and close eyes) can be identiÔ¨Åed by observing the characteristic changes of EEG signals.
As the key technology of brain computer interface (BCI),
EEG can be applied in Ô¨Åve stages [7]. Among them, there are
three important contents for signal processing, which are the
preprocessing, feature extraction, and classiÔ¨Åcation of the
EEG signal; all above have been widely studied [8, 9]. As early

2
as the end of the 19th century, British physiologist Richard
Caton took the lead in using a galvanometer to capture the
weak current signal on the surface of the animal‚Äôs cerebral
cortex [10]. Through the study of the captured electrical signals of animals, the researchers found that in the state of
quiet without external stimulation, the captured current signal waveform showed rhythmic oscillation. In recent years,
with the development of computer science and technology,
advanced technologies such as X-ray electronic computed
tomography and positron emission computed tomography
have been introduced in EEG research [11]. EEG is also commonly used to monitor a patient‚Äôs sleep, anesthesia depth,
and fatigue. This article is to monitor the state of eyes (fatigue
degree) through EEG.
A large number of scholars are trying to detect the fatigue
state through EEG. The intelligent transportation laboratory
(University of Pennsylvania) and NHTSA [12] use a brain
wave tester and head motion detector to test and analyze
the EEG and eye characteristic parameters of the driver
under a fatigue state and Ô¨Ånally determine PERCLOS (ratio
of cumulative time of eye closure to unit time) as the test
index of the driver‚Äôs physiological fatigue degree evaluation.
Bergasa et al. [13] (Australia) tested several nondrivers, and
based on the changes of the brain wave in a nonfatigue state,
they further analyzed the characteristics of brain wave
changes in Ô¨Åve stages of nonfatigue, near fatigue, moderate
fatigue, doze, and antifatigue (wake up from fatigue).
Yoshihiro Takei et al. (Japan University of Technology,
Zhipu) obtained the steering angle signal of drivers when
turning in the process of driving simulation on the basis of
the simulation experiment test. They Ô¨Årst processed the steering angle signal with the help of Fourier transform theory and
wavelet theory. Then, they determined the wavelet transform
value of the steering angle signal of drivers in diÔ¨Äerent mental
states by using nonlinear theory (chaos theory), so as to judge
the driver‚Äôs fatigue level. Finally, the fast transform algorithm
(FFT, fast wavelet transform) is discussed to realize the
real-time evaluation of driver fatigue state. According
to four kinds of typical brain waves (Œ¥ wave, frequency is
1-3.5 Hz; Œ± wave, frequency is 7.5-12.5 Hz; Œ≤ wave, frequency
is 12.5-30 Hz; and Œ∏ wave, frequency is 3.5-7.5 Hz) and their
changes, we can reÔ¨Çect people‚Äôs mental state. Relevant
research shows that the change of Œ± wave is the best reÔ¨Çection
of human fatigue [14]. W-Bang et al. collected four kinds of
typical brain waves, obtained the corresponding brain wave
entropy using the thermodynamic entropy theory, and evaluated the fatigue degree of drivers according to the change
of the calculated value [15]. Yan et al. [16] conducted experimental tests with the KT98-2000A dynamic electroencephalograph. First, the driver (healthy, not taking any irritating
drugs) under nonfatigue and fatigue states was collected to
engage in various driving operations (starting, shifting, controlling brain waves during movement, steering‚Ä¶). Next,
the power spectrum is obtained, and the power spectrum
density estimates of various brain waves are calculated.
Finally, the average power spectral density ratios of four typical brainwaves when the driver performs various driving
operations such as starting, shifting, braking, and steering
under nonfatigue and fatigue conditions are obtained.

Computational and Mathematical Methods in Medicine
Most of the research mentioned above are to judge the
fatigue state of the human body by directly recognizing the
characteristics of EEG. In this paper, the feature data is
extracted from EEG by wavelet transform technology,
and then, the eye state is predicted by a classiÔ¨Åcation algorithm, compared with traditional classiÔ¨Åcation algorithms,
k-nearest neighbor algorithm [17‚Äì19], naive Bayes algorithm
[20‚Äì22], artiÔ¨Åcial neural network (ANN) [23], and linear
discriminant analysis [24‚Äì27]. In this paper, we build a
FM+LSTM model to predict the eye state. The model is combined with the linear interaction characteristics of FM and
the nonlinear interaction characteristics of LSTM. It can
greatly improve the accuracy of eye state classiÔ¨Åcation and
prediction. On the basis of this research, we can also infer
the fatigue degree of the human body by monitoring the
eye state of the human body for a long time, which can help
us to recommend user behavior. For example, it can help us
to detect whether the user is in the state of work overload
in working time or not by combining the proposed eye state
classiÔ¨Åcation prediction method and our previous interaction
characteristic research results. Meanwhile, it can also help us
to detect whether the fatigue state of users is caused by nonworking reasons in nonworking time or not. Thus, more
accuracy user behavior recommendations can be got.

2. Related Work
The purpose of this paper is to predict the eye state (open and
closed eyes) by EEG data, which is a typical binary classiÔ¨Åcation problem. Because the traditional binary classiÔ¨Åcation
has many shortcomings in some aspects, and its performance
is poor, we use the FM algorithm which is widely used in the
click rate prediction of recommendation system, as well as a
good binary classiÔ¨Åcation algorithm. The advantages of the
FM algorithm are as follows: (1) FM model can carry out reasonable parameter trajectory in very sparse data; (2) the complexity of the FM model is linear, the optimization eÔ¨Äect is
good, and it does not need to rely on a support vector like
support vector machines (SVM); and (3) FM is a general
model, which can be used in any case where the eigenvalue
is real. Other factorization models can only be used in some
cases where the input data is relatively Ô¨Åxed. In addition,
we also use LSTM, which is a deep network model with good
generalization ability and nonlinear mapping ability. Compared with the recurrent neural network, LSTM solves the
gradient explosion problem; therefore, LSTM is a strong classiÔ¨Åcation prediction model.
In the experimental part of this paper, after extracting the
corresponding features through wavelet transform technology, one hot coding processing is carried out on these data,
which will not only increase the number of input data but
also generate a large number of sparse data (a large number
of zero data appears in the data set). According to the idea
of integrated learning, referring to the DeepFM [28] model
(a highly eÔ¨Écient click rate prediction model of recommendation system), we integrate FM and LSTM in parallel, and
the FM+LSTM model is constructed, which has the characteristics of automatic low-order feature combination, linear
data connection, and sparse matrix friendliness. LSTM can

Computational and Mathematical Methods in Medicine

3

ht-1

ht

Ct‚Äì1

Ct
tanh

ft

it

ot
~
Ct

ùúé

ht‚Äì1

Xt‚Äì1

ùúé

tanh

ùúé

ht

Xt

Figure 1: Internal structure of LSTM.

solve the gradient explosion problem and has the characteristics of achieving high-order feature combination and nonlinear mapping. In addition, EEG data is obtained from
sequential testing in a time series, which is very suitable for
the prediction and classiÔ¨Åcation of long-term and shortterm memory models. Therefore, the proposed depth factorization machine model is suitable for two classiÔ¨Åcation
problems that determine eye behavior. The depth factorization machine model combines the advantages of FM and
LSTM, and it is also applicable to two classiÔ¨Åcation problems
for judging the eye state. In the following section, we will
introduce the FM model and the LSTM model brieÔ¨Çy.
2.1. Introduction to FM. The factorization machine is a new
model proposed by Rendle in 2010, which uses the idea of
the implicit factor model and matrix decomposition for reference [29]. The problem of data sparsity can be overcome
to some extent by using the idea of matrix decomposition
to solve the optimal quadratic parameters. At present, many
implicit factor models have been used for rating prediction in
recommended Ô¨Åelds, such as the common matrix decomposition, and the representative algorithm is singular value
decomposition [30]. The main disadvantage of these algorithms is that they are only suitable for speciÔ¨Åc input data
types, and the optimization algorithm is only proposed for
the current task, which does not have generality. In diÔ¨Äerent
task scenarios, they cannot be directly migrated and extended
horizontally. The factorization machine model is a general
model, which can change the shortcomings of a traditional
matrix decomposition algorithm. The FM only needs to
change the form of the input eigenvector to simulate the
common matrix decomposition model, while the traditional
matrix decomposition model has to deÔ¨Åne model expression
and optimization method separately for each speciÔ¨Åc task.
Therefore, FM eÔ¨Äectively avoids this kind of malpractice.
2.2. Introduction of LSTM. Because the artiÔ¨Åcial neural network can model the nonlinear process, it can solve a series
of complex problems such as classiÔ¨Åcation, clustering,
dimensionality reduction, regression, and structural predic-

tion. With the revolution of the computer industry, the
exponential improvement of computer computing power,
and the explosive growth of data in recent years, the
deep-seated artiÔ¨Åcial neural network which needs a lot of
computing power has been widely used. From the most
classical perceptron, there are many kinds of neural network models. The typical models are the Convolutional
Neural Network (CNN), recurrent neural network (RNN),
and RNN variant LSTM. DiÔ¨Äerent neural network models
have diÔ¨Äerent scenarios.
As mentioned above, the cyclic neural network or RNN is
a kind of neural network for processing sequence data [31].
The network structure of LSTM was proposed by Hochreiter
and Schmidhuber in 1997 [32], and then, this kind of network became very popular. Many people solved many practical problems based on the network structure of LSTM,
and now, LSTM is still widely used. The recurrent neural network is a chain loop structure, and the network structure of
LSTM is basically the same structure, but LSTM has a more
complex structure in the network; therefore, it can deal with
long-term dependence. LSTM has three gates to control,
which are input gate, forgetting gate, and output gate. The
input gate controls the input of the network, the forgetting
gate controls the memory unit, and the output gate controls
the output of the network. The most important one is
the forgetting gate. The function of the forgetting gate is
to decide which memories will be preserved and which
memories will be forgotten. It is precisely because the
function of forgetting gate ‚ÄúLSTM‚Äù has a long-term memory function. For a given task, the forgetting gate can be
used to learn how many previous memories it can retain,
which makes the network have the ability of learning
autonomously without human interference.
The following explains the network Ô¨Çow process of LSTM
from the speciÔ¨Åc internal structure. The internal structure of
the LSTM is shown in Figure 1. Next, we will explain their
internal operation mode and how to represent the three gates
mentioned above.
Input gate it controls how much information can Ô¨Çow
into memory cells. Forgetting gate f t controls how much

4

Computational and Mathematical Methods in Medicine

information in the memory cells of the last moment can be
accumulated into the memory cells of the current moment.
Output gate ot controls how much information in the memory cells of the current time can Ô¨Çow into the current hidden
state ht .
Step one: use the forgetting gate to decide what information to discard from the cell state and calculate the attenuation coeÔ¨Écient. Read ht‚àí1 and xt and output a value
between 0 and 1 to each number in cell loading C t‚àí1 . This
determines what information we discard from the state of
the cell. Since the output of sigmoid is 0 to 1, 1 indicates ‚Äúfull
reservation‚Äù and 0 indicates ‚Äúcomplete abandonment.‚Äù
Step two: update the information. First, the sigmoid layer
is the ‚Äúinput gate layer,‚Äù which determines what value we will
update. Then, the tanh layer creates a new candidate vector.
Step three: update the time of old cell status C t‚àí1 , which is
updated to Ct .
Step four: the output gate decides what value to output.
The output at this time is calculated according to the Ct state
of the third part.
2.3. Methodology and Contribution. The research content of
this paper is to detect the eye state (open eyes, closed eyes)
through EEG data. The purpose is to detect the eye state for
a long time, so as to diagnose the fatigue and health status
of individuals. In fact, this is a two classiÔ¨Åcation problem.
SpeciÔ¨Åcally, in this paper, we extract feature data from EEG
by wavelet transform technology and then build a FM+LSTM
model to classify and predict the eye state. This model combines the linear interaction characteristics of FM and the
nonlinear interaction characteristics of LSTM, which can
greatly improve the classiÔ¨Åcation eÔ¨Éciency. The main contributions of this paper can be summarized as follows:
(1) The feature is extracted from EEG by wavelet
transform:

EEG image data set

Feature extraction using wavelet
transform

Build FM+LSTM model

Predicting eye state

Figure 2: The framework of the proposed method.

nation, linear data connection, and sparse matrix
friendliness. LSTM can be used to solve the problem
of gradient explosion and realize high-order feature
combination and nonlinear mapping, which is suitable for the classiÔ¨Åcation and prediction of eye
behavior in this paper

(3) In this paper, the model is tested on the real data set,
and through the comparison of the experimental
results, it is found that the FM+LSTM model established in this paper has better classiÔ¨Åcation and prediction eÔ¨Éciency than other classiÔ¨Åcation models

3. EEG Signal-Based FM+LSTM Model
(i) The Ô¨Årst-order low-frequency signal features of EEG
data are obtained by wavelet transform [33], and
there are 14 EEG values
(ii) The extracted data features are used as the basis for
our classiÔ¨Åcation and prediction

(2) Build a FM+LSTM model to classify and predict the
eye state:

(i) This model is the Ô¨Årst that we have established and
applied to the study of eye behavior classiÔ¨Åcation
and prediction based on EEG
(ii) The model is composed of FM and short-term memory neural network in a parallel form, which combines the advantages of both models with the
characteristics of automatic low-order feature combi-

3.1. Theoretical Framework. In the experimental part of this
paper, we will Ô¨Årst introduce the theoretical framework of
the experimental content, as shown in Figure 2.
3.2. Feature Extraction of EEG by Wavelet Transform. The
EEG signal is a nonlinear and nonstationary random weak
signal, with a relatively weak amplitude. Generally, the
amplitude of the EEG signal is not more than 300 ŒºV. Continuous wavelet transform (CWT) [33‚Äì36] essentially convolutes the EEG signal with the translation dilation wavelet
weight function with localization in a time and frequency
domain, so as to decompose the signal into various components in diÔ¨Äerent times or frequency. Let the signal f √∞t√û of
EEG be the square integrable function, which is recorded as
f √∞t√û ‚àà L2 √∞R√û. Convolute the EEG signal f √∞t√û with the mother
wavelet function, and call Equation (1) the continuous wavelet transform of the EEG signal f √∞t√û:




‚àí1/2

WT f √∞a, œÑ√û = f √∞t √û, œàa,œÑ √∞t √û = a

√∞



t‚àíœÑ
dt: √∞1√û
f √∞t √ûœà
a
R

Computational and Mathematical Methods in Medicine

5

In the above formula, WT f √∞a, œÑ√û is the wavelet coeÔ¨Écient
of the EEG signal, scale a controls the expansion and contraction of wavelet function, and translation amount œÑ controls
the translation of wavelet function. The scale corresponds
to frequency (inverse ratio), and translation œÑ corresponds
to time.
_
If the Fourier transform œà√∞w√û of the parent wavelet function satisÔ¨Åes the constant resolution constraint
√∞‚àû
Cœà =

0

j œà √∞ w√û j 2
dw < ‚àû,
w

√∞2√û

then there is a reconstruction formula for the continuous
wavelet transform of the EEG signal, and its expression is
shown in
f √∞t √û =

1
Cœà

√∞‚àû
0

da
a2

√∞



1
t‚àíœÑ
dœÑ:
WT x √∞a, œÑ√û pÔ¨ÉÔ¨ÉÔ¨É œà
a
a
R

√∞3√û

In the above formula, C œà is the permissive condition of
œà√∞t√û and WTx √∞a, t√û is the wavelet transform coeÔ¨Écient. Since
the wavelet base has two parameters of scale and displacement, the expansion of the wavelet base means that onehour function is projected on the two-dimensional timescale phase plane. And because of the characteristics of the
basic body of wavelet, the function projection to wavelet
transform is conducive to extract some features.
Because of the invariable window and the excellent characteristics of local analysis, the characteristics of the EEG signal in diÔ¨Äerent frequencies can be analyzed by wavelet
transform in diÔ¨Äerent time scales.
3.3. FM+LSTM Model Construction Method. For a classiÔ¨Åcation and prediction system, it is very important to learn the
EEG feature combination behind the real eye state. Among
the features extracted from EEG, low-order combined
features (including one-dimensional and two-dimensional
feature data) or high-order combined features (multidimensional feature data) may aÔ¨Äect the Ô¨Ånal classiÔ¨Åcation and prediction results. Considering the disadvantages of traditional
classiÔ¨Åcation methods, it includes the following:
(1) The decision tree model easily leads to overÔ¨Åtting and
ignores the correlation between data
(2) The random forest model is prone to overÔ¨Åtting
when the data noise is large
(3) The logistic regression model cannot combine features and depends on artiÔ¨Åcial feature combination
(4) The prediction process of the SVM model depends
on the support vector in the training sample
We can see that the traditional classiÔ¨Åcation algorithm
cannot complete the classiÔ¨Åcation task well, and therefore,
we use the FM in this paper. The factorization machine
model extracts the feature combination through the implicit
variable inner product of each one-dimensional feature,

which can extract the combined feature actively, keeps independent of the training sample but not rely on the support
vector, and will not easily be aÔ¨Äected by the noise data and
appear the phenomenon of overÔ¨Åtting. However, in theory,
FM can model higher-order feature combinations; in fact,
only the second-order feature combination is used because
of the complexity of calculation. In this paper, we solve the
problem of high-order feature combination by multilayer
neural networks which can learn the nonlinear complex relationship. We further use LSTM, which is a variation of RNN.
LSTM contains the characteristics of a traditional neural network which is composed of the input layer, hidden layer, and
output layer. LSTM also inherits all the advantages of RNN.
It can adjust the parameters through back propagation.
Moreover, LSTM can make the neurons in the hidden layer
communicate with each other and establish the connection
between the characteristic data. Not only that, the LSTM also
solves the problem that the circulating neural network is
prone to gradient explosion. Therefore, the LSTM contains
the advantages of many neural networks, and its performance has been improved. And it also has a good performance in the classiÔ¨Åcation problem.
Based on the advantages of the FM model and LSTM, we
build the FM+LSTM model on the basis of the DeepFM [28]
model to solve the classiÔ¨Åcation problem. It eÔ¨Äectively combines the advantages of FM and LSTM in feature learning:
It can extract low-order combined features and high-order
combined features at the same time. In the FM+LSTM
model, we use a parallel approach to build our depth factorization machine model. Through the depth factorization
machine model, on the one hand, FM can be used to extract
the features from the Ô¨Årst-order features and second-order
features which are by the combination of the pair Ô¨Årstorder features; on the other hand, LSTM can be used to
extract features from the higher-order features which is
formed by the input Ô¨Årst-order features. SpeciÔ¨Åcally, the
characteristics of the FM+LSTM model include
(1) being able to process sparse data
(2) combining the FM model and the LSTM model,
learning low-order feature combination and highorder feature combination at the same time
To sum up, we explained the principle of the FM+LSTM
model and the advantages of the model. Next, we will show
the mathematical principle of the model.
First, we use the FM [29]. The second-order expression of
the algorithm is shown in
n

n

n

y√∞x√û = w0 + „Ä† wi xi + „Ä† „Ä† wij xi x j ,
i=1

√∞4√û

i=1 j=i+1

where n represents the feature dimension, xi represents the
feature value of the Ô¨Årst feature, and wi and wij are the coefÔ¨Åcients of the primary term and the secondary term of the
factorization machine model, respectively. A symmetric
matrix w is composed of all the parameters wij of quadratic

6

Computational and Mathematical Methods in Medicine

terms. At this time, the matrix can be decomposed into the
following forms: w = vT v, where the ith column of v is the
corresponding vector expression of the ith feature, and at
this time, the coeÔ¨Écient of quadratic terms can be expressed
as the inner product of two vectors, namely, wij = hvi , v j i. In
this case, the expression of the second-order model is as
shown in
n
n
n


yFM = w0 + „Ä† wi xi + „Ä† „Ä† vi , v j xi x j ,
i=1

√∞5√û

i=1 j=i+1

When updating the old cell status, C t‚Äê1 is updated to Ct .
The calculation formula is shown in
~t:
C t = f t ‚àó C t‚àí1 + it ‚àó C

Use the output gate to decide what value to output. The
output at this time is calculated according to the C t state of
the third part. The calculation process is shown in
Ot = œÉ√∞W o ¬Ωht‚àí1 , xt  + bo √û,
H t = Ot ‚àó tanh √∞C t √û:

where vi is the vector expression of the ith feature k, dimension k, and <¬∑, ¬∑ > is the vector dot product. At this time, the
coeÔ¨Écients of the quadratic terms xh xi and xi x j are no longer independent. SpeciÔ¨Åcally, the coeÔ¨Écients of xh xi and xi
x j are <xh , xi > and <xi , x j >, which have the same term vi .
Then, all the samples with nonzero feature combination of
xi can be used to learn vi .
In the LSTM model [32], the output is controlled by the
forgetting gate, input gate, and output gate. The forgetting
gate is used to determine what information is discarded from
the cell state, and the attenuation coeÔ¨Écient is calculated as
shown in formula (6). Read ht‚àí1 and xt , and output a value
between 0 and 1 to each number in cell loading C t‚àí1 . This
determines what information we discard from the state of
the cell. Since the output of sigmoid is 0 to 1, 1 indicates ‚Äúfull
reservation‚Äù and 0 indicates ‚Äúcomplete abandonment‚Äù:


f t = œÉ W f ‚ãÖ ¬ΩH t‚àí1 , xt  + b f :

√∞6√û

In the above formula, W f is the weight value, t is the
number of input data, t is the range of t = f0, 1, ‚ãØ, Tg, xt is
the tth input data, H t‚àí1 is the output result of t‚Äê1 neuron,
b f is the deviation value, and œÉ√∞‚ãÖ√û is the activation function
sigmoid, which is deÔ¨Åned as shown in
f √∞x √û =

1
:
1 + e‚àíx

√∞7√û

Use the input gate to decide what value we are going to
update. Then, the tanh layer creates a new candidate vector.
The calculation equation is as follows:
it = œÉ√∞W i ‚ãÖ ¬Ωht‚àí1 , xt  + bi √û,
~ t = tanh √∞W c ‚ãÖ ¬Ωht‚àí1 , xt  + bc √û:
C

√∞8√û

In the above formula, œÉ√∞‚ãÖ√û is the activation function sigmoid, W i and W o are weight values, bi and bo are deviation
values, and tanh √∞‚ãÖ√û is the activation function. Its deÔ¨Ånition
is as shown in
f √∞x√û =

1 ‚àí e‚àí2x
:
1 + e‚àí2x

√∞9√û

√∞10√û

√∞11√û

In the above formula, œÉ√∞‚ãÖ√û is the activation function sigmoid, W o is the weight value, and bo is the deviation value.
The output results of each nerve unit can be obtained
through the above steps. Finally, the output results of the
neuron (the tth) can be obtained under the eÔ¨Äect of output
and transmission of diÔ¨Äerent cycle units:
yLSTM = œÉ√∞W t ‚ãÖ H t + bt √û:

√∞12√û

In the above formula, œÉ√∞‚ãÖ√û is the activation function sigmoid, W t is the weight value, and bt is the deviation value.
Finally, we combine the output of FM and LSTM to get
the prediction results as shown in
yprediction = sigmoid√∞yFM + yLSTM √û:

√∞13√û

We use logloss as the loss function of the depth factor
decomposition machine model constructed in this paper,
and then use gradient optimization algorithm to adjust the
parameters, and Ô¨Ånally get the optimal parameters.
We have introduced the mathematical principle of the
depth factor decomposition machine model in detail. Next,
we will show the overall Ô¨Çow chart of building the FM+LSTM
model, as shown in Figure 3.

4. Experiment and Execution Results
4.1. ClassiÔ¨Åed Forecast. In the task of classiÔ¨Åcation and prediction, we compare the eÔ¨Äect of the model used in this paper
with the following benchmark models.
(1) Decision Tree (DT) Algorithm [37]. It is a method of
approaching the value of discrete function, which is
a typical classiÔ¨Åcation method. Firstly, the data is
processed, the readable rules and decision trees are
generated by using an induction algorithm, and then
the new data is analyzed by using decision. In
essence, the decision tree is a process of data classiÔ¨Åcation through a series of rules.
(2) Random Forest (RF) Algorithm [38]. Random forest
is an algorithm that integrates multiple trees through
the idea of integrated learning. Its basic unit is the
decision tree, and its essence belongs to a big branch
of machine learning‚Äîensemble learning method.

Computational and Mathematical Methods in Medicine

7
Table 1: ClassiÔ¨Åcation prediction results of various methods.

yprediction = sigmoid (yFM + yLSTM)

FM

Algorithm/model
DT
RF
LR
SVM
FM
LSTM
FM+LSTM

LSTM
FM+LSTM
model
Dense embeddings

Accuracy

Precision

Recall

F1-measure

0.82
0.88
0.64
0.56
0.76
0.89
0.93

0.82
0.88
0.64
0.59
0.80
0.90
0.94

0.82
0.88
0.62
0.50
0.71
0.82
0.90

0.82
0.88
0.63
0.54
0.75
0.86
0.92

One hot coding of features

Feature extraction by wavelet
transform

EEG image data set

Figure 3: Overall Ô¨Çow chart of the FM+LSTM model.

(3) Logistic Regression (LR) Algorithm [39]. It is used to
deal with the regression problem when the dependent
variable is classiÔ¨Åed variable. The common problem
is the binomial or binomial distribution problem. It
can also deal with the multiclassiÔ¨Åcation problem.
In fact, it belongs to a classiÔ¨Åcation method.
(4) Support Vector Machines [40]. SVM Ô¨Ånds a hyperplane to divide the data into one class and other classes, which is a two-class classiÔ¨Åcation model. The
separation interval is the largest and diÔ¨Äerent from
the perceptron.
4.2. Prediction Scheme. In order to evaluate the prediction
eÔ¨Éciency of the classiÔ¨Åcation prediction task, we use common evaluation indicators: accuracy, precision, recall, and
F1-measure. SpeciÔ¨Åcally, the deÔ¨Ånitions of accuracy, precision, recall, and F1-measure are as follows [26]:
TP + TN
,
TP + TN + FN + FP
TP
,
Precision =
TP + FP
TP
,
Recall =
TP + FN
2 √ó Recall √ó Precision
F1‚ÄêMeasure =
:
Recall + Precision
Accuracy =

√∞14√û

TP is the number of correctly recognized closed eyes, FP
is the number of incorrectly recognized closed eyes, TN is the
number of correctly recognized open eyes, and FN is the
number of incorrectly recognized open eyes. The accuracy
rate is the ratio of the number of samples correctly classiÔ¨Åed
by the classiÔ¨Åer to the total number of samples in a given test

data set, the accuracy is the ratio of the number of correctly
predicted samples in all predictions, the recall rate is the correctly predicted positive samples in all actual prediction proportion, and the F1-measure is the harmonic average of the
exact value and the recall rate. These four evaluation schemes
help us compare the eÔ¨Éciency of diÔ¨Äerent classiÔ¨Åcation
models in the EEG data set for eye behavior prediction, and
the bigger the results of the four evaluation methods, the
closer the prediction results to the actual situation.
In this paper, the accuracy, precision, recall rate, and
F1-measure are used to evaluate the prediction eÔ¨Éciency
of diÔ¨Äerent models. They are all classic evaluation methods
of binary prediction which are suitable for the eye behavior (open and close eyes) classiÔ¨Åcation prediction based on
EEG data. Among them, accuracy is the ratio of the number of samples correctly classiÔ¨Åed by the classiÔ¨Åer to the
total number of samples in a given test data set, accuracy
is the proportion of the number of samples correctly predicted as positive in all predictions, recall rate is the proportion of samples correctly predicted as positive in all actual
predictions, and F1-measure is the harmonic average of the
accuracy and recall rate. These four evaluation schemes help
us to compare the eÔ¨Éciency of diÔ¨Äerent classiÔ¨Åcation models
in EEG data set for eye behavior prediction, and the bigger
the results of the four evaluation methods, the closer the prediction results to the actual situation.
4.3. Comparison of ClassiÔ¨Åed Prediction Results. The following table is the classiÔ¨Åcation prediction performance of the
model used in this paper and other benchmark models on
the EEG_EYE data set, and the speciÔ¨Åc results are shown in
Table 1.
As shown in Table 1, we sorted out the classiÔ¨Åcation and
prediction results of various classiÔ¨Åers on the EEG data set. In
order to compare the eÔ¨Äects of various classiÔ¨Åer models more
intuitively, we drew a histogram as shown in Figure 4.
In the traditional classiÔ¨Åcation prediction model, the logical regression model has the advantages of easy use and
understanding but has the disadvantages of not being able
to extract the combination features actively; the decision tree
model has the advantages of not being sensitive to the missing value and not being able to process the data type and
the conventional type attributes at the same time but has
the disadvantages of low antioverÔ¨Åtting ability and being easily disturbed by the noise data; the random forest model has
the advantages of strong antioverÔ¨Åtting ability and balance

8

Computational and Mathematical Methods in Medicine
Accuracy

Precision

1

1

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
DT

RF

LR

SVM

FM

DT

LSTM FM+LSTM

RF

LR

Recall

SVM

FM

LSTM FM+LSTM

FM

LSTM FM+LSTM

F1-measure

1

1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0

0
DT

RF

LR

SVM

FM

LSTM FM+LSTM

DT

RF

LR

SVM

Figure 4: Histogram of prediction results of each classiÔ¨Åcation model.

error, but it is also vulnerable to the interference of noise
data; the support vector machine model has the advantages
of Ô¨Ånding the global minimum value through the convex
optimization method, but it has the disadvantages of relying
too much on support vector and processing large-scale
training data; the factorizer model has the advantages of
high learning eÔ¨Éciency and processing large-scale sparse
data, but it has the disadvantages of only extracting the
second-order feature combination; the LSTM model has
the advantages of processing large-scale sparse data and
solving the problem of long sequence dependence, but it
can only extract the high-order feature combination and
cannot combine the high-order feature with the low-order
feature.
SpeciÔ¨Åcally, by combining the classiÔ¨Åcation results of
Table 1 and Figure 2, we can get the following conclusions:
(1) In the test set of EEG_EYE data, the overall classiÔ¨Åcation eÔ¨Äect of the factorization machine model is better than that of the logistic regression model and the
support vector machine model; this shows that the
factorization model has the characteristics of extracting the combined features actively and the characteristics of keeping independent of training samples,
which makes it better than the above logistic regression model and support the vector machine model
in classiÔ¨Åcation and prediction results

(2) In the test set of EEG_EYE data, the overall classiÔ¨Åcation eÔ¨Äect of LSTM is better than that of the decision
tree model and random forest model, which shows
that the LSTM has no serious overÔ¨Åtting linearity
due to the noise interference in the test set, and therefore, the classiÔ¨Åcation and prediction eÔ¨Äect is better
than the other two classiÔ¨Åcation models
(3) In the test set of EEG_EYE data, the model of FM
+LSTM is better than other models in classiÔ¨Åcation
and prediction. This is because the model can extract
low-order combined features and high-order combined features at the same time, which makes up for
the disadvantage that LSTM can only extract highorder feature combinations
In summary, the FM+LSTM model established by us can
not only extract the combined features actively but also
reduce the noise interference on the simulation. In addition,
it can extract both low-order combined features and highorder combined features; therefore, its performance is better
than other models.

5. Future Work
In this paper, we established a FM+LSTM model to predict
the eye behavior (open or close eyes) of the user by EEG data,

Computational and Mathematical Methods in Medicine
so as to infer whether the user is in a fatigue state. Simulation
results show that the proposed method achieved good classiÔ¨Åcation and prediction results. The direct signiÔ¨Åcance of this
work is that we can judge whether the user is in the fatigue
state through the EEG data. Furthermore, the fatigue state
is also an important feature of the user in the recommendation system, which can aÔ¨Äect the user‚Äôs preference and evaluation of the items. Therefore, in the future work, Ô¨Årst, we plan
to further study the user‚Äôs preference and evaluation of the
diÔ¨Äerent items based on the proposed research achievement
of the eye‚Äôs fatigue state which is an important feature factor
related to the context, so as to improve the eÔ¨Éciency of
recommendation. Second, we plan to use the attention
mechanism to distinguish the inÔ¨Çuence of various features
on eye behavior, so as to enhance the interpretability of
the classiÔ¨Åcation prediction result. In addition, based on the
research results of this paper, we plan to further use the graph
neural network model to study the complex interaction
between diÔ¨Äerent features in a more Ô¨Çexible and clearer
way, so as to obtain more eÔ¨Écient and more accurate recommendation results.

6. Conclusions
The purpose of this paper is to predict the eye state (open and
closed eyes) by EEG data, which is a typical dichotomous
problem. The signiÔ¨Åcance of this study is to diagnose the
fatigue and the health of the eyes by detecting the eye state
for a long time. And on the basis of this research, we can also
infer the fatigue degree of the human body by monitoring the
eye state of the human body for a long time, so that we can
help in user behavior recommendation based on this inferential. Firstly, we use wavelet transform technology to extract
the features of EEG, and then, we use a classiÔ¨Åer to classify
and predict. Because the traditional binary classiÔ¨Åcation has
many shortcomings in some aspects, and its performance is
poor, we use the FM algorithm which is widely used in the
click rate prediction of the recommendation system and
binary classiÔ¨Åcation algorithm. In addition, we also use
LSTM, which is a deep network model with good generalization ability and nonlinear mapping ability. According to the
idea of integrated learning, referring to the DeepFM [28]
model (a highly eÔ¨Écient prediction model of click through
rate of the recommendation system), we integrate FM and
LSTM in parallel and build the FM+LSTM model, which
combines the advantages of FM and LSTM and is suitable
for the two classiÔ¨Åcation problems of the eye state in this
paper. And its performance in real data set is better than
other classiÔ¨Åer models. Through this research, we can also
infer the fatigue degree of the human body by monitoring
the eye state of the human body for a long time, so that we
can help in user behavior recommendation based on this
inference, which will be the focus of our next research. In this
paper, the FM+LSTM model is established to solve the problem of eye behavior classiÔ¨Åcation and prediction. The conclusion obtained in this paper will be an important factor in the
determination of user preferences in the recommendation
system, which will be used in the analysis of interactive features by the graph neural network in the future work.

9

Data Availability
The data set used in this experiment is collected by Oliver
rothler from Germany, Stuttgart and Baden Wurttemberg
state cooperative University (DHBW). The data set is composed of EEG value and a value indicating eye state, which
belongs to the Ô¨Åeld of life medicine. All the data are the result
of continuous EEG measurement with Emotiv. The measurement duration is 117 seconds. During the EEG measurement,
the eye state is detected by the camera, and then manually
added to the Ô¨Åle after analyzing the video frame. "1" means
that the eyes are closed, and "0" means that the eyes are open.
For more information about the data, please visit: http://
archive.ics.uci.edu/ml/datasets/EEG+eye+state.

Conflicts of Interest
The authors declare that there is no conÔ¨Çict of interest
regarding the publication of this paper.

Acknowledgments
This work was supported partly by the National Natural
Science Foundation of China (61702292 and 61703219), International Cooperation Program for Key Professors of 2017 by
the Department of Education of Shandong Province, and Qilu
University of Technology (Shandong Academy of Sciences)
Young Doctor Cooperative Funding (2017BSH2012).

References
[1] M. X. Cohen, ‚ÄúWhere does EEG come from and what does it
mean?,‚Äù Trends in Neurosciences, vol. 40, no. 4, pp. 208‚Äì218,
2017.
[2] A. Gevins, ‚ÄúHans Berger was right: what I have learned about
thinking from the EEG in the past twenty years,‚Äù Electroencephalography and Clinical Neurophysiology, vol. 103, no. 1,
pp. 5-6, 1997.
[3] A. M. Coenen, ‚ÄúNeuronal activities underlying the electroencephalogram and evoked potentials of sleeping and waking:
implications for information processing,‚Äù Neuroscience & Biobehavioral Reviews, vol. 19, no. 3, pp. 447‚Äì463, 1995.
[4] K. E. Crowley and I. M. Colrain, ‚ÄúA review of the evidence for
P2 being an independent component process: age, sleep and
modality,‚Äù Clinical Neurophysiology, vol. 115, no. 4, pp. 732‚Äì
744, 2004.
[5] S. Y. Tseng, R. C. Chen, F. C. Chong, and T. S. Kuo, ‚ÄúEvaluation of parametric methods in EEG signal analysis,‚Äù Medical
Engineering and Physics, vol. 17, no. 1, pp. 71‚Äì78, 1995.
[6] P. X. Wang and Z. J. Zhang, ‚ÄúStudy on the recognition algorithm of epileptic carbuncle characteristic wave of EEG signal
under wavelet transform,‚Äù in Information and computer (theoretical Edition), pp. 63‚Äì65, China Optical Society, 2017.
[7] M. Z. Ilyas, P. Saad, and M. I. Ahmad, ‚ÄúA survey of analysis
and classiÔ¨Åcation of EEG signals for brain-computer interfaces,‚Äù in 2015 2nd International Conference on Biomedical
Engineering (ICoBE) IEEE, Penang, Malaysia, March 2015.
[8] S. Motamedi-Fakhr, M. MoshreÔ¨Å-Torbati, M. Hill, C. M. Hill,
and P. R. White, ‚ÄúSignal processing techniques applied to
human sleep EEG signals‚Äîa review,‚Äù Biomedical Signal Processing and Control, vol. 10, pp. 21‚Äì33, 2014.

10
[9] N. R. Tambe and A. Khachane, ‚ÄúMood based E-learning using
EEG,‚Äù in 2016 International Conference on Computing Communication Control and automation (ICCUBEA) IEEE, Pune,
India, Aug. 2016.
[10] R. M. Huang, S. H. Du, Z. Y. Chen, Z. Zhang, and Y. Zhou,
‚ÄúPattern recognition of epileptic and carbuncle EEG based
on support vector machine,‚Äù Journal of Biomedical Engineering, vol. 30, no. 5, pp. 919‚Äì924, 2013.
[11] M. Xi and G. H. Zhu, ‚ÄúMultiscale permutation and its application in epilepsy and carbuncle attack recognition,‚Äù Journal of
Biomedical Engineering, vol. 32, no. 4, pp. 751‚Äì756, 2015.
[12] Q. Wu and W. W. Yu, ‚ÄúIntegrating a HMM-based driver
fatigue recognition model into smart vehicle space for ubiquitous computing,‚Äù Key Engineering Materials, vol. 467-469,
pp. 23‚Äì30, 2011.
[13] L. M. Bergasa, J. Nuevo, M. A. Sotelo, R. Barea, and M. E.
Lopez, ‚ÄúReal-time system for monitoring driver vigilance,‚Äù
IEEE Transactions on Intelligent Transportation Systems,
vol. 7, no. 1, pp. 63‚Äì77, 2006.
[14] P. H. Gander, N. S. Marshall, I. James, and L. L. Quesne,
‚ÄúInvestigating driver fatigue in truck crashes: Trial of a systematic methodology,‚Äù Transportation Research Part F: TraÔ¨Éc
Psychology and Behaviour, vol. 9, no. 1, pp. 65‚Äì76, 2006.
[15] J. W. Bang, J. S. Choi, E. C. Lee, K. R. Park, and M. Whang,
‚ÄúNoise reduction of EEG signal based on head movement estimation by using frontal viewing camera,‚Äù Sensor Letters,
vol. 10, no. 5, pp. 1241‚Äì1246, 2012.
[16] S. Yan, J. Q. Wei, and Y. H. Wu, ‚ÄúResearch on feature extraction of brain wave in drivers' sleepy state,‚Äù Chinese Journal of
Biomedical Engineering, vol. 24, no. 1, pp. 110‚Äì113, 2005.
[17] X. Y. Wu, S. H. Wang, and Y. D. Zhang, ‚ÄúOverview of k nearest
neighbor algorithm theory and application,‚Äù Computer Engineering and Application, vol. 53, no. 21, pp. 1‚Äì7, 2017.
[18] P. Soucy and G. W. Mineau, ‚ÄúA simple KNN algorithm for text
categorization,‚Äù in A simple KNN algorithm for text categorization, San Jose, CA, USA, USA, Nov.-Dec. 2001.
[19] K. Murphy, B. van Ginneken, A. M. Schilham, B. J. de Hoop,
H. A. Gietema, and M. Prokop, ‚ÄúA large-scale evaluation of
automatic pulmonary nodule detection in chest CT using local
image features and k-nearest-neighbour classiÔ¨Åcation,‚Äù Medical Image Analysis, vol. 13, no. 5, pp. 757‚Äì770, 2009.
[20] F. Tahernezhad-Javazm, V. Azimirad, and M. Shoaran, ‚ÄúA
review and experimental study on the application of classiÔ¨Åers
and evolutionary algorithms in EEG-based brain-machine
interface systems,‚Äù Journal of Neural Engineering, vol. 15,
no. 2, p. 021007, 2018.
[21] J. Machado and A. Balbinot, ‚ÄúExecuted movement using EEG
signals through a naive, Bayes classiÔ¨Åer,‚Äù Micromachines,
vol. 5, no. 4, pp. 1082‚Äì1105, 2014.
[22] R. M. Mehmood, R. Du, and H. J. Lee, Optimal feature selection
and deep learning ensembles method for emotion recognition
from human brain EEG sensors, IEEE Access, 2017.
[23] P. Dande and P. Samant, ‚ÄúAcquaintance to artiÔ¨Åcial neural
networks and use of artiÔ¨Åcial intelligence as a diagnostic tool
for tuberculosis: a review,‚Äù Tuberculosis, vol. 108, pp. 1‚Äì9,
2018.
[24] T. Kim and J. Kittler, ‚ÄúLocally linear discriminant analysis for
multimodally distributed classes for face recognition with a
single model image,‚Äù IEEE Transactions on Pattern Analysis
and Machine Intelligence, vol. 27, no. 3, pp. 318‚Äì327, 2005.

Computational and Mathematical Methods in Medicine
[25] Y. Lu, H. Jiang, and W. Liu, ‚ÄúA review of EEG signal classiÔ¨Åer
based on deep learning,‚Äù in Proceedings of Information Science
and Cloud Computing ‚Äî PoS(ISCC 2017), Guangzhou, China,
March 2018.
[26] Z. H. Zhou, Machine Learning, Tsinghua University Press,
Beijing, 2016.
[27] L. F. Nicolas-Alonso and J. Gomez-Gil, ‚ÄúBrain computer interfaces, a review,‚Äù Sensors, vol. 12, no. 2, pp. 1211‚Äì1279, 2012.
[28] H. Guo, R. TANG, Y. Ye, Z. Li, and X. He, ‚ÄúDeepFM: a
factorization-machine based neural network for CTR prediction,‚Äù in Proceedings of the Twenty-Sixth International Joint
Conference on ArtiÔ¨Åcial Intelligence, Melbourne, Australia,
2017.
[29] S. Rendle, ‚ÄúFactorization machines,‚Äù in IEEE International
Conference on Data Mining IEEE, Sydney, NSW, Australia,
Dec. 2010.
[30] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Application of
dimensionality reduction in recommender system-a case study,
Minnesota Univ Minneapolis Dept of Computer Science,
2000.
[31] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ‚ÄúLearning
representations by back-propagating errors,‚Äù Nature,
vol. 323, no. 6088, pp. 533‚Äì536, 1986.
[32] S. Hochreiter and J. Schmidhuber, ‚ÄúLong short-term memory,‚Äù Neural Computation, vol. 9, no. 8, pp. 1735‚Äì1780, 1997.
[33] T. Wang, ‚ÄúMulti-focus fusion algorithm for noisy images,‚Äù
Optics and Precision Engineering, vol. 19, no. 12, pp. 2977‚Äì
2984, 2011.
[34] C. L. Zhen, Random Noise Suppression of Seismic Signal Based
on Wavelet Transform, Donghua University of technology,
2018.
[35] J. Morlet, G. Arens, E. Fourgeau, and D. Giard, ‚ÄúWave propagation and sampling theory-part II:sampling theory and complex waves,‚Äù Geophysics, vol. 47, no. 2, pp. 222‚Äì236, 1982.
[36] A. Grossmann and J. Morlet, ‚ÄúDecomposition of hardy functions into square Integrable wavelets of constant shape,‚Äù SIAM
Journal on Mathematical Analysis, vol. 15, no. 4, pp. 723‚Äì736,
1984.
[37] J. Zhang and J. Cao, ‚ÄúDecision tree algorithm for big data analysis,‚Äù Computer Science, vol. 43, no. S1, pp. 374‚Äì379, 2016.
[38] S. H. Zhang, J. X. Liu, and L. F. Kong, ‚ÄúOcclusion detection
based on depth image using random forest,‚Äù Acta Optica
Sinica, vol. 34, no. 9, pp. 197‚Äì208, 2014.
[39] P. Komarek, Logistic regression for data mining and highdimensional classiÔ¨Åcation, pp. 29‚Äì36, 2004.
[40] S. F. Ding, B. J. Qi, and H. Tan, ‚ÄúA review of support vector
machine theory and algorithm,‚Äù Journal of University of Electronic Science and Technology, vol. 40, no. 1, pp. 2‚Äì10, 2011.

