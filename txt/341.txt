Hindawi
Computational and Mathematical Methods in Medicine
Volume 2020, Article ID 2801015, 10 pages
https://doi.org/10.1155/2020/2801015

Research Article
EEG Signal and Feature Interaction Modeling-Based Eye Behavior
Prediction Research
Pengcheng Ma and Qian Gao
School of Computer Science and Technology, Qilu University of Technology (Shandong Academy of Sciences),
Jinan Shandong 250353, China
Correspondence should be addressed to Qian Gao; qiangao0603@163.com
Received 25 February 2020; Accepted 20 April 2020; Published 16 May 2020
Guest Editor: Yi-Zhang Jiang
Copyright © 2020 Pengcheng Ma and Qian Gao. This is an open access article distributed under the Creative Commons Attribution
License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is
properly cited.
In recent years, with the development of brain science and biomedical engineering, as well as the rapid development of
electroencephalogram (EEG) signal analysis methods, using EEG signals to monitor human health has become a very popular
research ﬁeld. The innovation of this paper is to analyze the EEG signal for the ﬁrst time by building a depth factorization
machine model, so that on the basis of analyzing the characteristics of user interaction, we can use EEG data to predict the
binomial state of eyes (open eyes and closed eyes). The signiﬁcance of the research is that we can diagnose the fatigue and the
health of the human body by detecting the state of eyes for a long time. On the basis of this inference, the proposed method can
make a further useful auxiliary support for improving the accuracy of the recommendation system recommendation results. In
this paper, we ﬁrst extract the features of EEG data by wavelet transform technology and then build a depth factorization
machine model (FM+LSTM) which combines factorization machine (FM) and Long Short-Term Memory (LSTM) in parallel.
Through the test of real data set, the proposed model gets more eﬃcient prediction results than other classiﬁer models. In
addition, the model proposed in this paper is suitable not only for the determination of eye features but also for the acquisition
of interactive features (user fatigue) in the recommendation system. The conclusion obtained in this paper will be an important
factor in the determination of user preferences in the recommendation system, which will be used in the analysis of interactive
features by the graph neural network in the future work.

1. Introduction
The electrical activity of the cerebral cortex is recorded by
detecting electrodes, and the potential amplitude is taken as
the vertical axis and the time as the horizontal axis to form
a map that can reﬂect the spontaneous and rhythmic electrical activity of diﬀerent parts of the brain with time, which is
called EEG [1]; its full name is electroencephalogram. In
1924, Hans Bergen, a German psychiatrist, ﬁrst discovered
and recorded the regular electrical activity of the human
brain [2]. In 1933, Berger’s research was aﬃrmed by the
famous British physiologist E.D. Adrian. Since then, EEG
has developed rapidly, and the detection methods which
include multilead regular electroencephalogram (spontaneous EGG and evoked EGG), sleep EEG, dynamic EEG, video
EEG, and other detection methods have occurred [3–5]. The

structure of the human brain is very complex and sophisticated. From the microscopic point of view, it is mainly composed of billions of neurons. The EEG signal consists of two
parts, one is the pyramidal neurons in the cortex and the
other one is the postsynaptic potential diﬀerence of the vertical dendrites. The bioelectric signal of the central nervous
system is used to transmit, store, and process various physiological activity information, so as to control the human
behavior [6]. As an action related to EEG, the eye state (open
and close eyes) can be identiﬁed by observing the characteristic changes of EEG signals.
As the key technology of brain computer interface (BCI),
EEG can be applied in ﬁve stages [7]. Among them, there are
three important contents for signal processing, which are the
preprocessing, feature extraction, and classiﬁcation of the
EEG signal; all above have been widely studied [8, 9]. As early

2
as the end of the 19th century, British physiologist Richard
Caton took the lead in using a galvanometer to capture the
weak current signal on the surface of the animal’s cerebral
cortex [10]. Through the study of the captured electrical signals of animals, the researchers found that in the state of
quiet without external stimulation, the captured current signal waveform showed rhythmic oscillation. In recent years,
with the development of computer science and technology,
advanced technologies such as X-ray electronic computed
tomography and positron emission computed tomography
have been introduced in EEG research [11]. EEG is also commonly used to monitor a patient’s sleep, anesthesia depth,
and fatigue. This article is to monitor the state of eyes (fatigue
degree) through EEG.
A large number of scholars are trying to detect the fatigue
state through EEG. The intelligent transportation laboratory
(University of Pennsylvania) and NHTSA [12] use a brain
wave tester and head motion detector to test and analyze
the EEG and eye characteristic parameters of the driver
under a fatigue state and ﬁnally determine PERCLOS (ratio
of cumulative time of eye closure to unit time) as the test
index of the driver’s physiological fatigue degree evaluation.
Bergasa et al. [13] (Australia) tested several nondrivers, and
based on the changes of the brain wave in a nonfatigue state,
they further analyzed the characteristics of brain wave
changes in ﬁve stages of nonfatigue, near fatigue, moderate
fatigue, doze, and antifatigue (wake up from fatigue).
Yoshihiro Takei et al. (Japan University of Technology,
Zhipu) obtained the steering angle signal of drivers when
turning in the process of driving simulation on the basis of
the simulation experiment test. They ﬁrst processed the steering angle signal with the help of Fourier transform theory and
wavelet theory. Then, they determined the wavelet transform
value of the steering angle signal of drivers in diﬀerent mental
states by using nonlinear theory (chaos theory), so as to judge
the driver’s fatigue level. Finally, the fast transform algorithm
(FFT, fast wavelet transform) is discussed to realize the
real-time evaluation of driver fatigue state. According
to four kinds of typical brain waves (δ wave, frequency is
1-3.5 Hz; α wave, frequency is 7.5-12.5 Hz; β wave, frequency
is 12.5-30 Hz; and θ wave, frequency is 3.5-7.5 Hz) and their
changes, we can reﬂect people’s mental state. Relevant
research shows that the change of α wave is the best reﬂection
of human fatigue [14]. W-Bang et al. collected four kinds of
typical brain waves, obtained the corresponding brain wave
entropy using the thermodynamic entropy theory, and evaluated the fatigue degree of drivers according to the change
of the calculated value [15]. Yan et al. [16] conducted experimental tests with the KT98-2000A dynamic electroencephalograph. First, the driver (healthy, not taking any irritating
drugs) under nonfatigue and fatigue states was collected to
engage in various driving operations (starting, shifting, controlling brain waves during movement, steering…). Next,
the power spectrum is obtained, and the power spectrum
density estimates of various brain waves are calculated.
Finally, the average power spectral density ratios of four typical brainwaves when the driver performs various driving
operations such as starting, shifting, braking, and steering
under nonfatigue and fatigue conditions are obtained.

Computational and Mathematical Methods in Medicine
Most of the research mentioned above are to judge the
fatigue state of the human body by directly recognizing the
characteristics of EEG. In this paper, the feature data is
extracted from EEG by wavelet transform technology,
and then, the eye state is predicted by a classiﬁcation algorithm, compared with traditional classiﬁcation algorithms,
k-nearest neighbor algorithm [17–19], naive Bayes algorithm
[20–22], artiﬁcial neural network (ANN) [23], and linear
discriminant analysis [24–27]. In this paper, we build a
FM+LSTM model to predict the eye state. The model is combined with the linear interaction characteristics of FM and
the nonlinear interaction characteristics of LSTM. It can
greatly improve the accuracy of eye state classiﬁcation and
prediction. On the basis of this research, we can also infer
the fatigue degree of the human body by monitoring the
eye state of the human body for a long time, which can help
us to recommend user behavior. For example, it can help us
to detect whether the user is in the state of work overload
in working time or not by combining the proposed eye state
classiﬁcation prediction method and our previous interaction
characteristic research results. Meanwhile, it can also help us
to detect whether the fatigue state of users is caused by nonworking reasons in nonworking time or not. Thus, more
accuracy user behavior recommendations can be got.

2. Related Work
The purpose of this paper is to predict the eye state (open and
closed eyes) by EEG data, which is a typical binary classiﬁcation problem. Because the traditional binary classiﬁcation
has many shortcomings in some aspects, and its performance
is poor, we use the FM algorithm which is widely used in the
click rate prediction of recommendation system, as well as a
good binary classiﬁcation algorithm. The advantages of the
FM algorithm are as follows: (1) FM model can carry out reasonable parameter trajectory in very sparse data; (2) the complexity of the FM model is linear, the optimization eﬀect is
good, and it does not need to rely on a support vector like
support vector machines (SVM); and (3) FM is a general
model, which can be used in any case where the eigenvalue
is real. Other factorization models can only be used in some
cases where the input data is relatively ﬁxed. In addition,
we also use LSTM, which is a deep network model with good
generalization ability and nonlinear mapping ability. Compared with the recurrent neural network, LSTM solves the
gradient explosion problem; therefore, LSTM is a strong classiﬁcation prediction model.
In the experimental part of this paper, after extracting the
corresponding features through wavelet transform technology, one hot coding processing is carried out on these data,
which will not only increase the number of input data but
also generate a large number of sparse data (a large number
of zero data appears in the data set). According to the idea
of integrated learning, referring to the DeepFM [28] model
(a highly eﬃcient click rate prediction model of recommendation system), we integrate FM and LSTM in parallel, and
the FM+LSTM model is constructed, which has the characteristics of automatic low-order feature combination, linear
data connection, and sparse matrix friendliness. LSTM can

Computational and Mathematical Methods in Medicine

3

ht-1

ht

Ct–1

Ct
tanh

ft

it

ot
~
Ct

𝜎

ht–1

Xt–1

𝜎

tanh

𝜎

ht

Xt

Figure 1: Internal structure of LSTM.

solve the gradient explosion problem and has the characteristics of achieving high-order feature combination and nonlinear mapping. In addition, EEG data is obtained from
sequential testing in a time series, which is very suitable for
the prediction and classiﬁcation of long-term and shortterm memory models. Therefore, the proposed depth factorization machine model is suitable for two classiﬁcation
problems that determine eye behavior. The depth factorization machine model combines the advantages of FM and
LSTM, and it is also applicable to two classiﬁcation problems
for judging the eye state. In the following section, we will
introduce the FM model and the LSTM model brieﬂy.
2.1. Introduction to FM. The factorization machine is a new
model proposed by Rendle in 2010, which uses the idea of
the implicit factor model and matrix decomposition for reference [29]. The problem of data sparsity can be overcome
to some extent by using the idea of matrix decomposition
to solve the optimal quadratic parameters. At present, many
implicit factor models have been used for rating prediction in
recommended ﬁelds, such as the common matrix decomposition, and the representative algorithm is singular value
decomposition [30]. The main disadvantage of these algorithms is that they are only suitable for speciﬁc input data
types, and the optimization algorithm is only proposed for
the current task, which does not have generality. In diﬀerent
task scenarios, they cannot be directly migrated and extended
horizontally. The factorization machine model is a general
model, which can change the shortcomings of a traditional
matrix decomposition algorithm. The FM only needs to
change the form of the input eigenvector to simulate the
common matrix decomposition model, while the traditional
matrix decomposition model has to deﬁne model expression
and optimization method separately for each speciﬁc task.
Therefore, FM eﬀectively avoids this kind of malpractice.
2.2. Introduction of LSTM. Because the artiﬁcial neural network can model the nonlinear process, it can solve a series
of complex problems such as classiﬁcation, clustering,
dimensionality reduction, regression, and structural predic-

tion. With the revolution of the computer industry, the
exponential improvement of computer computing power,
and the explosive growth of data in recent years, the
deep-seated artiﬁcial neural network which needs a lot of
computing power has been widely used. From the most
classical perceptron, there are many kinds of neural network models. The typical models are the Convolutional
Neural Network (CNN), recurrent neural network (RNN),
and RNN variant LSTM. Diﬀerent neural network models
have diﬀerent scenarios.
As mentioned above, the cyclic neural network or RNN is
a kind of neural network for processing sequence data [31].
The network structure of LSTM was proposed by Hochreiter
and Schmidhuber in 1997 [32], and then, this kind of network became very popular. Many people solved many practical problems based on the network structure of LSTM,
and now, LSTM is still widely used. The recurrent neural network is a chain loop structure, and the network structure of
LSTM is basically the same structure, but LSTM has a more
complex structure in the network; therefore, it can deal with
long-term dependence. LSTM has three gates to control,
which are input gate, forgetting gate, and output gate. The
input gate controls the input of the network, the forgetting
gate controls the memory unit, and the output gate controls
the output of the network. The most important one is
the forgetting gate. The function of the forgetting gate is
to decide which memories will be preserved and which
memories will be forgotten. It is precisely because the
function of forgetting gate “LSTM” has a long-term memory function. For a given task, the forgetting gate can be
used to learn how many previous memories it can retain,
which makes the network have the ability of learning
autonomously without human interference.
The following explains the network ﬂow process of LSTM
from the speciﬁc internal structure. The internal structure of
the LSTM is shown in Figure 1. Next, we will explain their
internal operation mode and how to represent the three gates
mentioned above.
Input gate it controls how much information can ﬂow
into memory cells. Forgetting gate f t controls how much

4

Computational and Mathematical Methods in Medicine

information in the memory cells of the last moment can be
accumulated into the memory cells of the current moment.
Output gate ot controls how much information in the memory cells of the current time can ﬂow into the current hidden
state ht .
Step one: use the forgetting gate to decide what information to discard from the cell state and calculate the attenuation coeﬃcient. Read ht−1 and xt and output a value
between 0 and 1 to each number in cell loading C t−1 . This
determines what information we discard from the state of
the cell. Since the output of sigmoid is 0 to 1, 1 indicates “full
reservation” and 0 indicates “complete abandonment.”
Step two: update the information. First, the sigmoid layer
is the “input gate layer,” which determines what value we will
update. Then, the tanh layer creates a new candidate vector.
Step three: update the time of old cell status C t−1 , which is
updated to Ct .
Step four: the output gate decides what value to output.
The output at this time is calculated according to the Ct state
of the third part.
2.3. Methodology and Contribution. The research content of
this paper is to detect the eye state (open eyes, closed eyes)
through EEG data. The purpose is to detect the eye state for
a long time, so as to diagnose the fatigue and health status
of individuals. In fact, this is a two classiﬁcation problem.
Speciﬁcally, in this paper, we extract feature data from EEG
by wavelet transform technology and then build a FM+LSTM
model to classify and predict the eye state. This model combines the linear interaction characteristics of FM and the
nonlinear interaction characteristics of LSTM, which can
greatly improve the classiﬁcation eﬃciency. The main contributions of this paper can be summarized as follows:
(1) The feature is extracted from EEG by wavelet
transform:

EEG image data set

Feature extraction using wavelet
transform

Build FM+LSTM model

Predicting eye state

Figure 2: The framework of the proposed method.

nation, linear data connection, and sparse matrix
friendliness. LSTM can be used to solve the problem
of gradient explosion and realize high-order feature
combination and nonlinear mapping, which is suitable for the classiﬁcation and prediction of eye
behavior in this paper

(3) In this paper, the model is tested on the real data set,
and through the comparison of the experimental
results, it is found that the FM+LSTM model established in this paper has better classiﬁcation and prediction eﬃciency than other classiﬁcation models

3. EEG Signal-Based FM+LSTM Model
(i) The ﬁrst-order low-frequency signal features of EEG
data are obtained by wavelet transform [33], and
there are 14 EEG values
(ii) The extracted data features are used as the basis for
our classiﬁcation and prediction

(2) Build a FM+LSTM model to classify and predict the
eye state:

(i) This model is the ﬁrst that we have established and
applied to the study of eye behavior classiﬁcation
and prediction based on EEG
(ii) The model is composed of FM and short-term memory neural network in a parallel form, which combines the advantages of both models with the
characteristics of automatic low-order feature combi-

3.1. Theoretical Framework. In the experimental part of this
paper, we will ﬁrst introduce the theoretical framework of
the experimental content, as shown in Figure 2.
3.2. Feature Extraction of EEG by Wavelet Transform. The
EEG signal is a nonlinear and nonstationary random weak
signal, with a relatively weak amplitude. Generally, the
amplitude of the EEG signal is not more than 300 μV. Continuous wavelet transform (CWT) [33–36] essentially convolutes the EEG signal with the translation dilation wavelet
weight function with localization in a time and frequency
domain, so as to decompose the signal into various components in diﬀerent times or frequency. Let the signal f ðtÞ of
EEG be the square integrable function, which is recorded as
f ðtÞ ∈ L2 ðRÞ. Convolute the EEG signal f ðtÞ with the mother
wavelet function, and call Equation (1) the continuous wavelet transform of the EEG signal f ðtÞ:




−1/2

WT f ða, τÞ = f ðt Þ, ψa,τ ðt Þ = a

ð



t−τ
dt: ð1Þ
f ðt Þψ
a
R

Computational and Mathematical Methods in Medicine

5

In the above formula, WT f ða, τÞ is the wavelet coeﬃcient
of the EEG signal, scale a controls the expansion and contraction of wavelet function, and translation amount τ controls
the translation of wavelet function. The scale corresponds
to frequency (inverse ratio), and translation τ corresponds
to time.
_
If the Fourier transform ψðwÞ of the parent wavelet function satisﬁes the constant resolution constraint
ð∞
Cψ =

0

j ψ ð wÞ j 2
dw < ∞,
w

ð2Þ

then there is a reconstruction formula for the continuous
wavelet transform of the EEG signal, and its expression is
shown in
f ðt Þ =

1
Cψ

ð∞
0

da
a2

ð



1
t−τ
dτ:
WT x ða, τÞ pﬃﬃﬃ ψ
a
a
R

ð3Þ

In the above formula, C ψ is the permissive condition of
ψðtÞ and WTx ða, tÞ is the wavelet transform coeﬃcient. Since
the wavelet base has two parameters of scale and displacement, the expansion of the wavelet base means that onehour function is projected on the two-dimensional timescale phase plane. And because of the characteristics of the
basic body of wavelet, the function projection to wavelet
transform is conducive to extract some features.
Because of the invariable window and the excellent characteristics of local analysis, the characteristics of the EEG signal in diﬀerent frequencies can be analyzed by wavelet
transform in diﬀerent time scales.
3.3. FM+LSTM Model Construction Method. For a classiﬁcation and prediction system, it is very important to learn the
EEG feature combination behind the real eye state. Among
the features extracted from EEG, low-order combined
features (including one-dimensional and two-dimensional
feature data) or high-order combined features (multidimensional feature data) may aﬀect the ﬁnal classiﬁcation and prediction results. Considering the disadvantages of traditional
classiﬁcation methods, it includes the following:
(1) The decision tree model easily leads to overﬁtting and
ignores the correlation between data
(2) The random forest model is prone to overﬁtting
when the data noise is large
(3) The logistic regression model cannot combine features and depends on artiﬁcial feature combination
(4) The prediction process of the SVM model depends
on the support vector in the training sample
We can see that the traditional classiﬁcation algorithm
cannot complete the classiﬁcation task well, and therefore,
we use the FM in this paper. The factorization machine
model extracts the feature combination through the implicit
variable inner product of each one-dimensional feature,

which can extract the combined feature actively, keeps independent of the training sample but not rely on the support
vector, and will not easily be aﬀected by the noise data and
appear the phenomenon of overﬁtting. However, in theory,
FM can model higher-order feature combinations; in fact,
only the second-order feature combination is used because
of the complexity of calculation. In this paper, we solve the
problem of high-order feature combination by multilayer
neural networks which can learn the nonlinear complex relationship. We further use LSTM, which is a variation of RNN.
LSTM contains the characteristics of a traditional neural network which is composed of the input layer, hidden layer, and
output layer. LSTM also inherits all the advantages of RNN.
It can adjust the parameters through back propagation.
Moreover, LSTM can make the neurons in the hidden layer
communicate with each other and establish the connection
between the characteristic data. Not only that, the LSTM also
solves the problem that the circulating neural network is
prone to gradient explosion. Therefore, the LSTM contains
the advantages of many neural networks, and its performance has been improved. And it also has a good performance in the classiﬁcation problem.
Based on the advantages of the FM model and LSTM, we
build the FM+LSTM model on the basis of the DeepFM [28]
model to solve the classiﬁcation problem. It eﬀectively combines the advantages of FM and LSTM in feature learning:
It can extract low-order combined features and high-order
combined features at the same time. In the FM+LSTM
model, we use a parallel approach to build our depth factorization machine model. Through the depth factorization
machine model, on the one hand, FM can be used to extract
the features from the ﬁrst-order features and second-order
features which are by the combination of the pair ﬁrstorder features; on the other hand, LSTM can be used to
extract features from the higher-order features which is
formed by the input ﬁrst-order features. Speciﬁcally, the
characteristics of the FM+LSTM model include
(1) being able to process sparse data
(2) combining the FM model and the LSTM model,
learning low-order feature combination and highorder feature combination at the same time
To sum up, we explained the principle of the FM+LSTM
model and the advantages of the model. Next, we will show
the mathematical principle of the model.
First, we use the FM [29]. The second-order expression of
the algorithm is shown in
n

n

n

yðxÞ = w0 + 〠 wi xi + 〠 〠 wij xi x j ,
i=1

ð4Þ

i=1 j=i+1

where n represents the feature dimension, xi represents the
feature value of the ﬁrst feature, and wi and wij are the coefﬁcients of the primary term and the secondary term of the
factorization machine model, respectively. A symmetric
matrix w is composed of all the parameters wij of quadratic

6

Computational and Mathematical Methods in Medicine

terms. At this time, the matrix can be decomposed into the
following forms: w = vT v, where the ith column of v is the
corresponding vector expression of the ith feature, and at
this time, the coeﬃcient of quadratic terms can be expressed
as the inner product of two vectors, namely, wij = hvi , v j i. In
this case, the expression of the second-order model is as
shown in
n
n
n


yFM = w0 + 〠 wi xi + 〠 〠 vi , v j xi x j ,
i=1

ð5Þ

i=1 j=i+1

When updating the old cell status, C t‐1 is updated to Ct .
The calculation formula is shown in
~t:
C t = f t ∗ C t−1 + it ∗ C

Use the output gate to decide what value to output. The
output at this time is calculated according to the C t state of
the third part. The calculation process is shown in
Ot = σðW o ½ht−1 , xt  + bo Þ,
H t = Ot ∗ tanh ðC t Þ:

where vi is the vector expression of the ith feature k, dimension k, and <·, · > is the vector dot product. At this time, the
coeﬃcients of the quadratic terms xh xi and xi x j are no longer independent. Speciﬁcally, the coeﬃcients of xh xi and xi
x j are <xh , xi > and <xi , x j >, which have the same term vi .
Then, all the samples with nonzero feature combination of
xi can be used to learn vi .
In the LSTM model [32], the output is controlled by the
forgetting gate, input gate, and output gate. The forgetting
gate is used to determine what information is discarded from
the cell state, and the attenuation coeﬃcient is calculated as
shown in formula (6). Read ht−1 and xt , and output a value
between 0 and 1 to each number in cell loading C t−1 . This
determines what information we discard from the state of
the cell. Since the output of sigmoid is 0 to 1, 1 indicates “full
reservation” and 0 indicates “complete abandonment”:


f t = σ W f ⋅ ½H t−1 , xt  + b f :

ð6Þ

In the above formula, W f is the weight value, t is the
number of input data, t is the range of t = f0, 1, ⋯, Tg, xt is
the tth input data, H t−1 is the output result of t‐1 neuron,
b f is the deviation value, and σð⋅Þ is the activation function
sigmoid, which is deﬁned as shown in
f ðx Þ =

1
:
1 + e−x

ð7Þ

Use the input gate to decide what value we are going to
update. Then, the tanh layer creates a new candidate vector.
The calculation equation is as follows:
it = σðW i ⋅ ½ht−1 , xt  + bi Þ,
~ t = tanh ðW c ⋅ ½ht−1 , xt  + bc Þ:
C

ð8Þ

In the above formula, σð⋅Þ is the activation function sigmoid, W i and W o are weight values, bi and bo are deviation
values, and tanh ð⋅Þ is the activation function. Its deﬁnition
is as shown in
f ðxÞ =

1 − e−2x
:
1 + e−2x

ð9Þ

ð10Þ

ð11Þ

In the above formula, σð⋅Þ is the activation function sigmoid, W o is the weight value, and bo is the deviation value.
The output results of each nerve unit can be obtained
through the above steps. Finally, the output results of the
neuron (the tth) can be obtained under the eﬀect of output
and transmission of diﬀerent cycle units:
yLSTM = σðW t ⋅ H t + bt Þ:

ð12Þ

In the above formula, σð⋅Þ is the activation function sigmoid, W t is the weight value, and bt is the deviation value.
Finally, we combine the output of FM and LSTM to get
the prediction results as shown in
yprediction = sigmoidðyFM + yLSTM Þ:

ð13Þ

We use logloss as the loss function of the depth factor
decomposition machine model constructed in this paper,
and then use gradient optimization algorithm to adjust the
parameters, and ﬁnally get the optimal parameters.
We have introduced the mathematical principle of the
depth factor decomposition machine model in detail. Next,
we will show the overall ﬂow chart of building the FM+LSTM
model, as shown in Figure 3.

4. Experiment and Execution Results
4.1. Classiﬁed Forecast. In the task of classiﬁcation and prediction, we compare the eﬀect of the model used in this paper
with the following benchmark models.
(1) Decision Tree (DT) Algorithm [37]. It is a method of
approaching the value of discrete function, which is
a typical classiﬁcation method. Firstly, the data is
processed, the readable rules and decision trees are
generated by using an induction algorithm, and then
the new data is analyzed by using decision. In
essence, the decision tree is a process of data classiﬁcation through a series of rules.
(2) Random Forest (RF) Algorithm [38]. Random forest
is an algorithm that integrates multiple trees through
the idea of integrated learning. Its basic unit is the
decision tree, and its essence belongs to a big branch
of machine learning—ensemble learning method.

Computational and Mathematical Methods in Medicine

7
Table 1: Classiﬁcation prediction results of various methods.

yprediction = sigmoid (yFM + yLSTM)

FM

Algorithm/model
DT
RF
LR
SVM
FM
LSTM
FM+LSTM

LSTM
FM+LSTM
model
Dense embeddings

Accuracy

Precision

Recall

F1-measure

0.82
0.88
0.64
0.56
0.76
0.89
0.93

0.82
0.88
0.64
0.59
0.80
0.90
0.94

0.82
0.88
0.62
0.50
0.71
0.82
0.90

0.82
0.88
0.63
0.54
0.75
0.86
0.92

One hot coding of features

Feature extraction by wavelet
transform

EEG image data set

Figure 3: Overall ﬂow chart of the FM+LSTM model.

(3) Logistic Regression (LR) Algorithm [39]. It is used to
deal with the regression problem when the dependent
variable is classiﬁed variable. The common problem
is the binomial or binomial distribution problem. It
can also deal with the multiclassiﬁcation problem.
In fact, it belongs to a classiﬁcation method.
(4) Support Vector Machines [40]. SVM ﬁnds a hyperplane to divide the data into one class and other classes, which is a two-class classiﬁcation model. The
separation interval is the largest and diﬀerent from
the perceptron.
4.2. Prediction Scheme. In order to evaluate the prediction
eﬃciency of the classiﬁcation prediction task, we use common evaluation indicators: accuracy, precision, recall, and
F1-measure. Speciﬁcally, the deﬁnitions of accuracy, precision, recall, and F1-measure are as follows [26]:
TP + TN
,
TP + TN + FN + FP
TP
,
Precision =
TP + FP
TP
,
Recall =
TP + FN
2 × Recall × Precision
F1‐Measure =
:
Recall + Precision
Accuracy =

ð14Þ

TP is the number of correctly recognized closed eyes, FP
is the number of incorrectly recognized closed eyes, TN is the
number of correctly recognized open eyes, and FN is the
number of incorrectly recognized open eyes. The accuracy
rate is the ratio of the number of samples correctly classiﬁed
by the classiﬁer to the total number of samples in a given test

data set, the accuracy is the ratio of the number of correctly
predicted samples in all predictions, the recall rate is the correctly predicted positive samples in all actual prediction proportion, and the F1-measure is the harmonic average of the
exact value and the recall rate. These four evaluation schemes
help us compare the eﬃciency of diﬀerent classiﬁcation
models in the EEG data set for eye behavior prediction, and
the bigger the results of the four evaluation methods, the
closer the prediction results to the actual situation.
In this paper, the accuracy, precision, recall rate, and
F1-measure are used to evaluate the prediction eﬃciency
of diﬀerent models. They are all classic evaluation methods
of binary prediction which are suitable for the eye behavior (open and close eyes) classiﬁcation prediction based on
EEG data. Among them, accuracy is the ratio of the number of samples correctly classiﬁed by the classiﬁer to the
total number of samples in a given test data set, accuracy
is the proportion of the number of samples correctly predicted as positive in all predictions, recall rate is the proportion of samples correctly predicted as positive in all actual
predictions, and F1-measure is the harmonic average of the
accuracy and recall rate. These four evaluation schemes help
us to compare the eﬃciency of diﬀerent classiﬁcation models
in EEG data set for eye behavior prediction, and the bigger
the results of the four evaluation methods, the closer the prediction results to the actual situation.
4.3. Comparison of Classiﬁed Prediction Results. The following table is the classiﬁcation prediction performance of the
model used in this paper and other benchmark models on
the EEG_EYE data set, and the speciﬁc results are shown in
Table 1.
As shown in Table 1, we sorted out the classiﬁcation and
prediction results of various classiﬁers on the EEG data set. In
order to compare the eﬀects of various classiﬁer models more
intuitively, we drew a histogram as shown in Figure 4.
In the traditional classiﬁcation prediction model, the logical regression model has the advantages of easy use and
understanding but has the disadvantages of not being able
to extract the combination features actively; the decision tree
model has the advantages of not being sensitive to the missing value and not being able to process the data type and
the conventional type attributes at the same time but has
the disadvantages of low antioverﬁtting ability and being easily disturbed by the noise data; the random forest model has
the advantages of strong antioverﬁtting ability and balance

8

Computational and Mathematical Methods in Medicine
Accuracy

Precision

1

1

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
DT

RF

LR

SVM

FM

DT

LSTM FM+LSTM

RF

LR

Recall

SVM

FM

LSTM FM+LSTM

FM

LSTM FM+LSTM

F1-measure

1

1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0

0
DT

RF

LR

SVM

FM

LSTM FM+LSTM

DT

RF

LR

SVM

Figure 4: Histogram of prediction results of each classiﬁcation model.

error, but it is also vulnerable to the interference of noise
data; the support vector machine model has the advantages
of ﬁnding the global minimum value through the convex
optimization method, but it has the disadvantages of relying
too much on support vector and processing large-scale
training data; the factorizer model has the advantages of
high learning eﬃciency and processing large-scale sparse
data, but it has the disadvantages of only extracting the
second-order feature combination; the LSTM model has
the advantages of processing large-scale sparse data and
solving the problem of long sequence dependence, but it
can only extract the high-order feature combination and
cannot combine the high-order feature with the low-order
feature.
Speciﬁcally, by combining the classiﬁcation results of
Table 1 and Figure 2, we can get the following conclusions:
(1) In the test set of EEG_EYE data, the overall classiﬁcation eﬀect of the factorization machine model is better than that of the logistic regression model and the
support vector machine model; this shows that the
factorization model has the characteristics of extracting the combined features actively and the characteristics of keeping independent of training samples,
which makes it better than the above logistic regression model and support the vector machine model
in classiﬁcation and prediction results

(2) In the test set of EEG_EYE data, the overall classiﬁcation eﬀect of LSTM is better than that of the decision
tree model and random forest model, which shows
that the LSTM has no serious overﬁtting linearity
due to the noise interference in the test set, and therefore, the classiﬁcation and prediction eﬀect is better
than the other two classiﬁcation models
(3) In the test set of EEG_EYE data, the model of FM
+LSTM is better than other models in classiﬁcation
and prediction. This is because the model can extract
low-order combined features and high-order combined features at the same time, which makes up for
the disadvantage that LSTM can only extract highorder feature combinations
In summary, the FM+LSTM model established by us can
not only extract the combined features actively but also
reduce the noise interference on the simulation. In addition,
it can extract both low-order combined features and highorder combined features; therefore, its performance is better
than other models.

5. Future Work
In this paper, we established a FM+LSTM model to predict
the eye behavior (open or close eyes) of the user by EEG data,

Computational and Mathematical Methods in Medicine
so as to infer whether the user is in a fatigue state. Simulation
results show that the proposed method achieved good classiﬁcation and prediction results. The direct signiﬁcance of this
work is that we can judge whether the user is in the fatigue
state through the EEG data. Furthermore, the fatigue state
is also an important feature of the user in the recommendation system, which can aﬀect the user’s preference and evaluation of the items. Therefore, in the future work, ﬁrst, we plan
to further study the user’s preference and evaluation of the
diﬀerent items based on the proposed research achievement
of the eye’s fatigue state which is an important feature factor
related to the context, so as to improve the eﬃciency of
recommendation. Second, we plan to use the attention
mechanism to distinguish the inﬂuence of various features
on eye behavior, so as to enhance the interpretability of
the classiﬁcation prediction result. In addition, based on the
research results of this paper, we plan to further use the graph
neural network model to study the complex interaction
between diﬀerent features in a more ﬂexible and clearer
way, so as to obtain more eﬃcient and more accurate recommendation results.

6. Conclusions
The purpose of this paper is to predict the eye state (open and
closed eyes) by EEG data, which is a typical dichotomous
problem. The signiﬁcance of this study is to diagnose the
fatigue and the health of the eyes by detecting the eye state
for a long time. And on the basis of this research, we can also
infer the fatigue degree of the human body by monitoring the
eye state of the human body for a long time, so that we can
help in user behavior recommendation based on this inferential. Firstly, we use wavelet transform technology to extract
the features of EEG, and then, we use a classiﬁer to classify
and predict. Because the traditional binary classiﬁcation has
many shortcomings in some aspects, and its performance is
poor, we use the FM algorithm which is widely used in the
click rate prediction of the recommendation system and
binary classiﬁcation algorithm. In addition, we also use
LSTM, which is a deep network model with good generalization ability and nonlinear mapping ability. According to the
idea of integrated learning, referring to the DeepFM [28]
model (a highly eﬃcient prediction model of click through
rate of the recommendation system), we integrate FM and
LSTM in parallel and build the FM+LSTM model, which
combines the advantages of FM and LSTM and is suitable
for the two classiﬁcation problems of the eye state in this
paper. And its performance in real data set is better than
other classiﬁer models. Through this research, we can also
infer the fatigue degree of the human body by monitoring
the eye state of the human body for a long time, so that we
can help in user behavior recommendation based on this
inference, which will be the focus of our next research. In this
paper, the FM+LSTM model is established to solve the problem of eye behavior classiﬁcation and prediction. The conclusion obtained in this paper will be an important factor in the
determination of user preferences in the recommendation
system, which will be used in the analysis of interactive features by the graph neural network in the future work.

9

Data Availability
The data set used in this experiment is collected by Oliver
rothler from Germany, Stuttgart and Baden Wurttemberg
state cooperative University (DHBW). The data set is composed of EEG value and a value indicating eye state, which
belongs to the ﬁeld of life medicine. All the data are the result
of continuous EEG measurement with Emotiv. The measurement duration is 117 seconds. During the EEG measurement,
the eye state is detected by the camera, and then manually
added to the ﬁle after analyzing the video frame. "1" means
that the eyes are closed, and "0" means that the eyes are open.
For more information about the data, please visit: http://
archive.ics.uci.edu/ml/datasets/EEG+eye+state.

Conflicts of Interest
The authors declare that there is no conﬂict of interest
regarding the publication of this paper.

Acknowledgments
This work was supported partly by the National Natural
Science Foundation of China (61702292 and 61703219), International Cooperation Program for Key Professors of 2017 by
the Department of Education of Shandong Province, and Qilu
University of Technology (Shandong Academy of Sciences)
Young Doctor Cooperative Funding (2017BSH2012).

References
[1] M. X. Cohen, “Where does EEG come from and what does it
mean?,” Trends in Neurosciences, vol. 40, no. 4, pp. 208–218,
2017.
[2] A. Gevins, “Hans Berger was right: what I have learned about
thinking from the EEG in the past twenty years,” Electroencephalography and Clinical Neurophysiology, vol. 103, no. 1,
pp. 5-6, 1997.
[3] A. M. Coenen, “Neuronal activities underlying the electroencephalogram and evoked potentials of sleeping and waking:
implications for information processing,” Neuroscience & Biobehavioral Reviews, vol. 19, no. 3, pp. 447–463, 1995.
[4] K. E. Crowley and I. M. Colrain, “A review of the evidence for
P2 being an independent component process: age, sleep and
modality,” Clinical Neurophysiology, vol. 115, no. 4, pp. 732–
744, 2004.
[5] S. Y. Tseng, R. C. Chen, F. C. Chong, and T. S. Kuo, “Evaluation of parametric methods in EEG signal analysis,” Medical
Engineering and Physics, vol. 17, no. 1, pp. 71–78, 1995.
[6] P. X. Wang and Z. J. Zhang, “Study on the recognition algorithm of epileptic carbuncle characteristic wave of EEG signal
under wavelet transform,” in Information and computer (theoretical Edition), pp. 63–65, China Optical Society, 2017.
[7] M. Z. Ilyas, P. Saad, and M. I. Ahmad, “A survey of analysis
and classiﬁcation of EEG signals for brain-computer interfaces,” in 2015 2nd International Conference on Biomedical
Engineering (ICoBE) IEEE, Penang, Malaysia, March 2015.
[8] S. Motamedi-Fakhr, M. Moshreﬁ-Torbati, M. Hill, C. M. Hill,
and P. R. White, “Signal processing techniques applied to
human sleep EEG signals—a review,” Biomedical Signal Processing and Control, vol. 10, pp. 21–33, 2014.

10
[9] N. R. Tambe and A. Khachane, “Mood based E-learning using
EEG,” in 2016 International Conference on Computing Communication Control and automation (ICCUBEA) IEEE, Pune,
India, Aug. 2016.
[10] R. M. Huang, S. H. Du, Z. Y. Chen, Z. Zhang, and Y. Zhou,
“Pattern recognition of epileptic and carbuncle EEG based
on support vector machine,” Journal of Biomedical Engineering, vol. 30, no. 5, pp. 919–924, 2013.
[11] M. Xi and G. H. Zhu, “Multiscale permutation and its application in epilepsy and carbuncle attack recognition,” Journal of
Biomedical Engineering, vol. 32, no. 4, pp. 751–756, 2015.
[12] Q. Wu and W. W. Yu, “Integrating a HMM-based driver
fatigue recognition model into smart vehicle space for ubiquitous computing,” Key Engineering Materials, vol. 467-469,
pp. 23–30, 2011.
[13] L. M. Bergasa, J. Nuevo, M. A. Sotelo, R. Barea, and M. E.
Lopez, “Real-time system for monitoring driver vigilance,”
IEEE Transactions on Intelligent Transportation Systems,
vol. 7, no. 1, pp. 63–77, 2006.
[14] P. H. Gander, N. S. Marshall, I. James, and L. L. Quesne,
“Investigating driver fatigue in truck crashes: Trial of a systematic methodology,” Transportation Research Part F: Traﬃc
Psychology and Behaviour, vol. 9, no. 1, pp. 65–76, 2006.
[15] J. W. Bang, J. S. Choi, E. C. Lee, K. R. Park, and M. Whang,
“Noise reduction of EEG signal based on head movement estimation by using frontal viewing camera,” Sensor Letters,
vol. 10, no. 5, pp. 1241–1246, 2012.
[16] S. Yan, J. Q. Wei, and Y. H. Wu, “Research on feature extraction of brain wave in drivers' sleepy state,” Chinese Journal of
Biomedical Engineering, vol. 24, no. 1, pp. 110–113, 2005.
[17] X. Y. Wu, S. H. Wang, and Y. D. Zhang, “Overview of k nearest
neighbor algorithm theory and application,” Computer Engineering and Application, vol. 53, no. 21, pp. 1–7, 2017.
[18] P. Soucy and G. W. Mineau, “A simple KNN algorithm for text
categorization,” in A simple KNN algorithm for text categorization, San Jose, CA, USA, USA, Nov.-Dec. 2001.
[19] K. Murphy, B. van Ginneken, A. M. Schilham, B. J. de Hoop,
H. A. Gietema, and M. Prokop, “A large-scale evaluation of
automatic pulmonary nodule detection in chest CT using local
image features and k-nearest-neighbour classiﬁcation,” Medical Image Analysis, vol. 13, no. 5, pp. 757–770, 2009.
[20] F. Tahernezhad-Javazm, V. Azimirad, and M. Shoaran, “A
review and experimental study on the application of classiﬁers
and evolutionary algorithms in EEG-based brain-machine
interface systems,” Journal of Neural Engineering, vol. 15,
no. 2, p. 021007, 2018.
[21] J. Machado and A. Balbinot, “Executed movement using EEG
signals through a naive, Bayes classiﬁer,” Micromachines,
vol. 5, no. 4, pp. 1082–1105, 2014.
[22] R. M. Mehmood, R. Du, and H. J. Lee, Optimal feature selection
and deep learning ensembles method for emotion recognition
from human brain EEG sensors, IEEE Access, 2017.
[23] P. Dande and P. Samant, “Acquaintance to artiﬁcial neural
networks and use of artiﬁcial intelligence as a diagnostic tool
for tuberculosis: a review,” Tuberculosis, vol. 108, pp. 1–9,
2018.
[24] T. Kim and J. Kittler, “Locally linear discriminant analysis for
multimodally distributed classes for face recognition with a
single model image,” IEEE Transactions on Pattern Analysis
and Machine Intelligence, vol. 27, no. 3, pp. 318–327, 2005.

Computational and Mathematical Methods in Medicine
[25] Y. Lu, H. Jiang, and W. Liu, “A review of EEG signal classiﬁer
based on deep learning,” in Proceedings of Information Science
and Cloud Computing — PoS(ISCC 2017), Guangzhou, China,
March 2018.
[26] Z. H. Zhou, Machine Learning, Tsinghua University Press,
Beijing, 2016.
[27] L. F. Nicolas-Alonso and J. Gomez-Gil, “Brain computer interfaces, a review,” Sensors, vol. 12, no. 2, pp. 1211–1279, 2012.
[28] H. Guo, R. TANG, Y. Ye, Z. Li, and X. He, “DeepFM: a
factorization-machine based neural network for CTR prediction,” in Proceedings of the Twenty-Sixth International Joint
Conference on Artiﬁcial Intelligence, Melbourne, Australia,
2017.
[29] S. Rendle, “Factorization machines,” in IEEE International
Conference on Data Mining IEEE, Sydney, NSW, Australia,
Dec. 2010.
[30] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Application of
dimensionality reduction in recommender system-a case study,
Minnesota Univ Minneapolis Dept of Computer Science,
2000.
[31] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning
representations by back-propagating errors,” Nature,
vol. 323, no. 6088, pp. 533–536, 1986.
[32] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[33] T. Wang, “Multi-focus fusion algorithm for noisy images,”
Optics and Precision Engineering, vol. 19, no. 12, pp. 2977–
2984, 2011.
[34] C. L. Zhen, Random Noise Suppression of Seismic Signal Based
on Wavelet Transform, Donghua University of technology,
2018.
[35] J. Morlet, G. Arens, E. Fourgeau, and D. Giard, “Wave propagation and sampling theory-part II:sampling theory and complex waves,” Geophysics, vol. 47, no. 2, pp. 222–236, 1982.
[36] A. Grossmann and J. Morlet, “Decomposition of hardy functions into square Integrable wavelets of constant shape,” SIAM
Journal on Mathematical Analysis, vol. 15, no. 4, pp. 723–736,
1984.
[37] J. Zhang and J. Cao, “Decision tree algorithm for big data analysis,” Computer Science, vol. 43, no. S1, pp. 374–379, 2016.
[38] S. H. Zhang, J. X. Liu, and L. F. Kong, “Occlusion detection
based on depth image using random forest,” Acta Optica
Sinica, vol. 34, no. 9, pp. 197–208, 2014.
[39] P. Komarek, Logistic regression for data mining and highdimensional classiﬁcation, pp. 29–36, 2004.
[40] S. F. Ding, B. J. Qi, and H. Tan, “A review of support vector
machine theory and algorithm,” Journal of University of Electronic Science and Technology, vol. 40, no. 1, pp. 2–10, 2011.

