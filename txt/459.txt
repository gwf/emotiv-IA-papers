Avances en Interacción Humano-Computadora, 2020, Año 5, Núm. 1, pp. 20-27
https://doi.org/10.47756/aihc.y5i1.63
RESEARCH PAPER

ViSA-EEG: A user-centered application for visualization
and statistical analysis of EEG signals
Yoselyn Nohemí Ortega-Gijón, Carmen Mezura-Godoy

Published: 30 November 2020

Abstract
The most common applications for human EEG research are:
Neuromarketing, Human factors, Social interaction, Psychology
and Neuroscience, Clinical and Psychiatric Studies and Brain
Computer Interfaces (BCI). In the BCI research, the existence of
software for the analysis of EEG signals is observed, however its
functionality is limited to showing the signals and certain
predefined characteristics, almost focused on the medical area,
allowing a visual analysis by an expert, in addition to the fact that
this software is developed depending on the signals to be analyzed
and on the BCI itself. Therefore, for the development of BCIs, it is
necessary for the developer to have software that allows him to
visualize and analyze the EGG signals, in addition to being able to
test and compare the interaction of users through the BCI, as well
as his brain activity during the interaction and being able to observe
the causes. In this context, we propose ViSA-EEG web application
that allows BCI developers to visualize and analyze the EEG
signals. This application was developed under a user-centered
approach, involving the user in each of the four development phases
and using different UX tools and techniques.

accordance with previous perception. The second refers to the
interaction, when the action performed by the human is sent to an
input interface, at that moment the recognition of the action is
performed, the representation and ends with the sending to the
output interface, to start again the cycle with perception. The third
involves the recognition of the actions by the computer and the
subsequent representation, the computer is responsible for
interpreting the user's cognitive functions and executing the
actions, giving the user feedback to continue the cycle.
Figure 1 shows the architecture of a Graphical User Interface GUI, where the 3 important parts of the Human-Computer
Interaction are located.
Particularly there is an interest in the development of
applications with Brain Computer Interfaces-BCI. The term
interface is used to name the functional connection that exists
between two programs, systems or devices, which provides
communication at various levels, making possible an exchange of
information.

Keywords
User centered design, Usability, User eXperience - UX,
Electroencephalography-EEG, Brain Computer Interface-BCI.

1. Introduction
The Human-Computer Interaction- IHC studies how people
interact with computers and to what extent computers develop to
improve interaction with people, its study components are: humans,
computers and the interaction between them [9].
Human interaction with the computer involves three processes.
The first comprises the cognitive functions performed when the
human being receives, interprets and stores information, at the
moment of sensory perception, then an action is performed in
Ortega-Gijón, Y.N., Mezura-Godoy, C.
Facultad de Estadística e Informática
Universidad Veracruzana
Xalapa, Veracruz, México.
zS18016065@estudiantes.uv.mx, cmezura@uv.mx

Figure 1. Architecture of the Graphical User Interfaces
In BCI, this exchange of information takes place between the
electrical activity of the brain and the device to be controlled [8].
The EEG measures the electrical activity of the brain at different
sites in the head, generally using electrodes placed on the scalp. In
the specific case of the BCI, mainly due to their architecture and
nature, the traditional evaluation methods such as interviews and
questionnaires are not necessary the best methods, because they
present the following problems: they do not give information in real
time, an information bias may arise or influence the evaluation,
since the user may be tired after the interaction with BCI. So, the
use of EEG has been proposed to evaluate the usability of BCIs
during user interaction [7,16].
There are different works that use algorithms for the analysis
of EEG signals [1,2,3,7,10,11,13,17,18], as well as different
20

Avances en Interacción Humano-Computadora
software or applications that perform the analysis [4,6,14,19]. But
in these works, the algorithms used were coded specifically for each
case study and in the case of the existing software, the license is too
expensive, and its functionality is limited to showing the signals
and certain predefined characteristics, almost they are focused on
the medical area, allowing a visual analysis only by an expert, also
they are mostly software desktop.
Therefore, for the development of BCIs, developers need
software that allows them to visualize and analyze the EGG signals,
in addition to test and to compare the interaction of users with the
application through the BCI, as well as his brain activity during the
interaction and being able to observe the causes. The present work
focuses on the development of ViSA-EEG, a web application that
allows: 1) data acquisition, 2) visualization of the EEG signals and
3) statistical analysis of the EEG signals. For statistical analysis,
fast Fourier transform algorithms were used to obtain the frequency
spectrum and wavelets (Daubechies 8) to obtain the frequency
bands. This application was developed under a user-centered
approach, involving the user in each of the four development phases
and using different UX tools and techniques.
The article is organized as follows: in section 2 the usercentered design approach is presented, the same as the development
of ViSA-EEG, in sections 3, 4, 5 and 6 the analysis and design of
the application and finally in section 7 the conclusions and future
work are presented.

2. User-centered design process
User-centered design is based on an explicit understanding of
users, tasks, and environment. Users are involved in the entire
design process. The user centered design has four phases according
to ISO 9241-210: 2010 [5]:
•
Understand and specify the context of use: To define it, it is
necessary to incorporate a methodology that includes central
user research.
•
Specify usage requirements: which are derived from the tasks
that the user performs in a context scenario.
•
Develop a design solution that meets the use requirements:
Based on the use requirements, a design solution is launched
to verify them, and a low or high-fidelity prototype will be
made depending on what is necessary for the test.
•
Evaluate the design solution with the usage requirements:
Finally, the solution is tested with real users that meet the
user's characteristics and a usability test is done, to correct
possible deficiencies, and re-iterate the process.

Ten people participated in the Visa design process (4 men and 6
women between 22 and 30 years old), all of them with experience
in software development. For each design phase, various UX
techniques were used that allowed feedback from the participants.

3. Understand and describe the context of use
The context of use is determined by: The characteristics of the user,
the most common tasks, equipment, the social and physical
environment where the equipment is used.

3.1. Characteristics of the User
Once our target audience is identified, it is necessary to empathize,
understand them as people in a context, who have needs,
motivations, expectations and aspirations that we must understand.
The empathy map helped humanize end-users and empathize
with them so that decisions are made based on their needs and
expectations, which have become a common goal. Empathy
Mapping is simplified into 5 main categories: 1) think / feel, 2) see,
3) hear, 4) say / do, 5) needs and pain, and focus on one person
within a specific situation relevant to the domain of the product.
The profile of the user to whom the product is directed is to a
BCI developer, whose main need is to make evaluation of BCI
interfaces with veracity in the information to improve the quality of
their work.
This type of user is characterized according to the 5 categories
by: 1) think/feel: about the architecture of the interfaces, the loss of
information, the bad interaction with clients and poor performance,
2) see: problems in hardware and software, irresponsible people,
the demand and the work overload, 3) hears: I don’t have time,
responsibility, 4) say/do: simultaneous tasks, be tired, evaluation
tests constantly, waste of time, improve interaction and endless
working hours, 5) needs: information overload, time insufficient.
To create the empathy map, a focus group was held where
users participated.
Figure 3 presents the empathy map developed, presenting as
main needs to improve its Interfaces through usability Assessment,
minimize time in testing and evaluation, and improve the quality of
its work.

Figure 2 shows the phases of the development process with
human-centered design, observing the order of each phase and the
correct iteration between them.

Figure 3. Empathy map of a BCI developer

3.2. Context of Use
Figure 2. Graph with the 4 phases of the ISO 9241 process

21

In a focus group session, users answered the following questions:
What Characteristics should the application have?. The most

Avances en Interacción Humano-Computadora
common responses were: easy access, security, cross-platform,
limited hard disk space. Analyzing the recovered information, it is
observed that a viable option was to build a web application, since
it could be executed with few computer resources and without the
need for prior installation.

3.3. Equipment
The information retrieved from the users in the focus group session
could establish the development of a web application, with the
following equipment specifications: i) System requirements: SO
Windows (7,8 y 10) 64 , Ubuntu, MacOs, ii) Platform: Web and iii)
Preferably browsers: Chrome and Safari.

4. Specify usage requirements
To obtain requirements and to visualize user´s experience as they
interact with the application the Customer Journey Map tool was
used. The Customer Journey Map describes the user´s interaction
points and helps to visualize the main functionalities. A focus group
was also carried out where the users expressed the main needs to
be solved.
-Requirements: BCI developers are the main users of ViSA-EEG.
These users need to analyze EEG signals, in order to for create new
BCI or improve them. This application must allow users to
visualize the signals obtained in your tests, compare the interaction
of the participant with their brain activity during the interaction,
observe the behavior of the signals through the spectrum and
frequency bands, being able to visually detect any sudden change
during the interaction and look for the causes of it. The list of
requirements was: 1) easy and friendly access, 2) to show all
channels properly, separating each one, 3) to observe the entire
length of the signal, 4) to visualize the bands and spectra, 5) to
visualize the user during the interaction for analysis, 6) to improve
analysis time and 7) to make statistical analysis.

5. Development of design solution
Once the user requirements have been defined, we proceed to the
design phase, by designing low and high-fidelity prototypes. To
carry out this phase, design tools are used, particularly were used
in Sketch, Wireframes and Mockups. It began developing the
Sketch which is a first paper sketch of the interface, then it
continued with the Wireframes where there is a real visualization
of the size and distribution of the controls, finally the Mockups
where the basic functionalities of the system can already be
appreciated like changing screens or displaying controls.

5.1. Low Fidelity Prototypes
At the beginning the Sketch tool was used was for the ViSA-EEG
software. The first strokes on a sheet of paper was made. In the
Sketch, the most characteristic elements such as logos, use of
metaphors are defined. Also, the form of navigation and content
and functional areas.

Figure 5. Sketch of the 1st screen
Figure 5 shows the final sketch of the first screen that was built
from the requirements, showing the distribution of the signal
elements, bands and spectrum. The distribution of the components
that were raised at the beginning was defined as follows: On the left
side, the test user is displayed during the interaction with the BCI
to be analyzed. In the central part are the EEG signals per channel.
On the right side, the frequency spectrum, frequency bands, and
busy montage are observed. With this structure user can visualize
the test and the signals on time at the same time, as well as their
bands and the spectrum of the signal to improve the analysis.

Figure 4. Customer Journey Map.
-User´s experience: The points of interaction were analyzed,
starting with access to the system and ending with the user and the
signs. For each point of interaction, the user experience was
evaluated based on the requirements and needs, analyzing the scope
that the application should have. In Figure 4 the Customer Journey
Map is presented. The green line presents de positive o negative
experience.
Figure 6. Sketch of the 2nd screen.

22

Avances en Interacción Humano-Computadora
Figure 6 shows the final sketch of the second screen that was built
from the requirements, showing the location of the video and the
EEG signals. The distribution of the components that were initially
raised for the second screen was stipulated as follows: on the left
side, the test user is shown during the interaction with the BCI to
be analyzed. On the right side, the obtained EEG signals are
observed. This distribution was based on the user's requirement to
visualize the interaction and the EEG signals at the same time to be
able to compare. Users participated by evaluating the design
elements and providing feedback.
Later the Wireframe tool was used. The Wireframe connects the
conceptual structure, or information architecture, with the visual
design of the web or application. They help establish functionality,
and relationships between different screen templates.
A Wireframe was developed for this application, through this
process the hierarchy of the design information could be defined,
and it was easier to plan the design according to how the user wants
to process the information.
Figure 7 shows the Wireframe of the first screen that was built
from the Sketch previously presented, showing the distribution of
the elements of the signals, bands and spectrum. Again, the
distribution of the first screen was proposed: on the left side, the
test user is displayed during the interaction with the BCI to be
evaluated. In the central part are the EEG signals per channel. On
the right side, the frequency spectrum, frequency bands, and busy
montage are observed.

In the development and validation of the Wireframes, the users
again had a strong participation. The Wireframes were shown to
them on the screen, feedback was obtained, and changes were
made, until the latest version was obtained. In particular, the size
and location of the controls were validated, as well as the first
functionalities were observed and verified. During Wireframe
construction, users had better ideas of sizes and spaces and use of
interface components.

5.2 High Fidelity Prototypes
For de development of the high-fidelity prototype Mockup tool was
used. The Mockup is a means of representing the appearance of the
product, it shows the fundamentals of its functionality. Mockups
include visual details, such as colors, typography, etc., and are
generally static. When looking at a mockup, you need to have a
good idea of what the end product will look like and a rough idea
of how it might work (even if the features haven't been developed
yet). For the development of the Mockups more similar to what the
application, web page, etc. will be, the ADOBE XD tool was used.
Figure 9 shows the Mockup of the first screen from the
previous Wireframes, showing the elements, the colors to use and
the graphic design. The distribution of the components is the same
as that shown previously by the Sketch and Wireframe of the first
screen, the main ones being the user's display, the EEG signals per
channel, the spectrum, the frequency bands and the assembly.
When making the Mockup, the idea of space and size of the
components continued to be improved by occupying an image of
real EEG signals, and the possible colors to be used in the
application are also presented. For EEG signals each channel is
represented with a color, in order to be able to locate and
differentiate one from the other in the assembly.
The first functionalities are also shown, pointing out in the
design the components that will perform some action by means of
a small arrow, these components are the buttons that are at the top
(Start, User, Bands).

Figure 7. Wireframe of the 1st screen.
Figure 8 shows the final Wireframe of the second screen that
was built from the Sketch, showing the location of the video and
synchronization with the signals. The same Sketch distribution of
the second window was followed, displaying the user interaction
on the left side and the EEG signals on the right side. With this
wireframe it is still a complete design phase, giving a bigger picture
of size and space. At this stage the components are still presented
in black and white.

Figure 9. Mockup of the 1st screen

Figure 8. Wireframe of the 2nd screen

23

Figure 10 shows the Mockup of the second screen from the
previous Wireframes and graphic design. The same distribution of
the Sketch and the Wireframe is followed, but in this case the user's
visualization during the interaction is represented with the BCI
image of Emotiv, where the movement of a cube from
concentration is performed. In the case of the signals, they are

Avances en Interacción Humano-Computadora
represented by the image of a graph and with the colors to be used
in the final application.

“reticulate” package, from Shiny the function calls are made in
Python and the result is received again.
Figure 12 details the programming languages, the development
software and the packages or libraries used for the development of
the application.

Figure 12. Implementation tools
Figure 10. Mockup of the 2nd screen.
In the operational part, the components that perform
visualization functions such as change of graph, change of screen
and modification of interactive graph are shown.
Figure 11 shows the Mockup, showing the transitions between
the screens, giving greater functionality and graphic design.

5.3.2. Software architecture
The architecture of the application is as follows: 1) Graphic
Interface: The user enters the web application and the start screen
is displayed, where it proceeds to load the data of the EEG signals,
sending a request to the server, then receives the response. 2)
Server: Receives the request and performs the respective process
by sending the result, the operations to be performed by the server
are to read the EEG data, view the signals and perform the statistical
analysis of the signals. Figure 13 presents the architecture of the
application.

Figure 11. Mockup of the Interaction between the 1st and
2nd week
The mockups were validated by the users, the mockups were
shown to them on the screen, feedback was obtained, and changes
were made, until the latest version was obtained. In particular, the
size, location of the controls and even the color of the interface, as
well as the basic functionalities, were ratified. At this point user
have a clear idea of how the final interface works.

5.3. Implementation
Once the interface design was completed and the functionalities
were defined, the ViSA-EEG coding continued. The following
describes: the implementation tools and the software architecture.

5.3.1. Implementation tools
The Shiny Package of RStudio was implemented, this package
allows the construction of graphic Web interfaces and
communication with Python, performing operations faster. The
communication between Python and R is done through the

Figure 13. Components of software architecture
-Graphical User Interface: The interface of the web application is
made up of the following elements: 1) Panels, which divide the
sector of signals, bands and spectrum on the screen. 2) Tabs, to
change the application section, between the signals section, the
spectrum section and finally the user / video section. 3) Sidebar,
where are the interaction controls to manipulate the signals. 4)
Controls, there is the data load button, slider to select the window
and the width of the window to be displayed, and finally a combo
box to select the channel / signal.
-Data read: To read the signals, the file format is ".csv", and it must
be structured as follows. Figure 14-left shows the structure of the
“.csv” file, figure 13-right shows the location of the nodes. Each
column represents a Channel, having a total of 14 channels (F3, F4,
F7, F8, T7, T8, AF3, AF4, P7, P8, O1, O2, FC5, FC6), the rows are
the records obtained from the channels.

24

Avances en Interacción Humano-Computadora

Figure 14. File specifications
- Statistical analysis of the EEG signals: The following algorithms
were used for the statistical analysis of the signals: 1) Fast Fourier
transform. - It is a mathematical transformation used to transform
signals between the time (or spatial) domain and the frequency
domain, which has many applications in physics and engineering,
its applications are signal processing and in this work they deal with
the acquisition of the frequency spectrum. 2) Waves. - It is a special
type of mathematical transform that represents a signal in terms of
translated and dilated versions of a finite wave (called the mother
wave). Regarding its applications, the wave transform is used for
signal encoding and analysis, being used in this work to obtain the
frequency bands.
- Visualization of EEG signals: The button to load the “CSV” file
is located in the upper left (See figure 15).

Figure 15. Data loading.
Once the signals are obtained, the EEG signals divided into
channels can be viewed. These channels are the same as those
presented in the assembly. At the moment of executing it, the
following dialog window will appear to select said structured file
with the specifications shown above.
Figure 16 shows the first second of time. of the signals. In
order to display more, you can change the width of the window and
the window to be displayed, changing the values on the left side of
the menu. Regarding the frequency bands, the default “F3” channel
bands are shown, to change it is also done through the menu.

Figure 16. Visualization of EEG signals.
Once the signals have been obtained, the frequency bands and
the frequency spectrum can be visualized, as shown in the
following image. It is important to emphasize that when changing
the width of the window and the # of the window to show the EEG
signals, it will also change the bands and the spectrum. Figure 17
presents the initial screen of the application and the location of the
EEG signals, bands and frequency spectrum.

Figure 17. Visualization of EEG signals.
The distribution of the components is not the same as that
previously proposed, given the size of the signals and the addition
of a control panel (data load, time window, window size), it was
necessary to change the distribution, adding a new window with
user visualization and EEG signals.
Figure 18 shows the frequency spectra of the signals, with the
functionality of changing the window width and the window to be
displayed.

Figure 17. Visualization of the frequency spectrum.

25

Avances en Interacción Humano-Computadora
And finally, figure 19 of the video display and the EGG signals
are shown, along with the frequency bands corresponding to the
selected channel, located in the 3rd tab of the application.

positive points of the application are as follows: 1) minimalist
design, 2) convenient interface colors, 3) proper design layout, and
4) consistent design.
Table 2. Table captions should be placed above the table.

Figure 19. User visualization during the interaction.

Heuristics

Description

1 2 3 4 5 R

System state
visibility

The system should always keep users
informed about what is happening, through
appropriate feedback in a reasonable time.

5 3 1 5 4 4

Coincidence The system must speak in the language of the
between the
user, with words, phrases and concepts
system and the familiar to him. Use real-world conventions, 5 5 4 5 4 5
real world
making information appear in a natural and
logical order.
User control
and freedom

6. Evaluate the design solution
For the evaluation it was necessary to define the heuristic
evaluation method. There are different heuristics for testing /
evaluation are called "heuristics", the most used heuristics are those
of Jakob Nielsen, these are ten general principles for the design of
the user interface [15]. Nielsen heuristics were used for the
application tests, this evaluation was carried out by 5 experts in
usability. Table 1 shows the characteristics of the evaluators such
as age, sex and the level of experience in usability, where 1
represents the minimum and 5 the maximum level of experience.
Table 1. Characteristics of the evaluators.
User

Sex

Usability experience

1

Women

5

2

Man

3

3

Women

4

4

Women

5

5

Man

4

The experts proceeded to carry out the system tests, starting
with the selection of the csv file to obtain and visualize the data, the
visualization of the signals and ending with the functionality of the
widgets.
Table 2 shows the results of the heuristic evaluation. Each
evaluator proceeded to validate each heuristic in the application. A
score of 1 to 5 was established, where 1 is the minimum value and
5 the maximum. It was also established that for elements evaluated
on average with 3 or lower, they should be attended immediately
and for elements evaluated between 5 and 4 on average they can be
done later (the next version of the system). Work was done
immediately on providing help and documentation and how to get
out of fatal errors. It should be noted that in addition to the heuristic
evaluation, the expert provided recommendations for improving the
application.
In the results of the heuristic evaluation, the benefits of
applying the human-centered design process can be observed,
obtaining good results and with few observations to solve. Among
the most important observations to improve the usability of the
application, and that were contributed by the experts, are the
following: 1) to include the level of interaction (know what is
before and what is next), 2) to use iconography with metaphors for
some functions and 3) provide help options. On the other hand, the

Users often choose features by mistake and
need an "emergency door" to get out of the
unwanted state. Offer support to undo and
redo actions.

3 3 3 5 5 4

Consistency Users should not have to wonder if the various
and standards words, situations, or actions mean the same
thing. That the rules and conventions of the 3 5 5 5 5 5
platform on which the system is being
implemented are followed.
Error
prevention

Rather than designing good error messages, it
5 3 5 5 5 5
is better to prevent the problem from occurring

Recognition
better than
remember

Minimize user memory load by making
objects, actions, and options visible. The user
should not have to remember information 3 5 5 5 4 4
from one part of the dialogue to another.

Flexibility and Accelerators, not seen by the beginning user,
efficiency of improve interaction for the expert user in such
use
a way that the system can be used by
3 5 3 5 5 4
inexperienced and experienced users. It is
important that the system allows customizing
frequent actions.
Aesthetic and
minimalist
design

Dialogues should not contain irrelevant or
rarely needed information. Each extra unit of
information in a dialogue competes with the 5 5 5 5 4 5
important information, decreasing its relative
visibility.

Help recognize, Error messages should be expressed in plain
diagnose and language (no codes), accurately indicating the
1 3 1 5 3 3
recover from
problem and suggesting a solution.
errors
Although it is better that the system can be
used without documentation, it is necessary to
Help and
provide the user with help and documentation.
documentation
1 1 3 5 4 3
This has to be easy to search, focused on the
user's tasks, with information on the stages to
be carried out and that is not very extensive.

7. Conclusion
The user-centered design process aims to make systems usable and
useful, by focusing on users, their needs and requirements, while
applying ergonomic techniques and usability knowledge. This
approach promotes effectiveness and efficiency, improves human
well-being, user satisfaction, accessibility, and sustainability,
taking into account the end user from conception and during
development.
The phases and tools that were used in the design process are
very important for development, since they helped make it clear to
whom the application is directed, why its development is necessary,

26

Avances en Interacción Humano-Computadora
what are the requirements to satisfy, minimize time in the
elaboration of the design at the moment of showing the users from
the initial sketches to the final application, helping to make
corrections from the beginning in a timely manner.
This application is aimed at all BCI developers, to analyze the
EEG signals resulting from the interaction with their developed
applications, having as objectives to visualize the signals
completely and correctly, to be able to visualize the user and obtain
a statistical analysis of the signals.
In the results of the heuristic evaluation, the benefits of
applying the user-centered design process can be observed,
obtaining good results and with few observations to resolve, such
as helping to resolve errors and user help section. Given the results
of the research, the line to follow is the analysis and tests for the
measurement of different aspects / factors to contribute and
improve the evaluation of usability in the BCI. Another aspect to
cover more rigorous testing of the application with users and to
update or add functionality.

Acknowledgements
This work was partially developed under the support of the
National Council of Science and Technology (CONACYT) in the
scope of the Catedras CONACYT project “Infraestructura para
Agilizar el Desarrollo de Sistemas Centrados en el Usuario”, Ref.
3053. In addition, we thank CONACYT for the doctoral
scholarship number 785866 of the first author, as well as at
Universidad Veracruzana for the support in the development of this
research.

References
[1] Ansari-Asl, K., Chanel, G., and Pun, T. (2007). A channel
selection method for EEG classification in emotion
assessment based on synchronization likelihood. In 2007 15th
European Signal Processing Conference (pp. 1241-1245).
IEEE.
[2] Appriou, A., Cichocki, A., and Lotte, F. (2018). Towards
robust neuroadaptive HCI: exploring modern machine
learning methods to estimate mental workload from EEG
signals. In Extended Abstracts of the 2018 CHI Conference on
Human Factors in Computing Systems (pp. 1-6).
[3] Bhardwaj, A., Gupta, A., Jain, P., Rani, A., and Yadav, J.
(2015). Classification of human emotions from EEG signals
using SVM and LDA Classifiers. In 2015 2nd International
Conference on Signal Processing and Integrated Networks
(SPIN) (pp. 180-185). IEEE.
[4] Brunner, C., Andreoni, G., Bianchi, L., Blankertz, B.,
Breitwieser, C., Kanoh, S. I., ... and Perego, P. (2012). BCI
software platforms. In Towards Practical Brain-Computer
Interfaces (pp. 303-331). Springer, Berlin, Heidelberg.
[5] DIS, I. (2010). 9241-210: 2010. Ergonomics of human system
interaction-Part 210: Human-centered design for interactive
systems (formerly known as 13407). International
Standardization Organization (ISO). Switzerland.

[6] Erkan, E., and Akbaba, M. (2018). A study on performance
increasing in SSVEP based BCI application. Engineering
Science and Technology, an International Journal, 21(3),
421-427.
[7] Frey, J., Pommereau, L., Lotte, F., and Hachet, M. (2014).
Assessing the zone of comfort in stereoscopic displays using
EEG. In CHI'14 Extended Abstracts on Human Factors in
Computing Systems (pp. 2041-2046).
[8] Gentiletti, G., Tabernig, C., and Acevedo, R. (2007). Interfaz
cerebro-computadora: Estado del arte y desarrollo en
Argentina. Revista Argentina de Bioingeniería, Revista SABI,
pp22-29, 13(1).
[9] Helander, M. G. (2014). Handbook of human-computer
interaction. Elsevier.
[10] Hosseini, S. A., and Khalilzadeh, M. A. (2010). Emotional
stress recognition system using EEG and psychophysiological
signals: Using new labelling process of EEG signals in
emotional stress state. In 2010 international conference on
biomedical engineering and computer science (pp. 1-6).
IEEE.
[11] Kumar, N., and Kumar, J. (2016). Measurement of cognitive
load in HCI systems using EEG power spectrum: an
experimental study. Procedia Computer Science, 84, 70-78.
[12] Kumar, J. (2016). Affective modelling of users in HCI using
EEG. Procedia Computer Science, 84, 107-114.
[13] Liu, Y., Sourina, O., and Nguyen, M. K. (2010). Real-time
EEG-based human emotion recognition and visualization.
In 2010 international conference on cyberworlds (pp. 262269). IEEE.
[14] Nam, C. S., Nijholt, A., and Lotte, F. (2018). Brain–
computer interfaces handbook: technological and theoretical
advances. CRC Press.
[15] Jimenez, C., Lozada, P., and Rosas, P. (2016). Usability
heuristics: A systematic review. In 2016 IEEE 11th
Colombian Computing Conference (CCC) (pp. 1-8). IEEE.
[16] Ortega-Gijón, Y. N., and Mezura-Godoy, C. (2019). Usability
evaluation process of brain computer interfaces: an
experimental study. In Proceedings of the IX Latin American
Conference on Human Computer Interaction (pp. 1-8).
[17] Parra, L. C., Spence, C. D., Gerson, A. D., and Sajda, P.
(2003). Response error correction-a demonstration of
improved human-machine performance using real-time EEG
monitoring. IEEE transactions on neural systems and
rehabilitation engineering, 11(2), 173-177.
[18] Wang, Q., Sourina, O., and Nguyen, M. K. (2010). Eeg-based"
serious" games design for medical applications. In 2010
international conference on cyberworlds (pp. 270-276). IEEE.
Xing, X., Wang, Y., Pei, W., Guo, X., Liu, Z., Wang, F., ... and
Chen, H. (2018). A high-speed SSVEP-based BCI using dry
EEG electrodes. Scientific reports, 8(1), 1-10.

© 2020 by the authors. This work is licensed under the Creative Commons AttributionNonCommercial-NoDerivatives 4.0 International License. To view a copy of this license,
visit http://creativecommons.org/licenses/by-nc-nd/4.0/ or send a letter to Creative
Commons, PO Box 1866, Mountain View, CA 94042, USA.

27

