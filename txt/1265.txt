HHS Public Access
Author manuscript
Author Manuscript

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.
Published in final edited form as:

IEEE Trans Neural Syst Rehabil Eng. 2017 August ; 25(8): 1153–1163. doi:10.1109/TNSRE.
2016.2608791.

A Robotic Coach Architecture for Elder Care (ROCARE) Based
on Multi-user Engagement Models
Jing Fan [Student Member, IEEE],
Electrical Engineering and Computer Science Department, Vanderbilt University, Nashville, TN
37212 USA

Author Manuscript

Dayi Bian,
Electrical Engineering and Computer Science Department, Vanderbilt University, Nashville, TN
37212 USA
Zhi Zheng,
Electrical Engineering and Computer Science Department, Vanderbilt University, Nashville, TN
37212 USA
Linda Beuscher,
Vanderbilt University School of Nursing, Nashville, TN 37204 USA
Paul A. Newhouse,
Center for Cognitive Medicine, Department of Psychiatry, Vanderbilt University School of
Medicine; Geriatric Research Education and Clinical Center, VA Tennessee Valley Health
System, Nashville, TN, 37212 USA

Author Manuscript

Lorraine C. Mion, and
Vanderbilt University School of Nursing, Nashville, TN 37204 USA
Nilanjan Sarkar [Senior Member, IEEE]
Mechanical Engineering Department, Electrical Engineering and Computer Science Department,
Vanderbilt University, Nashville, TN 37212 USA

Abstract

Author Manuscript

The aging population with its concomitant medical conditions, physical and cognitive
impairments, at a time of strained resources, establishes the urgent need to explore advanced
technologies that may enhance function and quality of life. Recently, robotic technology,
especially socially assistive robotics has been investigated to address the physical, cognitive, and
social needs of older adults. Most system to date have predominantly focused on one-on-one
human robot interaction (HRI). In this paper, we present a multi-user engagement-based robotic
coach system architecture (ROCARE). ROCARE is capable of administering both one-on-one and
multi-user HRI, providing implicit and explicit channels of communication, and individualized
activity management for long-term engagement. Two preliminary feasibility studies, a one-on-one
interaction and a triadic interaction with two humans and a robot, were conducted and the results
indicated potential usefulness and acceptance by older adults, with and without cognitive
impairment.

Fan et al.

Page 2

Author Manuscript

Index Terms
human-robot interaction; socially assistive robotics; system architecture; elder care; affective
computing

I. Introduction

Author Manuscript

In 2010, 13% of the US population was 65 years or older and this number is projected to
double by 2030 with the oldest-old, those 85 years and older, growing at the fastest pace;
this is the group most likely to have problems with physical functioning, functional decline,
cognitive impairment, dementia, falls, and injury [1][2][3][4]. Up to 70% of older adults will
develop significant disabilities and 35% will eventually reside in assisted living or enter a
nursing home [5]. Health care costs for the behavioral consequences of these disorders are
staggering [3][6]. Thus, maintaining or improving physical and cognitive function,
promoting communication and social interaction, and enhancing engagement are pivotal in
geriatric care.

Author Manuscript

Nonpharmacologic interventions for these disorders such as physical activity, exercise,
social interaction and engagement, cognitive stimulation, music, art therapy, reminiscence
therapy, and caregiver intervention have had inconsistent results [7][8] and can be resource
intensive. Additionally, considering nursing shortage and high staff turnover in long term
care settings, there is an urgent need for efficacious strategies that are tailored to the
individuals within resource strained environments. Recently, socially assistive robotic (SAR)
systems appear promising in addressing the physical, cognitive and/or social needs of older
adults. A SAR system, unlike robotic wheelchair and exoskeleton, provides assistance
and/or achieves measurable user progress through social interaction [9]. As compared to
other interactive technologies, SAR has the advantage of embedding novel quantitative
metrics, sensor-based non-invasive methodologies, incorporating physical movement into
realistically embodied interactions, and meaningfully responding to pivotal aspects of
human engagement and behavior, and thus has substantial promise for impacting function
and engagement of older adults.

Author Manuscript

Earlier work of SAR systems with older adults [10][11] primarily fall into two categories:
companion robots, generally animal shaped, for social engagement [12], and service type
robots supporting independent living, such as intelligent reminder etc. [13]. There is a
growing interest in SAR systems that act as a coach or a guide to engage and encourage
users through a series of therapeutic tasks for enhancing their physical or cognitive
functions, as well as their health conditions. We refer to such systems as robotic coach
systems. Several investigators have used the Wizard of Oz (WoZ) experimental paradigm
[14] or open-loop robotic systems [15]. These systems are limited in their capacity for HRI,
requiring remote human control for change of robot behaviors, and often times requiring
sophisticated users.
More recently, closed-loop robotic systems have been developed. Commercial robots NAO
[16][17], RoboPhilo [18], and Manoi-PF01 [19] were used to build robotic coach systems to
assist older adults in performing physical exercises. Fasola and Mataric [20] designed and
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 3

Author Manuscript

implemented a robotic coach system, Bandit, that monitored and encouraged older adults to
perform chair exercises. Bandit personalized its interaction via task performance, progress,
and session history. Tapus et al. [21] tested the effectiveness of robot-mediated cognitive
intervention with dementia patients once per week over eight months and observed an
improvement in task performance. These works relied on explicit task performance as
feedback to adapt robot’s behaviors. McColl et al. included implicit channel of
communication in their robotic system Brian 2.1 [22]. Brian 2.1 was developed to engage
older adults in eating activity and a cognitive stimulation activity, and had the capability of
adapting its behavior based on the state of the activities as well as user’s body language
(attentive or distracted). These researchers also developed a robotic system Tangy [23][24]
for use in long-term care facilities to provide telepresence and group-based cognitive
intervention. Robotic coach systems were also developed for stroke rehabilitation, autism
intervention, and weight loss [21][25][26].

Author Manuscript
Author Manuscript

Most systems to date have predominantly focused on one-on-one interaction. Multi-user
interaction is pivotal for fostering social interaction. Only two studies to our knowledge have
investigated group-based closed-loop robot-mediated interaction for older adults. Kanoh and
associates devised a robot-assisted activity program comprised of one robot with five to six
human participants, but required one human assistant to mediate communication between
the robot and the participants [27]. Louie and associates were able to provide autonomous
interaction by the robot with an individual, but not between individuals [24]. The objective
of this work was to develop a robotic coach system architecture that allows effective
interaction with one or multiple older adults and achieve long-term engagement for the
purpose of maintaining functional abilities as well as socialization. In this paper, we present
the mathematical models of the system architecture which a) is capable of one-on-one
interaction and multi-user interaction; b) contains both explicit and implicit channels of
communication; and c) allows dynamic adaptive robotic behavior and activity management
based on real-time human interaction. Further, we performed two feasibility studies on older
adults to assess our design paradigm and test on older adults’ acceptance of the robotic
coach system.
The paper is organized as follows. Section II presents the mathematical models of the
RObotic Coach ARchitecture for Elder care (ROCARE) and places it in context with
existing SAR architectures. Section III describes the preliminary feasibility studies and
system implementation. Section IV and V presents the results and discusses their
implications, respectively. Finally, we summarize the contributions of the paper and
highlight future directions in section VI.

Author Manuscript

II. Design of a Robotic Coach System Architecture
The primary goals of the ROCARE are: a) it should be able to adapt its behavior to each
individual user as the HRI progresses; b) it needs to perform quantitative measurements of
the user’s task performance on activities, as well as the user’s affective states and gaze
position; c) the robotic coach system must be designed so that it can be operated by a nontechnical caregiver; and d) the system can target activities designed to be beneficial in
addressing mobility and functioning simultaneously satisfying user’s preferences and ability.

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 4

Author Manuscript

To achieve these goals, ROCARE needs to have the following features: a) multimodal HRI;
b) individualized robot behavior adaption; c) rigorous measurements and well-structured
task design; and d) administrator friendly control panel.

Author Manuscript

ROCARE (Fig. 1), which possesses the aforementioned characteristics, is comprised of five
modules: Sensing, Actuation, Database, Supervisory Controller and Graphical User
Interface (GUI). A human administrator is responsible for initializing the session and
monitoring task progression via the GUI. Database maintains a knowledge base of each user
to facilitate the decision-making process of the Supervisory Controller. Supervisory
Controller is the core element of ROCARE. It estimates the states of HRI and human-human
interaction (HHI) based on engagement models, and generates control policies for dynamic
system adaptation. Users interact with ROCARE through Sensing and Actuation. Sensing
collects both implicit and explicit interaction cues from users, whereas Actuation performs
the actions the system needs to take as determined by the Supervisory Controller. The five
primary modules are composed of submodules that are responsible for specific
functionalities.
A. Comparison with Existing SAR Architectures

Author Manuscript

There are several existing SAR architectures designed for behavior intervention for children
with autism spectrum disorder [28], functional intervention or companion purpose for older
adults [13][20][24][29][30][31][32], as well as other applications [33][34]. All these
architectures including ours have component(s) or module(s) dedicated to sensing and
actuation, which provide the interface between SAR systems and targeted users; and
decision making, for system behavior adaptation. SAR Architectures in [28] and [20]
incorporated a database to store HRI history. In ROCARE, the submodule interaction
memory in Database serves a similar purpose.

Author Manuscript

Our approach is tightly coupled with the primary goals described earlier and results in some
differences and rearrangements of the modules. First, in Sensing we modified and extended
the Sensory Input Recognition and Analysis Modules proposed by Chan and Nejat [29] [30]
and the User State and Activity State Modules presented by Louie et al. [24]. The implicit
state submodule in ROCARE is dedicated to implicit channel of communication between the
SAR system and users, whereas the explicit state submodule is dedicated to explicit channel
of communication. Second, two submodules, activity preferences in Database and activity
management in Supervisory Controller, were added to keep track of user’s preferences and
select appropriate activities for the purpose of promoting engagement while maximizing the
efficiency of the interaction. Third, we integrated a GUI to allow intuitive control, operation,
and monitoring of the robotic coach system by an administrator.
Several characteristics distinguish ROCARE: a) mathematical models for each module and
relationships among modules instead of simple interconnection; b) engagement models to
capture the dynamics of HHI and HRI; c) capacity for both one-on-one interaction and
multi-user interaction; and d) generalizability of the architecture for different HRI scenarios.
In what follows, we describe each module along with its submodules in detail.

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 5

B. Engagement Models

Author Manuscript

In HRI, engagement is a critical component, defined as the act of being occupied or involved
in an external stimulus [35]. We capture the dynamics of HHI and HRI using engagement
models. Our models leverages the models for multiparty engagement proposed by Bohus
and Horvitz [36]. We adopted their idea of representing user engagement using three
engagement variables but modified the model for each engagement variable. The three
engagement variables for each agent a ∈ {user(s),robot} and interaction i ∈ {HRI,HHI} are:
the engagement state

, the engagement action

, and the engagement intention

.

Author Manuscript

The engagement state
represents whether agent a is involved in interaction i and is
modeled by a timed automaton with two states: engaged or not-engaged (Fig. 2). We
presume that all agents are in the state engaged at the beginning of the interaction. Since
engagement is a collaborative process, agent a is engaged either with an engagement action
initiated by agent a, such as gestures or direct responses, or with engagement
, which indicates agent a is paying attention to other agents. Agent a
intention
becomes disengaged, in state not-engaged, if he/she is not actively involved in the
interaction for time_out amount of time. The engagement action
conditional statistical model of the form:

is estimated by a

(1)

Author Manuscript

Occurrence of engagement action of agent a in the interaction i depends on gestures, speech
or direct inputs detected by the system, i.e., explicit state of agent a (Ψa (t)) ; previous
engagement states of all the agents in the interaction i

; current
; and the current

engagement states of all the agents in the interaction
game behavior (Λ(t)). Similarly, the engagement intention

is estimated by:

(2)

Author Manuscript

where Γa (t) denotes the agent’s implicit state detected by the system, including affective
states (engaged, bored, frustrated, etc.) as well as direction of attention measured by gaze
position. We describe Ψa (t) and Γa (t) in more detail in the next section. For agent a = robot,
∀t ∈ℝ,i∈ {HRI, HHI},

,

.

C. Sensing and Actuation
The multimodal HRI feature is reflected in Sensing and Actuation. Sensing is responsible
for logging and interpreting data collected by sensors and cameras. It is composed of

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 6

Author Manuscript

implicit state (Γa (t)) and explicit state (Ψa (t)). Implicit state facilitates the inference of the
engagement intention of agent a through affective states recognition and gaze estimation.
For example, in a multi-user interaction scenario, when the robot is interacting with one
user, another user may be engaged by having eye contact with the robot even though he/she
is not directly involved in the interaction. Explicit state aids the inference of the engagement
actions. According to the context of the interaction, i.e., game behavior (Λ(t)), detected
gesture or speech inputs are engagement actions if they are directly related to task
performance. Otherwise, based on the previous and current engagement states of all the
agents, detected Ψa(t) may be social cues during interaction (an engagement action) or
random noise (not an engagement action).
Both Γa (t) and Ψa (t) are detected by Sensing and are sent to the Supervisory Controller to

Author Manuscript

estimate
and
. Sensing communicates with Supervisory Controller in two
modes: a) sending current implicit state and explicit state upon request. For instance, the
Supervisory Controller queries gesture recognition about the user’s performance on the
exercise motions during the physical exercise task. b) Whenever a significant event is
detected. Example of a significant event is the user’s gaze shifts away when the robot is
dancing, which indicates the user is not interested or distracted; in this event, actions need to
be taken to reengage the user. Behaviors of the robotic system are generated via Actuation,
which consists of the low-level robot controller and audiovisual stimuli. Low-level robot
controller manages and controls the robot hardware to realize robot behavior, a.k.a.
, while the audiovisual stimuli operates all the other hardware involved in
the interaction, e.g. monitors, and updates the game behavior Λ (t).

Author Manuscript

D. Database and Graphical User Interface

Database contains three main submodules: interaction memory, activity preferences, and rule
engine. It is individualized; in other words, each user a ∈(Ω −{robot}) has his/her own
database which is independent from other databases. Interaction memory stores the history
of HHI and HRI, represented by the following tuple:

(3)

Activity preferences and rule engine submodules provide key information for activity
management. They maintain three sets of parameters, including each user’s degree of likes

Author Manuscript

and dislikes regarding different types of activities
activity type for each user
for each user
following model:

, the importance of each

, and the appropriate difficulty level of each activity type

. These parameters are updated during the interaction based on the

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 7

Author Manuscript

(4)

(5)

(6)

Author Manuscript

is a function of user’s engagement state corresponding to activity AT, as well as
direct input by an administrator through the GUI.
is a function of the history of the
game behavior, i.e., past activities, and changes made via the GUI. And the difficulty level
parameters
is determined by the user’s task performance and implicit state, as well as
GUI inputs. fGUI is a monotonically increasing function which weighs the direct inputs from
the GUI. The sole purpose of the GUI is to allow non-experts to operate ROCARE and
monitor the progress.
For illustrative purposes, we give an example of updating

. We assume that there are

m types of activities and
; the user likes the activity if he/she is engaged for
more than half of the activity duration and the weights for engagement and GUI inputs are

Author Manuscript

wES and wGUI respectively. Initially, ∀AT,

. The robotic system starts with the

activity “dance to music”. At the end of this activity, the new set of

is calculated as:

if AT = music,

(7)

(8)

Author Manuscript

∀AT ≠ music,

(9)

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 8

E. Supervisory Controller

Author Manuscript

Supervisory Controller is responsible for making autonomous decisions related to the
robot’s behavior
and task adjustment (Λ(t)) (e.g., repeat the exercise,
establish mutual gaze, etc.) regarding the ongoing activity chosen by activity management.

Activity management is dedicated to activity selection and scheduling by analyzing

,

, and the goal of the system (G). In a one-on-one interaction scenario, it can be realized

Author Manuscript

by simply selecting the activity that has the highest
value. System goal can be
represented by the engagement variables. For example, in one-on-one interaction scenarios,
the system goal could be to maximize user engagement during HRI, i.e., G = maxHRI (ES),
whereas for the multi-user case, the goal could be to maximize user engagement with
another user, i.e., G = maxHHI (ES). Robot behavior and game behavior are either controlled
by a reactive model or through learning algorithms. The control policies for robot behavior
and game behavior are conditioned on task difficulty level
, the engagement variables of
all the users EV, previous robot behavior and game behavior H, and the goal of the system
G.

(10)

(11)

Author Manuscript

(12)

III. Feasibility Studies

Author Manuscript

We conducted two preliminary feasibility studies to determine whether ROCARE a) can be
used for both one-on-one and multi-user interaction; and b) could engage older adults’
interest and participation. While the architecture does not assume any particular robot, our
system was built around the NAO robot platform (www.aldebaran.com) because of its
availability as well as its open architecture that allows relatively easy pathways for custom
software development and integration with other devices.
A. HRI Scenarios
Scenario 1 – individual user performing multiple activities—This scenario was
designed to explore older adults’ behaviors and responses to ROCARE, and the feasibility of
inferring their engagement intention variables

based on implicit communication

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 9

Author Manuscript

cues, in this specific case, through electrophysiological signals and gaze position (Γa (t)).
Several activities were selected: an orientation activity where the robot points to pictures
hanging in the experiment room, simple math, observing the robot dance to music, a form of
the “21 questions” game where the robot guesses the person’s birth state, and joint chair
exercises. Each participant sat in a straight back chair directly in front of and six feet away
from the robot. Three pictures were hung on the walls of the experiment room at different
locations. Electrophysiological sensors were placed on the head and the body of the
participant. A Kinect RGBD sensor was used to augment NAO’s vision for gesture
recognition and gaze estimation. A researcher initiated and observed the session via the GUI
and a one-way mirror in an adjacent room.

Author Manuscript

Scenario 2 – paired users performing single activity—We extended the interaction
to allow simultaneous interaction with two older adults mediated by the robotic coach. The
triadic HRI scenario consisted of introduction and “Simon says” game [37], where each
individual and the robot took turns as Simon. Physiological sensors were excluded in this
scenario.

Author Manuscript

1) One-on-one Interaction: The implemented Sensing module is capable of
electrophysiological signal collection, gaze estimation, gesture recognition, and speech
recognition. We used a 14-channel Emotiv EPOC neuroheadset (www.emotiv.com) to record
electroencephalography (EEG) signals, and a Biopac MP150 physiological data acquisition
system (www.biopac.com) to collect physiological data. The bandwidth of the EEG signals
is from 0.2 to 45Hz and the sampling rate is 128Hz. Regarding physiological signal, tonic
and phasic responses from galvanic skin response (GSR), were logged with a sampling rate
of 1000Hz. These signals have been shown to be sensitive to affective states in our previous
work as well as others [38][39][40]. The signals were collected for offline analysis.

Author Manuscript

Gaze estimation was approximated by participant’s head pose around yaw axis (horizontal
head turn) extracted from the Kinect Face Tracking engine. For gesture recognition, we
adapted a rule-based finite state machine (FSM) gesture recognition method [26] based on
the upper body skeletal data from Kinect to accommodate for motor control declines in older
adults. Both skeleton and head pose were updated at a frame rate of 30Hz. Gesture
recognition was used during the joint chair exercise activity for monitoring participant’s
performance on an exercise motion demonstrated by the robot. Four gestures were
recognized, including raise one arm up, raise both arms up, extend arms to the sides, and
wave. The robot provided feedback prompts based on older adult’s performance and then
demonstrated the next exercise motion. Speech recognition was designed to understand three
types of user responses: affirmative answer (e.g., yes, sure, ok, correct), negative answer
(e.g., no, wrong), and repeat question (e.g., repeat). We are aware of the limitations of
NAO’s speech recognition software. It requires participants to speak loudly and is sensitive
to different accents. Even though we informed the participants to speak loudly and clearly,
and provided a word list that robot could understand, there were times when they forgot
robot was not as intelligent as a human and would engage in conversation! For these
experiments, we increased the robustness of speech recognition by asking the administrator

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 10

Author Manuscript

to select the correct user response using the GUI. Both gesture recognition and speech
recognition were in idle states unless invoked by the Supervisory Controller.

Author Manuscript

Fig. 3(a) illustrates the Supervisory Controller for one-on-one interaction. Activity
management scheduled the five activities in a predefined order as shown in the figure. The
control policy for robot behavior and game behavior was modeled using hierarchical FSMs.
We expanded the hierarchical FSM and participant’s engagement model during the math
activity, shown in Fig. 3(a). The set of states in the hierarchical FSM model of control policy
represents robot behavior and game behavior. The machine starts in state s0, which has a
refinement that is another FSM with states and transitions designed to realize the math
activity. When the engagement state of the participant is not-engaged, the machine
transitions to state s1. In this state, robot gently prompts the participant to come back to the
activity. The transition from s1 to s0 is guarded by engaged and is a history transition. When
this transition is taken, the destination refinement s0 resumes in whatever state it was last in.
This ensures that the robot does not restart the activity from the beginning. The refinement
FSM initially enters the state Start activity and sends the start marker to the
electrophysiological data acquisition systems. For each math question, the robot either
repeats the question or gives feedback based on the participant’s response. The activity ends
after finishing all the math questions or if the participant indicates his/her unwillingness to
proceed. In this activity, the engagement action variable of the participant
was conditioned on speech recognition and game behavior, and the engagement intention
variable

was conditioned on gaze estimation. Since speech recognition was

Author Manuscript

enabled only when robot expected a response from the participant,
is true
when speech recognition return values and is false otherwise. The participant’s gaze, on the
other hand, was monitored continuously. The Kinect Face Tracking engine tracked the head
pose yaw angle from −45 degrees (turn towards the right) to 45 degrees (turn towards the
left).
is true when the participant’s gaze focuses on the robot, defined by |
yawAngle| ≤ 28. The engagement state transitions in Fig. 3(a) indicates that when the
participant looks away from the robot over a consecutive three-second time window, his/her
engagement state
omitted
mutual gaze.

changes to not-engaged. The engagement state model
because responding to the robot is usually accompanied by

Author Manuscript

The robot’s movement and speech were controlled through the NAOqi programming
framework. A library of primitive robot motions, such as cheers, pointing, etc., were
established. The primitive robot motions together with robot speech were building blocks for
robot behaviors.
2) Triadic Interaction: The chair exercise activity was expanded into a form of “Simon
says” game in this HRI scenario. One player takes the role of Simon and instructs other
players to perform physical movement. The other players should only follow the instructions

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 11

Author Manuscript
Author Manuscript

prefaced with the phrase “Simon says”. Due to the technical challenge of recognizing speech
inputs from two individuals at the same time, we used a Razer Hydra (sixense.com), which
has two separate controllers, to record trigger buttons click inputs instead. The control policy
modeled by a hierarchical FSM is shown in Fig. 3(b). There are three AND states, Main
Procedure, Gesture Checker, and User Input, implemented using threads and processes with
socket communication. The refinements of Gesture Checker and User Input control the
communication between Supervisory Controller and Sensing. Robot behavior and game
behavior were defined in the refinement of Main Procedure. The initial state is Meet each
other, when the robot and the participants introduce themselves and say “hi” to each other.
In the next state the robot explains the rules to the participants. The transition from Explain
game rules to Robot plays Simon takes place if both participants indicate understanding of
the rules. The robot leads the chair exercise first. It checks the performance of each
participant and provides feedback prompts. When the robot finishes three or four commands,
each participant takes turns to play Simon. If the participant who plays Simon signals
“Simon says” to the robot by pressing the trigger button, the robot mirrors his/her
movement.
B. Participants and Protocol
Informed consents were obtained before the experiments, according to the protocol approved
by Vanderbilt University Institutional Review Board.

Author Manuscript

Scenario 1 – One-on-one interaction—We recruited 11 community-residing older
adults (6 females, 5 males, age: 66–94 years, mean: 82.5) of which 4 had a preexisting
diagnosis of MCI or dementia. The entire session, approximately 60 minutes in duration,
was video-recorded. Electrophysiological signals were collected for a three-minute resting
baseline and during HRI. A survey (Robot User Acceptance Scale-RUAS) was conducted
pre-and post-experiment to determine the participants’ acceptance and anticipated use of the
robot on a 7-point scale (1 most positive to 7 most negative response). This survey was
adapted from the Unified Theory of Acceptance and Use of Technology (UTAUT) and
reflects the user’s acceptance and intention to use new technology based on performance
expectancy, effort expectancy, attitude toward using technology, and self-efficacy. The
UTAUT framework posits that the person’s pre-use attitudes influence the person’s
acceptance and use of the technology [41]. For this study, items were modified to reflect
adults’ interactions specific to robots. The final RUAS consisted of 29 items (9 performance
expectancy, 5 effort expectancy, and 15 attitude). Participants also completed a postexperiment questionnaire that provided opinions about the activities (from “extremely
interesting (1)” to “extremely boring (7)”).

Author Manuscript

Scenario 2 – Triadic interaction—We recruited 14 older adult participants (9 females, 5
males, age: 70–90 years, mean: 82.7) who were paired for simultaneous interaction with the
robot. One pair of the participants had a formal diagnosis of MCI or dementia. Paired
participants came to the lab once for approximately 30 minutes. EEG signals and the RUAS
were collected following the same procedure as in scenario 1. Participants also completed a
pre-and post-experiment questionnaire on the degree to which they enjoyed interacting with

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 12

Author Manuscript

and helping others. After the experiment, a questionnaire was provided to gain feedback on
the level of enjoyment or interest with the activity.

IV. Results
A. Data Analysis Methods
The Wilcoxon signed-rank test was applied to determine the survey’s ability to be sensitive
to change. RUAS and its three subscales (performance expectancy, effort expectancy, and
attitude) were subject to pre and post-experiment comparison. The Wilcoxon signed-rank
test, a non-parametric statistical hypothesis test of median, was used because it does not
assume normal distribution of the data, and is suitable for ordinal data.

Author Manuscript

EEG engagement index (EEI) and GSR-based arousal state (GAS) were extracted as
measures of affective states to characterize participant’s engagement intention. Filtered EEG
signals from baseline and different activities were used to compute both an engagement
threshold and engagement traces. EEI was the ratio of beta band spectral power (13–22 Hz)
to the sum of alpha band spectral power (8–13 Hz) and theta band spectral power (4–8 Hz)
[42][43]. We calculated the EEI at time t from 40-second sliding window preceding time t.
Bin powers within beta, alpha, and theta bands were summed together to compute the ratio
and the ratios from all 14 electrodes were combined to obtain the EEI at time t. This
procedure was repeated every two seconds to generate the engagement traces. The mean
value of the baseline engagement trace was set as the engagement threshold. A summarized
EEI was calculated by
number of EEI in the related activity.

for each activity, where n is the

Author Manuscript

GAS was computed using preprocessed GSR signal measured from participant’s fingers.
Tonic and phasic components were decomposed separately from the raw signal. The signal
was first filtered by a 0.5 Hz lowpass filter to remove noise. Then tonic component was
acquired by using a 0.05 Hz highpass filter. Phasic component was then calculated by
deducting tonic component from the denoised signal. GSR rate, which could be used as
arousal state, was calculated by averaging the first derivative of phasic component. For
baseline and each activity of the robot experiment, a set of GAS values were calculated
using a 40-second sliding window with 38-second overlap. A threshold value was computed
by averaging baseline GAS values. Similar to EEI, a summarized GAS was calculated for
each activity.
B. One-on-one Interaction Results

Author Manuscript

All the participants finished the interaction and completed the surveys and questionnaires
(Table I). Cronbach’s alpha coefficients were 0.88 and 0.92, pre-and post-survey
respectively. Perceptions became more positive for effort expectancy, attitude, and RUAS
post-experiment. Wilcoxon signed-rank test results are shown in the table, including the
standard score of the Wilcoxon signed ranks, p value, and effect size. It can be seen that
attitude subscale and RUAS were statistically significantly more positive after HRI at the
0.05 level with medium effect sizes.

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 13

Author Manuscript

EEI and GAS were computed for 10 participants, because the start/end marker were not
recorded properly for the third participant. For each activity and participant, we calculated
the corresponding summarized EEI and summarized GAS. The scatter plots (Fig. 4)
illustrates participants’ summarized EEI and summarized GAS with respect to self-rated
activity preferences. In the case of EEI, the dispersion of the data points along each rating
level shows that there are individual differences. For example, one participant rated the
exercise activity as “extremely interesting (1)” with the summarized EEI of −0.05 whereas
another participant provided the same rating with the summarized EEI of 0.18. We further
computed the Pearson’s r to assess the relationship between the summarized EEI and
participants’ self-rating data. There was a strong correlation between the two variables (r =
−0.73, N = 27, p < 0.001). This strong negative correlation implies that the EEI is high when
participants enjoy the activity whereas the EEI is relatively low when participants show less
interest to the activity.

Author Manuscript

Similarly, individual differences were found for GAS. For the music activity and rating level
2, participants’ summarized GAS ranged from −1.05 response peaks/s to 1.66 response
peaks/s. No correlation was found between the summarized GAS and self-rated activity
preference. The summarized GAS is an important indicator of the intensity of participants’
emotion state. Since the self-rating data indicated the level of likes or dislikes of the
activities and were not necessarily associated with changes in arousal states, it is not
surprising that no correlation was found. As shown in Fig. 4, on average participants had a
better opinion on the music and exercise activities compared to the other three activities.
C. Triadic Interaction Results

Author Manuscript

Survey data were collected for all 14 participants and the results are shown in Table II.
Cronbach’s alpha coefficients were 0.93 and 0.92, pre-and post-survey, respectively. All the
subscales and RUAS indicated more positive perceptions on ROCARE after the experiment.
Effort expectancy subscale was statistically significantly more positive after triadic
interaction at 0.01 level with a large effect size. Attitude subscale and RUAS were
statistically significantly more positive after triadic interaction at the 0.05 level with medium
effect sizes.

Author Manuscript

Participants’ perceptions on interacting with another person were recorded by a four-item
questionnaire. Eleven participants completed this pre-and post-experiment questionnaire.
The items were a) I would enjoy doing activities with another person (pre mean score 1.64,
post mean score 1.55); b) I would feel comfortable talking to another person (pre mean score
1.36, post mean score 1.18); c) I would help another person when needed (pre mean score
1.18, post mean score 1.27); and d) I would accept help from another person (pre mean score
1.09, post mean score 1.27). While no statistically significant conclusion could be drawn
from the questionnaire data, the very small post mean scores show that older adults enjoyed
interacting with another person in addition to the robot.
We logged EEG data for 6 participants. Their engagement threshold and summarized EEI
during the triadic interaction are listed in Table III together with self-rating data. Each
participant had different engagement threshold and different opinions on the “Simon says”
activity. Similar to the one-on-one experiment results, the summarized EEI is individualized.
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 14

Author Manuscript

Participant 009 rated the “Simon says” activity to be “Somewhat interesting (3)” with an
EEI equals 0.27 whereas participant 014’s EEI equals 0.09.

Author Manuscript

Head pose data were recorded for participants 009 to 014 to analyze whether the participants
communicated with each other. The yaw angle results are presented in Fig. 5. The first row
of plots show yaw angles from participants sitting on the right chair (PR), whereas the
bottom row plots include data from participants sitting on the left chair (PL). The yaw angle
should increase when participants’ turn their head to the left and decrease otherwise. Before
the triadic interaction, we asked the participants to look at the robot and then look towards
the other person. The corresponding head pose yaw angles were horizontal lines in the plots.
Pair 007’s head pose yaw angles towards each other were not properly recorded. The solid
dots in the plots represent instances when the robot provided instructions to elicit HHI. This
includes a) acquiring name of PL/PR from PR/PL; b) asking older adults to say hi to each
other; c) asking older adults to check each other’s gesture if one of them failed; and d) wave
goodbye. The number of dots are different for the three pairs because a) and c) might not
occur based on real-time human interaction. At the onset of the solid dots, we expect to see
that PR’s head pose yaw angles increase and PL’s head pose yaw angles decrease. From Fig.
5, this is the case for the majority of the time.

V. Discussion

Author Manuscript

ROCARE is designed to complement and augment care in the existing resource-strained
healthcare environment. Several useful interactions between a robot and older adults were
developed and tested by small feasibility studies. Overall, one-on-one interaction and triadic
interaction systems worked as designed. No participant dropped out of the studies and the
sensors were tolerable. Participants’ perceptions after the one-on-one and triadic
experiments were significantly more positive on the attitude subscale and RUAS. In
addition, the survey measurements were sensitive to change from pre-to post-experiment.

Author Manuscript

EEG and GSR data demonstrated individual differences in baseline features and variation
from baseline during HRI. The results also show that the participants had different degree of
likes or dislikes of the activities, and therefore it is important for ROCARE to be able to
keep track of the preferences of each older adult to maintain engagement. The strong
negative correlation between the summarized EEI and participants’ self-rating data indicates
the potential for objectively measuring participants’ engagement intention and harnessing it
to realize individualized activity management. Because the correlation was computed using
data from all the participants, we cannot be certain that this result applies to each individual
in the same way. As for GAS, although no correlation was found between the summarized
GAS and self-rated activity preference, it is worthwhile to develop an arousal state-related
rating scale and explore the reliability of using GAS as arousal index. In the future, we
intend to conduct multi-session experiment and implement the activity management
submodule using activity preferences learned from electrophysiological signals. This study
will provide results on how individual difference affect the EEG and physiological features
as well as the effect of activity management.

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 15

Author Manuscript

ROCARE allows for adaptation on two levels of abstraction: a) activity level, which
automatically schedules engaging activities; and b) low level, which adapts system behavior
based on older adults’ real-time interaction, such as gaze and gesture. In this paper, the low
level adaptation was implemented. There are several adaptive elements in the system,
including EEG and GSR sensors, head pose yaw angle estimation of gaze, and performance
related measurements. The EEG and GSR results will serve as the basis for activity level
adaptation in the future.

Author Manuscript

While the current work has demonstrated the potential of a novel HRI architecture with
small feasibility studies, it is important to understand the long term effect of such systems in
the nursing homes with longitudinal study. Ethical issues and the potential of misuse with
robots and older adults have been raised, including decreased human contact, loss of control,
loss of privacy, and feelings of objectification [44][45]. These are serious issues and
safeguards need to be considered before their deployment in nursing homes.

VI. Conclusion

Author Manuscript

Building upon the works of Bohus and Horvitz on multiparty engagement in open-world
dialog [36], Louie and associates on multi-user planning and scheduling architecture [24],
and state of the art SAR architectures [20][28][30], we proposed the mathematical models of
ROCARE, a robotic coach architecture, for augmenting elder care. This architecture is
capable of one-on-one and multi-user interactions between a SAR and older adults. By
incorporating a database for each individual user and including both implicit and explicit
sensing submodules, ROCARE allows individualized activity management and dynamic
adaptive robotic behavior for long-term engagement. We have conducted two preliminary
feasibility studies: a one-on-one HRI and a triadic HRI. Both systems functioned as desired.
Participants’ perceptions on the robotic systems were significantly more positive after HRI
for the attitude subscale and RuAS. Social communication between pairs of participants
could be elicited by the robot as seen from both video recordings and head pose data. In
addition, there were strong correlation between the summarized EEI and participants’ selfrating data (r = −0.73, p < 0.001), which indicated the potential of using EEG signals for
online affective states recognition.

Author Manuscript

The current work is limited in several ways. First, with the small sample size and the short
interaction duration, user perception and compliance results are susceptible to the novelty of
the technology. Second, electrophysiology-based affective state recognition was limited to
offline analysis. Third, since each participant only took part in one session, no activity
preference data were learned and therefore the order of the activities were predefined.
Nonetheless, the preliminary studies verified that 1) ROCARE was positively accepted by
older adults with and without cognitive impairment; 2) ROCARE can be used for one-onone and multi-user HRI; and 3) our selection of the EEG feature has strong linear correlation
with participants’ self-rating on each activity, and can be used for online affective state
recognition.
ROCARE is the first to our knowledge that defined multi-user engagement-based
mathematical models for robot-mediated interaction for elder care. Future works on building

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 16

Author Manuscript

individualized database and activity management need to be carried out with longitudinal
studies and a larger sample size. The effectiveness of the architecture to maintain long-term
engagement, promote functioning and social communication also needs to be studied.

Acknowledgments
This work was supported in part by the National Institute of Health Grant 1R21AG050483-01A1 and the Vanderbilt
University School of Nursing Independence Foundation Chair Funds.

References

Author Manuscript
Author Manuscript
Author Manuscript

1. N. C. f. H. Statistics. Older Americans 2012: Key Indicators of Well-being. 2012
2. Friedman SM, Mendelson DA. Epidemiology of fragility fractures. Clinics in geriatric medicine.
2014; 30:175–181. [PubMed: 24721358]
3. A. s. Association. 2014 Alzheimer’s disease facts and figures. Alzheimer’s & Dementia. 2014;
10:e47–e92.
4. Vega JN, Newhouse PA. Mild cognitive impairment: diagnosis, longitudinal course, and emerging
treatments. Current psychiatry reports. 2014; 16:1–11.
5. Freedman V. Disability and care needs of older Americans: An analysis of the 2011 National Health
and Aging Trends Study. 2014
6. Tabata K. Population aging, the costs of health care for the elderly and growth. Journal of
Macroeconomics. 2005; 27:472–493.
7. Cohen-Mansfield J, Marx MS, Dakheel-Ali M, Them K. The use and utility of specific
nonpharmacological interventions for behavioral symptoms in dementia: an exploratory study. The
American Journal of Geriatric Psychiatry. 2015; 23:160–170. [PubMed: 25081819]
8. Forbes SC, Little JP, Candow DG. Exercise and nutritional interventions for improving aging muscle
health. Endocrine. 2012; 42:29–38. [PubMed: 22527891]
9. Feil-Seifer D, Mataric MJ. Defining socially assistive robotics. Rehabilitation Robotics, 2005
ICORR 2005 9th International Conference on. 2005:465–468.
10. Bemelmans R, Gelderblom GJ, Jonker P, De Witte L. Socially assistive robots in elderly care: A
systematic review into effects and effectiveness. Journal of the American Medical Directors
Association. 2012; 13:114–120. e1. [PubMed: 21450215]
11. Mordoch E, Osterreicher A, Guse L, Roger K, Thompson G. Use of social commitment robots in
the care of elderly people with dementia: A literature review. Maturitas. 2013; 74:14–20.
[PubMed: 23177981]
12. Wada K, Shibata T, Saito T, Sakamoto K, Tanie K. Psychological and social effects of one year
robot assisted activity on elderly people at a health service facility for the aged. Robotics and
Automation, 2005 ICRA 2005 Proceedings of the 2005 IEEE International Conference on.
2005:2785–2790.
13. Gross H, Schroeter C, Mueller S, Volkhardt M, Einhorn E, Bley A, Martin C, Langner T, Merten
M. Progress in developing a socially assistive mobile home robot companion for the elderly with
mild cognitive impairment. Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International
Conference on. 2011:2430–2437.
14. Looije R, Neerincx MA, Cnossen F. Persuasive robotic assistant for health self-management of
older adults: Design and evaluation of social behaviors. International Journal of Human-Computer
Studies. 2010; 68:386–397.
15. Matsusaka Y, Fujii H, Okano T, Hara I. Health exercise demonstration robot TAIZO and effects of
using voice command in robot-human collaborative demonstration. Robot and Human Interactive
Communication, 2009 RO-MAN 2009 The 18th IEEE International Symposium on. 2009:472–
477.
16. Gorer, B., Salah, A., Akin, HL. Ambient Intelligence. Springer International Publishing; 2013. A
Robotic Fitness Coach for the Elderly; p. 124-139.

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 17

Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript

17. Simonov M, Delconte G. Humanoid Assessing Rehabilitative Exercises. Methods Inf Med. 2014;
53
18. Gadde P, Kharrazi H, Patel H, MacDorman KF. Toward monitoring and increasing exercise
adherence in older adults by robotic intervention: a proof of concept study. Journal of Robotics.
2011
19. Yoshino K, Kouda M, Shanjun Z. Correct Motion Advice on Rehabilitation Instruction Robot by
Superimposing Instructor CG Model. Intelligent Networks and Intelligent Systems (ICINIS), 2012
Fifth International Conference on. 2012:333–336.
20. Fasola J, Mataric MJ. A Socially Assistive Robot Exercise Coach for the Elderly. Journal of
Human-Robot Interaction. 2013; 2:3–32.
21. Tapus A, Tapus C, Mataric M. Long Term Learning and Online Robot Behavior Adaptation for
Individuals with Physical and Cognitive Impairments. Field and Service Robotics. 2010:389–398.
22. McColl D, Louie WYG, Nejat G. Brian 2.1: A socially assistive robot for the elderly and
cognitively impaired. Robotics & Automation Magazine, IEEE. 2013; 20:74–83.
23. Louie WYG, Li J, Vaquero T, Nejat G. A focus group study on the design considerations and
impressions of a socially assistive robot for long-term care. Robot and Human Interactive
Communication, 2014 RO-MAN: The 23rd IEEE International Symposium on. 2014:237–242.
24. Louie WYG, Vaquero T, Nejat G, Beck JC. An autonomous assistive robot for planning,
scheduling and facilitating multi-user activities. Robotics and Automation (ICRA), 2014 IEEE
International Conference on. 2014:5292–5298.
25. Kidd CD, Breazeal C. Robots at home: Understanding long-term human-robot interaction.
Intelligent Robots and Systems, 2008 IROS 2008 IEEE/RSJInternational Conference on.
2008:3230–3235.
26. Zheng Z, Das S, Young EM, Swanson A, Warren Z, Sarkar N. Autonomous robot-mediated
imitation learning for children with autism. Robotics and Automation (ICRA), 2014 IEEE
International Conference on. 2014:2707–2712.
27. Kanoh M, Oida Y, Nomura Y, Araki A, Konagaya Y, Ihara K, Shimizu T, Kimura K. Examination
of practicability of communication robot-assisted activity program for elderly people. Journal of
Robotics andMechatronics. 2011; 23:3.
28. Feil-Seifer D, Mataric MJ. B3IA: A control architecture for autonomous robot-assisted behavior
intervention for children with Autism Spectrum Disorders. Robot and Human Interactive
Communication, 2008 RO-MAN 2008 The 17th IEEE International Symposium on. 2008:328–
333.
29. Chan J, Nejat G. Promoting engagement in cognitively stimulating activities using an intelligent
socially assistive robot. Advanced Intelligent Mechatronics (AIM), 2010 IEEE/ASME
International Conference on. 2010:533–538.
30. Chan J, Nejat G. A learning-based control architecture for an assistive robot providing social
engagement during cognitively stimulating activities. Robotics and Automation (ICRA), 2011
IEEE International Conference on. 2011:3928–3933.
31. Gross HM, Debes K, Einhorn E, Mueller S, Scheidig A, Weinrich C, Bley A, Martin C. Mobile
Robotic Rehabilitation Assistant for walking and orientation training of Stroke Patients: A report
on work in progress. Systems, Man and Cybernetics (SMC), 2014 IEEE International Conference
on. 2014:1880–1887.
32. Johnson DO, Cuijpers RH, Juola JF, Torta E, Simonov M, Frisiello A, Bazzani M, Yan W, Weber
C, Wermter S. Socially Assistive Robots: A comprehensive approach to extending independent
living. International Journal of Social Robotics. 2014; 6:195–211.
33. Malfaz M, Castro-Gonzalez A, Barber R, Salichs MA. A biologically inspired architecture for an
autonomous and social robot. Autonomous Mental Development, IEEE Transactions on. 2011;
3:232–246.
34. Jayawardena C, Sarrafzadeh A. An alternative approach for developing socially assistive robots.
Biomedical Robotics and Biomechatronics (2014 5th IEEE RAS & EMBS International
Conference on. 2014:573–578.

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 18

Author Manuscript
Author Manuscript

35. Cohen-Mansfield J, Marx MS, Freedman LS, Murad H, Regier NG, Thein K, Dakheel-Ali M. The
comprehensive process model of engagement. The American Journal of Geriatric Psychiatry.
2011; 19:859–870. [PubMed: 21946802]
36. Bohus D, Horvitz E. Models for multiparty engagement in open-world dialog. Proceedings of the
SIGDIAL 2009 Conference: The 10th Annual Meeting of the Special Interest Group on Discourse
and Dialogue. 2009:225–234.
37. Cummings, M. Simon Says as a Teaching Tool. Nov 18. 2015 Available: https://
www.youtube.com/watch?v=RewIoHJ9RdM
38. Fan J, Wade JW, Dayi B, Key AP, Warran ZE, Mion LC, Sarkar N. A Step Towards EEG-based
Brain Computer Interface for Autism Intervention. presented at the 37th Annual International
Conference of the IEEE Engineering in Medicine and Biological Society (EMBS). 2015 in press.
39. Bian D, Wade J, Swanson A, Warren Z, Sarkar N. Physiology-based affect recognition during
driving in virtual environment for autism intervention. 2nd international conference on
physiological computing system (Accepted, 2015). 2015
40. Sarkar N. Psychophysiological control architecture for human-robot coordination-concepts and
initial experiments. Robotics and Automation, 2002 Proceedings ICRA’02 IEEE International
Conference on. 2002:3719–3724.
41. BenMessaoud C, Kharrazi H, MacDorman KF. Facilitators and barriers to adopting roboticassisted surgery: contextualizing the unified theory of acceptance and use of technology. PloS one.
2011; 6:e16395. [PubMed: 21283719]
42. Chaouachi, M., Chalfoun, P., Jraidi, I., Frasson, C. Affect and mental engagement: towards
adaptability for intelligent systems. Proceedings of the 23rd International FLAIRS Conference;
Daytona Beach, FL. 2010. http://citeseerx.ist.psu.edu/viewdoc/download
43. Freeman FG, Mikulka PJ, Prinzel LJ, Scerbo MW. Evaluation of an adaptive automation system
using three EEG indices with a visual tracking task. Biological psychology. 1999; 50:61–76.
[PubMed: 10378439]
44. Sharkey N, Sharkey A. The eldercare factory. Gerontology. 2012; 58:282–288. [PubMed:
21952502]
45. Körtner T. Ethical challenges in the use of social service robots for elderly people. Zeitschrift für
Gerontologie und Geriatrie. 2016:1–5.

Author Manuscript
Author Manuscript
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 19

Author Manuscript
Author Manuscript

Fig. 1.

Robotic coach system architecture (ROCARE).

Author Manuscript
Author Manuscript
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 20

Author Manuscript
Fig. 2.

Timed automaton model of

Author Manuscript
Author Manuscript
Author Manuscript
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 21

Author Manuscript
Author Manuscript
Fig. 3.

(a) Supervisory controller module for one-on-one interaction (b) Control policy for triadic
interaction

Author Manuscript
Author Manuscript
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 22

Author Manuscript
Author Manuscript

Fig. 4.

Summarized EEI (left) and summarized GAS (right) as a function of self-rated activity
preferences.

Author Manuscript
Author Manuscript
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Fan et al.

Page 23

Author Manuscript
Author Manuscript

Fig. 5.

Participants’ head pose yaw angles during triadic experiment.

Author Manuscript
Author Manuscript
IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Author Manuscript
50.5 (10.7)
100 (21.8)

Attitude

RUAS

Lower values are more positive.

a

19.1 (6.6)

25.5 (6.5)

Effort Expectancy

Performance Expectancy

84.4 (25.0)

39.7 (13.9)

15.6 (6.1)

28.6 (7.2)

Posta M (SD)

2.19

2.31

1.73

1.89

Z

0.028

0.021

0.084

0.059

P

Author Manuscript
Prea M (SD)

0.47

0.49

0.37

0.40

r

Author Manuscript

Survey Results for One-on-one Experiment N=11

Author Manuscript

Table I
Fan et al.
Page 24

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Author Manuscript
18.6 (6.5)
46.4 (15.6)
94.8 (30.9)

Attitude

RUAS

27.9 (9.7)

Effort Expectancy

Performance Expectancy

77.2 (26.4)

36.5 (15.0)

12.9 (7.2)

24.2 (8.4)

Post a M (SD)

2.14

2.28

2.82

1.82

Z

0.033

0.023

0.005

0.069

p

Author Manuscript
Pre a M (SD)

0.40

0.43

0.53

0.34

r

Author Manuscript

Survey Results for Triadic Experiment N=14

Author Manuscript

Table II
Fan et al.
Page 25

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

Author Manuscript

Author Manuscript
0.27
3

Self-rated Preference

0.95

“Simon says” Activity

Threshold

P009

2

0.00

0.39

P010

1

−0.13

0.78

P011

1

−0.20

0.65

P012

1

0.01

0.41

P013

3

0.09

0.57

P014

Author Manuscript

Summarized Eeg Engagement Index for Six Participants

Author Manuscript

Table III
Fan et al.
Page 26

IEEE Trans Neural Syst Rehabil Eng. Author manuscript; available in PMC 2017 August 11.

