Carpathian Journal of Electronic and Computer Engineering 11/2 (2018) 29-34
DOI: 10.2478/cjece-2018-0015

Processing EEG signals acquired from a consumer
grade BCI device
Fanny Monori
Faculty of Informatics
University of Debrecen
Debrecen, Hungary
fannymonori@gmail.com

Stefan Oniga
Faculty of Informatics
University of Debrecen
Debrecen, Hungary
oniga.istvan@inf.unideb.hu

These experiments were performed using clinical grade
EEG devices, but in the last few years consumer grade BCI
devices have appeared for the public. These devices usually
take the form of some headset, and they usually have the
means of not just processing the data but to send it over some
forms of communication channels. These consumer grade
devices without exception use dry electrodes, so they could
be easily used at home. One of the most widely known
producer is NeuroSky. The company has been producing
their one-channeled devices since 2011 under the name of
MindWave which comes with their EEG processing sensor,
the ThinkGear ASIC Modul (TGAM). OpenBCI also
produces consumer grade devices. They offer a variety of
pre-assembled headsets, but they also offer the 3D design of
their headset free charge. So, one can download the design,
print it with the help of a 3D printer, and assemble it with a
purchased OpenBCI sensor. Their devices utilize 16 to 35
channels. Emotiv also offers multiple of headsets. They have
devices that have fewer electrodes (5) as well as more robust
devices that can have up to 32 electrodes. Clinical grade BCI
devices are also available for purchase. NeuroStyle for
example is one of those companies that offer clinical grade
products. Besides the EEG device, they also offer softwares
for stroke-rehabilitation.

Abstract—BCI (Brain-Computer Interface) is a technology
which goal is to create and manage a connection between the
human brain and a computer with the help of EEG signals. In
the last decade consumer-grade BCI devices became available
thus giving opportunity to develop BCI applications outside of
clinical settings. In this paper we use a device called NeuroSky
MindWave Mobile. We investigate what type of information
can be deducted from the data acquired from this device, and
we evaluate whether it can help us in BCI applications. Our
methods of processing the data involves feature extraction
methods, and neural networks. Specifically, we make
experiments with finding patterns in the data by binary and
multiclass classification. With these methods we could detect
sharp changes in the signal such as blinking patterns, but we
could not extract more complex information successfully.
Keywords— BCI, EEG, neural networks, MindWave Mobile

I. INTRODUCTION
EEG (electroencephalography) is a type of monitoring
method that measures the electromagnetic change in the
brain. The measurement is usually done with electrodes
attached to the scalp, in a non-invasive way. In medical
application the so called wet electrodes are used, to decrease
the noise that the electrodes get from the environment as
much as possible. In the last decade consumer grade devices
became available, and they usually use dry electrodes instead
of wet. It makes them easier to use but it also introduces
more noise to the signal.

Many of the consumer graded devices were created with
the intent of using them with games, but there exist examples
of using them in scientific experiments. K. George et al. [13]
used the Emotiv Epov headset in a seemingly simple
experiment. They recorded EEG data with the headset while
the wearer was looking at white and black squares on a
monitor, and they developed a method for classifying these
records. A. Kline et al. [14] also used Emotiv headset in their
experiments. They tried to use the data provided by the
headset for controlling prosthesis. N. Chumerin et al. [15]
developed a game that can be controlled with human brain,
and they used that as the basis of comparison between
clinical and consumer grade BCI devices. C. Lin et al. [16]
used one of NeuroSky's devices in an embedded system
application that monitors the alertness of drivers. C. A. Lim
et al. [17] and J. He et al. [18] developed methods for this
problem also with the use of NeuroSky MindWave device.

The BCI (Brain-Computer Interface) is a technology
which goal is to create and manage a connection between the
human brain and a computer. Since the birth of this
discipline numerous applications have been created, in a
wide variety of fields. Medical and rehabilitation fields are
amongst the most populous fields in terms of patents and
publications. Specifically, BCI applications can offer great
help for people with disabilities. BCI can be used as a way of
controlling wheelchairs [1], [2], or virtual keyboards for
example [3]. Controlling prosthesis is also a widely
researched area of the BCI discipline. There exists both
invasive [4] and non-invasive [5], [6] methods. The latter
many times utilizes the EEG patterns created when
imagining left or right-hand movements [7], [8], [9]. Medical
applications are not the only type of BCI applications. One
popular field of BCI is helping car controlling. For example,
J. Kim et al. [10] tried to derive from the EEG signals the
exact moment where the driver started to initiate a brake.
Alerting systems that watches the drowsiness of the driver is
also a notable field in this field [11], [12].

ISSN 1844 – 9689

We used a NeuroSky MindWave Mobile device, and in
this paper, we investigate what kind of information can be
obtained from a consumer grade device like this and whether
it can be used in BCI applications. In Section II. we describe
the usual process of evaluating EEG signals. In Section III.
we describe the data types of MindWave Mobile. Then, in
Section IV. we demonstrate our method of processing data

29

https://www.degruyter.com/view/j/cjece

Carpathian Journal of Electronic and Computer Engineering 11/2 (2018) 29-34
EEG pattern. We tried to investigate whether these normal
states and the changes they go through in respect of time is
observable in the acquired data.

values that were computed by the device itself. Finally, in
Section V. we describe how we processed the raw data.

III.

MINDWAVE MOBILE

A. The device
The NeuroSky MindWave Mobile is a type of consumer
grade EEG headset that allows the user to record EEG data at
home with the help of a one-channeled dry electrode. It
transfers the data via Bluetooth which can be processed later
with arbitrary devices as the communication protocol is
available at NeuroSky’s site.
This device includes one EEG recording electrode that
lies on the front of the forehead, one clip that is attached to
one of the earlobes, and the ThinkGear ASIC Module
(TGAM). The electrode on the forehead records the activity
of the frontal lobe. The electrode on the clip takes on the task
of being the ground and reference. While usage the electrode
on the forehead takes up not just the activity of the brain but
also noise from the environment. So, the TGAM does a denoising with the help of the ear clip's electrode before
sending the data on Bluetooth. The TGAM has a sampling
frequency of 512 Hz which then becomes the raw data, and it
also does specific computations every one second.
B. Types of data and the communication protocol
The device can send the 16-bit raw data (sampled on 512
Hz) via Bluetooth and serial port at 57600 baud. The
MindWave also sends computed values every one second.
These values include controlling packets, like packets that
indicate poor signal. It also sends valuable information like
Attention and Meditation levels. The first one (a value
between 0 and 100) indicates the alertness and the measure
of concentration of the wearer [23]. The latter (also between
0 and 100) represents the calmness or relaxedness of the user
[24]. The device also sends 8 values every second that
represents the magnitude of 8 EEG wave patterns.

Fig. 1. Examples of EEG power values. Horizontal-axis represents time,
and vertical axis represents the EEG Power values.

II.

PROCESSING EEG SIGNALS IN GENERAL

Our brainwaves change according to our state and our
environment. Low frequency brainwaves are often associated
with relaxed state while higher frequency waves are
associated with movements, and alertness.

IV. PROCESSING THE PRE-COMPUTED SIGNALS
A. EEG Power values
These 8 values represent the following EEG wave
patterns. Delta (0.5 – 2.75 Hz), theta (3.5 – 6.75 Hz), lowalpha (7.5 – 9.25 Hz), high-alpha (10 – 11.75 Hz), low-beta
(13 – 16.75 Hz), high-beta (18 – 29.75 Hz), low-gamma (31
– 39.75 Hz), and high-gamma (41 – 49.75 Hz) [25]. These
values are the results of various calculations thus they are
only comparable with each other in respect of time, and they
cannot be compared directly with magnitudes obtained from
other type of devices [26].

Delta waves are at the lower end of the spectrum, their
frequency is between the of 0.5 and 3 Hz. They are
associated with deep, dreamless sleep. Theta waves are
predominantly intense in the frontal region of the brain [19].
It is usually considered between the frequencies of 4-7 Hz. It
is dominant in EEG records of wake children and sleeping
adults. The alpha wave can be recorded more successfully in
the posterior regions of the brain [20]. They are associated
with relaxed, but alert state, for example being awake with
closed eyes. The beta waves are associated with awake and
alert state [21]. It is considered to be the basic rhythm of the
awake adult brain. In the high-frequency end there lies the
gamma rhythm which is associated with specific cognitive
and motor functions. It should be noted that underlying
diseases can influence the EEG patterns, for example slow
wave activities in alert adults can suggest cerebral
dysfunctions [19], [22]. But the normal EEG pattern of a
person varies from task to task, and with a good EEG
measurement device we can even associate a task to a given

We tried to find out whether changes in the activity of the
subjects shows as changes in the signals. We recorded data in
the following manner. We recorded data in a relaxed state
while having our eyes closed. We also recorded data in a
more alert state, with open eyes, while sitting in front of a
computer and reading some text (which in theory is more of
a concentration demanding task). 300 seconds of recordings
are plotted in Fig. 1. where the first plot (named Data 1)
belongs to the relaxed state and the second one (named Data
2) belongs to the mindful, alert state.

This work was supported by the construction EFOP-3.6.3-VEKOP-162017-00002. The project was supported by the European Union, cofinanced by the European Social Fund.

ISSN 1844 – 9689

30

https://www.degruyter.com/view/j/cjece

Carpathian Journal of Electronic and Computer Engineering 11/2 (2018) 29-34
eye 1 and the Open eye 2 were both recorded while having
the eyes opened and listening to relaxing and upbeat music
respectively.

One can observe that there is a conspicuous difference
between opened and closed eyed states. The alpha waves are
stronger while having closed eyes, which is aligned to what
we know about EEG signals. Also, beta and gamma activity
does become stronger while having the eyes opened. But
other than that, no other information could be deducted from
the signals regarding the circumstances in which these
signals were recorded.

Furthermore, Open eye 1 was recorded while moderate
concentration (reading) and Open eye 2 were recorded while
doing no particular task.
One can observe that every data's mean value was varied
around the value 65. The standard deviation however is
distinguishable regarding to the state of the eyes. This
difference between having our eyes opened or closed is
maintained in many of the described features. It can also be
observed in some of the high order statistic features like
skewness and kurtosis. Kurtosis measures whether the data is
heavy- or light-tailed compared to that of normal
distribution. Skewness measures the asymmetry of a
probability distribution. Skewness for closed eyed data
varied in the positive domain, while skewness for opened eye
were usually around zero or below zero. Kurtosis for closed
eye were much higher most of the time, which can be
contributed to the fact that while having our eyes closed the
range of values becomes smaller. Also, recordings while
doing concentration-demanding tasks have usually higher
number of zero-crossings, which can be contributed to the

B. Attention and Meditation
As mentioned in section III.B, MindWave Mobile also
sends two 1-byte values that indicate the alertness and
calmness of the user. We collected data in a relaxed state
with closed eyes, and some of the data were collected while
having the eyes opened. We show some of the collected
averaged Attention and Meditation values in Table. I. While
having the eyes closed the Meditation values did reached a
higher value most of the time. But the Attention values were
in most cases stuck around the value 50, and it was difficult
to have it reach higher value than 50.
V. PROCESSING THE RAW DATA
A. Feature extraction of the signal
Using various feature extraction methods when
processing EEG time-series data is a usual part of this field.
Finding adequate methods is a widely researched area. These
features usually are simple statistical features (mean,
standard deviation) [27], [28]. Other more complex features
are also frequently computed. One complex feature is the socalled Power Spectral Entropy (PSE) [29], [30]. Other
notable feature for EEG analysis is Hjorth’s features [31],
[32].

TABLE I.

We calculated some of these features on the raw data
acquired in various circumstances. We gathered some of the
results in Table. II. The data belonging to the first column
(Closed eyes 1) was recorded while having the eyes closed
and listening to upbeat music. The second one (Closed eyes
2) was recorded while listening to relaxed music. The Open
TABLE II.

EXAMPLES OF ATTENTION AND MEDITATION VALUES

Attention

Meditation

Open eyes 1

48

61

Open eyes 2

52

53

Open eyes 3

50

50

Closed eyes 1

19

76

Closed eyes 2

75

64

Closed eyes 3

45

68

EXAMPLES OF EXTRACTED FEATURE VALUES

Feature extraction values
Closed eyes 1

Closed eyes 2

Open eyes 1

Open eyes 2

Mean

65

65

65

65

Standard deviation

34

41

47

70

Difference between minimum and
maximum value

1319

1542

1120

1678

Zero crossing rate

2048

1892

1631

4101

Spectral-centroid

45.25

43.6

41.8

37.0

Kurtosis

42

98

26

28

Skewness

0,06

4.64

-0.8

0.58

Petrosian Fractal Dimension

0.547

0.549

0.549

0.544

Hjorth’s Mobility

0,0004

0,0004

0.0003

0,005

Hjorth’s Complexity

2442

2383

2869

2043

Power spectral entropy

0.72

0.71

0.70

0.73

ISSN 1844 – 9689

31

https://www.degruyter.com/view/j/cjece

Carpathian Journal of Electronic and Computer Engineering 11/2 (2018) 29-34
We tried to analyze data in the frequency-domain by
plotting the Fourier-transform and the power spectral density
of the signals. To compare two different type of data one can
observe the power spectral density in Fig. 2. The first plotted
data was recorded while having the wearer’s eyes closed and
the second one while having the eyes opened. We concluded
that the state of the eyes has influence on the signal, the
alpha bin gets more dominant when eyes are closed, and the
frequency bin associated to beta and gamma also get more
prominent. But other potentially influencing circumstances
like listening to different kind of music or doing tasks that
demands concentration are hard to notice in these plots and
cannot be extracted accurately.
C. Processing data with neural networks
1) Neural networks and BCI
In the last few decades machine learning algorithms,
especially neural networks have been applied to almost every
field of science and technology imaginable. It has also
reached the field of BCI. Y. Liu et al. [33] used neural
networks for monitoring the alertness and fatigue of a driver.
Applications using convolutional neural networks (CNN) are
getting increasingly popular in the last few years, and this
trend also reached the processing of EEG signals. J. Zhang et
al. [34] developed a method that uses deep-learning
convolutional neural networks to classify imagined hand
movements. X. Li et al. [35] used CNN-s and RNN-s
(recurrent neural networks) for recognition of human
emotions. H. K. Lee et al. [36] took on the task of measuring
EEG data while performing visual experiments. Then they
showed that methods based on CNN-s can achieve higher
accuracy than traditional machine learning algorithms.

Fig. 2. Power spectral density of two different data.

fact that while concentrating we blink less and blinking
usually causes big changes in the signal. But other than that,
sharp contrast between the features of the various recordings
is not present.
B. Frequency-domain analysis
As mentioned previously, changes in the magnitude or
power of the EEG waves can hold information about the
circumstances in which the data were recorded.

We also tried to apply neural networks on the processing
of these data. We did that with the idea that maybe an
algorithm can find patterns in the signal where human eyes
cannot.
2) Recording while sound stimuli
For this experiment we have captured data with the
following process. We recorded two classes of a data. The
first class contains data that were recorded while playing an
annoying, harsh sound for the wearer of the headset. The
other class of data was recorded in a state where no sound
was played. We wanted to find out whether a stimulus as
harsh as this presents itself in the recorded signal.
First, we attempted to classify the following recorded
data with a simple neural network by the means of the
extracted features. We used the data bandpass filtered to the
beta frequency as this is the frequency commonly present in
the EEG of alert adult. We extracted the previously
mentioned features from the signal and that became the input
of our neural network. We created a simple neural network
with one input layer, two hidden layers, and one output layer.
We used ReLU (rectified linear unit) activation function in
the layers except for the output layer, where we used sigmoid
function. We had 120 samples, 60 positive (where a sound
had been played) and 60 negative. We used 100 samples for
training and 20 for testing. After numerous running we
concluded that the neural network can validate the training
data set with 65% accuracy and can classify the test data set
with an average of 55% accuracy.

Fig. 3. Three patterns of blinking. First one represents s, second
represents r and third represents k.

ISSN 1844 – 9689

32

https://www.degruyter.com/view/j/cjece

Carpathian Journal of Electronic and Computer Engineering 11/2 (2018) 29-34
On the second approach we used the individual samples
filtered to the beta frequency and made it as the input as is.
The neural network used for this was identical to the first
(other than the input dimensionalities). This succeeded more
with validating the training set back (averaged around 85%
accuracy), but the performance on the test data set was the
same as previously (50%).

REFERENCES
[1]

[2]

We also used a convolutional neural network for
classifying the data as images rather than numerical data. We
extracted the spectrograms from the samples and used them
as the input of the network. It succeeded around the same
accuracy as classifying the extracted features.

[3]

[4]

While processing the data with neural networks it became
obvious that finding patterns in the signal is not an easy task,
even with the help of neural networks. It succeeded on the
raw, beta frequency data the best, but it is still far from
getting a good classifier.

[5]

[6]

3) Recognizing patterns in blinking
Controlling devices with our minds can be achieved in
more than one way. One way is to train machine learning
algorithms to recognize imagined movements. Working with
this device it became obvious that training like these cannot
be achieved with it. But there is one type of pattern that was
conspicuous and easily recognizable by even the human eye:
blinking patterns.

[7]

[8]

[9]

We decided to run a simple experiment on the data. We
recorded data while blinking a few characters of the Morsecode: s, r, and k. The letter s has the pattern of short-shortshort, r is defined by short-long-short, and k is assigned to
long-short-long. Three recording of these patterns can be
seen in Fig. 3. The three patterns are distinguishable even
with the human eye.

[10]

[11]

We decided to run this data through a neural network and
confirm whether an algorithm can distinguish these patterns.
We created a simple two-layer multiclass classification
neural network. Then we recorded 10 of each pattern and
used other previously recorded data for negative data. Thus,
we obtained a 4-class classification. The results are
promising. It could fully validate back the training data and
running on new unseen data the network yielded promising
results. It could extract the pattern s easily, and it could also
extract the other two patterns with little error. It does have
false positives, but with a larger training set it potentially
could be used in real-time applications.

[12]

[13]

[14]

VI. CONCLUSION
In this paper we discussed different type of methods for
analyzing data from a consumer-grade device. We concluded
that using this one-channel device for complex EEG signal
analysis is not viable. The obtained raw data is hard to
analyze, it is noisy, and we cannot deduct concrete facts from
it other than the general alertness of the user. So, it is not
possible to use for BCI applications like recognizing
imagined hand movements or recognizing any other concrete
EEG pattern. But we did have promising results from
recognizing blinking patterns. These type signals are easy to
extract compared to any other information. They can
probably be a good basis for controlling devices or robots,
thus giving a platform for applications that may help disabled
people.

ISSN 1844 – 9689

[15]

[16]

[17]

[18]

33

B. Rebsamen et al., "A Brain Controlled Wheelchair to Navigate in
Familiar Environments," in IEEE Transactions on Neural Systems
and Rehabilitation Engineering, vol. 18, no. 6, pp. 590-598, Dec.
2010.
T. Carlson and J. del R. Millan, "Brain-Controlled Wheelchairs: A
Robotic Architecture," in IEEE Robotics and Automation Magazine,
vol. 20, no. 1, pp. 65-73, March. 2013.
R. Scherer, G. R. Muller, C. Neuper, B. Graimann and G.
Pfurtscheller, "An asynchronously controlled EEG-based virtual
keyboard: improvement of the spelling rate," in IEEE Transactions on
Biomedical Engineering, vol. 51, no. 6, pp. 979-984, June 2004.
A. Jackson, C. T. Moritz, J. Mavoori, T. H. Lucas and E. E. Fetz,
"The neurochip BCI: towards a neural prosthesis for upper limb
function," in IEEE Transactions on Neural Systems and
Rehabilitation Engineering, vol. 14, no. 2, pp. 187-190, June 2006.
G. R. Muller-Putz and G. Pfurtscheller, "Control of an Electrical
Prosthesis With an SSVEP-Based BCI," in IEEE Transactions on
Biomedical Engineering, vol. 55, no. 1, pp. 361-364, Jan. 2008.
C. Lin et al., "Noninvasive Neural Prostheses Using Mobile and
Wireless EEG," in Proceedings of the IEEE, vol. 96, no. 7, pp. 11671183, July 2008.
C. Guger, W. Harkam, C. Hertnaes and G. Pfurtscheller. (1999,
November). “Prosthetic Control by an EEG-based Brain- Computer
Interface (BCI)”. In Proc. aaate 5th european conference for the
advancement of assistive technology (pp. 3-6).
C. Neuper, A. Schlögl, G. Pfurtscheller (1999, July), “Enhancement
of Left-Right Sensorimotor EEG Differences During FeedbackRegulated Motor Imagery”, in Journal of Clinical Neurophysiology,
vol. 16, no. 4, pp. 373-382
F. Babiloni et al., "Linear classification of low-resolution EEG
patterns produced by imagined hand movements," in IEEE
Transactions on Rehabilitation Engineering, vol. 8, no. 2, pp. 186188, June 2000.
J. Kim, I. Kim, S. Haufe and S. Lee, "Brain-computer interface for
smart vehicle: Detection of braking intention during simulated
driving," 2014 International Winter Workshop on Brain-Computer
Interface (BCI), Jeongsun-kun, 2014, pp. 1-3.
C-T. Lin, R-C. Wu, S-F. Liang, W-H. Chao, Y-J. Chen and T-P. Jung,
"EEG-based drowsiness estimation for safety driving using
independent component analysis," in IEEE Transactions on Circuits
and Systems I: Regular Papers, vol. 52, no. 12, pp. 2726-2738, Dec.
2005.
R. N. Khushaba, S. Kodagoda, S. Lal and G. Dissanayake, "Driver
Drowsiness Classification Using Fuzzy Wavelet-Packet-Based
Feature-Extraction Algorithm," in IEEE Transactions on Biomedical
Engineering, vol. 58, no. 1, pp. 121-131, Jan. 2011.
K. George, A. Iniguez and H. Donze, "Sensing and decoding of visual
stimuli using commercial Brain Computer Interface technology,"
2014 IEEE International Instrumentation and Measurement
Technology Conference (I2MTC) Proceedings, Montevideo, 2014,
pp. 1102-1104.
A. Kline and J. Desai, "SIMULINK®based robotic hand control
using Emotiv™ EEG headset," 2014 40th Annual Northeast
Bioengineering Conference (NEBEC), Boston, MA, 2014, pp. 1-2.
N. Chumerin, N. V. Manyakov, M. van Vliet, A. Robben, A. Combaz
and M. M. Van Hulle, "Steady-State Visual Evoked Potential-Based
Computer Gaming on a Consumer-Grade EEG Device," in IEEE
Transactions on Computational Intelligence and AI in Games, vol. 5,
no. 2, pp. 100-110, June 2013.
C. Lin, C. Ding, C. Liu and Y. Liu, "Development of a real-time
drowsiness warning system based on an embedded system," 2015
International Conference on Advanced Robotics and Intelligent
Systems (ARIS), Taipei, 2015, pp. 1-4.
C. A. Lim, Wai Chong Chia and Siew Wen Chin, "A mobile driver
safety system: Analysis of single-channel EEG on drowsiness
detection," 2014 International Conference on Computational Science
and Technology (ICCST), Kota Kinabalu, 2014, pp. 1-5
J. He, D. Liu, Z. Wan and C. Hu, "A noninvasive real-time driving
fatigue detection technology based on left prefrontal Attention and
Meditation EEG," 2014 International Conference on Multisensor

https://www.degruyter.com/view/j/cjece

Carpathian Journal of Electronic and Computer Engineering 11/2 (2018) 29-34

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

[27]

[28] R. Jenke, A. Peer and M. Buss, "Feature Extraction and Selection for
Emotion Recognition from EEG," in IEEE Transactions on Affective
Computing, vol. 5, no. 3, pp. 327-339, 1 July-Sept. 2014.
[29] A. Zhang, B. Yang and L. Huang, "Feature Extraction of EEG Signals
Using Power Spectral Entropy," 2008 International Conference on
BioMedical Engineering and Informatics, Sanya, 2008, pp. 435-439.
[30] J Suto, S Oniga, "Efficiency investigation of artificial neural networks
in human activity recognition" in Journal of Ambient Intelligence and
Humanized Computing 9 (4), 1049-1060, August 2018
[31] B. Hjorth, "EEG analysis based on time domain properties" in
Electroencephalography and Clinical Neurophysiology , Volume 29 ,
Issue 3 , 306 – 310
[32] S-H. Oh, Y-R. Lee, and H-N. Kim, "A Novel EEG Feature Extraction
Method Using Hjorth Parameter" in International Journal of
Electronics and Electrical Engineering, Vol. 2, No. 2, pp. 106-110,
June 2014.
[33] Y. Liu, Y. Lin, S. Wu, C. Chuang and C. Lin, "Brain Dynamics in
Predicting Driving Fatigue Using a Recurrent Self-Evolving Fuzzy
Neural Network," in IEEE Transactions on Neural Networks and
Learning Systems, vol. 27, no. 2, pp. 347-360, Feb. 2016.
[34] J. Zhang, C. Yan and X. Gong, "Deep convolutional neural network
for decoding motor imagery based brain computer interface," 2017
IEEE
International
Conference
on
Signal
Processing,
Communications and Computing (ICSPCC), Xiamen, 2017, pp. 1-5.
[35] X. Li, D. Song, P. Zhang, G. Yu, Y. Hou and B. Hu, "Emotion
recognition from multi-channel EEG data through Convolutional
Recurrent Neural Network," 2016 IEEE International Conference on
Bioinformatics and Biomedicine (BIBM), Shenzhen, 2016, pp. 352359.
[36] H. K. Lee and Y. Choi, "A convolution neural networks scheme for
classification of motor imagery EEG based on wavelet time-frequecy
image," 2018 International Conference on Information Networking
(ICOIN), Chiang Mai, 2018, pp. 906-909.

Fusion and Information Integration for Intelligent Systems (MFI),
Beijing, 2014, pp. 1-6.
J. W. Britton, L.C. Frey, J. L. Hopp et al., authors; E.K St. Louis.,
L.C. Frey, editors. Electroencephalography (EEG): An Introductory
Text and Atlas of Normal and Abnormal Findings in Adults,
Children, and Infants [Internet]. Chicago: American Epilepsy Society;
2016.
The
Abnormal
EEG.
Available
from:
https://www.ncbi.nlm.nih.gov/books/NBK390357/
medicine.mcgill.ca,
“EEG
>
alpha
waves”,
https://www.medicine.mcgill.ca/physio/vlab/biomed_signals/eeg_raw
.htm [Accessed: 09-Nov-2018]
E. Niedermeyer and F. H. Lopes da Silva, "Electroencephalography:
Basic Principles, Clinical Applications, and Related Fields".
Lippincott Williams & Wilkins, 2005, pp. 178-180
S. J. M. Smith, “EEG in neurological conditions other than epilepsy:
when does it help, what does it add?” in Journal of Neurology,
Neurosurgery & Psychiatry, 2005, vol. 76, pp. ii8-ii12
neurosky.com, "ATTENTION eSense", [Online]. Available:
http://developer.neurosky.com/docs/doku.php?id=thinkgear_commun
ications_protocol#attention_esense. [Accessed: 09-Nov-2018]
neurosky.com, "MEDITATION eSense", [Online]. Available:
http://developer.neurosky.com/docs/doku.php?id=thinkgear_commun
ications_protocol#meditation_esense. [Accessed: 09-Nov-2018]
neurosky.com, "ASIC_EEG_POWER_INT", [Online]. Available:
http://developer.neurosky.com/docs/doku.php?id=thinkgear_commun
ications_protocol#asic_eeg_power_int. [Accessed: 09-Nov-2018]
neurosky.com, "EEG Band Power values: Units, Amplitudes, and
Meaning",
[Online].
Available:
http://support.neurosky.com/kb/development-2/eeg-band-powervalues-units-amplitudes-and-meaning. [Accessed: 09-Nov-2018]
J. Suto, S. Oniga and P. P. Sitar, "Music stimuli recognition from
electroencephalogram signal with machine learning," 2018 7th
International Conference on Computers Communications and Control
(ICCCC), Oradea, 2018, pp. 260-264.

ISSN 1844 – 9689

34

https://www.degruyter.com/view/j/cjece

