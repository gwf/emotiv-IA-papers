Journal of Education and Training Studies
Vol. 4, No. 1; January 2016
ISSN 2324-805X E-ISSN 2324-8068
Published by Redfame Publishing
URL: http://jets.redfame.com

LewiSpace: an Exploratory Study with a Machine Learning Model in an
Educational Game
Ramla Ghali1, Sébastien Ouellet1, Claude Frasson1
1

Université de Montréal, Département d’informatique et de recherche opérationnelle, 2920 Chemin de la Tour, H3C 3J7
(QC), Canada

Correspondence: Ramla Ghali, Université de Montréal, Département d’informatique et de recherche opérationnelle,
2920 Chemin de la Tour, H3C 3J7 (QC), Canada
Received: August 6, 2015
doi:10.11114/jets.v4i1.1153

Accepted: August 20, 2015

Online Published: October 19, 2015

URL: http://dx.doi.org/10.11114/jets.v4i1.1153

Abstract
The use of educational games as a tool for providing learners with a playful and educational aspect is widespread. In
this paper, we present an educational game that we developed to teach a chemistry lesson, namely drawing a Lewis
diagram. Our game is a 3D environment known as LewiSpace and aims at balancing between playful and educational
contents in order to increase engagement and motivation while learning. The game contains mainly five different
missions aim at constructing Lewis diagram molecules which are organized in an ascending order of difficulty. We also
conducted an experiment to gather data about learners’ cognitive and emotional states as well as their behaviours
through our game by using three types of sensors (electroencephalography, eye tracking, and facial expression
recognition with an optical camera) and a self report personality questionnaire (the Big Five). Primary results show that
a machine learning model namely logistic regression, can predict with some success whether the learner will success or
fail in each mission of our game, and paves the way for an adaptive version of the game. This latter will challenge or
assist learners based on some features extracted from our data. Feature extraction integrated into a machine learning
model aims mainly at providing learners’ with a real-time adaptation according to their performance and skills while
progressing in our game.
Keywords: educational game, electroencephalogram, eye tracking, facial expression recognition, logistic regression
model, big five questionnaire
1. Introduction
In Human Computer Interaction (HCI), the Intelligent Tutoring Systems (ITS) were among the first sophisticated
learning systems. These systems are characterized by their capacity to provide a continuous feedback, hints, helps, etc.
to learners. The adaptation was done mainly by using intelligence artificial techniques and more specifically machine
learning algorithms. The use of the latter provides these systems with the ‘intelligence’ criterion. Nowadays, the ITS
have progressed and moved to another type of environment since 2002: educational games or serious games (SGs). SGs
are video games that aim to inform, test and train people while playing. They can be applied in several fields: military,
government, education, business, health care, etc. Recently, they are more used for educational reasons (Conati 2002,
Ghali et al. 2014, Jackson et al. 2012, Rowe et al. 2009) through their playful aspect, known as ‘Game based Features’
(McNamara et al. 2010).
Although this environment presented a very appropriate and quite moderate way of learning, the problem of user
adaptation according to educational aspect remains of great importance. We think that researchers should focus more on
this problem in this type of environment due to its difference with ITS. However, to our knowledge, only few works are
interested to develop some adaptive user models in SGs and very few works are interested to provide learners’ with real
time adaptation which reacts while interacting with the game. However, we believe that this issue presents a very
important factor to consider in SGs since that their main goal in educational applications is to improve and focus more
on the educational and pedagogical content and not the playful aspect which does not contribute to learning
improvement process. Therefore, on one hand we think that the adaptation must more focus on the type and nature of
help to supplement and complement the educational content of the game. On the other hand, we think that this latter
should be instantly and in real time. So, the resulting environments (SGs) should react immediately and/or according to
192

Journal of Education and Training Studies

Vol. 4, No. 1; January 2016

user’s needs and learning capacity. Moreover, many works focus more on the playful aspect which increases motivation
and pleasure but not necessary contributes to improving the learning process which depends mainly on the pedagogical
contents. In addition, almost games present a serious problem when translating from game situations to non-game
contexts. Furthermore, the students generally spend too much time in using entertainment and playful aspects rather
than practicing educational contents.
In order to solve this problem and to develop more effective real time adaptive tools which consist of taking learners’
differences (a Big Five personality was administrated in our work) and focus more of detecting when users need really
more pedagogical help in SGs, we proposed in this paper a first version of a 3D puzzle game called LewiSpace. We
hypothesize that this game will focus more on learning how to draw Lewis diagrams rather than playful features (which
are available when navigating in a 3D environment, changing backgrounds’ colors with the different places and
gathering the requested atoms to construct complex molecules). Our goal with the study described in the current paper
is to investigate whether it is possible to predict a learner’s success and his desired level of help based on information
gathered through different types of data: electroencephalography (The Affectiv Suite from EPOC Emotiv), eye tracking
(the indice of workload extracted from pupil diameter), facial expression recognition (through FaceReader software)
and self-report big five personality questionnaire. Since this is part of a larger project that aims to develop a game that
will be able to adapt in real-time to learners, we first studied in this paper the descriptive results obtained, the
importance of each sensor used and how it improves prediction of learner’s success or fail in each mission of our game.
We also studied the utility of combining different types of data and the necessity of using them to build the most
appropriate real-time users’ adaptation.
This paper is structured as follows: in the next section, we describe some related works and mention the disadvantages
of the existing works. Next, we describe LewiSpace game that is designed to teach how to construct Lewid diagrams for
some complex molecules. Next, we describe the experiment that we conducted in order to gather data and their
pre-processing stage. Finally, the last section presents some descriptive results about learners’ performance distribution
in the different missions of our game. We also provide a comparison and a discussion about the different real time
statistical machine learning techniques used in this study, how we extract the features from our multimodal kinds of data
and how we select the best approach, more specifically concerning the real time machine learning algorithm, the
features and the hyper parameters to take into consideration for this type of applications.
2. Previous Works
Recently, the use of educational games or serious games became widespread. These games are beneficial for learning
because they incorporate two fundamental aspects: (1) educational aspect interested to learning content and strategies to
present to learners, and (2) playful aspect that allows learners to play, explore, take rewards, control the environment,
etc. In fact, researchers believe that this last aspect can increase learners’ motivation and engagement (McNamara et al.
2010, Lester et al. 2014, Ghali et al. 2014). This aspect is also known as 'Game-Based Features' (McNamara et al. 2010).
Moreover, Prensky, Johnson and Wu (Prensky 2001, Johnson et al. 2008) agree that educational games have not only
playful aspects but several criteria and characteristics to increase exploration, immersion and motivation aspects.
According to McNamara and Jackson (McNamara et al. 2010), games based features could be grouped into five main
categories: (1) Feedback which consists at providing learners with a specific, intelligent and motivational feedback; (2)
Incentives which aims at promoting the aspects of bonuses and rewards. The latter are related to extrinsic motivation
and have a direct effect on learners’ self-efficacy, engagement and interest; (3) Task difficulty which consist at varying
the difficulty of a task and adjust it according to learners’ skills; (4) Control which allows the learner to monitor and
manage the environment such as changing the color of background or avatar and finally (5) Environment which
focuses at the design and the type of the environment.
Despite the last criteria proposed by (McNamara et al. 2010) to develop more effective educational games, the latter
present several problems. Among them, we cite briefly the problem of spending too much time for playing instead of
entertainment and learning, the problem of the construction and the order of pedagogical content, the problem of
translating between playful and educational aspects, etc. To solve these problems, we suggest that more research will be
done in the field of SGs and that this latter should be more intelligent. The intelligence criterion consists of offering to
user a real time, continuous, and individualized adaptation according to learning content. We define this type of game as
Intelligent Educational Games (IEG). Whereas, to date, only some works are interested to automatic (but not real time)
user modeling and/or adaptation either in tutoring systems or educational games (Lester et al. 2014, D’Mello et al. 2012,
Gobert et al. 2015, McQuiggan et al. 2006). The adaptation or modeling is usually done using some learners’ criteria
(such as emotions, engagement, motivation, workload, self-efficacy, performance, etc.). They could also be classified
into two kinds of groups: (1) works based on the learner's interactions with the system and (2) works based on the
electro-physiological sensors. Among these works, we cite as an example those of Gobert, Baker and his team which are
193

Journal of Education and Training Studies

Vol. 4, No. 1; January 2016

interested to automatically detect learner’s disengagement (Gobert et al. 2015). They build an automatic machine
learning detector of disengagement behavior. Their model is based on human labels of behaviors from log files and data
mining techniques. Lester and colleagues (Lester et al. 2014) used Elliot and Pekrun model (Elliott et al. 2007) to
automatically predict and adapt learners’ emotions. This model has been empirically used with learners’ interaction data
with the system which are derived from a subjective method of self-assessment of emotions. Emotions are recorded
from learners using a portable device (smartphone game device) every seven seconds. D'Mello and colleagues (D’Mello
et al. 2012) have used eye tracking data to automatically detect emotions of boredom and disengagement among
learners in interactions with a tutoring system. Automatic tracking of eye movements was integrated into a tutor that
identify when a learner is bored, looking or zooming on the screen.
Recently, Jaques and colleagues (Jaques et al. 2014) used also gaze data features in order to predict two main emotions:
boredom and curiosity. These emotions are predicted from several machine learning and feature selection algorithms
collected from students’ self-reported emotions in Meta tutor system (Azevedo et al. 2010). They obtained an accuracy
of 69% for boredom and 73% for curiosity. Finally, (MCQuiggan et al. 2006) used decision trees and Bayesian
networks to generate predictive models of self-efficacy. They obtained two families of models: (1) static models that
are based on the demographics of the student from pre-test self-efficacy, and (2) dynamic models that combine static
data model and physiological data (heart rate and skin conductance). The authors have shown that static models predict
self-efficacy of students with an acceptable accuracy rate (73%). However, the dynamic models allow a prediction of
self-efficacy with better accuracy rate (83%).
Although these works present a very important way to automatically detect some learners’ negative behaviours or
emotions which are not effective for learning, we were not interested in this paper to predict learners’ emotions because
our designed game LewiSpace is not emotionally engaged but focus more on educational aspect. The game also detects
automatically learners’ emotions through FaceReader software. We use this sensor to extract seven basic emotions
(happy, sad, angry, surprised, scared, disgusted, and neutral) in addition to the valence and arousal of each emotion
(Lewinski et al. 2014). In (Chaffar et al. 2006) we have also anticipated learners’emotional response using EEG
techniques. We also complete the miss detection of some emotions due mainly to mouth occlusion by using the Affectiv
Suite provided by Emotiv EEG sensor (Gheeguluscu et al. 2014). Whereas, the usage of gaze data (Tobii Tx300 sensor)
more precisely pupil diameter is to measure learner’s state of workload (Bartels et al. 2012) while interacting with our
educational game. The following section describes LewiSpace, a 3D educational puzzle game.
3. LewiSpace: An Educational Puzzle Game
3.1 A Description and Design of the Environment
LewiSpace is an educational game which aims mainly to teach learners how to construct chemical structures of
molecules using Lewis diagrams (Ghali et al. 2015). The game is mainly designed to be explored by college students
who didn’t have any knowledge about how to build Lewis’ diagrams (a chemistry lesson). It has an exploratory
environment (3D) developed using Unity 4.5 for the design of the game, integrating EEG and eye tracking sensors data
using the Emotiv SDK v2.0 LITE and the Tobii SDK 3.0.
In the first user’s interaction with the game, the player is simulated as an astronaut exploring a planet’s surface and
communicating with a non-player character known as Commander Arnold (figure 1). The player is told that he fell
down into a cavern and that he has to explore the underground where he has each time to overcome obstacles
(obstructions, lack of a useful resource, etc.) in order to progress in the game and find his lander, allowing him to return
home. The player starts by exploring the environment which is mainly composed of five types of scenes leading to five
different missions to accomplish during the game. The missions are constructed in ascending order of difficulty
according to the complexity of molecules’ structures and the player can’t progress to the next mission before completing
the latest one. By exploring our educational game, the player accumulates a certain number of atoms (which are hidden
somewhere on the environment) that he adds to his inventory and can use them further in order to construct chemical
compounds. The latter are used to unlock paths and move to another stage in the game. In the following, we will
describe and present some screenshots for the different missions of our game.

194

Journal of Eduucation and Traaining Studies

Vol. 44, No. 1; January 2016

Figure 1. The beginning of tthe game
3.1.1 Mission 1: Produce Water
W
After starting by exploring the environmeent and seeingg tanks of hydrrogen and oxyygen, the playeer is invited to produce
H2O moleculee (water) in orrder to refill hhis spacesuit’s thermal regullation system. He has to plaace atoms in a grid by
clicking on thhem and deducce the correct L
Lewis diagram
m structure (figgure 2) accordiing to rules thaat are presented to him
throughout thee game (see seection 3.2), in tthe manner of a puzzle.

Figure 2. Atoms in thhe environmennt (left) and usiing a Lewis diaagram tool to pproduce H2O m
molecule (righ
ht)
3.1.2 Mission 2: Warm and Destruct
D
a Tunnnel
In this missioon, the player has to gather carbon and hyydrogen in orrder to produce methane gass (CH4). The player
p
is
provided withh the information about the ggroup of each atom and also the periodic ttable that repreesents the structures of
atoms accordiing to their grroup’s numberr and atomic nnumber of eacch one during all the missions. He has to find the
number of eleectrons availabble on the last aatom’s layer (tthe valence sheell) and to connstruct the righht diagram acco
ording to
the octet rule and the valennce electrons inndicated by thhe periodic tabble. After prodducing the methane, an anim
mation is
shown to the pplayer, allowinng the player too melt the tunnnel’s obstructioon with a methhane torch (figuure 3).

Figure 3. Meelting a tunnel’s obstruction uusing a methanne torch
3.1.3 Mission 3: Dissolve a Metal Debris
The player has to construct a more compleex molecule w
which lets him ddissolve metall debris. The coompound to prroduce is
sulfuric acid ((H2SO4). This structure has 332 electrons too distribute beetween the atom
ms and the plaayer has to mo
ove some
electrons in orrder to construuct double bonnds. We noticeed that until thhis stage, all thhe three missioons could be presented
p
by a symmetriical diagram Lewis
L
structuree.
195

Journal of Education and Training Studies

Vol. 4, No. 1; January 2016

3.1.4 Mission 4: Craft a Refrigerant
Here, the player has to craft a refrigerant (C2F3Cl) and use it for his spacesuit to regulate his body temperature. This
compound could be seen as less complex than the previous one, but it is the first one to present an asymmetrical
structure.
3.1.5 Mission 5: Fill in the Fuel Cell with Ethanol
In the last mission, the player is out of the cavern. He finds his lander module on the surface but its fuel cell is empty.
As a final task, the player has to gather and construct ethanol (C2H6O). As soon as this is done, the rocket takes off. At
this stage, the game is over (see figure 4).

Figure 4. The end of the game
3.2 A Description of the Given Instructions and Rules
In this section, we will focus more on how we present the educational materials to learners while they progress on the
game. Hence, to motivate the students with a playful aspect, we think that this latter is covered when they are navigating
on a 3D environment. Every time, they have to look everywhere in the cavern structure to find the appropriate atoms to
gather that allow them to construct the requested molecule. The design and the colors of the environments are also
attractive and different from each other’s. However, the educational aspect is covered by announcing the rules to use on
some missions and the directives mentioned in order (see table 1). The learner has also the option to see the periodic
table at any time while building a molecule by pressing a shortcut button that enables him to open or close this
informative tool.
Table 1. Instructions and rules presented in LewiSpace mentionned according the missions
Missions
Mission 1
Mission 2

Mission 3

Mission 4
Mission 5

Instructions
- Hydrogen atoms can only bond once. This is because a single covalent bond involves one pair
of electrons, and hydrogen needs 2 electrons to be full. This is an exception, as other atoms need
8 electrons. This is known as the octet rule, atoms tend to combine to satisfy it.
- Double covalent bonds involve 2 pairs of electrons. You can figu-re out if single or double
bonds are needed with the octet rule and with the number of valence electrons the atoms have.
- Open your Periodic Table by pressing I. Each column (except the pink-colored ones) group
atoms by their number of valence elect-rons. For example, hydrogen has 1, calcium (Ca) has 2,
aluminum (Al) has 3, fluorine (F) has 7.
- When crafting a compound, each single bond you add represents 2 electrons, shared between
two atoms. If an atom doesn't have 8 electrons after you sum up its lone electrons and those
shared through bonds, you might have to add double bonds or to redraw the structure.
- It's often important to consider formal charges when drawing structures. You can calculate each
atom's formal charge by sub-stracting each bond (1 for a single, 2 for a double one) and each lone
electron from its initial number of valence electrons.
- If the formal charge is not zero, you might be able to reconfigure the diagram (change the shape
or the type of bonds). The octet rule can be violated in some cases.
- Also, keep in mind that elements in the third row of the Periodic Table can sometimes hold
more than 8 electrons
- No new rules
- No new rules

As we mentioned before, the learner is provided at any time he wants by an informative tool, the standard periodic table.
This tool describes for each atom the symbol, the atomic number, the mass number or the number of nucleons and the
group indicated on the top of each column.
4. Experiment and Data Preprocessing
4.1 Experiment
In order to gather data from eye tracking, electroencephalogram (EEG) sensors and learners’ emotions, we conducted an
196

Journal of Eduucation and Traaining Studies

Vol. 44, No. 1; January 2016

experiment w
where 40 particcipants (25 maales and 15 fem
males aged bettween 19 and 35 years) from
m Montreal Un
niversity
participated voluntarily in thhe study (withh a compensatiion of 20$ forr each participaant). As a criteerion for admiissibility,
we requested students who have
h
no prior knowledge abbout Lewis Diaagrams (a chem
mistry course ssupposed to be
e learned
to college studdents). The stuudy was held uunder strict labboratory condittions. Once we explained thhe whole proce
ess of the
study and thee participant signed the ethiics agreement, the participaant is invited to start our exxperiment. Du
uring the
experiment, E
EEG is recorded with the Em
motiv headset, w
which is comm
municating to thhe computer thhrough Wi-Fi and only
requires a saline solution foor conduction.. EEG is samppled at a rate of 128 Hz at a second and 14 channels could
c
be
measured usinng this device through TestB
Bench. The heaadset was also communicatinng to the Affecctiv suite (Gherguluscu
2014), which outputs five high-level
h
featuures (short-term
m excitement,, long-term exccitement, medditation, frustra
ation and
boredom). Eye tracking wass performed ussing Tobii Tx300 which is chharacterized w
with a high ratinng sampling frrequency
of 300Hz per second and itts robustness too head movem
ments and lighht variations. W
We extract from
m this sensor the
t pupil
diameter in orrder to measurre learner’s woorkload (Bartells et al. 2012).. Facial expresssion recognitiion was done using
u
the
FaceReader 6.0 software byy recording thee participant w
with a webcam
m. The face traccking process uses the popullar Viola
and Jones algoorithm (Viola et al. 2001). T
This latter allow
ws us to obtainn a real time cllassification off seven basic emotions
e
defined by Ekkman (Ekman 1970): happyy, sad, angry, ssurprised, scarred, disgusted,, and neutral w
with their vale
ence and
arousal (Lewinski et al. 2014).
The experimeent process is composed
c
of 7 steps: (1) insstallation of E
Emotiv EPOC headset, (2) caalibration of Tobii
T
eye
tracker, (3) fiill in a personnality test (Biig Five (Olivier et al. 19999) ), (4) a pree-test that connsist of constructing 3
molecules (CO2, CCl2F2, C2H4), (5) expploring our 3D
D environmennt and learninng Lewis diaggram principle
es, (5) a
post-test whicch is of a similar difficulty off the pre-test ((this latter testss if the particippant’s understoood all the insttructions
presented on tthe game and could
c
apply theem to solve othher examples) and (7) finallyy, evaluation oof our environm
ment and
self-reported ddifficulty of each
e
presentedd mission of ouur game (easyy, medium andd hard rangingg from 1 to 3)) using a
questionnaire based on a Likkert’s scale (seee figure 5).

Figure 5. Thee experiment pprotocol
4.2 Data Pre-pprocessing.
Given the dataa’s sequential nature, the daata stream was divided in inddividual sequeences accordingg to the learne
ers’ trials
recorded by thhe game. For example,
e
the leearner could trry and fail threee times for thee first task of tthe game, with a fourth
successful triaal. Four sequeences would thhen be availabble for analyssis. Each sequuence was thenn reduced to a feature
vector consistting of the 4 metrics, meddian, standardd deviation, m
maximum, andd minimum vaalues for each
h feature
gathered durinng the game session: short-tterm excitemennt, long-term eexcitement, m
meditation, frusstration, boredo
om from
the Affectiv ssuite from Em
motiv (on a sccale from 0 too 1), pupil diaameter from thhe eye trackinng sensors to measure
learner’s workkload, arousal,, valence and tthe seven emottions mentioneed above from
m FaceReader ((15 features at total). A
total of 633 ssequences (accross 33 particcipants) 60-dim
mensional vecctors (15 featuures multiplieed by 4 metric
cs) were
produced. 7 pparticipants were
w
ignored foor analysis as technical erroors (unrelatedd to the participants) corrup
pted data
segments esseential for a corrrect synchronnisation of all ddata streams. S
So, only 33 paarticipants outt of 40 were ta
aken into
consideration for data analyysis in the rest oof this paper.
me) were
Other missingg data values (e.g. the eye traacker failing too fit a model tto the participaant for a smalll amount of tim
replaced by thhe mean valuess for each featuure.
Given the diffficulty and thhe nature of thhe game, whicch encourages trials and errrors, most sequuences are lab
belled as
failures. This presents a sevverely unbalannced dataset, annd we used cllass weighting in order to adddress this issu
ue. Class
weighting invversely penalizzes misclassiffications accorrding to the ffrequency of each class, annd is implemented in
Scikit-learn (P
Pedrogosa et all. 2011), the Pyython library w
we used to mannipulate data aand train machhine learning models.
m
5. Results
In this part, w
we will first preesent some desscriptive resultts gathered from
m our participants while inteeracting with our
o game,
197

Journal of Eduucation and Traaining Studies

Vol. 44, No. 1; January 2016

LewiSpace. S
Second, we wiill show a suiitable machinee learning moodel to integraate with the aappropriate fea
atures in
real-time appllications. Finallly, we will disscuss the impoortance of eachh sensor used fo
for further learnner’s help adap
ptation.
5.1 Descriptivve Results
As we mentiioned before (experiment ssection), all thhe participantts completed at the end a subjective ev
valuation
questionnaire which containns questions abbout the difficuulty of each m
mission of our ggame as well aas the degree of game’s
appreciation ((ranked from 1:not
1
appreciatted at all to 5: very appreciaated). We noticced then that w
we obtained a mean of
3.083 (medium
m appreciated) and a standaard deviation ((SD) of 1.204. So, we can seee clearly thatt a very big nu
umber of
participants liike the designn and the conntent of our ggame. Howeveer, a small nuumber didn’t. This factor could
c
be
explained by the value of SD
S which is a little bit high.. We also noticced in generall that a small nnumber of parrticipants
(20%: 8 from 40) succeed to
t complete thhe whole missiions of the gam
me because it’s a difficult leesson for non-sscientific
people and needs more exxplications andd examples (w
which is our m
main goal for an improved version of th
his game
according to ddifferent types of learners and personalitiess).
Next, we calcculated for eacch mission som
me statistics off the average nnumber of failure (see figurre 6 below). From this
figure, we repported the meaan and the stanndard deviationn M(SD) for each mission. F
For example, m
mission 1 is ranked the
second highesst in term of avverage of failuure although itt’s an easy misssion (H2O):100.04(9.49). Miission 2 has th
he lowest
number of faiilure (6.15(5.775)) despite itt is very simillar to mission 1. Mission 3 has the highest number off failure:
14.55(8.55). H
However, misssion 4 and misssion 5 are about the same in term of meean of failure. Whereas, it sh
hould be
noticed that is a large num
mber of particiipants decidedd to quit in m
mission 3 (27 ccases) and a ssmall number of them
completed mission 4 and more
m
particularly mission 5 ((8 cases) whichh is at the endd of our game.. Despite these
e results,
we noticed that there are soome learners have 0 failures in some missiions and somee ones have 299 errors or failu
ures (the
maximum num
mber of trials which
w
are wronng achieved foor our sample oof people).

Fiigure 6. Statistics of failure pper mission
Therefore, wee calculated in the table below
w the means aand standard errrors of the avverage durationn of success in seconds
(s) for each m
mission to studyy again the diffficulty of missions for our ssample of studdents. We noticced from this table that
mission 2 is tthe easiest onee (433.80 s) aand mission 3 is the hardestt one (1433.266 s). However,, missions 1 and 4 are
about the sam
me in term off difficulty acccording to thee time spent iin order to acccomplish them
m. This resultt is very
surprising for us as we assum
me that the miission 1 is veryy easy to accom
mplish.
Table 2. The aaverage successs time per misssion
Misssions
Mission 1
Mission 2
Mission 3
Mission 4
Mission 5

Total Duuration
Mean (Standdard Error)
926.68 (669.83)
433.80 (224.37)
1433.26 (667.43)
902.03 (773.96)
626.72 (86.76)

Moreover, wee realized an ANOVA
A
to studdy if the missiions are statisttically differennt according too the number of
o failure
and the duraation. Results shows that missions deppend only onn the numberr of failure aand not the duration
(F(4,666)=25..17;p=0.000***<0.01) but thhe results of thhree popular ppost hoc tests (Scheffe, LSD
D and Tukey)) are not
significant. This means thaat the missionns are not totaally different according to the failure faactor. Finally, a paired
samples t-testt was conducteed to comparee the score impprovement in the pre-test annd post-test. T
There was a sig
gnificant
difference in the scores foor the pre-test (M=12.28, S
SD=23.78) andd the post-testt (M=54.83, S
SD=29.42) con
nditions;
t(37)=-9.054, p = 0.000**. This result prooves that our ggame contribuutes to improvee learners’ scoores for drawin
ng Lewis
198

Journal of Education and Training Studies

Vol. 4, No. 1; January 2016

structures after learning the lesson.
5.2 Selection of the Best Machine Learning Model
Support vector machine (SVM) with a Radial Basis Function (RBF) kernel and logistic regression models were tested
with a grid search on values of gamma (for SVMs) and C to produce the highest balanced accuracy with a
leave-one-participant-out scheme. This scheme was used in order to promote the selection of a model that can
generalize well for a new participant from previous participants. Both algorithms performed similarly. For instance with
a RBF SVM, the accuracy is about 54.9% with the hyper-parameters (C=1.0 and gamma=0.05) using all the features
issued from 3 sensors. This value is very near to that of logistic regression (56.4%). In the following, we interest only
on communicating results for the best logistic regression models, as the focus of this paper is not the comparison of
machine learning algorithms. Logistic regression model in our case provides the highest accuracy in all cases as we will
see in the next section (by taken into consideration all or some features).
5.3 Comparaison of the Importance of Each Sensor and the Big Five
After selecting the best ML model that allows us to detect if the user needs help or not, we focus on this section to study
the features importance that contributes mainly to prediction. In what follows, we present the difference in accuracies in
term of substracting each time one feature (sensor feature or Big Five questionnaire). Balanced accuracy is determined
by the mean of correct classifications for each class while according both classes the same weight. Overall accuracy is
the mean number of correct classifications with weighting for the number of samples (therefore giving more weight for
the “failure” class), and the mean participant accuracy is the mean number of correct classifications per participant,
ignoring whether or not a participant produced more or less samples in the dataset, similarly to the balanced accuracy.
Table 3. Feature selection through classification accuracies

Balanced
accuracy
Overall accuracy
Mean participant
accuracy

All features (3
sensors )

Ignores
diameter

0.564

0.564

0.603
0.593

0.603
0.593

pupil

Ignores
Emotiv
0.501

Ignores facial
expression
recognition
0.564

Ignores Big Five
Questionnaire
0.584

0.256
0.312

0.603
0.593

0.564
0.549

Table 3 shows that ignoring the Emotiv has the highest impact on performance, whereas the other features do not seem
to change the accuracies when ignored. Adding five features from the self-reported Big Five Questionnaire (the values
along the five dimensions measured by the questionnaire before starting the game), we note that the balanced accuracy
is highest, but at the cost of the overall accuracy, which means that the classifier predicts more often that a task will be
successful but mispredicts more sequences in total. Ideally, the model should be balanced between those two measures
of accuracy. A model that measures only the features from the Emotiv headset was therefore tested and produces the
best results so far but still very similar to one which uses all features (using 3 sensors and ignoring the big five
questionnaire), with a balanced accuracy of 0.570 , an overall accuracy of 0.635 and a mean participant accuracy of
0.609. However, this indicates that other features are not necessary and might even add noise to the dataset. Table 4
shows its confusion matrix for the logistic regression using only Emotiv Affectiv Suite (The most important feature),
predicted values are shown vertically, and true values horizontally.
Table 4. Confusion matrix for a logistic regression model with Emotiv headset features
Failure

Success

Total number

Failure

0.665

0.335

532

Success

0.525

0.475

101

Total number
407
226
633
From table 4, we can see clearly that failure is easiest to predict (with an accuracy of 66.5% which is higher that the
random baseline of 50%), whereas, success is more difficult to predict (value of 47.5% which is less than 50%).
As to the relevance of the other features, we can speculate that brightness changes throughout the game (e.g. some
scenes or actions producing various lighting effects) have a larger impact on the pupil diameter, a factor unaccounted
during the experiment. We could improve this by controlling the brightness in real time. Facial expressions might also
be more useful in a game which is more emotionally engaging which is not the goal of our game. LewiSpace focuses
more on educational aspect and how to provide the adequate help to learners according the different situations
encountered when playing it.
Finally, we present the Receiver Operating Characteristic curves known as ROC curves (figure 7) for each participant
199

Journal of Eduucation and Traaining Studies

Vol. 44, No. 1; January 2016

compared witth the random baseline usingg our best moddel, a logistic regression (C value of 0.1). It is a plot off the true
positive rate aagainst the false positive ratte for the diffeerent possible cutpoints of a diagnostic teest. Accuracy for
f these
models was m
measured by thhe area under tthe ROC curve. An area of 1 represents a perfect test, w
whereas an are
ea of 0.5
represents a w
worthless test.. The figure bbelow illustrattes the width of the accuraacies encounteered due to in
ndividual
differences beetween the partticipants. We nnoticed a lot off people with a good accuraccy (under the ccurve) however a lot of
cases are miscclassified. This result suggests that we shoould more closely investigatte individuallyy trained mode
els rather
than generalizzed models.

Figuure 7. ROC currves for the 333 participants
6. Conclusion
ns
In this paper, we presentedd our educationnal game aim
med at teachingg players how to draw Lew
wis diagrams known as
LewiSpace. L
LewiSpace is a 3D environm
ment integratinng EEG and eeyetracking SD
DKs and combbining educatio
onal and
playful aspectts. Our study designed alsoo to investigaate the use off physiologicall data (electrooencephalograp
phy, eye
tracking, and facial expresssion recognitioon) and personnality traits (thhe Big Five Q
Questionnaire) in order to detect the
performance oof the learner and his need of help durinng progressingg in our game.. We describedd also some statistical
results in term
m of failure and duration for each mission.. From these rresults, we cann clearly see thhat the game sh
hould be
improved by pproviding morre help and exaamples for stuudents strugglinng to completee the tasks. Thhis aim will be realized
by collecting features from different typess of physiological sensors annd train a machhine learning aalgorithm. Ourr finding
shows that a logistic regresssion model uusing only Em
motiv EPOC A
Affectiv Suite as features is the most suittable for
detecting wheen learner havee more difficuulty (failure) annd needs moree help and exaamples to undeerstand the lessson. We
noticed also tthat personalityy traits as welll as pupil diam
meter and em
motions do not improve the aaccuracy of ou
ur model
however they add more noisse to our dataset due to the nnature of our gaame.
Future work w
will involve deeveloping a veersion of the game that reactts in real-time to the playerss’ physiologica
al data in
order to help or challenge them accordiingly. Before its developmeent, we will hhowever focus on models that
t
will
perform betterr on our currennt dataset and oon the real-tim
me data gathereed in our next eexperiment.
Acknowledgeements
We acknowleddge the CRSH
H (Conseil de R
Recherche en S
Sciences Humaaines, more preecisely LEADS project) and NSERC
for funding thhis work.
References
C
A., & Burkett, C. (2010): Self-rregulated learnning with Metaa-Tutor: Advan
ncing the
Azevedo, R., Johnson, A., Chauncey,
New Sciencce of Learnning, pp. 225–247.
2
science of learningg with MettaCognitive tools. In: N
m/chapter/10.10007%2F978-1-4419-5716-0__11
http://linkk.springer.com
Bartels, M., & Marshall, S. P. (2012). Measuring C
Cognitive Worrkload Across Different Eyye Tracking Hardware
H
Plateform
ms. ETRA 2012, Santa Barbaara, CA. http:///dl.acm.org/cittation.cfm?id=
=2168582
Chaffar, S., & Frasson, C. (22006). Predictiing Learners’E
Emotionl Respponse in Intelligent Distance learning Syste
ems. The
19th Inteernational FLA
AIRS Conferennce, AAAI Presss, Melbourne , FL , USA , M
May 15-17.
Conati, C. (2002). Probabiilistic assessm
ment of user's emotions in eeducational gaames. Applied Artificial Inte
elligence
16(7-8), 555-575. http://dx.doi.org/100.1080/0883955102900303900
D'Mello, S., Olney, A., Williams,
W
C., & Hays, P. (2012). Gaze tuutor: A gaze-rreactive intelliigent tutoring system.
mputer Studies 70(5), 377-398. http://dx.doi.org/10.1016//j.ijhcs.2012.01.004
Internatioonal Journal of Human-Com
Ekman, P. (1970). Univeersal facial expressions off emotion. C
California Mental Health Re-search Diigest, 8,
m/wp-content/uuploads/2013/007/Universal-F
Facial-Expresssions-of-Emotiions1.pd
151-158.https://www.ppaulekman.com
f
200

Journal of Eduucation and Traaining Studies

Vol. 44, No. 1; January 2016

Elliot, A. J.,, & Pekrun R.
R (2007), E
Emotion in thhe Hierarchicaal Model of Approach-Avvoidance Achiievement
Motivatioon.EmotioninE
Education, 57--74. http://dx.ddoi.org/10.10166/b978-0123722545-5/50005--8
Ghali, R., Chhaouachi, M., Derbali, L., & Frasson, C
C. (2014). Mootivational Strrategies to Suupport Engage
ement of
Learners in Serioous Games, The 6thh Internationnal ICAAR
RT Conferennce, March 2014.
http://dx..doi.org/10.10993/iwc/iwu0133
Ghali, R., Ouuellet, S., & Frrasson, C. (2015). LewiSpacce: An Educattional Puzzle G
Game Combinned with a Mu
ultimodal
Machine Learning Envvironment. Too appear in KII 2015: the 388th German Coonference on Artificial Intelligence,
Short papper.
Gherguluscu, I., & Munteann, C. H. (20144). A Novel Seensor-Based M
Methodology ffor Learner’s M
Motivation An
nalysis in
Learning.
Interractive
with
Compuuters,
Game-Baased
26(4).
http://iwcc.oxfordjournaals.org/contentt/early/2014/044/14/iwc.iwu013
Gobert, J. D.,, Baker, R. S.., & Wixon, M
M. B. (2015). Operationalizzing and Deteccting Disengaagement within
n Online
Science M
Microworlds. Educational
E
P
Psychologist, 50(1). http://dx..doi.org/10.10880/00461520.22014.999919
Jackson, G. T
T., Dempsey K.
K B., & McN
Namara D. S. (2012). Gam
me based Practtice in a Readding Strategy Tutoring
System: Showdown in iSTART‐ME
E. Computer games, 115-1388. http://dx.doii.org/10.1057/9978113700526
67.0013
Jaques, N., Coonati, C., Harlley, J., & Azevvedo, R. (20144). Predicting A
Affect from G
Gaze Data Duriing Interaction
n with an
Intelligennt Tutoring System. ITS conference 2014. http://www.css.ubc.ca/~conatti/my-papers/IITS-Natasha-2014.pdf.
Johnson, W. L
L., & Wu, S. (2008). Assesssing Aptitudee for Learning with a Seriouus Game for F
Foreign Langu
uage and
Culture. Intelligent Tuutoring Systems. B. Woollf, E. Aïmeurr, R. Nkamboou and S. Laajoie. Springer Berlin
Heidelbeerg, 5091, 520--529. http://linnk.springer.com
m/chapter/10.1007%2F978-33-540-69132-7_55
Lester, J., Sppires, H., Niettfeld, J., Minoogue, J., Mottt, W., & Lobbene, E. (20144). Designingg game-based learning
environm
ments for elem
mentary sciencee education: A narrative-cenntered learningg perspective. Information Sciences,
S
(264), 4-18. http://dx.ddoi.org/10.10166/j.ins.2013.099.005
Lewinski, P., den Uyl, T. M.,
M & Butler, C. (2014). Autoomated facial ccoding: validattion of basic eemotions and facs
f
AUs
in
FacceReader.
J
Journal
of
Neurosciennce.
Psychoology,
and
Economicss,
7(4),
227-236.
2
http://dx..doi.org/10.10337/npe0000028
McNamara, D
D. S., Jackson, G. T., & Grraesser, A. (20010). Intelligennt Tutoring annd Games (ITaaG). Ch3, Gam
ming for
Classroom
m-Based
Learning:
Digital
R
Role:
Playying
as
a
Motivvator
of
Study.
http://ww
ww.igi-global.ccom/chapter/inntelligent-tutorring-games-itagg/42686
McQuiggan, S
S., & Lester, J. (2006). Diaagnosing Self--efficacy in Inntelligent Tutooring Systems:: An Empirica
al Study.
Intelligennt Tutoring Syystems. M. Ikeeda, K. Ashleyy and T.-W. C
Chan, Springerr Berlin Heideelberg. 4053, 565-574.
5
http://linkk.springer.com
m/chapter/10.10007%2F117744303_56
Oliver, P. J., & Srivastavva, S. (1999).. The Big-Fivve Trait Taxoonomy: Histoory, Measurem
ment, and Theoretical
P
et O. P
P. John (Eds.), Handbook of personalityy: Theory annd research (2
2nd ed.).
Perspectiives, L., & Pervin
http://hecckman.uchicaggo.edu/sites/heeckman2013.ucchicago.edu/files/uploads/OE
ECD_Spencerr_2015/John_S
Srivastav
a_1999_B
BIG%20FIVE
E%20TRAIT%
%20TAXONOM
MY.pdf
Pedregosa et aal. (2011). Scikkit-learn: Machhine learning iin Python, JML
LR (12), 2825-2830. http://scikit-learn.org/stable/.
learning.
New
Prensky,
M.
(20011).
Digitall
game
based
ww.amazon.fr/D
Digital-Game--Based-Learninng-Marc-Prensky/dp/15577888634
http://ww

York:

McGrraw-Hill.

Rowe, J., Moott, B., McQuuiggan, S., Roobison, J., Leee, S., & Lesteer J. (2009). C
Crystal island: A narrative-centered
learning environment for eighth graade microbiollogy. Workshoop on Intelligeent Educationnal Games at the 14th
Conferrence
on
Artificial
Intelligence
in
Educaation,
Brighhton,
UK: 11-20.
Internatioonal
http://ww
ww.researchgatte.net/publication/2555767488_CRYSTAL__ISLAND_A__Narrative-Cenntered_Learnin
ng_Envir
onment_for_Eighth_Grrade_Microbioology
Viola, P., & JJones, M. (20001). Rapid object detection using a boosteed cascade of simple featurres. Proceeding
gs of the
IEEE Coomputer Societty Conferencee on Computerr Vision and P
Pattern Recognnition, Kauai, HI, U.S.A., December
8-14. httpps://www.cs.cm
mu.edu/~efross/courses/LBM
MV07/Papers/vviola-cvpr-01.ppdf

This work is licensed under a Creative Coommons Attribution 3.0 Licennse.
201

