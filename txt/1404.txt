Teegi: Tangible EEG Interface
Jérémy Frey, Renaud Gervais, Stéphanie Fleck, Fabien Lotte, Martin Hachet

To cite this version:
Jérémy Frey, Renaud Gervais, Stéphanie Fleck, Fabien Lotte, Martin Hachet. Teegi: Tangible
EEG Interface. UIST-ACM User Interface Software and Technology Symposium, Oct 2014,
Honolulu, United States. ACM, 2014, <10.1145/2642918.2647368>. <hal-01025621>

HAL Id: hal-01025621
https://hal.inria.fr/hal-01025621
Submitted on 3 Dec 2014

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Teegi: Tangible EEG Interface
Jérémy Frey∗
Univ. Bordeaux

Renaud Gervais∗
Inria

jeremy.frey@inria.fr

renaud.gervais@inria.fr stephanie.fleck@univlorraine.fr

∗ Co-first

Stéphanie Fleck
Univ. Lorraine

Fabien Lotte
Inria

Martin Hachet
Inria

fabien.lotte@inria.fr

martin.hachet@inria.fr

authorship, both authors contributed equally to this work.

ABSTRACT

We introduce Teegi, a Tangible ElectroEncephaloGraphy
(EEG) Interface that enables novice users to get to know more
about something as complex as brain signals, in an easy, engaging and informative way. To this end, we have designed
a new system based on a unique combination of spatial augmented reality, tangible interaction and real-time neurotechnologies. With Teegi, a user can visualize and analyze his
or her own brain activity in real-time, on a tangible character
that can be easily manipulated, and with which it is possible
to interact. An explorative study has shown that interacting
with Teegi seems to be easy, motivating, reliable and informative. Overall, this suggests that Teegi is a promising and
relevant training and mediation tool for the general public.
Author Keywords

Figure 1. Teegi (Tangible EEG Interface) is a friendly interactive character that users can manipulate to observe and analyze their own brain
activity in real-time.

Tangible Interaction; EEG; Spatial Augmented Reality;
Learning
ACM Classification Keywords

H.5.1 Multimedia Information Systems: Artificial, augmented, and virtual realities; H.5.2 User Interfaces: Interaction styles; H.1.2 User/Machine Systems: Human information processing; I.2.6 Learning: Knowledge acquisition

where many fantasies are linked to a misunderstanding of the
strengths and weaknesses of such new technologies. No, it is
not possible to read thoughts! But what can be done exactly?
Our motivation is to provide a tool that allows one to better
learn how EEG works, and to better understand the kinds of
brain activity that can be detected in EEG signals. Beyond the
knowledge of the brain that a user can acquire, we believe that
a dedicated tool may help demystify BCI, and consequently,
it may favor the development of such a promising field.

INTRODUCTION

Electroencephalography (EEG) measures the brain activity of
participants under the form of electrical currents, through use
of a set of electrodes connected to amplifiers and placed on
the scalp [17]. This technology is widely used in medicine
for diagnostic purposes. It is also increasingly explored in the
field of Brain-Computer Interfaces (BCI), the goal of which
is to enable a user to send input commands to interactive systems without any physical motor activities, by using brain activity alone [35]. BCI is an emerging research area in HumanComputer Interaction (HCI) that offers new opportunities
for interaction, beyond standard input devices [28]. These
emerging technologies are becoming increasingly more popular. It feeds into fears and dreams in the general public

We followed a multidisciplinary approach, combining
Human-Computer Interaction (Spatial Augmented Reality,
Tangible User Interfaces), Neurotechnologies (EEG, brain
signal processing) and Psychology/Human sciences (Human
Learning and Representations, Scientific Mediation) to design an interactive multimedia system that enables novice
users to get to know more about something as complex as
EEG signals and the brain, in an easy, engaging and informative way. Our final goal is to enhance learning efficiency
and knowledge acquisition by letting users actively and individually manipulate and investigate the concept to be learned
[31], i.e. EEG signals.
This gave birth to Teegi (Tangible EEG Interface), a physical
character that users can manipulate in a natural way to observe and analyze their own brain activity projected in realtime on the character’s head (see Figure 1). Beyond the technical description of Teegi, this paper depicts an explorative

ACM acknowledges that this contribution was authored or co-authored by an employee, contractor or affiliate of the national government. As such, the Government
retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government purposes only.
UIST’14, October 05–08 2014, Honolulu, HI, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3069-5/14/10 ...$15.00.
http://dx.doi.org/10.1145/2642918.2647368

1

study we conducted, which provides an experimental basis
for discussions and future works. Our major contribution for
this paper is the design of the first system to make EEG signals and brain activity easily accessible, interactive and understandable. This work is based on theoretical foundations,
technical developments, and preliminary investigations.

EEG signals collected using wearable EEG devices and visualize them in 3D [16]. This software enables the user to
estimate brain activity sources and connectivity but is still
mainly designed for brain signal and neuroscience experts,
and not so public-friendly. Another recent work, more suited
to lay persons, is the “Portable Brain Scanner” [26]. This system makes use of a consumer-grade EEG device (the Emotiv
EPOC) and a smartphone to provide a cheap and portable solution enabling anyone to visualize the sources of their brain
activity on their smartphone in 3D. Another more attractive
work, which is the most closely related to our Teegi system, is
the “Mind-Mirror” system [15]. This system combines Augmented Reality (AR), 3D Visualization, and EEG to enable
users to visualize their own brain activity in real-time superimposed to their own head, thanks to a semi-transparent
mirror-based AR setup.

NEUROIMAGING AND EEG

EEG signals are small electrical currents (in the µV range)
that can be measured on the surface of the scalp [17]. They
reflect the synchronous activity of millions of neurons from
the brain cortex (i.e., the outer layer of the brain). Compared
to alternative neuroimaging techniques, such as MagnetoEncephaloGraphy or functional Magnetic Resonance Imaging,
EEG is simultaneously cheap, portable and provides good
time resolution. Because of these advantages, EEG has been
used for many years in medicine, e.g., for the diagnosis of
sleep disorders or epilepsy [17]. More recently, with the advance of computer processing performance, it became possible to measure and analyze in real-time the content of these
EEG signals. This paved the way for the rise of BCI which
uses real-time analysis and decoding of EEG signals in order
to identify the mental state of the user and translate it into a
command for an application [35].

This short review of the existing literature about making EEG
accessible to the general public revealed that this is still a
vastly unexplored area. Moreover, these solutions do not take
into account any representation that the general public may
have regarding the brain and EEG signals – many lay people
do not even know what EEG signals are – in order to provide suitable visualizations and interaction devices to better
understand these concepts. Some rare studies have indicated
that misconceptions about brain functions prevail in general
public [7, 10, 25]. These works stress the importance of popular scientific communication and indicate that communication
efforts should be focused on increasing public awareness. It is
important to note that the existing works mentioned above are
mostly centered on visualization, with little or no interaction
possibilities to manipulate and understand the EEG signals in
real-time and in a friendly way. This further deters the general public from understanding brain activity [30]. Therefore,
with the aim to enhance general public awareness, our work
associates technical innovation and user-centered design.

The currently available tools used to visualize and analyze
such signals are tailored for experts with a deep understanding of the brain, EEG principles and EEG signal processing
[17]. Figure 2 (left and center) shows some typical visualizations of EEG signals used by experts, i.e., EEG signal
traces and a 2D topographic map. More complex visualizations have been proposed, such as 3D topographic maps (Figure 2, right), but they require many mouse inputs to be observed from all angles, which make them inconvenient to use
in practice.

INTRODUCING TEEGI
Founding principles

Design choices were made according to pedagogical principles. It has long been recognized that learner-centered education is much more effective than transmission-based education, even in informal situations [33]. According to the constructivist paradigm, people create unique personal meanings
by reflecting on interactive learning experiences. Therefore,
people/learners should investigate and manipulate in order to
become conscious of complex phenomena, change their misconceptions and construct scientific knowledge [31]. In association, meaningful models play an important role in this
type of learning processes [9]. This motivated the design of
an anthropomorphic interface that can be freely manipulated.

Figure 2. (Left) A trace of EEG signals collected from multiple sensors.
2D (center) and 3D (right) topographic maps. (Screenshots from OpenViBE [23]). The first two views are traditionally used by experts.

Although EEG visualizations are intended for experts only,
the general public is often compelled by how the brain works
and how its activity is measured. Anyone wondering about
brain injuries, epilepsy, sleep or learning disorders, aging,
etc. may want to seek further knowledge about how the brain
works. Currently, the public is increasingly exposed to neurotechnologies due to the availability of consumer grade EEG
devices, such as the Emotiv EPOC or the Neurosky MindWave. Consequently, it has become necessary to design tools
and user interfaces which will allow the general public to visualize, understand and interact with EEG signals. For instance, Mullen et al. proposed a software solution to process

Our user-centered interactive media uses Spatial Augmented
Reality (SAR) and tangible interaction. SAR, introduced by
Raskar et al. [22], adds dynamic graphics to real-world surfaces by the means of projected light. Many systems were
designed using projectors to add “painted” surface [22] or to
give the illusion of virtual elements actually being there [34,
2]. A related approach is Tangible User Interface (TUI). TUI
2

and to move it to the filter area. Then, by moving her right
hand, she should see changes in EEG amplitude on the left
hemisphere of Teegi’s head, as illustrated in Figure 4. The
manipulation of Teegi requires a motor activity. Therefore,
when the motor filter is on, manipulating Teegi will obviously
lead to observable changes in brain activity.

is concerned with providing tangible (i.e. physical) representations to digital information and controls [24]. One of
the strengths of tangibles is their situatedness: the interaction takes place in a real-world environment that often hides
most of the technological aspects to expose physical interaction components only. They are particularly well suited for
mediation purposes as they tend to be more inviting compared
to mouse-screen based interfaces [12].
SAR and TUIs are often found together [29, 21]. They are
very complementary in that they both take place in the real
world, in a common canvas. The tangible interaction allows for a hands-on approach by offering different input affordances (as well as physical constraints) to the user while
the SAR technology allows for a flexible and situated way to
give feedback. SAR can also be used as an affordable way
to embed dynamic graphics on a physical surface that would
otherwise require curved displays [4] or rear projection [3].
There are examples of systems that use either tangible or AR
principles to interact or review physiological data. Hinckley
et al. [11] designed a system which used tangible props to do
neurosurgical planning. A small tangible head was used in
conjunction with a plastic plane to select the cutting planes to
be visualized on a screen. Also mentioned above, the “MindMirror” [15] is the work closest to Teegi. However, with
Teegi, the data is not co-localized with the data source. It
provides flexibility and easier visualization as the users can
change viewpoints by tangible interactions instead of rotating their head while keeping their eyes on the mirror. This
“out-of-body” visualization also enables collaboration where
multiple users can explore the data.

Figure 3. Three mini-Teegis can be used to apply high-level EEG filters
to highlight brain processes associated to Motor, Vision and Meditation
activities. To do so, the user simply needs to move the desired mini-Teegi
into a specific zone projected on the table (green circle).

General description

Teegi is a tangible interface that enables users to visualize and
analyze a representation of their own brain activity recorded
via an EEG system in real-time and displayed on a physical
character. After some processing of the raw signals, a dedicated visualization is projected directly on top of the character. This character is tracked, which allows us to co-locate
the projection with the character’s head, at any time. Hence,
the user can easily visualize a realistic modeling of the EEG
signals in any part of the scalp by manipulating the character,
while maintaining a good spatial topology of the observed
data. Teegi was purposely given a child-like appearance, as
well as animated eyes (also projected) that blink at the same
time as the users do, in order to breathe life to the character and enhance attractiveness. Indeed blinking can be easily
detected in electrodes neighboring the eyes.

Figure 4. Examples of the displayed visualizations on Teegi for each of
the provided filters. Once a filter is active, the brain area corresponding
to the selected and processed activity is highlighted in colors while the
remaining EEG signals are displayed in grayscale.

At the end of this paper, we present an explorative study
we conducted to obtain feedback about the main features of
Teegi. However, Teegi is not limited to these first features. In
the next section, we describe additional interaction metaphors
we have explored, and that may benefit more advanced users.
These advanced features were not evaluated during the study.
Advanced features

Three different filters can be applied to the raw data (see the
technical section for details) enabling users to investigate influences of motor motions, visual activities or meditation, on
their brain activity in real-time. To remain consistent with the
tangible philosophy of this project, we decided to control the
filters by way of small tangible characters (mini-Teegis) that
can be moved on a “filter area”, which is highlighted on the
table by a projected halo (see Figure 3). For example, if a
user wants to apply a filter that will allow her to better see
what happens when moving her hand, she just needs to take
the dedicated mini-Teegi, i.e. the one with the colored hands,

Visualizing the raw signal recorded on each electrode of the
EEG is not very informative for the general public. However,
this can be instructive for students who are learning EEG signal processing and analysis. In our approach, we can display
on the table these raw data, as shown in Figure 5 (left). This
creates a visual link between what is recorded with the EEG
system, and the visualization that is provided on Teegi’s head.
This is possible because we know the rough position of the
user, and the exact position of Teegi. When applying a filter,
as described in the previous section, the user can see the effect
3

of his or her action on the signal (see Figure 5, right). Compared to a standard approach where everything takes place on
a screen, we believe that such a spatial and tangible approach
might ease the understanding of the filters’ effect.

scalp). This opens way to mediation activities that are more
advanced all the while keeping the simplicity and ease of use
brought forth by using SAR and tangible interaction.

Figure 5. (Left) The raw EEG readings are displayed going from the
user to the filter area and then rerouted towards Teegi. (Right) When a
mini-Teegi (i.e. a filter) is active, the corresponding filtered signals are
displayed between the filter area and Teegi instead.

Another dimension we explored is the use of tangible actions
to control some parameters of the EEG signal processing. As
an example, we have implemented a technique where the user
can control the amplitude of the visualization color map by
moving a tangible object on the table (figure 6). This could
be useful to reveal tiny fluctuations of EEG signals. With
such interaction techniques, the whole analysis could be conducted without the use of a screen or a mouse, which remains
consistent with the tangible philosophy of the project.

Figure 7. Using an inverse model, the cortical activity and EEG measures are presented together to users.

TECHNICAL DESCRIPTION
EEG

We designed different EEG signal processing pipelines that
each create a specific visualization tailored to identify specific elements in the signal. The details of these pipelines are
transparent to the user. Each pipeline corresponds to a miniTeegi filter. In particular, we set up the following EEG signal
processing pipelines:
1. Wide-band EEG activity: EEG signals were band-pass filtered between 3 Hz and 26 Hz, in order to filter DC drift
and part of the artifacts (e.g., facial muscle activity [8])
that may pollute them. Their power is then computed before being displayed. This corresponds to unspecific brain
signals, hence they were labeled as ”raw” signals.
2. Sensorimotor activity: EEG signals were first band-pass
filtered in the β band (16-24Hz), a brain rhythm highly involved in sensorimotor tasks [20]. Then, they were spatially filtered, i.e., the signals from several neighboring
EEG sensors were combined in order to enhance the signal of interest. In particular, we used and displayed Laplacian spatial filters around electrodes C3, C4 and Cz. This
enabled the users to visualize EEG activity changes due to
movements of the left hand, right hand and feet. Indeed, it
is known that the power of EEG signals in the β rhythm decreases in electrodes C3/Cz/C4 during right hand/feet/left
hand movements respectively, and increases just after the
end of this movement [20].
3. Visual activity: EEG signals were band-pass filtered in the
α band (8-12 Hz), then only electrodes P3, Pz, P4, PO3,
POz, PO4, O1, Oz and O2 (located on the back of the head,
above the neck) were selected and displayed. These electrodes are indeed located over the visual cortex of the brain,
i.e., the brain area in charge of visual information processing. The amplitude of the α rhythm is actually known to
increase while the user is closing his/her eyes and is thus

Figure 6. A moving tangible cursor is controlling the amplitude of the
visualization color map.

Finally, we developed a solution that highlights the relationship between EEG signals and localized cortical sources,
that is where the signals come from inside the brain. Using
sLORETA inverse modeling [19] and Brainstorm to compute
the kernel matrix [27], we obtained a model of the cortex containing 2002 voxels linked to the 32 EEG electrodes we used.
We can then project in real time the activity which arises from
the outer regions of the cortex on an object representing the
brain, alongside with Teegi (Figure 7). Since both Teegi and
the brain proxy are tracked, it becomes possible to manipulate
two synchronized representations of the same brain activity
(the source at the surface of the brain and the measures on the
4

not processing any visual information [17]. To ensure that
the user could perceive this increase after he/she reopened
his/her eyes, the visualization was delayed by 0.5s.
4. Meditation: on a more exploratory note, we used the synchronization between the signals from the anterior and posterior cortex (AFz/Pz), which was measured in a 7-28 Hz
band with instantaneous phase locking value [13]. There
are different outcomes (increase/decrease in synchronization) depending on meditation type. Mindfulness and body
focus practices decrease the synchronization while transcendental practice increases it [14].
EEG signals were acquired with a 32-channels EEG device (made of two g.tec g.USBAmp EEG amplifiers). This
professional-grade system ensured that our prototype had a
good signal-to-noise ratio and accurate electrode location,
avoiding unneeded uncertainties. Signals were processed in
real-time using OpenViBE [23]. For pipelines 1 to 3, the
displayed colors correspond to signal power strength; for
pipeline 4 they correspond to the degree of synchronization.
Spatial Augmented Reality

In order to create an augmented character, we have designed
a tabletop augmentation setup (see Figure 8). Teegi itself is
a 25cm high Trexi DIY toy. The mini-Teegis are also 10cm
high Trexis. The main program handling the whole installation was created with vvvv [1]. The primary projected content (Teegi augmentation and GUI display) is handled with a
single wide lens projector ProjectionDesign F20SX of resolution 1024x768 located over the table in a top-down orientation. The tracking of Teegi is achieved with an OptiTrack
V120:Trio. It runs at 120 FPS with an overall latency of
8.3ms and a precision of 0.8mm. The OptiTrack is located
in the same configuration as the main projector and both devices are calibrated together manually. The tracking data is
sent to vvvv using OptiTrack’s NatNet protocol. Teegi’s eyes
are projected using a second projector (Vivitek Qumi Q2) that
is located on the side of the table.

Figure 8. Diagram of the installation. (A) ProjectionDesign F20SX
projector (B) Sony PSEye web camera (C) OptiTrack V120:Trio (D)
Vivitek Qumi Q2 projector (E) Teegi (F) Program selection zone and
mini-Teegis.

brain. Ten participants (6 males, 4 females, mean age 28.6
(SD=9.7)) took part in this study. Pre-tests confirmed they
were rather naive on the subject. They manipulated the version of Teegi described in the General Description section (no
advanced features). The general procedure was as follows:
1. Pre-tests: The participant answered a first questionnaire assessing his or her representation of the brain. The participant then filled in different forms to measure his or her
previous knowledge; one form per studied brain process
(motor, vision and meditation).
2. Setting-up: The experimenter positioned the EEG cap on
the participant’s head. In parallel, the participant, guided
by the experimenter, was made aware of the four didactic “cards” explaining the different filters i.e., Motor, Vision, Meditation and Raw. Each card was comprised of
an image of the mini-Teegi associated with the filter along
with basic instructions to follow (e.g. the Motor card indicated to the participants to move their hands or feet while
staying relaxed). There were also two cards describing the
two types of visualization participants could face, signal
strength and synchronization. Once the participant was
equipped, a quick calibration phase occurred. While Teegi
was still inactive, participants were asked to close their
eyes for a few seconds, and to move their hands and feet
in order to identify the baseline activity for visualization.
3. Personal Investigation: The participant was asked to freely
manipulate Teegi as well as the filters to be able to answer
the following questions:

The filter selection is done using a Sony PSEye web camera
pointed at the position of the program selection GUI. Each
mini-teegi representing a filter has a fiducial marker attached
to it. The library ARToolkitPlus [32] is used to detect which
marker is currently selected.
The EEG signals are processed by the OpenViBE software
[23] that also generates a grayscale texture of the scalp signals. This texture is then exported to a local shared samba
folder which is then fetched and remapped to an appropriate
color scale in vvvv before being mapped to Teegi’s head. In
addition, the raw EEG signals are sent to vvvv over VRPN
for display purposes (see Figure 5).
EXPLORATIVE STUDY AND DISCUSSIONS
Protocol

We conducted an explorative study where participants had to
manipulate Teegi following a given scenario. The objectives
of this study were to i) evaluate the general usability of the
interface and ii) obtain initial feedback about the relevance of
the approach to help users understand EEG signals and the

• What happens when you move your hands or feet?
• What happens when you close your eyes?
• What happens when you meditate?
5

During the whole study the participant sat comfortably in a
chair. To avoid the occurrence of muscle artifacts that may
pollute the signals, the user was instructed to stay relaxed
and to refrain from making strong head movements.
4. Post-tests: The participant answered the questions above
on dedicated forms, the same that were given at the beginning of step 1. Finally, he or she filled in a user survey
questionnaire based on a 7-point Likert scale.
The whole session lasted approximately 1.5 hours per participant, with 15 to 20 minutes of hands-on time with Teegi.
Each session was video-recorded. Video segments were separately visualized and labeled with the corresponding behavior
(i.e. tangible and visual interactions, emotional expressions,
and investigation strategies) using The Observer XT R 11.5
(Noldus, Info Tech, Wageninen, The Netherlands). After the
session, the experimenter had an informal talk with the participant. He corrected the answers, making sure the participant
was not leaving with false knowledge, and explained in more
detail some aspects of the system (e.g. relationship between
visual filter and attentional states, the various effects of meditation, ...). This phase lasted from 30 min to 1 hour depending
on the participant’s curiosity.
Figure 9. Results of the questionnaire (selected questions). Note that
purple (resp. orange) bars indicate questions measuring Teegi’s qualities
(resp. limitations).

Results and discussions

To better understand the inherent strengths of Teegi towards
learning, we assessed three main aspects of Teegi: its technical reliability, its relevance to ease understanding for nonexperts, and the User eXperience (UX) it provides. This evaluation is based on 1) the results of the questionnaire that are
summarized in Figure 9, 2) the analysis of the video recordings, and 3) the analysis of the forms the participants filled in
to assess their pre and post-knowledge of the brain and EEG.

(SD 13.3) of session duration; Motor filter: 26.0% (8.3); visual filter: 16.9% (5.5); meditation filter: 26.6% (8.7)). Interestingly, the visual activity filter seemed slightly easier to
understand than the other filters. Moreover, video analyses
indicated that the participants did not have difficulty observing the signals on Teegi’s head, as soon as they found the
right location to observe. Overall, participants reported that
they were able to use Teegi without any difficulties.

Technical reliability

Participants unanimously reported that the whole system
worked properly. The quality of the SAR display is valued
by the participants. In particular, they reported that the resolution was appropriate, and they did not report problems of
offset between the display and the physical character. Participants declared that they were not disturbed by occlusion
problems. The mild temporal delay between their action and
their consequences seems not to be an issue.

All participants completed the required tasks. They used instruction cards 5 times per session on average. They reported
that they could focus on the tasks rather than on the mechanisms used to achieve them. This suggests that Teegi is a
rather transparent interface. Regarding learning of brain processes and EEG, participants reported that they believed they
had learned while doing the study. This was confirmed by
the results of the pre- and post-test assessments (see Figure
10). These assessments focused on the recognition and the
understanding of brain activation during Motor activities, Visual activities and Meditation. Understanding was marked as
acquired if 1) the activated areas were correctly localized and
2) the explanations of the brain process were correct. It was
marked as under way if only 1) or 2) was satisfied but not
both; and as not acquired if neither 1) nor 2) were satisfied.
The marks obtained by the participants improved after using
Teegi. Overall, this suggests that Teegi offers many interesting features to ease learning and mediation.

Manipulations of Teegi were numerous and frequent. Teegi
was touched or moved on average 25% of the session’s duration, twice per minute. These manipulations consisted mostly
of rotations, and to a lesser extent of lifting Teegi to enhance
visual perception. Two participants reported difficulties in
grasping Teegi while the remaining 8 were comfortable with
the form of the character. Video analyses did not show difficulties for the manipulation of Teegi. Similarly, applying
filters by manipulating the mini-Teegis seemed easy for the
participants.
Relevance of the interface to ease understanding

The participants reported that they understood the visualization associated with the filters. Video analyses indicated that
they systematically used all filters several times (3 times per
session on average) for a similar duration (Raw filter : 30.4%

All our results indicate that Teegi clearly promotes real-time
tangible interactions, which contributes to enhancing awareness. Constructivism and inquiry-based science education
principles indicate that, to become conscious of complex phe6

projected eyes, could enhance both empathy and implicit selfperception of one’s own brain activity, as provided by our interactive media. The anthropomorphic appearance of Teegi
could explain the motivation and positive UX reported by the
users. All these hypotheses would be the aim of a more extensive UX study.
Regarding visual attention, the participants were apparently
paying attention to Teegi most of the time (83.3%, SD 7.6).
This supports the fact that Teegi mobilized user attention. It
also indicates a cognitive user engagement. Personal investigations were permanent (only 1.9% of inactivity was measured during the session duration; SD=1.7). Behavior analyses indicate that participants made predictions, hypotheses
and tested them by conducting experiments. Numerous trial
and error strategies were frequently used. This clearly indicates personal active control of the task and inquiry processes.
Overall, Teegi stimulates investigations and encourages persistence in task completion.

Figure 10. Marks obtained by the participants during the pre- and posttest assessments. See text for details.

nomena and construct scientific knowledge, people/learners
have to experiment by interacting with and physically manipulating the content [30]. This is particularly true for brain
activity that is difficult to understand because it cannot be
sensed [6], contrary to other activities (e.g. respiratory) that
are perceived through sensory-motor mechanisms. Hence,
brain activities need to be conceptualized, and the success of
learning processes strongly depends on the interface. Teegi,
which has been largely promoted by the participants, seems
to fulfill this function.

CONCLUSIONS

In this paper, we presented Teegi, a tangible interface that
makes EEG understandable to non-expert users. Our main
contribution is the interface itself, which is built from both
theoretical foundations, notably from human learning and scientific mediation and technical developments, including spatial augmented reality, tangible interaction and real-time neurotechnologies. We also demonstrated that this interface was
well accepted by a first pool of users. In the future, we plan
to make a more in-depth investigation into how well users
are able to learn about EEG and brain activity with Teegi. To
this end, we will conduct dedicated experiments with students
and/or visitors in scientific museums. We would also like to
precisely evaluate how Teegi benefits learning compared to
standard approaches. For more advanced users, ad-hoc tangible filter creation could prove to be of great interest, adding
flexibility to the overall system. Finally, it is known that BCI
requires the user to learn to control his/her own brain activity to input computer commands [35], which is a long and
tedious task. We expect Teegi to be a motivating and informative way to support this training in the future.

User eXperience

The general experience with Teegi was rated as pleasant, attractive and stimulating, and participants did not feel stressed
or oppressed. Overall, participants reported that they liked
interacting with Teegi. The emotion expression analyses confirmed those statements. They showed that on average participants expressed curiosity and questioning about Teegi feedback during almost 20% (20.1% SD=9.1) of the manipulation
duration. Other emotion expressions observed for all participants were joy and pleasure (e.g. smile, laugh, joyful verbal
expression. . . ). They occurred during almost 10% (9.8% SD=
6.7) of the interaction duration with Teegi. Surprise emotions
were observed but less frequently. Interestingly, boredom,
weariness expressions occurred rarely (only for 2 users) and
only at the end of the manipulation time. We did not observe
any occurrence of exasperation or irritation. These results
suggest a high level of acceptance for Teegi. This is a fundamental requirement for a tool aiming at improving access to
knowledge.

REFERENCES

1. vvvv. http://vvvv.org.
2. Benko, H., Jota, R., and Wilson, A. Miragetable:
freehand interaction on a projected augmented reality
tabletop. In CHI ’12, ACM (2012), 199–208.

Behavior observations indicated that the majority of participants spoke with Teegi and used morphological zones specific
to human interactions while manipulating it. For example,
they held its hands and held it up by the waist as one would
do with a child. Some users spoke in the first person when
they observed changes on the character’s scalp for example
“so, when I move my hands, I light up on the sides”; many
said aloud that Teegi was their own image, for example “so,
Teegi is me!”. This identification suggests that an activation
of associations between the perceived character’s personality and self-perception may have occurred [18]. It is known
that identification can be associated with increasing loss of
self-awareness, and its temporary replacement with elements
of the perceived character’s personality [5]. Therefore a human shaped, child-like character, made lifelike by animated

3. Benko, H., Wilson, A. D., and Balakrishnan, R. Sphere:
multi-touch interactions on a spherical display. In UIST
’08, ACM (2008), 77–86.
4. Brockmeyer, E., Poupyrev, I., and Hudson, S.
PAPILLON: Designing Curved Display Surfaces with
Printed Optics. In UIST ’13, ACM (2013), 457–462.
5. Cohen, J. Defining Identification: A Theoretical Look at
the Identification of Audiences With Media Characters.
Mass Communication and Society 4, 3 (2001), 245–264.
6. Damasio, A. R. Descartes’ error: emotion, reason, and
the human brain. 1994.
7

21. Piper, B., Ratti, C., and Ishii, H. Illuminating clay: a 3-D
tangible interface for landscape analysis. In CHI ’02,
ACM (2002), 355–362.

7. Dekker, S., Lee, N. C., Howard-Jones, P., and Jolles, J.
Neuromyths in education: Prevalence and predictors of
misconceptions among teachers. Front. Psychol. 3
(2012).

22. Raskar, R., Welch, G., Low, K.-L., and Deepak, B.
Shader Lamps: Animating Real Objects With
Image-Based Illumination. In Rendering Techniques
2001, S. Gortler and K. Myszkowski, Eds.,
Eurographics. Springer Vienna, 2001, 89–102.

8. Fatourechi, M., Bashashati, A., Ward, R., and Birch, G.
EMG and EOG artifacts in brain computer interface
systems: A survey. Clin Neurophysiol 118, 3 (2007),
480–494.
9. Fleck, S., and Simon, G. An Augmented Reality
Environment for Astronomy Learning in Elementary
Grades: An Exploratory Study. In IHM ’13 (2013), 9.

23. Renard, Y., Lotte, F., Gibert, G., Congedo, M., Maby, E.,
Delannoy, V., Bertrand, O., and Lécuyer, A. OpenViBE:
An Open-Source Software Platform to Design, Test and
Use Brain-Computer Interfaces in Real and Virtual
Environments. Presence-Teleop Virt 19, 1 (2010), 35–53.

10. Herculano-Houzel, S. Do you know your brain? A
survey on public neuroscience literacy at the closing of
the decade of the brain. The Neuroscientist 8, 2 (2002),
98–110.

24. Shaer, O. Tangible User Interfaces: Past, Present, and
Future Directions. Foundations and Trends in
Human-Computer Interaction 3, 1-2 (2009), 1–137.

11. Hinckley, K., Pausch, R., Goble, J. C., and Kassell, N. F.
Passive real-world interface props for neurosurgical
visualization. In CHI ’94, ACM (1994), 452–458.

25. Simons, D. J., and Chabris, C. F. What people believe
about how memory works: A representative survey of
the US population. PloS one 6, 8 (2011), e22757.

12. Horn, M. S., Solovey, E. T., Crouser, R. J., and Jacob,
R. J. Comparing the use of tangible and graphical
programming languages for informal science education.
In CHI ’09, ACM (2009), 975–984.

26. Stopczynski, A., Stahlhut, C., Larsen, J. E., Petersen,
M. K., and Hansen, L. K. The Smartphone Brain
Scanner: A Portable Real-Time Neuroimaging System.
PloS one 9, 2 (2014), e86733.

13. Lachaux, J.-P., Rodriguez, E., Le Van Quyen, M., Lutz,
A., Martinerie, J., and Varela, F. J. Studying single-trials
of phase synchronous activity in the brain. Int. J.
Bifurcation Chaos 10, 10 (oct 2000), 2429–2439.

27. Tadel, F., Baillet, S., Mosher, J. C., Pantazis, D., and
Leahy, R. M. Brainstorm: a user-friendly application for
MEG/EEG analysis. Comput Intell Neurosci 2011 (Jan.
2011), 879716.

14. Lehmann, D., Faber, P. L., Tei, S., Pascual-Marqui,
R. D., Milz, P., and Kochi, K. Reduced functional
connectivity between cortical sources in five meditation
traditions detected with lagged coherence using EEG
tomography. NeuroImage 60, 2 (apr 2012), 1574–86.

28. Tan, D., and Nijholt, A. Brain-Computer Interaction:
Applying our Minds to Human-Computer Interaction.
Springer-Verlag: London., 2010.

15. Mercier-Ganady, J., Lotte, F., Loup-escande, E.,
Marchal, M., and Lécuyer, A. The Mind-Mirror: See
Your Brain in Action in Your Head Using EEG and
Augmented Reality. In VR, IEEE (2014).

29. Underkoffler, J., and Ishii, H. Urp: a luminous-tangible
workbench for urban planning and design. In CHI ’99,
ACM (1999), 386–393.
30. Vosniadou, S. Knowledge Acquisition and Conceptual
Change. Applied Psychology 41, 4 (1992), 347–357.

16. Mullen, T., Kothe, C., Chi, Y. M., Ojeda, A., Kerth, T.,
Makeig, S., Cauwenberghs, G., and Tzyy-Ping, J.
Real-time modeling and 3D visualization of source
dynamics and connectivity using wearable EEG. In
IEEE Eng Med Biol Soc, vol. 2013 (2013), 2184–2187.

31. Vosniadou, S., Ioannides, C., Dimitrakopoulou, A., and
Papademetriou, E. Designing learning environments to
promote conceptual change in science. Learn Instr, 11
(2001), 381–419.

17. Niedermeyer, E., and da Silva, F. L.
Electroencephalography: basic principles, clinical
applications, and related fields. Lippincott Williams &
Wilkins, 2005.

32. Wagner, D., and Schmalstieg, D. Artoolkitplus for pose
tracking on mobile devices. In CVWW ’07 (2007),
139–146.

18. Paiva, A., Dias, J., Sobral, D., Aylett, R., Woods, S.,
Hall, L., and Zoll, C. Learning by Feeling: Evoking
Empathy with Synthetic Characters. Applied Artificial
Intelligence 19, 3-4 (2005), 235–266.

33. Wellington, J. Formal and informal learning in science:
The role of the interactive science centres. Physics
Education 25, 5 (1990), 247.
34. Wilson, A., Benko, H., Izadi, S., and Hilliges, O.
Steerable augmented reality with the beamatron. In
UIST ’12, ACM (2012), 413–422.

19. Pascual-Marqui, R. Standardized low resolution brain
electromagnetic tomography (sLORETA): technical
details. Methods Find Exp Clin Pharmacol 24D (2002),
5–12.
20. Pfurtscheller, G., and da Silva, F. H. L. Event-related
EEG/MEG synchronization and desynchronization:
basic principles. Clin Neurophysiol 110, 11 (1999),
1842–1857.

35. Wolpaw, J. R., and Wolpaw, E. W. BCI: Principles and
Practice. Oxford University Press, 2012.

8

