UNIVERSIT√Ä DEGLI STUDI DI MILANO
SCUOLA DI DOTTORATO
INFORMATICA
DIPARTIMENTO
DI INFORMATICA ‚ÄúGIOVANNI DEGLI ANTONI‚Äù
TESI DI DOTTORATO DI RICERCA

ARTIFICIAL INTELLIGENCE
APPLIED TO THE STUDY
OF CONSCIOUS PERCEPTIVE STATES
Marialessia Musumeci
TUTOR
Prof.ssa Rita Pizzi
COORDINATORE DEL DOTTORATO
Prof. Paolo Boldi
A.A.2018-2019

To my husband

INDEX

ABSTRACT
1
THE CONCEPT OF CONSCIOUSNESS IN NEUROSCIENCE
1.1 INTRODUCTION
1.2 INTEGRATED INFORMATION THEORY
1.3 THESIS OBJECTIVE
2
BRAIN AS DYNAMICAL SYSTEM
2.1 SELF-ORGANIZATION, COMPLEX SYSTEMS AND CHAOS
2.2 COMPLEXITY AND NON-LINEARITY
2.3 NON-LINEARITY AND DYNAMICAL SYSTEMS
2.3.1 Non-Linear Analytical Methods
2.3.2 Fractal Dimension and Correlation Dimension
2.4 ARTIFICIAL NEURAL NETWORKS AS DYNAMICAL SYSTEMS
2.4.1 Stability and Regions of Attraction in Neural Models
2.4.2 Cohen-Grossberg THEOREM
2.4.3 Neural Models of Dynamical Systems Processing:
Spatiotemporal Patterns in Artificial Neural Networks
2.4.4 Neural Models of Dynamical Systems Processing:
Recurrent Neural Networks
2.4.5 Self-Organizing Networks
2.4.6 The ITSOM Architecture
2.4.7 Dynamical Analysis of ITSOM
2.4.8 Non-Linear Analysis of Cortical Signals and Functional
Binding of Perceptions
3
THE EXPERIMENTAL PHASE
3.1 EMOTIV EPOC +
3.2 EMOTIV EPOC + SOFTWARE: TEST BENCH
3.3 EMOTIV EPOC + 3D BRAIN ACTIVITY MAP
3.4 EPOC-SIMULINK CONNECTION
3.5 3D EXCELVAN GLASSES
3.6 SELECTED ELECTRODES

3
5
5
8
12
14
14
16
17
19
20
24
24
26
31
33
37
40
44
46
51
51
52
55
56
59
60

3.7 VIDEOS
3.7.1 First Colors Test
3.7.2 Second Colors test
3.8 EXPERIMENTAL PROCEDURE
4
SIGNAL PROCESSING
4.1 EMOTIVE EPOC +: DATA PRE-PROCESSING
4.2 PROCESSING
4.3 ITSOM APPLICATION
4.3.1 ITSOM results
4.3.2 First Colors Test results
4.3.3 Second Colors Test results
4.4 CORRESPONDENCE BETWEEN STIMULI AND
SHAPE OF ATTRACTORS
4.5 FINAL RESULTS
5
EVALUATION OF INTEGRATED INFORMATION
5.1 INTEGRATED INFORMATION CALCULUS
6
CONCLUSION
REFERENCES
INDEX OF FIGURES
INDEX OF TABLES

65
65
67
69
71
71
72
74
79
79
81
84
88
90
94
99
103
108
109

2

ABSTRACT

My PhD research consists of the processing of signals from a 14-electrode EEG system,
connected to immersive glasses that allow for a realistic visual experience and for the
investigation of the brain network in order to identify signal features corresponding to
different perceptive and cognitive stimuli.
The aim of the research is to implement a procedure that identifies correspondences
among EEG signals and chaotic attractors.
The chaotic attractors can be defined as a trajectory of a dynamical system, contained in a
defined volume of phase space. A dynamical system can have chaotic behavior, i.e. an
organized (but not periodic) behavior sensitive to the initial conditions. EEG signals can
be considered dynamical systems.
In this work a custom Artificial Neural Network (ITSOM) processes individual signals or
many signals simultaneously.
The sequence of the ITSOM winning nodes tends to repeat itself creating a time series of
chaotic attractors.
The ITSOM attributes similar codes to attractors emerging from similar brain states,
perceptions and emotions.
These attractors are isomorphic to the attractors in which the corresponding dynamical
system (the signal time series) is evolving and univocally characterize the input element
that produces them.
3

If the attractors are chaotic, this means that the signals are individually self-organized or,
by examining more signals together, there is a form of coherence among signals.
The ITSOM network memorizes the time series of the winning nodes.
The cumulative scores for each input are normalized following the z standardized variable
distribution.
Attractors are labeled with a binary code that univocally identifies them, and the
flexibility of the Artificial Neural Network allows attributing the same codes to similar
dynamical events.
During the experiment, the subject is looking at the screen while different shades of
colors, yellow, red and blue are displayed. Each stimulation lasts five seconds, between
stimuli there is a black screen, used to reset the previous color stimuli.
The collected results show, as forecast, many correspondences among binary codes
coming from similar stimuli. The thesis provides a detailed description of these results.

4

1 THE CONCEPT OF CONSCIOUSNESS IN NEUROSCIENCE

1.1 INTRODUCTION

In the last decade, neurosciences have started to consider the concept of consciousness as
a research subject, the definition and analysis of which constitutes one of the most
fascinating and difficult challenges in modern science.
Various authors have attempted to describe the general properties of consciousness.
Among them, Nagel [1], James [2], Greenfield [3], Hofstadter [4], Baars [5] , Searle [6] ,
Chalmers [7], Dennet [8], Metzinger [9] , Baars [10].
Specifically, in 1948, the noted neurophysiologist, Charles S. Sherrington, in an article
titled ‚ÄúThe Integrative Action of the Nervous System‚Äù [11] wrote:
‚ÄúEvery day of wakefulness is a stage dominated, for better or for worse, be it comedy, farce, or
tragedy, by a personal drama, the "I". And so it will be until the curtain comes down. And this ‚ÄúI‚Äù
is a unit. Its continuity in time, is only interrupted by sleep, its inalienable ‚Äúinteriority,‚Äù its
stability of perspective, the private, subjective nature of its experience, combine to guarantee it a
unique existence. Although characterized by multiple aspects, it has an internal cohesion.‚Äù

In summary, Sherrington highlights two aspects of the ‚ÄúEgo‚Äù by analyzing three
fundamental points:
1. Subjectivity: the state of the ego intended as the degree/level of personal
impression;
2. Integration: the concept of conscious experience and its connections affirming
"this ego is a unit". The problem of the feasibility in establishing a consciousness
5

3. measurement unit is not new: in philosophy at the times of Kant it was defined as
the problem of the "transcendental unity of perception".

Today,

in

neurophysiology the "binding problem" is discussed, i.e. the problem of how it is
possible to "integrate" the activity of different and distant neuronal groups, under
the assumption that their activity corresponds to different aspects of our conscious
experience.
4. Informativity: the conscious experience is defined as the amount of information
generated by the brain over a period of time, which unit of measurement is
evaluated.

The examination of these three fundamental aspects of the human psyche has been
interpreted from time to time, often in very different terms, by philosophers,
psychologists of various backgrounds, psychiatrists interested in psychopathology, and
finally by neurobiologists, who generally have tried to relate these to activity in certain
areas of the brain. Depending on the branch of Neuroscience considered, the concept of
consciousness assumes different meanings.
Some most neurobiological theories about consciousness assume that cortical activity as
well as that of the thalamus provide a large part of the content of consciousness. The
majority of these theories stems from the premise that the neural system that represents
consciousness is a functional complex of neuronal cells, but it is not yet clear what
neurons, cortical regions, or connections are involved.
Over the last fifteen years, Giulio Tononi has formulated a theoretical proposal to define
consciousness and to provide an explanation on both why the thalamo-cortical system
(Fig.1-1), unlike other structures such as the cerebellum, is more involved in conscious
6

experience, and why the different functional regime that involves this structure is able to
determine the presence or absence of consciousness in different states of wakefulness and
sleep. This is the Integrated Information Theory. The theory is founded on three
fundamental principles:
1. Consciousness is born out of the rapid integration of a great quantity of
information inside a dynamical nucleus of strongly integrated elements;
2. The reciprocal interconnections among the regions of the thalamocortical system
mediate this rapid integration;
3. The onset of the ‚Äúprimary consciousness‚Äù, i.e., the construction of our multi-mode
perceptual world, depends on the integration of sensory elaborations with the
memory of previously gained experiences.
This theory highlights the importance of a complex integration of thalamocortical
subsystems that appear to be functionally separated, yet highly interactive.

Figure 1-1 Composition of the thalamocortical system. These structures transmit information booth as inputs and
output from the external environment, integrating their signals. Source: Anastasi, Motta, Balboni ‚ÄùTrattato di
Anatomia Umana‚Äù, Edi-Ermes, ed. IV, 2006.

7

1.2

INTEGRATED INFORMATION THEORY

The Integrated Information Theory (IIT) [12] [13] [14] [15] [16] aims at explaining what
consciousness is, by describing the requirements of the physical systems that make it
possible and by measuring its quantity and quality thereof. Instead of starting from how
the brain is structured or from the functions it performs, IIT reverses the question, going
from phenomenology to physics: it begins by identifying the essential properties of
consciousness itself to derive the necessary and sufficient requirements for why a
physical substrate makes subjective experience possible. In summary, the Integrated
Information Theory deals with the fundamental problem of consciousness: what are the
necessary and sufficient conditions in which a physical system has the experience of
consciousness?
The theory starts from two observations concerning the fundamental properties of the
experience of consciousness: first of all, consciousness is highly informative; in fact,
whenever we enter a particular conscious state (for example, when we see a dark blue
sky), we exclude a number of possible alternative states (seeing red, yellow, darkness,
rain, being in a room, being in a cinema and seeing a particular frame of one of all
possible films, etc.). Secondly, consciousness is integrated; in fact, every conscious
experience is absolutely unitary, we could never, for example, be separately conscious of
the left or right visual field 1. This fundamental statement can be derived from those two
premises: "a physical system is conscious to the extent that it is able to integrate
information". That is, the substrate of consciousness must be a system composed of many
1

Actually this statement may be just a Tononi‚Äôs assumption, as it is contradicted by the so-called
‚Äúbinocular rivalry‚Äù phenomenon: see e.g. Baer N., and Baer W. ‚ÄúInterest-Attention Feedback
System for Separating Cognitive Awareness in to Different Left and Right Sensor Display‚Äù Patent
Application, 13/455,134, Filed 4/25/2012.
8

functionally different elements (information) that are, however, closely linked to each
other, forming an indivisible whole (integration). This is anything but trivial: it is a very
delicate balance between diversity and unity.
This interpretation helps to solve many paradoxes concerning the brain-consciousness
relationship. For example, it explains why an injury to the thalamo-cortical system can
result in coma while the complete removal of the cerebellum (a very complicated
structure with even more neurons) has no effect on consciousness. While the former is
made up of elements functionally very different from each other but closely linked by
short and long-distance nerve fibers, the latter has an essentially modular structure, not
integrated. Similarly, this theory explains why consciousness is reduced during slowwave sleep, even if the brain stays very active.
There are five essential properties of consciousness of every conceivable experience:
1. Its experience exists intrinsically (for the subject, not for an external observer);
2. It is structured (it is composed of various contents and their relationships);
3. It is informative (each experience is specific that which it is, therefore different
from countless others);
4. It is integrated, in the sense discussed below;
5. It is well defined in the subjective experience.
These five essential properties of phenomenology are converted by IIT into the five
physical requirements that must be satisfied by any physical substrate of consciousness,
where "physical" means, very generally, any substrate that has causal power - that is, it
can be directly or indirectly manipulated or observed - from the brain to neurons to
elemental particles.
9

Tononi intuitively identifies a fundamental difference between a non-conscious system
like a photodiode and a conscious system like Galileo, a human being. To describe this
difference in scrupulous, mathematical and quantitative terms, Tononi refers to the
mathematical information theory proposed by Claude Shannon and Warren Weaver [17].
According to the definitions given by the two two authors, the concept of information is
based on that of entropy (H), i.e. the measure of the amount of "uncertainty" present in an
aleatory signal. The concept of entropy, and therefore of uncertainty, emerges clearly
using some representative examples taken from the theory of probability.
If entropy corresponds to uncertainty, information is classically defined as a measure of
"reduction of uncertainty": the greater the number of alternative events excluded from the
realization of the observed event, the greater the information brought by the event in
question. In mathematical terms, the bit measurement of the amount of information
associated with an event corresponds to the negative logarithm to the base two of the
probability (P) of the event in question, or:

ùêº (ùë• ) = ‚àíùëôùëúùëî2 (ùëÉ(ùë• ))

Another way of calculating the amount of information for each state, in fact, is to
consider the number of possible states of a system, its repertoire of possible states (R),
and to calculate the logarithm to the base two of that number. Given that each state has
the same probability of being realized, the number of possible states will be equal to the
reciprocal of the probability of realization of each single state.

10

The key to calculating the first fundamental difference in the information present in a
system is suggested by analyzing not only the "observed" responses produced in output,
but the "possible" responses.
Considering that the photodiode has a "binary" sensor capable of determining the
presence or absence of light, it will have a repertoire of only two possible states, each
corresponding to 1 bit of information. On the contrary, a human being like Galileo, being
able to discriminate a very large number of different states, will have a vast repertoire of
possible states and the information brought by each will be extensive.
If Galileo and the photodiode are subjected to a very limited number of stimuli, the
simple alternation between light and dark, the responses of the two systems may seem
informative. To see the difference, therefore, it is necessary to establish as a condition
that the repertoire of possible states of a system is calculated by disrupting the input
peripheral devices of the system in all possible ways.
It must be emphasized that IIT is the antithesis of reductionism: even the fundamental
unit of integrated information, Œ¶, is a measure of irreducibility, which indicates if and
how much the whole cannot be reduced to its parts.
One of the consequences of the theory is that consciousness is measurable in principle:
the higher the value of integrated information Œ¶, the higher the concept of consciousness.
Theory can therefore be tested with facts. Thus a "consciousness meter", as
primitive/simple/basic as it may be, has been developed which uses a transcranial
magnetic stimulator and a large number of electrodes to read the integration of
information from the brain responses.

11

In principle, IIT can serve to establish if and to what extent animals other than us are
conscious, to clarify why consciousness has evolved and to explain why certain regions of
the cerebral cortex are essential for consciousness and others are not.
Finally, the theory has important implications for artificial intelligence, which is hastily
making new machines capable of equating and even exceeding our cognitive abilities.
The reason why a computer with a traditional Von Neumann architecture can never be
conscious is in direct agreement with IIT, as its sequential structure prevents to reach a
high integrated information value.
Consciousness is measured by considering how much actual information a set of elements
can integrate, or how many states are available to a single integrated system, in terms of
bits. Once one knows how to identify the integrated entities, one can go on to measure the
complexity, that is, to see how much integrated information there is inside. At the end of
the process you get a number associated with a particular set of elements.
The hypothesis is that complexity is distributed on a continuum, which is at a minimum in
sleep without dreams and its maximum when wide awake.

1.3

THESIS OBJECTIVE

The measurement of Œ¶ has so far been carried out with computer simulation.
In this thesis, a first experimental method of measurement of IIT is proposed [18]. This
objective is achieved by developing a coding method of states of consciousness that
makes use of an Artificial Neural Network (ANN) to identify perceptive and cognitive
events within EEG signals. The events are marked by chaotic attractors present in the
12

signals.
The ANN encodes them by assigning them with a binary code, attributing similar codes
to similar events and distinct codes to distinct events.
Finally, the attractors identified in this way make it possible to calculate the quantity of –§
for each event.

13

2 BRAIN AS DYNAMICAL SYSTEM
2.1 SELF-ORGANIZATION, COMPLEX SYSTEMS AND CHAOS

The theory of complex systems aims at analyzing and forecasting their behavior of the
interaction among many elementary components, using mathematical and other formal
tools. It also studies self-organization [19], i.e. the organization that emerges
spontaneously from complex systems that, in the presence of suitable conditions, react to
external environment changes reorganizing themselves [20] so as to exhibit novel
properties [21].
A classic example is a fluid heated from the bottom. In the presence of appropriate
boundary conditions, the convective motions of the molecules are arranged according to
the so-called B√©nard columns, that are vertical honeycomb formations. This unexpected
cooperation between molecules is established whereas the system would simply be
expected to increase in molecular disorder. The system reacted to the external
environment modifications by reorganizing in such a way as to exhibit an innovative
property.
Self-organization can be defined as a space-time structure that is not imposed from the
outside but emerges spontaneously from the evolution of the system as a function of its
dynamics [22]. The emerging organization is observable at a different space-time scale,
much greater than the molecular one.
14

The development of mathematical models for such systems [23] shows that the equations
that hold them are generally extremely sensitive to the initial conditions, so that extremely
small fluctuations give rise to completely different dynamical stories (the famous
Lorentz‚Äôs ‚Äúbutterfly effect‚Äù [24]). This indeterminacy in real terms (but not in principle)
is not avoidable, since for any numerical system a not infinite degree of precision must be
fixed, and any degree, even the highest possible, will produce different dynamical stories.
This represents the so-called "deterministic chaos": the system has a behavior altogether
regular but irregular in detail, thus it is impossible to predict its future behavior.
We define chaos the unpredictable behavior of deterministic dynamical systems because
of their sensitivity to initial conditions [25].
The behavior of a deterministic dynamical system is predictable once the initial
conditions are known. But there are cases in which, depending on the precision in
measuring the initial conditions, the motion of the system behaves very differently. More
precisely, a set S exhibits sensitivity to the initial values if there is a neighborhood œÅ
such as for each Œµ > 0 and for every x in S, there exists a y such that

|x-y|<Œµ

and

| xn - yn | > œÅ

for some

n> 0.

Then there is a fixed distance œÅ such that, no matter how precisely an initial state is
specified, there are neighboring states that eventually move away more than the distance
œÅ. This is what happens in chaotic systems.
A typical example of self-organization is present in all biological systems [26] and in
their more evolved expression, intelligent life.
In addition, computational models are becoming more and more advanced, being able to
simulate quite complex real systems.
15

A promising attempt to reproduce advanced functionalities by means of the collective
behavior of simple elements is given, as specified below, by the Artificial Neural
Networks paradigm: multiple interconnected elements exchange information on the basis
of a series of input from the outside, and realize a form of functional organization that is
not directly derivable from the algorithm imposed from the outside, but emerges from the
complexity of the system.

2.2 COMPLEXITY AND NON-LINEARITY

In the traditional approach the complex systems are processed analytically, i.e. are
reduced to a linear combination of elements. A classic linear relationship is the Hook's
law ( F= - kx , where x is the spring length and F the applied force) which regulates the
elastic force. But when the elasticity is lost (e.g. straining the spring or the rubber band
too much) the graph ceases to be linear. The system is not linear anymore, and in specific
conditions it shows a sudden change of behavior: the rubber band breaks.
In nature many systems are linear or approximated to linearity (e.g. the electromagnetic
wave equations), and this allowed the modeling of many natural phenomena. But for
many physical systems linearity is not sustainable, and their modeling becomes extremely
complex: as we will see in the following, almost all dynamical systems exhibit a chaotic
behavior, i.e. they are not inherently nondeterministic, but in fact unpredictable [27] [28].
The processing of strongly time-varying and not strictly linear space-time patterns, such
as those coming from the acquisition of real-world data, is an issue of growing
importance, and its complexity involves necessarily
the use and development of advanced mathematical tools.
The typical adaptivity of the Artificial Neural Networks and their generalization ability
16

seems to indicate them as a valid choice for the analysis of these systems. We will
examine them in more detail in the following.

2.3 NON-LINEARITY AND DYNAMICAL SYSTEMS

We call linear the functions which behave in such a way that

f (ax ÔÄ´ by ) ÔÄΩ af ( x) ÔÄ´ bf ( y )

where this equality is not held, the function is called non-linear, and everything becomes
mathematically more difficult.
For example if

f ( x) ÔÄΩ 0

and

f ( ax ÔÄ´ by ) is no more equal to zero for any

f ( y) ÔÄΩ 0
and

(superposition principle: more

solutions exist for each variable) and the solution must be sought with special methods.
A function that models real world is hardly linear, but is often approximated to a linear
function. Non-linear systems exhibit complex effects that are not deducible with linear
methods. This is particularly evident for dynamical systems [29] [30]. A system is called
dynamical system when it expresses the variability of a state X (or a point in a vector
space) in time:

dX
ÔÄΩ F ( x, t )
dt

F : W ÔÉå R n ÔÇÆ R n differentiable

(1)

The solution of the system is the set of trajectories as a function of the initial conditions.
A dynamic system is completely defined by a phase space or state space, whose
17

coordinates describe it at all times, and by a rule that specifies the future trend of all the
state variables.
Dynamic systems are said deterministic if there is only one solution for each state,
stochastic if there are several solutions following a certain probability distribution (e.g.
the toss of a coin).
The phase space is the collection of all possible states of a dynamic system. It can be
finite (as in the case of the coin, two states) or infinite (if the variables are real numbers).
For example, a cellular automaton is a dynamic system with discrete time, discrete
geometric space and discrete state space s(i, j), where i are spatial coordinates, j is the
time, and the update rule is

s (i, j + 1) = f (s) .

A simple example is the case of the pendulum, in which the phase space is continuous,
two-dimensional and its coordinates are angle and speed.
If we include time as a coordinate of the phase space we represent the dynamic system
with the above-mentioned differential equation (1), where (X, t) is the phase space.
Mathematically, a dynamic system is described by an initial value problem. The trajectory
in the phase space traced by a solution of an initial value problem is called trajectory of
the dynamic system.
We define constant trajectory a constant solution

x(t ) ÔÄΩ x(0)

of (1), i.e. a vector x(0) for which each component of the right side of (1) is zero.
18

A constant trajectory is said stable if the following conditions are met:
a) there must be a positive number Œµ such that each trajectory beginning within Œµ of
must asymptotically approach x(0) .
b) for each positive number Œµ a positive number Œ¥(Œµ) must exist such that a trajectory is
guaranteed to stay within Œµ of x(0) simply requiring it to start within Œ¥(Œµ) of x(0).
c) the set of all points that can be initial states of trajectories that asymptotically approach
a stable trajectory is said region of attraction of the stable trajectory.
A limit cycle, or cyclic attractor, is a closed curve in the n-dimensional space with the
following properties:
a) no constant trajectory is contained in the limit cycle
b) any trajectory that begins in a point of the limit cycle must lie within the limit cycle
also later on
c) for each positive number Œµ there must be a positive number Œ¥(Œµ) such that a trajectory is
guaranteed to stay within Œµ of the limit cycle simply requiring it to begin within Œ¥(Œµ) of
the limit cycle.
In summary, if some trajectories converge in some point, the set of initial states of these
generated trajectories is said region of attraction of the point. A region of attraction is
ultimately a set of points in the state space delimiting a finite diameter region such that
each trajectory enters and never gets out.

2.3.1 Non-Linear Analytical Methods

A very common type of self-organization, which in nature is established also outside the
life phenomena (e.g. involving meteorological and astronomical phenomena, fluid
19

dynamics, etc.), as mentioned above, is the deterministic chaos. The long-term behavior
of the chaotic systems follows structured patterns detectable by displaying the system
trajectories in the state space. These trajectories exhibit a spatial structure in which they
are confined in a strange attractor (i.e. they exhibit some regularity but never repeat
themselves exactly) [31]. A strange attractor is geometrically a fractal i.e. a structure with
a non-integer dimension.

2.3.2 Fractal Dimension and Correlation Dimension

Define dimension D of an object the exponent which connects its extent b with the linear
distance r :

b ÔÇµ rD

The extent b can refer to the linear distance, area, volume, or the amount of information in
1
2
bits. For a line b ÔÇµ r (and in fact a line has dimension 1), for a plan b ÔÇµ r , etc. Taking

the logarithms we obtain.

log b
r ÔÇÆ0 log r

D ÔÄΩ lim

It is possible to have non-integer dimension objects, the so-called fractals [32], [33].
Their important feature is to be self-similar, i.e. they do not possess a characteristic scale.
For example, a branch is a fractal object whose dimension ranges between 1 and 2. It is
shown that chaotic attractors have a fractal (or Hausdorff) dimension > 2.
20

It has been shown for example that the fractal dimension of eyes-closed EEG (about 2) is
lower than the open-eyes EEG dimension [34]. As we will see in detail below, according
to W. Freeman [35], [36], [37] a chaotic brain activity prepares for the perception of a
particular stimulus, and its trajectories end up within a periodic (limit cycle) or chaotic
basin of attraction. Even time series may exhibit characteristics of stochasticity or chaotic
organization [38].
To assess the dimension of a series, a procedure called delay-time embedding is used. If a
time series is long enough, the trajectory of the state space generated by it is
geometrically equivalent to the attractor of the system that generated the original series.
Grassberger and Procaccia [39] have developed a method, often applied to physiological
data, which allows to determine the so-called D2 correlation dimension (which
corresponds to a lower limit for the fractal dimension).
We replace each observation in the original signal X(t) with the vector:

y (i) ÔÄΩ x(i), x(i ÔÄ´ d ), x(i ÔÄ´ 2d ),..., x(i ÔÄ´ (m ÔÄ≠ 1)d )

obtaining as a result a series of vectors of m coordinates in an m-dimensional space:

Y ÔÄΩ y (1), y (2),..., y( N ÔÄ≠ (m ÔÄ≠ 1)d ))

n=2d+1.

where N is the length of the original series and d the so-called lag or delay time, i.e. the
number of points between the components of each reconstructed state vector.
21

It can be shown that the reconstructed state vectors are topologically invariant
transformations of the original state vectors, and that the set of state vectors (points in the
m-dimensional space) formed by Y in the reconstructed space has the same dimension of
the attractor of the system.
It also demonstrates (Taken‚Äôs Theorem) that there is a mathematical relationship between
the embedding dimension n of the series and the dimension of the attractor of the
corresponding dynamic system:
Now, the dimension D2 is defined as

D 2 ÔÄΩ lim
r ÔÇÆ0

log C (r )
log r

where the extension of the series is given by the correlation integral C(r).
The correlation integral is calculated as the average number of state vectors that stay
within a distance r from each other. In other words, C(r) calculates the average number of
points that are on the corresponding reconstructed attractor. If the attractor is a fractal, for
a certain range of r (the range in which fractals are perfectly self-similar) the logarithm of
this average will have a linear relationship with the logarithm of r.
In this region the slope of the curve measures the correlation dimension D2. The
correlation dimension D2 gives the measure of the complexity of the system attractor
and, in the way shown above, is connected to the correlation integral, which instead
measures the extension of the attractor.
The graph of the correlation dimension is expressed as a function of the embedding
dimension. Ideally, the graph should converge asymptotically to the real correlation
dimension.
22

In a time series the concept of self-similarity is used in a distributional sense: if viewed at
a different scale, the object distribution remains unchanged.
In such a case a long-range dependency occurs, i.e. the values at each instant are
correlated to the values of all the successive instants.
A self-similar time series has the property that when aggregated into a shorter series
(where each point is the sum of multiple original points) it maintains the same
autocorrelation function

r ÔÄ® k ÔÄ© ÔÄΩ E[( X t ÔÄ≠ ÔÅ≠ )( X t ÔÄ´ k ÔÄ≠ ÔÅ≠ )]

both in the series X = (Xt : t = 0,1,2, ...) and in the contracted series X

(m)

= (Xk

(m)

:k=

1,2,3, ...), aggregated in blocks of size m. So, the series is distributionally self-similar,
because the distribution of the aggregate series is the same (except for a scale variation)
as the original.
As a result, the self-similar processes show long-range dependency, i.e. have an
autocorrelation function,

r(k) ÔÅæ k ÔÄ≠ÔÅ¢ for k ÔÇÆÔÇ• 0 ÔÄº ÔÅ¢ ÔÄº 1

i.e. the function decays hyperbolically.

23

2.4 ARTIFICIAL NEURAL NETWORKS AS DYNAMICAL SYSTEMS

2.4.1 Stability and Regions of Attraction in Neural Models

An Artificial Neural Network (ANN) can be seen as a dynamic system which gives
account for the dynamics of n neurons.
Each neuron is mathematically defined by its state x(i) and its function g= g(xi) (gain)
differentiable everywhere and non-decrescent. A typical gain function is the logistic
function

g ÔÄ® x ÔÄ© ÔÄΩ ÔÄ®1 ÔÄ´ e

ÔÄ©

ÔÄ≠ x ÔÄ≠1

This feature provides values between 0 and 1. But it is often useful to use a transfer
function symmetrical with respect to zero, so to keep any symmetry of the input values.
Thus, the hyperbolic tangent function (values between -1 and +1) is used, or the function

F ÔÄ® PÔÄ© ÔÄΩ

A ÔÄ® ekp ‚Äì1ÔÄ©

ÔÄ®e

kp

ÔÄ´ 1ÔÄ©

with positive constants A and k.
The rate of change of each xi is determined by a function dependent on xi and on the
outputs gi(xi). In general, we can express this change with the system of differential
equations

24

dxi
ÔÄΩ ÔÄ≠ ki xi ÔÄ´ pi ( g ( x))
dt

(2)

where ki is a positive constant, and each pi is an in general polynomial function of n
variables g1(x(t), g2(x(t), ..., gn (x(t)), which behave well enough to make sure that the
trajectories for the system of equations exist and are unique.
By trajectory, we mean a series of points in an n-dimensional space that depart from some
initial state (at time zero) in the n-space to a final state. The task of the Artificial Neural
Network is to generate such a set of points up to the final state, which constitutes the
output of the network.
The levels of activity of n neurons are represented by a point in the n-dimensional space
[40]. Therefore, we build an n-dimensional dynamic system which solutions are
trajectories representing constant attractors (stable equilibrium) or cyclic attractors (limit
cycles).
We say that the purpose of the Artificial Neural Network is to generate trajectories in the
n-dimensional space that are asymptotically approaching some of the constant attractor
trajectories.
In the additive neural models (as the Multilayer Perceptron, see below) each pi is a linear
function of the components of g:

(3)

where Tij are real constants forming an n √ó n matrix.
However, recently higher order Artificial Neural Networks have emerged as more
25

efficient. In this kind of networks, each pi is a polynomial function of the components of
g: typically of the form

where each exponent ei is 0 or 1.
For linear networks of the type (3) the Cohen-Grossberg theorem [41] ensures the
existence of stable points, i.e. points such that

.

2.4.2 Cohen-Grossberg THEOREM

Every dynamical system of the form

s.t.
1) The matrix wij is symmetrical and each wij ‚â•0
2) The function aj(x) is continuous for x‚â•0 and aj(x)>0 for x>0
3) The function bj(x) is continuous and does not tend to infinity for any open interval for
x> 0
4) The function Sij(x)

is differentiable and S‚Äôij(x)>0 for x‚â•0
26

5) bi(x)-WiSi<0 for xÔÇÆÔÇ• has an at least countable set of stable points P such that

.
If the network status at time 0 is such that xi (0)>0 , then the ANN will converge usually
at some stable point P (i.e. such that

),

and at least a countable set of such points will exist.
Although these conditions are restrictive, they match those supported by many heteroand auto-associative ANNs (see below the Hopfield network, with fully interconnected
nodes and symmetrical weights).
The memories are set in the attractors, and the theorem guarantees their existence,
although there are many spurious attractors (Fig. 2-1).
To any state of a network an energy Lyapounov function can be associated that allows
you to determine certain properties of the trajectories. A Lyapounov function L is a
function:

,

for each

, where T is the transition function operated by the network.

Thus, L is monotone non-increasing along each trajectory. It follows that the equilibrium
points of the system correspond to the minimum points of L. For networks with a square
connection matrix, the L function is called energy function and is chosen as

27

where one can easily see that it is monotone non-increasing and

anytime, i.e. the

system is globally stable.
This is the case for the Hopfield network [31], an obvious example of how an ANN is a
dynamic system that can tend to a series of stable attractors.
It is a fully connected network with symmetrical weights, with bipolar input (+/- 1 or
0/1).
The inputs are simultaneously applied to all nodes, and the weights are set according to
the law

wij=ÔÉ•xixj for iÔÇπj
wij=0

for i=j

In the learning cycle each output of a neuron is a new input for the same neuron. The
calculation of the new value is established by the function

if
(threshold possibly equal to zero)
if
if

We can see an input pattern as a point in the state space that, while the network iterates,
moves gradually toward minima, which represent stable states of the network. The last
values of the weights represent the output of the network. The solution occurs when the
point moves to the lowest region of the basin of attraction.
In fact, as for symmetric matrices with diagonal equal to zero
28

i.e. always .

if

then

if

then

.

After a number of iterations the network will stabilize in a state of minimum energy. Each
minimum corresponds to a pattern stored in the network. An unknown pattern constitutes
a point on this hyperplane, which gradually moves toward a minimum. There may be socalled metastable states, i.e. minimum points that don‚Äôt have a corresponding stored
pattern (spurious attractors).

Figure 2-1 Typical trajectories in a two dimensional space with two memories and a limit cycle model

More generally the following theorem holds:
THEOREM:
Each ANN model of type (2) has a finite region of attraction.
29

Learning
Once a particular dynamic model and its attractors have been identified, a learning
algorithm is to be established that varies the locations of fixed points to encode
information. Therefore, a condition sufficient for the existence of such an algorithm is the
existence of isolated stable attractors in the system, i.e. of fixed points.
The weight matrix is to be adjusted in such a way as, given an initial state x0=x(t0), a
fixed point x‚àû=x(t‚àû) corresponds to a given input, and the fixed point has components that
have a desired set of values Di in the output units.
A typical method, used in the backpropagation networks [30], is to minimize a function E
that measures the distance between the desired fixed point (attractor) and the current fixed
point:

where

and Qi is a function which value is 1 or 0 according to whether the i-th unit belongs or not
to the output subset of the network units.
Then the learning algorithm will move the fixed points so as to satisfy on the output units
the equation
.

A typical way to do this is to let the system evolve in the weight space along the
30

trajectories antiparallel to the gradient of E:

where œÑ is a numeric constant that defines the temporal scale with which the weights are
changing. œÑ must be small, so that x could always be substantially constant, i.e.
.
When on the output layer the error is computed between current output and desired
output, this is propagated backwards to the other layers, in such a way as to adjust
weights of any single node.
This algorithm, that is called gradient descent, is used by the backpropagation networks;
it is not the only possible algorithm but is no doubt the easiest and most effective equation
for the minimization of E [42] [43].
It can be shown that, if the initial network is stable, the gradient descent dynamics does
not change the network stability.
This allows to state the reliability of the backpropagation algorithm, that yields the
necessary robustness to the deviations generated by the noise present in real data.

2.4.3 Neural Models of Dynamical Systems Processing: Spatiotemporal
Patterns in Artificial Neural Networks.

ANNs have been initially applied to problems regarding spatial or instantaneous patterns,
but the evolution of technology has made it necessary to apply them also to
31

spatiotemporal pattern. By spatiotemporal pattern we mean a function x(t) that associates
at any time t a point in the n-dimensional input space:

x ÔÄ® t ÔÄ© :{t0 , t1} ÔÇÆ Rn

In three dimensions, it is possible to represent a spatiotemporal pattern as a trajectory in
the input space parameterized as a function of time. The task of the ANN will be to
implement a time-variant transformation, that associates an output function y(t) to the
function x(t) for each time t.
Several methods have been proposed in the past to allow the ANNs to process the
spatiotemporal patterns, i.e. to generate parameterized attractor trajectories over time.
These methods can be classified mainly in the following variants [44]:
- Creation of a spatial representation of temporal data
- Setting of time-delays in neurons or connections
- Use of neurons with activations that add up the inputs over time
- Combinations of the above methods.
The earliest strategy was to convert the output data into a sequence of data. When a new
set of inputs is received, the previous data are deleted and so on. The network preserves
the memory of the past only in the intermediate layers.
Then the so-called time-delay networks were studied, in which the information at an
instant of time is moved to the right in a chain of nodes, while the new information is
added to the left. The number of nodes determines the number of time intervals on which
information is sampled.
An architecture that leads to stable states without time-delay can produce oscillations or a
chaotic behavior (with cyclic or chaotic attractors) once the delay is introduced. Instead, if
32

the delay is transmitted in the connections, the information remains in a certain state for a
period, then a connection is triggered that brings it to another state and so on. It can be
proved that such networks, which are obviously equipped with long or short-term
memory, are able to reproduce different types of temporal sequences.
Another method is to change the neurons in such a way that they are able to add up data
that arrive through time, allowing a gradual decay of the older information.
If neurons have recurrent connections, the feedback acts creating hysteresis in each
neuron, thus a memory of the information that persists beyond the stimulus.
ANNs have also been proposed that accept input information coded in the form of
frequencies, as actually occurs in the natural sensors.
These networks were used to drive robotic actuators, with good results in the hardware
implementation. The simplest of the above described ANNs are networks not equipped
with memory, with static architecture, which does not include any actual management of
the time variable [44].

2.4.4 Neural Models of Dynamical Systems Processing: Recurrent Neural
Networks

The so-called dynamical (in the strict sense) networks have proved to be more efficient in
processing time-dependent inputs. Their architecture [45] is characterized by a feedback
system called state feedback (Fig. 2-2), achieved through appropriate connections
between the nodes. It consists of the fact that a node receives as afferent signals both the
inputs and all the outputs of the other nodes, including its own. An internal state of the
network becomes definable, which all the nodes in the network with their current outputs
33

contribute to. These networks can be described by differential equations of the type where
ui(t) is the internal state of the i-th unit, ti is the time constant of the i-th unit, wij are the
connection weights, Ii(t) is the input of the i-th unit and g(uj (t)) is the output of the i-th
unit.

Figure 2-2 Recurrent network with state feedback

Pineda [46] shows that this system of equations is reduced to the system (2) through a
simple linear transformation.
Recurrent neural networks are ultimately nothing more than networks that possess
complex connections between the nodes, in contrast to the feedforward networks which
bind the connections to a single direction (from input towards the output) [47].
This model includes a large class of ANNs.
As mentioned, Recurrent neural networks give better performances than feedforward
networks in the treatment of spatiotemporal pattern and in general in the modeling of real
dynamic systems. For such systems theorems exist ( [48] [49]) showing that time-finite
trajectories of a given n-dimensional dynamical system are approximated by the internal
states of the output units of a Recurrent network with n units of output, N hidden nodes
34

and appropriate initial states.
In this way the theorem of existence of attractors in the case of Recurrent neural networks
is guaranteed by the same theorem (4).
The multilayer perceptron (MLP) is suitable to be turned into a Recurrent neural network
according to various possible schemes, the more classic of which is due to K. Narendra
[50] and is visible in Fig. 2-3:

Figure 2-3 Narendra Architetture

The input layer is connected to a tapped delay line, where the sequence of data to be
processed is flowing. In another delay line flow the output observations. The only output
u(k) is function of the n input observations and of the m previous outputs. The n+m-ple of
inputs is interpretable as a point in the input space.
Following the method introduced by Williams and improved by Pineda [51], [52], [46]
the following model is obtained.
The node equation is
35

u(k+1) = f (ÔÅìwijuj(k) + vi(k)) 0 ÔÇ£ k ÔÇ£ n

The first layer output is

z j ÔÄΩ u j ÔÄ®k ÔÄ©

0ÔÇ£ jÔÇ£ N

z j ÔÄΩ v j ÔÄ®k ÔÄ©

N ÔÄ´1 ÔÇ£ j ÔÇ£ L

where zj is the output of the first layer and vj the current input.
The current output is

u 'i ÔÄ® k ÔÄ´ 1ÔÄ© ÔÄΩ f ÔÄ® Ii ÔÄ® k ÔÄ© ÔÄ©
where

I i ÔÄ® k ÔÄ© ÔÄΩ ÔÉ• wij z j ÔÄ® k ÔÄ© ÔÄ´ z0

ÔÄ® z0 bias ÔÄ©

j

and the node equation is

ui ÔÄ® k ÔÄ´ 1ÔÄ© ÔÄΩ f ÔÄ® Ii ÔÄ® k ÔÄ© ÔÄ©

where f is sigmoid function. The learning algorithm is similar to that of the static MLP.
Despite Recurrent networks are an advanced treatment method for spatiotemporal
patterns [47], high variability in the data limits the performance of this ANN model in
the use in real time due to the difficulty of finding an exhaustive training set and/or to the
36

length of the learning process [53].
Applications suffer from severe limitations in computational speed or alternately in the
ability to adapt to input fluctuations, being difficult to arrive at a positive compromise
between the slow online learning process and the poor off-line learning performances.
This issue is intrinsic to the supervised learning method.

2.4.5 Self-Organizing Networks

An almost forced alternative to the limits of this architecture seems to be constituted by
the unsupervised ANNs [54] [55], whose most classical and still effective explication
remains currently the Self-Organizing Map (SOM) of T. Kohonen.
The SOM was developed in the 80s by T. Kohonen [56] based on previous studies of
neurophysiology. In fact the SOM mechanism was written taking into account the
neurophysiological mapping of sensory stimuli on the neocortex, where similar inputs are
mapped to nearby locations of the cortex in an orderly and topology-conservative fashion.
The structure of a Kohonen network consists of a layer of N elements, said competitive
layer. Each of these receives n signals x1, ...,xn that originate from an input layer of n
elements, whose connections have weight wij (Fig. 2-4).
If the competitive layer has a matrix topology, neurons are connected to each other in a
square, hexagonal or rhomboid pattern. If they are vector-based, neurons are simply
connected together to form a chain.
To estimate the input intensity Ii of each of the Kohonen layer elements the process is as
follows:

37

I i ÔÄΩ D ÔÄ® wi , x ÔÄ©

ÔÄ®

wi ÔÄΩ wi 1 , ..., win

ÔÄ©

T

xi ÔÄΩ ÔÄ® x1 , ..., xn ÔÄ©

T

where D (u , x ) is some distance function, e.g. the Euclidean one.
At this point a competition is put in place to assess which element has the smaller
intensity input (i.e .which wi is the nearest to x).

Figure 2-4 Kohonen Self organizing Map

In this architecture, each element receives excitatory stimuli from the adjacent elements
(the so-called neighborhood).
The existence of the neighborhood is useful not to polarize the network on a few winning
neurons.
In this way only the elements with distance below a certain value are activated, or in
restrictive cases only the unit with minimum distance is activated. At this point the
learning phase takes place, according to the so-called "Winner Take All‚Äù law (WTA).
38

The training data consist of a sequence of input vectors x. The Kohonen layer then
decides the winner neuron on the basis of the minimum distance. Now the weights are
modified according to the law

winew ÔÄΩ wiold ÔÄ´ ÔÅ° ( x ÔÄ≠ wiold ) zi

where 0 ÔÄº ÔÅ° ÔÄº 1 slowly decreases over time with the law

ÔÅ°(t) = ÔÅ°[1 - t/ÔÅ§]

where ÔÅ§ is a suitable constant. Being zi ‚â† 0 only for the winning neuron, the weights of the
winning neurons rotate more and more towards the closest vectors, up to ideally overlap
with them (Fig. 2-5).

Figure 2-5 Rotation of the weight vectors

In this way the SOM performs a vector quantization, that is a mapping from a space with
many dimensions to a space with a smaller number of dimensions, preserving the initial
39

topology.
In other words a Nearest Neighbor (NN) form of clustering is carried out, in which each
element of the competitive layer represents the class of the input elements.
The NN method classifies a pattern according to the smallest value obtained among all
the distances from a set of reference patterns. This method is useful for separating classes
representable by segments of hyperplanes.
For this reason, the SOM classifies correctly pattern topologically well distributed, but
shows difficulties in the case of non-linear distributions.
Moreover the importance of the initial weight configuration appears evident, as it must be
the most similar to the input topology.

2.4.6 The ITSOM Architecture

Various are, however, the reasons which in turn limit the SOM performances in the case
of strictly non-linear and time-varying input. The first reason is that if the non-linearity of
the input topology is too accentuated, the competitive layer is not capable to disentangle
itself enough on the form of that topology.
The second reason concerns the difficulty of ensuring convergence (due to the lack of
ability to establish a network error for each epoch). The third reason is the low output
cardinality, limited to number of competitive layer neurons.
Another problem of the SOM, typical of any clustering algorithm, and the lack of output
explication. Once the classification output is obtained, the user must extrapolate the
significance with an ad-hoc procedure, which in real-time applications can further
penalize the computational load.
40

Figure 2-6 Series of the winning neurons in 2-dimensional state space - x axis and y axis
indicate the weight order e values

A proven successful solution was found observing the time series the SOM winning
neurons epoch after epoch (Fig. 2-6). It can be shown in fact that this series forms
attractors that hold through epochs and that identify univocally the input pattern that
generated them. On the basis of this evidence the ITSOM (Inductive Tracing SelfOrganizing Map) model was developed, whose architecture is described below.
The time sequence of the SOM winning neurons tends to repeat creating chaotic attractors
or precise limit cycles that uniquely characterize the input that produced them: in fact, the
learning rule implies that the winning weight represents an approximation of the input.
At every epoch the new winning weight, along with the weight that won in the previous
epoch, constitutes a second order approximation of the input value, and so on.
So it is possible to derive the input value by comparing the characteristic configurations
of each input with a set of reference configurations, whose value is known.
In this way a real process of induction is realized, because once a vector quantization
many-to-few from the input layer on the weight layer is carried out, a few-to-many step is
41

operated from reference configurations to the whole input (Fig. 2-7).

Figure 2-7 ITSOM Architecture

This form of induction is much finer than that obtainable from the only final winning
neurons of the a SOM network, because the choice among a set of competitive layer
neurons is too limited to provide a meaningful classification.
Instead the possible ITSOM outputs are 2n, where n is the number of neurons of the
competitive layer, that make it possible to finely discriminate the input features.
It should be emphasized that the ITSOM does not need to be brought to convergence,
because the winning neurons configurations reach the necessary stability within a few
tens of epochs.
It was verified that for best results the network should not polarize on too few neurons but
even not disperse throughout the layer.
The best suited algorithm to recognize the configurations created by the network is based
42

on the z-score method.
The cumulative scores for each input are normalized according to the distribution of the
standardized variable z given by

z ÔÄΩ

ÔÄ®x

ÔÄ≠ ÔÅ≠ÔÄ©

ÔÅ≥

where x is the input, ÔÅ≠ is the average of the scores on the neurons of the competitive layer
and ÔÅ≥ is the standard deviation.
Once set a threshold 0 ÔÄº ÔÅ¥ ÔÇ£ 1 , which therefore constitutes one of the parameters of this
type of network, we put

z ÔÄΩ 1
z ÔÄΩ 0

for z ÔÄæ ÔÅ¥
for z ÔÇ£ ÔÅ¥

In this way, each configuration of winning neurons is represented by a binary number
formed by as many ones and zeros as many the output layer neurons.
Then it is immediate to use these binary numbers as templates of the input patterns.
Both SOM and other ANNs base their learning process on the cyclic repetition of the
input stimulus. Even in the brain there is evidence of reverberating circuits that strengthen
the input information on the cortical map.
However it seems unlikely that these loops can be repeated thousands of times in search
of a fixed target, also because it is difficult to support the hypothesis that the brain
recognizes the last activated neuron as the only information carrier.
It appears more reasonable that the reverberation activities run out spontaneously with the
43

exhaustion of the electrical firing process, and that the cortical maps is formed by a
constellation of activated neurons, the so-called mnestic traces, which in the following
will be used to recover information.
For this reason the ITSOM mechanism may appear more physiologically justified.
On the other hand the fact that learning can be both supervised and unsupervised seems
confirmed by the everyday experience and by several studies [57] [58] [59] [60] [61]
[62].
But ITSOM can also be used in a supervised fashion, as it can learn from a set of
examples and the obtained z-scores can be used to recognized new patterns [63] [64].

2.4.7 Dynamical Analysis of ITSOM

The SOM can be expressed as a non-linear dynamic model expressed by the differential
equation [65] [66].

dxi
ÔÄΩ I i ÔÄ≠ ÔÅ≠ ( xi )
dt

where the output variable xi can be matched to the average firing rate of the neuron i, Ii is
the combined effect of all inputs to the neuron i, and ÔÅ≠(xi) the sum of all the non-linear
losses of the firing process.
As mentioned above, the SOM architecture was studied by T. Kohonen following his
neurophysiological studies, observing the WTA function in the cortex [67].
B. Ermentrout [68] studied a cortical model in which the WTA process has the dual role
44

of selecting the most important stimulus and strengthening the patterns after the
disappearance of the stimulus.
The author shows that every time a neuron is active for a certain time and then stops
firing, the network oscillates between different states, as "ponies on a merry-go-round".
The author explains that the limit cycles that are created are the effect of the bifurcation
solutions of system.

dxi
ÔÄΩ ÔÄ≠ÔÅ≠ x j ÔÄ´ F ÔÄ® x j , u ÔÄ® t ÔÄ© ;ÔÅ° ÔÄ©
dt

j ÔÄΩ 1, ..., N

for N activated neurons xj , where F(x, y; ÔÅ°) is a function of two variables parameterized
by ÔÅ° and such that

F (ÔÉó)
ÔÄæ 0 and
dx

F (ÔÉó)
ÔÄº0,
dy

and u(t) is the inhibitory feedback of the form

ÔÉ¶
ÔÉ∂
u ÔÄ® t ÔÄ© ÔÄΩ G ÔÉß ÔÉ• xk ÔÉ∑
ÔÉ® k
ÔÉ∏

where G is monotonically increasing.
The overall activity x1(t) + .... + xj (t) is shown to lie almost on a closed trajectory, that
means that the total excitatory network activity remains almost constant.

45

2.4.8 Non-Linear Analysis of Cortical Signals and Functional Binding of
Perceptions

An application of the non-linear analysis methods has been tested in the study of the socalled binding problem, i.e. the problem of understanding the origin of the perceptual
unity of consciousness in the multiplicity of sensory stimuli.
Many neurophysiologists [69] [70] [71] [70] [72] [73] [74] [75] have proposed that such
unity can be related to the self-organization of gamma waves (~ 40 Hz) emitted by the
cortical neurons, which in many studies show to synchronize under sensory stimuli
among distant sites, and may therefore create a functional binding.
It was proposed that the oscillation activity at high frequency in the cortex may be linked
to the functional binding related to high-level cognitive functions such as memory and
learning.
Global coherent patterns of neuronal activity are considered by influent neuroscientists as
the main neural correlate of conscious experience [36], [37].
The ability to simultaneously record the activity of distant cortex sites through
microelectrodes led to the possibility to analyze the mechanism by which the activity of a
collection of neurons can be coordinated in a unique pattern.
It was proposed that neurons in the sensory cortex interact extensively and that the action
potentials evoked by stimuli lead to the emergence of a self-organized pattern of activity
as a cortical response to the stimulus [69].
In order to evaluate the possible correlations in the neural signals the above described
ITSOM network model was used, to highlight the presence of limit cycles or chaotic
attractors [76].
Electrophysiological signals were obtained from the brains of guinea pig isolated
46

artificially [70]. It was seen that the gamma activity can be induced in the median
entorhinal cortex (ERC) of guinea pigs which is administered carbachol (50-100 mM),
simulating the attentional activity in the presence of a sensory stimulus.
The gamma activity is recorded simultaneously at different points (up to 20) separated by
about 1mm in the median ERC [71] (Fig. 2-8)..

Figure 2-8 Entorhinal median cortex signals before and after carbachol admistration

Several files derived from 4 different monitoring sites in the entorhinal cortex were
recorded before, during and after the administration of carbachol, simulation of an
attentional stimulation.
The signals were considered simultaneously on all recording sites to assess their
correlation.
The same records were used as input for the ITSOM network, and the time series of the
winning neurons was processed with a MATLAB/SIMULINK procedure.
The procedure allowed to highlight the presence of limit cycles or chaotic attractors,
displaying their trajectory in the phase space.
Under control conditions (before the activation of the fast oscillations), the graphs show
47

some organization on the single record, but patterns with random structure or poorly
organized appear in case of signals processed simultaneously from multiple sites.
However, after the induction of oscillatory activity through the application of carbachol,
more chaotic patterns appear, with similar but never identical values, and strongly
symmetrical shapes (Fig. 2-9).

Figure 2-9 State space attractors before and after carbachol administration

In order to quantitatively evaluate the attractors, Hurst parameter, correlation dimension
and Recurrence Quantitative Analysis [77] have been used.
The Hurst parameter, constantly under the value of 0.4 before carbachol, grows sharply
after carbachol and exceeded the threshold of 0.5, often reaching 0.8. This indicates that
the signals become organized during the stimulus and keep the organization for a time
after the stimulus.
The correlation dimension does not appear to be a significant parameter because it keeps
constant in the range 2.6-3.2 (using 10 as the embedding dimension value) before and
after the stimulus: this value seems to be a feature of the type of signal.
It should be noted that the size> 2 shows a generic chaotic behavior of the series.
On the other hand the measurement of determinism of the embedded series, evaluated
with the Recurrent Quantification Analysis, confirms the same increase after the stimulus
48

shown by the Hurst parameter, jumping up to over 90% and keeping this very high value
for a time.
The analysis of the original time series with linear methods tested on distant sites
confirms an increase in values after the stimulus but is maintained lower than 0.4 in all
tests. The non-linear analysis on the single record or two records carried out with the
calculus of correlation dimension, Hurst parameter and Recurrence Quantification
Analysis essentially confirms the ITSOM results.
In some cases sharp differences of the parameter values have been detected whose
neurophysiological meaning is not known and should be investigated more closely.
In general, we can conclude that the ITSOM network identifies self-organizing structures
more often than linear numerical analysis. This may suggest a finer sensitivity of ANNs,
although the possibility of false positives cannot be ruled out.
On the other hand, the values of the Hurst parameter derived from the ITSOM are often
higher than the corresponding values derived from the original series.
It should also be pointed out that, unlike non-linear analysis on the original series, the
analysis carried out with the ANN made it possible to simultaneously analyze all the
recording sites, testing their possible synchronicity.
It is also possible, once an organized pattern is found, to identify it by its z-score and to
recognize the same attractor every time the set of signals generates one.
In conclusion, the existence of a non-linear coherence (in the form of chaotic attractors) in
rapid oscillations induced on guinea pig cortex is confirmed, suggesting a possible
functional binding of chaotic nature between distant regions of the entorhinal cortex. The
ITSOM method can test the coherence of records simultaneously from all sites. It is also
possible to deepen the analysis of the meaning of these patterns through the possibility to
compare similar attractors in time.
49

W. Freeman researches ( [35] and subsequent work) have proposed, through a study with
microelectrodes implanted on the cortex of rabbits and recorded during the experimental
release of smells, that cortical neurons interact extensively highlighting chaotic
spatiotemporal patterns, repetitive in correspondence of a specific smell and different in
response to different stimuli.
The ITSOM ANN non-linear analysis confirms the hypothesis that the coordinated 40 Hz
activity of cortical neurons may clarify the origin of the sensory "binding" that we all
perceive. It is also possible to deepen the analysis of the meaning of these patterns
through the possibility to compare similar attractors in time.

50

3

THE EXPERIMENTAL PHASE

The goal of this work is to process signals in order to detect and quantify their
information (and in some way their consciousness) content. For this purpose we carried
out an experimental phase devoted to obtain recorded digital EEG signals from human
subjects.

3.1 EMOTIV EPOC +

The instrument that has been used for recording EEG signals is EMOTIV EPOC +. The
signals amplitudes are recorded during the administration of two videos: the first consists
of primary colors with different shades, the second experiment with colors and images of
emotional and sensorial appeal.
In this project we processed signals from 14 electrodes of the wireless EEG system [78]
(Fig. 3-1). The EMOTIV EPOC + offers a headset with 14 electrodes plus a reference, a
single set of electrode felts, and a USB receiver for recording data on a PC has a
frequency of sampling equal to 2048 Hz with a resolution of 14 Bits, with a notch set
between the 50 and the 60 Hz. The electrodes provided are at international 10-20
locations: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4. There is a fixed
reference electrode at P3 (Emotiv labels for the CMS or ‚Äúcommon mode sense‚Äù) and a
51

‚Äúdriven right leg‚Äù (DRL) at P4. The CMS is the actual electrical reference for the EEG
recordings, the DRL provides a feedback noise cancellation system and is not a reference
in the EEG sense. The EMOTIV EPOC + uses saline felt electrodes. The electrodes are
gold-plated disks, and a round felt, wetted with saline, is placed in between this disk and
the scalp.

Figure 3-1 The EMOTIV EPOC +

The EEG signals received from the headset are transferred to a computer through a
wireless USB dongle. These properties along with it being lightweight make the EPOC
extremely portable and easy to use [78].

3.2 EMOTIV EPOC + SOFTWARE: TEST BENCH

The test bench is composed by the following tabs:
EEG: The function of this panel is to display contact quality feedback for the EPOC
Neuroheadset‚Äôs sensors and guidance to the user the EPOC Neuroheadset correctly. It is
52

most important for the user to test the contact quality before proceeding to the other
EPOC Control Panel tabs. Poor contact quality will result in poor Emotiv detection
results, although the EPOC will continue to perform moderately well with a small number
of missing or lower quality sensors (Fig.3-2).
Each circle represents one sensor and its approximate location when wearing the SDK
headset. The color of the sensor circle is a representation of the contact quality. To
achieve the best possible contact quality, all of the sensors should show as green.

Black: No signal (Not Acceptable)
Red: Very poor signal (Not Acceptable)
Orange: Poor signal
Yellow: Fair signal
All Green: Ideal signal
Green + Some Yellows: Acceptable
Green + Black and/or Orange/Red: Not
Acceptable (EPOC may continue to function
with several black or red sensors however
many detections will be disabled and others
will be less reliable).

Figure 3-2 Display of the electrodes contact quality

Another graph displays the signals from the EEG channels (Fig. 3-3).
It shows brainwave signals of 14 channels (AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8,
FC6, F4,F8, AF4). In this mode, the users can select to display one or different channels.

53

Figure 3-3 EEG Channels

FFT: The FFT Suite shows EEG graph in the frequency domain and the power of signal
in the frequency band (Fig. 3.4).
The first panel shows the FFT graphs of the selected channel in real time. The second
panel displays the power of signal in specific frequency bands: Delta (1-4Hz); Theta (47Hz); Alpha (7-13Hz); Beta (13-30Hz).

54

Figure 3-4 FFT EEG Band

3.3 EMOTIV EPOC + 3D BRAIN ACTIVITY MAP

This tool displays a real-time map of mental activity in different brainwave frequency
bands. Adjustable gain allows you to see detailed information and relative strengths
between different brain regions. Adjustable buffer size allows you to see instant responses
or average over longer periods.
The Advanced Suite allows to display significant brainwave in any frequency band.
In Fig.3-5 the screen displays brain activity in four significant brainwave frequency bands
55

(Delta, Theta, Alpha, Beta) and the contact quality for each EPOC sensor.

Figure 3-5 Brain activity map

Figure 3-6 Brain Activity summary

Fig 3-6 shows the brain activity in any frequency band defined by the user and the review
of a recorded session at any time.

3.4 EPOC-SIMULINK CONNECTION

Simulink is a MATLAB [79] environment used to simulate and model dynamic systems.

56

Simulink supports the simulation of non-linear systems that operate with continuity
classifying them based on the continuous or discrete time.
Moreover, Simulink offers a graphic interface that allows to define and create the model
through its flowchart. The blocks can be moved. This environment includes an elevated
number of libraries that include a wide range of blocks able to develop (easier) operation
on the signals. In addition, Simulink integrates itself completely with MATLAB.
In this project, Simulink has been interfaced both with EMOTIV and with MATLAB as
explained hereafter.
Simulink can be connected with EMOTIV EPOC + to allow recording in real time EEG
signals, synchronizing them with other procedure. By inserting the USB receiver of the
Emotiv device and clicking on Epoc-SimulinkSignalserver.exe, the connection is
activated when clicking START, as shown in Fig. 3-7.

Figure 3-7 EPOC Simulink Signal Server

Then, opening the MATLAB directory by importing the Epoc Simulink Signals folder,
the Simulink model opens (Fig. 3-8).
57

Simulink is an environment for the modeling, the analysis and the simulation of dynamic
systems.

Figure 3-8 The Simulink blocks

The model is formed of a series of blocks that are copied from a library in the work area
to create the chosen calculation model (Table 1):

58

TYPES OF BLOCKS

DESCRIPTION
This represents the connection of the circuit and is
can be seen how all the blocks are connected.

EpocEEG real time data synchronization with
video frames

This block receives the data which in real time are
converted into numbers.

Table 1 Types of Simulink blocks with description

The blocks are graphically connected with oriented links.
When clicking on Run on the blocks window, both the stimulating video and the
recording of the signals start in a synchronous mode.

3.5 3D EXCELVAN GLASSES

To isolate the sensitive experience of the videos in the surrounding environment we used
special glasses connected to the pc.
The 3D EXCELVAN glasses are in general used as Multi-media player for movies,
music, photos and books (Fig. 3-9).
The EXCELVAN glasses work with MP4, MP5, PMP, DVD and other multi-media
formats.
59

This Virtual Screen is equipped of detachable earphones, super dynamic quality stereo
sound effect. They are endowed with built-in rechargeable battery, advanced micro
displays technology, connected to the PC via HDMI .

Figure 3-9 3D-Excelvan Glasses

3.6 SELECTED ELECTRODES

In anatomy, the brain is divided into four lobes, differentiated by their location and
functions [80].
The electrodes have been selected on the of their functional role in relationship with the
chosen electrodes: F7 (Frontal lobe), T8 (Temporal lobe), P7(Parietal lobe), O1
(Occipital lobe).
F7 (Frontal lobe): The frontal lobe is the biggest lobe in the brain and the most important
lobe for the human species. In anatomy it extends from the frontal pole to the central
60

sulcus and is composed by different parts: precentral gyrus, premotor cortex,
supplementary motor cortex, frontal eye field and motor speech area (Broca speech area)
The association cortex of the frontal lobe, also known as the prefrontal cortex, is a latedeveloping region of the neocortex. In the human adult, the frontal lobe constitutes as
much as nearly one-third of the totality of the neocortex. The most general executive
function of the lateral prefrontal cortex is the temporal organization of goal-directed
actions in the domains of behavior, cognition, and language.

T8 (Temporal Lobe): The temporal lobe is located between the lateral fissure on both
cerebral hemispheres, inferior to the lateral sulcus, which separates the frontal lobe and
the parietal lobe. The temporal lobe is composed by: superior temporal gyrus, middle
temporal gyrus, inferior temporal gyrus, auditory tract, primary auditory cortex,
secondary auditory cortex. This lobe is active in processing sensory input and the in the
appropriate retention of visual memory, language comprehension, and emotion
association.

P7 (Parietal Lobe): The parietal lobe is superior to the occipital lobe and temporal lobe,
separated from the frontal lobe by the central sulcus. This lobe is composed to: MT
middle temporal area postcentral gyrus, primary somatosensory cortex, secondary
somatosensory cortex, supramarginal gyrus and angular gyrus. This lobe integrates
sensory information among various modalities, including spatial sense and navigation
(proprioception). The major sensory inputs from the skin (touch, temperature, and pain
receptors), relay through the thalamus to the parietal lobe. Several areas of the parietal
lobe are important in language processing.

61

O1 (Occipital Lobe): The occipital lobe is the visual processing center, containing most
of the anatomical region of the visual cortex. The primary visual cortex is the Brodmann
area 17, and it is located on the medial side of the occipital lobe within the calcarine
sulcus; the full extent continues onto the posterior pole of the occipital lobe. This lobe is
specialized for different visual tasks, such as visuospatial processing, color
differentiation, and motion perception.
We chose in particular to process four electrodes (T8, P7, O1, F7) as the most interesting
in relationship with the chosen stimulations. In fact, F7 is involved in cognitive control,
T8 in language and visual input and memory, P7 in visuospatial processing and the O1
main functional area is the primary visual cortex. The frequency analyzed were Beta
(between 12.5 and 30 Hz) and Gamma (>30 Hz) (Tables 2 and 3).

62

F7

T8

Location: Frontal lobe, Rostral region of

Location: Temporal lobe

superior frontal gyrus

Function, Connectivity:

Function, Connectivity:

Posterior part contains Wernicke's Area

BA9

and

BA11

make

up

prefrontal

Language comprehension

cortex,Executive functions Cognitive control

Table 2 Selected electrodes F7 (Frontal Lobe) and T8 (temporal lobe)

63

P7

O1

Location:

Location:

Occipital lobe

Medial part of occipital lobe

Includes parts of cuneus, lingual gyrus and the

Function, Connectivity.

lateral occipital gyrus

Initial site of cortical processing of visual information

Function, Connectivity.

Organized in orientation columns,

Visual processing

Table 3 Selected electrodes P7 (parietal Lobe) and O1(Occipital Lobe)

64

3.7 VIDEOS

We created two videos representing different perceptions and cognitive stimuli.
The videos have been realized with PowerPoint. Successively the Power Point
presentation has been saved into .mp4 format and synchronized using the Simulink
procedure.

3.7.1 First Colors Test

The First Colors test consists of three tones of the same colors. The colors that have been
selected are: Yellow, Red and Blue. Each colored stimulus last 5 s and is followed by a
5 s black stimulus, as a function of control and reset (Table 4 and Fig. 3-10).

65

COLORS

LIGHT COLORS

DARK COLORS

YELLOW

RED

BLU

Table 4 First Colors test

66

Figure 3-10 The first Colors test

3.7.2 Second Colors test

In this test we selected: colors, color imagines recalling colors written words representing
colors and sounds of the words of the colors.
The stimuli last 5s, followed by a 5 s black stimulus, as a function of control and reset
(Table 5 and Fig. 3-11).
.

67

COLORS

COLORED IMAGES

YELLOW

LEMONS

WRITTEN
COLORS

COLORS
SOUND

YELLOW
YELLOW
GREEN

MEADOW

GREEN
GREEN

BLUE

SKY

BLUE
BLUE

Table 5 Second Colors Test

68

Figure 3-11 The second Colors test

3.8

EXPERIMENTAL PROCEDURE

We collected 10 recordings from eight men and two women, aged between 22 and 65; the
educational level was graduations and PhD (Table 6).
The above described Simulink procedure synchronizes the acquired signals with the
various sensory and cognitive experiences presented in the videos. At the end of the
experiment, signals are recorded and the analysis procedure is applied.

69

SEX

AGE

EDUCATION
LEVEL

8 MEN

22-65

Master Degree.

2 WOMEN

30-60

Master Degree.

Table 6 Subjects Data

70

4 SIGNAL PROCESSING
4.1 EMOTIVE EPOC +: DATA PRE-PROCESSING

The EMOTIVE EPOC + system provides data to the user at a sampling rate of 128 Hz,
although per the technical specifications it works at a rate of 1024 Hz internally. The
down sampling is for various technical reasons including wireless transmission to the
receiver. Resolution is approximately 0.5 microvolts (14 bits). The working bandwidth is
0.2 to 43 Hz, allowing recordings into the low gamma range, and there are notch filters at
50 and 60 Hz for 7 electrical noise in both North America and Europe (Fig. 4-1).

Figure 4-1 From the Epoc+ manual: Epoc+ parameters

71

The online EEG was sampled at 1000 Hz with an online bandpass filter from1 to 100 Hz.
The signals from the other 14 scalp sites (channels) were high-pass filtered with a 0.16 Hz
cut-off, pre-amplified and low-pass filtered at an 83 Hz cut-off. The digitized signal was
filtered using a 5th-order sinc notch filter (50‚Äì60 Hz), low-pass filtered and downsampled to 128 Hz.
The system provides an embedded, in signals processing, a sinc filter is an idealized filter
that removes all frequency components above a given cutoff frequency, without affecting
lower frequencies, and has linear phase response. It is an "ideal" low-pass filter in the
frequency sense, perfectly passing low frequencies, perfectly cutting high frequencies;
and thus may be considered to be a brick-wall filter.
Real-time filters can only approximate this ideal, since an ideal sinc filter (a.k.a.
rectangular filter) is non-causal and has an infinite delay, but it is commonly found in
conceptual demonstrations or proofs, such as the sampling theorem and the Whittaker‚Äì
Shannon .

4.2 PROCESSING

As previously presented, the aim of this work is that of using the EEG tracing to isolate
some sensorial and cognitive stimuli (colors, writings or words) comparing the resulting
attractors and maximizing the similarities between similar stimuli and the differences
between different stimuli. For this reason, we used the ANN ITSOM network.
The parameters of the neural network have been optimized during the analysis. A schema
of the ideal structure of the whole system can be depicted as in Fig. 4-2 .

72

ANN
MODELING

COLOR
STIMULATION

EEG
MEASUREMENT

TEST
CASES

Figure 4-2 System representation.

The dotted line indicates the ideal correspondence between the
neural correlates of color perception and the ANN attractors.

The full tracing has been cleared from the start and end columns leaving only the 14
columns deriving from the electrodes.
The file has been further filtered through two elaboration chains written in MATLAB to
separate and distinguish beta and gamma frequencies.
‚óè butterbeta.m (Butterworth band-pass filter between 14 and 30,
beta waves)
‚óè buttergamma.m (Butterworth band-pass filter between 31 and 46,
gamma waves)

73

The procedures create two filtered files in beta and gamma frequencies for all the
electrodes. A track that divides the sampled signal compared to the different stimulations
is included in a script that creates one file (blue.txt, yellow.txt, ecc.) for each stimulation.
The electrodes in each file are in the following order:
AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4.
At the end, for each stimulation we have: 4 filtered files, one for electrode F7, P7, O1,
T8. Therefore, there are 8 unidimensional files in total, relating to each individual
color/writing/voice stimulation.

4.3 ITSOM APPLICATION

The sampled amplitudes files, thus divided, are elaborated by the ANN which is written
in C ANSI.
The ITSOM network is able to process more signals simultaneously but in this case it was
useful to process one signal at a time.
Starting parameters selected to elaborate this kind of signal are summarized in Table 7.
However, these parameters have been modified from time to time until a dynamic
stabilization threshold is reached.

74

INPUT NEURONS

1500

COMPETITIVE LAYER NEURONS

15 neurons

LEARNING RATE

0.01

DELTA1

0

DELTA2

0
0

NUMBER OF EPOCHS

400

Table 7 Initial parameters for ITSOM

The executable creates four output files in a subfolder that contain the signal files:
DYNDEC.txt, WEIGHTS.txt, ZSCORE.txt, ZREALS.txt
DYNDEC.txt: Represent the winning neurons that is those neurons that win the
competitions with weights. Fig. 4-3 shows a typical series of winning neurons.

75

Figure 4-3 Series of winning neurons of the yellow stimulation on electrode F7

76

WEIGHTS.txt :The weights are visualized with the goal of perform a control on their
variation (Fig. 4-4).

Figure 4-4 Snapshot of the weights variation file, indicating the ANN evolution in the time

ZREALS.txt: Coding in real numbers without threshold (Fig. 4-5).

Figure 4-5 List of Z real numbers

77

ZSCORE.txt : after the application of the threshold, the zeta score code processes in a
binary string the dynamic behavior (Fig. 4-6).

Figure 4-6 0s and 1s sequence that represents the network dynamic behavior

Once these files are generated, it is verified if the zscore are (as much as possible) similar
for similar stimuli and different for different stimuli.
If this is not the case, we look at zreal and see if, changing the delta threshold between 0
and 1, the zscore would change in a more appropriate way. In this situation, the threshold
is changed.
Otherwise, we proceed to change the other parameters of the network and restart the
procedure. As a general rule, larger competitive layers make it more difficult to find
correspondences. The learning rate should move the weights of the network at every
epoch, but not too much because the network must remain stable. If the weights do not
move, Dyndec.txt gives a series of equal values or close to equal. Dyndec.txt should show
groups of numbers that, more or less, repeat themselves in time. In the first epochs there
could be a transient, then the network should stabilize itself. It might tend to move and
show new numbers, but it should not change completely. The optimization of the
78

parameters should at the end be a single one for all the elaborated signals.

4.3.1 ITSOM RESULTS

In this paragraph the optimized ITSOM parameters and the results are presented (Table
8).
INPUT NEURONS

500

COMPETITIVE LAYER NEURONS

10

LEARNING RATE

0.001000

DELTA1

-0.200000

DELTA2

0.200000

NUMBER OF EPOCHS

150

Table 8 Optimized ITSOM parameters

4.3.2 First Colors Test Results

In Table 9 are reported the tones of colors that have been mainly involved, considering
all the available recordings, and on which electrode they have had an impact on the
presence of the chaotic attractor. Light yellow and dark yellow are present both on F7 and
T8 electrodes. The O1 electrode did not detect any correlation.
We highlight these results, divided in stimulation and reference electrodes.
79

COLORS TONES

ELECTRODES

LIGHT BLUE
DARK BLU

F7

LIGHT YELLOW
DARK YELLOW
RED
PINK

P7

LIGHT YELLOW

T8

DARK YELLOW

Table 9 First Colors test: highest correlation between stimuli and electrodes

In the Table 10 are reported, for each stimulus and electrode, the corresponding binary
code. The EEG band the results refer to is the gamma band, since the beta band did not
present satisfying results. The table refers to the best recording available.

80

STIMULI

ELECTRODES

BINARY CODE

BLUE

1 0 1 1 0 0 0 0 0 1

DARK BLU

1 0 1 1 0 0 0 0 0 0
F7

LIGHT YELLOW

1 0 1 0 1 0 0 0 0 0

DARK YELLOW

1 0 1 0 1 0 0 0 0 0

DARK RED

0 0 0 0 0 1 1 1 1 0

RED

P7

LIGHT YELLOW

0 0 0 0 1 1 1 1 1 0
0 1 0 1 1 1 1 1 0 0

DARK YELLOW

T8

0 1 0 1 0 1 0 1 0 0

Table 10 Stimulus, Electrode and corresponding binary Code: best similarities

It can be deduced that similar stimuli have similar responses and different stimuli have
different codes.

4.3.3 Second Colors Test Results

The second colors test consists of the presentation of colored stimuli with different
features entities such as: monochromatic, color associated to pictures, written colors and
in audio format. As in the previous example, Table 11 shows what are the images, colors,
colored writings that have been mainly involved in relation to which electrodes. In this
case the electrodes that showed the highest involvement in the stimuli were F7 and O1.

81

STIMULI

ELECTRODES

WRITTEN GREEN
WRITTEN MEADOW

O1

SKY
WRITTEN SKY
WRITTEN GREEN
WRITTEN MEADOWN
SKY
WRITTEN SKY
YELLOW SOUND
WRITTEN YELLOW

F7

YELLOW
WRITTEN LEMON
MEADOW SOUND
GREEN WRITTEN
YELLOW SOUND
YELLOW IMMAGIN COLORS
LEMON SOUND
MEADOWN SOUND
LEMON WRITTEN
YELLOW
LIGHT BLUE
SKY
WRITTEN LIGHTBLUE
YELLOW

T8

LEMONS
WRITTEN YELLOW
GREEN
MEADOW
WRITTEN GREEN

Table 11 Second Colors test: highest correlation between stimuli and electrodes

82

A common element on the four electrodes is that there is a higher involvement of the
colors when in written form. As in the previous experiment, the results displayed are
related to the gamma band, since the beta band did not report significant results.
Hereafter (Table 12) are summarized the stimuli, electrodes and bands involved with
binary codes. Also in this case it is confirmed that similar stimuli offer similar binary
codes.

STIMULI

ELECTRODES-

BINARY CODE

EEG BAND
LIGHTBLUE

0 0 0 1 1 0 1 0 1 0

SKY

0 0 0 1 1 0 0 1 1 0

WRITTEN LIGHTBLUE

0 0 0 1 1 0 1 1 1 0

YELLOW

1 0 0 1 0 0 1 1 1 1

LEMONS

T8

1 0 0 1 0 0 1 1 1 1

WRITTEN YELLOW

GAMMA

1 0 0 0 0 1 1 1 1 1

GREEN

0 0 0 0 0 1 0 1 0 0

MEADOW

0 0 0 0 0 1 1 1 0 0

WRITTEN GREEN

0 0 0 0 0 1 1 1 0 0

YELLOW

1 0 0 0 0 1 0 0 1 1

LEMONS

1 0 1 0 0 0 1 1 1 0

WRITTEN YELLOW

P7

1 0 1 0 0 0 1 1 0 0

LIGHT BLUE

GAMMA

01 0 0 0 0 1 1 0 0

WRITTEN LIGHTBLUE

0 0 0 0 0 0 1 1 0 0

WRITTEN GREEN
MEADOWN SOUND

0 0 0 0 0 0 1 1 0 0
F7
0 0 0 0 0 0 1 1 0 0
GAMMA

WRITTEN LEMON

1 0 0 1 0 0 0 0 0 0

YELLOW

1 0 0 1 1 0 0 0 0 1

83

YELLOW
LEMON SOUND

1 0 0 0 1 0 0 0 0 0
F7

1 0 0 0 0 0 0 1 0 0

GAMMA
WRITTEN YELLOW

1 0 0 0 0 0 1 1 1 0

YELLOW SOUND

1 0 0 0 0 0 0 1 1 0

SKY

0 0 0 0 0 0 0 0 0 1

WRITTEN SKY

0 0 0 0 1 0 0 0 0 0

WRITTEN GREEN

0 0 0 1 1 0 0 0 1 0

WRITTEN MEADOWN

O1

0 0 0 1 1 0 1 1 0 0

GAMMA
SKY

0 0 0 0 1 1 0 0 0 0

WRITEN SKY

0 0 0 0 1 0 0 0 0 0

Table 12 Stimuli, Electrodes and Binary codes of the second Colors test

4.4 CORRESPONDENCE BETWEEN STIMULI AND SHAPE
OF ATTRACTORS
It is important to outline that there is a correspondence not only in the codes, but also in
the shape of the attractors during the phases related to the considered stimuli. As we said
the attractors are created from the series of the winning neurons, using a two dimensional
model.
In Tab. n. 13-14-15 the first column shows the sensory and cognitive stimuli, the second
column shows the binary code resulted from the ANN processing the third column shows
the attractors generated by the dynamics of the sequence of the ITSOM winning neurons.
84

We can observe that similar stimuli present attractors that have a similar shape.
Moreover, this shape is different from that of the attractors deriving from different
stimuli.
The shape of the configuration of these attractors could therefore be apt to represent the
qualitative aspect of the states of consciousness, the so-called ‚Äúqualia‚Äù [88], [89], [90].
It must be outlined that of course the concept of ‚Äòqualia‚Äô refers to a purely subjective
phenomenon: it cannot be observed from ‚Äòoutside‚Äô, is not available by correlative
measures or physics in generally. It accounts for the subjective ‚Äòmeaning‚Äô of information,
not to its contents or the diversity or differences in perception .
Thus we have to stress that in this work we are dealing with a representation of the
perceptive counterpart of ‚Äúqualia‚Äù.

85

STIMULUS

BINARY CODE

CHAOTIC ATTRACTORS

YELLOW
1 1 0 0 1 0 1 1 1 1

LEMONS
1 1 0 0 0 0 1 1 1 1

YELLOW

1 1 0 0 0 1 1 1 1 1

Table 13 Results of the Yellow stimulus

86

STIMULUS

BINARY CODE

CHAOTIC ATTRACTORS

BLUE

0 0 0 1 1 0 0 0 1 0

SKY

0 0 0 1 1 0 1 0 1 0

BLUE
0 0 0 1 1 0 0 1 1 0

Table 14 Results of the Blue stimulus

87

STIMULUS

BINARY CODE

CHAOTIC ATTRACTORS

GREEN

0 0 0 0 0 1 1 1 0 0

MEADOW

1 0 0 0 0 1 1 1 0 0

GREEN

1 0 0 0 0 0 1 1 0 0

Table 15 Results of the Green stimulus

4.5 FINAL RESULTS
From the results of the first observation we can highlight that:
1.

The electrode that presents a higher correspondence with the stimulations it T8.
88

2.

Low presence of correspondence relative to pure colors.

3.

Substantial absence of spurious correspondences between pure colors or between

images,
4.

Low correspondence of the red color and similar (red appears with 4 electrodes),

5.

Clear higher number of correspondences for writing and words,

6.

The stabilization of the network is when reaching 150 epochs and is maintained

until over 1200 epochs.
7.

The Gamma band shows in both experiments a higher correspondence between

binary codes.
8.

There is a correspondence between stimulus and shape of the attractor: again.

Similar stimuli give raise to similar attractor shapes, different stimuli give raise to
different attractor shapes.

89

5 EVALUATION OF INTEGRATED INFORMATION

As mentioned in cap. 1, IIT refers to the mathematical theory of information proposed by
C. Shannon and W. Weaver [17]. According to this framework, information is defined as
the reduction of uncertainty among a number of possible outcomes x of a random variable
X when one of them occurs. Thus, an increase of uncertainty corresponds to higher
information, and the information content of x, I(x), will be a decreasing function of its
probability. Shannon showed that this function is expressed by

ùêº (ùë• ) = ‚àíùëôùëúùëî2 ùëÉ(ùë•)

where P(x) is the probability that x occurs. Entropy of the random variable X is defined as
the expected value of the information content of X (i.e. its average information content).

ùêª (ùëã) = ùê∏(ùêº(ùëã))

Thus Entropy can be defined as a measure of the uncertainty associated with X. Given
two subsets A and B defining a single bipartition of a system X, Mutual Information
measures the uncertainty of A that is accounted for by the state of B, and is defined as

ùëÄùêº(ùê¥; ùêµ) = ùêª (ùê¥) + ùêª (ùêµ) ‚àí ùêª(ùê¥ùêµ)
90

The Effective Information of a system measures the extent to which its repertoire of
possible states is differentiated in response to all possible inputs. Effective Information is
calculated as the Mutual Information across a partition when the outputs from one subset
have maximum Entropy.
As before mentioned, the IIT hypothesizes that consciousness corresponds to the capacity
of the system to integrate information, and this measure is indicated by –§.
–§ is defined as the Effective Information across the weakest link of the system, i.e. the
Minimum Information Bipartition. The Minimum Information Bipartition is the partition
of the system for which the Effective Information is lowest.
To summarize, in order to calculate the integrated information of a system –§ (thus a
measure of consciousness, as intended in the IIT framework) it is sufficient to calculate
the integrated information between two partitions of the system, among all the possible
ones, which have the lesser amount of effective information between them. A high value
–§ will denote highly structured complexity. In the brain, the thalamo-cortical system can
be described as a single large highly complex system whereas, on the contrary, the
cerebellum consists of a large number of very small complexes, each corresponding to a
single module and thus having a very low complexity. In terms of complexity, the
differences between brain and cerebellum are therefore not the amount of effective
information related to the repository of possible states that characterize each system, but
rather the level of integration of the information contained therein.
Hence the flow of information between two parts of the same system must be considered.
But once defined a formal way to measure –§ and once identified a brain system that may
represent a good candidate to generate integrated information, a method to represent
complexity and integration in brain structures in such a way as to quantify –§ from real
91

data must be developed.
One of the methods currently studied to analyze complexity in brain structures is to study
the brain as a dynamical system.
Brain dynamics refers typically to the dynamics of neuronal populations, networks or
columns within cortical areas. It is characterized by its high complexity, often involving
oscillations at different frequencies and amplitudes, perhaps interrupted by chaotic or
pseudo-chaotic irregular behaviour. Synchronization among groups of neurons were first
discovered in the olfactory system [81], [82], but has also been demonstrated in other
brain structures, such as the hippocampus [83] [84] and the visual cortex [85], [86], where
the oscillations tend to synchronize in phase.
Synchronous oscillations can occur in nearby neurons, but also over considerable
distances across spatially separate columns [86] and even between cortical areas [85],
[87]. According to IIT, several aspects of the organization of the cortico-thalamic system
and of transient attractor dynamics appear well suited to information integration.
It has been recognized that the massive interconnectivity within and among cortical areas
(and with thalamus) provides an ideal substrate for cooperative dynamics among
distributed neurons [88]. A plausible scenario for characterizing such dynamics is in
terms of transient attractors.
In fact neurons in the cortico-thalamic system seem to behave in such a way as to ensure
the rapid emergence of firing patterns that are distributed over wide regions of the cortex,
where some neurons are strongly activated, and many more are deactivated. These firing
patterns remain stable (hence they form attractors) over a time scale of tens/hundreds of
milliseconds, but then rapidly dissolve (hence the attractors are transient), to make room
for another transient attractor.
Attractors have been indicated in the form of binary strings (e.g. in a Hopfield network
92

consisting of 8 elements with 6 embedded attractors, the attractors are indicated with
00001111, 00110011, 01010101, and their mirror images.)
Metastable systems, namely dynamical configurations that constitute non-fixed-point
attractors, are good candidates to form a class of systems with high –§ [89], [90], [91].
Our approach stems from the wide literature mentioned above. Whit the ANN ITSOM,
we show how the dynamical analysis of neural signals may highlight the existence of
chaotic attractors, differentiated depending on the cognitive states, that outlines the
attractors in which the corresponding dynamical system is evolving.
If the attractors show to be chaotic, this means that the neural signals are individually
self-organized and, when analyzing more signals together, that there is a form of
coherence between signals. The ANN can also highlight the time course of this form of
coherence and identify different attractors with a unique code as we have the ANN
allows to attribute the same codes to similar but not identical brain events, reaching the
necessary range of flexibility. In Table 12 the first columns show the sensory and
cognitive stimuli, the second columns show the binary code resulted from the ANN
processing, the third columns show the attractors generated by the dynamics of the
sequence of ITSOM winning neurons: the figure represents a snapshot of movies that
show a typical chaotic path.
To summarize the results, comparing the stimuli, the codes in Table 16 are obtained,
clearly highlighting how similar stimuli give rise to similar codes, that result to be quite
different from the codes obtained by different stimuli.

93

Table 16 Summary of the results. Codes of similar stimuli are similar, codes of different stimuli are quite different

5.1 INTEGRATED INFORMATION CALCULUS

In order to quantify the IIT content of the organized signals collected after perceptive and
cognitive stimulations we considered the case of the T8 electrode in gamma band, that
slowed the best results in the previously described analysis.
Using the tool available at the website of the Center of Sleep and Consciousness of the
University of Wisconsin [92] [93], that implements the procedure explained at the
paragraph 1.2, we have been able to calculate the –§ value of the specific patterns through
their related dynamical attractors.
The summary of results in sketched in Table 17, where Œ¶ represents the integration at a
system level.
The dynamical representation in the concept (qualia) space of some of the patterns is
reported in Figures 5-1, 5-2 ,5-3, and their conceptual structure after calculation in the IIT
framework is depicted in Figures 5-4, 5-5, 5-6.

94

Table 17 Integrated Information Calculus

In conclusion, for all the color stimulations the –§ value was equal to 0.08323, except for
the Green color that had a –§ value equal to 0.21528. The other stimulations had a –§ value
higher than the pure colors and equal to 0.21528: in line with the IIT, this is correct as
they have not only sensory but also cognitive contents, thus should involve more neural
structures and can be considered more complex. Although the –§ value of stimulation
patterns of information content with equivalent complexity coincide, their specific
information contents are diverse and composed by subsystems with different values.
We would be tempted to state that these codes can be a way to identify qualia, i.e. the
subjective and qualitative experience of mental conscious states and of their neural
correlates [91], as there is an extremely high number of possible binary codes, but we can
distinguish a set of dynamical states with unique codes that we may call ‚Äúqualia codes‚Äù.

95

Figure 5-1 Attractor of Yellow

Figure 5-2 Attractor of Lemon

96

Figure 5-3 Attractor of Written Green

Figure 5-4 Conceptual structure of Yellow

97

Figure 5-5 Conceptual structure of Lemon

Figure 5-6 Conceptual structure of written Green

98

6 CONCLUSION

The aim of this thesis was the development of a method for the identification of
perceptive and cognitive mental states starting from EEG signals. The method used a tool
of computational intelligence, that is to say an AAN, able to catch the dynamical behavior
of the signal and codifying it in a binary string. Such code is comparable with the
corresponding codes to/of other mental events.
This way it was possible to identify the chaotic attractors present in the dynamical system
represented by the signal and, thanks to these, calculate the content of Integrated
Information related to each mental state.
The thesis has been presented by developing the following points.
The concept of consciousness and of Integrated Information has been introduced. Recent
studies in the field of neurophysiology brought to the understanding and study of the
requirements needed to measure the consciousness, analyzing the composition in
quantum terms [94].
The main concept underlying this thesis is that, under controlled stimuli, it is possible to
show that similar stimuli correspond to similar responses and different stimuli correspond
to different responses, and these responses can be identified and coded.
To elaborate this theory, we studied the brain as a dynamical system and processed
signals by means of the chaos theory and a suitable self-organized ANN.
99

Lastly, we highlighted the processed results with the ITSOM. Moreover, very detailed the
different phases of the experiments carried out were described in detail, as well the tools
used to record the signals and the choice of the electrodes, the analyzed EEG frequency
and the creation and choice of the sensorial and emotive stimuli.
Eventually, the procedure of preprocessing, data registration and the related results have
been presented.
The signal analysis with the abovementioned computational method indicated some key
points:
In general, there is a correspondence between binary codes and similar mental events,
while different mental events have very different codes: to be more precise, it can be
noted that there is a constant absence of spurious correspondence between pure colors and
images. The most frequent correspondences are between images and written words.
Pure colors are not involved in correspondences as much as we would expect, since they
are ‚Äúeasier‚Äù perceptions to identify. Moreover, it is observed that a less significant
number of correspondences is related to the color red.
The electrode in which correspondences are more frequent is F7, the electrode more
involved in cognitive activities. Actually the presence of complex images, not only
related to pure perceptions, make a cognitive processing necessary. The electrodes that do
not or only partially involve it do not seem apt to generate signals able to recognize
similarities between similar images.
Between the two chosen frequencies, the gamma frequency is definitely more selective
than the beta one. This is in line with the converging evidence that processes involved in
the creation and maintenance of (visual) feature bindings are accompanied by, and
systematically related to, neural activity in the gamma band.
A known unifying concept relates the associative principle of neural networks to the
100

mechanism of temporal binding at high frequencies. It suggests that for each memory
stored in an associative network there is a corresponding quasi-stable state of
synchronous oscillation at some frequency within the gamma band.
In particular, gamma band power is correlated with visual awareness [95] [96].
The chaotic attractors, isomorphic to the signals and created by the series of winning
neurons, are stabilized around 150 epochs and remain stable up until at least 1200 epochs.
This allowed us to characterize them and calculate the value of Integrated Information
related to each mental state.
We highlighted that the stimulation patterns with cognitive content have a value higher
than that of purely perceptive patterns (pure colors). This is completely in line with the
Integrated Information Theory.
By continuing the graphic processing of the attractors during the phases, we verified a
structural similarity of the attractors of similar cognitive-perceptive content and a
different shape in the attractors corresponding to different mental events.
We could try to affirm that the shape of these attractors may constitute a visual
counterpart of the ‚Äúqualia‚Äù, the elusive qualitative characterization of the conscious
states. The present work cannot clearly give a measure about the variation in subjective
experience for a given stimulus.
We can affirm that the possibility to computationally encode mental events, based on the
dynamical structure of the cerebral signals involved, gives an interesting result that can be
confirmed with further experiments.
In particular, the analysis of signals from waking and sleeping patients in the NREM
phase is underway with the aim to find a method to distinguish algorithmically the
conscious state (waking) from the unconscious state (NREM).
The other result of this thesis is the definition of a method to find the value of Integrated
101

Information related to real mental states. The ability to measure this value on real cerebral
signals opens unexplored perspectives on the possibility to explore conscious and
unconscious mental states and add new elements to the understanding of the complicated
and fascinating problem of consciousness.

102

REFERENCES

[1]
T. Nagel, ¬´What is it like to be a bat? In: Nagel T. Mortal questions,¬ª Cambridge:
Cambridge University Press, p. p. 165‚Äì80, 1979.
[2]
W. James, The principles of psychology, New York:: Henry Holt, 1890..
[3]
S.Greenfield, ¬´How might the brain generate consciousness?,¬ª in From brains to
cosciousness, London, In: Rose S, editor, 1998, pp. 210-270.
[4]
G.M. Edelman, G.Tononi, "Consciousness and the integration of information in
the brain.," Consciousness:at the frontiers of neuroscience. Avances in neurology., vol.
77, no. 80, p. 245, 1998.
[5]
B.J. Baars, ¬´A cognitive theory of consciousness,,¬ª Cambridge University Press,
1988.
[6]
J. Searle, ¬´ The Problem of Consciousness,¬ª Consciousess and Cognition, vol. 2, n.
4, pp. 310-319, 1993.
[7]
D. J. Chalmers, ¬´The conscious mind: In Search of a Fundamental Theory,¬ª in
Oxford University Press, 1996.
[8]
D. Dennett, Kinds of Minds: Towards an Understanding of Consciousness, Basic
Books, 1997.
[9]
T. Metzinger, Neural Correlates Consciousness: Empirical and Conceptual
Question, Mit Press, 2000.
[10] B. Baars ,N. M. Gage, Cognition, Brain and Consciousness: An Introduction to
Cognitive, AP, 2007.
[11] C.S. Sherrington, ¬´The Integrative Action of the Nervous System,¬ª Brain, vol. 130,
n. 4, pp. 887-894, 2007.
[12] G.M. Edelman, G.Tononi, ¬´Consciousness and the integration of information in
the brain,¬ª Advances in neurology, vol. 77, n. 80, p. 245, 1998.
[13] G.M. Edelman, G. Tononi, A Universe of Consciousness: How Matter Becomes
Imagination, Basic Books, 2000.
[14] C. Koch, M. Massimini, M. Boly, G.Tononi, ¬´Neural Correlates of consciousness:
progress and problems,¬ª Neuroscience, vol. 17, pp. 307-321, 2016.
[15] G. Tononi, M, Boly, Melanie, M. Massimini, C. Koch, ¬´Integrated information
theory: from consciousness to its physical substrate,¬ª Nature Reviews Neuroscience.
Nature Publishing Group, vol. 17, n. 5, pp. 450-461, 2016.
[16] M. Boly, M. Massimini, N. Tsuchiya, B.R. Postle, C. Koch, G. Tononi, ¬´Are the
Neural Correlates of Consciousness in the Front or in the Back of the Cerebral Cortex?,¬ª
Clinical and Neuroimaging , vol. 37, n. 40, pp. 9603-9613, 2017.
[17] C. Shannon, ¬´A Mathematical teory of communication,¬ª Bell System Technical
103

Journal, vol. 27, pp. 379-423 &623-656, 1948.
[18] R.Pizzi, M. Musumeci, ¬´Coding Mental States from EEG Signals and evaluating
their Integreted Information Content: a Computational Intelligence Approach,¬ª
Internationa Journal of Circuits, System and Signals Processing, vol. 11, n. 4464, pp. 464470, 2017.
[19] F. Heylighen, ¬´Self-Organization, Emergence and the Architecture of
Complexity,¬ª Proc. European Congress on System Science, AFCET Paris, pp. 23-32, 1992.
[20] M. Gell-Mann, ¬´What is Complexity ?,¬ª Complexity 1, pp. 16-19, 1995.
[21] R.K. Standish, ¬´On complexity and emergence,¬ª Complexity Int., vol. 9, 2002.
[22] R. Pizzi, M. Musumeci, Artificial Neural Networks, Dynamical Systems and SelfOrganization, Create Space, 2017.
[23] R. Rosen, ¬´Foundations of Mathematical Biology,¬ª Ac. Press New York, 1972.
[24] E. N. Lorenz, , J. Atmos., ¬´Deterministic Nonperiodic Flow,¬ª Sci., Vol. %1 di %220,,
n. 130, 1963.
[25] J. Gleick, ¬´Chaos,¬ª Viking New York, 1987.
[26] D.Green, ¬´Emergent behavior in biological systems,¬ª Complexity Int., vol. 1,
Aprile 1994.
[27] D. Kaplan, L. Glass, Understanding Nonlinear Dynamics,, Springer, 1995..
[28] E. Jackson, ¬´Perspectives in Nonlinear Dynamics,¬ª Cambridge Un. Press, vol. 1&2,
1989.
[29] H. Atmanspacher, J. Kurths, ¬´Complexity and Meaning in Nonlinear Dynamical
Systems,¬ª Open Systems and Information Dynamics, vol. 1, pp. 269-289, 1992.
[30] R. Rosen, ¬´Dynamical System Theory in Biology,¬ª Stability Theory and its
applications, vol. 1, 1970.
[31] H.O.Peitgen, H. Jurgens, D. Saupe, Chaos and Fractals. New Frontiers of Science,
Springer, 1992.
[32] B.Mandelbrot, The Fractal Geometry of Nature,, New York: Freedman&Co, 1983.
[33] E. Ott, ¬´Appendix: Hausdorff Dimension,¬ª Chaos in Dynamical Systems., New
York, Cambridge University Press, pp. 100-103, 1993.
[34] S. S. M. Radzi, V. S. Asirvadam, D. K. Y. Hutapea and S. C. Dass, ¬´Comparison of
EEG signals during alert and sleep inertia states using fractal dimension,¬ª in 2018 IEEE
14th International Colloquium on Signal Processing & Its Applications (CSPA), Batu
Feringghi, Malaysia, 2018.
[35] W.J. Freeman, ¬´Relation of olfactory EEG on behaviour: time series analysis,¬ª
Behavioural Neuroscience, vol. 100, 1987.
[36] W.J. Freeman, J. Pelt and F.H. Lopes da Silva, ¬´Role of Chaotic Dynamics in Neural
Plasticity, in:The Self-organizing Brain: from Growth Cones to Functional NetworksVan,¬ª
(eds) Elsevier, 1994.
[37] V.Menon, W.J.Freeman, ¬´Spatio-temporal Correlations in Human Gamma Band
Electrocorticograms,¬ª Electroenc. and Clin. Neurophys, n. 98, pp. 89-102, 1996.
[38] H.E. Schepers, J. Van Beek , J.B. Bassingthwaighte, ¬´Four methods to estimate the
fractal dimension from self-affine signal,¬ª IEEE Engineering in Medicine and Biology, vol.
11, pp. 57-64, 1992.
[39] P. Grassberger, I. Procaccia, ¬´Measuring the strangeness of a strange attractor,¬ª
Physica D, vol. 9, pp. 189-208, 1983.
[40] J. Geffries, ¬´Code Recognition and Set Selection with Neural Network,¬ª Birkhauser
104

Boston, 1991..
[41] R. Hecht-Nielsen, Neurocomputing, Addison Wesley, 1990.
[42] P. Werbos, Beyond Regression: New Tools for Prediction and Analysis in the
Behavioral Sciences., Harvard University: PhD thesis, 1974.
[43] D. Rumelhart, G.E. Hinton, R.J. Williams, ¬´"Learning representations by backpropagating errors",¬ª Nature, vol. 323, n. 6088, pp. 533-536, 1986.
[44] A. Maren, ¬´Neural Networks for Spatio-temporal Pattrn Recognition,¬ª in Handbook
of Neural Computation Applications, Maren A.J., Harston C.T., Pap R.M., Academic Press,
1991.
[45] Y. Bengio, P. Frasconi, M. Gori, G. Soda,, ¬´Recurrent Neural Networks for Adaptive
Temporal Processing,¬ª in Proc. Neural Nets WIRN Vietri199, Salerno, 1993.
[46] F. Pineda, ¬´Generalization of Backpropagation to recurrent and Higher order Neural
Networks,¬ª Physical Review Letters,, n. 18, pp. 2229-2232, 1987.
[47] T.Catfolis, ¬´Method for improving the real-time recurrent learning algorithm,¬ª
Neural Networks, vol. 6, pp. 807-821, 1993.
[48] K. Funahashi, Y. Nakamura, ¬´Approximation of Dynamical Systems by Continuous
Time Recurrent Neural Networks,¬ª Neural Networks, vol. 6, 1993.
[49] M.K. Sundareshan , ¬´Equilibrium Characterization of Dynamical Neural Networks
and a Systematic Synthesis Procedure for Associative Memories,¬ª IEEE Trans. on Neural
Networks, vol. 7, n. 5, Sept. 1991.
[50] K.S Narendra, K. Parthasarathy, ¬´Gradient methods for the optimization of
dynamical systems using neural networks,¬ª IEEE Trans. on Neural Networks, n. 2, pp.
252-262,, March 1991.
[51] R.J. Williams, D. Zipser , ¬´A lerning algorithm for continually running fully recurrent
neural networ,¬ª Neural Computation, pp. 270-280, 1989.
[52] R.J. Williams, J. Peng, ¬´An efficient gradient-based algorithm for on-line training of
recurrent network trajectories.,¬ª Neural Comp, vol. 2, n. 4, pp. 490-501, 1990.
[53] R. Grossberg, G.A. Carpenter,, ¬´, Self-organization Neural Network Architectures for
Real-Time Adaptive Pattem Recognition,,¬ª in: Zometzer S.F. ed., .An Introduction to
Neural and Electronic Networks, Academic Press, 1990.
[54] G. A. Carpenter, S. Grossberg , J.H Reynolds, ¬´Supervised real-time learning and
classification of nonstationary data by a self-organizing neural network,¬ª Neural
Networks, vol. 4, n. 5, p. 565, 199 1.
[55] M.A. Cohen, S. Grossberg, D. Stork, ¬´Recent Developments in a Neural Model of
Real-Time Speech Analysis and Synthesis,¬ª IEEE First International Conf on Neural
Networks, vol. 4, 1987.
[56] T. Kohonen, ¬´Self-Organisation and Association Memory,¬ª Springer Verlag, 1983.
[57] J. Ormrod, Human Learning, 3rd edition, Upper Saddle River; Prentice-Hall, NJ,
1999.
[58] A. Gruart, R. Leal-Campanario, J.C. L√≥pez-Ramos, J. M. Delgado-Garc√≠a, ¬´Functional
basis of associative learning and its relationships with long-term potentiation evoked in
the involved neural circuits: Lessons from studies in behaving mammals.,¬ª Neurobiology
of Learning and Memory Elsevier, n. 124, pp. 3-18, 2015.
[59] A. Tierney, ¬´The evolution of learned and innate behavior: Contributions from
genetics and neurobiology to a theory of behavioral evolution,¬ª Animal Learning &
Behavior, vol. 14, n. 4, p. 339‚Äì348, 1986.
105

[60] R.P. Keeling, J. Stevens Dickson, T. Avery , ¬´Biological Bases for Learning and
Development Across the Lifespan,¬ª In London M. (Ed.) The Oxford Handbook of Lifelong
LearningNew York: Oxford University Press, pp. 40-51, 2011.
[61] J. Willis, Bloomington, Solution Tree, ¬´Current Impact of Neuroscience on Teaching
and Learning,,¬ª Mind, Brain, Education: Neuroscience Implications for the Classroom,
pp. 45-66, 2010.
[62] S.L.Willis, K.W. Schaie, M. Martin , Cognitive Plasticity, In Bengtson Handbook of
Theories of Aging, New York: Springer, 2009.
[63] R. Pizzi, G. Cino, F. Gelain, D. Rossetti, A. Vescovi,, ¬´‚ÄúLearning in human neural
networks on microelectrode arrays‚Äù,¬ª Biosystems, pp. 1-15, 2007.
[64] R.Pizzi , D.Rossetti, G.Cino, D. Marino, A. Vescovi, W. Baer, ¬´A cultured human
neural network operates a robotic actuator.,¬ª BIOSYSTEMS, vol. 95, pp. 137-144, 2009.
[65] H. Ritter, K. Schulten , ¬´On the Stationary State of Kohonen's Self-Organizing
Sensory Mapping,¬ª Biological Cybemetics, n. 54., pp. 99-106, 1986.
[66] H. Ritter, K. Obermayer, K.Schulten, J. Rubner, Self-0rganizing Maps and Adaptive
Filters Models of Neural Network, E. Domany Springer, 1993.
[67] T. Kohonen, ¬´Physiological Interpretation of the Self-Organizing Map Algorithm,¬ª
Neural Networks, vol. 6, pp. 895-905, 1993.
[68] B. Ermentrout, ¬´Complex Dynamics in WTA Neural Networks with slow inhibition,¬ª
Neural Networks, vol. 5, 1992.
[69] S. Amari, ¬´Dynamical stability of Formation of Cortical Maps,,¬ª Dynamic Interaction
in Neural Networks: Models and Data, 1988.
[70] C.T. Dickson, G. Biella and M. De Curtis, ¬´Evidence for spatial modules mediated by
temporal synchronization of carbachol-induced gamma rhythm in medial entorhinal
cortex,¬ª J Neurosc, n. 20, pp. 7846-7854, 2000.
[71] J.J. Chrobak, G. Buzsaki, ¬´Gamma oscillations in the entorhinal cortex of the freely
behaving rat.,¬ª J Neurosci, pp. 388-398, 1998.
[72] M. Joliot, U.Ribary & R. Llinas, ¬´Human oscillatory brain activity near 40 Hz coexists
with cognitive temporal binding,,¬ª Proc. Natl. Acad. Sci USA 91, pp. 11748-11751, 1994.
[73] W.H.R. Mitner, C.Braun , M. Arnold ,H. Witte and E. Taub, ¬´Coherence of
Gammaband EEG Activity as a Basis for Associative Learning,¬ª Nature,, n. 397, pp. 434436, 1999.
[74] Rodriguez E., George N., Lachaux J.P., Martinerie J., Renault B. and Varela F.J.,,
¬´Perception‚Äôs Shadow: Long-distance Synchronization of Human Brain Activity,¬ª Nature,
n. 397, pp. 430-433, 1999.
[75] F.J. Varela, ¬´Resonant cell assemblies: a new approach to cognitive function and
neuronal synchrony,¬ª vol. 28, pp. 81-95, 1995.
[76] R. Pizzi, M. de Curtis, C. Dickson, ¬´Evidence of Chaotic Attractors in Cortical Fast
Oscillations Tested by an Artificial Neural Network,¬ª in Proc. WILF2001, Springer Verlag,
Milano, maggio 2001.
[77] S. K. Nayak , A. Bit , A. Dey , B. Mohapatra, K. Pal, ¬´A Review on the Nonlinear
Dynamical System Analysis of Electrocardiogram Signal,¬ª Journal of Healthcare
Engineering, n. 6920420, pp. 1-19, 2018.
[78] EMOTIV, Inc., ¬´https://www.emotiv.com,¬ª 2011 [Online]. Available:
https:/www.emotiv.com.
[79] MATLAB, ¬´MATLAB and Statistics Toolbox Release 2012a,¬ª The MathWorks, Natick,
106

MA.
[80] J. W. Britton, C. F. Lauren, J. L. Hopp, MD, P. Korb, M. Z. Koubeissi, W. E. Lievens, E.
M. Pestana-Knight and Erik K. St. Louis, Electroencephalography (EEG): An Introductory
Text and Atlas of Normal and Abnormal Findings in Adults, Children, and Infants¬ª
Chicago, Erik K. St. Louis, MD and Lauren C., 2016.
[81] E.D. Adrian, ¬´Olfactory reactions in the brain of the hedgehog,¬ª The Journal
Physiology, vol. 100, n. 4, pp. 459-473, 1942.
[82] W.J.Freeman, Neurodynamics: An Exploration in mesoscopic brain dynamicals,
Springer, 2000.
[83] J.D. Green, A. Arduini, ¬´Hippocampal Electrical activity in aUR,¬ª Journal of
Neurophygiology, pp. 533-557, 1954.
[84] C. Pantev, T. Elbert, B. L√ºtkenh√∂ner, Oscillatory Event-Related Brain Dynamics., New
York, 1994.
[85] R. Eckhorn, R. Bauer,W. Jordan,M. Brosch, W. Kruse, M. Munk, H. J. Reitboeck,
¬´Coherent oscillations: A mechanism of feature linking in the visual cortex? Multiple
electrode and correlation analyses in the cat. Biological Cybernetics,¬ª Biological
Cybernetics, vol. 60, n. 2, pp. 121-130, 1998.
[86] C.M. Gray, W. Singer, ¬´Stimulus-specific neuronal oscillations in orientation columns
of cat visual cortex,¬ª pp. 1698-702, 1989.
[87] A.K. Engel, P. Fries, P.R. Roelfsema , P. Konig , W. Singer, ¬´Temporal binding,
binocular rivalry, and consciousness.,¬ª Conscious Cogn, vol. 8, pp. 128-151, 1999.
[88] F. Crick, C. Koch, ¬´A framework for consciousness,¬ª Nat Neurosci., vol. 6, n. 2, pp.
119-126, 2003.
[89] D. Balduzzi, G. Tononi, ¬´Integrated information in discrete dynamical systems:
motivation and theoretical framework,¬ª Plos Comput. Biol, vol. vol. 4, n. 100091, 2008.
[90] G. Tononi, ¬´Consciousness as Integrated Information:a Provisional Maifesto,¬ª Bio
Bull, vol. 215, pp. 216-242, 2008.
[91] G. Tononi, ¬´Integrate information theory of consciousness: an updated account,¬ª
Archives Italiennes de biologie , vol. 150, n. 4, pp. 293-329, 2012.
[92] G. Tononi, ¬´I ntegrated Information Theory¬ª [Online]. Available:
http://integratedinformationtheory.org.
[93] M. Oizumi, L. Albantakis, G. Tononi, ¬´From the Phenomelogy to the Mechanisms
of Cosciusness: Integrated information Theory 3.0,¬ª PLOS Comput. Biol., vol. 10, n. 5, p.
e1003588, 2014.
[94] G. Vitiello, My double unveiled: The dissipative quantum model of the brain, John
Benjamins Publishing, 2001.
[95] A. Engel , W. Singer, ¬´ Temporal binding and the neural correlates of sensory
awareness,¬ª Trends Cogn Sci, vol. 5, pp. 16-25, 2001.
[96] Q. Luo, D. Mitchell, X. Cheng, K. Mondillo, D. Mccaffrey, T. Holroyd, J. Blair, ¬´Visual
Awareness, Emotion, and Gamma Band Synchronization,¬ª vol. 19, n. 8, pp. 1896-1904,
2009.

107

INDEX OF FIGURES

Figure 1-1 Composition of the thalamocortical system
Figure 2-1 Typical trajectories in a two dimensional space with two memories
and a limit cycle model
Figure 2-2 Recurrent network with state feedback
Figure 2-3 Narendra Architecture
Figure 2-4 Kohonen Self organizing Map
Figure 2-5 Rotation of the weight vectors
Figure 2-6 Series of the winning neurons in 2-dimensional state space
Figure 2-7 ITSOM Architecture
Figure 2-8 Entorhinal median cortex signals before and after
carbachol admistration
Figure 2-9 State space attractors before and after carbachol administration
Figure 3-1 The EMOTIV EPOC +
Figure 3-2 Display of the electrodes contact quality
Figure 3-3 EEG Channels
Figure 3-4 FFT EEG Band
Figure 3-5 Brain Activity Map
Figure 3-6 Brain Activity summary
Figure 3-7 EPOC Simulink Signal Server
Figure 3-8 The Simulink blocks
Figure 3-9 3D-Excelvan Glasses
Figure 3-10 The first Colors test
Figure 3-11 The second Colors Test
Figure 4-1 From the Epoc+ manual: Epoc+ parameters
Figure 4-2 System representation
Figure 4-3 Series of winning neurons of the yellow stimulation on electrode F7
Figure 4-4 Snapshot of the weights variation file, indicating
the ANN evolution in the time
Figure 4-5 List of Z real numbers
Figure 4-6 0s and 1s sequence that represents the network dynamic behavior
Figure 6-1 Attractor of Yellow
Figure 6-2 Attractor of Lemon
Figure 6-3 Attractor of Written Green
Figure 6-4 Conceptual structure of Yellow
Figure 6-5 Conceptual structure of Lemon
Figure 6-6 Conceptual structure of written Green

7
29
34
35
38
39
41
42
47
48
52
53
54
55
56
56
57
58
60
67
69
71
73
76
77
77
78
91
91
92
92
93
93
108

INDEX OF TABLES
Table 1 Types of Simulink blocks with description
Table 2 Selected electrodes F7 (frontal Lobe) and T8 (temporal lobe)
Table 3 Selected electrodes P7 (parietal Lobe) and O1(occipital Lobe)
Table 4 First Colors test
Table 5 Second Colors test
Table 6 Subjects Data
Table 7 Initial parameters for ITSOM
Table 8 Optimized ITSOM parameters
Table 9 First Colors test: highest correlation between stimuli and electrodes
Table 10 Stimulus, Electrode and corresponding binary code: best similarities
Table 11 Second Colors test: highest correlation between
stimuli and electrodes
Table 12 Stimuli, Electrodes and Binary codes of the second Colors test
Table 13 Results of the Yellow stimulus
Table 14 Results of the Blue stimulus
Table 15 Results of the Green stimulus
Table 16 Summary of the results
Table 17 Integrated Information Calculus

59
63
64
66
68
70
75
79
80
81
82
84
86
87
88
94
95

109

