Kent Academic Repository
Full text document (pdf)
Citation for published version
Yuvaraj, R. and Murugappan, M. and Ibrahim, Norlinah Mohamed and Sundaraj, Kenneth and
Omar, Mohd Iqbal and Mohamad, Khairiyah and Palaniappan, Ramaswamy (2014) Detection
of emotions in Parkinson's disease using higher order spectral features from brain's electrical
activity. Biomedical Signal Processing and Control, 14 . pp. 108-116. ISSN 1746-8094.

DOI
https://doi.org/10.1016/j.bspc.2014.07.005

Link to record in KAR
http://kar.kent.ac.uk/48275/

Document Version
Pre-print

Copyright & reuse
Content in the Kent Academic Repository is made available for research purposes. Unless otherwise stated all
content is protected by copyright and in the absence of an open licence (eg Creative Commons), permissions
for further reuse of content should be sought from the publisher, author or other copyright holder.

Versions of research
The version in the Kent Academic Repository may differ from the final published version.
Users are advised to check http://kar.kent.ac.uk for the status of the paper. Users should always cite the
published version of record.

Enquiries
For any further enquiries regarding the licence status of this document, please contact:
researchsupport@kent.ac.uk
If you believe this document infringes copyright then please contact the KAR admin team with the take-down
information provided at http://kar.kent.ac.uk/contact.html

*Manuscript
Click here to view linked References

Running head: Emotions in PD patients

Detection of emotions in Parkinson’s disease using higher order spectral
features from brain’s electrical activity

R. Yuvaraja,*, M. Murugappana, Norlinah Mohamed Ibrahimb, Kenneth Sundaraja, Mohd Iqbal Omara,
Khairiyah Mohamadb, R. Palaniappanc

a

School of Mechatronic Engineering, University Malaysia Perlis (UniMAP), Arau, Malaysia

b

Neurology Unit, Department of Medicine, UKM Medical Center, Kuala Lumpur, Malaysia

c

Faculty of Science and Engineering, University of Wolverhampton, Telford, UK

*Correspondence author at: School of Mechatronic Engineering, University Malaysia Perlis (UniMAP),
Campus UluPauh, Arau, 02600, Perlis, Malaysia. E-mail: yuva2257@gmail.com; Tel: +6-014-6011990;
Fax: 04-988-5167

1

Emotions in PD patients

2
Abstract

Objective: Non-motor symptoms in Parkinson’s disease (PD) involving cognition and emotion
have been progressively receiving more attention in recent times. Electroencephalogram (EEG)
signals, being an activity of central nervous system, can reflect the underlying true emotional
state of a person. This paper presents a computational framework for classifying PD patients
compared to healthy controls (HC) using emotional information from the brain’s electrical
activity. Approach: Emotional EEG data were obtained from 20 PD patients and 20 healthy age-,
gender- and education level-matched controls by inducing the six basic emotions of happiness,
sadness, fear, anger, surprise and disgust using multimodal (audio and visual) stimuli. In
addition, participants were asked to report their subjective affect. Because of the nonlinear and
dynamic nature of EEG signals, we utilized higher order spectral features (specifically,
bispectrum) for analysis. Two different classifiers namely K-Nearest Neighbor (KNN) and
Support Vector Machine (SVM) were used to investigate the performance of the HOS based
features to classify each of the six emotional states of PD patients compared to HC. Ten-fold
cross-validation method was used for testing the reliability of the classifier results.
Main Results: From the experimental results with our EEG data set, we found that (a)
classification performance of bispectrum features across ALL frequency bands is better than
individual frequency bands in both the groups using SVM classifier; (b) higher frequency band
plays a more important role in emotion activities than lower frequency band; and (c) PD patients
showed emotional impairments compared to HC, as demonstrated by a lower classification
performance, particularly for negative emotions (sadness, fear, anger and disgust). Significance:
These results demonstrate the effectiveness of applying EEG features with machine learning
techniques to classify the each emotional state difference of PD patients compared to HC, and

Emotions in PD patients

3

offer a promising approach for detection of emotional impairments associated with other
neurological disorders.
Keywords: electroencephalogram; emotion recognition; Parkinson’s disease; bispectrum; support
vector machine

Emotions in PD patients
1.

4

Background
Social communication and the ability to respond to emotional signals are essential for

meaningful interpersonal interactions. While Parkinson’s disease (PD) has traditionally been
defined as a motor system disorder (in the form of tremors, rigidity, and bradykinesia) [1], there
is growing evidence of cognitive and social deficits for people associated with this disease [2, 3].
Non-motor symptoms, including disruptions in processing of emotional information [4, 5] have
been found in over 50% of newly diagnosed PD patients [6] and can appear in any stage of
disease progression [7]. Interestingly, social cognitive dysfunction has been found before the
appearance of motor disturbances in PD [8].
Individuals with PD show impairments in the ability to recognize emotions from facial
expressions [9, 10], emotional prosody [11, 12] and show reduced startle reactivity to highly
arousing unpleasant pictures [13, 14]. There is sparse event related potential (ERP) evidence that
early processing of emotional prosody (mismatch negativity, [15]) and faces (show reduced
arousal ratings of highly arousing affective pictures, [16] and early posterior negativity [17]) may
be affected in PD. Still there is some controversy about which specific emotions are recognized
abnormally in PD. Some researchers report specific impairments in the recognition of fear and
sadness [18], whereas others have reported deficits in recognizing anger or disgust [9, 10], while
still others failed to report emotion recognition deficits [17, 19, 20]. Altogether, experimental
evidence so far supports the view of impairments in emotion processing in PD. Much of the
research in this area dealt with behavioral responses (self-ratings) i.e., participants were asked to
match, to identify, to judge, or to rate the emotional stimuli and physiological measures of
emotional experience (e.g., startle eye blink and ERPs). In addition, all the studies mentioned

Emotions in PD patients

5

above used traditional tools (i.e., statistical analysis) for the investigation of emotion-related
information processing in PD patients.
In recent years, numerous studies on engineering approaches to automatic emotion
recognition using machine learning techniques have been published, although research in this
field is relatively new compared to the long history of emotion research in psychology and
psychophysiology. In particular, many efforts have been deployed to recognize emotions using
facial expressions [21], speech signals [22] and gestures [23] in healthy controls (HC). Though
these modalities have been researched widely and have produced better results, they are all
susceptible to social masking. Emotions that are not expressed, emotions expressed differently
(an angry person may smile) or minor emotional changes that are invisible to the natural eye,
cannot be tracked by using these modalities [24]. These limitations lead the way to recognizing
emotions through physiological signals (or biosignals) [25]. As physiological signals reflects the
inherent activity of the autonomous nervous system (ANS) or the central nervous system (CNS),
social masking does not have any influence in recognizing true emotions felt by the person. This
approach also provides an opportunity to track minute emotional changes which cannot be
perceived visually or by hearing.
Biosignals such as electrocardiogram, galvanic skin response, electromyogram, skin
temperature, blood volume pressure, heart rate variability, and body temperature, and respiration
rate have been used to evaluate the emotional state of a person. In addition to these biosignals,
signals captured from the CNS, such as electroencephalogram (EEG), Magnetoencephalogram
(MEG), Positron Emission Tomography (PET), and functional Magnetic Resonance Imaging
(fMRI) have been proved to provide informative characteristics in response to emotional states.
Towards such a more reliable emotion recognition procedure, EEG [26] appears to be less

Emotions in PD patients

6

invasive and the one with best time resolution than the other three (MEG, PET, and fMRI). In
general, EEG signals have been widely used in order to study brain activity relating to affective
responses. Evidence of such activity is reported in the majority of EEG frequency bands such as
theta (4 – 8 Hz), alpha (8 – 13 Hz), beta (13 – 30 Hz) and gamma (30 – 49 Hz). For example,
frontal midline (Fm) theta power modulation is suggested to reflect affective processing during
emotional music [27]. The alpha-power asymmetry on the prefrontal cortex has been proposed
as an index for the discrimination between positively and negatively valenced emotions [28].
Beta activity has been associated with emotional arousal modulation [29]. Finally, gamma band
has been mainly suggested as related to arousal effects [30].
Nonlinear analysis has been applied to many areas such as medicine and biology over the
past decade. In particular, the nonlinear analysis method is effectively applied to EEG signals to
study the dynamics of the complex underlying behavior [31] and it is well known that the EEG
signals exhibit significant non-linear behavior [32]. Non-linear analysis based on chaos theory
helps in identifying the apparently irregular behaviors that were present in the system [33].
Several nonlinear features such as correlation dimension (CD), approximate entropy (AP),
largest lyapunov exponent (LLE), higher order spectra (HOS) and Hurst exponent (H) have been
used widely [34, 35] to characterize the EEG signal. In general, any analysis technique that can
detect and quantify some aspect of non-linear mechanisms, may better reflect the dynamics and
the characteristics of the EEG signal, and provide more realistic information about the
physiological and pathological state of the CNS, the phenomenon of non-linearity and deviations
of the signal from [36]. HOS are known to be useful to detect non-linearity and deviations from
Gaussian behavior.

Emotions in PD patients

7

Motivated by these, we set out to explore the relation between emotional states and EEG
frequency bands in PD patients compared to HC using a set of HOS based parameters as features
(specifically, bispectrum). Two different classifiers namely K-Nearest Neighbor (KNN) and
Support Vector Machine (SVM) were used to investigate the performance of the HOS based
features to classify each of the six emotional states (happiness, sadness, fear, anger, surprise and
disgust) of PD patients compared to HC. The remainder of the paper is organised as follows:
“Materials used” briefly presents the participants’ characteristics, emotion elicitation protocol,
and EEG recordings. “Methodology” presents the signal preprocessing, features extracted from
the bispectrum and the classifiers used. The results and discussion are presented in
“Experimental results and Discussion”. Finally, the paper is concluded in the last section.

2.

Materials used

2.1 Participants
Twenty PD patients (all right-handed) and 20 HC (all right-handed) matched for age,
gender, and education level participated in the study. Parkinson’s disease patients were recruited
from the clinic Neurology outpatient service of the Hospital University Kebangsaan Malaysia
(HUKM) medical center, Kuala Lumpur, Malaysia. All patients had been diagnosed with
idiopathic PD by a neurologist and were optimally medicated during the testing session (ON
state) with d2-agonist (n = 18); carbidopa/L-dopa (n = 13), monoamine oxidase B (MAO-B)
inhibitor (n = 7), catechol-O-methyltransferase (COMT) inhibitor (n = 5), amantadine (n = 5), or
anticholinergics (n = 3). The average duration of PD (post-diagnosis) in the group was 5.75 years
[standard deviation (SD) = 3.52, range = 1–12 years]. The severity of motor signs in the patient
group could be characterised as mild to moderate; all patients fit Hoehn and Yahr stages (H & Y)
[37] I – III (Stage I = unilateral disease with mild symptoms, Stage II = bilateral involvement,

Emotions in PD patients

8

Stage III = bilateral symptoms with postural and gait disturbances) with a mean Unified
Parkinson’s Disease Rating Scale (UPDRS) [38] motor score of 17.05 (SD = 3.15). None of the
patients had coexisting neurological (e.g., epilepsy) or psychiatric disturbances (e.g., major
depression or anxiety, psychotic symptoms, etc.) that might independently influence their
cognitive functioning.
The HC participants were recruited through the hospital community and/or from relatives
of PD patients. Exclusion criteria for controls included any psychiatric or neurological disorder.
To exclude dementia or depression, both of the groups scoring 24 or lower on the Mini-Mental
State Examination (MMSE) [39] or 18 or higher on the Beck Depression Inventory (BDI) [40]
were excluded. Handedness was determined by self-report and confirmed by Edinburgh
Handedness Inventory (EHS) [41]. This test consisted of 10 questions asking for the preferred
hand for a series of activities (e.g., writing, throwing, using scissors, etc.). All participants
reported normal or corrected-to-normal vision. Intact hearing was formally established in all
participants by administering a pure tone audiometric screening of both ears to ensure acceptable
normal hearing threshold (minimum 30 dB HL at 0.5, 1, 2, and 4 kHz, for the better ear). All
participants/caretakers gave informed consent before completing the study, which was ethically
approved by the Faculty of Medicine, Institutional Review Board of the HUKM. All participants
were paid 50 Malaysian Ringgits for their participation.
Patients and controls were comparable in demographic variables such as age (PD: mean
age: 59.05 ± 5.64; HC: mean age: 58.10 ± 2.95; t (38) = 0.667, p = 0.509), gender distribution
(PD: 10 men, HC: 09 men; x2 (1, N = 40) = 0.100, p = 0.752), and education level (PD: 10.45 ±
4.86 years; HC: 11.05 ± 3.34 years; t (38) = -0.455, p = 0.652). Table 1 lists the demographic
and clinical characteristics of the analyzed PD patients and HC participants. As can be seen from

Emotions in PD patients

9

the table, the groups did not significantly differ in mean MMSE scores, mean BDI scores as well
as mean EHI scores.
2.2 Stimulus material
Gathering good and meaningful data are essential in any signal processing application. In
works related to emotion recognition using physiological signal, acquiring emotional data that
corresponds to specific emotional state is challenging, because of the subjective nature of the
emotions and cognitive dependence of physiological signals which requires the emotional states
have to be elicited internally in the participant. Until now, most studies on emotion recognition
in PD have used only facial stimuli, prosodic stimuli, or music stimuli [4, 5, 42]. In addition, a
number of emotion induction techniques using pictures, sounds, music, or multimodal
approaches (combination of audio and visual) have been used to elicit target emotions in healthy
controls [26, 43-46]. Among all of these stimuli modalities researchers have identified that
multimodal stimuli induce emotions in the participants more naturally and more effectively
compared to other modalities [25, 45-47]. In this work, we utilised a multimodal approach to
evoke six basic emotions (happiness, sadness, fear, surprise, and disgust) that are universally
accepted.
The emotional stimuli we used were taken from different sources, such as the
International Affective Picture System (IAPS) database [48], International Affective Digitized
Sounds (IADS) [49] database and video clips (e.g., funny animals, wonder activities by humans,
etc.) collected from various resources on the internet (e.g., YouTube, Facebook, and others) [24].
The elicitation of emotions such as sad, fear, and disgust was attained by using affective pictures
from IAPS and sounds from IADS databases. Various psychological and psychophysiological
experiments have revealed that these stimuli sets have great potential in the investigation of sad,

Emotions in PD patients

10

fear, and disgust emotion [43, 50]. In addition, Mikels et al. [51] and Redondo et al. [52]
provided a more complete characterisation of the categorical structure of the IAPS and IADS
stimuli set, with the objective of identifying images and sounds that elicit one discrete emotion
more than other emotions. The IAPS pictures1 [disgust: valence- mean ± SD = 2.43 ± 1.51,
arousal mean ± SD = 5.90 ± 2.25; fear: valence mean ± SD = 3.80 ± 1.89, arousal mean ± SD =
5.85 ± 2.12; sadness: valence- mean ± SD = 2.74 ± 1.57, arousal mean ± SD = 5.00 ± 2.08] and
IADS sound2 [disgust: valence mean ± SD = 4.00 ± 1.72, arousal mean ± SD = 5.82 ± 1.93; fear:
valence mean ± SD = 4.00 ± 1.72, arousal mean ± SD = 5.82 ± 1.93; sadness: valence mean ±
SD = 3.28 ± 1.65, arousal mean ± SD = 6.61 ± 1.89] were selected and combined together
according to their arousal and valence values provided in the databases. For example, a
negative/high aroused sound was matched with a negative/high aroused image. On the other
hand, the emotions happiness, surprise, and anger were elicited using video clips. A pilot study
was conducted to identify the video clip that was better able to elicit the target emotion in the
participants. Ninety video clips corresponding to happiness, surprise, and anger were displayed
to thirty volunteers with a mean age of 26.4 years (ranging from 24 to 45 years). All of the
participants were psychology teachers or students at the UKM medical center, Kuala Lumpur. Of
these, 30 clips with the highest ratings were chosen for data collection. Table 2 shows the
summary of emotion induction stimulus material [see supplementary file 1].
1

The following pictures in the database were used for emotion induction: Disgust: 1945, 2352.2,

3000, 3010, 3015, 3030, 3051, 3060, 3061, 3071, 3080, 3110, 3120, 3130, 3140, 3150,3160,
3250, 3400, 7360, 7361, 7380, 8230, 9040, 9042, 9181, 9290, 9300, 9320, 9330, 9373, 9390,
9405, 9490, 9570, 9830; Fear: 1019, 1022, 1030, 1040, 1050, 1051, 1052, 1070, 1080, 1090,
1110, 1111, 1113, 1120, 1200, 1201, 1220, 1230, 1240, 1280, 1274, 1300, 1301, 1302, 1321,

Emotions in PD patients

11

1390, 1930, 1931, 3280, 5970, 5971, 5972, 6370, 9584, 9594, 9592; Sadness: 2205, 2271, 2276,
2490, 2520, 2590, 2700, 2800, 2900, 3220, 3230, 3300, 3301, 3350, 6570, 6838, 8010, 9000,
9041, 9050, 9120, 9190, 9210, 9220, 9331, 9410, 9415, 9470, 9520, 9530, 9561,9611, 9910,
9911, 9920, 9921.
2

The following sounds in the database were used for emotion induction: Disgust: 134, 115, 251,

262, 284, 698, 702, 711, 712, 713, 714, 720, 728, 729, 730, 732, 812, 813; Fear: 106, 133, 170,
171, 275, 276, 277, 279, 291, 312, 378, 380, 424, 425, 500, 626, 627, 699, 817; Sadness: 115,
150, 260, 261, 278, 280, 285, 286,290, 293, 295, 310, 311, 368, 403, 420, 422, 501, 600, 625.
2.3 Emotion elicitation protocol
An illustrated representation of the emotion elicitation protocol is shown in Figure 1(a).
As shown in the figure, the protocol had two sessions of three trials each. There was a break of
10–15 minutes between the sessions. The participants were allowed to relax during the break
since the continuous assessment would have been too exhausting. The multimodal stimuli
relating to all the six emotional states (happiness, sadness, fear, anger, surprise and disgust) were
displayed in each trial in a random order. Each combination of picture and sound was presented
for 6-seconds [22]. To maximise the participants’ emotional response, each clip block consisted
of six combinations of the same emotional category and lasted for 36-seconds. In addition, each
of the video clips varied from 36–45 seconds in duration, depending on the length of the clip.
Neutral images, which can calm down the participants, were displayed for 10 seconds at the start
of each trial. This would help the participants return to the normal or neutral state away from
emotional excitation. Besides, a 15 second rating interval [53] was provided between the clips in
which participants answered a five point self-assessment questionnaire. Each session took
approximately 30 minutes.

Emotions in PD patients

12

2.4 Procedure
The purpose of the study was clearly explained to the participants before initiating the
experiment. The participants were further requested to relax, minimise their bodily movements
(as much as possible, to reduce the appearance of undesired artifacts in the EEG recordings), and
concentrate on the emotional stimuli. The self-guided emotion elicitation protocol was then
displayed on the screen. The complete experimental set up is shown in Figure 1(b). At the end of
each clip, participants filled a self-assessment questionnaire to state the status of the emotions
they felt during the experiment; they were also asked to report the strength of the emotions using
a five-point scale according to the degree (1 = very low, 2 = low, 3 = medium, 4 = high, and 5 =
very high). These ratings were then used to understand the intensity of the emotional state they
experienced. However, despite the intensity levels, all emotional data were taken into
considerations. The participants were also allowed to indicate multiple emotions during the
experiment. An example of the self-assessment questionnaire is shown in Figure 1(c).
2.5 EEG recordings
EEG recordings were conducted using the Emotive EPOC 14 channel EEG wireless
recording headset (Emotive Systems, Inc., San Francisco, CA) [54]. The electrode scheme was
arranged according to the international 10–20 system and included active electrodes at AF3, F7,
F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, and AF4 positions, referenced to the common
mode sense (CMS-left mastoid)/driven right leg (DRL-right mastoid) ground as shown in Figure
1(d). The acquired data were digitised using the embedded 16-bit ADC with 128 Hz sampling
frequency per channel and sent to the computer via wireless communication, which utilises a
proprietary USB dongle to communicate using the 2.4 GHz band. Sample EEG recordings of PD

Emotions in PD patients

13

patient and HC corresponding for six emotional states are given in Figures 2 (a) and 2(b),
respectively.
3.

Methodology

3.1 Signal preprocessing
First, the time waves of EEG data were pre-processed using thresholding method to remove
eye blinking artifacts, in which data that are found to have amplitudes of more than 80 µV are
discarded from the study. Second, a 6th order bandpass Butterworth filter (with forward reverse
filtering algorithm) was used to extract the frequency range of 1–49 Hz. The focus was placed
upon the five EEG frequency bands, i.e., delta (1–4), theta (4–8 Hz), alpha (8–13 Hz), beta (13–
30 Hz) and gamma (30–49). Third, each channel of the EEG signal was segmented into six
seconds epoch without overlapping using time-windows [55]. Finally, features discussed below
were computed using each epoch of the EEG data.
3.2 Feature extraction
The main task of the feature extraction stage was to derive the salient features which can
map the EEG data into corresponding emotional states. In this work, we have used HOS based
features to investigate each of the six emotional states difference of PD patients compared to HC.
3.2.1 Bispectrum computation
Higher order spectra (also known as polyspectra) are the spectral representations of higher
order statistics, i.e., moments or cumulants of third and higher orders. In particular, we have
studied features related to the third-order statistics of the signal, namely, the bispectrum. The
bispectrum is the Fourier transform of the third order correlation of the signal and is given by,
B( f1, f 2 ) = E[ X ( f1 ) X ( f 2 ) X * ( f1 + f 2 )]

(1)

Emotions in PD patients

14

where B( f1 , f 2 ) is the bispectrum in the bifrequency ( f1 , f 2 ) , X ( f ) is the discrete time Fourier
transform (FT) of the given signal, * denotes complex conjugate. X ( f ) is the discrete time
Fourier transform for deterministic signals computed with discrete frequency samples using Fast
Fourier Transform (FFT) algorithm. The frequency f may be normalized by the Nyquist
frequency to be between 0 and 1. The bispectrum given by equation (1) is a complex valued
function of two frequency variables. It is well known that the FT of a real-valued signal shows
conjugate symmetry, and the power spectrum is redundant in the negative frequency region.
Likewise, the bispectrum, which is the product of three Fourier coefficients, exhibits symmetry
and therefore, was computed in the non-redundant region [56]. Assuming that there is no
bispectral aliasing, the bispectrum of a real valued signal is uniquely defined with the triangle

0 £ f 2 £ f1 £ f1 + f 2 £ 1 . This is termed as the principal domain or the non-redundant region,
denoted as W (the triangle region) in Figure 3. The extracted bispectral based features are:
i) Mean of bispectral magnitude: M avg =

1
å W B( f1, f 2)
L

(2)

where L is the number of points within the region.

ii) Normalised bispectral entropy (BE1): P1 = -å pk log( pk )

(3)

k

where pk =

B( f1 , f 2 )
, W = region as in Fig. (3)
åW B( f1, f 2 )

iii) Normalised bispectral squared entropy (BE2): P2 = -å qn log( qn )
n

where qn =

B( f1 , f 2 )

2

åW B( f1, f 2 )

2

, W = region as in Fig. (3)

(4)

Emotions in PD patients

15

The absolute value or magnitude and the square of the magnitude are the L1 and L2 norms
of the bispectrum. For both of these entropies, normalisation was done by the sum of the norm
over W which is the complete non-redundant bi-frequency region, such that each norm is now
similar to a probability distribution function (PDF) with values estimated over the W region.
These PDFs are one-dimensional histograms of these values. They allow entropies, namely P1
and P2 , to be defined and calculated.
In order to calculate above bispectral features across each frequency band of PD patients
and healthy controls, we used epochs of 768 samples with hanning window of 50% overlap
corresponding to six seconds at the given sampling rate. These epochs were taken from each
record of 1024 NFFT points.
3.3 Classification of emotional states
Twenty participants from each group with six trials and six epochs per channel resulted in a
total of 720 x 14 EEG data samples per emotion, which were processed. All the three HOS
features were extracted from these samples. The performance of the emotional feature between
PD patients and healthy controls were analyzed using KNN and SVM classifiers across different
EEG bands. We also tested other classification techniques such as linear discriminant analysis,
probabilistic neural network and Naive Bayes. However, these results are not superior to those
obtained with KNN and SVM methods and hence are not reported.
The KNN is a simple data-driven lazy learning algorithm, where an unlabeled point is
attributed to the predominant class within the k-nearest labeled points belonging to the training
class [57]. Euclidean distance was used as a measure to assess the similarity of testing points.

Emotions in PD patients

16

Euclidean distance was calculated using the below formula. In this work, different values of k
between 1 and 10 were tested.
N

DE = (a, b) = å (ai - bi ) 2

(5)

i =1

where a and b are the training and testing data, respectively and N is the number of features.
In SVM, a separating hyperplane that maximizes the margin between the input data classes
which are viewed in an n-dimensional space (n is the number of features used as inputs) is
determined. In general, a larger margin results in a lower generalization error. SVM can be easily
adapted to nonlinearly separable data by the use of kernal functions to map the data to a much
higher dimensional space where the data becomes more separable [58]. The radial basis function
(RBF) kernel and polynomial kernel are most commonly used [59]. With the use of kernels, an
explicit transformation of the data to the feature space is not required. In this work, we have used
RBF kernel function. The performance parameters of SVM (regularization constant, C and width
of the RBF kernal, s ) were obtained by using the grid search approach [60]. To achieve better
accuracy, the suitable values of C and s were given by this algorithm as 108 and 2.434,
respectively.
In this work, ten-fold cross validation method was used to test the performance and
reliability of the classifiers. During this method, the dataset is divided randomly in ten equal (or
approximately equal) subsets and for each fold nine subsets are used for training and one subset
for testing. The procedure is repeated ten-times (ten-folds) in order for all subsets to be used as
testing data. Classification performance was mainly evaluated through the classification accuracy
(CA) and was computed for each emotional states between PD patients and HC as,

Emotions in PD patients
ガ#˚˚­̇ø˚

岫牒帖"塚鎚"張寵岻

噺

17
択探鱈但奪嘆誰脱"達誰嘆嘆奪達担狸湛"達狸叩坦坦辿ピ辿奪辰"脱奪叩担探嘆奪"旦奪達担誰嘆坦曇尿任禰日任韮
鐸誰担叩狸"樽探鱈但奪嘆"誰脱"担奪坦担奪辰"脱奪叩担探嘆奪"旦奪達担誰嘆坦曇尿任禰日任韮

":"などど

(6)

where 継兼剣建件剣券 refers to one of the six emotional state of PD patients compared to healthy
controls (i.e., *̇ııÆº̋œœ岫牒帖"塚鎚"張寵岻 , 5̇¸º̋œœ岫牒帖"塚鎚"張寵岻 , (̋̇ø岫牒帖"塚鎚"張寵岻 , #º̌ø

牒帖"塚鎚"張寵 ,

5­øıøÆœ̋岫牒帖"塚鎚"張寵岻 , and &Æœ̌­œß 岫牒帖"塚鎚"張寵岻 ) across delta, theta, alpha, beta, gamma EEG frequency

bands and ALL (combination of five frequency bands). The overall performance of the classifier
was evaluated by taking the average and standard deviation (SD) of the accuracies of ten-folds.
Here, the SD of the classification clearly reveals the consistency of the classifier results and the
number of classes used for classification here was two.
4. Experimental results and discussion
Table 2 shows the results of the self-assessment phase (in percentage) for each of six
emotional states between PD patients and HC. From the table, it can be observed that the
subjective response accuracy to emotional stimuli confirmed that the participants were almost
able to induce the expected emotions and to investigate the correspondence in EEG responses. It
should be also noted that the happiness stimuli were recognised most easily (% average CA =
93.42) whereas, stimuli related to disgust emotion were recognised the worst (% average CA =
69.58).
Table 3(a)–3(e) shows the range of three features used for classification obtained from PD
patients compared to HC for each of the six emotional states across delta, theta, alpha, beta and

gamma frequency bands [see supplementary file 1]. From the tables, it can be observed that there
is a decrease in the values of the extracted features from PD patient’s EEG signals as compared
to the healthy controls during emotion processing. This is due to the dynamic processes
underlying the EEG recording that are less complex for PD patients than healthy controls. This

Emotions in PD patients

18

confirms to other studies that there will be decrease in brain complexity during emotion
processing due to the dysfunction in the neural circuits [10, 61, 62].
The statistical significance of all the three features was studied using analysis of variance
(ANOVA). The threshold was set to p = 0.05 and all the three features showed statistical
significance (p < 0.05) indicating that the each of the six emotional states of PD patients and HC
have significant difference in the feature values, for all cases studied. This would also ensure a
higher probability of achieving better classification accuracy in discriminating the emotional
states between the groups.
Table 4(a)–4(f) presents the classification performance of HOS based features to
distinguish each of the six emotional states of PD patient’s compared to HC across delta, theta,
alpha, beta, gamma and ALL bands using KNN and SVM classifier. From tables, several
important observations can be drawn, for all the cases studied. First, it can be noted that the
classification performance of HOS based features across ALL frequency bands is better than
those based on individual frequency bands in both the groups. Second, it is found that the
classification performance of alpha, beta, and gamma is obviously better than those of delta and
theta bands in discriminating the emotional state EEG between PD patients compared to HC.
This result partly reflects that higher frequency bands play a more important role in emotion
activities than lower frequency bands [63-65]. The current finding matches our previous study,
where bispectrum emotion-specific features were mainly related to higher frequency band rather
than lower frequency band in distinguishing six emotional states (happiness, sadness, fear, anger,
surprise, and disgust) of PD patients and HC respectively with an averaged recognition rate of
70.10% ± 2.83% and 77.29% ± 1.73% [55]. These clearly suggest that EEG signals, being an
activity of CNS, can reflect the underlying inherent emotional state of PD patients.

Emotions in PD patients

19

Third, PD patients achieved less classification performance for negative emotions
(sadness, fear, anger and disgust), whereas classification performance for happiness and surprise
emotion was comparable between PD patients and HC. This suggests that the results from PD
patients with lower accuracy are those where EEG features are not reflecting the emotions,
which can be interpreted as impairment in the brain processing of emotions, particularly for
negative emotions. Recent evidence points to neuropathological changes in PD in many brain
areas which are assumed to play key roles in emotion processing [66]. These include limbic
structures such as the amygdala, and the ventral striatum, which is centrally located within the
basal ganglia’s limbic loop. Furthermore, our results are comparable with the more general
hypothesis that a loss of complexity appears when the biological systems become functionality
impaired [67, 68].
Finally, the average classification performance of SVM out performs KNN classifier. For
PD patients, the classification accuracy of HOS features across ALL frequency bands using
SVM under each emotional state was: 86.89 % ± 1.74% for happiness, 82.56% ± 2.09% for
sadness, 79.99% ± 3.48% for fear, 80.98% ± 5.28% for anger, 91.27% ± 4.04% for surprise, and
80.57% ± 3.38% for disgust. For healthy controls, the classification accuracy of HOS features
across ALL frequency bands using SVM under each emotional state was: 94.76% ± 2.28% for
happiness, 93.86% ± 3.92% for sadness, 91.74% ± 1.38% for fear, 90.86% ± 2.48% for anger,
94.98% ± 3.84% for surprise and 93.39% ± 2.97% for disgust. This definitely proves the
robustness of the SVM over KNN classifier for these datasets. Furthermore, this study provided a
different viewpoint and new insights into emotional responses to PD patients. So far, no related
work that specifically attempted the EEG frequency band based emotion classification in PD

Emotions in PD patients

20

patients using machine learning techniques has been reported in the literature and therefore, it
was difficult for the acquired results to be compared.
Some limitations of our study should be pointed out. First, the use of small number of PD
samples which can affect the reliability of the system. Future studies should use larger number of
PD patients to examine the relationship between brain activity and emotions. Second, the present
study was limited by the fact that the PD sample consisted of PD patients in H & Y 1–3 stage,
only, and all patients had ON-medication UPDRS motor scores mean value of 17.05. Thus, our
finding is limited by the fact that persons with severe PD were not included in the study (H & Y
4–5 stage). Further research would explore this limitation. Finally, all PD patients were under
dopamine replacement therapy, which might also affect the performance in the emotion
processing [69] and future research is required with unmedicated patients to reveal the actual
effects on PD [70].
5. Conclusion

This study indicates that EEG signals are reliable in identifying the inherent emotional state
of PD patients. The design of data acquisition protocol for eliciting the six emotional states
(happiness, sadness, fear, anger, surprise and disgust) and the data acquisition methodology were
explained in detail. Since the EEG signal is non-linear, non-stationary, and non-Gaussian in
nature, non-linear features such as bispectrum were used to classify each of the six emotional
states difference between PD and HC. The performance of the extracted features was analysed
using two classifiers namely KNN and SVM. Experimental results demonstrate that
classification performance of bispectrum features across ALL frequency bands was better than
those based on individual frequency bands in both the groups using SVM classifier. We also
found that high frequency bands play a more important role in emotion activities than low

Emotions in PD patients
frequency band. PD patients showed emotional impairments than HC, as demonstrated by a
lower classification performance, particularly for negative emotions. Quantitative measure to
assess emotional states may have a wide range of clinical applications in patient populations,
including expression training, assessment of treatment effects and detection of persons at risk.

21

Emotions in PD patients

22

Acknowledgements
The research was financially supported by Ministry of Science and Technology (MOSTI),
Malaysia. Grant Number: 9005-00053. The authors would like to thank Dr. Mohamad Fadli, Dr.
Siva Rao Subramanian and Dr. Shahrul Azmin for their assistance with recruitment of PD
participants. Also we would like to thank all of the individuals who participated in this study.

Emotions in PD patients

23

References
[1] J.M. Savitt, V.L. Dawson, T.M. Dawson, Diagnosis and treatment of Parkinson disease:
molecules to medicine, The Journal of Clinical Investigation 116 (2006) 1744-1754.
[2] E. Mohr, J. Juncos, C. Cox, I. Litvan, P. Fedio, T.N. Chase, Selective deficits in cognition
and memory in high-functioning Parkinsonian patients, Journal of Neurology Neurosurgery
and Psychiatry 53 (1990) 603-606.
[3] B. Pillon, B. Dubois, Y. Agid, Testing cognition may contribute to the diagnosis of
movement disorders Neurology 46 (1996) 329-334.
[4] H.M. Gray, L. Tickle-Degnen, A meta-analysis of performance on emotion recognition tasks
in Parkinson's disease, Neuropsychology 24 (2010) 176-191.
[5] J. Péron, T. Dondaine, F.L. Jeune, D. Grandjean, M. Vérin, Emotional processing in
Parkinson's disease: a systematic review, Movement Disorder 27 (2012) 186-199.
[6] C. Janvin, D. Aarsland, J.P. Larsen, K. Hugdahl, Neuropsychological Profile of Patients with
Parkinson’s Disease without Dementia, Dementia and Geriatric Cognitive Disorders 15
(2003) 126-131.
[7] A. Park, M. Stacy, Non-motor symptoms in Parkinson’s disease, Journal of Neurology 256
(Suppl.3) (2009) S293-S298.
[8] M. Kawamura, S. Koyama, Social cognitive impairment in Parkinson’s disease, Journal of
Neurology, 254 (Suppl 4) 2007 S49-S53.
[9] U.S. Clark, S. Neargarder, A. Cronin-Golomb, Specific Impairments in the Recognition of
Emotional Facial Expressions in Parkinson’s Disease, Neuropsychologia 46 (2008) 23002309.

Emotions in PD patients

24

[10] A.D. Lawrence, I.K. Goerendt, D.J. Brooks, Impaired recognition of facial expression of
anger in Parkinson’s disease patients acutely withdrawn from dopamine replacement therapy,
Neuropsychologia 45 (2007) 65-74.
[11] C. Dara, L. Monetta, M.D. Pell, Vocal emotion processing in Parkinson's disease: Reduced
sensitivity to negative emotions, Brain Research 1188 (2008) 100-111.
[12] S. Paulmann, M.D. Pell, Dynamic emotion processing in Parkinson's disease as a function
of channel availability, Journal of Clinical Experimental Neuropsychology 32(8) (2010) 822835.
[13] D. Bowers, K. Miller, A. Mikos, L. Kirsch-Darrow, U. Springer, H. Fernandez, K. Foote,
M. Okun, Startling facts about emotion in Parkinson's disease: blunted reactivity to aversive
stimuli, Brain 129 (2006) 3356-3365.
[14] K.M. Miller, M.S. Okun, M. Marsiske, E.B. Fennell, D. Bowers, Startle reflex
hyporeactivity in Parkinson's disease: an emotion-specific or arousal-modulated deficit?,
Neuropsychologia 47 (2009) 1917-1927.
[15] C. Schröder, J. Möbes, M. Schütze, F. Szymanowski, W. Nager, M. Bangert, T.F. Münte, R.
Dengler, Perception of emotional speech in Parkinson's disease, Movement Disorder 21
(2006) 1774-1778.
[16] M.J. Wieser, A. Muhlberger, G. Alpers, M. Macht, H. Ellgring, P. Pauli, Emotion
processing in parkinson's disease: Dissociation between early neuronal processing and
explicit ratings, Clinical Neurophysiology 117 (2006) 94-102.
[17] M.J. Wieser, E. Klupp, P. Weyers, P. Pauli, D. Weise, D. Zeller, J. Classen, A. Muhlberger,
Reduced early visual emotion discrimination as an index of diminished emotion processing

Emotions in PD patients

25

in Parkinson’s disease? - Evidence from event-related brain potentials, Cortex 48 (2012)
1207-1217.
[18] A. Ariatti, F. Benuzzi, P. Nichelli, Recognition of emotions from visual and prosodic cues
in Parkinson’s disease, Neurological Sciences 29 (2008) 219-227.
[19] M.D. Pell, C.L. Leonard, Facial expression decoding in early parkinson's disease, Cognition
Brain Research 23 (2005) 327-340.
[20] P. Garrido-Vásquez, M.D. Pell, S. Paulmann, K. Strecker, J. Schwarz, S.A. Kotz, An ERP
study of vocal emotion processing in asymmetric Parkinson's disease, Social and Cognitive
Affective Neuroscience 8 (2013) 918-927.
[21] I. Cohen, A. Garg, T.S. Huang, Emotion Recognition from Facial Expressions using
Multilevel HMM, Proceedings of Neural information Processing Systems Workshop
Affective Computing (2000).
[22] J. Kim, Bimodal emotion recognition using speech and physiological changes, Technical
Report, (2007).
[23] L. Kessous, G. Castellano, G. Caridakis, Multimodal emotion recognition in speech-based
interaction using facial expression, body gesture and acoustic analysis, Journal of
Multimodal User Interfaces 3 (2010) 33-48.
[24] S. Jerritta, M. Murugappan, K. Wan, S. Yaacob, Classification of emotional states from
electrocardiogram signals: a non-linear approach based on Hurst, Biomedical Engineering
Online 12 (2013) 44-62.
[25] K.H. Kim, S.W. Bang, S.R. Kim, Emotion recognition system using short-term monitoring
of physiological signal, Medical & Biological Engineering and Computing 42 (2004) 419427.

Emotions in PD patients

26

[26] P.C. Petrantonakis, L.J. Hadjileontiadis, A novel emotion elicitation index using frontal
brain asymmetry for enhanced EEG-based emotion, IEEE Transactions on Information
Technology in Medicine 15 (2011) 737-746.
[27] D. Sammler, M. Grigutsch, T. Fritz, S. Koelsch, Music and emotion: electrophysiological
correlates of the processing of pleasant and unpleasant music, Psychophysiology 44 (2007)
293-304.
[28] L.A. Schmidt, L.J. Trainor, Frontal brain electrical activity (EEG) distinguishes valence and
intensity of musical emotions, Cognition and Emotion 15 (2001) 487-500.
[29] L.I. Aftanas, N.V. Reva, L.N. Savotina, V.P. Makhnev, Neurophysiological correlates of
induced discrete emotions in humans: An individually oriented analysis, Neuroscience and
Behavioral Physiology 36 (2006) 119-130.
[30] M. Balconi, C. Lucchiari, Consciousness and arousal effects on emotional face processing
as revealed by brain oscillations: a gamma band analysis, International Journal of
Psychophysiology 67 (2008) 41-46.
[31] R.A. McCarthy, E.K. Warrington, Cognitive Neuropsychology: A Clinical Introduction,
Academic Press, San Diego, LA, (1990).
[32] C.J. Stama, J.P.M. Pijn, P. Suffczynski, F.H. LopesdaSilvab, Dynamics of the human alpha
rhythm: evidence for non-linearity?, Clinical Neurophysiology 110 (1999) 1801-1831.
[33] J. Gao, J. Hu, W. Tung, Facilitating Joint Chaos and Fractal Analysis of Biosignals through
Nonlinear Adaptive Filtering, Plos One 6 (2011) 1-8.
[34] T. Balli, R. Palaniappan, Classi"cation of biological signals using linear and nonlinear
features, Physiological Measurements 31 (2010) 903-920.

Emotions in PD patients

27

[35] K.C. Chua, V. Chandran, U.R. Acharya, C.M. Lim, Application of higher order spectra to
identify epileptic EEG, Journal of Medical Systems 35 (2011) 1563-1571.
[36] M. Shen, F.H.Y. Chan, L. Sun, F.J. Beadle, Parametric bispectral estimation of EEG signals
in different functional states of the brain, IEEE Proceedings of Science and Measurements
Technology 147(6) (2000).
[37] M.M. Hoehn, M.D. Yahr, Parkinsonism: Onset, Progression and mortality, Neurology, 17
(1967) 427-442.
[38] S. Fahn, R.L. Elton, M. Committee, Unified Parkinson's Disease Rating Scale, in: Fahn's,
Marsden CD, Calne DB, Goldstein M, Clane DB, Recent Developments in Parkinson's
disease, Macmillan Health Care Information, Florham Park, 1987, pp.153-163.
[39] M.F. Folstein, S.E. Folstein, P.R. Mchugh, Mini-Mental State Examination: a practical
method for grading the cognitive state of patients, Psychology Research 12 (1975) 189-198.
[40] A.T. Beck, C.H. Ward, M. Mendelson, J. Mock, J. Erbaugh, An inventory for measuring
depression., Achieves of General Psychiatry 4 (1961) 561-571.
[41] R.C. Oldfield, The assessment and analysis of handedness: the Edinburgh inventory,
Neuropsychologia 9 (1971) 97-113.
[42] C.F. Lima, C. Garrett, S.L. Castro, Not all the sounds sound the same: Parkinson's disease
affects differently emotion processing in music and in speech prosody, Journal of Clinical
and Experimental Neuropsychology 35 (2013) 373-392.
[43] T. Baumgartner, M. Esslen, L. Jancke, From emotion perception to emotion experience:
Emotions evoked by pictures and classical music, International Journal of Psychophysiology
60 (2006) 34-43.

Emotions in PD patients

28

[44] R.J. Davidson, Anterior cerebral asymmetry and the nature of emotion, Brain and Cognition
20 (1) (1992) 125-151.
[45] J.J. Gross, R.W. Levenson, Emotion elicitation using films, Cognition and Emotion 9 (1995)
87-108.
[46] M. Murugappan, M. Rizon, R. Nagarajan, S. Yaacob, An Investigation on Visual and
Audiovisual Stimulus based Human Emotion Recognition using EEG, International Journal
of Medical Engineering and Informatics (IJMEI) 1 (2009) 342-356.
[47] Y. Wang, L. Guan, Recognizing Human Emotional State From Audiovisual Signals, IEEE
Transactions on In Multimedia 10 (2008) 659-668.
[48] P.J. Lang, M.M. Bradley, B.N. Cuthbert, International affective picture system (IAPS):
Affective ratings of pictures and instruction manual, Technical Report A-8, University of
Florida, Gainesville, FL (2008).
[49] M.M. Bradley, P.J. Lang, International affective digitized sounds (2nd Edition; IADS-2):
Affective ratings of sounds and instruction manual, Technical Report B-3 University of
Florida, Gainesville, FL (2007).
[50] L. Brown, B. Grundlehner, J. Penders, Towards wireless emotional valence detection from
EEG, IEEE Engineering in Medicine and Biology Society, (2011) 2188-2191.
[51] J. Mikels, B. Fredrickson, G. Larkin, C. Lindberg, S. Maglio, P. Reuter-Lorenz, Emotional
Category data on images from the international affective picture system, Behavioral Research
Methods, 37 (2005) 630-636.
[52] J. Redondo, I. Fraga, I. Padron, A. Pineiro, Affective ratings of sound stimuli, Behavioral
Research Methods, 40 (2008) 784-790.

Emotions in PD patients

29

[53] H. Hamdi, P. Richard, A. Suteau, P. Allain, Emotion assessment for affective computing
based on physiological responses, IEEE proceedings of World Congress on Computational
Intelligence (2012) 10-15.
[54] S.K. Hadjidimitriou, L.J. Hadjileontiadis, Toward an EEG-based recognition of music liking
using time-frequency analysis, IEEE Transactions on Biomedical Engineering 59 (2012)
3498-3510.
[55] R. Yuvaraj, M. Murugappan, M.I. Norlinah, M. Iqbal, K. Sundaraj, K. Mohamad, R.
Palaniappan, M. Satiyan, Emotion classification in Parkinson's disease by higher-order
spectra and power spectrum features using EEG signals: A comparative study, Journal of
Integrative Neuroscience 13 (2014) 1-32.
[56] C.L. Nikias, A. Petropulu, Higher-order spectral Analysis: A Nonlinear signal Processing
Framework, Prentice Hall, Englewood Cliffs, NJ, (1993).
[57] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann, 2nd
edition, (2006).
[58] K.R. Muller, S. Mika, G. Ratsch, K. Tsuda, B. Scholkopf, An introduction to kernal based
learning algorithms, IEEE Transactions on Neural Networks 12 (2001) 181-201.
[59] N. Christianini, J. Taylor, Support vector machines and other kernal-based learning
methods, Cambridge University Press, Cambridge, (2000).
[60] C.W. Hsu, C.C. Chang, C.J. Lin, A practical guide to support vector classification.,
Technical report, Department of Computer Science, National Taiwan University (2003).
[61] A. Suzuki, T. Hoshino, K. Shigemasu, M. Kawamura, Disgust-specific impairment of facial
expression recognition in Parkinson’s disease, Brain 129 (2006) 707-717.

Emotions in PD patients

30

[62] T.P. Bouchard, N. Malykhin, W.R. Martin, C.C. Hanstock, D.J. Emery, N.J. Fisher, R.M.
Camicioli, Age and dementia-associated atrophy predominates in the hippocampal head and
amygdala in Parkinson's disease, Neurobiology of Aging 29 (2008) 1027-1039.
[63] W. Klimesch, EEG alpha and theta oscillations reflect cognitive and memory performance:
a review and analysis, Brain Research Reviews 29 (1999) 169-195.
[64] D.J. Oathes, W.J. Ray, Worry, generalized anxiety disorder, and emotion: evidence from the
EEG gamma band, Biological Psychology 79 (2008) 165-170.
[65] X.W. Wang, D. Nie, B.L. Lu, Emotional state classification from EEG data using machine
learning approach, Neurocomputing, 129 (2013) 94-106.
[66] H. Kober, L.F. Barrett, J. Joseph, E. Bliss-Moreau, K. Lindquist, T.D. Wagera, Functional
grouping and cortical–subcortical interactions in emotion: A meta-analysis of neuroimaging
studies, Neuroimage 42 (2008) 998-1031.
[67] J. Roschke, J. Fell, P. Beckmann, Nonlinear analysis of sleep EEG data in schizophrenia:
calculation of the principal Lyapunov exponent, Psychiatric Research, 56 (1995) 257-269.
[68] J. Jeong, S.Y. Kim, S.H. Han, Non-linear dynamical analysis of the EEG in Alzheimer’s
disease with optimal embedding dimension, Electroencephalography and Clinical
Neurophysiology 106 (1998) 220-228.
[69] A. Tessitore, A. Hariri, F. Fera, W. Smith, T. Chase, T. Hyde, D. Weinberger, V. Mattay,
Dopamine modulates the response of the human amygdala: A Study in Parkinson's disease,
Journal of Neuroscience 22 (2002) 9099-9103.
[70] R. Sprengelmeyer, A.W. Young, K. Mahn, U. Schroeder, D. Woitalla, T. Büttner, W. Kuhn,
H. Przuntek, Facial expression recognition in people with medicated and unmedicated
Parkinson’s disease, Neuropsychologia 41 (2003) 1047-1057.

Figure

EEG emotion recognition in PD

Fig. 1 (a) Schematic representation of the experiment protocol

Fig. 1 (b) Experimental setup for emotion assessment using multimodal stimuli

EEG emotion recognition in PD

Fig. 1 (c) Self-assessment questionnaire

Fig. 1 (d) Electrode positions, according to the 10-20 system, of the Emotiv EPOC device used for EEG
acquisition.

EEG emotion recognition in PD

(a)

(b)

Fig. 2 Sample recording of EEG signals corresponding to six emotions (a) PD patients (b) healthy
controls

Fig. 3 Non-redundant region (W) of computation of the bispectrum for real signals

Table

Table 1 Demographic and clinical characteristics of PD patients and HC.

Variable

PD (n = 20)

HC (n = 20)

Test's Value

Statistical result*

Age (years)

59.05 ± 5.64

58.10 ± 2.95

t = 0.667

p = 0.509

Gender

2

10F/10M

11F/9M

x = 0.100

p = 0.752

Education (years)

10.45 ± 4.86

11.05 ± 3.34

t = -0.455

p = 0.652

MMSE (0 – 30)

26.90 ± 1.51

27.15 ± 1.63

t = -0.502

p = 0.619

Hoehn and Yahr scale (I/II/III)

2.25 ± 0.63

-

-

-

Motor UPDRS

17.05 ± 3.15

-

-

-

Disease duration (years)

5.75 ± 3.52

-

-

-

BDI (0 – 21)

5.80 ± 2.87

5.45 ± 2.18

t = 0.433

p = 0.667

EHS (1 – 10)

9.55 ± 0.76

9.84 ± 0.72

t = -0.818

p = 0.403

Note: n = number of participants, PD = Parkinson’s disease, HC = healthy controls, M = male, F = female, MMSE = Mini Mental State
Examination, UPDRS = Unified Parkinson’s Disease Rating Scale, BDI = Beck Depression Inventory, EHS = Edinburg Handedness Inventory.
Data presented as mean ± SD. *Difference is significant at the p < 0.05 level.

Table 2 Self-assessment classification accuracy (in percentage) for each of six emotional states between PD patients and healthy controls
obtained from the confusion matrix.

Emotion
Happy

Happy (%)
PD
HC
94.33
92.50

Sad (%)
PD
HC
0
0

Fear (%)
PD
HC
0
0

Anger (%)
PD
HC
0
0

Surprise (%)
PD
HC
5.67
7.60

Disgust (%)
PD
HC
0
0

Sad

0

0

75.00

84.67

1.83

0

4.45

2.77

0

0

18.72

12.56

Fear

0

0

2.56

1.49

80.33

77.50

7.92

12.56

3.48

0

5.71

8.45
2.01

Anger

0

0

4.79

0

11.56

15.32

78.00

82.67

0

0

5.65

Surprise

12.00

3.33

0

0

0

0

0

0

88.00

96.67

0

0

Disgust

0

0

24.89

18.42

0

8.12

2.44

6.96

0

0

72.67

66.50

Table 4(a) Percentage ± SD of classification of KNN and SVM classifiers with HOS features (Mavg, P1, and P2) between PD patients and healthy
controls emotional state across delta (1–4 Hz) frequency band.

Emotion

KNN classifier (%)

SVM classifier (%)

PD

HC

AVG

PD

HC

AVG

Happiness

64.84 ± 3.76

75.39 ± 2.58

70.11 ± 3.19

66.49 ± 3.49

76.29 ± 2.01

72.89 ± 2.17

Sadness

61.28 ± 2.13

71.86 ± 3.19

66.57 ± 2.48

64.29 ± 2.57

75.49 ± 3.45

69.89 ± 3.58

Fear

59.20 ± 1.29

65.28 ± 2.30

62.24 ± 3.60

60.49 ± 3.59

70.39 ± 2.59

65.44 ± 3.49

Anger

62.39 ± 3.90

68.44 ± 3.29

65.41 ± 4.04

66.24 ± 4.29

74.12 ± 3.29

70.18 ± 4.56

Surprise

65.38 ± 3.71

73.20 ± 4.83

69.29 ± 3.75

69.72 ± 3.29

75.39 ± 4.22

72.55 ± 3.59

Disgust

60.10 ± 4.49

68.39 ± 5.46

64.24 ± 2.58

62.67 ± 2.49

72.28 ± 2.25

67.47 ± 4.29

Table 4(b) Percentage ± SD of classification of KNN and SVM classifiers with HOS features (Mavg, P1, and P2) between PD patients and healthy
controls emotional state across theta (4–8 Hz) frequency band.

Emotion

KNN classifier (%)

SVM classifier (%)

PD

HC

Average

PD

HC

Average

Happiness

69.22 ± 5.81

71.39 ± 3.65

70.31 ± 4.11

76.54 ± 5.21

77.34 ± 3.10

76.94 ± 4.12

Sadness

62.50 ± 3.45

73.33 ± 3.98

67.92 ± 3.11

67.67 ± 3.96

75.78 ± 3.02

71.73 ± 3.34

Fear

60.56 ± 4.28

72.08 ± 4.51

66.32 ± 2.78

66.34 ± 4.92

75.67 ± 4.97

71.00 ± 2.01

Anger

64.17 ± 5.16

70.00 ± 6.14

67.08 ± 3.55

65.24 ± 5.03

73.12 ± 4.23

69.18 ± 3.56

Surprise

68.11 ± 4.76

69.39 ± 3.34

68.75 ± 2.91

75.72 ± 4.34

75.84 ± 6.89

75.78 ± 2.44

Disgust

65.56 ± 6.32

68.19 ± 4.76

66.88 ± 3.60

64.78 ± 6.25

72.24 ± 3.56

68.51 ± 3.23

Table 4(c) Percentage ± SD of classification of KNN and SVM classifiers with HOS features (Mavg, P1, and P2) between PD patients and healthy
controls emotional state across alpha (8–13 Hz) frequency band.

Emotion

KNN classifier (%)

SVM classifier (%)

PD

HC

Average

PD

HC

Average

Happiness

74.72 ± 6.76

77.78 ± 3.52

76.25 ± 4.18

86.97 ± 6.82

88.56 ± 4.43

87.77 ± 3.11

Sadness

74.03 ± 2.62

80.97 ± 3.76

77.50 ± 2.56

79.85 ± 2.32

84.00 ± 3.33

81.93 ± 2.45

Fear

71.94 ± 4.80

78.50 ± 5.35

75.22 ± 3.24

78.45 ± 4.50

82.65 ± 4.05

80.55 ± 3.76

Anger

77.36 ± 3.76

82.64 ± 3.47

80.00 ± 2.53

78.56 ± 3.00

83.67 ± 2.92

81.12 ± 2.67

Surprise

79.47 ± 5.43

80.83 ± 2.71

80.15 ± 3.73

81.85 ± 5.56

83.23 ± 5.24

82.54 ± 4.45

Disgust

72.78 ± 5.56

79.53 ± 2.73

76.16 ± 2.93

75.56 ± 5.11

82.96 ± 3.78

79.26 ± 3.40

Table 4(d) Percentage ± SD of classification of KNN and SVM classifiers with HOS features (Mavg, P1, and P2) between PD patients and healthy
controls emotional state across beta (3–30 Hz) frequency band.

Emotion

KNN classifier (%)

SVM classifier (%)

PD

HC

Average

PD

HC

Average

Happiness

87.00 ± 2.55

88.01 ± 3.41

87.50 ± 2.23

90.89 ± 5.74

92.45 ± 5.95

91.67 ± 3.23

Sadness

80.87 ± 3.22

89.96 ± 2.36

85.41 ± 2.18

82.71 ± 6.62

90.91 ± 3.79

86.81 ± 5.56

Fear

81.94 ± 5.67

87.49 ± 3.82

84.72 ± 3.63

81.67 ± 4.34

89.78 ± 5.56

85.73 ± 4.33

Anger

81.03 ± 2.81

87.00 ± 4.90

84.02 ± 2.65

82.76 ± 3.77

89.47 ± 5.23

86.11 ± 3.43

Surprise

86.61 ± 3.52

87.02 ± 2.88

86.81 ± 2.44

91.65 ± 5.78

92.67 ± 3.88

91.67 ± 4.22

Disgust

81.82 ± 3.43

87.65 ± 3.65

84.73 ± 2.22

80.83 ± 4.34

89.92 ± 4.82

85.38 ± 3.56

Table 4(e) Percentage ± SD of classification of KNN and SVM classifiers with HOS features (Mavg, P1, and P2) between PD patients and healthy
controls emotional state across gamma (30–49 Hz) frequency band.

Emotion

KNN classifier (%)

SVM classifier (%)

PD

HC

Average

PD

HC

Average

Happiness

85.85 ± 2.89

90.27 ± 4.10

88.06 ± 3.39

86.68 ± 3.37

93.58 ± 3.55

90.13 ± 2.35

Sadness

78.87 ± 2.48

90.29 ± 3.49

84.58 ± 4.25

82.27 ± 2.48

91.09 ± 2.01

86.68 ± 1.04

Fear

80.32 ± 3.10

89.20 ± 4.90

84.76 ± 2.77

77.67 ± 4.28

92.76 ± 2.43

85.21 ± 3.88

Anger

77.29 ± 1.59

90.84 ± 4.12

84.06 ± 3.49

80.76 ± 2.51

90.13 ± 3.38

85.44 ± 2.57

Surprise

87.36 ± 3.29

88.98 ± 3.17

88.17 ± 4.10

92.27 ± 3.83

93.98 ± 4.00

93.12 ± 1.25

Disgust

78.96 ± 4.17

88.05 ± 2.75

83.50 ± 5.29

78.00 ± 3.59

91.97 ± 2.18

84.98 ± 2.58

Table 4(f) Percentage ± SD of classification of KNN and SVM classifiers with HOS features (Mavg, P1, and P2) between PD patients and healthy
controls emotional state across ALL (combination of five bands) frequency bands.

Emotion

KNN classifier (%)

SVM classifier (%)

PD

HC

Average

PD

HC

Average

Happiness

85.90 ± 1.37

91.39 ± 3.28

88.64 ± 4.12

86.89 ± 1.74

94.76 ± 2.28

90.82 ± 2.37

Sadness

78.98 ± 3.37

91.78 ± 2.45

85.38 ± 3.77

82.56 ± 2.09

93.86 ± 3.92

88.21 ± 3.85

Fear

81.61 ± 4.23

90.49 ± 3.78

86.05 ± 4.29

79.99 ± 3.48

91.74 ± 1.38

85.85 ± 4.88

Anger

76.90 ± 3.19

93.28 ± 4.98

85.09 ± 2.48

80.98 ± 5.28

90.86 ± 2.48

85.92 ± 2.47

Surprise

88.20 ± 4.00

89.78 ± 2.10

88.99 ± 3.67

91.27 ± 4.04

94.98 ± 3.84

93.16 ± 3.19

Disgust

76.30 ± 3.15

92.39 ± 3.10

84.34 ± 4.29

80.57 ± 3.38

93.39 ± 2.97

86.98 ± 2.56

Table_suplementary

1
2

Table 3(a) Range of various HOS based features (in mean ± standard deviation) and results of ANOVA between PD patients and healthy controls during each of
six emotional states under delta (1–4 Hz) EEG frequency bands.
Mavg

P1

P2

Emotions

3

PD

HC

p-value

Happiness

3.67 E+6 ± 2.24 E+6

4.24 E+7 ± 5.90 E+8

0.023

Sadness

5.78 E+6 ± 6.13 E+8

4.89E+9 ± 2.98E+10

Fear

4.89 E+6 ± 3.98 E+8

Anger

F value

PD

HC

p-value

F value

PD

HC

p-value

F value

1.404

0.678 ± 0.047

0.689 ± 0.034

0.039

1.859

0.589 ± 0.024

0.598 ± 0.015

0.018

2.900

0.015

2.006

0.643 ± 0.071

0.698 ± 0.052

0.006

3.298

0.528 ± 0.025

0.594 ± 0.013

0.020

1.579

4.89 E+7 ± 4.87 E+8

0.018

1.774

0.689 ± 0.049

0.706 ± 0.043

0.011

2.470

0.561 ± 0.026

0.589 ± 0.018

0.046

3.656

5.72 E+6 ± 3.13 E+8

4.87 E+7 ± 7.98 E+9

0.008

2.903

0.691 ± 0.041

0.725 ± 0.065

0.008

2.975

0.548 ± 0.022

0.632 ± 0.016

0.015

2.072

Surprise

4.15 E+6 ± 4.67 E+8

6.96 E+7± 4.98 E+9

0.029

1.083

0.674 ± 0.028

0.791 ± 0.012

0.017

1.852

0.589 ± 0.014

0.636 ± 0.020

0.040

3.982

Disgust

4.29 E+6 ± 5.14 E+8

4.76 E+7 ± 3.87 E+9

0.000

12.749

0.645 ± 0.039

0.767 ± 0.036

0.009

2.854

0.574 ± 0.016

0.601 ± 0.020

0.017

1.849

Note: The p-value represents the significance (p < 0.05) difference between PD patients and healthy controls on extracted HOS features.

4
5
6

Table 3(b) Range of various HOS based features (in mean ± standard deviation) and results of ANOVA between PD patients and healthy controls during each of
six emotional states under theta (4–8 Hz) EEG frequency bands.
Mavg

P1

P2

Emotions

7
8

PD

HC

p-value

Happiness

1.11E+6 ± 1.52E+7

3.37E+7 ± 7.18E+8

0.026

Sadness

6.53E+7 ± 1.73E+9

1.49E+9 ± 3.95E+9

Fear

2.51E+7 ± 8.87E+8

Anger

F value

PD

HC

p-value

F value

PD

HC

p-value

F value

1.257

0.792 ± 0.025

0.799 ± 0.025

0.036

1.826

0.632 ± 0.013

0.636 ± 0.015

0.010

2.693

0.029

4.754

0.763 ± 0.022

0.788 ± 0.027

0.000

14.210

0.598 ± 0.012

0.624 ± 0.013

0.013

6.121

3.68E+7 ± 6.14E+8

0.024

2.522

0.783 ± 0.026

0.793 ± 0.025

0.015

3.232

0.629 ± 0.011

0.636 ± 0.018

0.035

2.095

6.53E+6 ± 1.34E+8

1.71E+8 ± 3.65E+9

0.011

3.782

0.772 ± 0.025

0.790 ± 0.025

0.017

1.847

0.628 ± 0.013

0.632 ± 0.016

0.001

11.466

Surprise

2.23E+6 ± 4.29E+7

1.88E+8± 4.77E+9

0.017

1.862

0.793 ± 0.028

0.799 ± 0.016

0.049

3.006

0.634 ± 0.023

0.636 ± 0.020

0.035

1.856

Disgust

5.61E+6 ± 1.20E+8

1.45E+8 ± 3.11E+9

0.016

5.796

0.762 ± 0.025

0.788 ± 0.026

0.000

13.619

0.622 ± 0.012

0.632 ± 0.020

0.000

28.241

Note: The p-value represents the significance (p < 0.05) difference between PD patients and healthy controls on extracted HOS features.

1
2

Table 3(c) Range of various HOS based features (in mean ± standard deviation) and results of ANOVA between PD patients and healthy controls during each of
six emotional states under alpha (8–13 Hz) EEG frequency bands.
Mavg

P1

P2

Emotions
PD

HC

p-value

F value

PD

HC

p-value

F value

PD

HC

p-value

F value

Happiness

1.65E+4 ± 3.74E+5

2.94E+4 ± 4.53E+5

0.044

1.048

0.801 ± 0.022

0.803 ± 0.023

0.046

3.381

0.654 ± 0.019

0.666 ± 0.011

0.048

2.446

Sadness

1.32E+6 ± 3.53E+7

4.29E+6 ± 8.98E+7

0.037

2.035

0.791 ± 0.019

0.801 ± 0.023

0.001

12.609

0.638 ± 0.013

0.654 ± 0.016

0.022

2.660

Fear

3.64E+4 ± 5.80E+5

8.91E+6 ± 2.10E+8

0.004

8.464

0.790 ± 0.023

0.802 ± 0.024

0.007

4.751

0.639 ± 0.012

0.656 ± 0.015

0.045

Anger

1.12E+5 ± 2.83E+6

3.46E+5 ± 6.68E+6

0.019

2.866

0.791 ± 0.023

0.802 ± 0.023

0.024

2.544

0.644 ± 0.020

0.656 ± 0.016

0.000

95.283

Surprise

2.22E+4 ± 4.82E+5

5.51E+4 ± 1.26E+7

0.022

1.471

0.802 ± 0.019

0.804 ± 0.024

0.045

2.414

0.661 ± 0.020

0.664 ± 0.010

0.048

3.387

Disgust

2.00E+4 ± 3.78E+5

1.43E+6 ± 2.38E+7

0.034

4.502

0.782 ± 0.021

0.802 ± 0.024

0.017

5.736

0.639 ± 0.014

0.656 ± 0.019

0.001

12.894

1.838

3

Note: The p-value represents the significance (p < 0.05) difference between PD patients and healthy controls on extracted HOS features.

4
5
6

Table 3(d) Range of various HOS based features (in mean ± standard deviation) and results of ANOVA between PD patients and healthy controls during each of
six emotional states under beta (13–30 Hz) EEG frequency bands.
Mavg

P1

P2

Emotions

7

PD

HC

p-value

F value

PD

HC

p-value

Happiness

2.20E+5 ± 5.04E+7

9.74E+6 ± 1.78E+7

0.030

1.054

0.836 ± 0.012

0.849 ± 0.014

0.030

Sadness

1.42E+5 ± 2.07E+6

2.71E+7 ± 6.47E+8

0.000

26.544

0.831 ± 0.014

0.846 ± 0.013

Fear

1.66E+5 ± 4.30E+8

7.98E+7 ± 1.31E+7

0.000

14.505

0.833 ± 0.013

Anger

1.68E+5 ± 3.87E+7

7.28E+6 ± 1.19E+7

0.000

18.930

Surprise

6.86E+5 ± 1.07E+7

1.53E+7± 3.41E+8

0.010

Disgust

2.10E+5 ± 3.21E+6

2.48E+6 ± 4.84E+7

0.000

F value

PD

HC

p-value

1.054

0.729 ± 0.024

0.733 ± 0.035

0.024

1.341

0.000

52.304

0.698 ± 0.022

0.712 ± 0.036

0.000

50.171

0.842 ± 0.014

0.000

53.442

0.702 ± 0.025

0.714 ± 0.031

0.000

95.072

0.839 ± 0.014

0.843 ± 0.014

0.000

31.376

0.706 ± 0.033

0.722 ± 0.036

0.000

34.863

2.703

0.836 ± 0.013

0.848 ± 0.014

0.010

2.703

0.709 ± 0.032

0.731 ± 0.036

0.015

2.430

27.798

0.832 ± 0.013

0.841 ± 0.014

0.000

92.734

0.710 ± 0.032

0.723 ± 0.032

0.000

42.054

Note: The p-value represents the significance (p < 0.05) difference between PD patients and healthy controls on extracted HOS features.

F value

1
2

Table 3(e) Range of various HOS based features (in mean ± standard deviation) and results of ANOVA between PD patients and healthy controls during each of
six emotional states under gamma (30–49 Hz) EEG frequency bands.
Mavg

P1

P2

Emotions

3
4

PD

HC

p-value

F value

PD

HC

p-value

Happiness

4.56 E+7 ± 4.12 E+5

5.67 E+8 ± 3.56 E+5

0.007

3.257

0.856 ± 0.012

0.878 ± 0.014

0.000

Sadness

3.23 E+7 ± 3.14 E+7

5.78 E+8 ± 5.78 E+4

0.036

4.385

0.896 ± 0.014

0.900 ± 0.013

Fear

2.89 E+7 ± 3.78 E+7

5.23 E+8 ± 3.67 E+7

0.004

7.986

0.872 ± 0.013

Anger

4.23 E+7 ± 2.78 E+6

3.89 E+8 ± 7.64 E+2

0.000

11.341

Surprise

6.13 E+7 ± 4.78 E+4

7.23 E+8 ± 2.67 E+4

0.015

Disgust

4.56 E+7 ± 2.67 E+5

3.34 E+8 ± 2.67 E+6

0.002

F value

PD

HC

p-value

7.289

0.779 ± 0.037

0.798 ± 0.045

0.000

4.917

0.000

10.372

0.776 ± 0.033

0.800 ± 0.051

0.000

5.827

0.889 ± 0.014

0.000

9.410

0.793 ± 0.029

0.798 ± 0.044

0.000

7.478

0.895 ± 0.014

0.903 ± 0.014

0.000

5.821

0.754 ± 0.032

0.767 ± 0.062

0.000

3.298

2.016

0.875 ± 0.013

0.898 ± 0.014

0.000

4.932

0.772 ± 0.022

0.784 ± 0.025

0.000

2.786

8.972

0.890 ± 0.013

0.921 ± 0.014

0.000

3.980

0.718 ± 0.049

0.745 ± 0.048

0.000

3.986

Note: The p-value represents the significance (p < 0.05) difference between PD patients and healthy controls on extracted HOS features.

F value

