sensors
Article

Electroencephalogram Profiles for Emotion
Identification over the Brain Regions Using
Spectral, Entropy and Temporal Biomarkers
Noor Kamal Al-Qazzaz 1,2, *, Mohannad K. Sabir 1 , Sawal Hamid Bin Mohd Ali 2 ,
Siti Anom Ahmad 3,4 and Karl Grammer 5
1
2
3
4
5

*

Department of Biomedical Engineering, Al-Khwarizmi College of Engineering, University of Baghdad,
Baghdad 47146, Iraq; dr.mohannad@uob.edu.iq
Department of Electrical, Electronic & Systems Engineering, Faculty of Engineering & Built Environment,
Universiti Kebangsaan Malaysia, UKM Bangi, Selangor 43600, Malaysia; sawal@ukm.edu.my
Department of Electrical and Electronic Engineering, Faculty of Engineering, Universiti Putra Malaysia,
UPM Serdang, Selangor 43400, Malaysia; sanom@upm.edu.my
Malaysian Research Institute of Ageing (MyAgeing), Universiti Putra Malaysia, Serdang, Selangor 43400,
Malaysia
Department of Evolutionary Anthropology, University of Vienna, Althan strasse 14, A-1090 Vienna, Austria;
karl.grammer@univie.ac.at
Correspondence: noorbme@kecbu.uobaghdad.edu.iq; Tel.: +964-773-543-1383

Received: 24 October 2019; Accepted: 3 December 2019; Published: 20 December 2019




Abstract: Identifying emotions has become essential for comprehending varied human behavior
during our daily lives. The electroencephalogram (EEG) has been adopted for eliciting information in
terms of waveform distribution over the scalp. The rationale behind this work is twofold. First, it aims
to propose spectral, entropy and temporal biomarkers for emotion identification. Second, it aims to
integrate the spectral, entropy and temporal biomarkers as a means of developing spectro-spatial (SS),
entropy-spatial (ES) and temporo-spatial (TS) emotional profiles over the brain regions. The EEGs
of 40 healthy volunteer students from the University of Vienna were recorded while they viewed
seven brief emotional video clips. Features using spectral analysis, entropy method and temporal
feature were computed. Three stages of two-way analysis of variance (ANOVA) were undertaken so
as to identify the emotional biomarkers and Pearson’s correlations were employed to determine the
optimal explanatory profiles for emotional detection. The results evidence that the combination of
applied spectral, entropy and temporal sets of features may provide and convey reliable biomarkers
for identifying SS, ES and TS profiles relating to different emotional states over the brain areas.
EEG biomarkers and profiles enable more comprehensive insights into various human behavior
effects as an intervention on the brain.
Keywords: emotion; electroencephalography; spectral power; entropy; Hilbert transform; ANOVA;
Pearson’s correlation

1. Introduction
Within the brain, impetus inclinations, behavioral reactions, physiological stimulation, states of
mind and cognitive procedures are all directly conveyed through emotion. Brain activity and neural
pathways are interrelated in a manner that influences mathematical, verbal, perceptive and other
forms of intelligence, which further shape emotions [1,2]. From a particular response of the body to an
instinctive reaction, individual emotional reactions can vary [3]. Accordingly, the possible extent of
congruence between socio-affective circumstances and particular brain areas has been investigated
through applying an array of simulation methods in a substantial number of studies [4,5].
Sensors 2020, 20, 59; doi:10.3390/s20010059

www.mdpi.com/journal/sensors

Sensors 2020, 20, 59

2 of 21

The dimensional and discrete models are the two affective models that may be adopted to
determine and categorize affective states in accordance with a psychological perspective. Key emotions
are identified in the discrete model which specific, distinct affective states are connected to; fundamental
emotions such as happiness, sadness, surprise, disgust, fear and anger are individually or in some
mixture deemed to be responsible for any further emotions [6,7]. Adopting a circumplex emotion
model, the dimensional model has been pervasively adopted for affective identification application
mapping, as a two-dimensional (2D) cognitive-emotional state theory [8,9]. A two-scale valence-arousal
graph is used for conveying emotions, with emotional strength between calm to excited presented
on the vertical axis as ‘arousal’, while the unpleasant to pleasant degree of emotion is conveyed
on the horizontal axis as ‘valence’ [8–10]. Furthermore, quartiles Q1 to Q4 are the four principal
sites of emotional states, with low arousal–high valence (LAHV), low arousal–low valence (LALV),
high arousal–low valence (HALV) and high arousal–high valence (HAHV) presented in Q4, Q3, Q2 and
Q1 respectively [11]. Beyond the 2D model, focus-disinterest characteristics have been incorporated
into a three-dimensional (3D) cognitive-emotional state model in certain studies [12].
Various emotional states have been produced through the adoption of varied techniques in studies.
Consequently, audio-visual, auditory or visual stimuli have all been adopted in different instances.
As in brain-computer interfacing (BCI) research, diminishing or expanding the sensorimotor rhythm
amplitude is the process for auditory and visual stimuli [13]. Additionally, compared to music-based
audio stimuli, brain signals more straightforwardly convey picture-based visual stimuli [14]. So as
to provoke a particular affective state in the most effective manner, auditory and visual stimulus’
amalgamated impact has been acknowledged in studies, thus establishing the optimal context for
affective identification. Regarding automatic emotion identification, audio-visual stimuli have also been
applied [4]. In contrast with alternative stimuli methods, audio-visual production of emotional states
has been found to be superior and more pervasively adopted [13,15,16]. Therefore, brief audio-visual
film excerpts were adopted to elicit emotion in this research.
Emotional changes would be elicited using different physiological signals such as galvanic skin
response (GSR) [15], electrodermal activity (EDA) [17], blood volume pressure (BVP) [18], and skin
temperature (ST) [19], evoked potentials (EP) [20], electrocardiogram (ECG) [21], electromyogram
(EMG) [22], and electroencephalogram (EEG) [23–30]. Clinically, EEG signals have been widely used
as useful indicators of different mental states such as epilepsy, Alzheimer’s disease (AD) and vascular
dementia (VaD) [31–35].
As the brain is a complex structure that has a dynamic behavior, electrical activities including
emotional states, can be reflected by using EEG. EEG is a neurophysiological tool used to monitor and
identify brain changes [36]. EEG is a widely available, cost-effective, and non-invasive tool that tracks
information processing with milliseconds precision and high temporal resolution [36,37]. A typical
clinical EEG frequency ranges from 0.01 Hz to approximately 70 Hz [38]; the corresponding waveforms
have an amplitude of a few µVolt to approximately 100 µVolt [39]. EEG background waveforms also
convey valuable information. Thus, these waveforms can be classified into five specific frequency
power bands: the delta band (δ), the theta band (θ), the alpha band (α), the beta band (β), and the
gamma band (γ) [40,41]. Studies on EEG signal processing have been conducted to identify the brain
activity patterns involved in cognitive science, neuropsychological research, clinical assessments,
and consciousness research [42–47]. Recently, EEG has been widely used to assess and evaluate
the human emotional states with excellent time resolution [3,15,28–30,48]. EEG can provide useful
information of emotional states that have been described as a potential biomarker to evaluate different
emotional responses from multi-channel EEG datasets over the brain regions [38]. A key advantage of
the multi-channel EEG signal processing is to interpret EEG changes during different emotional states
over the brain regions. Thus, numerous studies have been performed including this study to deal with
issue [49–51]. For instance, Nattapong et al. have proposed a continuous music-emotion recognition
approach based on brain wave signals [52]. Olga et al. have applied a combined music therapy process

Sensors 2020, 20, 59

3 of 21

with the real-time EEG-based human emotion recognition algorithm to identify the current emotional
state based on neurofeedback and adjust the music therapy based on the patient’s needs [53].
As the brain neurons are controlled by linear and non-linear phenomena, several linear techniques
including traditional spectral powers have been used to analyze the smoothness of the EEG as a
time series and to elicit the emotional information from the EEG signals. The higher order statistics
(HOS) features, namely skewness and kurtosis, have been applied as well to measure the presence of
transients in the signal [52,54–56]. Due to the capability of the brain to perform sophisticated emotional
tasks and to investigate the complex dynamic information that is reflected from the brain cortex, several
researchers have used non-linear methods for automatic detection of emotions through EEG signals [57].
Previous emotion studies have used a small number of features, mostly relative powers [3], Hurst [15],
Hjorth parameters [58], Fractal Dimension (FD) [59], and statistical features [60,61]. Moreover, entropy
has been considered as the most prevalent methods to evaluate the presence or absence of long-range
dependence on physiological signal analysis including approximate entropy (ApEn), sample entropy
(SampEn) and permutation entropy (PerEn) which are relatively robust to noise and powerful enough
to quantify the complexity of a time series [62]. Amplitude-aware permutation entropy (AAPE) has
demonstrated efficiency in discriminating between calmness and distress [63–65]. Fuzzy entropy
(FuzEn) was proposed for EEG analysis in [66,67]. SampEn is slightly faster than FuzEn, however the
latter is more consistent and less dependent on the data length [68]. Azami et al. has considered the
advantages of FuzEn over SampEn and recently has introduced refined composite multiscale FuzEn
(RCMFE) [68–70]. In RCMFE, the entropy stability is improved, the signals’ length sensitivity is
reduced and the coarse-grained process of RCMFE smoothens the signals. Hence, RCMFE has been
used in this study.
EEG signal contains useful information on physiological states of the brain and has proven
to be a potential biomarker to realize the linear and non-linear behavior of the brain [31,32,71–73].
Therefore, motivation of this work is twofold. First, in order to investigate alternate information
from multi-channel emotional EEG datasets, linear spectral conventional analysis, non-linear entropy
method and temporal feature were performed to obtain the potential EEG emotional biomarkers.
Second, the obtained biomarkers may be further considered to provide additional information to
illustrate the EEG spectro-spatial (SS), entropy-spatial (ES) and temporo-spatial (TS) profiles for the
seven emotional states over the brain regions.
The preprocessing stage has been used to limit the unwanted frequency from the EEG dataset.
Spectral biomarkers were computed by employing the absolute powers (AbsP) of δ, θ, α, β, and γ.
Moreover, to quantify the complexity of brain functions, entropy biomarkers across multi-channel EEG
signals have been measured using RCMFE. Furthermore, the temporal biomarker was reported by
amplitude envelope which was extracted using Hilbert transform, and the amplitude values were
investigated by skewness (Skw) to get HSkw . Three stages of two-way analysis of variance (ANOVA)
were conducted to obtain the spectral, entropy and temporal biomarkers followed by Pearson’s
correlations to get the spatial profiles that are related to anger, anxiety, disgust, happiness, sadness,
surprise and neutral emotional states over the brain regions. The valance-arousal circumplex model
was employed in this study to represent and recognize human emotions due to its effectiveness in
viewing the emotions while audio-visual video clips were used [74]. To the author’s best knowledge
this study has two contributions: firstly, it is the first use of a combination of certain features to develop
spectral, entropy and temporal biomarkers towards SS, ES and TS profile identification for the seven
emotional states over the brain regions; secondly, the EEG elicitation protocol and EEG measurement
procedure have never been used before for emotion data acquisition.
2. Materials and Methods
This study is intended to be focused on the potential EEG emotional biomarkers and profiles that
obtained from EEG datasets. Figure 1 illustrates the block diagram of the proposed study.

Sensors 2020, 20, 59
Sensors 2019, 19, x FOR PEER REVIEW

4 of 21
4 of 21

Figure
1. The
Theblock
blockdiagram
diagramofofthe
theproposed
proposed
study.
Figure 1.
study.

2.1. EEG Acquisition and Recording
2.1. EEG Acquisition and Recording
A transportable Emotiv EPOC EEG 14-channel headset (Emotive Systems, Inc., San Francisco, CA,
A transportable Emotiv EPOC EEG 14-channel headset (Emotive Systems, Inc., San Francisco, CA)
USA) was adopted in order to evaluate 14 EEG electrodes (AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8,
was adopted in order to evaluate 14 EEG electrodes (AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4,
FC6,
F4, F8, AF4) overall with 2 ground electrodes which were provided by the driven right leg (DRL)
F8, AF4) overall with 2 ground electrodes which were provided by the driven right leg (DRL) mastoid
mastoid
and common
mode
sense
leftThe
mastoid.
Emotiv
EEG uses sponge-based
and common
mode sense
(CMS)
left(CMS)
mastoid.
EmotivThe
EPOC
EEG EPOC
uses sponge-based
electrodes
electrodes
which
were
located
based
on
the
10–20
system.
The
electrode
information
wasa filtered
which were located based on the 10–20 system. The electrode information was filtered through
0.5–
through
a 0.5–70 Hz
band-pass
filter. A 128
Hz sampling
was used
with
a resolution of
70 Hz band-pass
filter.
A 128 Hz sampling
frequency
was usedfrequency
with a resolution
of 0.51
mV.
0.51 mV.
40 university students agreed to participate in this research (Table 1). A subject appraisal was
40 university
students
agreed
to participate
in previous
this research
(Table 1).
A subject appraisal
carried
out for each
individual
to guarantee
that no
psychiatric
or neurological
problemswas
carried
out for
each individual
to guarantee
thatproviding
no previous
psychiatric
orto
neurological
problems
had been
suffered,
with the participant
then
their
agreement
participation
throughhad
signing
an informed
document,
before thetheir
study
proceeded.
Subjects werethrough
presented
with an
been
suffered,
with theconsent
participant
then providing
agreement
to participation
signing
different
brief
film
excerpts
alongside
audio
that
aimed
to
be
emotionally
engaging,
after
which
a
informed consent document, before the study proceeded. Subjects were presented with different brief
self-assessment
questionnaire
(SAQ)
was to
filled
in by the subjects
to provide
their assessment
and
film
excerpts alongside
audio that
aimed
be emotionally
engaging,
after which
a self-assessment
scoring of emotional
reactions
excerpts.
Thetosubsequent
video
excerpt was
after
a 45
questionnaire
(SAQ) was
filled to
in the
by the
subjects
provide their
assessment
andpresented
scoring of
emotional
second pause.
process
presented invideo
Figure
2 [75]. was presented after a 45 s pause. This process
reactions
to the This
excerpts.
Theissubsequent
excerpt
is presented in Figure 2 [75].

Table 1. Sociodemographic data of the subjects with self-assessment questionnaire (SAQ) scores
shown. (Age in years, SAQ mean ± standard deviation SD).
Table 1. Sociodemographic data of the subjects with self-assessment questionnaire (SAQ) scores shown.
(Age in years, SAQ mean
± standard deviation
SD).features
Demographic
and clinical
Subjects

Number
40
Subjects
Age
22.475 ± 2.522
Number
40
Female/Male
17F/23M
Age
22.475 ± 2.522
Anger
4.052 ± 2.001
Female/Male
17F/23M
Anxiety Anger
1.844
± 2.591
4.052
± 2.001
DisgustAnxiety
3.859
±
1.8442.843
± 2.591
Happiness
2.204
± 2.947
Disgust
3.859
± 2.843
SAQ
Happiness 1.804
2.204
± 2.947
Sadness
± 2.365
1.804
± 2.365
surpriseSadness
2.093
± 2.438

SAQ

Demographic and Clinical Features

surprise

2.093 ± 2.438

Sensors 2020, 20, 59
Sensors 2019, 19, x FOR PEER REVIEW

5 of 21
5 of 21

Figure 2.
2. The
Theexperimental
experimentalprotocol
protocolof
ofemotion.
emotion.
Figure

Respondents rated their responses in the SAQ according to the level of emotion felt, from 5 = very
Respondents rated their responses in the SAQ according to the level of emotion felt, from 5 =
high; 4 = high; 3 = medium; 2 = low, to 1 = very low, thus providing a five-point scale [48]. This enabled
very high; 4 = high; 3 = medium; 2 = low, to 1 = very low, thus providing a five-point scale [48]. This
the neutral circumstances and six affective states—anger, anxiety, sadness, disgust, surprise and
enabled the neutral circumstances and six affective states—anger, anxiety, sadness, disgust, surprise
happiness. Rottenberg’s suggestions were followed in order to identify appropriate affective film
and happiness. Rottenberg’s suggestions were followed in order to identify appropriate affective film
excerpts [75]; one film excerpt had a duration of four minutes, which was the longest, with the others
excerpts [75]; one film excerpt had a duration of four minutes, which was the longest, with the others
differing in length.
differing in length.
In order to assist with the presentation of the affective video excerpts to the subjects, the University
In order to assist with the presentation of the affective video excerpts to the subjects, the University
of Vienna’s virtual emotion presenter program was applied. Further information source documentation
of Vienna’s virtual emotion presenter program was applied. Further information source documentation
and arbitrary presentation is permitted through the program. The anthropology research laboratory
and arbitrary presentation is permitted through the program. The anthropology research laboratory
was the location of the research; the sound for the film was played to the subjects at a consistent
was the location of the research; the sound for the film was played to the subjects at a consistent and
and reasonable volume through a stereo system; film excerpts were viewed on an LCD display;
reasonable volume through a stereo system; film excerpts were viewed on an LCD display; the
the laboratory had consistent natural light sources, with the VEP also adopted as explained above.
laboratory had consistent natural light sources, with the VEP also adopted as explained above. As the
As the 40 subjects viewed the affective video excerpts, monitoring of the EEG electrode signals ensued.
40 subjects viewed the affective video excerpts, monitoring of the EEG electrode signals ensued.
2.2. Preprocessing Stage
2.2. Preprocessing Stage
Brain responses and artefacts may have intersected due to the latter residing within the frequency
Brain responses and artefacts may have intersected due to the latter residing within the
bands of the EEG waves. In terms of EEG signal preprocessing, a significant aspect is noise eradication.
frequency bands of the EEG waves. In terms of EEG signal preprocessing, a significant aspect is noise
Standard filtering may be an aspect of the preprocessing phase, with EEG signals seeing the introduction
eradication. Standard filtering may be an aspect of the preprocessing phase, with EEG signals seeing
of further software filters—band pass and notch filters for example—to carry out this process. As a
the introduction of further software filters—band pass and notch filters for example—to carry out
means of restricting EEG signal frequencies in accordance with [76], a higher cutoff frequency around
this process. As a means of restricting EEG signal frequencies in accordance with [76], a higher cutoff
64 Hz and a low cutoff of 0.5 Hz (3 dB) was adopted for the band pass filter. A 50 Hz cutoff frequency
frequency around 64Hz and a low cutoff of 0.5Hz (3 dB) was adopted for the band pass filter. A 50Hz
was adopted for the notch filter; eliminating A/C electricity line interference is the typical reason for
cutoff frequency was adopted for the notch filter; eliminating A/C electricity line interference is the
doing so [38]. Three 10 s trials per video excerpt comprised the overall video, with every 10 s trial
typical reason for doing so [38]. Three 10 second trials per video excerpt comprised the overall video,
comprising of 1280 information points, in order to carry out additional filtered EEG data processing.
with every 10 second trial comprising of 1280 information points, in order to carry out additional
filtered
EEG data
processing.
2.3. Features
Extraction
Comprehending
2.3. Features
Extraction various affective states’ associations is assisted by EEG signals as a significant
source of brain function data. In terms of identifying particular emotional actions, the EEG signal offers
Comprehending
various affective
states’affective
associations
assisted bywere
EEGderived
signals as
a significant
various
quantifiable measures.
Accordingly,
EEGisbiomarkers
from
a number
source
of brain function
data.
In terms of into
identifying
particular
actions,
EEG signal
of characteristics,
primarily
distinguished
temporal,
entropy emotional
and spectral
powerthe
characteristics,
offers various quantifiable measures. Accordingly, affective EEG biomarkers were derived from a
number of characteristics, primarily distinguished into temporal, entropy and spectral power

Sensors 2020, 20, 59

6 of 21

as a means of determining the principal characteristics that enable the EEG data to be matched with
affective states, while also allowing improved explication of the brain areas’ altering affective states.
Additionally, the brain areas’ and seven affective states’ spectro-spatial (SS), entropy-spatial (ES)
and temporo-spatial (TS) profiles were determined through combining the quantified biomarkers via
Pearson’s correlations.
2.3.1. Spectral Biomarker
Through investigating the impact on different brain areas of various multi-channel EEG signals’
frequency bands, such spectral assessments as a linear characteristic for appraising affective alterations
have been pervasively adopted. Multi-channel EEG alterations have been quantified via the AbsP
characteristic as aspects of brain rhythms. Meanwhile, Welch’s technique was applied to calculate
the EEG information’s power spectral density (PSD), with the specific frequency bands of gamma
(γ: 32 ≤ f ≤ 60) Hz, beta (β: 16 ≤ f ≤ 32) Hz, alpha (α: 8 ≤ f ≤ 16) Hz, theta (θ: 4 ≤ f ≤ 8) Hz, and delta
(δ: 0 ≤ f ≤ 4) Hz being distinguished as particular frequency bands for the EEG signals’ PSD [77].
A single band’s level of EEG activity autonomous of different bands’ activity is indicated by the AbsP,
with Equation (1) adopted to determine it [78].
P
10 × log10
Selected frequency band
P
AbsP(%) =
Total range (0.5 − 64 Hz)

(1)

Every film excerpt’s last 30 s were divided into three 10 s parts comprising of 1280 information
points per part, providing 3840 information points overall from which the EEG signal information’s
AbsP features were ascertained.
2.3.2. Entropy Biomarker
The obtained EEG signals, inclusive of the RCMFE, have been assessed by applying the non-linear
entropy method, given that complex mental procedures may
by the brain.
 be undertaken

In order to calculate the RCMFE based on mean RCMFEµ for 1 ≤ u ≤ τ, zτu =
{yu,1 (τ), yu,2 (τ), . . .}, where
Pu+τj−1
x
b=u+τ( j+1) b
µ yu,j (τ) =
τ
For a defined scale factor τ and embedding dimension, m, ∅τ,km |(k = 1, . . . , τ) and
∅τ,km+1 |(k = 1, . . . , τ) for each of zτk |(k = 1, . . . , τ) are separately calculated. Next, the average of
values of ∅τ,km and ∅τ,km+1 on 1 ≤ k ≤ τ are computed, respectively. Finally, the RCMFE is computed
as in Equation (2):


m+1

RCMFE(X, τ, m, n, r) = − ln ∅τ

m

/ ∅τ

(2)

The embedding dimension m, RCMFE power n, and tolerance r for all of the approaches were
respectively chosen as τ = 1, m = 3, n = 2, r = 0.1 ∼ 0.2SD, and SD is the standard deviation of the
original time series [68].
2.3.3. Temporal Biomarker
In contrast with alternative brain imaging approaches, greater temporal resolution and altered
temporal changeability over a particular time period are provided by EEG signals, which provide its
clinical advantage. Accordingly, precise millisecond readings of electro-physiological alterations may
be derived from EEG. Consequently, temporal data analysis enables the formulation of EEG biomarkers.
The Hilbert transformation’s adoption enables the application of the amplitude envelope to define
the temporal biomarkers. Skewness (Skw) was calculated to get HSkw in relation to the distribution for
every EEG channel, once the amplitude envelope had been established.

Sensors 2020, 20, 59

7 of 21

Therefore, to compute the temporal biomarkers set, first the EEG signal Xk (n), for channel k and n
is the time-domain index, the temporal envelope is then extracted using the Hilbert transform H{.} as
in Equation (3) [79].
q

(3)
ei (n) = Xk (n)2 + H Xk (n) 2
n
o
Let mn = E (x − E{x})n be the nth central moment of the HSkw distributions. The Skw is defined
as in Equation (4).
m3
Skw =
(4)
(m2 )3/2
Skw is the normalized 3rd order moment of amplitude distribution. If the distribution is
symmetrical, then Skw is zero. By contrast, large Skw values are associated with the asymmetry degree
of amplitude distribution [80–82].
2.4. Statistical Analysis
Enhanced comprehension of brain states is a requisite outcome of the approach taken to the
EEG dataset’s mapping. IBM USA’s SPSS program version 25 was adopted to undertake statistical
analysis. Resultantly, four recording areas relating to the cerebral cortex’s scalp region formed the
basis of the initial categorization of the 40 fit participants’ EEG dataset. The dimension of the feature
matrix was (40 subjects × 14 EEG Channels × 7 emotional states) = 3920 attributes for each of spectral,
entropy and temporal biomarkers. The different brain regions’ alternative affective states’ profiles and
affective biomarkers could be directly conveyed by the divergences in brain areas, facilitated by the
mean characteristics of the area. The area mean’s derived characteristics were used to categorize the
various brain regions’ differences, for example occipital (O1 and O2 channels), parietal (P7 and P8
channels), temporal (T7 and T8 channels) and frontal (AF3, F7, F3, FC5, F4, FC6, F8, and AF4 channels).
Subsequently, Levene’s test for homoscedasticity was applied, and the Kolmogorov–Smirnov test was
performed to test the normality assumption required by the ANOVA statistical test. Two methods
of statistical analysis were applied. One established the extent to which brain areas had varying
affective states in relation to temporal, entropy and spectral characteristics, namely the analysis of
variance (ANOVA) test. The brain areas’ various connectivity characteristics were established through
Pearson’s correlation.
2.4.1. ANOVA
There were three aspects to the ANOVA test. Firstly, the distinctive characteristics were subject to
a two-way ANOVA test; the dependent variable related to the spectral biomarker and was the AbsP
characteristic, while the independent variables were the four brain areas (occipital, parietal, temporal
and frontal) as well as the seven emotional states (anger, anxiety, disgust, happiness, sadness, surprise
and neutral).
Secondly, the RCMFE characteristic was subjected to the two-way ANOVA test, with the
independent variables being the brain areas and seven affective states, while the entropy biomarker
was the dependent variable.
Thirdly, the dependent variable of the seven affective states’ amplitude envelope distributions’
HSkw was subject to the two-way ANOVA test, with the temporal biomarker’s independent variable
being the seven affective states and four brain areas.
Duncan’s test was applied in order to provide the post hoc contrast, with p < 0.05 established as
each statistical assessments’ level of significance. Resultantly, the seven affective states and the brain
areas’ possible temporal, entropy and spectral biomarkers are conveyed in this part. The Bonferroni
post hoc test has been conducted to examine multiple comparisons for each group of tests, including
the seven emotional states and the four brain regions.

Sensors 2020, 20, 59

8 of 21

2.4.2. Pearson’s Correlations
As a means of analyzing and revealing the spatial variability and distribution changes in three
different ways along the EEG signals’ length, the spectral, entropy and temporal biomarkers obtained
during the previous section will be integrated into the brain spatial information, thus enabling
an appropriate understanding of emotional significance. Consequently, three stages of Pearson’s
correlation were implemented for developing spectro-spatial (SS), entropy-spatial (ES) and
temporo-spatial (TS) profiles. These patterns offered a concise, consolidated method of EEG profile
representation over the brain regions relating to anger, anxiety, disgust, happiness, sadness, surprise
and neutral emotions.
During each of the three sessions, Pearson’s correlation coefficient (r) was calculated so as to
establish the biomarkers’ correlations, including for the neutral emotional state and six emotion states.
Each correlation analysis under the Pearson’s correlation method was calculated at p < 0.05, reflecting
statistical significance. All correlation sessions were implemented
for every participant.



Determination of every specific affective state’s SS profile— SSanger for anger, SSanxiety for anxiety,






SSdisgust for disgust, SShappiness for happiness, (SSsadness ) for sadness, SSsurprise for surprise)—as
well as SSneutral for the neutral affective state, was undertaken during Pearson’s correlation’s
initial application.




A 2nd session of Pearson’s correlation, the ES profile— ESanger for anger, ESanxiety for anxiety,






ESdisgust for disgust, EShappiness for happiness, (ESsadness ) for sadness, ESsurprise for surprise—as
well as ESneutral for the neutral affective state, were computed.




A 3rd session of Pearson’s correlation, the TS profile— TSanger for anger, TSanxiety for anxiety,






TSdisgust for disgust, TShappiness for happiness, (TSsadness ) for sadness, TSsurprise for surprise)—as
well as TSneutral for the neutral affective state, were obtained.
3. Results
An overall duration of 3840 information points over 30 s intervals for the 14 EEG channels
was subject to characterization. For the seven specific affective activities, the EEG recordings were
distinguished into 10 s parts with 1280 information points being the duration per section. The statistical
analysis methods of ANOVA and Pearson’s correlation were applied to determine the character
extraction findings.
3.1. ANOVA Results
The subsequent parts explore the four brain areas (occipital, parietal, temporal and frontal) in
relation to the seven affective states (anger, anxiety, disgust, sadness, surprise, happiness and neutral)
in relation to the spectral, entropy and temporal biomarker statistical features.
Figure 3 presents the spectral biomarker performance corresponding to each individual emotional
state across the brain regions. It is apparent
that the frontal lobes presented the most significant activity

compared with other brain lobes SpectralFrontal > SpectralTemporal > SpectralOccipital > SpectralParietal .
The highest means were attained for Spectralneutral , which varied significantly from all other emotional
states across each brain region apart from Spectralsurprise . Moreover, the Spectralanger response was
significantly different from Spectralsurprise and Spectralneutral , given that both anger and surprise emotions
were situated in the upper-right quadrant and upper-left quadrant of the valance-arousal circumplex
model respectively. Spectralanxiety was significantly different from Spectralsadness , Spectralsurprise and
Spectralneutral , with anxiety and sadness located in the upper- and lower-right quadrants of the
valance-arousal circumplex model respectively. Meanwhile, surprise was located in the upper-left
quadrant of the valance-arousal circumplex model. The significant differences were established at
p < 0.05 level of significance.

Sensors 2020, 20, 59
Sensors 2019, 19, x FOR PEER REVIEW

9 of 21
9 of 21

Figure
plotofofthe
thespectral
spectralbiomarker
biomarker
anger,
anxiety,
disgust,
happiness,
sadness,
Figure3.3. The
The comparative
comparative plot
forfor
anger,
anxiety,
disgust,
happiness,
sadness,
surprise
emotionalstates
statesover
over
the
frontal,
temporal,
parietal
occipital
regions.
surpriseand
and neutral
neutral emotional
the
frontal,
temporal,
parietal
and and
occipital
brainbrain
regions.

The
has
been
conducted
to examine
multiple
comparisons.
Table
2 shows
TheBonferroni
Bonferronipost
posthoc
hoctest
test
has
been
conducted
to examine
multiple
comparisons.
Table
2
the
post-hoc
emotion
multiple
comparisons
using
Bonferroni
adjustments
for
Spectral
Biomarker.
shows the post-hoc emotion multiple comparisons using Bonferroni adjustments for Spectral
The
post hoc The
testspost
using
the
Bonferroni
correction
revealed
thatrevealed
neutral was
Biomarker.
hoc
tests
using the
Bonferroni
correction
thatstatistically
neutral wassignificant
statisticallyfrom
sadness
and from
happiness
respectively
(p = 0.004,
0.05), anger
statistically
significant
from sadness
significant
sadness
and happiness
respectively
( 𝑝 = was
0.004,
0.05 ), anger
was statistically
significant
from(psadness
and0.05),
happiness
(𝑝 was
= 0.05,
0.05), anxiety
was statistically
significant
from
and
happiness
= 0.05,
anxiety
statistically
significant
from sadness
and happiness
sadness
and
happiness
respectively
(𝑝
=
0.019,
0.002),
sadness
was
statistically
significant
fromand
respectively (p = 0.019, 0.002), sadness was statistically significant from surprise (p = 0.001)
surprisewas
( 𝑝 statistically
= 0.001 ) and
surprisefrom
washappiness
statistically
from happiness
( 𝑝 =3, 0.05
).
surprise
significant
(p significant
= 0.05). Moreover,
from Table
the brain
Moreover,
from
Table
3,
the
brain
region
multiple
comparisons
using
Bonferroni
adjustments
for
region multiple comparisons using Bonferroni adjustments for Spectral Biomarker have been illustrated.
Spectral
Biomarker
have
been illustrated.
Thefrom
frontal
region was
statistically
significant
The
frontal
region was
statistically
significant
temporal,
parietal
and occipital
brainfrom
regions
temporal,
parietal
and
occipital
brain
regions
(𝑝
=
0.05).
(p = 0.05).
Secondly, ANOVA was conducted as a comparative study to check the performance of RCMFE
Table 2. Emotions multiple comparison test using Bonferroni for the spectral biomarker.
entropy biomarkers. The significant differences among the entropy biomarker were evaluated over the
a
(I) Emotion_Class
(J) Emotion_Class
MeanThe
Difference
four brain regions.
The significances
were set at p < 0.05.
temporal(I-J)
lobes𝒑-value
have the
highest mean
Anger
0.659
0.123 From the visual
and they were significantly different from
other brain lobes for
all emotional states.
Anxiety
-0.096
1for the all emotional
inspection
of
Figure
4,
it
can
be
observed
that
the
highest
entropy
values
were
noted


Disgust
-0.349
1 visual inspection
states EntropyTemporal
> EntropyParietal > EntropyOccipital > EntropyFrontal . From the
Neutral
0.004*
Sadness
-0.891
of Figure 4, it can be observed that the highest entropy values were noted for the Entropyanxiety has
0.114
1 for Entropy
highest mean which was significantlySurprise
differenced from all emotional
states except
surprise .
0.05*
Happiness
-1.032
The response of Entropyneutral was significantly different from Entropyanxiety and Entropysurprise as both
Anxiety
-0.755
0.033
anxiety and surprise were located at the
upper right and upper
left quadrant of
the valance-arousal
Disgust
-1.008
0.001
circumplex model, respectively. The significant differences were set at ( p < 0.05).
Anger
0.05*
Sadness
-1.55
Surprise
-0.545
0.477
0.05*
Happiness
-1.691
Disgust
-0.253
1
0.019*
Sadness
-0.795
Anxiety
Surprise
0.21
1
0.002*
Happiness
-0.936

Sensors 2020, 20, 59

10 of 21

Table 2. Emotions multiple comparison test using Bonferroni for the spectral biomarker.
(I) Emotion_Class

Neutral

Anger

Anxiety

Disgust
Sadness
Surprise

(J) Emotion_Class

Mean Difference (I-J)

p-Value a

Anger
Anxiety
Disgust
Sadness
Surprise
Happiness
Anxiety
Disgust
Sadness
Surprise
Happiness
Disgust
Sadness
Surprise
Happiness
Sadness
Surprise
Happiness
Surprise
Happiness
Happiness

0.659
−0.096
−0.349
−0.891
0.114
−1.032
−0.755
−1.008
−1.55
−0.545
−1.691
−0.253
−0.795
0.21
−0.936
−0.542
0.463
−0.683
1.005
−0.141
−1.146

0.123
1
1
0.004 *
1
0.05 *
0.033
0.001
0.05 *
0.477
0.05 *
1
0.019 *
1
0.002 *
0.492
1
0.09
0.001 *
1
0.05 *

* The mean difference is significant at the 0.05 level.

a

Adjustment for multiple comparisons: Bonferroni.

Table 3. Brain regions multiple comparison test using Bonferroni for the spectral biomarker.
(I) Brain Region
Frontal
Temporal
Parietal

(J) Brain Region

Mean Difference (I-J)

p-Value a

Temporal
Parietal
Occipital
Parietal
Occipital
Occipital

1.657
2.812
2.31
1.155
0.653
−0.502

0.05 *
0.05 *
0.05 *
0.05 *
0.038
0.215

* The mean difference is significant at the 0.05 level.

a

Adjustment for multiple comparisons: Bonferroni.

For the entropy biomarkers, Table 4 shows the post hoc emotion multiple comparisons using
Bonferroni adjustments for the entropy biomarker. The post hoc tests using the Bonferroni
correction revealed that anger was statistically significant from disgust and happiness respectively
(p = 0.001, 0.05) and sadness was statistically significant from happiness (p = 0.0035). Moreover,
from Table 5, the brain region multiple comparisons using Bonferroni adjustments for the entropy
biomarker have been illustrated. The frontal region was statistically significant from temporal, parietal
and occipital brain regions (p = 0.05).

emotional states 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
> 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
> 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
> 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
. From the
visual inspection of Figure 4, it can be observed that the highest entropy values were noted for the
𝐸𝑛𝑡𝑟𝑜𝑝𝑦
has highest mean which was significantly differenced from all emotional states except
for 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
. The response of 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
was significantly different from 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
and 𝐸𝑛𝑡𝑟𝑜𝑝𝑦
as both anxiety and surprise were located at the upper right and upper left
Sensors 2020, 20, 59
11 of 21
quadrant of the valance-arousal circumplex model, respectively. The significant differences were set
at ( 𝑝 < 0.05).

Figure 4. The comparative plot of the entropy biomarker for anger, anxiety, disgust, happiness, sadness,
surprise and neutral emotional states over the brain regions.

Table 4. Emotions multiple comparison test using Bonferroni for entropy biomarker.
Emotion

Neutral

Anger

Anxiety

Disgust
Sadness
Surprise

(J) Class_Emotion

Mean Difference (I-J)

p-Value a

Anger
Anxiety
Disgust
Sadness
Surprise
Happiness
Anxiety
Disgust
Sadness
Surprise
happiness
Disgust
Sadness
Surprise
Happiness
Sadness
Surprise
Happiness
Surprise
Happiness
Happiness

−0.03
−0.004
0.014
−0.016
−0.004
0.025
0.026
0.044
0.014
0.027
0.055
0.018
−0.012
0.001
0.029
−0.03
−0.017
0.011
0.012
0.041
0.028

0.095
1
1
1
1
0.435
0.323
0.001 *
1
0.26
0.05 *
1
1
1
0.134
0.109
1
1
1
0.003 *
0.169

* The mean difference is significant at the 0.05 level.

a

Adjustment for multiple comparisons: Bonferroni.

Sensors 2020, 20, 59

12 of 21

Table 5. Brain regions multiple comparison test using Bonferroni for entropy biomarker.
(I) Brain Region
Frontal
Temporal
Parietal

(J) Brain Region

Mean Difference (I-J)

p-Value a

Temporal
Parietal
Occipital
Parietal
Occipital
Occipital

−0.072
−0.062
−0.058
0.01
0.014
0.004

0.05 *
0.05 *
0.05 *
1
1
1

* The mean difference is significant at the 0.05 level.

a

Adjustment for multiple comparisons: Bonferroni.

Thirdly, ANOVA was conducted as a comparative study to check the performance of
temporal biomarkers which have been characterized by the amplitude envelope parameters
using HSkw as temporal biomarkers.
The significant differences among the temporal
biomarkers
were
evaluated
over
the
4
brain
regions. The significances were set at12pof<210.05.
Sensors 2019, 19, x FOR PEER REVIEW
Figure 5 shows the temporal biomarkers of the emotional responses among the brain
biomarkers
of the
emotional
brain regions.
Theinfrontal
the most
regions.
frontal
lobes responses
have the among
most the
significant
activity
comparison
to other
brain
 The
 lobes have
significant
activity
in
comparison
to
other
brain
lobes:
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
>
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
lobes: TemporalFrontal > TemporalOccipital > TemporalParietal > TemporalTemporal . The response to> the
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
The response
to the
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
hashave
the highest
mean.
Temporal
highest mean. .Temporal
Temporal
the same
mean,
anger and
surprise almost
sadness has>the
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
and
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
almost
have
the
same
mean,
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
and
Temporal
and
Temporal
almost
have
the
same
performance
and
finally
Temporal
anxiety
neutral
disgust and
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
almost
have
the
same
performance
and
finally
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
and
Temporalhappiness have the same effect and that related to their distribution within the valance-arousal
𝑇𝑒𝑚𝑝𝑜𝑟𝑎𝑙
have
the
same
effect
and
that
related
to
their
distribution
within
the
valancecircumplex model. The significant differences were set at p < 0.05.
arousal circumplex model. The significant differences were set at 𝑝 < 0.05

Figure
plot of
of the
thetemporal
temporalbiomarkers
biomarkers
anger,
anxiety,
disgust,
happiness,
Figure5.5. The
The comparative
comparative plot
forfor
anger,
anxiety,
disgust,
happiness,
sadness,
surprise
and
neutral
emotional
states
over
the
brain
regions.
sadness, surprise and neutral emotional states over the brain regions.

For
Table 66 shows
showsthe
thepost
posthoc
hocemotion
emotion
multiple
comparisons
using
Forthe
thetemporal
temporal biomarkers,
biomarkers, Table
multiple
comparisons
using
Bonferroni
adjustments
for
the
temporal
biomarker.
The
post
hoc
tests
using
the
Bonferroni
correction
Bonferroni adjustments for the temporal biomarker. The post hoc tests using the Bonferroni
revealed
that
it werethat
not itstatistically
different (p
> 0.05)(𝑝for
seven
emotional
states.. Moreover,
correction
revealed
were not statistically
different
> the
0.05)
for the
seven emotional
states..
from
Table
7,
the
brain
region
multiple
comparisons
using
Bonferroni
adjustments
for theforspectral
Moreover, from Table 7, the brain region multiple comparisons using Bonferroni adjustments
the
biomarker
have been illustrated.
frontal region
was statistically
significant
from
temporal,from
parietal
spectral biomarker
have been The
illustrated.
The frontal
region was
statistically
significant
and
occipital
brain and
regions
respectively
(p = respectively
0.05, 0.05, 0.001).
temporal,
parietal
occipital
brain regions
(𝑝 = 0.05, 0.05, 0.001).
Table 6. Emotions multiple comparison test using Bonferroni for the temporal biomarker.

(I) Class_Emotion

(J) Class_Emotion
Anger
Anxiety

Mean Difference (I-J)
0.031
0.051

𝒑-valuea
1
1

Sensors 2020, 20, 59

13 of 21

Table 6. Emotions multiple comparison test using Bonferroni for the temporal biomarker.
(I) Class_Emotion

(J) Class_Emotion

Mean Difference (I-J)

p-Value a

Anger
Anxiety
Disgust
Sadness
Surprise
Happiness
Anxiety
Disgust
Sadness
Surprise
Happiness
Disgust
Sadness
Surprise
Happiness
Sadness
Surprise
Happiness
Surprise
Happiness
happiness

0.031
0.051
−0.034
0.009
0.062
0.024
0.02
−0.065
−0.022
0.031
−0.007
−0.085
−0.042
0.011
−0.027
0.043
0.096
0.058
0.053
0.015
−0.038

1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0.837
1
1
1
1

Neutral

Anger

Anxiety

Disgust
Sadness
Surprise
a

Adjustment for multiple comparisons: Bonferroni.

Table 7. Brain regions multiple comparison test using Bonferroni for the temporal biomarker.
(I) Brain Region

(J) Brain Region

Mean Difference (I-J)

p-Value a

Temporal
Parietal
Occipital
Parietal
Occipital
Occipital

0.183
0.169
0.136
−0.014
−0.047
−0.034

0.05 *
0.05 *
0.001 *
1
1
1

Frontal
Temporal
Parietal

* The mean difference is significant at the 0.05 level.

a

Adjustment for multiple comparisons: Bonferroni.

3.2. Results of Pearson’s Correlations
During the second statistical analysis stage, Pearson’s correlation coefficients were calculated
relating to the spectral, entropy and temporal biomarkers for the neutral state as well as six emotional
states (anger, anxiety, disgust, happiness, sadness and surprise) per each EEG channel for the frontal,
temporal, parietal and occipital brain regions. Significant differences were calculated as existing
between the various emotions with regard to EEG-based correlation alterations.
The correlations of SSneutral − SSanger, anxiety, disgust,hapiness,sad,surprise were significantly positive in all
cases, as Figure 6 presents. For example, the frontal region SSneutral showed a very strong positive
correlation especially with SSanxiety (r = 0.880, p < 0.01), SSsadness (r = 0.866, p < 0.01) and SSanger (r = 0.857,
p < 0.01). Furthermore, temporal area SSneutral had a very strong positive correlation particularly with
SSanxiety (r = 0.894, p < 0.01), SSanger (r = 0.866, p < 0.01) and SShappiness (r = 0.805, p < 0.01). SSneutral
expressed a very strong positive correlation with SSsadness , SSsurprise and SSanger (r = 0.881, r = 0.861,
r = 0.842, p < 0.01), respectively, in the parietal region. Moreover, SSneutral had a very strong positive
correlation with SSanxiety , SSsadness and SSanger (r = 0.861, r = 0.827, r = 0.861, p < 0.01) in the occipital
region. Overall, SSneutral and SSanger had the highest correlation in the temporal region (r = 0.866,
p < 0.01). SSneutral and SSanxiety had the highest correlation in the temporal region and frontal regions
(r = 0.894, r = 0.880, p < 0.01). SSneutral and SShappiness had the highest correlation in the temporal region

Sensors 2020, 20, 59

14 of 21

(r = 0.805, p < 0.01). SSneutral and SSdisgust had the highest correlation in the temporal region (r = 0.616,
p < 0.01). SSneutral and SSsadness had the highest correlation in the parietal region (r = 0.881, p < 0.01).
SSneutral and SSsurprise had the highest correlation in the parietal region (r = 0.861, r = 0.970, p < 0.01).
Regarding the SS profile, the lowest positive correlation was observed between SSneutral and SSdisgust
in the occipital and parietal regions (r = 0.461, r = 0.489, p < 0.01) respectively. Accordingly, regarding
the
SS emotional profile, the frontal, temporal and parietal lobes participated to the greatest extent
in
Sensors 2019, 19, x FOR PEER REVIEW
14 of 21
emotional elicitation.

Figure 6. SSneutral − SSanger, anxiety, disgust,hapiness,sad,surprise correlations occurring in the frontal, temporal,
Figure 6.
𝑆𝑆 regions.
correlations
,
,
,
,
parietal
and𝑆𝑆occipital−brain
Correlations
of, significance
at 0.05 leveloccurring
(2-tailed). in the frontal,
temporal, parietal and occipital brain regions. Correlations of significance at 0.05 level (2-tailed).

The correlation of ESneutral − ESanger, anxiety, disgust,hapiness,sad,surprise had significant positive
The correlation
of 𝐸𝑆
− 𝐸𝑆
significant
positive
correlations
in all cases,
as shown
in Figure
7. For
instance,
frontalhad
region,
ESneutral
had a
,
,
,
,in the
,
very
strong positive
correlation
particularly
ESanxiety (rin=the
0.684,
p < region,
0.01) and
(r =a0.683,
correlations
in all cases,
as shown
in Figure 7.with
For instance,
frontal
𝐸𝑆ESsadnesshad
very
pstrong
< 0.01).
It
can
be
observed
that
for
the
temporal
region
that
the
ES
had
very
strong
positive
positive correlation particularly with 𝐸𝑆
(𝑟 = 0.684, 𝑝 ˂neutral
0.01) and 𝐸𝑆
(𝑟 = 0.683,
correlation
withthat
ESanxiety
(r =
0.707, p region
< 0.01)that
andthe
ESsadness
0.633,
p <strong
0.01). positive
For the
𝑝 ˂ 0.01). Itparticularly
can be observed
for the
temporal
𝐸𝑆 (r = had
very
parietal
region,
ESneutral had
positive
correlation
particularly
(r
=
0.608,
p
< 0.01).
correlation
particularly
witha strong
𝐸𝑆
(𝑟 = 0.707,
𝑝 ˂ 0.01)
and 𝐸𝑆with ES(𝑟
=
0.633,
𝑝
˂
0.01).
For
anxiety
Moreover,
strong
positive
correlation
with
ESanxiety (rwith
= 0.693,
the
the parietalES
region,
𝐸𝑆 a very
had
a strong
positive
correlation
particularly
𝐸𝑆 p < 0.01)
(𝑟 = at
0.608,
neutral had
occipital
In other
ESneutral
and
ESanger
had the
highest correlation
region
𝑝 ˂ 0.01).region.
Moreover,
𝐸𝑆 wordshad
a very
strong
positive
correlation
with 𝐸𝑆 at the(𝑟frontal
= 0.693,
𝑝 ˂
(r
= 0.621,
< 0.01). ES
and
ESanxiety
had𝐸𝑆the highest
at the
region (r = at
0.707,
0.01)
at thepoccipital
region.
other
words
andcorrelation
𝐸𝑆
had
thetemporal
highest correlation
the
neutral In
pfrontal
< 0.01).
ESneutral
ESdisgust
the𝐸𝑆
highest correlation
= 0.606, p <at0.01).
region
( 𝑟 =and
0.621,
𝑝 ˂ had
0.01).
and 𝐸𝑆 at temporal
had the region
highest(r correlation
the
ES
and
ES
had
the
highest
correlation
at
frontal
region
(r
=
0.533,
p
<
0.01).
ES
and
neutral regionhappiness
temporal
(𝑟 = 0.707, 𝑝 ˂ 0.01). 𝐸𝑆
and 𝐸𝑆
had the highest correlation atneutral
temporal
ES
the highest
correlation
at the
(r = the
0.688,
p < 0.01).
ESneutralatand
ESsurprise
had
sadness
region
(𝑟had
= 0.606,
𝑝 ˂ 0.01).
𝐸𝑆
andfrontal
𝐸𝑆 region had
highest
correlation
frontal
region
(𝑟
the
highest
correlation
at
the
parietal
region
(r
=
0.592,
p
<
0.01).
For
the
ES
profile
the
lowest
positive
= 0.533, 𝑝 ˂ 0.01). 𝐸𝑆
and 𝐸𝑆
had the highest correlation at the frontal region (𝑟 = 0.688,
correlation
can be seen
EShad
EShappiness
at theattemporal
region
(r = 0.456,
p < 0.01).
neutral
𝑝 ˂ 0.01). 𝐸𝑆
and between
𝐸𝑆
theand
highest
correlation
the parietal
region
(𝑟 = 0.592,
𝑝 ˂
Therefore,
for
the
ES
emotional
profile
the
frontal
lobes
were
mostly
participating
in
anger,
happiness
0.01). For the 𝐸𝑆 profile the lowest positive correlation can be seen between 𝐸𝑆
and
and
states,
whereas
temporal
lobes
were responsible
foremotional
anxiety and
disgust
𝐸𝑆 sadnessatemotional
the temporal
region
(𝑟 = the
0.456,
𝑝 ˂ 0.01).
Therefore,
for the 𝐸𝑆
profile
the
emotional
elicitation.
frontal lobes
were mostly participating in anger, happiness and sadness emotional states, whereas
the temporal lobes were responsible for anxiety and disgust emotional elicitation.

Sensors
Sensors 2020,
2019, 20,
19, 59
x FOR PEER REVIEW

15
15 of
of 21
21

Figure 7. ESneutral − ESanger, anxiety, disgust,hapiness,sad,surprise correlations occurring in the frontal, temporal,
Figure 7.
𝐸𝑆 regions.
correlations
,
,
,
,
parietal
and𝐸𝑆
occipital−brain
Correlations
of, significance
at 0.05 level occurring
(2-tailed). in the frontal,
temporal, parietal and occipital brain regions. Correlations of significance at 0.05 level (2-tailed).

The correlation of TSneutral − TSanger, anxiety, disgust,hapiness,sad,surprise is shown in Figure 8. For instance,
correlation
ofneutral
𝑇𝑆 had a−moderate
𝑇𝑆
is shown
Figure
For
in theThe
frontal
region, TS
correlation
with TSin
(r = 8.
0.509,
, positive
,
,
, particularly
,
sadness
pinstance,
< 0.01). in
It can
observed
that𝑇𝑆for the temporal
area thepositive
TSneutral correlation
had a moderate
correlation
the be
frontal
region,
had a moderate
particularly
with
particularly
TSsadness
= 0.506,
p < 0.01).
TSneutral that
had afor
moderate
positive
correlation
𝑇𝑆
(𝑟with
= 0.509,
𝑝 ˂(r0.01).
It can
be observed
the temporal
area
the 𝑇𝑆 with TS
had
angera
(r
= 0.402, pcorrelation
< 0.01) at the
parietal region,
had a moderate
positive
moderate
particularly
with 𝑇𝑆respectively.
(𝑟 = Moreover,
0.506, 𝑝 ˂TS
0.01).
had a moderate
neutral𝑇𝑆
correlation
with TSdisgust
= 0.598,(𝑟
p <= 0.01)
region.
In other
words
TSneutral and
TSanger
positive correlation
with(r𝑇𝑆
0.402,at𝑝the
˂ occipital
0.01) at the
parietal
region,
respectively.
Moreover,
had
at the parietal
region
(r =𝑇𝑆
0.402, p <(𝑟0.01).
TSneutral
had the
𝑇𝑆 the highest
had a correlation
moderate positive
correlation
with
= 0.598,
𝑝 ˂ and
0.01)TS
atanxiety
the occipital
highest
correlation
at the
region
p <highest
0.01). TS
TS
had the
highest
region. In
other words
𝑇𝑆frontal and
𝑇𝑆(r = 0.300,
had the
correlation
the
parietal
region
(𝑟 =
neutral andat
disgust
correlation
at
the
occipital
region
(r
=
0.598,
p
<
0.01).
TS
and
TS
had
the
highest
correlation
0.402, 𝑝 ˂ 0.01). 𝑇𝑆
and 𝑇𝑆
had the highest
correlation
at the frontal region (𝑟 = 0.300,
neutral
happiness
at
occipital
(r =
< 0.01).
TSneutralcorrelation
and TSsadness
hadoccipital
the highest
correlation
at 𝑝
the˂
𝑝 the
˂ 0.01).
𝑇𝑆 region
and
𝑇𝑆0.377, phad
the highest
at the
region
(𝑟 = 0.598,
temporal
region
(r
=
0.560,
p
<
0.01).
TS
and
TS
had
the
highest
correlation
at
the
occipital
surprise
neutral
0.01). 𝑇𝑆
and 𝑇𝑆
had the
highest correlation
at the occipital region (𝑟 = 0.377, 𝑝 ˂
region
(r = 0.417,and
p < 𝑇𝑆
0.01). Forhad
the the
TS highest
profile the
lowest positive
correlation
was(𝑟observed
0.01). 𝑇𝑆
correlation
at the temporal
region
= 0.560, 𝑝between
˂ 0.01).
TS
the the
temporal
(r = 0.03,
p<
0.01). Therefore,
the TS
happiness athad
𝑇𝑆neutral and
andTS𝑇𝑆
highestregion
correlation
at the
occipital
region (𝑟 =for
0.417,
𝑝 ˂emotional
0.01). For
profile,
frontal,
temporal
and occipital
lobes
were
mostlybetween
participating
the 𝑇𝑆 the
profile
the lowest
positive
correlation
was
observed
𝑇𝑆 in emotional
and 𝑇𝑆 elicitation.
at the
temporal region (𝑟 = 0.03, 𝑝 ˂ 0.01). Therefore, for the 𝑇𝑆 emotional profile, the frontal, temporal
and occipital lobes were mostly participating in emotional elicitation.

Sensors 2020, 20, 59
Sensors 2019, 19, x FOR PEER REVIEW

16 of 21
16 of 21

Figure 8. TSneutral − TSanger, anxiety, disgust,hapiness,sad,surprise correlations occurring in the frontal, temporal,
Figure 8. 𝑇𝑆
− 𝑇𝑆
correlations occurring in the frontal,
,
,
,
,
,
parietal and occipital brain regions. Correlations of significance at 0.05 level (2-tailed).
temporal, parietal and occipital brain regions. Correlations of significance at 0.05 level (2-tailed).

4. Discussion
4. Discussion
EEG’s utility as a clinical tool for analyzing functional changes associated with different emotional
as disgust,
a clinical
tool for sadness,
analyzing
functional
changesacross
associated
with
different
statesEEG’s
(anger,utility
anxiety,
happiness,
surprise
and neutral)
different
brain
areas
emotional
states
(anger,
anxiety,
disgust,
happiness,
sadness,
surprise
and
neutral)
across
different
(frontal, temporal, parietal and occipital scalp) is of considerable interest. In this regard, the research has
brain areas a(frontal,
temporal, connection
parietal and
occipital
is and
of considerable
interest.
In this regard,
established
novel conceptual
between
thescalp)
SS, ES
TS profiles and
the aforementioned
the
research
has
established
a
novel
conceptual
connection
between
the
𝑆𝑆,
𝐸𝑆
and
𝑇𝑆
profiles and
emotional states across the brain regions. Conventional filters were employed to provide a preprocessing
the
aforementioned
emotional
states
across
the
brain
regions.
Conventional
filters
were
employed
to
stage. A total of 14 channels across the various scalp regions were recorded while participants viewed
provide
a preprocessing
stage. A total
of 14clips.
channels
various
scalp regions
recorded
seven
brief
emotional audio-visual
video
The across
variousthe
domain
features
duringwere
this research,
while
participants
viewed
seven
brief
emotional
audio-visual
video
clips.
The
various
domain
including spectral, entropy and temporal features, were computed so as to illustrate key EEG biomarkers
features
during
this
research,
including
spectral,
entropy
and
temporal
features,
were
computed
so
relating to several emotional states. To provide more in-depth investigation, SS, ES and TS EEG
as to illustrate
keywere
EEGdeveloped
biomarkers
relating
several emotional
To provide
in-depth
emotional
profiles
through
theto
multivariate
additionstates.
of spectral,
entropymore
and temporal
investigation,
𝑆𝑆
,
𝐸𝑆
and
𝑇𝑆
EEG
emotional
profiles
were
developed
through
the
multivariate
characteristics to spatial information. Overall, from the visual inspection of the spectral and temporal
addition of it
spectral,
entropy
and
temporal
characteristics
to responsible
spatial information.
Overall,
from
the
biomarkers,
was found
that the
frontal
regions
are particularly
for emotion
detection
while
visual
inspection
of
the
spectral
and
temporal
biomarkers,
it
was
found
that
the
frontal
regions
are
experiencing anger and anxiety in the upper-right quadrant of the valence-arousal circumplex model,
particularly
responsible
for
emotion
detection
while
experiencing
anger
and
anxiety
in
the
upperwhereas sadness and disgust appear in the lower-right left quadrant of the valence-arousal circumplex
right quadrant
of and
the valence-arousal
whereas sadness
and
appear in the
model.
Surprise
happiness werecircumplex
situated inmodel,
the upper-left
quadrant
ofdisgust
the valence-arousal
lower-right
left
quadrant
of
the
valence-arousal
circumplex
model.
Surprise
and
happiness
were
circumplex model. The entropy biomarkers evidenced that the temporal regions were especially
situated
in
the
upper-left
quadrant
of
the
valence-arousal
circumplex
model.
The
entropy
biomarkers
activated in the detection of emotion while experiencing anxiety and surprise, in the valence-arousal
evidenced model’s
that the upper-right
temporal regions
were especially
in the
detection
of the
emotion
while
circumplex
and upper-left
quadrantsactivated
respectively.
Table
8 presents
most highly
experiencing
anxiety
and
surprise,
in
the
valence-arousal
circumplex
model’s
upper-right
and
uppercorrelated emotions with neutral for the SS, ES and TS profiles across the four brain regions. It was
left quadrants
Table 8 presents
most
highlylobes
correlated
emotions
with neutral
the
evidenced
thatrespectively.
the frontal, temporal,
parietalthe
and
occipital
are primarily
responsible
for for
anger,
𝑆𝑆,
𝐸𝑆
and
𝑇𝑆
profiles
across
the
four
brain
regions.
It
was
evidenced
that
the
frontal,
temporal,
anxiety and sadness elicitations. Emotions such as surprise are detectable in the frontal and parietal
parietal
and occipital
are primarily
anxiety
and sadness
elicitations.
lobes
whereas
happinesslobes
and disgust
may be responsible
elicited fromfor
theanger,
temporal
and occipital
lobes respectively.
Emotions such
as findings
surpriseimply
are detectable
in the frontal
parietal
lobesand
whereas
happiness
and
Accordingly,
such
that the combination
of and
spectral,
entropy
temporal
feature sets
disgust
may
be
elicited
from
the
temporal
and
occipital
lobes
respectively.
Accordingly,
such
findings
could provide and convey more reliable biomarkers as a means of identifying SS, ES and TS profiles
imply that the combination of spectral, entropy and temporal feature sets could provide and convey
more reliable biomarkers as a means of identifying 𝑆𝑆 , 𝐸𝑆 and 𝑇𝑆 profiles for anger, anxiety,

Sensors 2020, 20, 59

17 of 21

for anger, anxiety, disgust, happiness, sadness, surprise and neutral emotional states across the frontal,
temporal, parietal and occipital scalp brain areas. The SS profile is significant in representing how
anger emotions correspond to all brain lobes, while the ES profile is significant for representing anxiety
emotions. Additionally, the TS profile is important for representing the sadness emotions.
Regarding the neuro-scientific perspective, all of the obtained results are consistent with the
frontal, temporal, parietal and occipital brain lobes’ principal functions. The frontal lobe is deemed to
be the emotional control center [83,84], while temporal lobes are linked to emotional perception [85].
Resultantly, to obtain greater insight into EEG emotional states, we incorporated several features
from spectral, entropy and temporal aspects, enabling the identification of the most reliable EEG
emotional biomarkers, as well as the development of the SS, ES and TS profiles as benchmarks for
deeper inspection.
To sum up, emotions play a critical role in our day-to-day lives. Emotion investigation can gain a
deeper understanding of human complex behavior. Emotions like happiness are considered as positive
emotions that have been linked to a variety of outcomes including increased longevity and increased
marital satisfaction [82]. Conversely, anger, anxiety and sadness are often thought of as negative
emotions that have been linked to decreased life expectancy and may even have an impact on physical
health [83,84]. Therefore, to capture and characterize people’s everyday emotional experiences, many
recent scientific works validate the use of EEG as a diagnostic tool that is widely used in everyday life.
So far, spectral, entropy and temporal biomarkers and SS, ES and TS EEG emotional profiles might be
valuable physiological information that help in improving emotional investigation procedure.
Table 8.
The most correlated emotions with neutral for spectro − spatial (SS), entropy −
(
)
spatial ES and temporo − spatial (TS) profiles over the frontal, temporal, parietal and occipital
brain regions.
Profiles
SS
ES
TS

Frontal

Temporal

anger, anxiety,
sadness, surprise
anxiety, sadness
sadness

anger, anxiety,
happiness
anxiety, sadness
sadness

Parietal
anger, sadness, surprise
anxiety
anger, sadness, surprise

Occipital
anger, sadness,
surprise
anxiety
disgust

5. Conclusions
In this study, EEG has been adopted for eliciting information in terms of waveform distribution
over the scalp. The spectral, entropy and temporal biomarkers for emotion identification have been
performed. These biomarkers were integrated to develop SS, ES and TS emotional profiles over
the brain regions. The EEGs of 40 healthy volunteer students from the University of Vienna were
recorded while they viewed seven brief emotional video clips. ANOVA has been conducted to identify
the emotional biomarkers and Pearson’s correlations have been employed to determine the EEG
emotion profiles. The results evidence that the combination of applied spectral, entropy and temporal
sets of features may provide and convey reliable biomarkers for identifying SS, ES and TS profiles
relating to different emotional states over the brain areas. EEG biomarkers and profiles enable more
comprehensive insights into various human behavior effects as an intervention on the brain.
Author Contributions: N.K.A.-Q.: Analysis, and interpretation of the EEG data for the work; drafting the
manuscript. M.K.S.: Revising the work critically for important intellectual content. S.H.B.M.A.: Revising the
work; support the article by fund. S.A.A.: Revising the work critically for important intellectual content. K.G.:
Acquisition the EEG signals. All authors have read and agreed to the published version of the manuscript.
Acknowledgments: This research was partially supported by Universiti Kebangsaan Malaysia and Ministry of
Education, Malaysia, Grant Code FRGS/1/2018/TK04/UKM/02/2.
Conflicts of Interest: The authors declare no conflict of interest.

Sensors 2020, 20, 59

18 of 21

References
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.

14.
15.
16.
17.
18.

19.
20.
21.
22.
23.

24.

Jerritta, S.; Murugappan, M.; Khairunizam, W.; Yaacob, S. Electrocardiogram-based emotion recognition
system using empirical mode decomposition and discrete Fourier transform. Expert Syst. 2014, 31, 110–120.
Xu, T.; Zhou, Y.; Wang, Z.; Peng, Y. Learning emotions EEG-based recognition and brain activity: A survey
study on BCI for intelligent tutoring system. Procedia Comput. Sci. 2018, 130, 376–382. [CrossRef]
Murugappan, M.; Ramachandran, N.; Sazali, Y. Classification of human emotion from EEG using discrete
wavelet transform. J. Biomed. Sci. Eng. 2010, 3, 390. [CrossRef]
Bos, D.O. EEG-based emotion recognition. Influ. Vis. Audit. Stimuli 2006, 56, 1–17.
Zaki, J.; Davis, J.I.; Ochsner, K.N. Overlapping activity in anterior insula during interoception and emotional
experience. Neuroimage 2012, 62, 493–499. [CrossRef]
Barrett, L.F. Discrete emotions or dimensions? The role of valence focus and arousal focus. Cogn. Emot. 1998,
12, 579–599. [CrossRef]
Ekman, P. An argument for basic emotions. Cogn. Emot. 1992, 6, 169–200. [CrossRef]
Mehrabian, A. Pleasure-arousal-dominance: A general framework for describing and measuring individual
differences in temperament. Curr. Psychol. 1996, 14, 261–292. [CrossRef]
Wang, X.-W.; Nie, D.; Lu, B.-L. Emotional state classification from EEG data using machine learning approach.
Neurocomputing 2014, 129, 94–106. [CrossRef]
Mauss, I.B.; Robinson, M.D. Measures of emotion: A review. Cogn. Emot. 2009, 23, 209–237. [CrossRef]
Soroush, M.Z.; Maghooli, K.; Setarehdan, S.K.; Nasrabadi, A.M. Emotion classification through nonlinear
EEG analysis using machine learning methods. Int. Clin. Neurosci. J. 2018, 5, 135–149. [CrossRef]
Kensinger, E.A. Remembering emotional experiences: The contribution of valence and arousal. Rev. Neurosci.
2004, 15, 241–252. [CrossRef] [PubMed]
Maaoui, C.; Pruski, A. Emotion recognition through physiological signals for human-machine communication.
In Cutting Edge Robotics 2010; Vedran, K., Alex, L., Munir, M., Eds.; Intech Open: London, UK, 2005;
Available online: https://www.intechopen.com/books/cutting-edge-robotics-2010/emotion-recognitionthrough-physiological-signals-for-human-machine-communication (accessed on 1 October 2010).
Shaheen, R.; Coifman, K.; Flynn, J.; Matt, L.; Halachoff, D. A film set for the elicitation of emotion in research:
A comprehensive catalog derived from four decades of investigation. Behav. Res. methods 2017, 6, 2061–2082.
Selvaraj, J.; Murugappan, M.; Wan, K.; Yaacob, S. Classification of emotional states from electrocardiogram
signals: A non-linear approach based on hurst. Biomed. Eng. Online 2013, 12, 44. [CrossRef]
Schaefer, A.; Nils, F.; Sanchez, X.; Philippot, P. Assessing the effectiveness of a large database of
emotion-eliciting films: A new tool for emotion researchers. Cogn. Emot. 2010, 24, 1153–1172. [CrossRef]
Ping, H.Y.; Abdullah, L.N.; Halin, A.A.; Sulaiman, P.S. A study of physiological signals-based emotion
recognition systems. Int. J. Comput. Technol. 2013, 11, 2189–2196. [CrossRef]
Kushki, A.; Fairley, J.; Merja, S.; King, G.; Chau, T. Comparison of blood volume pulse and skin conductance
responses to mental and affective stimuli at different anatomical sites. Physiol. Meas. 2011, 32, 1529.
[CrossRef]
Kuraoka, K.; Nakamura, K. The use of nasal skin temperature measurements in studying emotion in macaque
monkeys. Physiol. Behav. 2011, 102, 347–355. [CrossRef]
Al-Zidi, M.G.; Santhosh, J.; Ng, S.C.; Bakar, A.R.A.; Ibrahim, I.A. Cortical auditory evoked potentials as
indicators of hearing aids performance in speech perception. J. Eng. Res. 2017, 5, 76–94.
Agrafioti, F.; Hatzinakos, D.; Anderson, A.K. ECG pattern analysis for emotion detection. IEEE Trans. Affect.
Comput. 2011, 3, 102–115. [CrossRef]
Künecke, J.; Hildebrandt, A.; Recio, G.; Sommer, W.; Wilhelm, O. Facial EMG responses to emotional
expressions are related to emotion perception ability. PLoS ONE 2014, 9, e84053. [CrossRef] [PubMed]
Vecchiato, G.; Toppi, J.; Astolfi, L.; Fallani, F.D.V.; Cincotti, F.; Mattia, D.; Bez, F.; Babiloni, F. Spectral EEG
frontal asymmetries correlate with the experienced pleasantness of TV commercial advertisements. Med.
Biol. Eng. Comput. 2011, 49, 579–583. [CrossRef] [PubMed]
Coan, J.A.; Allen, J.J. Frontal EEG asymmetry as a moderator and mediator of emotion. Biol. Psychol. 2004,
67, 7–50. [CrossRef] [PubMed]

Sensors 2020, 20, 59

25.

26.
27.
28.

29.

30.

31.
32.
33.

34.

35.
36.

37.
38.
39.

40.
41.
42.
43.

44.

19 of 21

Di Flumeri, G.; Aricò, P.; Borghini, G.; Sciaraffa, N.; Maglione, A.G.; Rossi, D.; Modica, E.; Trettel, A.;
Babiloni, F.; Colosimo, A. EEG-based approach-withdrawal index for the pleasantness evaluation during
taste experience in realistic settings. In Proceedings of the 2017 39th annual international conference of the
IEEE engineering in medicine and biology society (EMBC), Seogwipo, Korea, 11–15 July 2017; pp. 3228–3231.
Zheng, W.-L.; Lu, B.-L. Investigating critical frequency bands and channels for EEG-based emotion recognition
with deep neural networks. IEEE Trans. Auton. Ment. Dev. 2015, 7, 162–175. [CrossRef]
Alarcao, S.M.; Fonseca, M.J. Emotions recognition using EEG signals: A survey. IEEE Trans. Affect. Comput.
2017, 10, 374–393. [CrossRef]
Al-Qazzaz, N.K.; Sabir, M.K.; Grammer, K. Gender differences identification from brain regions using
spectral relative powers of emotional EEG. In Proceedings of the 2019 7th International Work-Conference on
Bioinformatics and Biomedical Engineering, Granada, Spain, 8–10 May 2019; pp. 38–42.
Al-Qazzaz, N.K.; Sabir, M.K.; Grammer, K. Correlation indices of electroencephalogram-based relative
powers during human emotion processing. In Proceedings of the 2019 9th International Conference on
Biomedical Engineering and Technology, Tokyo, Japan, 28–30 March 2019; pp. 64–70.
Al-Qazzaz, N.K.; Sabir, M.K.; Ali, S.; Ahmad, S.A.; Grammer, K. Effective EEG Channels for emotion
identification over the brain regions using differential evolution algorithm. In Proceedings of the 2019 41th
Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Berlin,
Germany, 23–27 July 2019.
Xie, S.; Krishnan, S. Wavelet-based sparse functional linear model with applications to EEGs seizure detection
and epilepsy diagnosis. Med. Biol. Eng. Comput. 2013, 51, 49–60. [CrossRef]
Abásolo, D.; Hornero, R.; Espino, P.; Alvarez, D.; Poza, J. Entropy analysis of the EEG background activity in
Alzheimer’s disease patients. Physiol. Meas. 2006, 27, 241. [CrossRef]
Al-Qazzaz, N.; Hamid Bin Mohd Ali, S.; Ahmad, S.; Islam, M.; Escudero, J. Automatic artifact removal in
EEG of normal and demented individuals using ICA–WT during working memory tasks. Sensors 2017, 17,
1326. [CrossRef]
Al-Qazzaz, N.K.; Ali, S.H.B.M.; Ahmad, S.A.; Islam, M.S.; Escudero, J. Discrimination of stroke-related mild
cognitive impairment and vascular dementia using EEG signal analysis. Med. Biol. Eng. Comput. 2017, 56,
1–21. [CrossRef]
Davidson, P.R.; Jones, R.D.; Peiris, M.T. EEG-based lapse detection with high temporal resolution. IEEE Trans.
Biomed. Eng. 2007, 54, 832–839. [CrossRef]
Vecchio, F.; Babiloni, C.; Lizio, R.; Fallani, F.V.; Blinowska, K.; Verrienti, G.; Frisoni, G.; Rossini, P. Resting
state cortical EEG rhythms in Alzheimer’s disease: Toward EEG markers for clinical applications: A review.
Suppl. Clin. Neurophysiol. 2012, 62, 223–236.
Al-Qazzaz, N.K.; Ali, S.H.B.; Ahmad, S.A.; Chellappan, K.; Islam, M.S.; Escudero, J. Role of EEG as biomarker
in the early detection and classification of dementia. Sci. World J. 2014, 2014. [CrossRef] [PubMed]
Urigüen, J.A.; Garcia-Zapirain, B. EEG artifact removal-state-of-the-art and guidelines. J. Neural Eng. 2015,
12, 031001. [CrossRef] [PubMed]
Al-Kadi, M.I.; Reaz, M.B.I.; Ali, M.A.M.; Liu, C.Y. Reduction of the dimensionality of the EEG channels
during scoliosis correction surgeries using a wavelet decomposition technique. Sensors 2014, 14, 13046–13069.
[CrossRef]
Pizzagalli, D.A. Electroencephalography and high-density electrophysiological source localization. Handb.
Psychophysiol. 2007, 3, 56–84.
Jeong, J. EEG dynamics in patients with Alzheimer’s disease. Clin. Neurophysiol. 2004, 115, 1490–1505.
[CrossRef]
John, E.; Prichep, L.; Fridman, J.; Easton, P. Neurometrics: Computer-assisted differential diagnosis of brain
dysfunctions. Science 1988, 239, 162–169. [CrossRef]
Leuchter, A.F.; Cook, I.A.; Newton, T.F.; Dunkin, J.; Walter, D.O.; Rosenberg-Thompson, S.; Lachenbruch, P.A.;
Weiner, H. Regional differences in brain electrical activity in dementia: Use of spectral power and spectral
ratio measures. Electroencephalogr. Clin. Neurophysiol. 1993, 87, 385–393. [CrossRef]
Lizio, R.; Vecchio, F.; Frisoni, G.B.; Ferri, R.; Rodriguez, G.; Babiloni, C. Electroencephalographic rhythms in
Alzheimer’s disease. Int. J. Alzheimer’s Dis. 2011, 2011. [CrossRef]

Sensors 2020, 20, 59

45.

46.

47.
48.
49.
50.
51.

52.
53.

54.

55.
56.
57.
58.
59.
60.
61.

62.
63.
64.

65.
66.
67.

20 of 21

Yuvaraj, R.; Murugappan, M.; Ibrahim, N.M.; Omar, M.I.; Sundaraj, K.; Mohamad, K.; Palaniappan, R.;
Mesquita, E.; Satiyan, M. On the analysis of EEG power, frequency and asymmetry in Parkinson’s disease
during emotion processing. Behav. Brain Funct. 2014, 10, 12. [CrossRef]
Yang, Y.; Wu, Q.; Qiu, M.; Wang, Y.; Chen, X. Emotion recognition from multi-channel EEG through parallel
convolutional recurrent neural network. In Proceedings of the 2018 International Joint Conference on Neural
Networks (IJCNN), Rio de Janeiro, Brazil, 8–13 July 2018; pp. 1–7.
Li, M.; Xu, H.; Liu, X.; Lu, S. Emotion recognition from multichannel EEG signals using K-nearest neighbor
classification. Technol. Health Care 2018, 26, 1–11. [CrossRef] [PubMed]
Chao, H.; Zhi, H.; Dong, L.; Liu, Y. Recognition of emotions using multichannel EEG data and DBN-GC-based
ensemble deep learning framework. Comput. Intell. Neurosci. 2018, 2018. [CrossRef] [PubMed]
Thammasan, N.; Moriyama, K.; Fukui, K.-i.; Numao, M. Continuous music-emotion recognition based on
electroencephalogram. IEICE Trans. Inf. Syst. 2016, 99, 1234–1241. [CrossRef]
Sourina, O.; Liu, Y.; Nguyen, M.K. Real-time EEG-based emotion recognition for music therapy. J. Multimodal
User Interfaces 2012, 5, 27–35. [CrossRef]
Chandran, V.; Acharya, R.; Lim, C. Higher order spectral (HOS) analysis of epileptic EEG signals.
In Proceedings of the 2007 29th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society, Lyon, France, 22–26 August 2007; pp. 6495–6498.
Lan, Z.; Sourina, O.; Wang, L.; Liu, Y. Real-time EEG-based emotion monitoring using stable features. Vis.
Comput. 2016, 32, 347–358. [CrossRef]
Jin, M.J.; Kim, J.S.; Kim, S.; Hyun, M.H.; Lee, S.-H. An integrated model of emotional problems, beta power of
electroencephalography, and low frequency of heart rate variability after childhood trauma in a non-clinical
sample: A path analysis study. Front. Psychiatry 2018, 8, 314. [CrossRef]
García-Martínez, B.; Martínez-Rodrigo, A.; Zangróniz Cantabrana, R.; Pastor García, J.; Alcaraz, R. Application
of entropy-based metrics to identify emotional distress from electroencephalographic recordings. Entropy
2016, 18, 221. [CrossRef]
Mehmood, R.M.; Lee, H.J. Towards emotion recognition of EEG brain signals using Hjorth parameters and
SVM. Adv. Sci. Technol. Lett. Biosci. Med. Res. 2015, 91, 24–27.
Ruiz-Padial, E.; Ibanez-Molina, A.J. Fractal dimension of EEG signals and heart dynamics in discrete
emotional states. Biol. Psychol. 2018, 137, 42–48. [CrossRef]
Yuen, C.T.; San San, W.; Seong, T.C.; Rizon, M. Classification of human emotions from EEG signals using
statistical features and neural network. Int. J. Integr. Eng. 2009, 1. [CrossRef]
Yuen, C.T.; San San, W.; Ho, J.-H.; Rizon, M. Effectiveness of statistical features for human emotions
classification using EEG biosensors. Res. J. Appl. Sci. Eng. Technol. 2013, 5, 5083–5089. [CrossRef]
Bandt, C.; Pompe, B. Permutation entropy: A natural complexity measure for time series. Phys. Rev. Lett.
2002, 88, 174102. [CrossRef] [PubMed]
Azami, H.; Escudero, J. Amplitude-aware permutation entropy: Illustration in spike detection and signal
segmentation. Comput. Methods Programs Biomed. 2016, 128, 40–51. [CrossRef]
Martínez-Rodrigo, A.; García-Martínez, B.; Zunino, L.; Alcaraz, R.; Fernández-Caballero, A. Multi-lag
analysis of symbolic entropies on EEG recordings for distress recognition. Front. Neuroinform. 2019, 13, 40.
[CrossRef] [PubMed]
Li, L.; Cao, R.; Xiang, J. Comparative study of approximate entropy and sample entropy based on
characterization of EEG. Comput. Eng. Des. 2014, 35, 1021–1026.
Tian, J.; Luo, Z. Motor imagery EEG feature extraction based on fuzzy entropy. J. Huazhong Univ. Sci. Technol
2013, 41, 92–95.
Cao, Y.; Cai, L.; Wang, J.; Wang, R.; Yu, H.; Cao, Y.; Liu, J. Characterization of complexity in the
electroencephalograph activity of Alzheimer’s disease based on fuzzy entropy. Chaos Interdiscip. J. Nonlinear
Sci. 2015, 25, 083116. [CrossRef]
Azami, H.; Fernández, A.; Escudero, J. Refined multiscale fuzzy entropy based on standard deviation for
biomedical signal analysis. Med. Biol. Eng. Comput. 2017, 55, 2037–2052. [CrossRef]
Zheng, J.; Tu, D.; Pan, H.; Hu, X.; Liu, T.; Liu, Q. A refined composite multivariate multiscale fuzzy entropy
and laplacian score-based fault diagnosis method for rolling bearings. Entropy 2017, 19, 585. [CrossRef]
Azami, H.; Escudero, J. Refined composite multivariate generalized multiscale fuzzy entropy: A tool for
complexity analysis of multichannel signals. Phys. A Stat. Mech. Appl. 2017, 465, 261–276. [CrossRef]

Sensors 2020, 20, 59

68.

69.

70.

71.
72.
73.

74.
75.
76.

77.
78.

79.

80.
81.
82.
83.
84.

85.

21 of 21

Al-Qazzaz, N.K.; Ali, S.; Islam, M.S.; Ahmad, S.A.; Escudero, J. EEG markers for early detection and
characterization of vascular dementia during working memory tasks. In Proceedings of the 2016 IEEE EMBS
Conference on Biomedical Engineering and Sciences (IECBES), Kuala Lumpur, Malaysia, 4–8 December 2016;
pp. 347–351.
Al-Qazzaz, N.K.; Ali, S.; Islam, S.; Ahmad, S.; Escudero, J. EEG wavelet spectral analysis during a working
memory tasks in stroke-related mild cognitive impairment patients. In Proceedings of the International
Conference for Innovation in Biomedical Engineering and Life Sciences, Putrajaya, Malaysia, 6–8 December
2015; pp. 82–85.
Al-Qazzaz, N.K.; Ali, S.; Ahmad, S.A.; Islam, M.S.; Escudero, J. Entropy-based markers of EEG background
activity of stroke-related mild cognitive impairment and vascular dementia patients. In Proceedings of the
2nd International Conference on Sensors Engineering and Electronics Instrumental Advances (SEIA 2016),
Barcelona, Spain, 22–23 September 2016.
Xing, B.; Zhang, H.; Zhang, K.; Zhang, L.; Wu, X.; Shi, X.; Yu, S.; Zhang, S. Exploiting EEG signals and
audiovisual feature fusion for video emotion recognition. IEEE Access 2019, 7, 59844–59861. [CrossRef]
Rottenberg, J.; Gross, J.J.; Wilhelm, F.H.; Najmi, S.; Gotlib, I.H. Crying threshold and intensity in major
depressive disorder. J. Abnorm. Psychol. 2002, 111, 302. [CrossRef] [PubMed]
Abásolo, D.; Escudero, J.; Hornero, R.; Gómez, C.; Espino, P. Approximate entropy and auto mutual
information analysis of the electroencephalogram in Alzheimer’s disease patients. Med. Biol. Eng. Comput.
2008, 46, 1019–1028. [CrossRef] [PubMed]
Teplan, M.; Krakovská, A.; Špajdel, M. Spectral EEG features of a short psycho-physiological relaxation.
Meas. Sci. Rev. 2014, 14, 237–242. [CrossRef]
Kang, J.; Zhou, T.; Han, J.; Li, X. EEG-based multi-feature fusion assessment for autism. J. Clin. Neurosci.
2018, 56, 101–107. [CrossRef]
Clerico, A.; Tiwari, A.; Gupta, R.; Jayaraman, S.; Falk, T.H. Electroencephalography amplitude modulation
analysis for automated affective tagging of music video clips. Front. Comput. Neurosci. 2018, 11, 115.
[CrossRef]
Mammone, N.; Morabito, F.C. Enhanced automatic artifact detection based on independent component
analysis and Renyi’s entropy. Neural Netw. 2008, 21, 1029–1040. [CrossRef]
Escudero, J.; Hornero, R.; Abásolo, D.; Fernández, A. Quantitative evaluation of artifact removal in real
magnetoencephalogram signals with blind source separation. Ann. Biomed. Eng. 2011, 39, 2274–2286.
[CrossRef]
Escudero, J.; Hornero, R.; Abásolo, D.; Fernández, A.; López-Coronado, M. Artifact removal in
magnetoencephalogram background activity with independent component analysis. IEEE Trans. Biomed.
Eng. 2007, 54, 1965–1973. [CrossRef]
Davidson, R.J.; Begley, S. The Emotional Life of Your Brain: How Its Unique Patterns Affect the Way You Think,
Feel, and Live–and How You Can Change Them; Hachette: London, UK, 2012.
Goghari, V.M.; MacDonald III, A.W.; Sponheim, S.R. Temporal lobe structures and facial emotion recognition
in schizophrenia patients and nonpsychotic relatives. Schizophr. Bull. 2010, 37, 1281–1294. [CrossRef]
Lawrence, E.M.; Rogers, R.G.; Wadsworth, T. Happiness and longevity in the United States. Soc. Sci. Med.
2015, 145, 115–119. [CrossRef] [PubMed]
Wolkowitz, O.M.; Epel, E.S.; Reus, V.I.; Mellon, S.H. Depression gets old fast: Do stress and depression
accelerate cell aging? Depress. Anxiety 2010, 27, 327–338. [CrossRef] [PubMed]
Chellappan, K.; Mohsin, N.K.; Ali, S.H.B.M.; Islam, M. Post-stroke Brain Memory Assessment Framework.
In Proceedings of the IEEE-EMBS Conference on Biomedical Engineering and Sciences, Langkawi, Malaysia,
17–19 December 2012.
Staicu, M.-L.; Cuţov, M. Anger and health risk behaviors. J. Med. Life 2010, 3, 372–375. [PubMed]
© 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).

