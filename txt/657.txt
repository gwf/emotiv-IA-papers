Comparing the Levels of Frustration between
an Eye-Tracker and a Mouse: A Pilot Study
Hildegardo Noronha, Ricardo Sol, and Athanasios Vourvopoulos
Madeira Interactive Technologies Institute,
University of Madeira 9000-390 Madeira, Portugal
hildegardo.noronha@m-iti.org, rsol@alummni.carnegiemellon.edu,
athanasios.vourvopoulos@m-iti.org
http://m-iti.org

Abstract. This paper tries to identify increases in user frustration when
using Eye-Tracking devices as compared to common interfacing devices
like a standard mouse. For this, we used an electroencephalograph (EEG)
to measure frustration levels while users navigated within a maze using
each of the referred devices. Results from the analysis performed on the
EEG data indicate that Eye-tracking has the same amount of frustration
as a standard mouse for common mouse tracking tasks. In addition, a
correlation between the users reported frustration and the extracted EEG
data could not be found rendering the above result virtually invalid. The
users’ self-reported frustration lends support to our hypothesis but it still
is not statistically signiﬁcant and hence does not conﬁrm the hypothesis.
Keywords: Human Computer Interaction, Natural User Interfaces,
Eye-Tracker, Mouse, Electroencephalography.

1

Introduction

Computer interface devices are continuously improving towards a more natural
user interaction. Natural User Interfaces (NUI) unlike the traditional devices
like keyboard and mouse do not require training and familiarization. Devices
like Microsoft Kinect (Microsoft Co.) and Nintendo Wii (Nintendo Co., Ltd.)
are examples of this transition into a more compelling experience without the
use of any mediatory device that users have to learn to use and operate. Going
a step further, eye-tracking interfaces using eye position and eye movement for
pointing and selecting can act as Natural User Interfaces. Using an eye-tracker
as a pointing device is a self-evident way of using eye-gaze as input in a computerized device. Studies conducted over the past three decades have shown that
the performance of the eye-tracking devices has steadily improved in the recent
years [1]. A major improvement in video-based eye-trackers systems is the range
of freedom given to the users head movements. Since these systems are essentially composed of video cameras and software, a substantial decrease in price is
soon to be expected. Thus these systems can potentially become part of future
computers without major additional costs.
A. Holzinger et al. (Eds.): SouthCHI 2013, LNCS 7946, pp. 107–121, 2013.
c Springer-Verlag Berlin Heidelberg 2013


108

H. Noronha, R. Sol, and A. Vourvopoulos

Nevertheless current eye-tracking technology still fails to achieve fulﬁlling interaction with targets of recent applications or websites.
The lack of overall performance might translate into frustration from the
user’s point of view. This frustration can be quantiﬁed for further analysis and
performance assessment. Relating these two quantities (low performance triggering high frustration) a tool can be built for assessing future interactive systems
that require speed and precision (intrinsic to user interfaces). Understanding the
levels of frustration that the users are exposed to can also give us an indication
of the potential success of such devices.
The evaluation of such a system can capture the eﬀects on the user experience, quantitatively and qualitatively, by collecting extensive synchronized brain
activity and behavioral data on users performance during the testing process.
Additionally, such a system can provide us with extremely valuable data that can
be used to propose a generalization of it for future systems that can eventually
be used by all users, either for entertainment, education or general use.
Technological advances with the synchronization of eye tracking gaze data and
electrophysiological data like electroencephalographic (EEG) signals can be combined for scientiﬁc research purposes, market research, and a wide range of other
application areas. EEG is already a multi-purpose scientiﬁc tool used for diseases
diagnosis, biofeedback, medical applications and general scientiﬁc research. This
technology and the data captured from it, can leverage the knowledge of where
the users attention is focused (through the eyes) when an event is taking place.
The hypothesis, H1, that we try to verify, is that user frustration is higher
when using eye-tracking as the input device instead of a standard mouse for
common mouse tracking tasks.
Our research reported in this paper uses a questionnaire and electroencephalographic (EEG) data to analyze the levels of frustration in a sample of 10 users
while they try to navigate through several labyrinths with a cursor controlled
by eye-gaze or mouse system.

2

Background and State of the Art

Each area of the human brain is responsible for diﬀerent functions including
problem solving, emotion, complex thought, movement, visual stimuli and auditory information [2]. Through the use of electroencephalography (EEG), there
are diﬀerent wave patterns or rhythms that are distinguished and associated
to diﬀerent cognitive or motor actions [3]. This kind of knowledge has been
used with Brain-Computer Interfaces (BCIs) based on the pattern recognition
approaches for communication and control of computers [4] ranging from Braincontrolled robots, modern computer games [5], prosthetics, control systems [6]
through to medical diagnostics. The mental tasks are chosen in such a way that
they activate diﬀerent parts of the brain. In the last few years commercial low
cost EEG equipment has been introduced as an alternative game controller by
various companies such as Emotiv [7], setting a milestone in user experience with
brain-controlled computer games and virtual worlds [5].

Comparing the Levels of Frustration between an Eye-Tracker and a Mouse

109

Recent evaluations of the detection accuracy of such devices indicate an acceptable level of accuracy for performing mental actions [8] although for the
Emotivs Aﬀectiv Suite that is used also for this experiment, similar tests suggest that further examination is needed to verify Emotivs’ ability to accurately
track cognitive state [9].
The merge of eye-tracking technology with EEG has only been implemented
quite recently with the SMI RED-m eye tracker (SensoMotoric Instruments Co.)
and the Emotiv EEG Neuro-headset for market research purposes [10]. This online analysis of emotional responses can give an insight into consumers subconscious behavior by merging visual perception and brain response introducing a
new type of marketing, neuromarketing [11].
In 2005, Ashmore, Duchowsky and Shoemaker speciﬁed and deﬁned four reasons why eye pointing has more problems than manual pointing [13]. The four
reasons are: Eye tracker accuracy, Sensor lag, Fixation jitter, and Midas touch.
Eye tracker accuracy depends on the visual angle. The visual angle is associated with the reﬂection of the eye and not the actual position of the eyes
when facing the screen that should be around 90◦. In less recent literature,
it is possible to ﬁnd references to visual angles of 3◦, however a visual angle
around 0.5-1◦ is commonly accepted. This means that when looking at our
23" computer monitor with a resolution display of 1980x1080 at a viewing
distance of 65 cm, the eye pointing will be limited in accuracy to around
22-44 pixels.
Sensor lag is a delay in processing the gaze position. In our system this delay
is typical 0.005 seconds (200 Hz frame rates).
Fixation jitter occurs with the dwell time (or ﬁxation time, i.e. time spent
selecting through ﬁxation) associated with eye pointing. Three types of these
involuntary eye movements (microsaccades) disturb ﬁxation: ﬂicks, drifts,
and tremors. The biggest of these movements has a visual angle that is less
than 1◦.
Midas touch is a problem deﬁned by Jacob in 1991 that occurs because the
eyes are always active making the selection task indistinct from the search
task [14].
Researchers worldwide have been dealing with the above problems and trying
to ﬁnd ways to improve the interaction.
Mouse and Gaze Input Cascaded (MAGIC) that uses gaze to dynamically
redeﬁne the position of the cursor is one of those improvements [15]. In MAGIC
after the eye redeﬁnes the cursor position the user will makes a small manual
input action to select the target. MAGIC has two approaches. In the ﬁrst approach, referred to as the liberal approach, the cursor moves to the top of the new
target that the user looks at. The second approach, the conservative approach
that, leaves the cursor at the boundaries of the target.
Salvucci and Anderson presented their intelligent gaze-added interfaces [16].
They addressed accuracy problems that we also face. In their work any target
positioned where the users’ eye gaze is, is a highlighted target. Then a gaze key

110

H. Noronha, R. Sol, and A. Vourvopoulos

gives the user the chance to trigger the action. The system uses a probabilistic
algorithm to guess the targets the user is going to look at.
McGuﬃn and Balakrishnan showed that expanding targets facilitates the
pointing task [17]. Their results show that working with expanding targets can
be accurately modeled by Fitts’ law. They have also shown that targets that
expand just as the user is about to reach them can be acquired approximately
as fast as targets that are always in an expanded state. They speciﬁcally found
strong evidence that user performance is consistently aided by target expansion.
Miniotas and Spakov used an expansion of targets visible to the users [18]. To facilitate pointing they used dynamic target expansion for ﬁxing the calibration of
the eye tracker, basing the correction on the relative change in the gaze position
after the expansion.
Ashmore and Duchowsky reﬁned a ﬁsheye lens to support eye pointing [13].
They hid the lens during visual search and obtained improvements in speed
and accuracy. Fisheye interaction was evaluated by Fitts pointing and, a visual
search. In contrast to MAGIC pointing, where the cursor was quickly moved to
the vicinity of one’s gaze prior to mouse movement, they directly slaved the lens
to the gaze position.
EyePoint used expansions of interactive targets, and used a key for input [19].
When the key is pressed the gaze area is enlarged. When the key is released the
selections are made according to where the eye gaze is.
All of the above mentioned work reﬂect the idea that simple eye gaze interaction is not promising [15]. Quantifying this dissatisfaction by looking into
frustrations levels is the goal of this work.

3
3.1

Materials and Methods
Hardware

EEG headset. The Emotiv EPOC Headset is a neuro-signal acquisition and
processing wireless neuro-headset with 14 wet (using a common contact lens
liquid) sensors and 2 reference sensors being able to detect brain signals and
facial expressions. An integrated gyroscope generates positional information,
connected wirelessly through a USB dongle and comes with a lithium battery
providing 12 hours of continuous use [7]. Detailed speciﬁcations are illustrated
in Table 1. The sixteen (14 plus 2 reference) sensors are placed on the international 10-20 system [11], an internationally recognized method which describes
the electrode placement on the scalp for EEG tests or experiments.
Eye-Tracker. The Tobii TX300 is an eye tracker that uses infrared diodes to
illuminate the users eye [20]. The back part of the eye called fovea, reﬂects when
illuminated, and this refection is then collected by the image sensor. Using this
reﬂection, the eye tracker uses complex image processing to determine where in
screen is the user looking. Detailed speciﬁcations are illustrated in Table 2.

Comparing the Levels of Frustration between an Eye-Tracker and a Mouse

111

Table 1. Headset speciﬁcation
Characteristic

Deﬁnition

Number of channels
Channel name (10-20 locations)
Sampling method
Sampling rate
Resolution
Bandwidth
Dynamic range (input referred)

14 (plus CMS/DRL references)
AF3/4, F3/4/7/8, FC5/6, P3/4/7/8, T7/8, O1/2
Sequential sampling, Single ADC
∼128Hz (2048Hz internal)
16 bits (14 bits eﬀective) 1 LSB = 0.51 µV
0.2 - 45Hz, d. notch ﬁlters at 50Hz and 60Hz
256mVpp

Table 2. Eye-Tracker speciﬁcation
Characteristic
Sampling rate (binocular/variability)
Latency
Freedom of head mov. (65 cm) (w x h)
Max gaze angle
Screen size
Screen resolution (Max)
Bandwidth
Response time

3.2

Deﬁnition
300 Hz / 0.3%
≤ 10ms
37 x 17 cm (15 x 7)
35◦
23" TFT
1920 x 1080 pixel
0.2 - 45Hz, d. notch f. at 50Hz and 60Hz
∼5ms

Software

EEG Headset. For acquiring the frustration levels, we used the Emotiv SDK.
Emotiv uses a black box algorithm for the detection of cognitive characteristics
in a suite called Aﬀectiv.
The Aﬀectiv Suite reports real time changes in the subjective emotions experienced by the user. Emotiv currently oﬀers three distinct Aﬀectiv detections:
Engagement, Instantaneous Excitement, and Long-Term Excitement.
The Aﬀectiv detections look for brainwave characteristics that are universal
in nature and dont require an explicit training or signature-building step on the
part of the user.
Eye-Tracker. The Tobii TX300 comes with several software programs. One of
them is worth mentioning, the Tobii Software Development Kit that enables the
development of software to control the eye tracker.
Custom Made Software. Since no current software was adequate for our
research we developed our own custom software. It is composed of four main
components: The Emotiv EEG interaction, the Tobbi Eye-Tracker interaction,
the test and a log.

112

H. Noronha, R. Sol, and A. Vourvopoulos

Both the Emotiv and Tobbi interaction components use their respective and
commercially available SDK as a base to communicate with the hardware. The
logging component logs the data enumerated on the section D-Data Description
that is gathered from the EEG and the input method (either the mouse or
the Eye-Tracker). Finally, the test component is responsible for merging all the
components, drawing the mazes and the user interfaces and implementing all the
test logic. Fig. 1 shows the visualization created by the software. It corresponds
to the last maze of the least thickness. It illustrates an example of what the user
has to traverse during the test.

Fig. 1. Example of a maze presented to the user

3.3

Experimental Procedure

The tests are composed of a sequence of simple mazes in which the user navigates from the starting point to the end within the maze borders. If the user
moves outside this area, the cursor position is reset back to the starting point.
The mazes vary in thickness and in complexity (amount of curves/length of
the maze). Every user navigates through a ﬁxed number of diﬀerent levels of
varying thickness and increasing complexity. The ﬁrst level of thickness is for
training purposes. The participant using the eye-tracker, even with poor calibration, can easily control it. The second level is of a comfortable thickness that
the user can easily navigate but where he/she has to exercise carein order not to
move outside the maze limits. The last thickness is purposely thin to a degree
that the failure rate increases signiﬁcantly, again, with the eye-tracker (some
users were not even able to complete a single maze on this diﬃculty) in the hope
of noticing an eﬀect in the frustration levels between the devices. Still, it is easily

Comparing the Levels of Frustration between an Eye-Tracker and a Mouse

113

traversed with a mouse, making the test less artiﬁcial. Since there is repetition
the user can always come back to the mouse version to compare his performance
with the eye tracker.
The users have to complete the whole set four mazes times the tree thickness
once for each condition (mouse Vs eye tracker) and repeat it three times. The
ﬁrst condition is selected randomly and from then on the user alternates between
conditions.
For every maze, if a user fails 5 times in a row he/she is be sent to the next
maze. This number was chosen as a compromise between getting enough data
and not taking too long to get it, and to avoid user fatigue.
3.4

Data Description

The raw data was automatically logged by custom-made software that was used
for the user tests. The data was split in two ﬁles both using a standard commaseparated-values (csv) format. The ﬁrst ﬁle logs the onscreen cursor position
along with frustration and engagement levels, sampled every frame. The second
ﬁle is an event log that logs data when special events happen. The events are
Level Mouse and Level Eye, indicating the start of a level for mouse and eye
respectively, Failed, indicating that the user moved the cursor outside the maze
area, GaveUp, indicating that the user failed too many times and the experiment had just advanced, and ﬁnally, Complete, indicating that the user reached
his/her goal.
The ﬁrst ﬁle logs the following:
Timestamp in milliseconds, starting from the system initialization;
Cursor Position (either by using the mouse or by using the eye-tracker), in
pixels;
Frustration Levels values between 0 and 1;
Engagement Levels values between 0 and 1;
The second ﬁle logs the following:
Timestamp in milliseconds, starting from the system initialization;
Type of Event string (single or double word) describing the event;
Event Data string with extra data when needed, 0 if not.
3.5

Conditions

The test is very sensitive to the mental state of the user and external stimulation.
This makes this experiment diﬃcult to condition and control. The room where
the hardware was located was not dedicated exclusively for the experiment.
However, the participants did not face any interruption or disturbance during
the tests.

114

3.6

H. Noronha, R. Sol, and A. Vourvopoulos

The Questionnaire

A modiﬁed version of the NASA TLX questionnaire was used for the users to ﬁll
up after completing the assessment. NASA-TLX is a workload assessment tool
with six sub-scales including Mental Demands, Physical Demands, Temporal
Demands, Own Performance, Eﬀort and Frustration [12]. This is used to corroborate the accuracy of the headsets frustration data. The whole questionnaire set
was used, even if some questions did not seem relevant to the experiment, since
some of the standard analyses require the whole data set.
In Fig. 8 and Fig. 9 it is possible to analyze the questionnaire answers.

3.7

Sample

Since we chose Convenience Sampling as our sampling method, users were selected from friends and colleagues, as they were easily accessible to the researchers.
The experiment was performed with 10 participants, 5 males and 5 females,
with normal or corrected-to-normal vision. The participants were between 20
and 33 years old. All participants were regular computer and mouse users.

3.8

Statistical Analysis

Central Tendency and Dispersion. There are two input devices (Mouse
and Eye-tracker), each one representing a condition and also two data sets that
represent the same variable (the EEG data and the questionnaire answers).
Fig. 2 and Fig. 3 demonstrates a large overlapping of the frustration results.
This overlap is bigger for the EEG than it is for the Questionnaire.

Fig. 2. Whiskers plots Questionnaire

Fig. 3. Whiskers plots for the EEG

Comparing the Levels of Frustration between an Eye-Tracker and a Mouse

115

Data Normality. Before deciding which statistical test is appropriate for testing the hypothesis of this project, it is important to check the normality of the
acquired data as a necessary statistical procedure to avoid incorrect usage of
tests that require normality. The distribution of the data will help us choose
between parametric or non-parametric tests.
We did several tests, including Histograms (Fig. 4 and Fig. 5), QQ-Plots
and several quantitative tests. These tests indicate Normality, but this was not
conﬁrmable with the current sample size.

Fig. 4. Histograms and Normality
curve for the Questionnaire

4
4.1

Fig. 5. Histograms
curve for the EEG

and

Normality

Results
Central Tendency and Dispersion

For the EEG Headset, the range of the ratio data is from 0.0 to 1.0. The Eye has
a Mean of 0.5965, a Median of 0.6149 and a Standard Deviation of 0.10461 and
the Mouse has a Mean of 0.5790, a Median of 0.5850 and a Standard Deviation
of 0.06003.
The Interquartile Range is 0.34 for the Eye-Tracker and 0.06 for the Mouse.
This indicates a fairly larger variability in the Eye-Tracker data than in the
Mouse data. Also, this value of 0.34 represents a third of the whole range, suggesting that the data might not be very good.
For the Questionnaire, the data range is from 1 to 10, ordinal. The Eye has a
Median of 8 and a Standard Deviation of 2.378 and the Mouse has a Median of
2.5 and a Standard Deviation of 2.741.
The Interquartile Range is 3 for the Eye-Tracker and 4 for the Mouse. This
represents from 33% to 44% of the data range, making it an even worse data
than that of the EEG.
Fig. 6 and Fig. 7 show the result of the visualization of the cursor trajectory
when users navigated through the maze. One can notice higher loss of intended

116

H. Noronha, R. Sol, and A. Vourvopoulos

Fig. 6. Mouse Trajectory

Fig. 7. Eye Trajectory

Fig. 8. Mouse questionnaire results

Fig. 9. Eye-gaze questionnaire results

control while using an Eye-Tracker as compared to a Mouse for normal pointing
tasks. The eye-gaze control (Fig. 7) is less accurate.
The tables in Fig. 8 and Fig. 9 show the questionnaire results for the Mouse
and the Eye respectively.
Table 3 and Table 4 show the EEG log results for events an data respectively,
it demonstrates what happens when a user fails 5 times in a row: it is considered
a give up and the user goes on to the next maze.

Comparing the Levels of Frustration between an Eye-Tracker and a Mouse

117

Table 3. Event Log
Time
121249441

XY
801 578

Frustration Engagement
0.584 0.879

Table 4. Data Log
Time
12149424
12196613
12221551
12226329
12232051
12233392
12238636

4.2

Type Data
Level Mouse 1
Level Eye 1
Failed 0
Failed 0
Failed 0
Failed 0
GaveUp 0

Eﬀect: EEG

Wilcoxon Signed Ranks Test. The data was found not to have a normal
distribution. Due to this, a non- parametric test had to be used to verify our
hypothesis. The experiment was within-subjects with two conditions (Mouse and
Eye- Tracker). For these reasons, a Wilcoxon Signed Ranks test was conducted.
The results of the test follow:
We can infer that, from the 10 users that participated in the experiment, 4
found the Mouse more frustrating to use as compared to the Eye-Tracker, while
the other 6 users felt the other way around.
The T value is 22 with a ρ = 0.575, higher than the standard ρ ≤ 0.05. The
Tcritical for a two-tail test with α = 0.05 is 8. Hence 22 ≥ 8 then T ≥ Tcritical .
We can now conclude that we should keep the null hypothesis H0 - Eye-tracking
has the same amount of frustration as a standard mouse for common mouse
tracking tasks.
The Power. There is a chance that we are making a Type II error, especially
due to the small sample size. In order to address this, we did a test of power to
check the probability of such error. We found a power of 0.8000817, indicating
a high probability of mistakenly not ﬁnding an eﬀect that was there. Another
interesting value is the amount of tests we would need to perform in order to see
an eﬀect. This value is 380 tests.
4.3

Eﬀect: Questionnaire

Wilcoxon Signed Ranks Test. To check the accuracy of the EEG headset
data, we provided a questionnaire at the end of the tests for the users to indicate
their frustration for each of the conditions (Mouse and Eye-Tracker). We then
checked the correlation between the two.

118

4.4

H. Noronha, R. Sol, and A. Vourvopoulos

EEG: Questionnaire Correlation

We ﬁrst did a Spearmans ρ test to obtain the correlation coeﬃcient. We got a
result of ρ = -0.131. The ρcritical is 0.45 for Spearmans ρ test with α = 0.05,
for N = 20. Since |-0.131| ≤ 0.45, ρ ≤ ρcritical and so the correlation is not
signiﬁcant.
To complement this result we plotted the linear regression plot (Fig. 10 ).
While we expected a linear relationship close to y = x , we got an almost horizontal line.
Looking into those results, we conclude that there is no evidence of correlation.

Fig. 10. Linear regression between the Questionnaire and the EEGs Frustration

5
5.1

Discussion and Conclusion
Main Hypothesis Rejection

According to the EEG data, 4 out of 10 users had higher frustration levels using
the Mouse whole the remaining 6 users had higher frustration levels with the
Eye-Tracker and not the Mouse. The performed Wilcoxon T showed a value of
T = 22, with a ρ = 0.575 resulting in a non-signiﬁcant result. Also, the T value
is higher than the Tcritical = 8. The sum of ranks for a less frustrating EyeTracker is 33 and 22 for the Mouse. However, a Type II error could be present.
To investigate this, we tested the power of the test. A value of 0.8 was found,
indicating a high probability of an undetected eﬀect.
As there is no clear relation between the users reported frustration levels and
the frustration levels registered by the EEGs, we did a statistical analysis of the
questionnaire results.
We then found a T value is of 8.5 with a ρ = 0.52, which is still higher than
the standard ρ ≤ 0.05. The Tcritical for a two-tail test with α = 0.05 is 8. This
time 8.5 ≥ 8 so T ≥ Tcritical . This value is close to the critical value but the
signiﬁcance is still low.

Comparing the Levels of Frustration between an Eye-Tracker and a Mouse

119

Taking this subsequent statistical analysis into account, we now arrive at a
diﬀerent result from the one we got with the EEG. These subsequent results
suggest that 8 users felt more frustrated using the Eye-Tracker as compared to
using the Mouse, while the other 2 users felt the other way around. One of the
users has extreme values (very frustrated using the mouse and very not frustrated
using the Eye-tracker) going against both the expected results and the gathered
results. Another result that is not consistent with the expected results is from
a user that answered very closely for both devices (7 for Eye-Tracker, 8 for the
Mouse).
The lack of agreement in the data may be a due to a combination of two
technical issues:
First, the users tended to use the scale relatively, gathering around one of the
extremes of the scale: they feel they are either very frustrated or not at all.
On the other hand, EEG headsets measures absolute frustration;
Second, the EEG Headset may not be accurate or sensitive enough to output
good enough data for scientiﬁc usage.
The amount of noise that is generated during the task performance on the headset electrodes can lead to false classiﬁcation of the frustration, as it is output
from the Emotiv algorithm. In addition, the sense of frustration is subjective.
The lack of agreement in the data can also be due to the small sample size or
the conditions of the environment under which the experiment was conducted.
Another explanation could be that the EEGs algorithm cannot really extract
true frustration.
5.2

Conclusion

The data from our experiment was not found to be normally distributed, although it shows some tendency towards normality. Yet, given the small sample,
we treated the data as not normal and performed non-parametric tests. We performed a Wilcoxon Signed Ranks test on the frustration data which led us to
conclude that we cannot reject the null hypothesis - H0 - Eye-tracking has the
same amount of frustration as a standard mouse for common mouse tracking
tasks.
Since we suspected that the EEG data might not be accurate, supported by
the strong eﬀect power, we ran a questionnaire to gauge how frustrated the user
felt while using each of the devices and then compared this data with the EEGs.
A correlation was not found, suggesting that the EEG might not be accurate or
that the users might be answering incorrectly.
We then further analyzed the questionnaire results and found out that there
was a bigger eﬀect, even if it was still not statistically signiﬁcant.
Thus, we draw two conclusions:
First, the frustration data from the EEGs might be inaccurate - further research
is required to prove or refute this.

120

H. Noronha, R. Sol, and A. Vourvopoulos

Second, no eﬀect was found but both the power of the frustration data from the
EEGs as well as the data from the questionnaire seem to indicate a possible
missed eﬀect.
5.3

Future Work

A better frustration measurement method should be found. After a suﬃciently
reliable method is found, a bigger sample should be acquired to gather enough
information for a signiﬁcant result to be achieved. Future work can also compare
diﬀerent kinds of input devices in order to arrive at a more complete understanding of users frustration levels with these devices.
Acknowledgments. We would like to thank our friends and colleagues that
were kind enough to serve as users in our experiment. We would like to thank
Professors Mónica Cameirão and Mon-Chu Chen, for giving us valuable
comments.

References
1. Zuchowski, A.: Eye Tracking Methodology: Theory and Practice. Springer, Berlin
(2003)
2. Carew, T.J.: Behavioral Neurobiology: The Cellular Organization of Natural Behavior. Sinauer Associates Inc. (2004)
3. Gevins, A., Zeitlin, G., Yingling, C., Doyle, J., Dedon, M., Schaﬀer, R., Roumasset,
J., Yeager, C.: EEG patterns during cognitive tasks. I. Methodology and analysis
of complex behaviors. Electroencephalography and Clinical Neurophysiology 47(6),
693–703 (1979)
4. Wolpaw, J.R., Birbaumer, N., McFarland, D.J., Pfurtscheller, G., Vaughan, T.M.:
Braincomputer interfaces for communication and control, Clinical neurophysiology? Oﬃcial Journal of the International Federation of Clinical Neurophysiology 113, 767–791 (2002)
5. Lecuyer, A., Lotte, F., Reilly, R.B., Leeb, R., Hirose, M., Slater, M.: BrainComputer Interfaces, Virtual Reality, and Videogames. Computer 41, 66–72 (2008)
6. Loudin, J.D., Simanovskii, D.M., Vijayraghavan, K., Sramek, C.K., Butterwick,
A.F., Huie, P., McLean, G.Y., Palanker, D.V.: Optoelectronic retinal prosthesis:
system design and performance. J. Neural Eng. 4(1), S72–S84 (2007)
7. Emotiv — EEG System — Electroencephalography,
http://emotiv.com/ (accessed: December 16, 2012)
8. Taylor, G.S., Schmidt, C.: Empirical Evaluation of the Emotiv EPOC BCI Headset
for the Detection of Mental Actions. In: Proceedings of the Human Factors and
Ergonomics Society Annual Meeting, vol. 56(1), pp. 193–197 (September 2012)
9. Goldberg, B., Brawner, K.W., Holden, H.K.: Eﬃcacy of Measuring Engagement
during Computer-Based Training with Low-Cost Electroencephalogram (EEG)
Sensor Outputs. In: Proceedings of the Human Factors and Ergonomics Society
Annual Meeting, vol. 56(1), pp. 198–202 (September 2012)

Comparing the Levels of Frustration between an Eye-Tracker and a Mouse

121

10. SensoMotoric Instruments GmbH Gaze and Eye Tracking Systems Applications
Neuromarketing,
http://www.smivision.com/en/
gaze-and-eye-tracking-systems/applications/neuromarketing.html
(accessed: December 16, 2012)
11. Klem, G.H., Lders, H.O., Jasper, H.H., Elger, C.: The ten-twenty electrode system
of the International Federation. The International Federation of Clinical Neurophysiology, Electroencephalogr. Clin. Neurophysiol. Suppl. 52, 3–6 (1999)
12. Hart, S.G.: NASA-Task Load Index (NASA-TLX); 20 Years Later. In: Proceedings
of the Human Factors and Ergonomics Society 50th Annual Meeting, pp. 904–908.
HFES, Santa Monica (2006)
13. Ashmore, M., Duchowski, A.T., Shoemaker, G.: Eﬃcient Eye Pointing with a Fisheye Lens. In: Proceedings of Graphics interface 2005, ACM International Conference Proceeding Series, vol. 112, pp. 203–210 (2005)
14. Jacob, R.J.K.: What You Look at is What You Get: Eye Movement-Based Interaction Techniques. In: Proc. CHI 1990, pp. 11–18. ACM Press (1990)
15. Zhai, S., Morimoto, C., Ihde, S.: Manual and gaze input cascaded (MAGIC) pointing. In: Proc. of CHI 1999, pp. 246–253. ACM (1999)
16. Salvucci, D.D., Anderson, J.R.: Intelligent Gaze-Added Interfaces. In: Proceedings
of the SIGCHI Conference on Human Factors in Computing Systems, CHI 2000,
pp. 273–280. ACM Press (2000)
17. McGuﬃn, M., Balakrishnan, R.: Acquisition of Expanding Targets. In: Proceedings
of the SIGCHI Conference on Human Factors in Computing Systems CHI 2002,
pp. 57–64. ACM Press (2002)
18. Miniotas, D., Špakov, O., MacKenzie, I.S.: Eye Gaze Interaction with Expanding Targets. In: CHI 2004 Extended Abstracts on Human Factors in Computing
Systems, pp. 1255–1258. ACM Press (2005)
19. Kumar, M., Paepcke, A., Winograd, T.: EyePoint: Practical Pointing and Selection
Using Gaze and Keyboard. In: Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems CHI 2007, pp. 421–430. ACM Press (2007)
20. Tobii Technology, Tobii TX300 Eye Tracker Users Manual (2011)

