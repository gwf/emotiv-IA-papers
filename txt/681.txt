1

ECORFAN Journal-Bolivia

Article

June 2020 Vol.7 No.12 1-9

Emotion classiﬁcation from EEG signals using wearable sensors: pilot test
Clasificación de las emociones a partir de las señales de EEG con sensores portátiles:
prueba piloto
JARILLO-SILVA, Alejandro†*´, GOMEZ-PEREZ, Víctor A.´, ESCOTTO-CÓRDOVA, Eduardo A.´´
and DOMÍNGUEZ-RAMÍREZ, Omar A.´´´
´Universidad de la Sierra Sur, Instituto de Informática, Centro de Tecnologías de la Información, Laboratorio de Interacción
Humano Computadora
´´Universidad Autónoma del Estado de Hidalgo, Research Center on Information and Systems Technology, Electronics and
Control Group
´´´Universidad Nacional Autónoma de México, Facultad de Estudios Superiores Zaragoza, Carrera de Psicología, Av.
Guelatao No. 66, Col. Ejército de Oriente, alcaldía de Iztapalapa, CDMX
ID 1st Author: Alejandro, Jarillo-Silva / ORC ID: 0000-0002-9776-6533, CVU CONACYT ID: 241966
ID 1st Coauthor: Víctor A., Gómez-Pérez / ORC ID: 0000-0002-7758-6690, CVU CONACYT ID: 222462
ID 2nd Coauthor: Eduardo A. Escotto-Córdova / ORC ID: 0000-0002-1104-8195, CVU CONACYT ID: 168236
ID 3rd Coauthor: Omar A., Domínguez Ramírez / ORC ID: 0000-0002-9663-8089, CVU CONACYT ID: 202942
DOI: 10.35429/EJB.2020.12.7.1.9

Received January 19, 2020; Accepted June 29, 2020

Abstract

Resumen

The objective of this work is to present a procedure for the
classification of basic emotions based on the analysis of
EEG signals (electroencephalogram). For this case, 25
subjects were stimulated, of whom 17 were men and 9
women between 20 and 35 years of age. The stimulus to
induce positive, negative and neutral emotions with a
certain level of excitation (activation) was a set of video
clips previously evaluated. The processed and analyzed
signals belong to the gamma and beta frequency bands of
the F3, F4, P7, P8, T7, T8, O1 and O2 electrodes. The
characteristic variables with the best result are the entropy
of each band of each electrode. The cross validation
algorithms are applied and later the main component
analysis algorithm. Finally, four classifier algorithms are
used: classifier trees, Support- Vector-Machine (SVM),
Linear-Discriminant-Analysis (LDA) and k-NearestNeighbors (KNN). The results confirm that by carrying
out the proposed procedure, the EEG signals contain
enough information to allow the recognition of basic
emotions.

El objetivo de este trabajo es presentar un procedimiento
para la clasificación de emociones básicas basado en el
análisis de señales de EEG (electroencefalograma). Para
este caso, se estimularon 25 sujetos, de los cuales 17
fueron hombres y 9 mujeres entre 20 y 35 años de edad. El
estímulo para inducir emociones positivas, negativas y
neutras con un cierto nivel de excitación (activación) fue
un conjunto de videoclips evaluados previamente. Las
señales procesadas y analizadas pertenecen a las bandas de
frecuencia gamma y beta de los electrodos F3, F4, P7, P8,
T7, T8, O1 y O2. Las variables características con mejor
resultado son la entropía de cada banda en cada electrodo.
Se aplican los algoritmos de validación cruzada y
posteriormente el algoritmo de análisis de principales
componentes. Finalmente, se emplean cuatro algoritmos
clasificadores: árboles clasificadores, SupportVectorMachine (SVM), Linear-Discriminant- Analysis (LDA) y
k-Nearest-Neighbours (KNN). Los resultados confirman
que llevando acabo el procedimiento planteado, las señales
de EEG contienen suficiente información para permitir el
reconocimiento de las emociones básicas.

EEG signal analysis (Electroencephalogram), Machine
learning, Recognition of Emotions

Análisis de señales EEG (Electroencefalograma),
Aprendizaje
automático,
Reconocimiento
de
emociones

Citation: JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A., ESCOTTO-CÓRDOVA, Eduardo A. and
DOMÍNGUEZ-RAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals using wearable sensors: pilot test. ECORFAN
Journal-Bolivia. 2020. 7-12: 1-9.

* Correspondence to Author (E-mail: ajarillo0205@gmail.com)
† Researcher contributing first author.

© ECORFAN Journal-Bolivia

http://www.ecorfan.org/bolivia

2
Article

ECORFAN Journal-Bolivia
June 2020 Vol.7 No.12 1-9

Introduction
In recent years, the volume of studies and
publications on the recognition of emotions has
increased.
Thanks
to
technological
advancement, techniques and models have been
diversified in the generation of systems for the
detection of emotions. These systems can be
easily differentiated between them; for example,
the use of various stimuli, the characteristics for
the classification, the size of the time window,
the classifiers, the number of participants and the
models of emotions. Most research related to
emotion detection is mainly based on the
biosignal treaty. These can be obtained from
different
devices,
such
as;
an
electroencephalograph
(ECG),
an
electroencephalogram (EEG), galvanic-sensorresponse (GSR), thermal imaging cameras, etc
(Koelstra et al., 2011) and in (Li & Lu, 2009).
Thanks to access to technology in recent years
the amount of research has increased
significantly, where they make use of an EEG
(electroencephalograph), however, the field of
research is still very wide.
The effectiveness and efficiency of
algorithms for the biosignals treaty still show
limitations. According to Herger (2013) these
include response time, precision, number of
electrodes, number of recognized emotions, and
the generation of a robust control group
database.
The expression of emotions, not only
facially, but bodily, mainly involves the
bioelectrical activity of various brain structures:
the cingulum, the nucleus accumbens, the insula,
the orbitofrontal and medial zone, the
hypothalamus, the pituitary, the hippocampus,
and the amygdala among the most prominent.
Unfortunately, with electrodes placed on the
scalp that record brain signals (EEG), it is not
possible to distinguish or record the relative
participation of each one, nor its dynamic
participation in each of the possible emotions.
However, the signals that are recorded and
amplified with an EEG can be correlated with
the induction of emotions, especially if a general
classification of emotions is used, that is,
positive or negative. During the presence of
emotions, changes in the electrical signals of the
brain are manifested, which are related to the
voltage levels (result of ionic current flows
within the neurons in the brain) and frequency.

ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

The electrical activity of the brain is
classified according to the high and low
frequency rhythms called frequency bands.
These bands have been defined through studies
of psychological and physiological phenomena
associated with brain activity.
According to Megías (2011) the study of
emotions under experimental conditions has
become a fundamental tool to understand the
psychological and neurobiological processes
involved in their development. Over the last
decades, various strategies have been
successfully used to induce emotions in
experimental conditions (e.g., images, music,
videos, self-induction, etc.). Currently the use of
scenes from movies (vide films) to induce
emotions is one of the most widely used
techniques, since it has important advantages
such as greater ecological validity since they are
stimuli more similar to those perceived in real
life. In addition, they are dynamic and different
perceptual channels intervene (visual and
auditory), allow the standardization and
reproduction of the procedure, and allow the
induction of specific basic emotions.
In this work, we present a procedure that
controls the stimulation of emotions from an
intra-subject
experimental
design,
the
processing of EEG signals and the evaluation of
classification algorithms.
The rest of this document is organized as
follows. In Section II a review of the literature is
made, describing the models of emotion, stimuli,
characteristics, time window and classifier.
Section III presents the methodology used in this
research. Section IV presents the results
obtained. Section V presents a discussion of the
results obtained. Finally, Section VI describes
the conclusions reached in this work.
Literature review
The factors that have determined different
results in different investigations using an EEG
are: emotion model, stimulus, characteristic,
time window and the classifier. These factors are
described below.

JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

3

ECORFAN Journal-Bolivia

Article

June 2020 Vol.7 No.12 1-9
Models of emotion

Stimuli

Emotions according to the literature can be
classified based on two models: categorical or
discrete and dimensional (Bradley & Lang,1994)
and in (Gray, 2011). The dimensional model
proposes that emotional states can be accurately
represented by a small number of underlying
affective dimensions. That is, it represents the
continuous emotional state as a vector in a
multidimensional space. Most dimensional
models incorporate valence and activation.
Valence refers to the degree of "liking"
associated with an emotion. It ranges from
unpleasant (eg, sad, stressed) to pleasant (eg,
happy, exalted). Whereas, activation refers to the
force of the emotion experienced. This
activation occurs along a continuum and can
range from inactive (eg, uninteresting, boring) to
active (eg, alert, excited) (Posner, Russell &
Peterson, 2011). This model is used in many
investigations for its ease of expressing an
emotion in terms of valence and arousal (see
Figure 1)

It is defined as the way or way to evoke or induce
a certain emotion. Some researchers claim that
video clips are the best stimuli, while others find
that music or even memories is better. What is
clear is that a robust and strong stimulator causes
performance with good results, since it
guarantees the induction of a certain emotion.
Some types of stimulation are: images (NeathTavares & Itier, 2016), video clips (Daşdemir,
Yıldırım & Yıldırım, 2017), music (Daly et al.,
2015), memories (Chanel et al., 2015), selfinduction (Iacoviello et al., 2015), games
(Chanel et al, 2011), etc. There are generalized
databases for the stimulation of emotions, for
example, the IAPS (International Affective
Picture Systmes), the IADS (International
Digitized Sound System) and the GADEP
(Geneva Affcetive Picture Database). These
databases are the result of the average emotional
evaluations of a group of many people.

Figure 1 Dimensional model of emotion
Source: (Russell, 1980)

Discrete theories of emotion propose the
existence of small amounts of separate emotions.
These are characterized by coordinated response
patterns in physiology, neural anatomy, and
morphological expressions. According to Herger
(2013) six basic emotions frequently used in
research papers include happiness, sadness,
anger, disgust, fear, and surprise

ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

On the other hand, there are published
databases of physiological information collected
during the stimulation of a certain emotion.
DEAP (Dataset for Emotion Analysis using
Physiological) which includes data collected
from 32 subjects (17 men with an average age of
27.2 ± 4.4 years) and SEED (SJTU EEG
database) which contains the collection of 62
channels from 15 subjects (7 men of 23.7 ± 2.37
years), where the subjects were stimulated with
15 videos of 4 minutes each. The induced
emotions were positive, neutral and negative.
However, if analyzes of the DEAP and
SEED databases are performed, non-conclusive
results are obtained, such is the case of the
comparison made by Li et al. (2018) where using
SEEE an accuracy of 59.06% and DEAP of 83%
are obtained. It is one of the reasons why this
research does not make use of these databases.
In Mexico there are various indigenous
languages and cultural traditions that influence
their categorization, expression and perception.
For this reason, the stimulus used is based on
video clips, previously validated by the study
community.

JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

4
Article

ECORFAN Journal-Bolivia
June 2020 Vol.7 No.12 1-9

Features
There are a considerable number of variables
extracted from EEG signals to be considered
representative characteristics of the electrical
activity of the brain. In the frequency domain the
most widely used is PSD (Power Spectral
Density), the power of the EEG signal in its
frequency bands using Fourier transform (AlNafjan et al., 2017). In the time domain they are:
activity, mobility and complexity, using the
Hjorth parameters and the Fractal dimension
with the Higuchi method (Yuvaraj &
Murugappan, 2016). In the Wavelet domain:
entropy and energy using Wavelet transform
(Zhang, et al, 2015). Statistical characteristics:
mean, standard deviation, Kurtosis, Skewness,
etc (Friedrich et al., 2015).
However, it is interesting to note that
nonlinearity in the brain is introduced even at the
cellular level, since the dynamic behavior of
individual neurons is governed by threshold and
saturation phenomena. In this way, on a global
level, the brain also presents a really complex
and heterogeneous performance, which means
that its behavior is far from being considered
linear. This research makes use of characteristics
based on the study of "log-energy" entropy,
which in the described context are justified.
Temporary window
The appropriate length of the time window
largely depends on the type of emotion and
physiological signal used. According to
Jatupaiboon, Pan-ngum & Israsena (2013) on
average the emotion time is between 0.5 and 4
seconds. When using an inappropriate window,
the emotion may be misclassified because
different emotions may be present when the
periods are too long. Existing literature does not
provide an adequate window size to achieve
optimal EEG-based emotion recognition. A
window size of 1 second is used in this
investigation.

However, in this research a comparison
is developed between K-NN, SVM and classifier
trees using the "log-energy" entropy as a
characteristic.
Methodology
The hypothesis that "induced emotions are
correlated
with
electroencephalographic
patterns" has been tried with different emotional
induction procedures. However, there are
different variables, both of the recording of
signals (noise, artifacts, etc.) and of the stimuli
used in the induction of emotions (images of
faces) as characteristics of the participants (race,
age, sex, language, culture, etc.) that influence
the results. This results in difficulty in inducing
a real emotional response using generalized
artificial techniques. On the other hand, if a
controlled experiment is guaranteed under the
same operating conditions, where in addition,
the selection of participants meet inclusion
criteria, then it is possible to induce an emotional
response with the appropriate stimulus.
Based on the above, this section
describes the development of two models to
predict: one the level of emotion in the
dimensions of affective valence (positive,
neutral or negative) and the second model the
level of activation (high, neutral or low). Figure
2 shows the architecture, which is made up of
four main modules: stimulation of the subject,
acquisition and processing of the data, extraction
of the characteristics and evaluation of the
performance of the models.

Algorithm classifier

A number of machine learning algorithms have
been employed for the classification of
emotions, such as SVM (Support Vector
Machine), K-NN (K- Nearest Neighbors), LDA
(Linear Discriminant Analysis), NM (Naiver
Bayes), trees classifiers, ANN (Artificial
Neuronal Network), etc.
ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

5
Article

ECORFAN Journal-Bolivia
June 2020 Vol.7 No.12 1-9
In order to stimulate different emotions
in the study subjects, seven validated video clips
were used. Each video stimulates a particular
emotion with greater intensity. Subjects evaluate
each of the videos in terms of valence and
excitement
using
the
Self-Assessment
Mannequin (SAM) instrument. In these tests, the
liker scale is used to quantify arousal and
pleasure. They are represented by graphic
images that express 9 levels (Morris, 1995).
Figure 3 shows the process for the
induction of emotions, which is based on a crosscase study. It begins with the recording of signals
from a baseline, in this case the subject remains
seated with his eyes open facing a black screen
for 35 seconds. Subsequently, the subject is
stimulated by a video with a duration of between
3 and 5 minutes. At the end of each video clip
you must answer the SAM (Select Assessment
for Manufacturing) test, which allows you to
know subjectively the assessment of each video
in two dimensions (see Figure 4).

Figure 3 Emotion induction process

Figure 4 Sam test for two dimensions
Figure 2 General model architecture

Stimuli
The experiment involved 25 healthy subjects
between 18 and 35 years with an average of 23.7
years, 17 male and 9 female, from the Sierra Sur
region of Oaxaca, which were selected for
convenience. Exclusion criteria are based on
whether the subject is at neurological or
psychiatric risk and addictions to alcohol or
drugs.

ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

After 30 seconds of having finished the
first video, the subject is stimulated again with
another video, at the end, the subject answers the
SAM test corresponding to the immediately
previous video, this is repeated until the subject
has seen all the videos continuously. At the end
of the videos, a second baseline is obtained,
which is analyzed and stored in the data
processing. The experiment lasts approximately
28.5 minutes.

JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

6

ECORFAN Journal-Bolivia

Article

June 2020 Vol.7 No.12 1-9
Data acquisition and processing
For this research, the EMOTIV EPOC device is
used, which consists of 14 channels (AF3, AF4,
FC6, FC5, F3, F4, P7, P8, T7, T8, O1 and O2)
located according to the international system 10
-20. Each electrode provides a sampling rate of
128 Hz and a resolution of 14 bits (see Figure 5.
The data is sent to the computer wirelessly using
Bluetooth technology. Emotiv Pro software
provides raw data for each of the channels,
which is stored in a file with the * csv extension.
Emotiv Epoc device complies with many
regulatory
requirements
like
Federal
communication commission (FCC) rules part 15,
Radio standard specification (RSS) 210 and low
voltage requirement rule: Directive 2006/95/EC.
FCC ensures that the device may not cause any
harmful interference and the interference
received should not cause any undesired
operation. RSS-210 is to ensure that the device
itself should not cause any interference. (Emotiv,
2016a.)

Figure 5 Emotiv device and electrode position system 1020 modified

To manipulate the information extracted
from the device, a data grouping method was
developed. This method allows organizing and
filtering the relevant information, reducing the
dimensionality of the data set, in order to search
for characteristics that best define the emotional
state. This methodology optimized the training
and prediction process of the models.
Feature extraction
Alpha, beta and gamma signals are of great
interest in emotion research. However, the
presence of noise from artifacts such as
eyepieces (below 4 Hz), heart sounds (around
1.2 Hz) and muscle (above 30 Hz) are eliminated
by using only the bands of beta and gamma
frequency.
ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

On the other hand, nonlinear analysis has
proven to be valuable in the evaluation of
physiological time series, since hidden
information related to the mechanisms has been
obtained in a wide variety of clinical settings.
However, although there are a large number of
nonlinear measurements, entropies based on
quantification of the regularity of time series
have been widely used in recent years, as they
can work as a success even on short and noisy
recordings (Pincus, 1991).
Performance
algorithms

evaluation

of

classifying

From the extracted characteristics, the next step
is to compare the performance of the classifying
algorithms proposed in this investigation.
Classifying algorithms are used to provide two
models. The valence dimension model has three
classes: positive, negative, and neutral. The
arousal model consists of three classes; high, low
and neutral. In each model, the sensitivity,
specificity and percentage of accuracy are
obtained. From the Area Under Curve (AUC) it
is determined if the model is appropriate to
identify emotions.
To avoid overfitting the data when
generating each model, it is used k-fold crossvalidation (k-fold CV). This algorithm randomly
divides the information into k-1 subsets where
80% of the data is destined to train and build the
model, while 20% of the remaining data was
reserved to evaluate and validate the classifier.
The objective of cross-validation is to ensure
independence between partitions of training and
test data. In this procedure k = 5 were used.
On the other hand, the PCA (Principal
Component Analysis) algorithm is used. The
objective is that from a set of observations of
possibly correlated variables they are converted
into a set of linearly uncorrelated variables. In
this case of a total of 24 variables, 7 linearly
uncorrelated variables were found.
Results
To analyze the results of the SVM, K-NN, LDA
and classifier trees algorithms, the confusion
matrix was implemented, which contains
information about the actual and predicted
classification of each algorithm. Table 1 shows
the performance of each classifying algorithm in
each model.
JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

7

ECORFAN Journal-Bolivia

Article

June 2020 Vol.7 No.12 1-9
Classifier Algorithms
Classifying trees
SVM
KNN
LDA

Valence
74.3%
83.2%
83.7%
67.3%

Arousal
60.8%
78.8%
81.1%
47%

Table 1 Accuracy results of each classifier algorithm with
the respective model

Performance evaluation of the KNN classifier
algorithm
The classifier algorithm with the best
performance in this pilot test is KNN. The KNN
algorithm in the affective valence dimension
presents a true positive rate of 85% and a false
negative rate of 15% to identify a negative class.
While for the neutral class 15% of the data
identifies it as positive and 14% as negative (see
Table 2). Furthermore, the area under the AUC
curve = 0.94, which is interpreted as the
appropriate KNN algorithm to identify positive,
negative and neutral emotions. This means that
this classifying algorithm has a better chance of
discerning between positive, negative and
neutral emotions.
True
classes
Negative
Positive
Neutral
Predicted
classes

-

-

-

-

-

85%
15%
14%
Negative

12%
83%
15%
Positive

2%
2%
71%
Neutral

85%
83%
71%
True
positive

15%
17%
29%
False
negative

Table 2 Confusion matrix of the KNN algorithm for the
affective valence dimension

The Table 3 shows the confusion matrix
for the arousal dimension. The KNN classifier
algorithm presents a prediction accuracy for a
high emotion of 82%, while to predict if the
emotion is low level it is 79%. On the other hand,
of all the data that correspond to the neutral
class, only 18% incorrectly predict it. The results
of the confusion matrix analysis indicate that it
has a true positive prediction rate of 82%. While
the false positive rate is 13%. The AUC is 0.93,
which indicates that the algorithm is
discriminant to define if there is a high arousal
level, a very low level or a neutral level.
True
classes
Low
High
Neutral
Predicted
classes

-

-

-

-

-

79%
16%
8%
Low

19%
82%
9%
High

2%
2%
82%
Neutral

79%
82%
72%
True
high

21%
18%
28%
False
low

Table 3 Confusion matrix of the KNN algorithm for the
arousal dimension
ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

Finally, Table IV presents the results of
the SAM test evaluation. It is observed that video
clips 1, 3, 5 and 7 induce a very low level in the
valence dimension, which is interpreted as very
negative emotion. Videos 2, 4 and 6 induce a
very positive emotion. In the arousal dimension,
videos 5 and 7 indicate a high level of excitement
while videos 1, 2, 3, 4 and 6 induce a low level
of excitation.
Videos
1
2
3
4
5
6
7

Stimulation
Negative
Positive
Negative
Positive
Negative
Positive
Negative

Valence
1.8
6.7
3.2
6.1
1.5
6.7
1.9

Arousal
3.0
2.7
2.8
2.7
4.8
2.1
6.4

Table 4 SAM test results

Discussions
In this work, we verify the effectiveness of a
procedure considering a cross-case study for the
induction and recognition of basic emotions.
Where entropy is considered as a unique
characteristic of the beta frequency bands and
range of an EEG. Furthermore, the process
allows comparing the performance of classifying
algorithms using EEG signals to predict basic
emotions.
The results show that the EEG signals
contain enough information to distinguish
between high, low and neutral in the arousal
dimension. While for the valence dimension,
distinguish between positive and negative and
neutral in affective valence. Furthermore, in
particular the KNN classifier algorithm using
entropy as its only characteristic is able to
distinguish between these classes, although it is
worth noting that the SVM model gives results
very similar to the KNN.
Subjects play an important role in
evaluating classifiers. An attempt was made to
select the subjects adequately, so that based on
the exclusion criteria, there were no biases in the
results. However, although there is an initial
baseline, there was no evaluation at the
beginning of the experiment that allowed
determining the emotional state of the subject.
Incorporating information from the subject's
emotional state at the start of the experiment
probably improves the results of the classifying
algorithms.
JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

8

ECORFAN Journal-Bolivia

Article

June 2020 Vol.7 No.12 1-9
The results in Table 4 show that the video
clips induce the expected emotion, both in the
affective and activation valence dimensions.
This correlates with the results of the
KNN classifier model. On the other hand,
although tests were made using the 14 electrodes
of the Emotiv device, the F3, F4, P7, P8, T7, T8,
O1 and O2 electrodes were the ones that provide
the greatest variability information in emotion
detection.
Conclusions
In this work we have explored the way to
distinguish positive and negative emotions, as
well as to discern between emotions with a high
activation level (excitation) and with a low level.
The use of databases to stimulate
emotions does not guarantee favorable results,
since it has been seen that much depends on the
cultural, social and sometimes even political
aspects. According to the results of the pilot test,
the use of exclusive videos to stimulate basic
emotions in the Oaxaca region of Mexico
presents optimistic results.
The use of classifying algorithms in the
study of emotions based on EEG information is
a way that guarantees encouraging results.
Among the algorithms most used for this type of
procedure, the KNN provides efficiency and
effectiveness in recognizing basic emotions.
However, the cross-validation and PCA
algorithms are important to achieve that the
classifier algorithm provides favorable results in
terms of its sensitivity and specificity.
Finally, it is not necessary to use all the
electrodes of the Emotiv device for the study of
emotions, with only 8 favorable results were
obtained.
In future work, it is intended to use only
one pair of electrodes, which will generate
sufficient evidence to identify emotions in the
affective and arousal valence dimensions.
Acknowledgments
This research work was supported by PRODEP,
IDCA 21306, code UNSIS-CA-13 in the 2018
Strengthening of Academic Bodies call.

ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

References
Al-Nafjan, A., Hosny, M., Al-Wabil, A., & AlOhali, Y. (2017). Classification of human
emotions from electroencephalogram (EEG)
signal using deep neural network. International
Journal of Advanced Computer Science and
Applications, 8(9), 419-425.
Bradley, M. M., & Lang, P. J. (1994). Measuring
emotion: the self-assessment manikin and the
semantic differential. Journal of behavior
therapy and experimental psychiatry, 25(1), 4959.
Chanel, G., Kierkels, J. J., Soleymani, M., &
Pun, T. (2009). Short-term emotion assessment
in a recall paradigm. International Journal of
Human-Computer Studies, 67(8), 607-627.
Chanel, G., Rebetez, C., Bétrancourt, M., & Pun,
T. (2011). Emotion assessment from
physiological signals for adaptation of game
difficulty. IEEE Transactions on Systems, Man,
and Cybernetics-Part A: Systems and Humans,
41(6), 1052-1063.
Daly, I., Williams, D., Hallowell, J., Hwang, F.,
Kirke, A., Malik, A & Nasuto, S. J. (2015).
Music-induced emotions can be predicted from
a combination of brain activity and acoustic
features. Brain and cognition, 101, 1-11.
Daşdemir, Y., Yıldırım, E., & Yıldırım, S.
(2017). Emotion Analysis using Different
Stimuli with EEG Signals in Emotional Space.
Natural and Engineering Sciences, 2(2), 1-10.
Emotiv. (2016). Epoc -14 Channel Wireless
EEG
Headset
Description.
https://www.emotiv.com/epoc/.
Friedrich, E. V., Sivanathan, A., Lim, T., Suttie,
N., Louchart, S., Pillen, S., & Pineda, J. A.
(2015). An effective neurofeedback intervention
to improve social interactions in children with
autism spectrum disorder. Journal of autism and
developmental disorders, 45(12), 4084-4100.
Gray, J. R. (2001). Emotional modulation of
cognitive control: Approach–withdrawal states
double-dissociate spatial from verbal two-back
task performance. Journal of Experimental
Psychology: General, 130(3), 436.

JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

9
Article

ECORFAN Journal-Bolivia
June 2020 Vol.7 No.12 1-9

Heger, D., Mutter, R., Herff, C., Putze, F., &
Schultz, T. (2013). Continuous recognition of
affective states by functional near infrared
spectroscopy signals. In 2013 Humaine
Association
Conference
on
Affective
Computing and Intelligent Interaction (pp. 832837). IEEE.
Iacoviello, D., Petracca, A., Spezialetti, M., &
Placidi, G. (2015). A real-time classification
algorithm for EEG-based BCI driven by selfinduced emotions. Computer methods and
programs in biomedicine, 122(3), 293-303.
Jatupaiboon, N., Pan-ngum, S., & Israsena, P.
(2013). Emotion classification using minimal
EEG channels and frequency bands. In The 2013
10th International Joint Conference on
Computer Science and Software Engineering
(JCSSE) (pp. 21-24). IEEE.
Koelstra, S., Muhl, C., Soleymani, M., Lee, J. S.,
Yazdani, A., Ebrahimi, T., & Patras, I. (2011).
Deap: A database for emotion analysis; using
physiological signals. IEEE transactions on
affective computing, 3(1), 18-31.

Pincus, S. M. (1991). Approximate entropy as a
measure of system complexity. Proceedings of
the National Academy of Sciences, 88(6), 22972301.
Posner, J., Russell, J. A., & Peterson, B. S.
(2005). The circumplex model of affect: An
integrative approach to affective neuroscience,
cognitive development, and psychopathology.
Development and psychopathology, 17(3), 715734.
Yuvaraj, R., & Murugappan, M. (2016).
Hemispheric asymmetry non-linear analysis of
EEG during emotional responses from
idiopathic Parkinson’s disease patients.
Cognitive neurodynamics, 10(3), 225-234.
Zhang, C., Tong, L., Zeng, Y., Jiang, J., Bu, H.,
Yan, B., & Li, J. (2015). Automatic artifact
removal from electroencephalogram data based
on a priori artifact information. BioMed research
international, 2015.

Li, X., Song, D., Zhang, P., Zhang, Y., Hou, Y.,
& Hu, B. (2018). Exploring EEG features in
cross-subject emotion recognition. Frontiers in
neuroscience, 12, 162.
Li, M., & Lu, B. L. (2009). Emotion
classification based on gamma-band EEG. In
2009 Annual International Conference of the
IEEE Engineering in medicine and biology
society (pp. 1223-1226). IEEE.
Megías, C. F., Mateos, J. C. P., Ribaudi, J. S., &
Fernández-Abascal, E. G. (2011). Validación
española de una batería de películas para inducir
emociones. Psicothema, 23(4), 778-785.
Morris, J. D. (1995). Observations: SAM: the
Self-Assessment Manikin; an efficient crosscultural measurement of emotional response.
Journal of advertising research, 35(6), 63-68.
Neath-Tavares, K. N., & Itier, R. J. (2016).
Neural processing of fearful and happy facial
expressions during emotion-relevant and
emotion-irrelevant tasks: a fixation-to-feature
approach. Biological psychology, 119, 122-140.

ISSN-On line: 2410-4191
ECORFAN® All rights reserved.

JARILLO-SILVA, Alejandro, GOMEZ-PEREZ, Víctor A.,
ESCOTTO-CÓRDOVA, Eduardo A. and DOMÍNGUEZRAMÍREZ, Omar A. Emotion classiﬁcation from EEG signals
using wearable sensors: pilot test. ECORFAN Journal-Bolivia.
2020

