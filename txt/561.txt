World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:8, No:3, 2014

A Real Time Set Up for Retrieval of Emotional
States from Human Neural Responses
Rashima Mahajan, Dipali Bansal, Shweta Singh

International Science Index, Biomedical and Biological Engineering Vol:8, No:3, 2014 waset.org/Publication/9997644

Abstract—Real time non-invasive Brain Computer Interfaces
have a significant progressive role in restoring or maintaining a
quality life for medically challenged people. This manuscript
provides a comprehensive review of emerging research in the field of
cognitive/affective computing in context of human neural responses.
The perspectives of different emotion assessment modalities like face
expressions, speech, text, gestures, and human physiological
responses have also been discussed. Focus has been paid to explore
the ability of EEG (Electroencephalogram) signals to portray
thoughts, feelings, and unspoken words. An automated workflowbased protocol to design an EEG-based real time Brain Computer
Interface system for analysis and classification of human emotions
elicited by external audio/visual stimuli has been proposed. The front
end hardware includes a cost effective and portable Emotiv EEG
Neuroheadset unit, a personal computer and a set of external
stimulators. Primary signal analysis and processing of real time
acquired EEG shall be performed using MATLAB based advanced
brain mapping toolbox EEGLab/BCILab. This shall be followed by
the development of MATLAB based self-defined algorithm to
capture and characterize temporal and spectral variations in EEG
under emotional stimulations. The extracted hybrid feature set shall
be used to classify emotional states using artificial intelligence tools
like Artificial Neural Network. The final system would result in an
inexpensive, portable and more intuitive Brain Computer Interface in
real time scenario to control prosthetic devices by translating
different brain states into operative control signals.

Keywords—Brain
Computer
Interface
(BCI),
Electroencephalogram (EEG), EEGLab, BCILab, Emotiv, Emotions,
Interval features, Spectral features, Artificial Neural Network,
Control applications.
I. INTRODUCTION

A

UTOMATED analysis of the physiological signals like
EEG has become more extensive during the last three
decades for the development of BCIs to include areas like lie
detection, stress and emotion measurement [1]. This sparked
some interest in investigating whether an emotion could be
recognized merely seeing the physiological response.
Although emotional information could also be retrieved from
other modalities like subject’s face expressions, speech, text,
gestures, etc. However, these can be consciously altered. This
led to the development of emotion detection methods based on

R. Mahajan and Shweta Singh are Research Scholars at Manav Rachna
International
University,
Faridabad,
Haryana,
India
(e-mail:
rashimamahajan@gmail.com; shweta_mmec@yahoo.com).
Dipali Bansal is the HOD of ECE Department at Manav Rachna
International
University,
Faridabad,
Haryana,
India
(e-mail:
dipali.fet@mriu.edu.in).
Rashima Mahajan is the Adjunct faculty at ECE Department at Apeejay
Stya
University,
Gurgaon,
Haryana,
India
(e-mail:
rashimamahajan@gmail.com).

International Scholarly and Scientific Research & Innovation 8(3) 2014

human physiological signals such as heart rate, skin
conductance, cardiac activity, neural responses (EEG), etc.
Recent researches on the human EEG reveal that brain activity
plays a major role in the assessment of emotions [2]. Further,
recognizing emotional states from neural responses is an
effective way of implementing affective brain computer
interfaces [3]. BCI systems create a communication channel
between the brain and computer by acquiring, analyzing and
classifying neural activities under certain stimulations, and
generate control signals for real world applications in areas
including clinic, psychiatry, security, military, law
enforcement, and telecommunications. Therefore, automatic
emotion recognition from EEG signals is obtaining more
attention nowadays. An EEG signal represents an electrical
activity of brain with its amplitude ranges from 10 to 100
microvolt whereas frequency lies in the range of 1 to 100Hz.
Brain waves are characterized by five frequency sub bands,
defined as; delta waves (1-4 Hz), theta waves (4-8 Hz), alpha
waves (8-13 Hz), beta1 waves (13-18 Hz), beta2 waves (18-30
Hz), and gamma waves (>30 Hz) [4]. These EEG signal
frequency bands are associated with the neural activity and
tend to change under different emotional environment [5].
Thus, by capturing these variations and analyzing them, it is
possible to characterize the correlated emotional state.
Area of affective computing has been extensively explored
in the context of human neural responses. Some previously
published works utilizes statistical features of EEG for
automated emotion recognition [1], [6], [7], discrete wavelet
transform (DWT) [8], [9] and lifting based wavelet transforms
in fusion with spatial filtering to extract emotion related
features of EEG in order to classify happiness, sadness,
disgust, and fear emotions using Fuzzy C-Means clustering
[10]. DWT based techniques are not so favorite due to large
feature set. Another research investigates the application of
optimization techniques including different sizes of sliding
windows, normalization approaches, filtering methods and
dimensionality reduction algorithms on time and frequency
domain features of EEG signal to distinguish pleasant, neutral,
and unpleasant emotional states using support vector machines
(SVM) [11]. This is followed by methods that involve the
application of short time Fourier Transform and Fast Fourier
Transform to the acquired EEG signals to classify feelings of
joy, sadness, anger, and pleasure/fear using SVM but with low
accuracy [12], [13]. The fusion of EEG with other
physiological signals such as skin conductance, blood volume
pulse (BVP) and respiratory rate has been explored
successfully to classify calm-neutral and negative excited
emotions using Genetic Algorithm (GA) and Elman neural

144

scholar.waset.org/1307-6892/9997644

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:8, No:3, 2014

network. The whole feature set comprises of linear features of
EEG in conjunction with chaotic invariants like approximate
entropy, fractal and correlation dimension [2]. Further a set of
algorithms classify human emotions by estimating power

International Science Index, Biomedical and Biological Engineering Vol:8, No:3, 2014 waset.org/Publication/9997644

Specifications
Channels
Sampling rate
Resolution
Bandwidth
Dynamic range
Coupling mode
Cost
Battery type
Battery life
Remarks

spectrum density followed by the extraction and comparison
of five EEG power bands with the standard EEG sub bands
using Bayesian network [14] and SVM [15], respectively.

TABLE I
COMPARISON OF EEG HEADSETS BY DIFFERENT MANUFACTURERS
Neurosky Mindwave
Xwave with Neurosky
Emotiv EEG
Neuroheadset [26]
[27]
[28]
14
1 (1-ref, 1-gnd)
1 (1-ref, 1-gnd)
128 Hz
512 Hz
16-bits
12-bits
8-bits
0.2-45 Hz
3-100 Hz
3-100 Hz
256mVpp
1 mVpp
AC coupled
AC Coupled
$750
$99.99
$90
Li-poly
AAA
Lithium
12hrs
8hrs
6hrs
Capture 4 mental
Capture 2 mental
Extracts 8-EEG band
States, 5- EEG bands
states
data

These linear feature extraction techniques suppress the
phase information related to the morphology of non-linear and
non-stationary EEG waves [16] and thus are less accurate. A
group of researchers presented a technique to detect and
classify emotions from human EEG signals using higher order
crossings analysis and achieved higher classification rates to
classify the emotions into six categories [17]-[20]. Another
recent research involves the use of higher order spectral
features of EEG to develop an emotional stress recognition
system using LDA classifier and achieved noticeable high
classification accuracy [21]. These latest findings reveal the
importance of higher order spectral analysis in affective
computing.
Work done earlier mainly involves the use of linear or nonlinear features of EEG. This paper proposes a real time
portable set up for retrieval of emotional states from human
neural responses by capturing both temporal (linear) and
spectral (non-linear) variations in EEG attained from
corresponding lobes of the brain using Emotiv EEG
Neuroheadset under external emotional stimulations.
II. DESIGN CONSIDERATIONS
The basic design for construction of real time and portable
set up for EEG based automated emotion recognition
incorporates the set of subsystems namely, stimuli modalities,
human subjects, EEG acquisition unit, signal processing unit.
A. Stimuli Modalities Selection
Development of an efficient emotion detection module
based on real time human neural responses primarily involves
the construction of emotion specific EEG signal dataset from
healthy volunteers by external stimulation, to make them
experience the emotional states of interest. As the literature
findings indicate that emotional state is reflected in human
neural responses it reflects high chances of EEG reactivity to
evoked emotion when the induction method is active for the
subject. Primary development procedure includes the selection
of efficient and reliable emotion induction stimuli as this

International Scholarly and Scientific Research & Innovation 8(3) 2014

Muse
[29]
4
220-500 Hz
2-50 Hz
2 mVpp
AC Coupled
$269
Lithium
4.5hrs
Detects positive and negative
emotions, 5 bands of brain waves

would be the key to repetition of experiment. Different stimuli
modalities include audio, visual or combination of both. The
labeled database of visual stimuli and audio stimuli for
emotion induction are International Affective Picture System
(IAPS) [22] and International Affective Digitized Sounds
(IADS) [23], respectively. It has been reported that EEG data
acquired with visual stimuli are relatively difficult to classify
in comparison to audio and audio-visual modalities [24]
whereas combined audio-visual stimuli outer performs the
other two [2], [6], [25]. Therefore, experiments with fusion of
both audio and visual stimuli to evoke human emotions shall
be realized in order to attain best emotion classification rates.
B. Subjects
To construct emotion specific EEG signal dataset twenty
healthy volunteered right-handed male subjects between the
ages of 20-30 years shall be selected. Each participant
equipped with EEG acquisition unit shall be made to sit in a
quiet and electromagnetic interference free environment to
acquire emotion elicited neural responses in terms of EEG.
C. Selection of Acquisition Unit
The next step is to explore the availability and features of
commercially available EEG headsets required to acquire
emotion specific neural responses. Table I compares and
highlights features of various commercial EEG headsets like
Emotiv EEG Neuroheadset [26], Neurosky Mindwave headset
[27], Xwave with Neurosky [28], and Muse headset [29].
Major innovations and up gradations has been made in the key
areas such as cost, portability, low power consumption,
lengthened battery performance, increased bit rate, better
resolutions, quick response, wireless connectivity and thus
enhanced efficiency and reliability of acquisition units.
The comparison of headsets present commercially for EEG
acquisition justifies the selection and suitability of Emotiv
EEG Neuroheadset to this research as it possesses higher bit
rate, better resolution and comparatively more user-friendly
interface.

145

scholar.waset.org/1307-6892/9997644

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:8, No:3, 2014

Toolbox

FieldTrip [30]

EEGLab [31]

BCILAB [32]

International Science Index, Biomedical and Biological Engineering Vol:8, No:3, 2014 waset.org/Publication/9997644

LIMO EEG [33]

BioSig [34]

PyEEG [35]
OpenVIBE [36]

TABLE II
COMPARISON OF FEATURES OF VARIOUS EEG SIGNAL PROCESSING AND ANALYSIS TOOLBOXES
Implementation Software
Objective
Features
No GUI, User can interact directly with
To test differences between averaged evoked
MATLAB functions, Rich feature set for real
responses entire scalp and time dimensions,
MATLAB
time and offline EEG preprocessing, event
provides flexible combination of high and low level
related responses, spectral analysis, connectivity
functions according to requirement.
analysis.
Provides functions for Independent Component
Analysis of EEG, event related potentials
MATLAB
To investigate single trial response variability.
(ERPs), power spectrum, event related cross
coherence and inter-trial coherence.
Plugin of EEGLab, online/offline analysis,
Signal processing, feature extraction, common
MATLAB
possesses ability to classify brain states based on
spatial patterns, slow cortical potentials,
statistical learning (LDA, Bayesian classifier).
spectrum analysis and non-linear classification.
First level analysis with maximum statistics,
To analyze evoked responses over all space and time
MATLAB
spatial temporal clustering-1D, 2-D, ERPs,
dimensions, provide robust parametric tests.
followed by second level statistical analysis.
Provides vast features including time, frequency
Accepting/generating signals in multiple data
and time-frequency transformations, common
C/C++, MATLAB/Octave
formats for EEG preprocessing, visualization,
spatial pattern classification, blind source
feature extraction and classification.
separation.
Provides a total set of 21 frequency domain and
Python
Feature extraction and feature vector mapping.
non-linear features.
Provides a platform to acquire, filter, process and
C++
Supports online signal processing and classification
classify EEG signals.

D.Selection of EEG Signal Processing Toolbox
Once the EEG acquisition unit is finalized an appropriate
MATLAB based advanced brain mapping toolbox would be
selected to primarily process and analyse the acquired EEG
signals. Data control and signal processing algorithms are then
explored on the acquired signal. To start with the development
the first task is to review the different standalone and
MATLAB based brain mapping toolboxes available for BCI
research ( FieldTrip [30], EEGLab [31], BCILAB [32], LIMO
EEG [33], BioSig [34], PyEEG [35], OpenVibe [36]) and
identify the right kind of signal processing platform that
provides quality set of features, programmability, and
flexibility. Table II compares the features of various EEG
signal processing toolboxes. EEG Lab toolbox and its plugin
BCILAB provides a perfect environment and platform for
analysis, detection and classification of emotional states from
acquired EEG signals.
Detailed materials required and method to be used in this
work is explained in the subsequent section.
III. MATERIALS AND METHODS
This research proposes the design set up of cost effective
and portable real time system for acquisition and analysis of
neural responses to classify human emotional states. Block
diagram of the EEG based real time human emotion
assessment system is sketched in Fig. 1. The proposed system
consists of stimuli generator to elicit the emotional state of
interest, EEG acquisition unit (Emotiv EEG Neuroheadset) to
acquire brain activity in the form of EEG, Bluetooth receiver

International Scholarly and Scientific Research & Innovation 8(3) 2014

for wireless reception of EEG signals, signal processing and
feature extraction module to characterize variations in EEG
under different emotional states followed by the classifier to
classify the human emotions.
A. EEG Signal Acquisition
Real time EEG potentials shall be acquired from subject’s
scalp using cost effective and portable EEG Neuroheadset unit
EMOTIV. It shall acquire neural signals of subject generated
in response to distinct audio-visual emotion stimulators using
14-channel electrode sensors (AF3, AF4, F7, F3, FC5, T7, P7,
O1, O2, P8, T8, FC6, F4, F8 with 2 reference electrodes CMS
and DRL) arranged at standard positions on scalp as shown in
Fig. 2 (a). The acquired EEG signal shall be transmitted to a
data receiver laptop through the Bluetooth dongle. The EEG
dataset shall be recorded at a sampling frequency of 128Hz
and saved as .edf (European data format) file. The name of the
electrode refers to the region of the cerebral cortex as depicted
in Fig. 2b above which the electrode is located, F corresponds
to the frontal lobe (involved in thoughts/conscious, deliberated
movements) and T the temporal lobe (involved in speech
reception), O the occipital lobe (signal reception from eye
retinas) and P the parietal lobe (sensory signal reception) with
C corresponds to central lobe [37]. It has been also observed
by continuously monitoring that emotional changes are more
associated with frontal scalp regions and thus can be
maximum captured at frontal channels i.e., AF3, AF4, F3, F4,
FC5 and FC6.

146

scholar.waset.org/1307-6892/9997644

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:8, No:3, 2014

International Science Index, Biomedical and Biological Engineering Vol:8, No:3, 2014 waset.org/Publication/9997644

Fig. 1 Block diagram of the proposed portable and wireless EEG based real time human emotion recognition and classification system

(a)

(b)

Fig. 2 (a) Emotiv EEG channels and their positioning layout [26], (b)
Lobes of cerebral cortex [37]

B. EEG Signal Processing and Algorithm Development
Preliminary signal processing of real time acquired EEG
shall be done using EEGLab/BCILAB in MATLAB
workspace and EDF Browser application software platforms.
Independent Component Analysis (ICA) algorithm of
EEGLAB shall be explored to identify distinct emotional
states from the neural signals attained through scalp channels.
Activity of the distinct Emotiv headset channels during certain
emotion shall be identified by plotting their channel activity
spectra plots. The event-related EEG-dynamics and relative
comparison information shall be retrieved by plotting
channel’s event related potentials (ERPs). The understanding
obtained from primary signal processing results using
predesigned toolboxes shall be applied to develop an efficient
MATLAB based algorithm for EEG based emotion
recognition by extracting an informational feature set from
human neural responses (EEG).
Further physiological signals including EEG exhibit
nonlinear behavior [16]. Considering this an attempt shall be
made to extract linear temporal and non-linear spectral
features of EEG. All the possibilities for fusion of linear and
non-linear features shall be tested to capture the finest
variations in human EEG responses under respective
emotional stimuli. The combination of the best discriminative
and low-dimensional feature set leading to the best
classification results using artificial intelligence tools shall be
selected.
C. Classification of Emotions
Once the neural responses are mapped into a feature set an

International Scholarly and Scientific Research & Innovation 8(3) 2014

appropriate artificial intelligence tool would be selected and
trained to classify distinct emotional states. The training
procedure shall involve the labeling of emotions according to
subject’s feedback. Several classification algorithms have
been proposed such as Bayesian statistical classifier [14], [38],
Support vector machine [11]-[13], [15], k-nearest neighbor
[8], [10], [39] Linear Discriminant Analysis (LDA) [21], [24]
and Artificial neural network (ANN) models [40], [41]. Out of
these defined classifiers support vector machines and artificial
neural network classifiers outer perform the others in terms of
processing time, flexibility, availability of multiple
architectures, size of training vector requirement and
suitability for both linear and non-linear modalities, hence
shall be implemented in the proposed research.
Finally the control interface stage consisting of neural
decoder and translation algorithm could be developed to
translate the classified emotions from EEG signals into
meaningful commands for various control applications for
rehabilitation. Fig. 3 is the experimental set up for Emotiv
EEG Neuroheadset based real time system for acquisition and
analysis of EEG signals to interpret human emotional states.

Fig. 3 Experimental set up for acquisition and analysis of EEG
signals for emotion assessment

IV. DISCUSSION
Real time affective Brain computer interfaces that could be
used for rehabilitative control need to be designed carefully. A
compromise could have been made between efficiency and
reliability to size, cost, hardware potential and power
requirements by the system. In comparison to earlier used
EEG acquisition system, Emotiv EEG Neuroheadsets have
sufficient power for long-lasting use [26]. The relative

147

scholar.waset.org/1307-6892/9997644

International Science Index, Biomedical and Biological Engineering Vol:8, No:3, 2014 waset.org/Publication/9997644

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:8, No:3, 2014

advantages and disadvantages of the different EEG acquisition
units have been discussed in detail. The design proposed in
this work shall ensure sophisticated real time processing of
neural signals using free of cost accessible advanced brain
mapping toolboxes in conjunction with Emotiv that requires
less power, is compact in size, portable, possesses higher
information rate and resolution and is cost effective. It has also
been reported that EEG data acquired with combination of
audio-visual stimuli exhibits higher classification rates [2], [6],
[25]. Different brain mapping toolboxes have been surveyed in
context of their ability to analyze and thus construct the most
informational feature set from human neural responses (EEG)
corresponding to elicited emotional states. The feature vector
must also be compact in size in order to reduce complexity
and computational load associated with feature extraction and
classification stage. The classification stage classifies the
signals by training the classifier using labeled emotional
feature set. The selection of the best discriminative features is
therefore essential to achieve effective emotion classification
rates in order to accurately decode the subject’s intentions.
Therefore, an effort shall be attempted to develop a more
efficient and robust technique to detect and classify human
emotions automatically by merely analyzing the brain activity
of subject using MATLAB based algorithms without
compromising with the accuracy while reducing complexity
and response time of the system. The efforts shall also be
directed towards investigating the combinations of feature sets
of real time attained EEG signals in the attempt to increase the
classification rate to interpret human mental states in order to
enrich human-computer interface

Rachna International University’ and the platform that has
been provided to work as a team.
REFERENCES
[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]
[11]

V. CONCLUSION
Design of real time Brain computer interfaces is crucial for
successful analysis of neural responses for rehabilitation. An
attempt has been made to present a review of construction
protocols and neural feature sets considered for development
of existing BCIs. Documentation of the existing BCIs design
process shall lead towards designing of a brain computer
interface for human emotion recognition with refinement of
existing ones using additional feature set. A design set up of
real time, cost-effective and portable EEG based affective BCI
using Emotiv EEG Neuroheadset has been proposed. The
arrangement discussed in this paper would result in an
inexpensive established solution to real time implementation
of BCIs for acquiring and analyzing EEG signals to
discriminate human emotions with reduced complexity and
response time of the system. The designed system can be
further programmed towards the development of a
neuroscientific and medical tool to assist complete or partial
paralyzed patients suffering from voluntary motor disorder
such as speech loss, amputation or psychiatric disorders in
order to restore or maintain a quality life.
ACKNOWLEDGMENT

[12]

[13]

[14]

[15]

[16]
[17]

[18]

[19]

This research has been made possible owing to the
encouragement and support provided by our institute ‘Manav

International Scholarly and Scientific Research & Innovation 8(3) 2014

148

R.W. Picard, E. Vyzas and J. Healey, “Toward Machine Emotional
Intelligence: Analysis of Affective Physiological State”, IEEE T. Pattern
Anal., vol. 23, pp.1175-1191, 2001.
M. A. Khalilzadeh, S. M. Homam, S. A. Hosseini and V. Niazmand,
“Qualitative and Quantitative Evaluation of Brain Activity in Emotional
Stress”, Iranian Journal of Neurology, vol.8 (28), pp. 605-618, 2010.
K. Schaaff and T. Schultz, “Towards an EEG-Based Emotion
Recognizer for Humanoid Robots”, in The 18th IEEE International
Symposium on Robot and Human Interactive Communication, Toyama,
Japan. 2009: pp. 792-796.
D. P. Subha, P.K. Joseph, R. Acharya and C.M. Lim, “EEG Signal
Analysis: A Survey”, Journal of Medical Systems, vol. 34(2), pp. 195212, 2010.
S.A. Hosseini, “Classification of Brain Activity in Emotional States
Using HOS Analysis”, International Journal of Image, Graphics and
Signal Processing, vol. 4(1), pp. 21-27, 2012.
K. Takahashi and A. Tsukaguchi, “Remarks on Emotion Recognition
from Multi-Modal Biopotential Signals”, Proceeding of the IEEE
International Workshop on Robot and Human Interactive
Communication, Sept. 20-22, 2004, IEEE Xplore, Japan, pp: 95-100
C. T. Yuen, W. S. San, J. H. Ho and M. Rizon, “Effectiveness of
Statistical Features for Human Emotions Classification using EEG
Biosensors,” Research Journal of Applied Sciences, Engineering and
Technology, vol. 5(21), pp. 5083-5089, 2013.
M. Murugappan, R. Nagarajan and S. Yaacob, “Comparison of different
wavelet features from EEG signals for classifying human emotions”,
Proceeding of IEEE Symposium on Industrial Electronics and
Applications, 2009, pp: 836-841, Kuala Lumpur.
E. D. Ubeyli, “Combined Neural Network Model Employing Wavelet
Coefficients for EEG Signal Classification”, Digit. Signal. Process, vol.
19, pp.297-308, 2009.
M. Murugappan, R. Nagarajan and S. Yaacob, “Combining Spatial
Filtering and Wavelet Transform for Classifying Human Emotions
Using EEG Signals”, J. Med. Biol. Eng., vol. 31(1), pp.45-51, 2010.
K. Schaaff and T. Schultz, “Towards Emotion Recognition from
Electroencephalographic Signals”, Proc. of 3rd International
Conference on Affective Computing and Intelligent Interaction (ACII)
and Workshops, pp. 1-6, 2009.
Y. P. Lin, C. H. Wang, T. L. Wu, S. K. Jeng and J. H. Chen, “EEGBased Emotion Recognition in Music Listening: A Comparison of
Schemes for Multiclass Support Vector Machine”, Proceeding of
ICASSP, IEEE International Conference on Acoustics, Speech and
Signal Processing, 2009, pp.489- 492, Taipei.
Mikhail M, Ayat K.E, “Using Minimal Number of Electrodes for
Emotion Detection Using Brain Signals Produced from a New
Elicitation Technique”, Int. J. Autonomous and Adaptive
Communications Systems, vol. 6(1), pp. 80-97, 2013.
K.E. Ko, H. C. Yang and K. B. Sim, “Emotion Recognition Using EEG
Signals with Relative Power Values and Bayesian Network”,
International Journal of Control, Automation & Systems, vol. 7(5),
pp.865-870, 2009.
N. Jatupaiboon, S. Panngum, and P. Israsena, “Real-Time EEG-Based
Happiness Detection System”, Hindawi Publishing Corporation: The
Scientific World Journal Volume, Article ID 618649, 12 pages, 2013,
K. C. Chua, V. Chandran and R. Acharya, “Application of Higher Order
Statistics/Spectra in Biomedical Signals - A Review”, Journal of
Medical Engineering and Physics, vol. 32(7), pp. 679-689, 2010.
P.C. Petrantonakis and L. J. Hadjileontiadis, “EEG-Based Emotion
Recognition Using Hybrid Filtering and Higher Order Crossings”, Proc.
of 3rd International Conference on Affective Computing and Intelligent
Interaction (ACII) and Workshops: IEEE, 2009, pp. 1-6, Amsterdam.
P.C. Petrantonakis and L. J. Hadjileontiadis, “Emotion Recognition from
Brain Signals Using Hybrid Adaptive Filtering and Higher Order
Crossings Analysis”, IEEE Transactions on Affective Computing, vol.
1(2), pp. 81-97, 2010.
P.C. Petrantonakis and L. J. Hadjileontiadis, “Emotion Recognition from
EEG Using Higher Order Crossings”, IEEE T. Inf. Technol., vol. 14, pp.
186-197, 2010.

scholar.waset.org/1307-6892/9997644

International Science Index, Biomedical and Biological Engineering Vol:8, No:3, 2014 waset.org/Publication/9997644

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:8, No:3, 2014

[20] Y. Liu, O. Sourina and M.K. Nguyen, “Real-Time EEG-Based Human
Emotion Recognition and Visualization” Proceeding of International
Conference on Cyberworlds, pp. 262-269, 2010.
[21] S. A. Hosseini, M. A. Khalilzadeh, M. B. Naghibi-Sistani and V.
Niazmand, “Higher Order Spectra Analysis of EEG Signals in
Emotional Stress States”, ITCS '10 Proceedings of Second International
Conference on Information Technology and Computer Science, IEEE
Computer Society, 2010, pp. 60-63, Washington, DC, USA.
[22] P. J. Lang, M. M. Bradley, and B. N. Cuthbert, “International Affective
Picture System (IAPS): Affective Ratings of Pictures and Instruction
Manual”, the Center for Research in Psychophysiology, University of
Florida, Gainesville, FL, USA, 2005.
[23] M. M. Bradley and P. J. Lang, “International Affective Digitized Sounds
(IADS): Stimuli, Instruction Manual and Affective Ratings”, the Center
for Research in Psychophysiology, University of Florida, Gainesville,
FL, USA, 1999.
[24] D. O. Bos, “EEG-Based Emotion Recognition”, [online] http://hmi.ewi.
utwente.nl/verslagen/capita-selecta/CS-Oude_Bos-Danny.pdf, 2006.
[25] K. H. Kim, S. W. Bang and S. R. Kim, “Emotion Recognition System
Using Short-Term Monitoring of Physiological Signals”, Medical and
Biological Engineering and Computing, Vol. 42, pp. 419-427, 2004.
[26] Emotiv Website: http://www.emotiv.com/, Accessed 26 January, 2014.
[27] Neurosky Website: http://store.neurosky.com/products/mindwave-1,
Accessed 26 January, 2014.
[28] XwaveWebsite:
http://www.plxdevices.com/product_info.php?id=
WAVESPORT, Accessed 27 Januaryy, 2014.
[29] Interaxon Muse Website: http://www.interaxon.ca/muse/, Accessed 27
Januaryy, 2014.
[30] R. Oostenveld, P. Fries, E. Maris, and J. M. Schoffelen, “FieldTrip:
Open Source Software for Advanced Analysis of MEG, EEG, and
Invasive Electrophysiological Data”, Computational Intelligence and
Neuroscience Vol. 2011 (2011), Article ID 156869, 9 pages.
[31] A. Delorme and S. Makeig, “EEGLAB: An Open Source Toolbox for
Analysis of Single-Trial EEG Dynamics”, J. Neurosci. Methods, vol.
134, pp. 9–21, Mar. 2004.
[32] G. Schalk, et al., “BCI2000: A General-Purpose Brain-Computer
Interface (BCI) System”, IEEE Transactions on Biomedical
Engineering, vol. 51(6), pp. 1034-1043, 2004.
[33] C. R. Pernet, N. Chauveau, C. Gaspar, and G. A. Rousselet, “LIMO
EEG: A Toolbox for Hierarchical LInear MOdeling of
ElectroEncephaloGraphic Data”, Computational Intelligence and
Neuroscience, vol. 2011, Article ID 831409, 11 pages, 2011.
[34] C. Vidaurre, T. H. Sander, and A. Schlögl, “BioSig: The Free and Open
Source Software Library for Biomedical Signal Processing,” Comput.
Intell. Neurosci., pp. 935364, 2011.
[35] F. S. Bao, X. Liu, and C. Zhang, “PyEEG: An Open Source Python
Module for EEG/MEG Feature Extraction,” Comput. Intell.Neurosci.,
pp. 406391, 2011.
[36] Openvibe website: http://openvibe.inria.fr/ Accessed 27 January, 2014.
[37] J. L. Andreassi, Psychophysiology: Human Behavior and Physiological
Response, fourth ed. Lawrence Erlbaum Associates, Hillsdale, New
Jersey, 2000.
[38] H. Suk and S. W. Lee, “A Novel Bayesian Framework for
Discriminative Feature Extraction in Brain-Computer Interfaces”, IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 35 (2),
pp. 286-299, February 2013.
[39] A. C. Wanpracha, Y. Fan and C.S. Rajesh, “On the Time Series Knearest Neighbor Classification of Abnormal Brain Activity”, IEEE T.
Syst. Man Cy., vol.37, pp.1005-1016, 2007.
[40] C. J. Lin and M. H. Hsieh, “Classification of Mental Task from EEG
Data Using Neural Networks Based On Particle Swarm Optimization”,
Neurocomputing, vol.72, pp.1121– 1130, 2009.
[41] V. Srinivasan, C. Eswaran, and N. Sriraam, “Approximate EntropyBased Epileptic EEG Detection Using Artificial Neural Networks,”
IEEE Transactions on Information Technology in Biomedicine, vol.
11(3), May 2007.

International Scholarly and Scientific Research & Innovation 8(3) 2014

149

scholar.waset.org/1307-6892/9997644

