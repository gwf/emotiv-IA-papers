MulDmodal	  ValidaDon	  of	  Facial	  Expression	  DetecDon	  SoIware	  for	  
Real-­‐Dme	  Monitoring	  of	  Aﬀect	  in	  PaDents	  with	  Suicidal	  Intent	  
Francesco	  Amico	  a,	  Graham	  Healy	  b,	  Mahnaz	  Arvaneh	  c,	  Damien	  Kearney	  d,	  
Eva	  Mohedano	  b,	  Darren	  Roddy	  a,	  John	  Yek	  a,	  Alan	  F.	  Smeaton	  b,	  Jus/n	  Brophy	  a	  
	  
b

a	  Newcastle	  Psychiatric	  Hospital,	  Newcastle,	  Co.	  Wicklow,	  Ireland;	   	  The	  Insight	  Centre	  for	  Data	  Analy/cs,	  Dublin	  City	  University,	  Ireland;	  c	  Trinity	  College	  
Ins/tute	  of	  Neuroscience,	  and	  The	  Insight	  Centre	  for	  Data	  Analy/cs,	  Ireland;	  d	  Biomedical	  Engineering	  Research	  Group,	  Maynooth	  University	  
	  

BACKGROUND	  
High risk for suicide is typically assessed by clinicians using questionnaires and interviews.
Although useful in a wide range of clinical settings, this assessment approach has many
disadvantages e.g., misinterpretation of subtle differences in meanings of words used in
emotional scales, objective and subjective biases and difficulties in reliably assessing the
intensity of the emotion. Most significantly, these cues can be missed with catastrophic
consequences.
In this context, we suggest that novel, non-intrusive facial affect detection technology could
play a role in the clinical evaluation of suicidal ideation. We report on the acquisition of
discrete emotional states (i.e., fear, sadness, joy, anger, disgust and surprise) while the
patient is participating in a standardised task utilising the presentation of emotionally
challenging images.

OBJECTIVES	  

Fig.2. The image presentation task employed

PRELIMINARY	  RESULTS	  
FACET
Differences between conditions for FACET measures (N= 33) began to appear approximately
1 second after stimulus presentation (Fig.3). Post-hoc comparison for between-subjects
effects revealed significant differences for “sadness”: F(1,31)= 7.333, p= .011 and “anger”:
F(1,31)= 4.012, p= .054 (near significant)

We sought to test the hypothesis that previously validated biomarkers of high risk for suicide,
namely event related potentials (ERP), Galvanic skin response (GSR) and heart rate
variability (HRV) can be employed in combination with facial affect and pupil dilation
measures, in a novel diagnostic battery that will ultimately increase reliability of clinical
evaluations of suicidal persons.

MATERIALS	  AND	  METHODS	  
	  
Participants
Suitable patients and age-/gender-matched healthy controls (subjects with no history of
suicidal ideation, were recruited from South Dublin and Wicklow Mental Health Directorate.
All participants were screened by an experienced psychiatrist through a standardized
clinically conducted diagnosis of either depression, bipolar depression or borderline
personality disorder. Clinical exclusion criteria included current alcohol dependence and/or
drug misuse.

Fig.3. RM-ANOVA F-statistic over time for each of the FACET sources with a sliding (boxcar) window of -350
ms, 350 over 16 time points. P-values (dashed horizontal lines) are Bonferroni corrected. (F(d f1= 1.6, d f2=
47), N= 33

EEG/ERP
The P300 was identified to be present in the time region of approximately 300ms to 800ms
post-stimulus. Average amplitude across trials within this time region was computed for each
condition for each subject (N=16) for input to the RM-ANOVA model. The sum of channels
O1+O2 was used as the primary epoch window. A significant relationship for stimulus type
was found F(1.54, 16.941) = 5.099, p= .015. Results are Greenhouse-Geisser corrected
(Fig.4).

Measures acquired and data acquisition technology
Real-time facial and physiological data were acquired using the iMotions FACET system
software package (http://imotionsglobal.com) integrated with a Shimmer unit to measure
GSR and HRV.
Further, we acquired continuous EEG data using the Emotiv EPOC system and headset
(http://epoc.com), a wireless high resolution revolutionary brain computer interface capable
of recording EEG data comparably to traditional EEG devices. Emotiv EPOC features 14
EEG channels plus 2 references offering optimal positioning for accurate spatial resolution.
Channel names based on the international 10-20 electrode location system are: AF3, F7, F3,
FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4, with CMS/DRL references in the P3/P4
locations and uses sequential sampling method, single ADC, at a rate of 128 SPS or 256
SPS* (2048 Hz internal). Emotiv EPOC operates at a resolution of 14 bits or 16* bit per
channel with frequency response between 0.16 - 43 Hz. The experimental set up is shown in
Fig.1

GSR
Fig.4. Event related potentials (ERP) elicited after presentation of sad, neutral or positive images within 1000
ms epochs
Galvanic Skin Response values (N= 33) following
stimulus presentation are epoched into five
3 second segments (0s-15s) with the 500ms preceding stimulus onset as a baseline. So far,
a weak trend for a within-subject main effect for stimulus condition exists F(1.159, 35.493) =
2.875, p = .094

HRV
Time had a significant main effect [F(6, 102) = 12.66, p <0.001)]. Moreover, HRV was
Fig.5. Galvanic Skin Response values following stimulus presentation are epoched in 1 second segments.
significantly different in patients
(N= 10) and healthy controls (N= 9) (F(1,17)= 4.63, p=
So far, no effects have been revealed (Fig.5)
0.046). These results are shown in Fig.6

quality	  

Fig.1. Top: An example of real-time face recording from a participant; bottom left, the Emotiv EPOC system;
bottom right: The Shimmer Wearable Sensor System

Behavioural task employed
Data were acquired from participants during presentation of emotionally challenging images
randomly selected from the Geneva affective picture database (GAPED). Images (N= 48)
were subdivided in 3 categories, each containing 16 images: 1) sad (average emotional
valence score: 26.7/100); 2) neutral (average emotional valence score: 55.5/100); 3) positive
(average emotional valence score: 91.5/100). Each image was presented for 6 sec, with an
interval of 8 sec between each image. Categories were randomized throughout the session
(Fig.2).

RESEARCH POSTER PRESENTATION DESIGN © 2015

www.PosterPresentations.com

Fig.6. Heart rate variability (HRV) for patients and healthy controls during and after image presentation

CONCLUSIONS	  
Our preliminary results suggest that our data acquisition set up is sensitive image emotional
valence. A larger subject population is needed to confirm these results and to investigate
putative anomalies in suicidal patients.

©	  2
2
B
p

