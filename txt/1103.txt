electronics
Article

Motor Imagery Based Continuous Teleoperation
Robot Control with Tactile Feedback
Baoguo Xu 1, * , Wenlong Li 1 , Xiaohang He 1 , Zhiwei Wei 1 , Dalin Zhang 1 , Changcheng Wu 2
and Aiguo Song 1
1

2

*

School of Instrument Science and Engineering, Southeast University, Nanjing 210096, China;
zzuliwenlong@126.com (W.L.); hxhseu@126.com (X.H.); wswzw1993@163.com (Z.W.);
zhangdalin@163.com (D.Z.); a.g.song@seu.edu.cn (A.S.)
College of Automation Engineering, Nanjing University of Aeronautics and Astronautics,
Nanjing 210003, China; changchengwu@nuaa.edu.cn
Correspondence: xubaoguo@seu.edu.cn; Tel.: +86-1364-519-3539

Received: 16 December 2019; Accepted: 15 January 2020; Published: 17 January 2020




Abstract: Brain computer interface (BCI) adopts human brain signals to control external devices
directly without using normal neural pathway. Recent study has explored many applications, such
as controlling a teleoperation robot by electroencephalography (EEG) signals. However, utilizing
the motor imagery EEG-based BCI to perform teleoperation for reach and grasp task still has many
difficulties, especially in continuous multidimensional control of robot and tactile feedback. In this
research, a motor imagery EEG-based continuous teleoperation robot control system with tactile
feedback was proposed. Firstly, mental imagination of different hand movements was translated into
continuous command to control the remote robotic arm to reach the hover area of the target through a
wireless local area network (LAN). Then, the robotic arm automatically completed the task of grasping
the target. Meanwhile, the tactile information of remote robotic gripper was detected and converted
to the feedback command. Finally, the vibrotactile stimulus was supplied to users to improve their
telepresence. Experimental results demonstrate the feasibility of using the motor imagery EEG
acquired by wireless portable equipment to realize the continuous teleoperation robot control system
to finish the reach and grasp task. The average two-dimensional continuous control success rates
for online Task 1 and Task 2 of the six subjects were 78.0% ± 6.1% and 66.2% ± 6.0%, respectively.
Furthermore, compared with the traditional EEG triggered robot control using the predefined
trajectory, the continuous fully two-dimensional control can not only improve the teleoperation robot
system’s efficiency but also give the subject a more natural control which is critical to human–machine
interaction (HMI). In addition, vibrotactile stimulus can improve the operator’s telepresence and
task performance.
Keywords: brain computer interface; motor imagery; continuous teleoperation robot control;
vibrotactile feedback

1. Introduction
Brain computer interface (BCI) utilizes brain activity to communicate with external devices
directly [1–3]. In the past few decades, both invasive BCI and noninvasive BCI received much attention
from researchers. The BCI has evolved from basic communication to a state in which some complex
tasks can be routinely performed with healthy subjects. Soekadar et al. [4] demonstrated that the
hand exoskeleton based on hybrid electroencephalography (EEG)/electro-oculogram (EOG) BCI can
restore the autonomy and independence of paraplegic individuals in everyday life. The feasibility
of inducing neurological recovery in paraplegic patients by long term training with a BCI-based gait

Electronics 2020, 9, 174; doi:10.3390/electronics9010174

www.mdpi.com/journal/electronics

Electronics 2020, 9, 174

2 of 16

protocol was shown in [5]. In addition, BCI-based control of virtual object [6], robotic arm [7–9], robotic
prosthetic [10,11], wheelchair [12], and various rehabilitation devices [13–16] were also reported in
previous research.
With the development of the BCI technology, some groups have carried out research on BCI-based
teleoperation. In [17], a brain-driven telepresence system was provided to the user in remote
environments through a mobile robot. The EEG signal of P300 was utilized. A BCI-based teleoperation
control for the exoskeleton robotic system was proposed in [18]. In this study, the subject can guide the
robot to perform manipulation tasks by integrating the BCI commands and adaptive fuzzy controllers.
Zhao et al. [19] developed a teleoperation control framework for multiple coordinated mobile robots
using BCI. Both of the above two studies adopt the EEG signals of steady-state visually evoked
potentials (SSVEP).
However, few research groups have attempted to apply the motor imagery EEG signals to
the teleoperation robotic system in reach and grasp tasks, and many difficulties still remain, such
as continuous extracting trajectory information from human movement imagination, continuous
multidimensional control, and tactile feedback. Most of the previous research focuses on the
conventional two class or four class classification of EEG signal to get one or four discrete control
commands and trigger the robot to move along the predefined trajectory instead of directly
converting the EEG signals to multidimensional continuous control information [20]. For example,
Bousseta et al. [21] proposed a BCI system which controlled a robot arm based on the user’s thought.
Four subjects were instructed to imagine the execution of movements of the left hand, right hand,
both hands, or movement of the feet. The classifier generated four commands to control the robot’s
arm to move along the predefined trajectory instead of continuous control. Li Y et al. [22] presented
an EEG-based system classifying the signals from the Emotiv EPOC into the corresponding action
commands. The trigger commands were sent to the robot and the robot performed the predefined basic
maneuvering, such as moving forwards, moving backwards, turning left, and turning right. In our
previous work, trigger commands were also used to control the rehabilitation robot [23]. In addition,
most of the BCI-based online control systems adopted nonportable equipment and could only be used
in laboratory environments. Although it has high signal-to-noise ratio, it is very inconvenient to use
and carry.
Aiming at these problems, we designed a BCI-based continuous teleoperation robot control
system with tactile feedback and recruited a group of healthy participants to use their movement
imagination EEG to continuously control the remote robotic arm for performing reach and grasp
tasks. Wireless portable acquisition equipment was adopted to obtain the EEG signals in order to
make the BCI-based system easier to use in daily life. Moreover, the tactile information of remote
robotic gripper was detected and transferred to the local computer. At last, the subjects were provided
with vibrotactile stimulus to improve their telepresence and task performance. The motor imagery
EEG-based continuous teleoperation robot control system with vibrotactile feedback for the task of
reach and grasp may offer the following advantages: (a) It allows subjects to perform teleoperation
using only movement imagination and explore the operator’s motor initiatives; (b) the continuous
control not only can improve the teleoperation robot system’s efficiency but also offer the subject a more
natural control which is very important in human machine interaction, especially in the teleoperation
robot system; (c) the biofeedback based on vibrotactile stimulus may improve operator’s telepresence,
enhance the confidence of the operator, and eventually improve task performance; (d) it may provide
critical data to understand the processes of motor imagery based-teleoperation robot control system.
2. Materials and Methods
2.1. System Description
Figure 1 shows the experimental setup used in this study. The EEG-based continuous teleoperation
robot system consists of the following components: A wireless EEG amplifier, vibrotactile stimulation

Electronics 2020, 9, 174

Electronics 2020, 9, x FOR PEER REVIEW

3 of 16

3 of 16

system,
a robotic
arm, robotic
gripper
force detection
system,
a wireless
gateway, asystem,
master PC,
and a
vibrotactile
stimulation
system,
a robotic
arm, robotic
gripper
force detection
a wireless
slave
PC.
gateway, a master PC, and a slave PC.

Figure1. 1.
Motor
imagery
EEG-based
continuous
teleoperation
robot
control
with
Figure
Motor
imagery
EEG-based
continuous
teleoperation
robot control
system
with system
biofeedback.
biofeedback.

Firstly, the master PC displayed the target to indicate the participant to perform the corresponding
master
displayed
target
to indicateSecondly,
the participant
perform
the
motorFirstly,
imagerythe
of left
hand,PC
right
hand, boththe
hands,
or relaxation.
the cursortowas
controlled
corresponding
motor
of left hand,
right
hand,
bothashands,
or relaxation.
Secondly,
the
by
motor imagery
EEGimagery
and continued
moving
on the
screen
the visual
feedback until
it hit the
cursor target.
was controlled
by motor
imagery EEG
and continued
on the
themoved
visual
virtual
In accordance
with continuous
motion
trajectory ofmoving
the cursor,
the screen
roboticas
arm
feedback until
it hit the target.
virtual The
target.
In accordance
with continuous
motion
trajectory
of the
cursor,
continuously
toward
wireless
EEG amplifier
is in charge of
recording
the motor
imagery
the robotic
arm moved
the target. The
Themaster
wireless
amplifier for
is inprocessing
charge of
EEG
and sending
the datacontinuously
to the mastertoward
PC by Bluetooth.
PCEEG
is responsible
recording
the motor
imagery
EEG
and sending
to the master
by Bluetooth.
master
the
movement
imagination
EEG
signals,
sendingthe
thedata
continuous
motionPC
commands
to theThe
slave
PC,
PC is responsible
forcursor
processing
movement
imagination
EEG
signals,
sending
the continuous
controlling
the virtual
for thethe
purpose
of providing
subjects
with
the visual
feedback,
receiving
motion
slavegripper
PC, controlling
cursor forthe
thevibrotactile
purpose of
providing
the
force commands
informationtoofthe
robotic
from slavethe
PC,virtual
and controlling
stimulation
subjectsfor
with
visualoffeedback,
receiving
the force
of robotic
gripper
slave PC,
system
the the
purpose
supplying
the subjects
with information
tactile feedback.
The slave
PC from
is in charge
of
and controlling
the vibrotactile
system
for theaccording
purpose of
subjectsfrom
with
controlling
the robot
to finish thestimulation
task of reach
and grasp
to supplying
the motionthe
trajectory
tactile
feedback.
The slave
is ininformation
charge of controlling
the robotand
to sending
finish the
reach PC.
and
the
master
PC, acquiring
thePC
tactile
of robotic gripper,
it task
to theofmaster
grasp
according
to the motion between
trajectory
from and
the slave
master
acquiring
the tactile information
of
In
addition,
the communication
master
PCPC,
is based
on a client-server
system with
roboticprotocol.
gripper, The
and master
sendingPC
it and
to the
master
PC.
theclient,
communication
TCP-IP
slave
PC act
asIn
theaddition,
server and
respectively.between master
and slave PC is based on a client-server system with TCP-IP protocol. The master PC and slave PC
2.2.
Architecture
act Control
as the server
and client, respectively.
The control architecture of the EEG-based continuous teleoperation robot control system is shown
2.2. Control Architecture
in Figure 2. To begin with, the multichannel EEG signals were spatially filtered by a common average
reference
Secondly,
every
50 ms, the
amplitudeteleoperation
of specific mu
rhythm
band
or betais
The (CAR)
controlfilter.
architecture
ofinthe
EEG-based
continuous
robot
control
system
rhythm
over2.the
(C3with,
channel)
and right (C4EEG
channel)
hemispheres
werefiltered
estimated
on
shown band
in Figure
Toleft
begin
the multichannel
signals
were spatially
by abased
common
aaverage
16 orderreference
autoregressive
(AR) model
using
last50500
signals.ofThirdly,
amplitudes
(CAR) filter.
Secondly,
in the
every
ms,ms
theEEG
amplitude
specificthese
mu rhythm
band
were
linearly
mapped
generate
the
two-dimensional
continuous
motionhemispheres
trajectory. Next,
motion
or beta
rhythm
band to
over
the left
(C3
channel) and right
(C4 channel)
werethe
estimated
trajectory
was utilized to(AR)
control
the using
cursorthe
for last
the 500
purpose
of giving
visual
feedback.
based on information
a 16 order autoregressive
model
ms EEG
signals.
Thirdly,
these
At
the same were
time, linearly
the motion
trajectory
information
was transmitted continuous
to the slavemotion
PC by the
wires
amplitudes
mapped
to generate
the two-dimensional
trajectory.
local
(LAN). Then,
the robotic
was controlled
Next,area
the network
motion trajectory
information
wasarm
utilized
to control according
the cursorto
forthe
thecontinuous
purpose ofmotion
giving
trajectory.
Once the
arm
arrives
the hover
area, theinformation
robotic gripper
reachto
and
visual feedback.
Atrobotic
the same
time,
the motion
trajectory
was would
transmitted
thegrasp
slavethe
PC
target
automatically
order
to reduce
the brain
load.
“hover
area”
was
a virtual cylindrical
by the
wires local in
area
network
(LAN).
Then,
theThe
robotic
arm
was
controlled
according region
to the
centered
above
the target
woodOnce
with the
a radius
of 1arm
cm.arrives
What is
more,
the
grasp
wasgripper
detected
and
continuous
motion
trajectory.
robotic
the
hover
area,
theforce
robotic
would
sent
to and
the master
PC also
byautomatically
wireless LAN in
as order
the feedback.
Finally,
the feedback
on area”
vibrotactile
reach
grasp the
target
to reduce
the brain
load. Thebased
“hover
was a
virtual cylindrical region centered above the target wood with a radius of 1 cm. What is more, the
grasp force was detected and sent to the master PC also by wireless LAN as the feedback. Finally, the

Electronics 2020, 9, 174

4 of 16

Electronics 2020, 9, x FOR PEER REVIEW

4 of 16

stimulus was given to the subjects when the robotic gripper grasped the target in order to improve the
feedback based on vibrotactile stimulus was given to the subjects when the robotic gripper grasped
telepresence and task performance.
the target in order to improve the telepresence and task performance.
Master
Multichannel
EEG acquisition

Cursor control

Continuous
motion trajectory
generation

CAR filter

Vibrotactile
biofeedback

Amplitude of
specific frequency
band calculation

Force processing

Continuous motion
command

Force feedback
Communication by wireless LAN

Slave

Robotic arm trajectory generator

Inverse
kinematics

Continuous robot
control

Grasp force
detection

Reach and grasp

Figure2.2.Control
Controlarchitecture
architectureofofBCI-driven
BCI-drivencontinuous
continuousteleoperation
teleoperationrobot
robotsystem.
system.
Figure

2.3.Human
HumanSubjects
Subjects
2.3.
Sixright-handed
right-handedhealthy
healthysubjects
subjectswere
werethe
theusers
usersofofthe
theBCI-based
BCI-basedteleoperation
teleoperationrobot
robotsystem.
system.
Six
Allparticipants
participants
no previous
experience
forimagery
motorbased
imagery
based BCI and
experiments
and
All
hadhad
no previous
experience
for motor
BCI experiments
teleoperation
teleoperationThey
experiments.
They were
recruited
from Southeast
Nanjing,
China.
experiments.
were all recruited
fromall
Southeast
University,
Nanjing,University,
China. Before
performing
Before performing
experiments,
informed
consent
was subject.
obtainedThis
fromstudy
each was
subject.
This study
was
experiments,
informed
consent was
obtained
from each
approved
by local
approved
by local Ethics Committee.
Ethics
Committee.
2.4.
2.4.Experimental
ExperimentalParadigm
Paradigm
Each
Eachsubject
subjectsat
satininaareclining
recliningchair
chairfacing
facingaascreen,
screen,while
whilescalp
scalpelectrodes
electrodesrecorded
recordedthe
theEEG.
EEG.
The
Therobotic
roboticarm
armwas
wasplaced
placedon
onanother
anothertable
tableabout
about88mmaway
awayfrom
fromthe
thesubjects.
subjects.This
Thiscan
canbe
beseen
seeninin
Figure
Figure3.3.The
Thesubject’s
subject’stask
taskwas
wastotoimagine
imaginemovement
movementofofthe
theleft
lefthand,
hand,right
righthand,
hand,both
bothhands,
hands,and
and
relaxation
relaxationofofboth
bothhands.
hands. The
The subject
subject was
was looking
looking at
atthe
thevirtual
virtualcursor
cursorduring
during the
themotor
motorimagery,
imagery,
and
andcould
couldnot
notsee
seethe
therobotic
roboticarm.
arm. By
Bythe
themotor
motorimagery,
imagery,the
thesubjects
subjectslearned
learnedtotomodulate
modulatetheir
their
sensorimotor
rhythm
amplitude
in
the
mu
rhythm
(8–12
Hz)
and
beta
(18–26
Hz)
frequency
bands.
sensorimotor rhythm amplitude in the mu rhythm (8–12 Hz) and beta (18–26 Hz) frequency bands.
Each
Eachsubject
subjectperformed
performedfive
fiveruns
runsand
andeach
eachrun
runincluded
included1212trials.
trials.

Electronics 2020, 9, 174
Electronics 2020, 9, x FOR PEER REVIEW

5 of 16
5 of 16

Figure
arm (b).
(b).
Figure 3.
3. A
A subject
subject with
with our
our BCI-driven
BCI-driven system
system (a)
(a) and
and the
the teleoperation
teleoperation robotic
robotic arm

Each trial started with a period of 2 s.
s. Next, the virtual target was displayed on the screen to
perform the
the corresponding
corresponding movement
movement imagination. After
indicate the subject to perform
After 2 s, the cursor was
moving on
on the
the screen
screenas
asthe
thevisual
visualfeedback.
feedback.Meanwhile,
Meanwhile,the
thecontinuous
continuous
motion
trajectory
was
sent
moving
motion
trajectory
was
sent
to
to
the
slave
PC
by
wireless
LAN
and
the
robotic
arm
moved
continuously
toward
the
target
in
real
the slave PC by wireless LAN and the robotic arm moved continuously toward the target in real time.
time. the
Once
the movement
imagination-controlled
the the
target,
the robotic
arm gripper
had
Once
movement
imagination-controlled
cursor cursor
hit the hit
target,
robotic
arm gripper
had arrived
arrived
the
hover
area
and
would
perform
grasping
automatically.
At
the
same
time,
the
fore
the hover area and would perform grasping automatically. At the same time, the fore information of
information
of robotic
gripper was
transmitted
from
slavePC,
PCand
to master
PC, and
the feedback
based
robotic
gripper
was transmitted
from
slave PC to
master
the feedback
based
on vibrotactile
on vibrotactile
stimulus
supplied
to to
theimprove
subject the
so as
to improveFinally,
the telepresence.
the
stimulus
was supplied
to was
the subject
so as
telepresence.
the robotic Finally,
arm moved
robotic
arm
moved
to
the
original
position
and
prepared
to
reach
and
grasp
for
the
next
trial.
to the original position and prepared to reach and grasp for the next trial.
2.5. EEG Recording and Processing
According
electrode
placement
[24],
electrodes
(Figure
4) of4)
C3,
According to
tothe
theinternational
internationalstandard
standard
electrode
placement
[24],
electrodes
(Figure
ofFC3,
C3,
CP3,
FC4,
C6 and
wereC6
fedwere
into afed
g.tec’s
system, namely
g.MOBIlab
FC3, C5,
CP3,C4,
C5,
C4,CP4,
FC4,and
CP4,
intoportable
a g.tec’sacquisition
portable acquisition
system,
namely
module.
Allmodule.
channels
referenced
to the left earlobe
andearlobe
the ground
electrode
AFz. EEG
g.MOBIlab
Allwere
channels
were referenced
to the left
and the
groundwas
electrode
was
signals
of
movement
imagination
were
acquired
from
the
amplifier
using
the
BCI2000
[25]
software
by
AFz. EEG signals of movement imagination were acquired from the amplifier using the BCI2000 [25]
Bluetooth.
sample rate
256 rate
Hz. The
electrodes of
was
kept below
10kept
KΩ.below
BCI2000
software byThe
Bluetooth.
The was
sample
was impedance
256 Hz. Theofimpedance
electrodes
was
10
is
in charge
ofiscontrolling
thecontrolling
virtual cursor
and displaying
thedisplaying
virtual targets.
KΩ.
BCI2000
in charge of
the virtual
cursor and
the virtual targets.

Figure 4.
4. The
The EEG
EEG electrodes
electrodes positions
positions adopted
adopted in
in our
our study.
study.
Figure

In
In EEG-based
EEG-based BCI
BCI systems,
systems, the
the use
use of
of spatial
spatial filters
filters can
can significantly
significantly improve
improve the
the user’s
user’s
performance [20]. A CAR filter was used to preprocess the eight-channel motor imagery EEG signals.
performance [20]. A CAR filter was used to preprocess the eight-channel motor imagery EEG
Then, an autoregressive (AR) model was adopted to estimate the amplitude of the sensorimotor rhythm
signals. Then, an autoregressive (AR) model was adopted to estimate the amplitude of the
in a specific frequency band of the subject. The AR model is given by:
sensorimotor rhythm in a specific frequency band of the subject. The AR model is given by:
Xi = p
i= p
xxt t==
wi xxt−i +
(1)
w
+ εε,,
(1)
ii=
=11 i t −i



i =1

Electronics 2020, 9, 174

6 of 16

where xt was the estimated signal at time t, wi was the weight coefficient, and ε is the error of estimation.
Every 50 ms, the 16th order AR model with the last 500 ms EEG data was applied to obtain the online
amplitude of mu or beta rhythmic activity. Coefficients of the AR model were calculated based on the
least-squares criteria.
The vertical movement of the cursor (DV ) was obtained by:
DV = wRV RV + wLV LV + bV

(2)

where RV and LV were the right-side amplitude and left-side amplitude, respectively, wRV and wLV
were the coefficients, bV was the offset. The initial values of wRV , wLV , and bV were +1.0, +1.0, and
0.0, respectively.
The horizontal movement of the cursor (DH ) was given by:
DH = wRH RH + wLH LH + bH

(3)

where RH and LH were the right-side amplitude and left-side amplitude, respectively, wRH and wLH
were the coefficients, bH was the offset. The initial values of wRH , wLH , and bH were +1.0, −1.0, and
0.0, respectively.
According to Equations (2) and (3), when subjects imagine the movement of both hands, the
right-side amplitude (RV ) and the left-side amplitude (LV ) will decrease. Therefore, DV becomes
negative and the cursor is controlled to move upwards. Conversely, when subjects imagine the
relaxation of both hands, the right-side amplitude (RV ) and the left-side amplitude (LV ) will increase.
As a result, DV becomes positive and the cursor is controlled to move downwards. Similarly, when
subjects imagine the right hand movement or left hand movement, the right-side amplitude (RH )
will decrease or increase and the left-side amplitude (LH ) will increase or decrease. Consequently,
DH becomes negative or positive and the cursor is controlled to move right or left. After the first
trial, the least-mean-square (LMS) algorithm adaptively adjusts weights and offsets according to past
experiments. This adaptation optimizes the online translation of EEG control into the cursor control
for the next trial [26].
As a result, the sensorimotor rhythm amplitude of specific frequency bands over the left and
right sensorimotor cortex was linearly mapped to the control virtual cursor in one or two dimensions.
Simultaneously, the control signals were sent to the robot control software through the TCP/IP protocol
with 5 Hz to continuously control the remote robotic arm in two dimensions.
2.6. Grasp Force Detection and Biofeedback System
Figure 5 shows the grasp force detection system. Firstly, the differential signals from the micro
force sensor FSS1500 supplied by Honeywell were amplified and filtered. Then, the microcontroller
with internal analog to digital convert transformed the analog force signals into digital signals. Finally,
the digital signals were calibrated and sent to slave PC via wireless interface. The sample rate of
this force detection system is 100 Hz and the measure range is 0–2000 g. Figure 6 demonstrates the
calibration data of two micro force sensors. It can be seen that these sensors have good linearity and
can be met with requirements of the fore measurement between the robotic gripper and the target.
There are many ways to realize the tactile feedback, such as vibration stimulation [27], electrical
stimulation [28], and thermal stimulation. Vibration stimulation was chosen as the motor imagery
EEG-based teleoperation robot system’s biofeedback due to its characteristics of fast response,
convenient wearing, small size, low power, etc. Moreover, vibrotactile stimulation has been widely
used in other research fields, such as rehabilitation training and prosthesis control [29].

Electronics 2020, 9, x FOR PEER REVIEW

7 of 16

Micro force senor
FSS1500

Electronics 2020, 9, 174

Wireless

7 of 16

Electronics 2020,
2020, 9,
9, x
x FOR
FOR PEER
PEER REVIEW
REVIEW
Electronics

7 of
of 16
16
7

Amplify and filter

Microcontroller

Micro
Micro force
force senor
senor
FSS1500
FSS1500

Wireless
Wireless
Battery power

Figure
5.and
Robotic
system.
Amplify
and
filter grasp force detection
Microcontroller
Amplify
filter
Microcontroller
Force Sensor Calibration

1000
900
800

y=0.4363*x-18.3863
R2=0.9971

900
Battery power
power
Battery
800
700

OutVoltage/mv

500

Force
Force Sensor
Sensor Calibration
Calibration

400
1000
1000

y=0.4363*x-18.3863
y=0.4363*x-18.3863
=0.9971
R22=0.9971
R

300
900
900
200
800
800

(a)

OutVoltage/mv
OutVoltage/mv

100
700
700

200

400

600

800

1000

Force/g

400
400
300
300

y=0.4277*x-11.3308
R2=0.9993

600
Figure
Robotic
grasp
force
detection
system.
Figure5.5.
5.Robotic
Roboticgrasp
graspforce
force
detectionsystem.
system.
Figure
detection

600

1200

1400

1600

1800

2000

OutVoltage/mv
OutVoltage/mv

OutVoltage/mv

700

0
600
600
0
500
500

Force Sensor Calibration

1000

500

Force Sensor
Sensor Calibration
Calibration
Force

400
1000
1000
300
900
900
200
800
800
100
700
700
0
600
600
0
500
500

y=0.4277*x-11.3308
y=0.4277*x-11.3308
R22=0.9993
=0.9993
R
(b)
200

400

600

800

1000

1200

1400

1600

1800

2000

Force/g

400
400

Figure 6. Calibration of left (a) and right (b)
300force sensors of the robot gripper.
300
200
200

200
200

100
100
There 100
are many ways to realize the tactile
such as vibration stimulation(b)
100
(b)[27], electrical
(a) feedback,
(a)
0
0
stimulation 00[28], and thermal stimulation. Vibration stimulation
was chosen as the motor imagery
0
200
400
600
800
2000
0
200
400
600
800
0
200
400
600
800 1000
1000 1200
1200 1400
1400 1600
1600 1800
0
200
400
600
800 1000
1000 1200
1200 1400
1400 1600
1600 1800
1800 2000
2000
EEG-based teleoperation
robot
system’s
biofeedback
due
to
its
characteristics
of 1800
fast2000response,
Force/g
Force/g
Force/g
Force/g
convenient wearing, small size, low power, etc. Moreover, vibrotactile stimulation has been widely
Figure6.
6. Calibration
Calibration of
of left
left (a)
(a) and
and right
right (b)
(b) force
forcesensors
sensorsof
ofthe
therobot
robotgripper.
gripper.
Figure
6.
Calibration
of
left
(a)
and
right
(b)
force
sensors
of
the
robot
gripper.
Figure
used in other research
fields, such as
rehabilitation
training
and prosthesis
control [29].
The
vibrotactile
feedback
system
consistsfeedback,
of vibrating
motors,
motor
driving[27],
modules,
a
There
are
to
the
such
vibration
stimulation
electrical
The
vibrotactile
feedback
system
consists
of vibrating
driving
There
are many
many ways
ways
to realize
realize
the tactile
tactile
feedback,
such as
as motors,
vibration motor
stimulation
[27],modules,
electrical
microcontroller,
and
a
wireless
module
used
for
communication
with
master
PC.
The
vibrating
[28],
stimulation.
Vibration
stimulation
chosen
as
imagery
astimulation
microcontroller,
andthermal
a wireless
module used
for communication
with
master
PC. motor
The vibrating
stimulation
[28], and
and
thermal
stimulation.
Vibration
stimulation was
was
chosen
as the
the
motor
imagery
motors
were
attached
to
the
cuff,
which
was
wrapped
around
the
user’s
upper
arm
during
the
EEG-based
teleoperation
robot
system’s
biofeedback
due the
to its
its
characteristics
of fast
fast the
response,
motors
were teleoperation
attached to therobot
cuff, which
wasbiofeedback
wrapped around
user’s
upper arm during
online
EEG-based
system’s
due
to
characteristics
of
response,
online
experiment.
Figure
7
illustrates
the
locations
of
the
vibrating
motors.
These
locations
were
convenient
small
low
power,
etc.
vibrotactile
stimulation
has
widely
experiment.
Figure 7 illustrates
locations
theMoreover,
vibrating motors.
These
locations were
selected
on
convenient wearing,
wearing,
small size,
size,the
low
power,of
etc.
Moreover,
vibrotactile
stimulation
has been
been
widely
selected
on the
basis of
our such
previous
prosthetic tactile
feedback
and teleoperation
robot study
used
in
other
research
fields,
as
rehabilitation
training
and
prosthesis
control
[29].
the
basis
of ourresearch
previousfields,
prosthetic
feedback and
teleoperation
robot study
[29,30].
used
in other
suchtactile
as rehabilitation
training
and prosthesis
control
[29].The vibrating
[29,30].
Thevibrotactile
vibrating stimulation
waveform
was a of
series
of discrete
pulses
with adriving
duty cycle
of 50%a
The
feedback
system
consists
vibrating
motors,
motor
modules,
stimulation
waveform feedback
was a series
of discrete
pulses
with a duty
cycle ofmotor
50% and
the frequency
ofa
The
vibrotactile
system
consists
of vibrating
motors,
driving
modules,
and
the
frequency
of
each
pulse
was
250
Hz.
Once
the
robotic
arm
grasped
the
target,
the
grasp
microcontroller,
and
a
wireless
module
used
for
communication
with
master
PC.
The
vibrating
each
pulse was 250and
Hz.aOnce
the robotic
arm
grasped
the target, the grasp
microcontroller,
wireless
module
used
for communication
with information
master PC. was
Themeasured
vibrating
information
was
measured
by the
force
detection
system and
sent to
master
PC via
wireless
net.
motors
were
attached
to the
the
cuff,
which
was wrapped
wrapped
around
thethe
user’s
upper
arm
during
the
by
the force
detection
system
and
sentwhich
to the master
PC via wireless
net.
At
the same
time,
theduring
vibration
motors
were
attached
to
cuff,
was
around
the
user’s
upper
arm
the
At
the
same
time,
the
vibration
stimulation
based
feedback
was
provided
to
the
subject.
Finally,
the
online
experiment.
Figure
7
illustrates
the
locations
of
the
vibrating
motors.
These
locations
were
stimulation
based
feedback
was
provided
to
the
subject.
Finally,
the
robotic
arm
released
the
target
and
online experiment. Figure 7 illustrates the locations of the vibrating motors. These locations were
robotic
arm
released
theoftarget
and returned
to the center.
Meanwhile,and
the vibration stimulation
was
selected
on
the
basis
prosthetic
tactile
robot
study
returned
the vibration
stimulation
was stopped.
The vibrotactile
feedback
selected to
onthe
thecenter.
basis Meanwhile,
of our
our previous
previous
prosthetic
tactile feedback
feedback
and teleoperation
teleoperation
robot
study
stopped.
Thevibrating
vibrotactile
feedbackwaveform
system can
to improve
thewith
telepresence
andoftask
[29,30].can
The
stimulation
wasbeaa expected
series
of discrete
discrete
pulses
duty cycle
cycle
50%
system
bevibrating
expectedstimulation
to improvewaveform
the telepresence
and task
performance
ofwith
the operator.
[29,30].
The
was
series
of
pulses
aa duty
of 50%
performance
of
the
operator.
and
the
frequency
of
each
pulse
was
250
Hz.
Once
the
robotic
arm
grasped
the
target,
the
grasp
and the frequency of each pulse was 250 Hz. Once the robotic arm grasped the target, the grasp
information
information was
was measured
measured by
by the
the force
force detection
detection system
system and
and sent
sent to
to the
the master
master PC
PC via
via wireless
wireless net.
net.
（a）
At the
the same
same time,
time, the
the vibration
vibration stimulation
stimulation based
based feedback
feedback(b)was
was provided
provided to
to the
the subject.
subject. Finally,
Finally, the
the
At
robotic
arm
released
the
target
and
returned
to
the
center.
Meanwhile,
the
vibration
stimulation
was
robotic arm released the target and returned to the center. Meanwhile, the vibration stimulation was
stopped. The
The vibrotactile
vibrotactile feedback
feedback system
system can
can be
be expected
expected to
to improve
improve the
the telepresence
telepresence and
and task
task
stopped.
performance
of
the
operator.
1
performance of the operator.

2

（a）
（a）

(b)
(b)

Figure
Figure 7.
7. Vibrating
Vibrating motor
motor (a)
(a) and
and vibration
vibration stimulation
stimulation location
location (b).
(b).
1
1
2
2

Figure 7.
7. Vibrating
Vibrating motor
motor (a)
(a) and
and vibration
vibration stimulation
stimulation location
location (b).
(b).
Figure

Electronics 2020, 9, x FOR PEER REVIEW
Electronics 2020, 9, 174

8 of 16
8 of 16

2.7. Task Design

Electronics
2020,
x FOR PEERthe
REVIEW
8 of 16
In order
to9,improve
task performance for the motor imagery EEG-based teleoperation,
a
2.7.
Task
Design
series of experiments with progressively increasing task difficulty were designed. The success rate
2.7. Task Design
defined
as the
of thethe
correct
hit versus
adoptedEEG-based
to evaluateteleoperation,
the performance
In order
toratio
improve
task target
performance
for all
thetargets
motorisimagery
a
In
order
to
improve
the
task
performance
for
the
motor
imagery
EEG-based
teleoperation,
a rate
of theofparticipants.
series
experiments with progressively increasing task difficulty were designed. The success
series
of experiments
with
increasing
task difficulty
were designed.
success rate
Asasshown
in Figure
8, inprogressively
the
first hit
stage,
experiments
performed
with The
one-dimensional
defined
the ratio
of the correct
target
versus
all targetswere
is adopted
to evaluate
the performance left
of
defined as the ratio of the correct target hit versus all targets is adopted to evaluate the performance
vs.participants.
right virtual cursor movement control by imagining the movement of left hand or right hand for
the
of the participants.
several
sessions
until the
task
success
rateexperiments
reached 80%. In the
second with
stage,one-dimensional
subjects were asked
to
As shown
in Figure
8, in
firstfirst
stage,
left vs.
As shown
in Figure
8,the
in the
stage, experimentswere
wereperformed
performed with
one-dimensional left
control
the
virtual
cursor
move
in
another
one-dimensional
up
vs.
down
by
imagining
the
right vs.
virtual
controlcontrol
by imagining
the movement
of left
or right
hand
forfor
several
rightcursor
virtualmovement
cursor movement
by imagining
the movement
of hand
left hand
or right
hand
movement
ofthe
both
hands
relaxing
until
theIntask
performance
exceeded
80%.
In the
third
sessions
untilsessions
task
success
rate
reached
80%.
the
second
subjects
were
asked
to
control
the
several
until
theor
task
success
rate
reached
80%.
In thestage,
second
stage, subjects
were
asked
to stage,
two-dimensional
virtual
cursor
control
tasks, one-dimensional
namely
Task by
1up
and
were
used tothe
control
virtual
cursor
move
in another
vs.Task
down2,the
by
imagining
virtual
cursorthe
move
in another
one-dimensional
up vs. down
imagining
movement
offurther
both
enhance
the ability
of
modulating
mutask
andperformance
betaInrhythm.
the
three
stages,
movement
of until
both the
hands
orperformance
relaxing their
untilexceeded
the
80%.
In above
the third
stage,
hands
or relaxing
task
80%.
the exceeded
thirdAfter
stage,
two-dimensional
virtual
two-dimensional
virtual
cursor
control
tasks,
namely
Task
1
and
Task
2,
were
used
to
further
participants
EEGTask
of imagining
handused
movement,
handthe
movement,
both hands
cursor
control used
tasks,the
namely
1 and Taskleft
2, were
to furtherright
enhance
ability of modulating
enhance and
the both
abilityhands
of modulating
their
mu and
beta
rhythm.
After
the
above three
stages,
movement,
relaxation
to
control
the
remote
robot
arm
continuously
and
the tactile
their mu and beta rhythm. After the above three stages, participants used the EEG of imagining
left
participants
used the EEG of imagining left hand movement, right hand movement, both hands
feedback
was
offered.
hand movement, right hand movement, both hands movement, and both hands relaxation to control

movement, and both hands relaxation to control the remote robot arm continuously and the tactile

the remote
robot arm continuously and the tactile feedback was offered.
feedback was offered.

Figure 8. Cursor control tasks at different stages.
Figure
Cursorcontrol
control tasks
tasks at
Figure
8. 8.Cursor
atdifferent
differentstages.
stages.

3. Experiment
Results
3. Experiment
Results
3. Experiment
Results
3.1.Task
Task
Success
Rate
Cursor
Control
Training
3.1. Success
Task
Success
Rate
of
Cursor
Control
Training
3.1.
Rate
ofofCursor
Control
Training
Figure
9a,b
show
thetraining
trainingtask
task success
success rate
ofofcursor
control
in one-dimensional
left vs.
right
Figure
9a,b
show
the
rateof
cursor
control
one-dimensional
left
vs.right
right
Figure
9a,b
show
the
training
task
success
rate
cursor
control
ininone-dimensional
left
vs.
and
another
dimension
up
vs.
down,
respectively.
The
average
training
duration
of
one-dimensional
andanother
anotherdimension
dimensionup
upvs.
vs.down,
down,respectively.
respectively.The
Theaverage
averagetraining
trainingduration
durationofofone-dimensional
one-dimensional
and
for subjects
all subjects
was
4.6h hand
anditit was
was finished
finished in
several
days.
Obviously,
the the
subjects’
ability to
for
all
was
4.6
in
several
days.
Obviously,
subjects’
for allcontrol
subjects
was 4.6 h and it was finished in several days. Obviously, the subjects’ ability toability
controlto
the one-dimensional virtual cursor improved significantly after training and the task
control
the
one-dimensional
virtual
cursor
improved
significantly
after
training
and
the
task
the one-dimensional
improved
significantly
training
andsuccess
the task
performance
performance of allvirtual
subjectscursor
exceeded
80%. Moreover,
subject after
4 achieved
the task
rate
of 93%,
of all subjects
80%.
Moreover,
subject
4 achieved
the rate
task of
success
rate of was
93%,
ofperformance
all which
subjects
80%.exceeded
Moreover,
subject
achieved
the
task success
93%, which
wasexceeded
greatly increased
compared with
the 4start
of the training.
which
was
greatly
increased
compared
with
the
start
of
the
training.
greatly increased compared with the start of the training.

Figure 9. Task success rate of one-dimensional cursor control training. (a) Left vs. right. (b) Up vs.
down.

Figure9.9. Task
Tasksuccess
successrate
rateof
of one-dimensional
one-dimensional cursor
cursor control training. (a)
UpUp
vs.
Figure
(a)Left
Leftvs.
vs.right.
right.(b)(b)
down.
vs.
down.

Electronics
Electronics2020,
2020,9,9,174
x FOR PEER REVIEW

9 9ofof1616

Figure 10a,b demonstrate the success rate of two different cursor control tasks in two
Figure 10a,b demonstrate the success rate of two different cursor control tasks in two dimensional
dimensional spaces. The average training duration of the two-dimensional control for all subjects
spaces. The average training duration of the two-dimensional control for all subjects was 3.8 h within
was 3.8 h within several days. Similarly, the task performance after training is obviously better than
several days. Similarly, the task performance after training is obviously better than before. However,
before. However, the overall success rate of the two-dimensional control is lower than that of
the overall success rate of the two-dimensional control is lower than that of one-dimensional control
one-dimensional control due to the increasing difficulty. Additionally, the performance of Task 2
due to the increasing difficulty. Additionally, the performance of Task 2 dropped a lot and the success
dropped a lot and the success rate of all subjects was less than 80%. Subject 4 still got the best task
rate of all subjects was less than 80%. Subject 4 still got the best task performance with the success rate
performance with the success rate of 77%.
of 77%.

Figure10.
10.Task
Tasksuccess
successrate
rateofoftwo-dimensional
two-dimensionalcursor
cursorcontrol
controltraining.
training.(a)
(a)Task
Task1.1.(b)
(b)Task
Task2.2.
Figure

After
Afterthe
thetraining,
training,subjects
subjectsutilized
utilizedthe
themotor
motorimagery
imageryEEG
EEGtotocontinuously
continuouslycontrol
controlthe
theremote
remote
robot
arm.
Figures
11
and
12
are
the
topographies
of
power
in
8–13
Hz
frequency
band
of
two
subjects
robot arm. Figures 11 and 12 are the topographies of power in 8–13 Hz frequency band of two
controlling
the robotic the
armrobotic
to perform
and grasp
task. and
In these
figures,
represents
energy
subjects controlling
armthe
toreach
perform
the reach
grasp
task. blue
In these
figures,
blue
decrease
andenergy
red indicates
energy
increase.
represents
decrease
and red
indicates energy increase.
3.2.
3.2.The
TheERD/ERS
ERD/ERSPhenomenon
Phenomenon
From
From Figures
Figures 11
11and
and12,
12,we
wecan
canobserve
observethe
theevent-related
event-relateddesynchronization
desynchronization (ERD)
(ERD) and
and
event-related
synchronization
(ERS)
phenomenon
of
subject
1
and
subject
2
for
the
online
experiments.
event-related synchronization (ERS) phenomenon of subject 1 and subject 2 for the online
When
the subjects
imagined
unilateral
handunilateral
movement
(Figure
11a,b and
Figure
12a,b),
power
experiments.
When
the subjects
imagined
hand
movement
(Figures
11a,b
andthe
12a,b),
the
inpower
the specific
band
of
the
contralateral
brain
decreased
compared
with
the
motor
imagery
in the specific band of the contralateral brain decreased compared with the motor imageryofof
relaxation
relaxation(Figures
(Figures11d
11dand
and12d)
12d)and
andthe
thepower
powerin
inthe
thespecific
specificband
bandof
ofthe
theipsilateral
ipsilateralbrain
brainincreased.
increased.
Moreover,
the
decrease
of
the
power
in
the
specific
band
of
the
bilateral
brain
was
apparent
Moreover, the decrease of the power in the specific band of the bilateral brain was apparentwhen
when
the
thesubjects
subjectsperformed
performedmovement
movementimagination
imaginationofofboth
bothhands
hands(Figures
(Figures11c
11cand
and12c).
12c).Based
Basedon
onthe
the
above
two-dimensional
continuous
control
information
was was
extracted
fromfrom
mu
abovedifferent
differentphenomena,
phenomena,
two-dimensional
continuous
control
information
extracted
or
beta
frequency
bandsbands
usingusing
Equations
(2) and
and
teleoperation
robot robot
was
mu
or rhythm
beta rhythm
frequency
Equations
(2)(3)
and
(3)the
andremote
the remote
teleoperation
controlled
continuously.
was controlled continuously.
InInaddition,
addition, from
fromthe
thetopographies
topographies inindifferent
differentfrequency
frequencybands,
bands, we
wecan
cansee
seethat
thatthe
themost
most
obvious
difference
between
four
different
imagery
tasks
exists
near
12
Hz
for
these
two
subjects.
obvious difference between four different imagery tasks exists near 12 Hz for these two subjects. The
The
determination
of optimal
frequency
everysubject
subjectisiscritical
critical for
for the
the motor
determination
of optimal
frequency
forforevery
motor imagery
imageryEEG-based
EEG-based
teleoperation
control
system.
The
offline
analysis
tool
from
the
BCI2000
platform
can
be
teleoperation control system. The offline analysis tool from the BCI2000 platform can beused
usedtoto
identify
the
specific
electrodes
and
frequencies
that
were
most
differential
during
the
execution
identify the specific electrodes and frequencies that were most differential during the executionofof
movement
movementimagination
imaginationtasks.
tasks.

Electronics 2020, 9, 174
Electronics 2020,
2020, 9,
9, xx FOR
FOR PEER
PEER REVIEW
REVIEW
Electronics

10 of 16
10
of 16
16
10 of

Figure 11.
11. Topographies
Topographies
of power
power in
in 8–13
8–13 Hz
Hz frequency
frequency band
Topographies of
band during
during motor
motor imagery
imagery of
of subject
subject 1.
1.
Figure

Figure 12. Topographies of power in 8–13 Hz frequency band during motor imagery of subject 2.
Figure 12.
12. Topographies
Topographies of
of power
power in
in 8–13
8–13 Hz
Hz frequency
frequency band
band during
during motor
motor imagery
imagery of
of subject
subject 2.
2.
Figure

3.3. Trajectory of Robotic Arm
3.3. Trajectory
Trajectory of
of Robotic
Robotic Arm
Arm
3.3.
Figure 13 demonstrates the target distribution, coordinate system, and an example trajectory of
Figure
13
demonstrates
the target
targetplane.
distribution,
coordinate
system,
andinan
an
example trajectory
trajectory
of
Figure
demonstrates
the
distribution,
coordinate
system,
and
of
robotic
arm 13
within
a two-dimensional
There are
four targets
located
a example
restricted
square area.
robotic
arm
within
a
two-dimensional
plane.
There
are
four
targets
located
in
a
restricted
square
robotic
arm within
two-dimensional
targets
in aarea.
restricted
square
At the beginning
of athe
experiment, theplane.
roboticThere
arm isare
in four
the center
oflocated
the square
The distance
area. At
At the
the
beginning
of the
theDexperiment,
experiment,
the robotic
roboticBarm
arm
is in
in the
the
center
of
the square
square
area. The
The
area.
beginning
of
the
is
center
the
area.
between
target
B and target
is on the X axis
where
is positive
and
D is of
negative.
Similarly,
the
distance
between
target
B
and
target
D
is
on
the
X
axis
where
B
is
positive
and
D
is
negative.
distance
betweentarget
targetABand
and
target
onYthe
axis where
B is positive
and D is The
negative.
distance between
target
C isDonisthe
axisXwhere
A is positive
and C is negative.
initial
Similarly,ofthe
the
distance
between
target
A and
and
target C
C is
is on
on the
the Y
Y axis
axis where
where A
A is
is positive
positive and
and C
C is
is
Similarly,
between
target
A
target
position
thedistance
robotic arm
is at the
origin
point.
negative.
The
initial
position
of
the
robotic
arm
is
at
the
origin
point.
negative. The initial position of the robotic arm is at the origin point.

Electronics 2020, 9, 174

11 of 16

Electronics 2020, 9, x FOR PEER REVIEW

11 of 16

A
y

D

0

x

B

C

Figure
trajectory of
of the
the robotic
robotic arm.
arm.
Figure 13.
13. Target
Target distribution,
distribution, coordinate
coordinate system,
system, and
and an
an example
example trajectory

Figures
15 demonstrate
demonstrate the
Figures 14
14 and
and 15
the normalized
normalized trajectories
trajectories of
of the
the robotic
robotic arm
arm within
within aa
two-dimensional
plane
above
the
target
objects.
The
remote
continuous
movement
of
the
robotic
two-dimensional plane above the target objects. The remote continuous movement of the robotic
arm
arm driven
was driven
directly
by motor
imagery
signals
acquired
subject
was
directly
by motor
imagery
EEG EEG
signals
acquired
from from
local local
subject
1 and12.and 2.
The
a region
above
target
A are
shown
in Figures
14a
The trajectories
trajectoriesof
ofrobotic
roboticarm
armmoving
movingtoward
toward
a region
above
target
A are
shown
in Figures
and
15a.
The
subjects
performed
the
movement
imagination
of
both
hands
to
modulate
their
14a and 15a. The subjects performed the movement imagination of both hands to modulate their
sensorimotor
rhythm amplitudes
amplitudeswhich
whichwere
wereutilized
utilizedtotogenerate
generate
continuous
trajectories
based
sensorimotor rhythm
thethe
continuous
trajectories
based
on
on
Equations
(2)
and
(3).
When
the
subjects
imagined
the
movement
of
the
left
hand
more
intensely
Equations (2) and (3). When the subjects imagined the movement of the left hand more intensely than
than
the robotic
arm deviated
the On
Y axis.
On the contrary,
the
robotic
arm
right right
hand,hand,
the robotic
arm deviated
to righttoofright
the Yof
axis.
the contrary,
the robotic
arm
moved
to
moved
to
the
left
of
the
Y
axis,
if
movement
imagination
of
the
right
hand
was
performed
more
the left of the Y axis, if movement imagination of the right hand was performed more intensely than
intensely
left hand. than left hand.
Next,
Next, Figures
Figures 14b
14b and
and 15b
15b demonstrate
demonstrate the
the normalized
normalized trajectories
trajectories when
when subjects
subjects imagined
imagined the
the
movement
of
their
right
hand
to
guide
the
robotic
arm
to
the
hover
region
above
target
B.
If
the
movement of their right hand to guide the robotic arm to the hover region above target B. If the robotic
robotic
arm deviated
X axis,
the carried
subjectsout
carried
out the movement
imagination
of both
arm deviated
to belowtoXbelow
axis, the
subjects
the movement
imagination
of both hands
to
hands
to move
thearm
robotic
arm forward.
Conversely,
thearm
robotic
arm deviated
X
move the
robotic
forward.
Conversely,
when thewhen
robotic
deviated
to above to
of above
X axis,ofthe
axis,
the
subjects
imagined
the
relaxation
of
both
hands
to
move
the
robotic
arm
backward.
subjects imagined the relaxation of both hands to move the robotic arm backward.
Furthermore,
whensubjects
subjects
imagined
relaxation
of both
theirhands,
both hands,
thearm
robotic
arm was
Furthermore, when
imagined
relaxation
of their
the robotic
was controlled
controlled
to
move
toward
target
C.
In
this
case,
the
trajectories
of
the
robotic
arm
are
illustrated
in
to move toward target C. In this case, the trajectories of the robotic arm are illustrated in Figures 14c
Figures
14c
and
15c.
If
the
robotic
arm
moved
to
the
right
of
Y
axis,
the
subjects
imagined
the
and 15c. If the robotic arm moved to the right of Y axis, the subjects imagined the movements of left
movements
of the
leftrobotic
hand toarm
drive
the left.
robotic
to the left.the
Onsubjects
the contrary,
the the
subjects
imagined
hand to drive
to the
Onarm
the contrary,
imagined
movements
of
the
movements
of
right
hand
to
move
the
robotic
arm
to
the
right,
if
the
robotic
arm
deviated
to
left
right hand to move the robotic arm to the right, if the robotic arm deviated to left of the Y axis.
of theMoreover,
Y axis. the trajectories of the robotic arm moving toward target D are demonstrated in Figures
Moreover,
the trajectories
of theofrobotic
towardtotarget
D the
arerobotic
demonstrated
in
14d and
15d. Movement
imagination
the leftarm
handmoving
was executed
control
arm. If the
Figures
14d
and
15d.
Movement
imagination
of
the
left
hand
was
executed
to
control
the
robotic
robotic arm deviated to below of the X axis, the subjects imagined the movements of both hands to move
arm.
If the robotic
arm deviated
to below
the X axis,
the subjects
imagined
the
of both
the robotic
arm forward.
Conversely,
if theofrobotic
arm deviated
to above
of the
X movements
axis, imagination
of
hands
to
move
the
robotic
arm
forward.
Conversely,
if
the
robotic
arm
deviated
to
above
of
the
X
the relaxation of both hands was performed to control the robotic arm to move backward.
axis, Then,
imagination
of
the
relaxation
of
both
hands
was
performed
to
control
the
robotic
arm
to
move
if the robotic arm reached the hover region above target A, the robotic arm descended
backward.
automatically to grasp the object. As was illustrated in Figure 5, the tactile information between the
Then,
if theand
robotic
arm reached
the hover
above
target
A, the system,
robotic arm
descended
robotic
gripper
the target
was conducted
byregion
the grasp
force
detection
which
adopted
automatically
to
grasp
the
object.
As
was
illustrated
in
Figure
5,
the
tactile
information
between
the
micro force sensors of FSS1500 from Honeywell. Finally, the biofeedback based on vibrotactile stimulus
robotic
grippertoand
the target was
conducted
the grasp force
detection
system, which adopted
was
provided
the participants
to improve
theby
telepresence
and task
performance.
microAdditionally,
force sensors
of
FSS1500
from
Honeywell.
Finally,
the
biofeedback
based
on vibrotactile
the maximum trajectories error of target A, B, C, and D is 6.20%,
6.53%,
8.27%, and
stimulus
provided
to the participants
to improve
and task performance.
7.46% for was
subject
1, respectively.
Similarly, for
subject 2,the
the telepresence
maximum trajectories
error is 8.53%, 8.20%,
Additionally,
8.52%,
and 8.26%. the maximum trajectories error of target A, B, C, and D is 6.20%, 6.53%, 8.27%,
and 7.46% for subject 1, respectively. Similarly, for subject 2, the maximum trajectories error is 8.53%,
8.20%, 8.52%, and 8.26%.

Electronics 2020, 9, 174
Electronics 2020, 9, x FOR PEER REVIEW
Electronics 2020, 9, x FOR PEER REVIEW

12 of 16
12 of 16
12 of 16
1

1

Y

1

1

Y

0.5

0.5
0.5

0.5

0.5

-0.5

-1

X

0.5

-0.5

-1

X

1

1

0.

-0.5

-1

-0.5

X

1

1

-0.5
-0.5

-1

-1
-1

-1
1

1

Y

1

1

Y

Y
Y

0.5

0.5
0.5

0.5

-0.5

-1

X

0.

-0.5

-1

-0.5

0.5

-0.5

-1

Y
Y

0.5

X

X
1

1
-1

0.5

-0.5

-1

0.5

-0.5

X

X
1

1

-0.5

-0 5

-0.5

-0 5

1

-1

1

-1

Figure
14.14.
Normalized
continuous
trajectories
robotic
arm
moving
towards
target
A (a), (b),
target B
Figure
Normalized
continuoustrajectories
trajectories
ofofof
robotic
arm
moving
towards
targettarget
A
(a), target
Figure
14. Normalized
continuous
robotic
arm
moving
towards
A (a),Btarget
B
(b),target
target
C (c),
target
(d) controlled
by movement
imagination
EEG
signals
from
C (c),
andand
target
D (d)Dcontrolled
by movement
imagination
EEG signals
from
subject
1. subject 1.
(b), target C (c), and target D (d) controlled by movement imagination EEG signals from subject 1.
1

1

Y

1

1

Y

0.5

0.5

0.5

0.5

-1

-0.5

0.5

-0.5

-1

0.5

X
X

1

1

-1

0.5

-0.5
0.5

-0.5

-1

-1
-1

1

1

Y

Y
Y

0.5

0.5
0.5

0.5

-0.5
0.5

-0.5

-0.5

1

X -1

1

X

-1

-0.5

0.5

-0.5

0.5

X

X
1

1

-0.5
-0.5

-0.5

-1

-1
-1

1

1

Y

0.5

-1

1

1

-0.5

-1

-1

X
X

-0.5

-0.5
-0.5

-1

Y
Y

-1

.

.

Figure
trajectories
of robotic
armarm
moving
towards
target
A (a),
B (b),B
Figure15.
15.Normalized
Normalizedcontinuous
continuous
trajectories
of robotic
moving
towards
target
Atarget
(a), target
Figure
15.
Normalized
continuous
trajectories
of robotic
arm moving
towards
target
A (a),2.target B
target
C
(c),
and
target
D
(d)
controlled
by
movement
imagination
EEG
signals
from
subject
(b), target C (c), and target D (d) controlled by movement imagination EEG signals from subject 2.
(b), target C (c), and target D (d) controlled by movement imagination EEG signals from subject 2.

3.4. Online Control Task
3.4. Online Control Task
3.4. Online
Task the success rate of the reach and grasp task, in which the subjects used motor
FigureControl
16 presents
Figure 16 presents the success rate of the reach and grasp task, in which the subjects used motor
imagery
EEG
control
therate
remote
arm.grasp
Similar
cursor
the
Figure
16 signals
presentstothe
success
of therobotic
reach and
task,tointhe
which
the control
subjectstraining,
used motor
imagery EEG signals to control the remote robotic arm. Similar to the cursor control training, the
control
performance
of
movement
imagination
EEG
for
Task
1
is
better
than
Task
2.
After
a
series
of
imagery EEG signals to control the remote robotic arm. Similar to the cursor control training, the
control performance of movement imagination EEG for Task 1 is better than Task 2. After a series of
control performance of movement imagination EEG for Task 1 is better than Task 2. After a series of
cursor control training, the success rate of the reach and grasp task is greatly increased. The average
cursor control training, the success rate of the reach and grasp task is greatly increased. The average

Electronics 2020, 9, 174

13 of 16

Electronics 2020, 9, x FOR PEER REVIEW

13 of 16

cursor control training, the success rate of the reach and grasp task is greatly increased. The average
two-dimensional continuous control success rates for online Task 1 and Task 2 of the six subjects are
two-dimensional continuous control success rates for online Task 1 and Task 2 of the six subjects are
78.0% ± 6.1% and 66.2% ± 6.0%, respectively. It indicates that the ability of subjects to modulate their
78.0% ± 6.1% and 66.2% ± 6.0%, respectively. It indicates that the ability of subjects to modulate their
sensorimotor rhythm amplitude in the mu or beta frequency band over the left and right
sensorimotor rhythm amplitude in the mu or beta frequency band over the left and right sensorimotor
sensorimotor cortex has greatly improved. Thus, the two-dimensional continuous control ability for
cortex has greatly improved. Thus, the two-dimensional continuous control ability for the teleoperation
the teleoperation robot increases dramatically. This teleoperation system can effectively and
robot increases dramatically. This teleoperation system can effectively and continuously control
continuously control the robotic arm to complete the four-target reach and grasp task using motor
the robotic arm to complete the four-target reach and grasp task using motor imagery EEG signals.
imagery EEG signals. In addition, the operator is able to get the telepresence by the vibration
In addition, the operator is able to get the telepresence by the vibration stimulus based feedback.
stimulus based feedback.

(a)

(b)
Figure
Task
success
of motor
imagery
EEG-based
teleoperation
robot
system
for online
Figure
16.16.
Task
success
raterate
of motor
imagery
EEG-based
teleoperation
robot
system
for online
TaskTask
1
(a) and
online
(a)1and
online
TaskTask
2 (b).2 (b).

4. 4.
Discussion
Discussion
In In
thethe
past,
a variety
of studies
focused
on living
interaction
with robotic
[31–34]
past,
a variety
of studies
focused
on organisms
living organisms
interaction
withcues
robotic
cues
and
controlling
the robot through
BCI,through
but there
have
been
fewhave
research
theresearch
control of
[31–34]
and controlling
the robot
BCI,
but
there
beenon
few
onteleoperation
the control of
robot
based on motor
imagery
most
of the previous
research
groupsresearch
focus ongroups
the
teleoperation
robot based
on EEG.
motorMeanwhile,
imagery EEG.
Meanwhile,
most of
the previous
conventional
two
class or fourtwo
classclass
classification
from classification
EEG signals tofrom
get one
orsignals
four control
focus on the
conventional
or four class
EEG
to getcommands.
one or four
It can
only commands.
use the command
trigger
thethe
robot
arm to move
along the
control
It canto only
use
command
to trigger
thepredefined
robot armtrajectory.
to moveHowever,
along the
continuous
multidimensional
control
is
very
important,
especially
in
teleoperation.
It
can
not
only
predefined trajectory. However, continuous multidimensional control is very important, especially
in teleoperation. It can not only improve the teleoperation robot system’s efficiency but also give the
subject a more natural human machine interaction.

Electronics 2020, 9, 174

14 of 16

improve the teleoperation robot system’s efficiency but also give the subject a more natural human
machine interaction.
In this paper, a continuous teleoperation robot control system is utilized to demonstrate the
feasibility of using the motor imagery EEG acquired by wireless portable equipment to realize the reach
and grasp task and it is a fully two-dimensional continuous control system. The real-time continuous
control signals sent to the robotic arm includes both horizontal and vertical position control signals
when the subject performs a motor imagery. The robotic arm can be controlled to move toward the
target in a fully two-dimensional plane.
Furthermore, visual feedback has been utilized in the EEG-based teleportation system. In [18],
a BCI-driven teleoperation control of an exoskeleton robotic system was presented. Zhao et al. [19]
developed an EEG-based teleoperation control framework of multiple coordinated mobile robots.
Both of these studies used the visual feedback.
Nevertheless, tactile feedback also plays an important role in the traditional teleoperation system
and will be a critical part of any EEG-based teleoperation system. We adopt both visual and vibrotactile
feedback in the proposed motor imagery based teleoperation system. Thus, it can not only fully explore
the operator’s initiatives and attention processes but also increase the operator’s telepresence.
Moreover, the wireless portable EEG acquisition device was adopted in this study in order to
overcome the disadvantages of the traditional EEG equipment, which is inconvenient to carry and
complex to operation. Thus, the proposed motor imagery EEG-based teleoperation system provides
us a novel and convenient way to interact with the external device without using keyboard, joystick,
hand controller, and any other traditional input equipment. Additionally, it also allows the people to
interact with the remote various scenarios.
5. Conclusions and Future Work
In this paper, a BCI-based teleoperation robot control system was developed with a wireless
portable EEG acquisition device. The movement imagination EEG were translated into a continuous
two-dimensional control signal and transmitted to the remote robotic arm using TCP/IP and the robotic
arm moved through the control signal in real time. According to the continuously extracted trajectory
information, the remote robotic arm finished the reach and grasp task. Furthermore, the grasp force
was detected and sent to the master PC. Finally, the biofeedback based on vibrotactile stimulus was
given to the subjects in order to improve the telepresence and task performance.
An important work of the next step is to extend the current two-dimensional control to
three-dimensional (3D) control. Due to the characteristics of noninvasive EEG, it is very difficult to
directly extract the 3D trajectory information from the EEG signals. In order to control the robotic arm
to move towards the target in the 3D space, we are currently conducting research on a hybrid BCI
system. Moreover, the teleoperation system can be improved from four targets to more targets in the
reach and grasp task.
Furthermore, potential application of this system is continuous control of the teleoperation robot,
multi-degree of freedom prosthesis, and rehabilitation robot using only motor imagery for paraplegic.
Author Contributions: Conceptualization, B.X. and X.H.; methodology, B.X., W.L., X.H., Z.W. and D.Z.; software,
B.X. and X.H.; formal analysis, B.X., W.L. and X.H.; investigation, X.H. and W.L.; supervision, A.S.; writing—original
draft preparation, B.X. and Z.W.; writing—review and editing, W.L., D.Z. and C.W. All authors have read and
agreed to the published version of the manuscript.
Funding: This research was funded by National Key Research and Development Program of China, grant number:
2016YFB1001303; National Natural Science Foundation of China, grant number: 61673114, 91648206, 61803201
and 61673105; Natural Science Foundation of Jiangsu Province, grant number: BK20170803.
Conflicts of Interest: The authors declare no conflict of interest.

Electronics 2020, 9, 174

15 of 16

References
1.
2.
3.
4.

5.

6.

7.

8.
9.
10.

11.

12.

13.

14.
15.
16.

17.

18.

19.

Wolpaw, J.R.; Birbaumer, N.; McFarland, D.J.; Pfurtscheller, G.; Vaughan, T.M. Brain–computer interfaces for
communication and control. Clin. Neurophysiol. 2002, 113, 767–791. [CrossRef]
Van Gerven, M.; Farquhar, J.; Schaefer, R.; Vlek, R.; Geuze, J.; Nijholt, A.; Ramsey, A.; Haselager, P.; Vuurpijl, L.;
Gielen, S.; et al. The brain–computer interface cycle. J. Neural Eng. 2009, 6, 041001. [CrossRef]
Romano, D.; Donati, E.; Benelli, G.; Stefanini, C. A review on animal-robot interaction: From bio-hybrid
organisms to mixed societies. Biol. Cybern. 2019, 113, 201–225. [CrossRef]
Soekadar, S.R.; Witkowski, M.; Gómez, C.; Opisso, E.; Medina, J.; Cortese, M.; Vitiello, N. Hybrid
EEG/EOG-based brain/neural hand exoskeleton restores fully independent daily living activities after
quadriplegia. Sci. Robot. 2016, 1, 3296. [CrossRef]
Liu, J.; Abd-El-Barr, M.; Chi, J.H. Long-term Training with a Brain-Machine Interface-Based Gait Protocol
Induces Partial Neurological Recovery in Paraplegic Patients. Neurosurgery 2016, 79, N13–N14. [CrossRef]
[PubMed]
Xia, B.; Maysam, O.; Veser, S.; Cao, L.; Li, J.; Jia, J.; Xie, H.; Birbaumer, N. A combination strategy based
brain–computer interface for two-dimensional movement control. J. Neural Eng. 2015, 12, 046021. [CrossRef]
[PubMed]
Minati, L.; Yoshimura, N.; Koike, Y. Hybrid control of a vision-guided robot arm by EOG, EMG, EEG biosignals
and head movement acquired via a consumer-grade wearable device. IEEE Access 2016, 4, 9528–9541.
[CrossRef]
Meng, J.; Zhang, S.; Bekyo, A.; Olsoe, J.; Baxter, B.; He, B. Noninvasive electroencephalogram based control
of a robotic arm for reach and grasp tasks. Sci. Rep. 2016, 6, 38565. [CrossRef]
Casey, A.; Azhar, H.; Grzes, M.; Sakel, M. BCI controlled robotic arm as assistance to the rehabilitation of
neurologically disabled patients. Disabil. Rehabil. Assist. Technol. 2019, 1–13. [CrossRef]
McMullen, D.P.; Hotson, G.; Katyal, K.D.; Wester, B.A.; Fifer, M.S.; McGee, T.G.; Harris, A.; Johannes, M.S.;
Vogelstein, R.J.; Ravitz, A.D.; et al. Demonstration of a semi-autonomous hybrid brain–machine interface
using human intracranial EEG, eye tracking, and computer vision to control a robotic upper limb prosthetic.
IEEE Trans. Neural Syst. Rehabil. Eng. 2014, 22, 784–796. [CrossRef]
Hotson, G.; McMullen, D.P.; Fifer, M.S.; Johannes, M.S.; Katyal, K.D.; Para, M.P.; Armiger, R.; Anderson, W.S.;
Thakor, N.V.; Wester, B.A.; et al. Individual finger control of a modular prosthetic limb using high-density
electrocorticography in a human subject. J. Neural Eng. 2016, 13, 026017. [CrossRef] [PubMed]
Fernández-Rodríguez, Á.; Velasco-Álvarez, F.; Bonnet-Save, M.; Ron-Angevin, R. Evaluation of switch and
continuous navigation paradigms to command a brain-controlled wheelchair. Front. Neurosci. 2018, 12, 438.
[CrossRef] [PubMed]
Lazarou, I.; Nikolopoulos, S.; Petrantonakis, P.C.; Kompatsiaris, I.; Tsolaki, M. EEG-Based Brain–Computer
Interfaces for Communication and Rehabilitation of People with Motor Impairment: A Novel Approach of
the 21st Century. Front. Hum. Neurosci. 2018, 12, 14. [CrossRef] [PubMed]
He, Y.; Eguren, D.; Azorín, J.M.; Grossman, R.G.; Luu, T.P.; Contreras-Vidal, J.L. Brain–machine interfaces for
controlling lower-limb powered robotic systems. J. Neural Eng. 2018, 15, 021004. [CrossRef]
Xu, B.G.; Song, A.G.; Zhao, G.P.; Liu, J.; Xu, G.Z.; Pan, L.Z.; Yang, R.H.; Li, H.J.; Cui, J.W. EEG-modulated
robotic rehabilitation system for upper extremity. Biotechnol. Biotechnol. Equip. 2018, 32, 795–803. [CrossRef]
Delisle-Rodriguez, D.; Cardoso, V.; Gurve, D.; Loterio, F.; Romero-Laiseca, M.A.; Krishnan, S.; Bastos Filho, T.
System based on subject-specific bands to recognize pedaling motor imagery: Towards a BCI for lower-limb
rehabilitation. J. Neural Eng. 2019, 16, 056005. [CrossRef]
Escolano, C.; Antelis, J.M.; Minguez, J. A telepresence mobile robot controlled with a noninvasive
brain–computer interface. IEEE Trans. Syst. Man. Cybern. Part B Cybern. 2012, 42, 793–804. [CrossRef]
[PubMed]
Qiu, S.; Li, Z.; He, W.; Zhang, L.; Yang, C.; Su, C.Y. Brain-Machine Interface and Visual Compressive
Sensing-Based Teleoperation Control of an Exoskeleton Robot. IEEE Trans. Fuzzy Syst. 2017, 25, 58–69.
[CrossRef]
Zhao, S.; Li, Z.; Cui, R.; Kang, Y.; Sun, F.; Song, R. Brain–machine interfacing-based teleoperation of multiple
coordinated mobile robots. IEEE Trans. Ind. Electron. 2017, 64, 5161–5170. [CrossRef]

Electronics 2020, 9, 174

20.
21.
22.
23.
24.

25.
26.
27.

28.
29.
30.
31.
32.
33.

34.

16 of 16

Lo, C.C.; Chien, T.Y.; Chen, Y.C.; Tsai, S.H.; Fang, W.C.; Lin, B.S. A wearable channel selection-based
brain-computer interface for motor imagery detection. Sensors 2016, 16, 213. [CrossRef]
Bousseta, R.; El Ouakouak, I.; Gharbi, M.; Regragui, F. EEG based brain computer interface for controlling a
robot arm movement through thought. Innov. Res. Biomed. Eng. 2018, 39, 129–135. [CrossRef]
Li, Y.; Zhou, G.; Graham, D.; Holtzhauer, A. Towards an EEG-based brain-computer interface for online
robot control. Multimed. Tools Appl. 2016, 75, 7999–8017. [CrossRef]
Xu, B.G.; Song, A.G.; Zhao, G.P.; Xu, G.Z.; Pan, L.Z.; Yang, R.H.; Li, H.J.; Cui, J.W.; Zeng, H. Robotic
neurorehabilitation system design for stroke patients. Adv. Mech. Eng. 2015, 7, 1687814015573768. [CrossRef]
Acharya, J.N.; Hani, A.; Cheek, J.; Thirumala, P.; Tsuchida, T.N. American Clinical Neurophysiology
Society Guideline 2: Guidelines for Standard Electrode Position Nomenclature. J. Clin. Neurophysiol. 2016,
33, 308–311. [CrossRef] [PubMed]
Schalk, G.; McFarland, D.J.; Hinterberger, T.; Birbaumer, N.; Wolpaw, J.R. BCI2000: A general-purpose
brain-computer interface (BCI) system. IEEE Trans. Biomed. Eng. 2004, 51, 1034–1043. [CrossRef]
Wolpaw, J.R.; McFarland, D.J. Control of a two-dimensional movement signal by a noninvasive
brain-computer interface in humans. Proc. Natl. Acad. Sci. USA 2004, 101, 17849–17854. [CrossRef]
De Nunzio, A.M.; Dosen, S.; Lemling, S.; Markovic, M.; Schweisfurth, M.A.; Ge, N.; Graimann, B.; Falla, D.;
Farina, D. Tactile feedback is an effective instrument for the training of grasping with a prosthesis at low-and
medium-force levels. Exp. Brain Res. 2017, 235, 2547–2559. [CrossRef]
Patel, G.K.; Dosen, S.; Castellini, C.; Farina, D. Multichannel electrotactile feedback for simultaneous and
proportional myoelectric control. J. Neural Eng. 2016, 13, 056015. [CrossRef]
Wu, C.C.; Song, A.G.; Ling, Y.; Wang, N.; Tian, L. A control strategy with tactile perception feedback for
EMG prosthetic hand. J. Sens. 2015, 2015, 869175. [CrossRef]
Xu, X.N.; Song, A.G.; Ni, D.J.; Li, H.J.; Xiong, P.W.; Zhu, C.C. Visual-haptic aid teleoperation based on 3-D
environment modeling and updating. IEEE Trans. Ind. Electron. 2016, 63, 6419–6428. [CrossRef]
Romano, D.; Benelli, G.; Stefanini, C. Encoding lateralization of jump kinematics and eye use in a locust via
bio-robotic artifacts. J. Exp. Biol. 2018, 222, jeb187427. [CrossRef] [PubMed]
Romano, D.; Benelli, G.; Hwang, J.S.; Stefanini, C. Fighting fish love robots: Mate discrimination in males of
a highly territorial fish by using female-mimicking robotic cues. Hydrobiologia 2019, 833, 185–196. [CrossRef]
Nishinoma, H.; Ohno, K.; Kikusui, T.; Nagasawa, M.; Tsuchihashi, N.; Matsushita, S.; Mikayama, T.; Tomori, S.;
Saito, M.; Murayama, M.; et al. Canine Motion Control Using Bright Spotlight Devices Mounted on a Suit.
IEEE Trans. Med. Robot. Bionics 2019, 1, 189–198. [CrossRef]
Polverino, G.; Karakaya, M.; Spinello, C.; Soman, V.R.; Porfiri, M. Behavioural and life-history responses of
mosquitofish to biologically inspired and interactive robotic predators. J. R. Soc. Interface 2019, 16, 20190359.
[CrossRef]
© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).

