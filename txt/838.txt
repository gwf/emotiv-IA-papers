IMMERSIVE NEUROFEEDBACK: A NEW PARADIGM

Mohamed Elgendi1, Francois Vialatte2, Martin Constable3 and Justin Dauwels4
1

Institute for Media Innovation, Nanyang Technological University, Singapore
2
ESPCI ParisTech, Paris, France
3
School of Art, Design and Media, Nanyang Technological University, Singapore
4
School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore
@ntu.edu.sg , @brain.riken.jp , @ntu.edu.sg , @ntu.edu.sg

Keywords:

Immersive-Healthcare, Neurofeedback, EEG, Brain waves, Telemedicine

Abstract:

Healthcare organizations continue to pursue ways of offering higher-quality care to face the demand and
expectations in promoting and maintaining health and in disease prevention. Currently, in neuroscience,
there is an undergoing paradigm shift towards immersive neurofeedback mechanism. This will improve the
user’s (or patient’s) ability to control brain activity, medical diagnoses, and rehabilitation of neurological or
psychiatric disorders. Indeed, several psychological and medical studies have confirmed that virtual
immersive activity is enjoyable, stimulating, and can have a healing effect. The new paradigm consists of an
immersive room and three input devices: Emotiv headset (wireless non-invasive acquisition of brain waves),
Kinect camera (gesture recognition), and wireless microphone (voice/speech recognition); towards
immersive treatment and better quality health system in the near future.

1

INTRODUCTION

The electroencephalogram (EEG) was first recorded
in 1924 by Hans Berger [1]. At that time, Berger
studied and described for the first time the nature of
EEG alterations in brain diseases such as epilepsy.
Currently, EEG is a helpful tool in clinical
neuroscience, with several applications such as:
• Monitor alertness, coma and brain death [2, 3]
• Locate areas of damage following head
injuries [4, 5], stroke [6, 7] or brain
haemorrhage [8, 9]
• Detect Alzheimer's disease [10-13] and brain
tumour [14, 15]
• Investigate sleep disorders [16, 17] and
epilepsy [18, 19]
• Monitor human brain development [20, 21]
• Measure the depth of anaesthesia [22]
• Test drug effects [23, 24]

Both the progressive developments in electrical
engineering and the fascination with the human
brain have attracted researchers from different
background to investigate EEG recordings.
One of the interesting multidisciplinary
applications of EEG is sonification, i.e., converting
the brain waves into music. Several researchers [2530] tried to generate sound from EEG signals; there
are still many open questions and challenges, and
plenty of opportunities especially after the recent
advent of convenient wireless EEG headsets [31-35].
As far as we know, converting brain waves into
combined representation (i.e. sounds, graphics, and
haptics) in an immersive room has not been reported
in literature. However, Elgendi et al [36] suggested
transforming real-time EEG signals into multimodal
tangible representation such as sounds (sonification)
and graphics (visualization), to improve neurological
diagnosis and neurofeedback.
In this paper we are providing a new paradigm
that translates EEG signals, recorded from a wireless
EEG headset, into sounds and graphics mapped in an
immersive room.

Figure 1: A performer tries to control the sounds and the tunnel properties (i.e. colour and speed) generated from his
EEG, by adjusting the mental states associated with the heard sound and shown graphics.

The immersive room offers a unique and powerful
platform to represent brain waves in a tangible
fashion. Although neural feedback has been
investigated for quite some time now, it has never
been implemented in an interactive and immersive
room. Such novel representation of brain signals can
be valuable for therapy, diagnosis, entertainment,
and arts. Indeed, several psychological and medical
studies have confirmed that virtual immersive
activity is enjoyable, stimulating, and can have a
healing effect. These studies have also shown that
the effect is stronger with virtual reality (VR)
feedback than with simple 2D feedback [37-40].

2

VISION

A visitor in the immersive room can see, hear and
touch his brainwaves, as if he is standing in the
middle of his own brain, as shown in Fig.1. Such
intense neural feedback may for example be used to
cure neurological diseases such as depression,
epilepsy, bipolar disorder, cognitive impairment,
migraines, and autism spectrum disorders;
alternatively, it can be used to explore and
investigate
mental
states
(e.g.,
emotions,
meditation).

3

METHODS

We map electroencephalogram (EEG) signals onto
computer graphics, sounds, music, and haptic stimuli
(vibrating gloves).

Those different representations can be generated
separately or simultaneously, resulting in a virtual
reality (VR) that has been sculpted from EEG
signals.
This virtual reality can be generated offline: that
allows a medical doctor to screen EEG signals of
patients in a retrospective fashion.
We are also developing a real-time
implementation: the visitor then perceives his own
brainwaves in real-time, which in turn will alter the
brainwaves;
such
feedback
system
(“neurofeedback”) may have a stabilizing effect on
the brain [39], and has been shown to be an effective
cure for a wide spectrum of neurological diseases
[41].
A virtual human (VH) in the immersive room
guides the visitor through different applications and
types of neural feedback. The visitor can customize
the demo in the immersive room on the fly: he can
control certain parameters of the virtual reality (e.g.,
colors, speed, angle of view, zoom), by talking to the
virtual human and by gestures.

4

SCENARIO

Different scenarios can be proposed, but in here we
will explain the generic scenario. Once the visitor
enters the room, the Virtual Human (VH) will
operate as a host. First the VH will verify the
identity of the user, and will check whether the
visitor has access to the system. Then, the VH will
ask the visitor whether he would like to use the
system for real-time neural feedback or for offline
analysis of recorded EEG signals. In the latter case,
the VH will ask the EEG database to be processed;

in the former case, the VH will ask the visitor to
wear the wireless EEG headset. In both cases, the
VH will ask the visitor to select one of the
applications, including Paint, MIDI-3D brain,
Vortex, and Topoplot.
• Paint: Painting with your brain waves in 3D.
• MIDI-3D brain: Listening to the music
generated by the brain waves in 3D, while
watching a 3D artistic rendering of brain
waves, and feeling the brain waves as
vibrations in smart gloves.
• Tunnel: Monitoring and controlling the level
of consciousness of the visitor through 3D
tunnel, as shown in Fig. 1.
• Topoplot: A variety of research-oriented
representations of the brain waves, including
time-frequency maps, spatial distribution of
power, EEG statistics such as synchrony and
complexity.
The visitor can ask the VH to stop the system at
any time.

5

SYSTEM DESIGN

Our system has three input devices: Emotiv headset
(wireless non-invasive acquisition of brain waves),
Kinect camera (gesture recognition), and wireless
microphone (voice/speech recognition). These
devices are connected to Processing (3d graphics
mapping), Dolby surround system, topoplot (brain
activity mapping), and SAPI5.4 (Speech Application
Programming Interface).
The graphics output of these software packages
will be projected on the screens in the immersive
room, and the sound will be fed into the Dolby
Surround System. As shown in Fig.2, the system is
developed in different programming languages; the
input devices are all processed in VC++, whereas
the output devices are developed in Java, VC++, and
Python.
We use multithreading technology and sockets to
seamlessly integrate those different languages; the
same technology also allows us to run multiple
applications in parallel, and to connect and process
additional sensors and input/output devices;
information can even be transmitted and received
through the world wide web, enabling various
powerful extensions of our approach (e.g., multiuser applications for study of social interactions).

Fig. 2. Emotiv (wireless EEG headset), Kinect (gesture
detection camera) and wireless microphone are connected
to Processing.org software (graphical rendering), Topoplot
(research-oriented visualizations), and Speech Application
Programming Interface (SAPI5.4). The programming
language used for each component is indicated on the
arrows. The package BCI2000 serves as an interface
between those different languages, and operates as a metaplatform.

5

CONCLUSION

A new healthcare model that shifts towards
immersive neurofeedback has been introduced.
Mapping brain signals in an immersive room can be
valuable for therapy, diagnosis, entertainment, and
art.
The committee on quality of health care in
America Institute indicate that a radical
transformation of health services supply process is
required for the 21st century. Fully immersive realtime feedback of the users’ mental state offers a
potential for a new paradigm in future healthcare.

ACKNOWLEDGEMENTS
Mohamed Elgendi and Justin Dauwels would like to
thank the Institute for Media Innovation (IMI) at
Nanyang Technological University (NTU) for
partially
supporting
this
project
(Grant
M58B40020).

REFERENCES
[1] H. Berger, “Über Das Elektrenkephalogramm
Des Menschen,” Archiv für Psychiatrie und
Nervenkrankheiten, vol. 87, pp. 527-570, 1929.
[2] E. F. M. Wijdicks, “The Diagnosis of Brain
Death,” New England Journal of Medicine, vol.
344, no. 16, pp. 1215-1221, 2001.
[3] “The
Electroencephalogram
in
the
Determination of Brain Death,” New England
Journal of Medicine, vol. 300, no. 9, pp. 502502, 1979.
[4] E. Gütling, A. Gonser, H.-G. Imhof et al.,
“EEG reactivity in the prognosis of severe head
injury,” Neurology, vol. 45, no. 5, pp. 915-918,
May 1, 1995, 1995.
[5] R. W. Thatcher, C. Biver, R. McAlaster et al.,
“Biophysical Linkage between MRI and EEG
Amplitude
in
Closed
Head
Injury,”
NeuroImage, vol. 7, no. 4, pp. 352-367, 1998.
[6] K. G. Jordan, “Emergency EEG and
Continuous EEG Monitoring in Acute Ischemic
Stroke,” Journal of Clinical Neurophysiology,
vol. 21, no. 5, pp. 341-352, 2004.
[7] R. A. Jackel, and R. N. Harner, “Computed
EEG
topography
in
acute
stroke,”
Neurophysiologie
Clinique/Clinical
Neurophysiology, vol. 19, no. 3, pp. 185-197,
1989.
[8] P. M. Vespa, M. R. Nuwer, C. Juhász et al.,
“Early detection of vasospasm after acute
subarachnoid hemorrhage using continuous
EEG
ICU
monitoring,”
Electroencephalography
and
clinical
Neurophysiology, vol. 103, no. 6, pp. 607-615,
1997.
[9] J. Claassen, S. A. Mayer, and L. J. Hirsch,
“Continuous EEG Monitoring in Patients With
Subarachnoid Hemorrhage,” Journal of
Clinical Neurophysiology, vol. 22, no. 2, pp.
92-98, 2005.
[10] J. Dauwels, F. Vialatte, and A. Cichocki,
“Diagnosis of alzheimers disease from EEG
signals: Where are we standing?,” Current
Alzheimer Research, vol. 7, pp. 487-505, 2010.
[11] J. Dauwels, F. Vialatte, T. Musha et al., “A
comparative study of synchrony measures for
the early diagnosis of alzheimer’s disease based
on EEG,” NeuroImage, vol. 49, pp. 668-693,
2010.
[12] J. Dauwels, K. Srinivasan, R. Reddy et al.,
“Slowing and loss of complexity in

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

Alzheimer’s EEG: Two sides of the same
coin?,” International Journal of Alzheimer's
Disease, no. (in press), 2011.
F.-B. Vialatte, J. Solé-Casals, M. Maurice et
al., “Improving the Quality of EEG Data in
Patients with Alzheimer’s Disease Using ICA,”
Advances in Neuro-Information Processing ,
Lecture Notes in Computer Science, vol.
5507/2009, pp. 979-986, 2009.
F. N. Karameh, and M. A. Dahleh, "Automated
classification of EEG signals in brain tumor
diagnostics." pp. 4169-4173 vol.6.
R. Silipo, G. Deco, and H. Bartsch, “Brain
tumor classification based on EEG hidden
dynamics,” Intelligent Data Analysis, vol. 3,
no. 4, pp. 287-306, 1999.
R. Benca, W. Obermeyer, C. Larson et al.,
“EEG alpha power and alpha power asymmetry
in sleep and wakefulness,” Psychophysiology,
vol. 36, no. 04, pp. 430-436, 1999.
H. Merica, R. Blois, and J. M. Gaillard,
“Spectral characteristics of sleep EEG in
chronic insomnia,” European Journal of
Neuroscience, vol. 10, no. 5, pp. 1826-1834,
1998.
N. Kannathal, M. L. Choo, U. R. Acharya et al.,
“Entropies for detection of epilepsy in EEG,”
Computer Methods and Programs in
Biomedicine, vol. 80, no. 3, pp. 187-194, 2005.
K. K. Jerger, T. I. Netoff, J. T. Francis et al.,
“Early Seizure Detection,” Journal of Clinical
Neurophysiology, vol. 18, no. 3, pp. 259-268,
2001.
P. J. Marshall, Y. Bar-Haim, and N. A. Fox,
“Development of the EEG from 5 months to 4
years of age,” Clinical neurophysiology :
official journal of the International Federation
of Clinical Neurophysiology, vol. 113, no. 8,
pp. 1199-1208, 2002.
A. Meyer-Lindenberg, “The evolution of
complexity in human brain development: an
EEG study,” Electroencephalography and
clinical Neurophysiology, vol. 99, no. 5, pp.
405-411, 1996.
X. S. Zhang, R. J. Roy, and E. W. Jensen,
“EEG complexity as a measure of depth of
anesthesia
for
patients,”
Biomedical
Engineering, IEEE Transactions on, vol. 48,
no. 12, pp. 1424-1433, 2001.
M. C. Salinsky, B. S. Oken, and L. Morehead,
“Intraindividual analysis of antiepileptic drug
effects on EEG background rhythms,”

[24]

[25]

[26]

[27]

[28]

[29]
[30]
[31]
[32]
[33]
[34]

[35]

[36]

[37]

[38]

Electroencephalography
and
clinical
Neurophysiology, vol. 90, no. 3, pp. 186-193,
1994.
J. Bruhn, H. Röpcke, and A. Hoeft,
“Approximate
Entropy
as
an
Electroencephalographic Measure of Anesthetic
Drug Effect during Desflurane Anesthesia,”
Anesthesiology, vol. 92, no. 3, pp. 715-726,
2000.
A. Lucier, “Statement on: music for solo
performer,” Biofeedback and the Arts: Results
of Early Experiments vol. (Vancouver, Canada:
Aesthetic Research Centre of Canada), 1967.
E. R. Miranda, K. Sharman, K. a. Kilborn et al.,
“On Harnessing the Electroencephalogram for
the Musical Braincap,” Computer Music
Journal, vol. 27, no. 2, pp. 80-102, 2003.
R. Teitelbaum “In tune: Some early
experiments in biofeedback music (19661974),” Aesthetic Research Center of Canada
Publications, 1976.
D. Rosenboom, “Method for Producing Sounds
or Light Flashes with Alpha Brain Waves for
Artistic Purposes,” Leonardo, vol. 5, no. 2, pp.
141-145, 1972.
D. Rosenboom, “Computer Music Journal,”
vol. 14, no. 1, pp. 48-66, 1990.
G. Baier, and T. Hermann, "The Sonification of
Rhythms in Human Electroencephalogram."
"EmotivSystems. Emotiv - brain computer
interface technology. ://emotiv.com.."
Imec.
" ://www2.imec.be/be_en/press/imecnews/imecEEGMDMWest.html."
NeuroFocus. " ://www.neurofocus.com/."
MKS.
" ://www.mks.ru/eng/Products/EEG/Neurobelt/.
"
Biopac.
" ://www.biopac.com/researchApplications.asp?
Aid=23&AF=437&Level=3."
M. Elgendi, B. Rebsamen, A. Cichocki et al.,
“Real-Time Wireless Sonification of Brain
Signals,” in International Conference on
Cognitive Neurodynamics, Japan, 2011.
R. Leeb, D. Friedman, G. R. ller-Putz et al.,
“Self-Paced (Asynchronous) BCI Control of a
Wheelchair in Virtual Environments: A Case
Study with a Tetraplegic,” Computational
Intelligence and Neuroscience, vol. 2007, 2007.
R. Leeb, F. Lee, C. Keinrath et al., “BrainComputer Communication: Motivation, Aim,
and Impact of Exploring a Virtual Apartment,”

IEEE Transactions on Neural Systems and
Rehabilitation Engineering, vol. 15, no. 4, pp.
473-482, 2007.
[39] T. Ros, M. A. M. Munneke, D. Ruge et al.,
“Endogenous control of waking brain rhythms
induces neuroplasticity in humans,” European
Journal of Neuroscience, vol. 31, no. 4, pp.
770-778, 2010.
[40] J. Gruzelier, A. Inoue, R. Smart et al., “Acting
performance and flow state enhanced with
sensory-motor
rhythm
neurofeedback
comparing ecologically valid immersive VR
and training screen scenarios,” Neuroscience
Letters, vol. 480, no. 2, pp. 112-116, 2010.
[41] M. Arns, S. de Ridder, U. Strehl et al.,
“Efficacy of neurofeedback treatment in
ADHD: the effects on inattention, impulsivity
and hyperactivity: a meta-analysis,” Clin. EEG
Neurosci, vol. 40, no. 3, pp. 180-9, 2009.

