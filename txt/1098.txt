ElectroEncephaloGraphics: Making Waves in Computer
Graphics Research
Maryam Mustafa, Marcus Magnor
Index Terms—perception,EEG,rendering,visualization,aesthetics

We present the application of ElectroEncephaloGraphy
(EEG) as a novel modality for investigating perceptual graphics problems. Until recently, EEG has predominantly been used
for clinical diagnosis, in psychology and by the BCI community. Here we want to extend its scope to assist in understanding the perception of visual output from graphics applications
and to create new approaches based on direct neural feedback.
We begin by introducing the fundamentals of EEG measurements, its neurophysiological basis and the limitations of EEG
in determining certain aspects of visual perception. We then
present three different areas for EEG application in graphics:
determining perceived image and video quality through the detection of typical rendering artifacts, evaluating visualization
effectiveness by calculating cognitive load from EEG data, and
automatic optimization of rendering parameters for images and
videos based on implicit neural feedback. We conclude with an
outlook on what the future of EEG in graphics may hold.
1

I NTRODUCTION

The recent integration of methods and techniques from perception research into graphics has enhanced both fields and created novel approaches for solving existing problems. In rendering, for example, resources can be allocated to areas of a
scene that matter most to human observers, saving computation time. Similarly, visualization techniques have benefited
from perceptual measures such as processing speed which determines how quickly features like colour and texture are perceptually processed. This integration is particularly important
if the goal is to create stunningly realistic imagery for movies,
games and immersive environments, the ultimate audience for
which is the human. A failure to explore and understand the innate properties of the perceptual system will result in synthetic
images having unintended consequences. Perceptual research
has shown that people may perceive things differently from
how they actually are; there is a difference between perceptual
reality and physical reality [6] because the human visual system has to make a lot of assumptions to make sense of the real
world. The complexity and nuances of the human visual system are highlighted by many different kinds of entertaining illusions. An example of the quirkiness of our perceptual system
• Maryam Mustafa. E-mail: mustafa@cg.cs.tu-bs.de
• Marcus Magnor E-mail: magnor@cg.cs.tu-bs.de

and its unexpected outcomes is the Uncanny Valley effect. Intuitively, it would seem that the more human an android becomes
in appearance and movement, our corresponding response also
becomes increasingly positive and empathetic. This is in-fact
not true, and although the human response initially is positive,
a point is reached beyond which, as the android becomes more
human, the response turns into revulsion. This effect could be
witnessed, for example, in the response to the film Polar Express which used CGI generated people and evoked an unexpected and visceral reaction of revulsion in viewers [5].
Traditionally, several important tools have been employed
for perceptual research in graphics, the most prominent of
which have been psychophysical experiments and eye trackers [6]. Psychophysical experiments have been particularly
useful in studying the relationship between physical stimuli
and the resulting sensations and perceptions. Similarly, eye
trackers have been employed to investigate what kind of visual information is being focused on while viewing an image,
video or visualization. This can provide valuable information
on which parts of the stimulus are important and also on the order in which an image is scanned. All these techniques have become part of mainstream graphics research and have provided
unique insights. However, there exists one methodology commonly used in psychology and medical diagnoses that has immense potential for graphics applications but that, has been so
far overlooked. Here, we present the application of ElectroEncephaloGraphy (EEG) in computer graphics
An ElectroEncephaloGraph (EEG) is a device which records
electrical activity in the brain through multiple electrodes
placed on the scalp. Traditionally, an EEG has been used predominantly clinically for either diagnostic purposes, in perceptual psychology and by the Brain Computer Interaction (BCI)
community for assisting or augmenting human cognition and
movement. Here we extend the scope of EEG to assist in understanding the perception of the visual output from computer
graphics applications and to propose new applications based on
direct neural feedback.
The use of EEG outside of specialized fields was until recently restricted not only due to the cost of the EEG equipment
but also because the technical knowledge required to set up the
apparatus and decode the signals was complicated. With the advent of technologies like the Emotiv EEG neural headset, however, many of these limitations no longer apply (Fig.2)1 . The
headset is cheap, wireless and gel-less which makes it much
1 http://www.emotiv.com/store/hardware/epoc-bci/epoc-neuroheadset/

Typically the brain’s response to a stimulus is analysed using event-related potentials (ERP) which measure the response to
sudden changes in stimuli [1]. Given that EEG data reflects many concurrent neural processes, the response to a single event
is not directly visible in the recording of a single trial (Fig.1a). Many identical trials must be conducted to average out any
non-related brain activity and to make the ERP waveform visible (Fig b). Averaging is done by extracting the segment of
EEG surrounding the stimulus from each trial and electrode and lining them up with respect to the start of the
stimulus (Fig 1b) [1]. The resulting ERP’s consist of positive and negative voltage deflections which are called components.
In Fig 1b the peaks are labelled P1,N1,P2,N2 and P3. The initial peak P1 occurs regardless of the type of stimulus and is
just the response to any visual stimulus. In contrast, the P3 wave, which occurs approximately 300ms after stimulus onset,
depends on the task being performed and the visual stimulus presented[1].

(a) Labelled EEG data over time from a single trial: Each curve (b) Averaged curve of many trials for one eleccorresponds to one electrode.
trode

Figure 1. Raw EEG data (a) shows no distinct peaks in response to stimulus occurrence (vertical lines in a). By averaging
many identical trials, time-locked to the start of stimulus, the Event Related Potential (ERP) becomes visible (b).
[1] S. J. Luck. An introduction to the event-related potential technique. MIT press Cambridge, MA:, 2005.

easier to use, although the signal to noise ratio for this system is much higher than for medical grade EEG devices. Also,
with the vast amount of research in the analysis of EEG signals from the BCI and signal processing community, the issue
of data analysis has become less critical. EEG is a particularly interesting modality for use in graphics research because,
unlike behavioural measures, EEG data makes it possible to
covertly monitor reactions to stimuli (images/videos) that may
be perceived subconsciously (unattended versus attended stimuli) but are consciously ignored. Another great advantage that
the EEG provides is the spontaneous (online) acquisition of
neural responses. While the viewer is watching a video or playing a computer game, the emotional and perceptual response
is recorded immediately instead of being reconstructed afterwards. This can be an important advantage in graphics research
where the emotional response to visual content often plays a
major role. Emotions, however, are ephemeral in nature and responses gained at the end of a session are based on the memory
of the emotion evoked, as opposed to the immediate emotional
and perceptual response evoked during the video or game.
In the following, we present an introduction to EEG and
discuss what it can measure, what its limitations are, and we
present some of its recent applications in graphics.
2

E LECTRO E NCEPHALO G RAPHY

EEG measures the electrical activity of a large number of neurons close to the brain surface. Traditional EEG systems re-

Fig. 2: 32-electrode setup for conducting EEG experiments

quire anywhere from 32 - 64 electrodes to be fitted to the head
of a participant at specific locations (Fig 1a). This is usually achieved with a cap of attached electrode positions that
is pulled over the head. To ensure conductivity between the
electrodes and the scalp, contact gel needs to be applied to the
electrodes which is a time-consuming and messy procedure.
Fortunately, recent advances have made it easier to use EEG.
Cost-effective, gel-less, wireless EEG headsets use fewer electrodes and require minimal effort to set up (Fig.2). These neural
head sets come with different suites that automatically detect
mental and emotional states e.g. attentive, non-attentive, angry,
happy, etc. This progress has significantly lowered the barrier
to EEG-based research in graphics.
EEG signals from electrodes must be amplified before they
can be converted to digital form and stored. They also need to
be filtered to remove artifacts from amplification and sampling.
Another type of artifact to be considered and removed originate

(a) Tradiotional 32 Electrode layout according to
the 10-20 system. The yellow electrodes are over
the frontal cortex while the green are over the
visual cortex

(b) Emotional response to different rendering artifacts. F3/F7(averaged) are eletrodes over left
frontal cotex and F4/F8(averaged) are right frontal cortex electrodes.

Fig. 1: The emotional response (b) to different artifacts can be detected by comparing the signal from the right and left frontal
cortex where the yellow electrodes are over the frontal cortex while the green are over the visual cortex (a).
from eye blinks and facial muscle movements.
There exists a small body of work on using EEG for graphics problems based on ERP measurements. Unfortunately, the
ERP method is time-consuming and it requires many participants and many trials per participant. Recent advances in EEG
research have overcome this impediment by creating methods
for the analysis and classification of single-trial data [9]. In
the following, we explore the current work in applying EEG to
graphics and the future of EEG as a viable modality for graphics research.
3

V IDEO AND I MAGE Q UALITY A SSESSMENT WITH
EEG

The subjective evaluation of image or video quality is typically
achieved through opinion tests in which subjects judge perceived quality based on a rating scale (e.g, between 1-5). Quality ratings obtained through user studies are usually filtered by
some decision process which, in turn, may be influenced by external factors. In contrast, EEG provides a less explicit way of
determining perceived visual quality and does not rely on conscious decision making processes.
Recently, several studies have proposed the use of EEG as
a viable modality for implicitly determining perceived visual
quality of images or video sequences. This body of work is
particularly novel since, typically, EEG has not been used for
complex or moving stimuli. In a 2012 study, we explored
the possibility of detecting artifacts in video sequences with
EEG [11]. The study measured the covert (implicit) visual processing associated with different types of artifacts. The basic
stimulus for the experiment was a 5.6 second video (resolution:
1440x1024,30 fps) of a person walking along a park trail. Five
different kinds of artifacts were incorporated into the scene.
The test cases shown were;popping, ghosting and blurring in
the static background, popping and blurring on the moving

foreground person along with a ground truth sequence where
there were no artifacts. All artifacts evoke a distinct neural response in the brain. Interestingly, the artifacts that evoke the
greatest response are linked with the foreground object. This
study was the first step in exploring the possibility of studying
the neural response to complex real-world stimuli with an EEG.
Apart from a response from the visual cortex there is a distinct emotional response to the artifacts as well (Fig 1b). Previous EEG experiments have provided evidence of lateralization
of emotion in the frontal cortex [1]. The classification of emotion using physiological signals has also been well researched
in the affective computing community [7]. Our results show
that the ground truth trials evoke a positive emotional response,
as opposed to the negative responses from the trials with artifacts and an increased output is seen in the right frontal cortex
for test cases with more severe artifacts (Popping on Person and
Blurring on Person) (Fig. 1b). This may be evidence that artifacts linked with a moving foreground not only evoke a larger
visual response but are also emotionally more disturbing. It is
also interesting to note that ghosting is associated with a much
smaller emotional response.
In a second study, we explored the idea of using a singletrial of EEG data to determine if subjects perceive artifacts in a
video sequence, and if they do, what type of artifact it is. [9].
We developed a novel wavelet-based approach for evaluating
the EEG signals which allows the prediction of perceived image quality from only a single trial. With this approach it is
possible to use data from only 10 electrode channels (Fig.1a)
for single-trial classification. After filtering the EEG data using a complex wavelet transform, an SVM classifies any single
trial based on the type of artifact. The study looked at three
classification tasks: trials with artifacts versus trials with no
artifacts, severe artifacts versus all other artifacts and ground
truth, and classification of each trial according to the specific

An early EEG study in graphics examined the brain’s response to JPEG-compression artifacts [1]. Three 512 * 512-pixel
JPEG-images were used as test material. Each image was presented in 7 different states of compression: The original image
and 6 image versions with different compression ratios. The evaluation of the ERPs revealed not only that the brain reacts to
JPEG artifacts, but that the reaction varies with compression ratio. Fig.1 illustrates the difference between ERPs elicited by
the ground truth stimulus, for which the participants did not report visible artifacts (red curve), and a highly compressed
image version, for which the participants did report highly noticeable artifacts (yellow curve).

(a) The ERPs show brain activity, averaged over electrodes O1,
Oz, and O2, for ground truth (red),and the compressed image
version(orange).

(b) The topographic maps show difference in voltage deflections over the scalp.

Figure 1. The ERPs (a) show brain response to the ground truth image (red) and to the compressed image version (orange).
The topographic maps (b) show the difference in voltage deflections over the scalp at different points in time for the ground
truth stimulus (red box) and the compressed image version (orange box).
[1] L. Lindemann and M. Magnor. Assessing the quality of compressed images using EEG. In Proc. IEEE International
Conference on Image Processing (ICIP), pages 3170 - 3173, 2011.

artifact present. We could predict the presence of an artifact
in a video sequence with 85% accuracy and the presence of a
severe artifact with a 95% accuracy.
Another study published by Scholler et al. [12] also showed
that it is possible to determine the video quality using an EEG.
Subjects in their experiment watched short video clips, some
of which featured a sudden quality change from high quality
to a lower quality level during the video. Unlike the previous study which used a real-world video sequence, Scholler
et al. used video sequences generated based on a synthetic image of a textured checker-board where the quality loss was induced by lossy compression of the synthesized video sequence.
Their work also supports the conclusion that it is possible to
reliably determine the quality of a video sequence from EEG
data. Schollers study also showed that the neural response was
directly related to the level of distortion.
Recently [3] published a study summarizing a series of experiments which used EEG to assess perceived visual and audio
quality. Their experiments show EEG to be a feasible measurement technique for assessing both audio and visual quality.
In summary these studies are an interesting step towards
EEG-based video quality assessment and show that EEG is a
cheap and effective way to determine the perceptual quality
of complex video sequences. We show that EEG is a viable
modality to determine the perception of different types of artifacts. We introduced a single-trial approach that uses wavelets
and an SVM to distinguish between different types of artifacts
appearing in video stimuli based on how they are perceived.

4

V ISUALIZATION E FFECTIVENESS AND EEG

Due to the sheer complexity and size of scientific data creating
efficient visualizations that promote an intuitive understanding
of a dataset is a difficult task. Within the area of visualization
there exist many methods for the display of information, but the
choice of which technique to use for a given data set is difficult.
Typically, scientific visualization methods are evaluated using
expert assessments and user studies. Although these methods
are useful for determining certain measures of usability, such
as increase in user response speed or decrease in error rates,
other measures are more complicated to evaluate. For example,
it is difficult to assess improved understanding and effectiveness at eliciting insight from a dataset because these are highly
subjective measures.
User studies rely on verbal feedback and are often coloured
by personal preference or past experiences. Recently, EEG has
been used as a novel modality for the effective evaluation of
visualizations [2]. This is a a particularly fitting option since
human factors play an important role in the study of the impact
of scientific visualization on research.
Anderson et. al [2] conducted a study to explore the effectiveness of scientific visualizations by calculating the amount of
mental work, as determined by cognitive load, required to interpret a visualization. Cognitive load is a concept closely tied to
working memory and is based on a mental architecture where
the working memory is limited in capacity and time for holding
novel information. Given that, people have a limited cognitive
capacity during learning and problem solving. The way that
information is presented can affect the amount of load placed

on working memory and subsequently, performance. Anderson’s work evaluates the effectiveness of different visualization
techniques by calculating the extraneous cognitive load which
is the extra load placed on a user due to the design of the task.
The study compared variations of the box plot to see which was
most effective in displaying a statistical data distribution. The
box plot is a graphical data analysis method used to visually
show the distribution of a data set by depicting the minimum,
median, and maximum data values, as well as the interquartile
range. Based on the EEG recordings and subsequent analysis,the canonical Box Plot was found to place the least amount
of strain on the users cognitive resources for the given tasks.
The study suggests correlation between task difficulty and both
reaction time as well as cognitive load; as the difficulty of the
task increases, so does the computed cognitive load and also
the reaction times.
This study presents an initial step into the use of direct brain
measurements for evaluating the effectiveness of different visualization techniques. Additional studies exploring the relationship between cognition, working memory, and the visual
system will provide further insights into the human factors of
how to visually convey abstract information.
5

B IO -F EEDBACK LOOP FOR G RAPHICS A PPLICA TIONS

Given that EEG has proven to be a promising approach for
neural feedback in BCI [8], we investigate a novel method to
aesthetically enhance videos and images based on a person’s
perceptual and emotional response, as measured by an EEG.
The idea is to explore the possibilities of more interactive uses
of EEG as direct input to rendering algorithms. Our example
applications represent a particularly challenging problem since
perceived image quality is not always an objective measure.
While up to a point, people can largely agree on what distinguishes a higher-quality rendering from a lower-quality image,
when it comes to visual aesthetics, there exist considerable diversity of people’s personal taste. What’s worse, when asked
to explain our visual preferences, we typically find it exceedingly difficult to reflect on our aesthetic predilections, or to find
objective reasons for their justification.
We investigate the hypothesis that both general visual quality as well as individual preferences can, up to a point, be reliably and reproducibly assessed based on EEG recordings. We
record a person’s brain response to rendered images and, based
on a previously trained Support Vector Machine (SVM), immediately determine from the EEG signal a ”visual appeal” score.
The score is used to drive a numerical optimization routine that
varies the parameter values of the rendering algorithm, changing in turn the rendered image observed by the user. This optimization loop drives the rendered output towards an aesthetic
optimum, as perceived by the individual user. 2 To evaluate our
approach, we consider two different application scenarios. In
the first scenario, static photos of real-world scenes are EEGoptimized with respect to saturation, brightness, and contrast
according to individual taste. In the second scenario, three ren2 For the purpose of this paper we use the term ‘quality‘ to mean noise or
artifacts and ‘aesthetics’ to mean the ‘look’ or atmosphere of an image.

Fig. 4: The framework of the optimization loop requires a
training phase (upper part), which is conducted only once after which the loop will optimize any video or image based on a
single trial (lower part).

dering parameters are varied to optimize the general appeal of
an animation sequence [10].
5.1

Components

Fig. 4 shows the main components of our EEG-driven optimization loop. There is a one-time training phase required to teach
the SVM classifier the difference between the neural response
to pleasing versus displeasing image versions. Once the classifier is trained, it can optimize an image independent of content for any user based on a single trial EEG [9]. The user
sees an image or a video, while the EEG is recorded and SVMclassified. The classifier calculates a score from the EEG data
reflecting the user’s ‘liking’ for the image or video. The optimizer, in turn, varies a pre-defined number of parameters of
the rendering algorithm in response to the score. The rendering
algorithm then re-renders the image or video corresponding to
the new parameter values, which is again displayed to the user.
This loop is iterated several times until no further increase in
the score is observed.
Our optimization framework is applicable to any rendering
algorithm that generates still images or animated sequences and
whose output quality varies depending on some set of parameter values. The modular set-up allows for easy replacement of
the rendering component to optimize different rendering algorithms.
5.2

EEG Data Analysis

To record the EEG data, we use a BioSemi ActiveTwo system
with 32 electrodes placed on the scalp according to the International 10-20 system (Fig.1a). The recorded data were referenced to the mastoids and filtered with a high-pass filter with a
cut-off frequency of 0.1 Hz to remove DC-offset and drifts. All
trials with blinks, severe eye movements, and too many alpha
waves were manually removed. EEG data is recorded while the
user is watching the rendering output on screen. The EEG data
is then sent to the SVM classifier along with synchronization
information as to the onset of the image or video.
To process the EEG data before classification, we use the
Complex Discrete Wavelet Transform (CDWT) using a separate Hilbert Transform followed by two wavelet transformations. For analysis, we cut out a two second chunk with half
a second before the image/video starts. We then remove the

We use an EEG to create a neural feedback loop which uses the brain’s response to appealing and unappealing images with
the goal to generate aesthetically pleasing image versions (Fig.1a). Analysis of the EEG data shows a distinct and reliable
difference in the neural response to images with the same content but different parameter settings for saturation, contrast,
and brightness. This work intends to answer two questions: is it possible to measure the preference for images with varying
levels of pleasingness? And if so, is it possible to computationally model the EEG measurements to optimize images based
on personal preferences? We address these questions by first analysing the brain’s response to appealing and unappealing
versions of the same image for different participants. Based on a trained SVM classifier we are then able to create optimized
versions of the images, tailored to each participant’s EEG-deduced appeal (Fig. 1).

(a) The neural feedback loop used to optimize (b) Original Flowers Image
image and video parameters

(c) Optimized Participant1

(d) Optimized Participant2

Figure 1. EEG feedback loop are unique for optimizing images and videos.

Fig. 3: Original image versions used for SVM training (from MIT-Adobe FiveK Dataset)
baseline drift from the signal to avoid introducing erroneous
high frequencies in the Hilbert Transformation.
For classification of EEG data after processing we use a standard support vector machine (SVM). Given that we are interested in the overall power for each frequency band over time we
use the absolute of the complex wavelet coefficients as input to
the SVM rather than the complex numbers. Also, we limit the
data to the 8Hz to 32Hz range where waking neural activity occurs. Once the SVM has been trained, we use the probabilistic
version, i.e. the one that produces not only a classification but
also a confidence value of how accurate the classification is, for
generating a score value for any EEG input. The score value
is simply defined as the confidence of the input belonging to
the class of good images. A confidence below 50% means the
image is more likely to belong to the class of bad images.
In order to aesthetically optimize our given set of rendering parameters we not only need a score function that tells us
how good the presented image is but also an optimization algorithm to change the parameters accordingly. We assume that
our score function has a single maximum, i.e. it is unimodal,
and we are interested in finding a good value close to this maximum rather than its exact location. For the actual optimization,
i.e. the task of estimating new parameter values to test for, we

chose the basic Nelder-Mead heuristic. The main advantage
of the Nelder-Mead heuristic is its fast convergence compared
to other direct evaluation methods. The initial step in every
Nelder-Mead driven optimization is to set up the initial simplex
x1 ...xn+1 , consisting of N + 1 locations, i.e. parameter settings,
for N parameters, and to evaluate the score function for these
parameter values. We start with some initial parameter settings,
present the corresponding image, capture the EEG data, process the data and run it through the SVM to produce the score
value [10].
We verify the viability of our approach, we consider two
application scenarios: optimizing still-image photographs according to users’ individual preferences, and optimizing overall
rendering quality of short animation clips. For each application
scenario, we train a separate SVM using exclusive visual content and other participants than when we test the optimization
framework.
5.3

Application: Image Personalization

In the first optimization scenario saturation, brightness and contrast of a photo are varied to obtain aesthetically pleasing versions of the original image. Prior to performing the evaluation experiments, EEG data is acquired for SVM training. 2
male and 8 female, healthy participants of an average age of 25

(a) Original input image

racy of the image in terms of color or details that the users expressed interest in but more often than not, their preference for
the enhanced image was based on ’how it made them feel’,i.e.
by the atmosphere of the image version.
We also ran a study with 50 participants comparing the optimized images against images created from random parameters.
This study was conducted to ensure that our results were not
due to random parameter generation. The average score of the
optimized images was 3.6 compared to 2.2 for the random images, showing that the optimized parameters are much better on
average than randomly selected parameters.
5.4

(b) Optimized Version 1

(c) Optimized Version 2

(d) Photographer Version 1

(e) Photographer Version 2

Fig. 5: EEG-optimized results are unique for each individual and competitive in terms of visual appeal with the
photographer-enhanced versions.

years and with normal or corrected-to-normal vision took part
in collecting the EEG data needed to train the SVM. The basic
stimuli for the training phase consisted of 23 randomly selected
images from the MIT-Adobe FiveK Dataset [4], Fig. 3. The
database has a total of six versions for each image, the original
photo plus five different, professional photographer-modified
versions. To gather our SVM training data, we presented
our participants with the original photo, two of the expertretouched aesthetic versions, as well as a clearly over-saturated
and over-exposed version, totaling 5 versions per photo and 115
different images overall. Once the SVM was trained with this
data, the classifier was ready to categorize a single trial and
calculate a visual appeal score for individual photographs. We
evaluated our method with 15 users who did not participate in
the SVM training phase. Their average age was 25 years, and
they had no professional experience in image or video editing.
The evaluation experiment was done on 12 randomly selected
photos from the MIT-Adobe FiveK Dataset [4] which had not
been used for SVM training before. For each photo, the optimization loop was initialized with the original image version.
To personally optimize the photo, the optimization loop was set
to vary the three parameters saturation, brightness and contrast.
Our optimization loop creates distinct versions of original
images (Fig.5). These versions are unique to each individual
and often quite different from the photographer-enhanced versions. After each image optimization, we had detailed discussions with the participants regarding the optimized images. All
the participants preferred their own optimized version over the
original image. Interestingly, often times it was not the accu-

Application: Guided Image Filter Parameter Optimization

In the second optimization scenario, we evaluated the performance of our technique when optimizing visual quality of a
guided image-filtered, ray-traced animation sequence. Filtering
noisy images is a fundamental image enhancement operation
in video and image processing, but also in global illumination
methods based on Monte Carlo sampling. The guided image
filter is a powerful, edge-aware de-noising filter that uses additional model information such as normals and depth as guide
to smooth out image noise while not affecting scene information [10]. The filter features three parameters, filter radius and
two epsilon values, that need to be selected and whose optimal
values depend on scene characteristics. All three parameters
affect the rendering result in different ways, controlling both
surface smoothness and amount of detail. For training test data,
we ray-traced the popular Crytek Sponza scene and the Sibenik
Cathedral. We used a real-time global illumination ray tracer
to create in total 28 different versions of both scenes for SVM
training:
1. Four un-filtered sequences with 1, 4, 64 and 256 samples
per pixel,
2. Six sequences using the guided image filter with 1 and 4
samples per pixel, each with three different radii,
3. Four sequences using the Á-Trous wavelet transform filter
with 1 and 4 samples per pixel, each with two different
radii.
To test our EEG feedback loop we used a scene from the
blender movie Sintel. The filter parameters to be optimized
were radius, epsilon(normal) and epsilon(depth). We chose
to limit the radius range between 2 and 32, and also both epsilon values could vary within a generously wide range. Optimization started from the original rendered sequences and subsequently the EEG-driven optimized versions. In this experiment, the optimization process terminated automatically when
the variation of parameter values between subsequent iterations
became too small. The iteration step with the highest EEGderived score was selected as the final optimization result for
each user.
To evaluate the preference of the EEG-optimized videos to a
general audience, we conducted a perceptual experiment with
23 participants. The participants were asked to rate 7 video versions out of which 6 were optimized by our framework and one

had been optimized manually by an expert. The participants
had not been part of the training or testing phase. They were
shown the animation sequences and were asked to rate each
from 1(worst) to 5(best), based on the quality of each video.
They were allowed to view each sequence as many times as
needed to make a decision about the rating but were not informed about the parameters or if the video was manually optimized or EEG-optimized. We designed the experiment to ask
the participants to rate the videos as opposed to simply picking
one best version because we wanted to know how close together
in terms of preference the different versions were. We ran a two
tailed t-test on the data from these participants. The t-test probability for the null-hypothesis P(H0) indicated that the ratings
of the optimized versions are from the same random population
as for the manually optimized one. The scores for each version
were similar and the t-test analysis showed that all optimized
versions were statistically indistinguishable from each other
The results show that our EEG-optimized video sequences
are visually as pleasing as the expert optimized sequence. More
importantly our results indicate that it is possible to determine
the perceptual quality of a video sequence from single-trial
EEG measurements without the need for a reference video.
This is especially interesting because videos have been known
to be notoriously difficult to analyze using EEG techniques.
Videos contain movement and rapid content changes which
makes it very hard to determine whether EEG signals are due
to quality or due to changing video content. Since we tested
our method with video content that the classifier had not been
trained on, the results suggest that our approach is able to discriminate between visual quality and changing content.
6

Recent years have seen an emerging interest within the
BCI community for the application of EEG devices to
gaming environments [1]. Entertainment companies such
as Neurosky, Uncle Milton and Mattel have released
many EEG-based games like ‘Star Wars Science Force
Trainer’ or ‘MindFlex’. Most current games are based on
the user’s conscious effort to move an object or achieve a
goal. Current research aims to use EEG to access implicit
emotions and responses which can then be used to change
ongoing game play, like the ‘AlhaWOW’ game created by
Nijholt et al. which detects activity in the alpha frequency
to control aspects of the game ‘World of warcraft’ [2].
[1] J. B. Van Erp, F. Lotte, M. Tangermann, et al.
Brain-computer interfaces: beyond medical applications.
Computer-IEEE Computer Society-, 45(4):2634, 2012.
[2] Nijholt, A., Bos, D. P. O., & Reuderink, B. (2009).
Turning shortcomings into challenges: Braincomputer
interfaces for games. Entertainment Computing, 1(2),
85-94.

been an interest in creating applications for the use of EEG in
gaming environments, it is still in its infancy and requires research on a wider scale. By connecting our brains via EEG
with computer graphics applications, many intriguing possibilities will emerge.

D ISCUSSION

The presented projects have shown that not only is it possible
to determine the quality of an image or video using EEG, it is
also possible to modify that quality in a direct feedback loop till
an optimal solution is reached. Neural data constitutes a viable
measure of aesthetic appeal for images and videos. However,
EEG is not without its limitations. Analysing responses based
on EEG data does not work well for small changes in visual
stimuli (image/video). This is because an EEG does not pick
up small neural changes in response to minute changes in images. Also, our neural-feedback loop’s binary output does not
account for the entire range of emotional and mental states involved in the perceptual scenarios. Additionally, the interpretation of EEG-based measures for such abstract concepts such as
’appeal’ or ’atmosphere’ are purely empirical and still await an
explanation of their neural origins.
7

EEG and Games

O UTLOOK

EEG has begun to enter computer graphics research as an exciting new modality to assess our perception of rendered images.
There exist many graphics problems that can benefit from its
use. For example, it is ideally suited for the quality assessment
of 3D images and videos. Similarly, we are currently exploring
the possibility of quantifying the Uncanny Valley effect from
EEG data. Another interesting area of research is the automatic changing of a gaming environment based on emotional
response via EEG. Although over the past few years there has

R EFERENCES
[1] G. L. Ahern and G. E. Schwartz. Differential lateralization for positive and negative
emotion in the human brain: EEG spectral analysis. Neuropsychologia, 23(6):745–
755, 1985.
[2] E. W. Anderson, K. C. Potter, L. E. Matzen, J. F. Shepherd, G. A. Preston, and C. T.
Silva. A user study of visualization effectiveness using EEG and cognitive load.
Computer Graphics Forum, 30(3):791–800, 2011.
[3] S. Arndt, J. Antons, R. Schleicher, S. Moller, and G. Curio. Using electroencephalography to measure perceived video quality. 2014.
[4] V. Bychkovsky, S. Paris, E. Chan, and F. Durand. Learning photographic global
tonal adjustment with a database of input/output image pairs. In Computer Vision
and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 97–104. IEEE,
2011.
[5] P. Clinton. Review: ’polar express’ a creepy ride. CNN, 2004. http://edition.
cnn.com/2004/SHOWBIZ/Movies/11/10/review.polar.express/.
[6] D. Cunningham and C. Wallraven. Experimental design: From user studies to psychophysics. AK Peters, Ltd., 2011.
[7] S. Koelstra, C. Muhl, M. Soleymani, J.-S. Lee, A. Yazdani, T. Ebrahimi, T. Pun,
A. Nijholt, and I. Patras. Deap: A database for emotion analysis; using physiological
signals. Affective Computing, IEEE Transactions on, 3(1):18–31, 2012.
[8] A. Lécuyer, L. George, and M. Marchal. Toward adaptive VR simulators combining
visual, haptic, and brain-computer interfaces. Computer Graphics and Applications,
IEEE, 33(5):18–23, 2013.
[9] M. Mustafa, S. Guthe, and M. Magnor. Single trial EEG classification of artifacts
in videos. ACM Transactions on Applied Perception (TAP), 9(3):12:1–12:15, July
2012.
[10] M. Mustafa, S. Guthe, and M. Magnor. The Human in the Loop: EEG-driven Photo
Optimization. Technical report, TU Braunschweig : Computer Graphics Lab,, 2013.
[11] M. Mustafa, L. Lindemann, and M. Magnor. EEG analysis of implicit human visual
perception. In Proc. ACM Human Factors in Computing Systems (CHI) 2012, May
2012.
[12] S. Scholler, S. Bosse, M. Treder, B. Blankertz, G. Curio, K. Muller, and T. Wiegand.
Toward a direct measure of video quality perception using EEG. Image Processing,
IEEE Transactions on, 21(5):2619–2629, 2012.

