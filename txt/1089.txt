Augmented Iterations: Integrating Neural Activity in
Evolutionary Computation for Design
Pierre Cutellic, Fabien Lotte

To cite this version:
Pierre Cutellic, Fabien Lotte. Augmented Iterations: Integrating Neural Activity in Evolutionary
Computation for Design. eCAADe 2013, Sep 2013, Delft, Netherlands. 2013. <hal-00843050>

HAL Id: hal-00843050
https://hal.inria.fr/hal-00843050
Submitted on 10 Jul 2013

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Augmented Iterations
Integrating Neural Activity in Evolutionary Computation for Design
Pierre Cutellic1, Fabien Lotte2
The Computational Monkeys, France, 2INRIA Bordeaux Sud-Ouest, Labri, France

1

http://www.compmonks.com 2http://team.inria.fr/

1

compmonks@compmonks.com 2fabien.lotte@inria.fr

1

Abstract. The principle of Augmented Iterations is to create shapes of progressively
higher complexity, thanks to a fast neuronal selection of shapes among several possible
evolving designs. Such a process is made possible by the use of a brain signal known as
P300, which appears when a user perceives a rare and relevant stimulus and can be used
for intricate pattern recognition and human computation systems. We aim at using this
P300 signal to identify the (re)cognition of shapes or designs that a user finds almost
instantaneously relevant and noticeable, when exposed to a rapid visual flow of
variations of such shapes or designs. Using evolutionary algorithms, the shapes identified
as those triggering a P300 in the user’s EEG signals is selected and combined to give rise
to geometrical aggregations of a higher complexity. These new shapes replace the
previous ones in the rapid flow of variations presented to the user, hence iterating the
evolutionary design.

Keywords. Neurodesign; Generative Design; Integrated Cognition; Evolutionary
Computation.

1. Introduction
Since research on Brain Computer Interfaces : BCI began in 1970s at the
University of California Los Angeles and revealed the first apparition of the
expression recorded in scientific literature (Vidal, 1973, 1977), the evolution of
interfacing the nervous system in general or the brain specifically to a device or a
computer system in order to restore or augment animal and human abilities to sense
its environment, to communicate, to move into space as well as to perform cognitive
tasks grew fast (Wolpaw et al, 2002). Despite the youth of the field of research,
applications development have been intensive specially in developing
neuroprosthetics for medical purposes at various ranges of invasiveness into the
human body. In parallel to that development and the one of technologies of
information and communications : TIC, private companies and open-source initiatives
led to the popular access of even cheaper and non-invasive devices using the
evolution of Electroencephalography : EEG and signal processing technologies.
Between Neurosky, eMotiv, openEEG, G.Tec or many other companies and initiatives,
the accessibility and precision of the technology led to open the capacity to create an
effective loop between the neural activity of the human body and computers to other
fields of research and experimentations (Lécuyer et al, 2008; van Erp et al, 2012).
Along with that evolution of accessibility to both technological innovations and
biological material, a critical aspect of integration opened to computational design.
Since 2005, and the 3D mappings of brain activities realized by Marcos Novak and
Mark Cohen as a spatial representation of intricate phenomenons leading to creative
acts (Novak, 2005), design experiments have evolved in either the multi-dimensional

representation of the neural activity as for 4D brain mapping projects (Collins and
Hasegawa, 2011) or the expansion of domotic technologies and human-machine
cooperations by controlling external devices to modify the physical space, as for the
CogniGame (Festo, 2012). But as we are advancing in the comprehension of
morphogenesis for generative design and the evolutive integration of ambient data
into that very generation, many transitions in the process between one step to the
other is yet constrained under the necessity of human cognition and empiristic phases.
The cognitive task of performing a selection of satisfactory generated results is yet to
be performed as a separate and complementary process in the development of a
morphogenetic design and leaving an important blur between a systematized design to
satisfy a predefined set of rules and constraints and the judgment/selection of a
satisfactory performance. The ongoing research described hereafter intends to
establish a critical and effective link between the computation of human cognition and
the evolution of design models by exploiting recent advancements in neurosciences to
interface and integrate the human capacity to compute cognitive selections at fast
pace in an iterative and evolutionary design loop. We define as NeuroDesign the
fluent process to compute such design models merging both human cognitive
performances and machine systemic capacities in a single loop. This first definition
was first experimented and challenged at the beginning of 2012 and revealed the very
potential of accelerating the process toward a closer definition of a generative design
model combining those two aspects by augmenting every iterations with the
acquisition and treatment of a peculiar neurosignal produced by the human brain
when a specific recognition is made. This last definition is called Augmented
Iterations.
This paper is organized as follows: Section 2 gives more details about the
design of a BCI and its use in the process. Then, Section 3 presents our work and
experimentation on Neurodesign. Finally, Section 4 proposes the refinement of the
Neurodesign definition as the current step of investigation: Augmentation Iterations.

2. Designing a BCI
BCI are communication systems that enable a user to send commands to a
computer by means of brain activity only, this activity being generally measured by
EEG (Wolpaw et al, 2002). A typical example of a BCI would be a system with which
a user could move a cursor, on a computer screen, towards the left or right by
imagining movements of the left or right hand, respectively. Designing and using a
BCI consists in setting up 4 main components, illustrated in [Figure 1].

Figure 1 Operation principle of a BCI

First, the user’s brain activity must be measured. To do so, most BCI systems are
based on EEG, which measures small electrical current on the user’s scalp reflecting
the synchronous activity of millions of neurons. It should be mentioned that current
EEG-based BCI technology is far from being able to (and may never be able to)
identify any kind of mental states in the user’s EEG signals. As such, current BCI
measures the user’s brain signal while he/she is involved in specific mental tasks
which lead to specific EEG patterns. As an example, numerous BCI are based on
Motor Imagery, that is they can recognize specific EEG patterns that appear when the
user is imagining limb, mostly hands or feet, movements (Pfurtscheller and Neuper,
2001). Another widely used EEG pattern is known as the P300, which is a Positive
increase of the EEG signal amplitude which appears 300 ms after the user perceived a
rare and relevant stimulus (Donchin et al, 2000). Once the user’s brain activity
measured, the next step consists in analyzing and processing the measured brain
signals in real-time in order to identify a specific EEG pattern, such as that
corresponding to an imagined hand movement or a P300. This is achieved using
advanced signal processing and machine learning algorithms whose details are
outside the scope of this paper. Interesting readers could refer to : Lotte et al (2007)
and : Bashashati et al (2007) for details on these aspects. One point must be
mentioned though: in order to identify a given user’s EEG patterns, the BCI system
must be calibrated specifically for this user since there are currently no one-size-fit-all
universal BCI. This is achieved thanks to several examples of EEG signals of this
given user, collected while he/she performs the targeted mental tasks. In practice, this
means that before using a BCI, the user must first participate to a calibration session
during which examples of his/her EEG signals will be collected.
Once the EEG signals measured, processed and identified, we can assign a given
command to the recognized EEG pattern. For instance, we could associate a
recognized imagined left hand movement to moving the cursor towards the left,
whereas an imagined right hand movement will be associated to a cursor movement
towards the right. Finally, the loop can be closed by providing a feedback to the user,
in order to let him know which EEG pattern the system has recognized. This will help
the user to learn how to use the BCI, as well as help him/her to improve his/her
control over his/her own brain activity. Indeed, BCI control can be seen as a skill,
which improves with practice. In other words, the more the user performs a given
mental task, the better at it he/she will become and the clearer the EEG patterns will
be. Overall, this will make the recognition performance of the whole system better.
Because they do not rely on any actual motor activity, BCI have quickly become a
promising device for people suffering from severe paralysis, since they offer them a
unique alternative way to communicate (Birbaumer et al, 2000). More recently, the
application scope of BCI have even widen, with several new fields benefiting from
BCI technologies for healthy users, such as video games, virtual reality, humancomputer interaction, cognitive monitoring or neuromarketing (Lécuyer et al, 2008)
and (Van Erp et al, 2012). In this paper, we propose and explore a new application
area for BCI: Neurodesign.

3. Experimenting Neurodesign
As mentioned previously, BCI brings together a capacity to merge both human and
computer performances for cognition and calculus. It operates as a heuristic graft
in the evolution of a systemic design to seek novel solutions not only based on
optimal performances but also on the augmentation of process iterations by the
continuous cognition of what was preceding a current generation to define the
following generation. This particular notion of the Following Generation as
developed by : Malabou (2005) is here understood as a critical point to underline a
different understanding of generative design where the filiation of one generation
after another is more than, and also different from, the very linear parent-children one.
Therefore, ruled-based design implemented in such a system to evolve does not only
represent spatial optimums but an intricate resolution of computational aesthetics.

3.1.

Proof of Concept

To experiment such a definition we first organized an inter-semester workshop
which have been taking place in an architectural school in February 2012 and
composed of a mixed range of twenty architecture students. The general focus of this
event was to experiment logical associations and formal dissociation between
algorithmic, geometry, and related neural activity. On the one hand, the challenge of
such a synthetic approach was on the definition and effective use of an appropriate
and stable BCI and on the other, to develop methods of conception based on
systematic processes of form generation and cognition. The evolution of this
workshop has then be constrained by the implementation of an interface, the
development of generative models and their association within the following
framework for evaluating the very first results of this initiative and identifying their
potentials for an ongoing research described hereafter. More precisely, the experiment
was divided between the setup of the BCI, the acquisition of brain signals, the
analysis of those signals and the development of generative models as an integrative
design loop to act on virtual models without physical movements [Figure 2]. Other
aspects of the implementation of such a loop will be mentioned as the signal
processing, classification (pattern recognition), translation into a command and the
perceptive feedback or Neurofeedback.

Figure 2 First workshop, a participant in the process of moving a cube in a 3 dimensional space.

3.2.

Hardware / Software

The BCI was physically formed of
a non-invasive BCI. More precisely,
brain signals were measured using the
g.USBamp EEG device (G.Tec,
Austria), with 15 EEG sensors,
localized at the standard positions Fz,
FC3, FCz, FC4, C5, C3, C1, Cz, C2,
C4, C6, CP3, CPz, CP4, Pz [FIGURE
3]. These electrodes are indeed
localized over the motor cortex areas of
the brain, and as such ideal to identify
imagined movements of hands or feet.
EEG signal processing and the
neurodesign application ran both on the
same standard laptop computer.
Figure 3 Standard localisation of EEG sensors. The head is seen here from the top, the nose facing upwards.
Electrodes used in the Neurodesign experiment are indicated in red color.

In the objective to make an accessible design experiment from this research in
the future, all software used are both open-source and free to use. The acquisition and
exploitation of brain signals has been made possible by the use of OpenViBE [1] a
software platform used for the design, test and use of BCI (Renard et al, 2010). It
features the real-time processing of brain signals and can be used to acquire, filter,
process, classify and visualize such signals in real-time. OpenViBE was used here to
digitally acquire EEG signals, process them and identify imagined limb movements

(left hand, right hand or foot movements) in real-time. To distinguish imagined left
hand movements from imagined right hand movements, a standard algorithm was
used, based on Common Spatial Pattern (Blankertz et al, 2008) and Support Vector
Machine (Lotte et al, 2007). Imagined foot movements were identified as described
in : Lotte et al (2008). Once the mental state of the user identify, this state was sent to
Processing [2], a popular software used to teach fundamentals of computer
programming in a visual context and allows for quick assertion in design experiments.
Processing was used simultaneously to the set-up of the hardware and calibrations to
teach students how to transform an architectural or design model into a graphical
programming model. Both softwares allowed to progressively bring the notions of
systemic design and shape generation to students while trying to translate ruled-based
design into lines of code. Finally, The Processing and OpenViBE softwares were
connected using the VRPN protocol [3]. This enables Processing to receive mental
commands identified in EEG signals and sent by OpenViBE at a fast pace. Ultimately,
the stable results of these applications will be compiled and made accessible through a
web base application at the end of this first research [4].

3.3.

Refining Definition

Beyond technical improvements in signal acquisition and analysis as well as
translations into the design model, this first experiment allowed us to refine and
extend the previous definition of Neurodesign. If such an interface can be validated to
integrate a design process, it doesn’t improve it by any means or bring novelty to the
evolution of a geometrical model. The only powerful aspect of this definition would
be to bring injured or physically handicapped people new creative means. But
imagined limb movements could never surpass a real movement as would do a simple
click on a mouse to move a virtual object from one place to another. Therefore it was
not the human computation of movements in space that we would integrate anymore
but the very neural reaction to a change of state in a particular model or shape.
The synaptic efficiency to compute the cognition of intricate psycho-physiological
events in reaction to an environmental change would be a more promising resource to
integrate in terms of immediacy of response and emergence of novelty.
4. Implementing Augmented Iterations
The general idea behind the augmented iteration Neurodesign concept is to create
shapes of progressively higher complexity, thanks to a fast neuronal selection of
shapes among several possible designs and the use of evolutionary algorithms. To do
so, we plan to use the brain signal known as the P300, which appears when a user
perceives a rare and relevant stimulus and can be used for intricate pattern recognition
and human computation systems. We aim at using this P300 to identify the
(re)cognition of shapes or designs that a user finds almost instantaneously relevant
and noticeable, when exposed to a rapid visual flow of variations of such shapes or
designs. Using evolutionary algorithms, the shapes identified as those triggering a
P300 in the user’s EEG signals will be selected and combined to give rise to
geometrical aggregations of a higher complexity. These new shapes will replace the
previous ones in the rapid flow of variations presented to the user, hence iterating the

evolutionary design [Figure 4].

Figure 4 Graphical explanation of an iterative model selecting shapes by the recognition of a P300 signal.

In order to be more specific, here follows how we envision this application: the
user will be sitting in front of screen, wearing an EEG cap (see following section
Hardware / Software interface for electrodes location) connected to the computer.
This user will be presented with a rapid visual flow of different shapes (that would
mostly be variations of a given shape). Each shape will appear several times in the
flow of images. This user will be instructed to pay attention to this shape and to
concentrate on the most relevant and aesthetics according to him. While the user is
watching the visual flow of shapes on screen, his/her EEG signals will be collected
and analyzed in real-time. Each time a shape is displayed on screen, a BCI will be
used to identify whether this shape triggers a P300 in the user’s brain activity. If it
does, it probably means that the user consciously or unconsciously finds this shape
relevant in some way. As such, the amplitude of the P300 or the number of times the
P300 appears for a given shapes gives use a Fitness Score, indicating how cognitively
relevant this shape is for the user. Once each shape has been presented a given
number of time, we can mark them with the Fitness Score described above. This score
will be used to select and combine these shapes into several aggregations of shapes of
higher complexity. These new shapes will then replace the previous shape in the rapid
flow of visual shapes, and the process will iterate (i.e., the process will start again at
step 1, using these new shapes). In this way, several shapes of increasingly complex
design and hopefully increasingly more relevant will be created, based on the
cognitive response (the P300) of the user.

4.1. Hardware / Software
For this system as well, it would be
appropriate to collect EEG signals using
the g.USBAmp. However, since we aim
at recognizing a different brain signal,
here the P300, different sensor locations
should be used. More precisely, sensors
located in positions Fz, Cz, P3, Pz, P4,
PO7, PO8 and Oz would be more
appropriate [Figure 5], since the P300 is
expected to occur in these locations. A
standard laptop would still be enough to
run the EEG processing and neurodesign
applications.
Figure 5 Location of sensors that are relevant to identify a P300 in EEG signals, and that would use for
augmented iterations neurodesign.

Here again, combining OpenViBE for BCI design with Processing for shape
generation, display and iteration would still be ideal. Concerning EEG signal
processing, recognizing the P300 in EEG signals could be achieved using dedicated
algorithms already available in OpenViBE, such as xDAWN, see, e.g. : Congedo et al
(2011) and : Rivet et al (2009).

4.2. Current Design Experiment
By developing and refining the previous definition of Neurodesign to seek a
working model of Augmented Iterations we found an efficient combination to
explore: the implementation of an evolutionary ruled-based design model merging
with the human computation of intricate change of state in an evolutive shape by the
cognition of environmental information existing beyond geometry or the rules
defining the model itself. The framework and the process defined in that paper
explains the development of the reflexion leading to the current state of this research
and propose new opportunities to investigate the potential emergence of novelty in
generative design. The current process of design experiment aims at extending and
refining this actual definition. By using previously established knowledge and
experience we developed a peculiar generative model which detailed description goes
beyond the scope of this paper but will be briefly introduced. We chose to first
develop models which could create smooth and generic geometries in order to enable
more freely cognitive reactions without sticking instantly recognizable common
shapes or geometries. Therefore, as a starting point, we implemented an isosurface
enveloping an evolving set of particles in four dimensions. This envelope being
rendered as a mesh and visually enriched by custom shaders. The role of these custom
shaders are here precisely to augment the difficulty of instant visual recognition of
shapes by the human brain and stimulates cognitive performances at a higher level
[FIGURE 6].

Figure 6 Current experiment in generative design using the principle of augmented iterations with isosurfaces,
particle systems and custom shaders.

To prevent a recognition of a certain repeatability, each iteration of the model is
set in a constant and random 3d rotation as well as the random movement of the
particles making the shape grow. Generation after generation, the model evolves
along the very protocol defined above and express a generative principle at a
stochastic level that only a human-computation system can process [FIGURE 7].

Figure 7 Generation samples of the current model of experimentation.From left to right and top to bottom:
generation 10, generation 20, generation 50 and generation 80.

References
A. BASHASHATI, M. FATOURECHI, R.K. WARD, G.E. BIRCH, “A Survey of
Signal Processing Algorithms in Brain-Computer Interfaces Based on Electrical Brain
Signals”, Journal of Neural engineering, 4, R35-57, 2007
N. BIRBAUMER, A. KÜBLER, N. CHANAYIM, T. HINTERBERGER, J.
PERELMOUTER, J. KAISER, I. IVERSEN, B. KOTCHOUBEY, N. NEUMANN, H.
FLOR, “The Thought Translation Device (TTD) for completely paralyzed patients”,
IEEE Transactions on Rehabilitation Engineering, vol. 8, pp. 190-193, 2000
B. BLANKERTZ, R. TOMIOKA, S. LEMM, M. KAWANABE, K.-R. MÜLLER,
“Optimizing spatial filters for robust EEG single-trial analysis”, IEEE Signal Proc
Magazine, vol. 25, pp. 41-56, 2008
M. CONGEDO, M. GOYAT, N. TARRIN, L. VARNET, B. RIVET, G. IONESCU, N.
JRAD, R. PHLYPO, M. ACQUADRO, C. JUTTEN, “‘Brain Invaders’: a prototype
of an open-source P300-based video game working with the OpenViBE platform”,
5th International BCI Conference, 2011
E. DONCHIN, K. SPENCER, R. WIJENSINGHE, “The mental prosthesis: assessing
the speed of a P300-based brain-computer interface”, IEEE Transactions on
Rehabilitation Engineering, vol. 8, pp. 174-179, 2000
A. LECUYER, F. LOTTE, R. REILLY, R. LEEB, M. HIROSE, M. SLATER, “BrainComputer Interfaces, Virtual Reality, and Videogames”, IEEE Computer, vol. 41, no.
10, pp 66-72, 2008
F. LOTTE, M. CONGEDO, A. LECUYER, F. LAMARCHE, B. ARNALDI, "A
Review of Classification Algorithms for EEG-based Brain-Computer Interfaces",
Journal of Neural Engineering, 4, R1-R13, 2007
F. LOTTE, Y. RENARD, A. LECUYER, "Self-paced Brain-Computer Interaction
with Virtual Worlds: a Quantitative and Qualitative Study 'Out of the Lab'", 4th
International Brain-Computer Interface Workshop, pp. 373-378, 2008
G. PFURTSCHELLER, C. NEUPER, “Motor Imagery and Direct Brain-Computer
Communication”, proceedings of the IEEE, vol. 89, pp. 1123-1134, 2001
Y. RENARD, F. LOTTE, G. GIBERT, M. CONGEDO, E. MABY, V. DELANNOY,
O. BERTRAND, A. LECUYER, “OpenViBE: An Open-Source Software Platform to
Design, Test and Use Brain-Computer Interfaces in Real and Virtual Environments”,
Presence: teleoperators and virtual environments, vol. 19, no. 1, pp. 35-53, 2010
B. RIVET, A. SOULOUMIAC, V. ATTINA, G. GIBERT, “xDAWN Algorithm to
Enhance Evoked Potentials: Application to Brain Computer Interface”, IEEE

Transactions on Biomedical Engineering, vol. 56, pp. 2035-2043, 2009
J. VAN ERP, F. LOTTE, M. TANGERMANN, "Brain-Computer Interfaces: Beyond
Medical Applications", IEEE Computer, vol. 45, no. 4, pp. 26-34, 2012
J. WOLPAW, N. BIRBAUMER, D. MC FARLAND, G. PFURTSCHELLER, T.
VAUGHAN, "Brain-computer interfaces for communication and control", Clinical
Neurophysiology, 113, 767-791, 2002
J. VIDAL, “Toward direct brain-computer communication, Annual review of
biophysics and bioengineering 2: 157-80”, 1973, and “Real-Time Detection of Brain
Events in EEG”, IEEE Proceedings 65: 633-641, 1977.
M. COLLINS, T. HASEGAWA, “NYC Neural Cartography Project”, Lincoln Center
Campus, Hearst Plaza, Brain-Wave data associated with 3D geometry, GSAPP Cloud
Lab, Proxy: http://www.thecloudlab.org/bci.html. ,2010
M. NOVAK, “Alloaesthetics and Neuroaesthetics: Travels Through Phenomenology
and Neurophysiology”, Journal of Neuroaesthetics Theory 4, July 2005, Conference
of Neuroaesthetics, Goldsmith University, London, United Kingdom.
FESTO AG & Co. KG, “Cognigame, New Operational Concepts for Human-Machine
Interaction”, W. STOLL, M. FISCHER, N. KÄRCHER, E. KNUBBEN, M.
GEHRING, C. MANGLER, Festo AG & Co. KG; A. GHARABAGHI, F. GRIMM,
G. NAROS, Centre for Integrative Neuroscience of the Tübingen University Hospital,
2012.
C. MALABOU, “La génération d’après,” Fresh Théorie, Paris, Léo Scheer, 2005.
URL:
[1] http://openvibe.inria.fr/
[2] http://processing.org/
[3] http://www.cs.unc.edu/Research/vrpn/
[4] http://www.compmonks.com

