EEG Based Brain Activity Monitoring using Artificial
Neural Networks
K. Amarasinghe, D.Wijayasekara, M.Manic
University of Idaho
Idaho Falls, Idaho, USA
unaw1815@vandals.uidaho.edu, wija2589@vandals.uidaho.edu, misko@ieee.org

Abstract—Brain Computer Interfaces (BCI) have gained
significant interest over the last decade as viable means of human
machine interaction. Although many methods exist to measure
brain activity in theory, Electroencephalography (EEG) is the
most used method due to the cost efficiency and ease of use.
However, thought pattern based control using is difficult due two
main reasons; 1) EEG signals are highly noisy and contain many
outliers, 2) EEG signals are high dimensional. Therefore the
contribution of this paper is a novel methodology for recognizing
thought patterns based on Self Organizing Maps (SOM). The
presented thought recognition methodology is a three step
process which utilizes SOM for unsupervised clustering of preprocessed EEG data and feed-forward Artificial Neural
Networks (ANN) for classification. The presented method was
tested on 5 different users for identifying two thought patterns;
“move forward” and “rest”. EEG Data acquisition was carried
out using the Emotiv EPOC headset which is a low cost,
commercial-off-the-shelf, noninvasive EEG signal measurement
device. The presented method was compared with classification
of EEG data using ANN alone. The experimental results show an
improvement of 8% over ANN based classification.
Keywords— Brain Computer Interface; Emotiv EPOC; EEG;
SOM; ANN

I.

INTRODUCTION

Brain Computer Interfaces (BCI) are communication
systems where humans interact with external devices using
merely their brain activity [1], [2]. Therefore BCI enables
humans to control machines without any peripheral muscular
activity [3] ,[4]. BCIs can be of immense benefit to people who
suffer from severe physical imparities by providing them with
a method to interact with machines [5]-[7], design of prosthetic
devices that can be controlled by thought [8]-[10] etc. Further,
it has been shown that BCI can be used for tele-operation of
robots [1], [11], gaming [12], [13] etc.
Theoretically, brain activity monitoring for BCI can be
carried out by several measurements such as; electric field of
brain (EEG), magnetic field of brain (MEG), functional
magnetic resonance (fMRI), position emission tomography or
functional near-field infrared spectroscopy(fNIR) [4], [14].
However, in practice, Electroencephalography (EEG) signal
measurement is the most used method used for BCI due to the
low cost measurement set up and low demanding technical
requirements [4], [15]. Extensive research on EEG based BCI
and modern technological advancements has resulted in

development of low cost consumer grade EEG-BCI devices.
Emotive EPOC [16], Neuroski Mindwave [17] and Myndplay
BrainBand [18] are existing examples for such consumer grade
hardware.
The accuracy of an EEG based BCI largely depends on its
ability to identify different thought patterns of the user, since
those thought patterns are transferred into commands [19]. The
thought pattern identification process relies on the performance
of the classification algorithm used [19]. EEG data are highly
noisy and multi dimensional [4], [19] and can contain noise
such as muscle movements, eye movements, eye blinks making
it extremely difficult to identify the portion of signal pertaining
to the intended BCI command [19].
Researchers have proposed various applications for EEG
based BCIs. In [1], the authors proposed a BCI for mobile
robot control. The authors investigated the feasibility of using a
consumer grade EEG-BCI device and concluded by stating it is
possible but significant improvements to the classification
algorithm should be made. Various different classification
methodologies have been explored in the past for different
applications. In [20], the authors have proposed an EEG
classification method which uses Support Vector Machines as
the EEG classifier. Similarly, in [21], the authors have used
Support Vector Machines based EEG classification for
identifying epileptic seizures. The authors used a neural
network classifier optimized with a genetic algorithm for EEG
based BCI for wheelchair control in [22]. In [8], the author
used Self Organizing Maps combined with Auto-regressive
spectrum to distinguish between hand and foot movement
through EEG classification.
This paper presents a methodology for identifying specific
thought patterns which enables brain activity based mobile
robot control that utilizes a combination of Self-Organizing
Maps (SOM) [24], and feed-forward Artificial Neural
Networks (ANN) [23] for thought patter recognition. The
presented methodology can be divided into 4 steps: 1) data
acquisition, 2) data pre-processing, 3) unsupervised clustering
by SOM, and 4) classification by ANN. The SOM is used to
cluster the pre-processed data in an unsupervised manner, and
a separate ANN is trained for each of the clusters in the SOM
which perform the final classification of the data.
The thought pattern identification method presented in this
paper was implemented for recognizing two thought patterns;
“move forward” and “rest” and was tested on 5 healthy

individuals. Emotiv EPOC neuroheadset [16], which is a low
cost, commercial-off-the-shelf, non-invasive EEG device, was
used for EEG data acquisition. Furthermore, the presented
methodology was compared to a thought pattern identification
process using only ANN. The experimental results show an
improvement of 8% over ANN based classification.
The rest of the paper is organized as follows. Section II
introduces Self-Organizing Maps and its functionality. Section
III describes the presented method. Section IV describes the
implementation of the presented method. Section V presents
the experimental results and finally, Section VI concludes the
paper.
II.


Step 2 - Sampling: Selecting a random input pattern bg
from the training dataset.
Step 3 – Competitive Learning: Finding the Best



Matching Unit (BMU) for the current input pattern bg . The
BMU is the neuron where the Euclidean distance between its


synaptic weight vector w , and the input pattern bg , is
minimal. The BMU can be expressed as,

SELF-ORGANIZING MAPS

The Self-Organizing Map (SOM) was developed by
Kohonen [24] which employs unsupervised learning. The
SOM comprises of a topological neuron grid typically
arranged in a 1D or 2D lattice [25], which defines the spatial
neighborhood of each neuron. SOM adjusts itself to the
topological properties of the input data set using unsupervised
winner take all learning algorithm together with cooperative
adaptation.
For a C dimensional input space, a synaptic weight vector,

w  {w1 ,...,wC } , is maintained by every neuron. A dataset B
containing G data points can be expressed as:
 

B  {b1, b2 ,....., bG }

Step 1 - Initialization: Randomly initializing all synaptic
weight vectors in the input domain.

(1)




BMU (bg )  arg min bg  w j , j  1, 2, ...,J

(3)

j



where, BMU (bg ) is the best matching unit for input pattern


bg , operator

denotes the Euclidian distance norm, and J is

the number of all the neurons in the SOM.
Step 4 – Cooperative Updating: Updating the synaptic
weight vectors of all neurons in SOM using the cooperative
update rule:




w j (i  1)  w j (i )   (i ) h j, BMU (b ) (i ) (bg  w j (i ))

(4)

g



where bg represents the gth data point. Each bg has C

dimensions. Thus b g can be expressed as:


bg  {v g ,1, v g ,2 ,....., v g ,C }

(2)


where v g , c is the c dimension of bg .
Initialization of all neurons is done randomly and they are
adapted iteratively based on the training input data set. The
training process can be described in several steps as follows
[25]:
th

(a)

where, i denotes the iteration,  (i ) is the learning rate and

h j , BMU ( b ) (i ) is the value of the neighborhood function for the
g

neuron k centered at BMU(bg ) .
Step 5 – Convergence Test: Checking whether the
specified convergence criterion is met. If the criterion is met,
learning process is terminated. If not, algorithm is moved back
to Step 2.
The learning process is controlled by two parameters; 1)
neighborhood function h and 2) dynamic learning rate  . A
Gaussian function centered at the selected neuron as the BMU

(b)

Fig. 1 Self-Organizing Map displayed in the output space (a) and in the input space adapted to 2D distribution of input points (b).

is typically used as the neighborhood function. Its amplitude
applied to neuron k can be expressed as,

h j ,BMU ( b

g)

 

 w w

j
BMU ( bg )

 exp  

2 2



2









TABLE I. FREQUENCY BANDS AND THEIR NOTATION [8]
Frequency Band

Notation

Frequency Range (Hz)

Delta




4-8

Theta





Alpha

(5)

Beta
Gamma

The size of the Gaussian neighborhood function is
determined by parameter  . When parameter  is
decreased, the size of the neighborhood deceases. Thus,
parameter  is decreased to improve convergence.
The learning process described in Steps 2-5 is repeated
until a specific convergence criterion is met. Typically,
training is terminated when the average weight change for an
iteration drops below a predefined value.
After convergence, the number of times each neuron j was
selected as a best matching unit (BMU) is stored as N BMU , j .

<4
8 - 13
13 - 25
>25

Step 4 - ANN based classification: Classifying the thought
patterns using the clusters obtained in Step 3.
Each step of the process is explained in detail below.
A. Step1: Data Acquisition
EEG data for T number of actions are acquired from an
individual using a non invasive EEG measurement device,
which includes several sensors. Therefore, if the measurement
device contains M number of sensors, a single data record
consists of M dimensions. A data record acquired at time t,
from a EEG measurement device with M sensors, can be
expressed as,

J

 N BMU , j  C
j 1

(6)

where J is the number of neurons and C is the total number of
data points.
Furthermore, for labeled data, the number of times each
neuron j was selected as a best matching unit (BMU) for each
class is stored as N BMU , j , f .
J

F

  N BMU , j , f

C

t
d t  {S1t , S2t ,..., S M
}
t

where S m is the value of the mth sensor at time t.
For real-time application, and reduced noise in the input
data, data processing performed for a window of n data records
at a time. The data window is designed to move through the
data set, moving one data record at a time. Thus, two adjacent
data windows; Wk and Wk 1 , can be expressed as,

(7)

j 1 f 1

where f is the class label and F is the number of classes in the
dataset

III.

(8)

SOM BASED THOUGHT PATTERN RECOGNITION FOR
MOBILE ROBOT CONTROL

This paper presents a methodology that benefits from a
combination of, unsupervised learning capability of SOM and
the non-linear classification capability of ANN to perform
thought pattern recognition. The thought pattern recognition
methodology presented in this paper can be divided into 4
steps:
Step 1 - Data Acquisition: EEG data acquisition for
different actions from an individual.
Step 2 - Data pre-processing: Converting the EEG data in
the time domain to the frequency domain. Then segmenting the
frequency data into the frequency bands that exist in brain
signals.
Step 3 - SOM based clustering: Clustering the thought
patterns using the frequency data obtained in Step 2 as inputs.

Wk  {dt , dt 1,..., dt  n }

(9)

Wk 1  {d t 1, d t  2 ,..., d t  n 1}

(10)

where, dt is the M dimensional data record acquired at time t.
B. Step2: Data Pre-Processing
Once the window Wk is acquired, the raw data is converted
into the frequency domain using Discrete Fourier
Transformation (DFT) method. The DFT method converts the
data in the time domain to the frequency domain enabling
segmentation of data with respect to frequency bands that exist
in EEG signals.
DFT is applied to each sensor separately to obtain the
frequency values for each sensor independently. Thus, for
window Wk , DFT is applied M times. The DFT conversion
process can be expressed as,

m
Wk

tq

 2i
1 n 1
n , q  0,... n  1
  Smt e
n t 0

(13)

where Ŵkm is the output of the DFT process for the kth window
for sensor m sensor and S mt is the raw EEG value of sensor m
at time t data record
The obtained frequency domain data is then segmented into
the five frequency bands that exist in brain signals. The
frequency bands are shown in Table I. Once the segmented
bands are obtained, the average power of each of the frequency
band for each sensor is calculated. For instance:
k
P( m
)

1 n 1
 p( mi )
n i 0

(14)
Fig. 2 Emotiv EPOC Neuroheadset [1]

where

P( mk )

is the average power of the frequency band

Alpha for the kth window and mth sensor and p( mi ) is the
power of Alpha for record i and sensor m for the kth window.
Similarly for all the other frequency bands the average powers
are calculated. Therefore, the set of average powers for are
k
k
k
Rm
 {P( m
), P(  mk ), P( m
), P( mk ), P( mk )} , for window

Wk for sensor m.
Further, each of the M sensor value for each window is
averaged to produce:
k
d k  {S1k , S2k ,..., S M
}

(11)

where d k is the averaged set of sensor values for window k
and:
t n

 S mi

S mk



i t

n

(12)

Using the power of the frequency ranges and the averaged
sensor values, the input vector U k for the SOM is generated:
k
U k  {d k , R1k , R2k ,..., RM
}

(15)

C. Step3: Unsupervised Clustering using SOM
Thus, for a given window k the input vector U k consist of
5M + M elements, making up a 6M dimensional input vector.
Further, for training, the action label assigned in data collection
is added to the window. This will act as the class label for the
method.
As mentioned in Section II, the SOM finds the BMU for
each input pattern and for each neuron and saves the number of
times which a neuron was selected as the BMU for the
respective class ( N BMU , j from (7)). The labeled training data
is sent to the SOM and once the specified convergence

criterion is met and the training process is completed, each
neuron in the SOM is assigned a class label l. This class label
is chosen as the largest of the N BMU , j, f values of the neuron.
Then for a given, unlabeled input U k , the cluster can be
extracted as the class label l of the neuron that was selected as
the BMU for U k .
D. Step4: Classifcation of Thought Pattern using ANN
Once the clusters are extracted from the SOM for the
training data, an ANN is trained for each of the clusters in the
SOM. This is done by first extracting the cluster label for each
of the input patterns in the training data, then using each cluster
to train a separate ANN. Each ANN will classify a given input
pattern into one of the T actions that the system identifies.
After each ANN is trained, a given input pattern can be
classified. Once a given input pattern is pre-processed using
Steps 1 and 2, it is fed into the trained SOM in Step 3. The
SOM assigns a label to the input patter according the cluster.
Then the ANN assigned to that cluster is used to classify the
input patter. Thus, for a given input patter only one ANN will
be used for classification. However, since the ANN is trained
on a clustered sub-set of data, a localized classification is
performed, thereby improving the classification accuracy.
IV.

IMPLEMENTATION

This section details the specifics of the implementation of
the presented SOM based thought pattern identification
methodology in this paper.
A. Data Acquisition
In this paper, EEG data acquisition was carried out using a
commercial-off-the-shelf, low cost, non invasive, BCI device,
Emotive EPOC Neuroheadset [16] (See Fig. 2). The Emotive
EPOC Neuroheadset was chosen because it has been shown
that it compares well with high grade research level equipment
and the information retrieved is reliable and sufficient for most
applications [26], [27], and its price and availability as a
consumer product.
The Emotive EPOC measures the brain activity of the
wearer by utilizing 14 sensors placed on the scalp, which
sensors are placed according to the international 10-20 system

TABLE II. CONFUSION MATRIX

Actual
Class

Classified as
“Move Forward”

“Rest”

“Move
Forward”

True Positives (TP)

False Negatives (FN)

“Rest”

False Positives (FP)

True Negatives (TN)

TABLE III
COMPARISON OF RESULTS OBTAINED BY SOM BASED ANN
METHOD AND ONLY ANN BASED METHOD

Users
1

Presented SOM based
ANN
Training
Testing
Accuracy
Accuracy
98.60%
95.33%

ANN
Training
Accuracy
97.80%

Testing
Accuracy
89.67%

2

98.80%

96.00%

96.80%

88.00%

3

98.20%

97.00%

95.60%

86.00%

4

99.40%

98.33%

97.60%

91.33%

5

98.40%

96.33%

96.80%

87.00%

Average

98.68%

96.60%

96.92%

88.40%

Fig. 3 Labels of the trained SOM for User 4

[27]. Since the Emotive EPOC headset was used for data
acquisition, M in (8) was equal to 14.
EEG data acquisition process was assisted by a Graphical
User Interface (GUI). The GUI provided an interactive 3D
object that acted as a visual stimulus in the data collecting
process. Alongside the values of the 14 sensors, an action label
was recorded for training and validating purposes.
B. Implementation of Thought Pattern Recognition
The size of the moving data window n described in Section
III was set to 100. Data pre-processing Step 2 (see Section III)
was applied to this window. Since data from 14 sensors were
recorded, the dimensionality of the input vector to the SOM
was 84.
The SOM was implemented as a 2D lattice which consisted
of 200 neurons arranged in a 2010 matrix. Each of the
neural networks trained contained 1 input layer consisting of
84 neurons, 2 hidden layers consisting of 10 and 5 neurons
each and an output layer consisting of one neuron.
500 data points (windows with size 100) was used for
training the SOM and the neural networks, and 300 data points
were used for testing.
V.

EXPERIMENTAL RESULTS

The presented methodology was applied to EEG data
collected from 5 individuals for two thought patterns, “move
forward” and “rest”. Specific implementation details given in
Section IV were used.
Fig. 3 shows the 2D lattice of the trained SOM for user 4,
along with class labels for each neuron.
The presented thought pattern recognition method was
compared to a typical thought pattern identification

TABLE IV. AVERAGE CLASSIFICATION RESULTS FOR ALL
USERS
Method

Train/Test

TP

TN

FP

FN

Training

98.96%

98.40%

1.60%

1.04%

Testing

96.93%

96.27%

3.73%

3.07%

Training

97.12%

96.72%

3.28%

2.88%

Testing

89.60%

87.20%

12.80%

10.40%

SOM - ANN

ANN

methodology using only ANN without the unsupervised
learning capability of SOM. Same EEG data were used for
both methods, while for the ANN only method, only Steps 1
and 2 were used for pre-processing. Furthermore, the same
ANN architecture was sued for both methods. The
performance of each method was measured by utilizing the
classification accuracy and true positive and true negative rates
(See Table II).The input patterns which were classified
correctly as "Move Forward" were considered to be true
positive and input patterns which were correctly classified as
"Rest" were considered to be true negatives. False positives
and false negatives were the patterns which were incorrectly
classified for the above patterns respectively. The classification
accuracy was obtained by calculating the percentage of
correctly classified instances out of all instances.
Table III shows classification accuracy achieved by each
method for each user, while Table IV lists the average true
positive, true negative, false positive and false negative rates
for each method. The presented method was shown to have a
higher classification accuracy in all cases while the overall
percentage improvement was 8% for the testing data.

VI.

CONCLUSION

This paper presented a methodology for identifying thought
patterns for brain activity based mobile robot control. The
presented method utilizes the unsupervised learning capability
of Self-Organizing Maps (SOM) and the classification
capabilities of Artificial Neural Networks (ANN) to highly
accurate achieve thought pattern recognition.

[10]

[11]

The presented method was implemented using a low-cost
commercial-consumer grade EEG device and was tested on 5
different individuals for identifying two thought patterns
related to mobile robot control. Furthermore, the presented
method was compared to a typical thought pattern recognition
method that utilizes ANN. The experimental results showed an
improvement of 8% over ANN based classification for testing
data.

[12]

As future work, the presented method will be tested on a
larger set of thought patterns collected from larger number of
individuals. The presented method will also be tested on real
world scenarios of controlling a mobile robot in an
environment with obstacles.

[15]

[13]
[14]

[16]
[17]
[18]

REFERENCES
[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

D. Wijayasekara, M. Manic, “Human Machine Interaction via Brain
Activity Monitoring,” in Proc. IEEE Int. Conf. on Human System
Interaction (HSI), pp. 103-109, June 2013.
D. Dietrich, R. Lang, D. Bruckner, G. Fodor, B. Muller, “Limitations,
possibilities and implications of Brain-Computer Interfaces,” in Proc.
IEEE Int. Conf. on Human System Interaction (HSI), pp. 722-726, May
2010.
J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, T.
Vaughan, “Brain–computer interfaces for communication and control,”
in Clinical neurophysiology, vol. 113, no. 6, pp. 767-791, 2002.
A. Materka, P. Poryzala, “High-speed noninvasive brain-computer
interfaces,” in Proc of IEEE Conf. on Human System Interactions (HSI),
pp. 7-12, June 2013.
J. Philips, J, Millan, G. Vanacker, “Adaptive Shared Control of a BrainActuated Simulated Wheelchair,” in Proc. IEEE Int. Conf. on
Rehabilitation Robotics, (ICORR), pp. 408-414, 2007
K. Krishnaswamy, R. Kuber, “Toward the Development of a BCI and
Gestural Interface to Support Individuals with Physical Disabilities,” in
Proc. of ACM SIGACCESS conference on Computers and accessibility,
(ASSETS), pp. 229-230, 2012.
J. Millan, F. Galan, D. Vanhooydonck, “Asynchronous non-invasive
brain-actuated control of an intelligent wheelchair,” in Proc. IEEE Int.
Conf. of the Engineering in Medicine and Biology Society, pp. 33613364, 2009.
A. R. Gonzalez, “System of communication and control based on the
thought,” in Proc of IEEE Conf. on Human System Interactions (HSI),
pp. 275-280, 2010.
M. Palankar, K. De Laurentis, R. Dubey, “Using biological approaches
for the control of a 9-DoF wheelchair-mounted robotic arm system:

[19]

[20]

[21]

[22]

[23]
[24]

[25]
[26]

[27]

Initial experiments,” in Proc. IEEE Int. Conf. on Robotics and
Biomimetics, pp. 1704-1709, 2009.
H. A. Shedeed, M. F. Issa, S. M. El-sayed, “Brain EEG signal
processing for controlling a robotic arm,” in Proc. Int. Conf. Computer
Engineering & Systems (ICCES), pp. 152-157, Nov. 2013.
A. Vourvopoulos, F. Liarokapis, “Brain-Controlled NXT Robot: Teleoperating a Robot through Brain Electrical Activity,” in Proc. of Int.
Conf .on Games and Virtual Worlds for Serious Applications (VSGAMES), pp. 140-143, 2011.
P. Coulton, C. G. Wylie, W. Bamford, “Brain interaction for mobile
games,” in Proc. Int. Academic MindTrek Conf.: Envisioning Future
Media Environments, pp. 37-44, 2001.
A. Loska, “BCI and virtual collaboration,” in Proc. Int. Conf. on
Cognitive Infocommunications (CogInfoCom), pp. 89-94, 2012.
J. Wolpaw, G. Loeb, B. Allison, E. Donchin, “BCI Meeting 2005workshop on signals and recording methods,” in IEEE Trans. Neural
Systems and Rehabilitation Engineering, vol. 14, no. 2, pp. 138–141,
2006.
Y. Tomita, Y. Mitsukura, “Hemodynamic characteristics for
improvement of EEG-BCI performance,” in Proc of IEEE Conf. on
Human System Interactions (HSI), pp. 495-500, June 2013.
Emotiv Website [Online] Available:: http://www.emotiv.com/
Neurosky
Mindwave
[Online]
Available:
http://neurosky.com/Products/MindWave.aspx
Myndplay
BrainBand
[Online]
Available:
http://myndplay.com/products.php
F. Lotte, M. Congedo, A. Lécuyer, F. Lamarche, B. Arnaldi, “A review
of classification algorithms for EEG-based brain–computer interfaces,”
in Journal of neural engineering, vol. 4, 2007.
H. Sun, Y. Xiang, Y. Sun, H. Zhu, J. Zeng, “On-line EEG classification
for brain-computer interface based on CSP and SVM,” in Proc. int.
Cong. on Image and Signal Processing (CISP), vol. 9, pp. 4105-4108,
Oct. 2010.
A. S. M. Murugavel, S. Ramakrishnan, U. Maheswari, B. S. Sabetha,
“Combined Seizure Index with Adaptive Multi-Class SVM for epileptic
EEG classification,” in Proc. Int. Conf. Emerging Trends in VLSI,
Embedded System, (ICEVENT), pp. 1-5, Jan. 2013.
R. Chai, S. H. Ling, G. P. Hunter, H. T. Nguyen, “Toward fewer EEG
channels and better feature extractor of non-motor imagery mental tasks
classification for a wheelchair thought controller,” in Proc. Int. Conf.
Engineering in Medicine and Biology Society (EMBC), pp. 5266-5269,
Sept. 2012.
J. Zurada, Introduction To Artificial Neural Systems, West Publishing
Co., 1992.
T. Kohonen, “Automatic Formation of Topological Maps of Patterns in
a Self-Organizing System, ” in Proc. SCIA, E. Oja, O. Simula, Eds., pp.
214-220, 1981.
S. Haykin, Neural Networks and Learning Machines – Third Edition,
Prentice Hall, 2008.
M. van Vliet, A. Robben, N. Chumerin, “Designing a brain-computer
interface controlled video-game using consumer grade EEG hardware,”
in Proc. of Biosignals and Biorobotics Conference (BRC), pp. 1-6, 2012.
H. S. AlZubi, N. S. Al-Zubi, W. Al-Nuaimy, “Toward Inexpensive and
Practical Brain Computer Interface,” in Proc. of Developments in Esystems Engineering (DeSE), pp. 98-101, 2011.

