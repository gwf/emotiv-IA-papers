Proceedings of 2015 IEEE
International Conference on Mechatronics and Automation
August 2 - 5, Beijing, China

Feasibility Study of a Novel Rehabilitation
Training System for Upper Limb Based on
Emotional Control
Shuxiang Guo1,3 and Xin Zhao1
1

Tianjin Key Laboratory for Control
Theory and Applications in Complicated
Systems
Tianjin University of Technology
391 Binshui Xidao, Xiqing District Tianjin
300384,P.R.China
zhaoxin00n@hotmail.com

Wei Wei2 and Jian Guo1
2

College of Physics, Optoelectronics
and Energy
Soochow University
1, Shizi Street, Suzhou 215006,
Jiangsu, P. R. China
weiweilove20000@163.com

3

Intelligent Mechanical Systems
Engineering Department

Kagawa University
2217-20, Hayashi-cho, Takamatsu,
761-0396, Japan
guo@eng.kagawa-u.ac.jp

In recent decades, many therapeutic robots have been
developed to enhance post-stroke rehabilitation of movement,
such as MIT-MANUS developed by Krebs and Hogan in 1998
[2], MIME designed by Charles G. Burgar in 2000 [3],
ARMin II [4], the second prototype of a robot for arm therapy
applicable to the training of activities of daily living, and so
many other rehabilitation robots. The application of these
robots can save the therapists from intensive training with the
patients and yields positive effects on neuromuscular function
rehabilitation. However, no consistent improvement of the
functional abilities provided by robot-assisted physical therapy
has yet been found [5].
BCI
technology
brings
new
hope
for
rehabilitation medicine, which depends on decoding patients’
mental messages without requirement of any residual muscular
movement. Logically, to combine BCI technology with robotassisted physical therapy into an integrative rehabilitation
strategy has become the focus of the attention of many
researchers.
In 2009, Kai Keng Ang [6] and his team combined BCI
and robotic arm for post-stroke rehabilitation exercises.
Experimental results showed that most stroke patients are
capable of operating the BCI effectively. Two years later(in
2011), K. Shindo and K. Kawashima [7] carried out an
experiment in which a motor imagery BCI was studied. They
found that BCI-based training method appears to have yielded
some improvement in motor function and brain plasticity.
In recent years, more BCI-based rehabilitation robots have
been presented. In 2012, Timm Meyer and Jan Peters [8]
introduced a system that combines a Barret seven degree-offreedom robot arm with neurophysiological recordings to
conduct a study on motor learning during reaching movements.
And in the same year, Antonio Frisoli [9] proposed a new
multimodal architecture for gaze-independent BCI-driven
control of a robotic upper limb exoskeleton for stroke
rehabilitation to provide active assistance in the execution of
reaching tasks in a real setting scenario.
Last year, MENRVA Group [10] in Canada presented a
wearable system consisting of a Robotic Arm Orthosis (RAO),

Abstract - This paper introduces a new way to help people
who lose motor function regain their abilities of activities of daily
living (ADL). As is proved, repeated training can help the
paralytics rebuild the strength of muscles, while active
participation of the patients will improve the outcome of
rehabilitation than them barely assisted by robots. Braincomputer interface (BCI) technology brings paralytics a new way
to join in the training process actively. The novel idea of our
study is to treat the robot as a co-worker and the paralytic
interacts in the training process with emotional states based on
his satisfaction level of the robot’s work. This system consists of
two main parts: the robot and BCI. The robot can work in three
different modes in training process. This paper focuses on the
feasibility study of emotional control of the robot. Experiments
were conducted with a healthy male subject. Brain signals of the
subject were extracted by an electroencephalogram (EEG)
headset. Four different mental states were detected and
interpreted into control commands to start the robot, stop the
robot, maintain training mode and switch training mode. Raw
EEG data were recorded for off-line analysis. Powers of four
frequency bands of EEG signals were analyzed to find their
relationship with different emotional states. Experimental results
proved the feasibility of our system and shown that it’s much
easier to control the training process with the collaborating of the
semi-autonomous robot. We also found that different EEG
frequency bands carry important messages about different
emotions, which may provide references for further study of
emotional control.
Index Terms – Brain-Computer Interface, Emotional States,
Upper Limb Exoskeleton Rehabilitation Device, Rehabilitation
Training

I. INTRODUCTION
Rehabilitation methods for patients with motor impairment
due to cerebrovascular brain damage have been studied for
decades. Unlike chronic stroke patients, acute ones who suffer
severe motor impairment are not included by current clinical
therapies like constraint-induced movement therapy (CIMT)
which relies on the residual physical movements of the patients
[1]. And traditional therapies which require one-to-one
treatment are limited by the time and capabilities of the
therapists. So, alternative strategies are needed.

978-1-4799-7096-4/15/$31.00 ©2015 IEEE

Fang Zhao1 and Yuye Hu1

1507

a Functional Electrical Stimulation (FES) system, and a
wireless BCI to assist individuals with neurological disorders
to complete the task of independently drinking a glass of
water.
Most of current researches about BCI-robot hybrid
systems are staying in preliminary studies. The accuracy of
recognition of brain activities and the instantaneity of signal
transmission are always confusing problems in BCI-related
systems. Moreover, most of the existing systems are so large
that can’t be helpful in home rehabilitation. And MI [11, 12] is
always used in modulating control signals, which is hard and
boring for patients without long time exercises to accomplish.
Though SSVEP is easy to generate and don’t need any
exercise, an extra visual stimulating device is always required.
Besides, patients need to be too much attentive and are easy to
get tired [13].
Our study focuses on the rehabilitation of upper limbs
because of their necessity in daily living. In this paper, a
wearable and portable rehabilitation training system is
proposed. Unlike other BCI-based systems, emotional states
are used as control strategies. Three different emotional states
(four different levels) are detected by an EEG neuroheadset.
Powers of four frequency bands of the signals are analyzed to
find the relationship with different emotional states. The robot
is designed in a way that it can work in multiple modes which
are predetermined by programming and can be reprogrammed
according to the need of the training process. It
collaborates with the subject to make the training job easy and
comfortable. The robot runs the training process in a certain
mode for a specific period of time as soon as the subject gives
orders mentally. And during the training the subject can either
join in by imaging the motion of the disabled upper limb or
just keeping relaxed. The feasibility of the collaborative
training method is investigated and the comfort of the training
process is evaluated.
The rest parts of this paper are organized as follows:
section II is devoted to the presentation of the whole system
structure including both hardware and software; then, in
section III, experiments are carried out with a healthy male and
experimental results are demonstrated to verify the feasibility
of the system; finally, conclusions and outlook of the novel
system are drawn.

at home to help impaired patients restore the motor function of
the upper limb. It’s easily wearable and ergonomically
comfortable with joints and segments corresponding to those
of the person it is externally coupled with.

Fig. 1 The upper limb rehabilitation training system block diagram

This exoskeleton device consists of three degree of
freedoms (DOF) including the elbow flexion/extension,
forearm pronation/supination and wrist flexion/extension,
which generally cover the most important joins of the upper
limb. During the training process, the exoskeleton is hard
bound onto the upper limb of the subject to avoid unexpected
movements. To make sure it’s portable and not a burden to the
patient, main frames of this device are made of aluminum
board [14]. Design process of ULERD can be obtained in
detail from reference [15].

Fig. 2 The upper limb exoskeleton rehabilitation device

The robot has three different modes of operation which
are predefined by mode selecting module and can be
reprogrammed according to the need of training process.
The three operating modes can be distinguished by the
speed and times of the training procedure during which the
motor controller ensures the precision of each step.

II. SYSTEM STRUCTURE
Like other BCI-robot hybrid systems this upper limb
rehabilitation training system proposed here primarily consists
of two subsystems: the rehabilitation robot subsystem and
BCI.
A. Rehabilitation robot subsystem
The rehabilitation robot subsystem can be subdivided into
three parts: the Upper Limb Exoskeleton Rehabilitation
Device (ULERD), motor controller and mode selecting
module (Fig. 1).
The ULERD (Fig. 2) designed by our team is based on the
motivation that it can be taken out to do rehabilitation training

B. BCI
According to definition, a BCI is a communication and
control system that provides an individual a new way to
interact with the environment without depending on normal
neuromuscular output channels [16]. The goal of any BCI
system is to record the brain activities and translate them into
messages and commands to fulfill communication purpose. In
a BCI system, four processes are always consisted of: data

1508

acquisition, feature extraction, feature translation, and device
output [17].
In our study, a wireless and portable Emotiv EPOC
headset [18] is used to capture EEG signals of the subject.
After being interpreted mental states of the subject are
translated in the form of commands to the robot to start, stop,
maintain or change the training process.

brainwave activity to discern the user’s conscious intent to
perform distinct physical actions on a real or virtual object.
Researches have shown that frontal lobe activity
characterized in terms of decreased power in certain frequency
bands is associated with emotional states [20]. The best known
correlates of emotionality found with EEG is that, a positive
affect is associated with greater activity in the left prefrontal
region than in the right side, and negative affect with the
reverse [21].

Fig. 3 Electrode placement for recording EEG data
Fig. 5 Emokey interface and Emokey rules

The EPOC is a high resolution, multi-channel EEG system
which features 14 EEG channels plus 2 references offering
optimal positioning for accurate spatial resolution. Positions of
electrodes are named according to the international 10-20
electrode location system [19], which are: AF3, F7, F3, FC5,
T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4, with references in
the P3/P4 locations (Fig.3). The EEG signals are recorded at a
sampling rate of 2048 Hz and down-sampled to 128 Hz. The
raw EEG data are preprocessed by a high pass filter with a cut
off at 0.16Hz, a low pass filter with a cut off at 85 Hz, and a
notch filter at 50Hz and 60 Hz to remove the main artifacts.

In this paper, we use the Affective Suite (Fig. 4) to detect
the emotional states of the subject in response to the robot’s
behavior. The Affective detections look for brainwave
characteristics that are universal in nature and don’t require an
explicit training or signature-building step on the part of the
user.

Fig. 6 The Uart-Key software interface

Brain signals of the subject are captured by the
neuroheadset. After being converted to digital form, the
signals are preprocessed, and the results are wirelessly
transmitted to a PC (Fig. 1). A series of post processing are
done on the PC to translate brain signals into control
commands. An Emokey software (Fig.5) is used to correspond
classification results of four emotional states to four different
sequences of keystrokes according to predefined rules. And a
communication interface software named Uart-key (Fig.6) is
developed to translate the outputs of Emokey into control
commands and send them wirelessly to the robot. Another

Fig. 4 Affective Suite panel

The software that comes with the Emotiv headset provides
three different detection suits: Expressive Suit, Affective Suit
and Cognitive Suit. The Expressive Suite uses the headset to
collect EEG signals affected by intended action potentials of
facial muscles and maps the expressions to the avatar. The
Affective Suite extracts real time changes of the user’s
emotional state and concentration levels from gathered EEG
data. The Cognitive detection suite evaluates a user’s real time

1509

usage of Uart-key is to provide an auxiliary control strategy
for the superviser with an easy-to-operate interface.

evokes changing signals. The green line drawn in the picture is
not used in our experiments.

III. EXPERIMENTS AND RESULTS
Primary experiments were performed with a healthy male
on his right hand. In the paper, only elbow flexion and
extension motion were focused on to test the feasibility of the
novel emotional control-based rehabilitation training system.
During experiments the subject wearing EPOC headset
tried his best to fall in specific emotional states. Some simple
exercises had been down before experiments to ensure the
subject to take his emotion under control easily. After the
subject falling into a certain and right emotional state, the
robot worn on his upper limb would receive messages from the
computer which was used to translate brain signals into control
commands almost in real-time. These messages would guide
the robot to assist the subject to complete the training process.
Fig.7 shows the upper limb rehabilitation training system and
experimental environment.

Fig. 8 Three emotional states (four different levels) used to communicate with
the robot (Instantaneous Excitement, Engagement and Frustration)

After a certain emotional level is triggered responsive
commands are transmitted to the robot. After receiving
commands from BCI, the robot needs to do a few judgements
to confirm what messages are sent to it, thus makes movements
accordingly.
Start

Fig. 7 The upper limb rehabilitation training system

Receive
Message

To start the training process, the subject needs to be much
more excited than normal state. When the instantaneous
excitement level carried with brain signals is high enough, the
training procedure is triggered. While, as the engagement level
is reduced due to fatigue of the subject or emergencies, the
training will be stopped. Otherwise, the current training mode
will be maintained as long as engagement is kept in a certain
level, or changed when the frustration level is high enough
(Fig. 8).
In Fig.8 lines with different colours represent the level of
different emotions. The black line represents the level of
instantaneous excitement which controls the start of the
training. The red line indicates the level of engagement which
triggers both stopping and maintaining signals with different
levels. The blue line shows the level of frustration which

Loop
Already

N

Start ?

N

Start Now ?

Y

N

Y

Maintain ?

Start Training
N

Y
Maintain Training Mode

Change ?
Y

Change Training Mode

N

Stop ?

Y

Stop Training

Fig. 9 The program flow chart of mode selecting module

1510

Fig.9 shows the control strategies used in mode selecting
module after receiving messages. When the starting message
comes in, the robot starts training process and runs in mode 0.
Afterwards, maintaining message does not change the current
training mode, while changing message does (among mode 0,
mode 1 and mode 2). As long as a stopping message is
received, the robot will stop the training.
Three training modes are predefined by programming in
the mode selecting module. Each type of training is under the
precise position PID control mode to ensure the security of the
subject. As long as one training mode is triggered, the subject
can either stay rest while assisted by the robot, or follow the
robot to do motor imagery, which does not disturb the training
process but improves the outcome of motor rehabilitation
remarkably.

time as soon as a training segment is triggered, which saves the
subject much energy.

(a)

(b)

(c)

(d)
Fig. 11 The power of four EEG frequency bands (Delta: 1-4Hz, Theta: 4-7Hz,
Alpha: 7-13Hz and Beta: 13-30Hz) under four emotional states at channel F3
Fig. 10 Raw EEG data recorded at all channels by TestBench

IV. CONCLUSIONS AND FUTURE WORK

Raw EEG data (Fig.10) were recorded by TestBench
during experiments for off-line analysis. With the use of fast
Fourier transformation, the power of four well-known
frequency bands (Delta: 1-4Hz, Theta: 4-7Hz, Alpha: 7-13Hz
and Beta: 13-30Hz) under four emotional states at channel F3
are displayed in Fig.11. Graph (a) corresponds to the starting
stage when the power of Theta is much bigger than other
frequency bands. From experiments we can tell that Theta
band makes a lot of contribution to instantaneous excitement
emotion when the total power of EEG is much bigger than
other three emotions. While, graph (b) corresponds to the
stopping stage when Alpha band takes the main parts of brain
signals. Experimental results show that Alpha band power
increases when the subject stays relaxed, especially when
closing eyes, which is called the “Berger effect”in other
researches [22]. Graph (c) and graph (d) present that during
the maintaining stage power of EEG signals are distributed
evenly between four frequency bands, and the increase of the
power of low frequency Delta band helps in stepping into the
changing stage. Due to the control of the engagement emotion
is energy consuming the robot is designed as a collaborative
partner that takes charge of control for a period of training

In this paper, a novel rehabilitation training system for
upper limb based on emotional control is proposed. We
combined BCI with a wearable exoskeleton robot into a
portable system. EEG signals of a healthy male were extracted
by EPOC headset. Four types of mental states were analyzed
and interpreted into commands to start, stop, maintain or
change the training process. Conclusions can be drawn as
follows:
1) Experiments proved the feasibility of our system and
shown that it’s much easier to control the training process
with the collaborating of the semi-autonomous robot.
2) In each training segment the robot ran the process
autonomously, during which the subject could do either
motor imagery or stay rest. After more than one hour
training, the subject could still trigger a certain emotion
without much effort.
3) It has been found that EEG frequency bands carry
important messages about emotions, such as Alpha band
power increment indicates low level of engagement while
low frequency Delta and Theta bands are associated with
some strong emotions like instantaneous excitement or

1511

[13] Meng, L., Jin, J., and Wang, X., “A comparison of navigation system
based on P300 BCI and SSVEP BCI,” 2012 24th Chinese Control and
Decision Conference, pp. 3703-3708, 2012.
[14] Wei, W., Guo, S., Zhang, W., Guo, J., and Wang, Y., “A novel VRbased upper limb rehabilitation robot system,” 2013 ICME International
Conference on Complex Medical Engineering, pp. 302-306, 2013.
[15] Song, Z. and Guo, S, “Design Process of a Novel Exoskeleton
Rehabilitation Device and Implementation of Bilateral Upper Limb
Motor Movement,” Journal of Medical and Biological Engineering,
32(5), pp. 323, 2012.
[16] Wolpaw, J.R., Birbaumer, N., McFarland, D.J., Pfurtscheller, G., and
Vaughan, T.M., “Brain-computer interfaces for communication and
control,” Communications of the ACM, 54(5), pp. 767-791, 2002.
[17] Shih, J.J., Krusienski, D.J., and Wolpaw, J.R., “Brain-Computer
Interfaces in Medicine,” Mayo Clinic Proceedings, 87(3), pp. 268-279,
2012.
[18] http://www.emotiv.com
[19] Ernst Niedermeyer, Fernando Lopes da Silva, “Electroencephalography,
Basic Principles, Clinical Applications, and Related Fields,” Lippincott
Williams & Wilkins, pp. 140, 2004.
[20] Coan, J.A., and Allen, J.J.B., “Frontal EEG asymmetry as a moderator
and mediator of emotion,” Biological Psychology, 67(1-2), pp. 7-50,
2004.
[21] S.K. Sutton and R.J. Davidson, R.J., “Prefrontal brain asymmetry: a
biological substrate of the behavioral approach and inhibition systems,”
Psychological Science, 8(3), pp. 204-210, 1997
[22] Kuno Kirschfeld, “The physical basis of alpha waves in the
electroencephalogram and the origin of the “Berger effect” ,” Biological
Cybernetics, 92(3), pp.177-185, 2005

frustration, which may provide references for further study
of emotional control.
With its portable and easy-to-control characteristics, our
system is very promising in home rehabilitation training. In
future work, more experiments will be done to test the
universality of its application.
ACKNOWLEDGMENTS
This research is partly supported by National Natural
Science Foundation of China (61375094), Key Research
Program of the Natural Science Foundation of Tianjin
(13JCZDJC26200), and National High Tech. Research and
Development Program of China (No.2015AA043202).
REFERENCES
[1]

Ang, K.K., and Guan, C., “Brain-Computer Interface in Stroke
Rehabilitation,” Journal of Computing Science and Engineering, 7(2),
pp. 139-146, 2013.
[2] Prange, G.B., Jannink, M.J.A., Groothuis-Oudshoorn, C.G.M.,
Hermens, H.J., and IJzerman, M.J., “Systematic review of the effect of
robot-aided therapy on recovery of the hemiparetic arm after stroke,”
The Journal of Rehabilitation Research and Development, 43(2), pp.
171, 2006.
[3] Ang, K.K., Guan, C., Sui Geok Chua, K., Sui Geok Chua, K., Ang,
B.T., Kuah, Wang, C., Phua, K.S., Chin, Z.Y., and Zhang, H., “A
clinical study of motor imagery-based brain-computer interface for
upper limb robotic rehabilitation,” 2009 Annual International
Conference of the IEEE Engineering in Medicine and Biology Society,
pp. 5981-5984, 2009.
[4] M. Mihelj, T. Nef, and R. Riener, “Armin ii - 7 dof rehabilitation robot:
mechanics and kinematics,” 2007 IEEE International Conference on
Robotics and Automation, pp. 4120-4125, 2007.
[5] Keiichiro Shindo, M., and Kimiko Kawashima, M., “Effects of
neurofeedback training with an electroencephalogram-based braincomputer interface for hand paralysis in patients with chronic stroke: a
preliminary case series study,” Journal of Rehabilitation, 43(10), pp.
951-957, 2011.
[6] H.I. Krebsa, N. Hogana, B.T. Volpec, M.L. Aisend, L. Edelsteine, and
C. Dielse, “Overview of clinical trials with MIT-MANUS: a robot-aided
Neuro -rehabilitation facility,” Technology and Health Care, 7(6), pp.
419-423, 1999.
[7] C.G. Burgar, P.S. Lum, P.C. Shor, and H.F.M. Van der Loos,
“Development of robots for rehabilitation therapy,” The Palo Alto
VA/Stanford experience, Journal of Rehabilitation Research and
Development, 37(6), pp. 663-674, 2000.
[8] Meyer, T., Peters, J., Brtz, D., Zander, T.O., Scholkopf, and B.,
Soekadar, “A brain-robot interface for studying motor learning after
stroke,” 2012 IEEE/RSJ International Conference on Intelligent Robots
and Systems, pp. 4078-4083, 2012.
[9] Frisoli, A., Loconsole, C., Leonardis, D., Banno, F., Barsotti, M.,
Chisari, C., and Bergamasco, M., “A New Gaze-BCI-Driven Control of
an Upper Limb Exoskeleton for Rehabilitation in Real-World Tasks,”
IEEE Transactions on Systems, Man, and Cybernetics, Part C
(Applications and Reviews), 42(6), pp. 1169-1179, 2012.
[10] Looned, R., Webb, J., Xiao, Z.G., and Menon, C., “Assisting drinking
with an affordable BCI-controlled wearable robot and electrical
stimulation: a preliminary investigation,” Journal of NeuroEngineering
and Rehabilitation, 11(1), pp. 51, 2014.
[11] de Vries, S., and Mulder, T., “Motor imagery and stroke rehabilitation: a
critical discussion,” Journal of Rehabilitation Medicine, 39(1), pp. 5-13,
2007.
[12] Sharma, N., Pomeroy, V.M., and Baron, J.C., “Motor Imagery: A
Backdoor to the Motor System After Stroke?,” Stroke, 37(7), pp. 19411952, 2006.

1512

