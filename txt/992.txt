Available online at www.sciencedirect.com

ScienceDirect
Procedia Technology 26 (2016) 374 – 381

3rd International Conference on System-integrated Intelligence: New Challenges for Product and
Production Engineering, SysInt 2016

Classification of Electroencephalogram Data from Hand Grasp and
Release Movements for BCI Controlled Prosthesis
Gerrit Langea, Cheng Yee Lowb,*, Khairunnisa Joharb, Fazah Akthar Hanapiahc,e,
Fadhlan Kamaruzamand
a
University of Applied Sciences Osnabrück, Albrecht Stasse 30, 49076 Osnabrück, Germany
Faculty of Mechanical Engineering, UniversitiTeknologi MARA, 40450 Shah Alam, Malaysia
c
Faculty of Medicine, Universiti Teknologi MARA, 47000 Sungai Buloh, Malaysia
d
Faculty of Electrical Engineering, Universiti Teknologi MARA, 40450 Shah Alam, Malaysia
e
Institute of Pathology, Forensic and Laboratory Medicine (I-PPerForM), Universiti Teknologi MARA, 47000 Sungai Buloh, Malaysia
b

Abstract
The use of body-powered prostheses can be tiring and lead to further problems with compliance and prosthetic restoration. BrainComputer-Interfaces (BCI) offers a mean of controlling prostheses for patients that otherwise are unable to operate such devices
due to physical limitations. An issue with BCIs is that they tend to either require invasive recording methods, posing a surgical
risk, or work by generating control signals from not task related brain activity patterns such as right vs. left hand, hand vs. leg or
visual stimulation and therefore are not intuitive in their control. This research aims to test the possibility of controlling the grasp
and release of an upper limb prosthetic terminal device by classifying Electroencephalogram (EEG) data from real hand grasping
and releasing movement. Data from five healthy subjects were recorded using a consumer grade non-invasive Emotiv EPOC
headset. During the measurement the subjects were asked to perform isometric finger extension and flexion of their right hand. In
order to bring the EEG data into correlation with the executed movement a simultaneous electromyogram (EMG) recording is
proposed as an alternative method to recordings of visual cued movement. Classified EMG data was used to generate markers in
the EEG data and to epoch the data. In order to increase the signal to noise ratio and allow better classification, the EEG data was
filtered and spectrally weighted common spatial patterns (spec-CSP) were used for feature extraction. Using linear discriminant
analysis a classification rate of up to 73.2% between grasp and release was achieved. In this work, a novel EMG-assisted
approach has been developed for classification of EEG data from hand grasp and release movements. It shows feasibility for a
more intuitive control of upper limb prosthetic terminal device using low-cost BCI without the risk associated with invasive
measurement.

* Corresponding author. Tel.: 00603 5543 6276; fax: 00603 5543 5160.
E-mail address: chengyee.low@salam.uitm.edu.my

2212-0173 © 2016 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license
(http://creativecommons.org/licenses/by-nc-nd/4.0/).
Peer-review under responsibility of the organizing committee of SysInt 2016
doi:10.1016/j.protcy.2016.08.048

Gerrit Lange et al. / Procedia Technology 26 (2016) 374 – 381
©
Published
by by
Elsevier
Ltd.Ltd.
This is an open access article under the CC BY-NC-ND license
© 2016
2016The
TheAuthors.
Authors.
Published
Elsevier
(http://creativecommons.org/licenses/by-nc-nd/4.0/).
Peer-review
under
responsibility
of
the
organizing
committee of SysInt 2016.
Peer-review under responsibility of the organizing committee of SysInt 2016
Keywords: BCI; EEG; EMG; prosthetics control; mechatronic development

1.

Introduction

Brain Computer Interfaces (BCIs) present a direct link for communication between a human operator and a
machine. By detecting the brains signals and interpreting them they allow generating control commands for external
devices [1]. When used in prosthetics they can restore or replace function of damaged or lost limbs. Due to the direct
connection to the brain, they can allow patients to control prosthesis even for patients with damaged nervous
systems, for patients that lost the muscle used for the desired movement or even patients suffering from locked in
syndrome [2]. The detection of the brain signals is performed either by recording of its electrical activity, or the
related magnetic activity, though more imaging techniques such as radioactive markers exist [3]. Those based on
electrical activity measure the electric field generated from active neurons or neuron-clusters associated with the
mental task performed. Electrical recordings can further be divided into invasive and noninvasive setups. While
invasive measurements allow a higher spatial resolution (up to a single neuron) [4], and are less affected by noise
due to being inside the skull, they pose a surgical risk and require increased effort and cost. Noninvasive recordings
(EEG) are performed by measuring the electric field on the patients scalp by means of electrodes. With the increased
distance, mixing of multiple underlying sources and distortion in skull EEG provides a poor spatial resolution in the
range of centimeters [5,6]. This limits them to the detection of rather large neuron clusters and increases the
necessary post processing work. Their advantage lies in the noninvasive and therefore risks-free measurement as
well as in easier recording setup and cheaper equipment needed. The time/spectral resolution for both invasive and
noninvasive recordings (up to milliseconds) is very good and superior to other imaging techniques [3]. The control
of prosthetic terminal devices via EEG based BCIs has been a well-researched topic over the last decade [7]. The
brains signals related to movement or imagined movement are known to be dominant in the motor cortex of the
brain. Oscillating processes (event related desynchronization and event related synchronization) occurring in specific
frequency bands (mu 7-12Hz, beta 12-30Hz) related to movement [8,9] are found in those regions. Analysis show
that specific body parts such as hands, feet, tongue can be linked to different areas on the motor cortex (known as the
homunculus) [10,11], and therefore even with EEGs low spatial resolution can be distinguished. A number of studies
show classifications between movement of right and left hand, hand and feet or movement to rest condition
[12,13,14]. The ability to differentiate between those movements based on EEG readings then allows forming a
binary control command for prosthesis. Other neurological phenomena as the SSVEP, based on classification of
visually observed stimuli also allow a classification of different tasks based on EEG recordings that can then be used
to form a command to control a prosthesis [15,16].
In order to classify the signals there are two stages employed in this paper. During the first stage, the subject is
instructed to perform the relevant tasks, while the brain activity is recorded with EEG. Based on those training trials,
a filter is calculated to distinguish the tasks based on the EEG recording. In the second stage the filter can be applied
to recordings of unknown trials, and it is tested if the classification made by the filter is correct. The instructions on
what task to perform are usually given to the subject in a randomized order by either auditory or visual stimuli
[12,13,17]. At the same time a marker is generated inside the continuous EEG data. Those markers allow extracting
time frames related to the specific task needed to train/calculate the filter and classifier.
2.

Problem Statement and Research Goal

The aim of this study is to investigate the feasibility of creating a BCI for control of an upper limb prosthetic
terminal device. To allow risk free, cheap and easy setup it is based on the consumer grade EEG system Emotiv
EPOC consisting of 14 electrodes and 2 reference channels.
The approach most BCI research uses poses 2 different problems. The first comes from how markers are created
based on stimuli or cue. When used for application in prosthetics, the BCI is to detect voluntary movement rather

375

376

Gerrit Lange et al. / Procedia Technology 26 (2016) 374 – 381

than the reaction to a cue. Studies suggest that a difference in the EEG signal of cued and uncued movement can be
found [18]. Training a classifier on uncued movement should therefore enhance classification rate. Further there are
cue related EEG pattern, as a reaction to visual or auditory stimuli and their interpretation [19]. While they are not
dominant in the motor cortex, we can help avoid them with uncued recordings. Often EEG recordings involve
repetitive performance of a task by the subject. Ensuring stable data over large amounts of trials can be a problem
due to subject fatigue, attention level or the specifics of how the task, for example hand movement is performed.
Ensuring a stable task performance in timing and force is desired.
Our first goal is to add markers into EEG data of voluntary movement tasks, while ensuring stable task
performance of the subject. We propose a marker based on simultaneous EMG recordings on the subject.
A second problem in studies aimed at BCI controlled prosthetics is the classification of movement, not related to
the desired motion of the prosthesis. In a BCI-based prosthesis, the main function of opening and closing the
prosthetic hand should be controlled by the brains intention to open and close said hand. Yet to our knowledge there
are no published papers on the classification of these movements for use in prosthetics, or on the differences in their
EEG pattern.
The second goal of this study is to check classification rates for grasping versus release movement, using
approaches common to similar movements. This would allow a more intuitive control.
3.

EMG based Marker

Markers are used to link data to tasks or conditions. The reaction time to a given stimuli may differ based on the
subjects attention level, and therefore the link between condition and data may contain an unknown. This is avoided
by basing the marker on the condition directly. When looking at the application in prosthetics, a movement
command to the prosthesis is given by the prosthesis-wearer. To capture this voluntary movement instead of
movement as a response to a given instruction could increase the classification rate of those voluntary movements.
Further this would reduce any environmental stimuli related activity in the EEG recording like the reaction to light,
color or sound that is not related to the movement itself. While those influences are minimal in the motor cortex,
studies on reacting to audible and visual stimulation show that reactions exist [19]. The main advantage is the ability
to measure and compare the engagement in the task. While a subject reacting to visual cues might aim to react in the
same way over a number of trials, this cannot be verified without measurement. This would further allow classifying
the same movement/task into different levels of intensity, allowing better control over the prosthesis provided
corresponding patterns in EEG can be found. The limitation of using real hand movement compared to often used
imagined movement, holds the risk of introducing muscle artifacts to the data and limits direct applications for
amputees. On the other hand, it is easier to supervise the recording and it does not require intensive subject training.
After the brain formed the decision to move, electric impulses are sent to the muscle via the nerves. When these
impulses reach the muscles motor end plate, the muscle is stimulated and an action potential is caused along the
muscle fiber. Like with EEG, it is possible to detect the potential by measurement on the skin via electrodes. A pair
of electrode placed alongside the muscle is reached by the action potential at different latencies, due to the slow
propagation velocity of the muscle (~ 5 m/s) [20]. Due to this latency a differential amplifier between the two
electrodes can detect the muscle activity.
4.

Methodology

A subject is asked to perform isometric finger extension and flexion by grasping and releasing based on a visual
cue. Though the initial aim was to work without cued movement, we decided it was needed to compare EMG based
markers with traditional visual markers classifying the same EEG recording. EEG and EMG are recorded. Based on
the EMG the movement can be detected and classified. This information is added into the EEG recording in form of
markers. Markers based on the visual cue are included for comparison. From these labeled EEG recordings we can
now extract epochs. These epochs are used to calculate a filter that enables to extract relevant features from the EEG
and to calculate a classifier model for those features (Fig. 1). Filters and classifier are now checked for their
classification rates.

Gerrit Lange et al. / Procedia Technology 26 (2016) 374 – 381

The recording is performed on 10 male and 1 female subjects of age 20 to 36. All subjects are right-handed able
bodied without prior neurological or musculoskeletal diseases. Only subjects able to produce reliable EMG markers
were considered for EEG recording, leading to 5 male subjects aged 26 to 36.

Fig. 1. A novel EMG-assisted approach has been developed for classification of EEG data from hand grasp and release movements.

4.1. EMG Recording
Two consumer grade EMG-sensors (Muscle Sensor v3 from advancer technologies) were deployed. There are
two electrodes plus a reference electrode powered by +- 5V DC. The electrodes are placed on the forearm extensor
and the forearm flexor, with the reference placed on the elbow and wrist. The sensor amplifies, rectifies and filters
the raw signal [21], before sending an analog value to an Arduino Uno. The Arduino is used to convert the two
analog signals into 10 bit digital signals at a sampling rate of 512Hz. The 2 mean values over 32 samples for each
sensor are computed to be used for classification. To send the data to MATLAB via serial connection the resolution
is reduced to 6bit. Labeled training sets of 300 mean values per sensor are recorded for resting condition, isometric
finger extension and flexion of the right hand. Based on the training set a linear discriminant analysis (LDA)
classifier with 2 feature inputs (2 sensor) and 3 class outputs (flex, extend, rest) is modeled. Due to the low
complexity of the signal and the real-time requirement of the classification, LDA proved to be viable. During
recording of unlabeled data, the class of the mean sensor values is predicted. The output class scoring the highest
probability is noted down and compared to a 70% threshold. A change of the highest scoring class to a different
class leads to a marker send to the Emotiv EPOC’s TestBench software via a virtual serial connection. An example
of a recording is illustrated in (Fig. 2).
Due to the Muscle Sensor v3s circuit design the system is strongly influenced by cable artifacts. To reduce these,
the Arduino and sensors are mounted onto the subject’s hand, reducing cable length and cable movement. Further
introducing noise into the recording of the training data can help to increase the robustness of the LDA classifier
[22].

4.2. EEG Recording Setup
After calibrating the EMG-sensors, the Emotiv EPOC is placed on the subjects head. Four of the front most
electrodes are placed to cover the 10-20 system positions FC3, FC4, C1, and C2 on the motor cortex. The 10-20
system is an often used standard for electrode positioning during EEG studies. The remaining electrodes positions
are then measured. While this goes against the usual placement of the EPOC [23], it allows better coverage of motor
cortex activity. Due to the rigid structure of the EPOC, there are slight deviations between 10-20 system and actual
position. After good conductivity on all electrodes is ensured in the TestBench software, the marker generated from
the EMG is included into TestBench and the EEG recording is started. The software and hardware during EEG
recording are illustrated in Fig. 3.

377

378

Gerrit Lange et al. / Procedia Technology 26 (2016) 374 – 381

Fig. 2. Illustration of received EMG data and classification. (a) Transmitted sensor data from Arduino. The blue line displays the averaged values
recorded on the extensor muscle, the red line displays the averaged values recorded on the flexor muscle; (b)The transmitted data consisting of
two values per sample time is displayed as a point on a 2D plane. Red, blue and yellow are training data with the color indicating the labels close,
open and rest. Green points are the unlabeled data seen in figure 2a; (c) The probability for each sensor value pair to fall into one of the tree
trained classes. Combined they add to 100%; (d) The final prediction to what class a sensor value pair belongs. The highest class from figure 2c is
selected. A change in the predicted class leads to an EMG-marker generated. 3,2 and 1 represent classes rest, open and close.

Fig. 3: Software and hardware during EEG recording. The time sequence of single EEG trial is illustrated on the right.

The subjects are asked to perform resting, grasping and releasing movements, based on a visual stimuli presented
to the subjects via a computer monitor (Fig. 4), and to hold those positions against resistance. The visual stimuli
presented last four seconds and is embedded into a 10 second cycle including two seconds for baseline correction,
and four seconds for the subject to relax the hand, blink and swallow .This way one hour (45min for subject two) of
data is recorded and saved as .EDF file.

379

Gerrit Lange et al. / Procedia Technology 26 (2016) 374 – 381

Fig. 4: Schematic of the recording procedure

4.3. EEG Processing and Classification
Recordings are loaded into the MATLAB plug-in EEGLAB. From the Emotiv EPOC's 35 recorded channels, the
14 EEG data channels are extracted. Based on the measured electrode locations a .loc file is generated and added to
the dataset. Signals are high-pass filtered using a FIR-filter with 1Hz cutoff to remove DC components and slow
drift from the signal. Visual inspection is then used to check for channel values indicating loss of contact or artifacts.
Trials containing those are rejected. Trials including ambiguous EMG-markers are rejected as well. The number of
remaining trials for each subject is listed in Table 1 below.
Table 1. Number of trials remaining after preprocessing of EEG data.

Subject
1
2
3
4
5

# Rest
78
76
65
81
33

#EMG release
60
45
51
94
37

#Cue release
64
69
65
97
37

#EMG grasp
55
52
11
64
34

#Cue grasp
56
52
74
64
35

# Trials total
313
294
266
400
176

The preprocessed recordings are then loaded into the BCILAB interface. Here a paradigm for feature extraction
and classification is chosen. An approach deploying spectrally weighted common spatial pattern (spec-CSP) as
feature extraction and linear discriminant analysis as classifier show good results with motor classification. The data
is band-pass filtered between 7Hz and 33Hz. This covers the beta and mu frequency band associated with motor
tasks. The Spec-CSP then reduces the 14 channels down to 6 surrogate channels via filters that maximize variance
for one class of trials while minimizing it for the other class. The log-variance of those surrogate channels are used
as features for the LDA. The data used for this classification are intervals of the four second trials. The intervals are
specified in relation to the markers based on EMG or on the markers related to the visual stimuli. The length and
position of the interval are altered in halve second steps. The classification rates between release-rest, grasp-rest and
grasp-release are calculated using 5-fold cross validation. The interval providing the best classification result is used
[14]. This change of interval allows finding the part of data that holds the most relevant information for
classification. Due to a trend of support vector machines used over LDA the best LDA matches for grasp vs. release
using EMG markers are retrained on a SVM for comparison.

380

5.

Gerrit Lange et al. / Procedia Technology 26 (2016) 374 – 381

Results and Conclusion

The best classification rates for grasp vs. release motion, depending on the data interval used, are displayed in
Table 2. In addition the mean classification rates over all intervals are displayed for grasp vs. release and for
grasp/release vs. rest. Intervals range from 0.5 seconds before the marker to 2.5 seconds after the marker. Longer
intervals are not considered since the delay between EMG-markers and cue-markers reduces the actual length
available below four seconds.
Table 2. EEG grasp and release classification rates for EMG-based and cue-based epochs.

Subje
ct
1
2
3
4
5

EMG based
Best

Cue based
Best

EMG based
Mean

Cue based
Mean

EMG based
Mean

Cue based

Grasp vs. release

Grasp vs. release

Grasp vs. release

Grasp vs. release

Grasp/Release
vs. Rest

Mean
Grasp/Release vs.
Rest

56.4%
(0.5s – 1.0s)
59.5%
(-0.5s – 0.0s)
68.2%
(0.5s – 1.5s)
73.2%
(0.0s – 0.5s)
55.9%
(-0.5s – 0.0s)

56.5%
(1.0s – 1.5s)
56.3%
(0.5s – 1.5s)
57.9%
(1.0s – 2.0s)
60.4%
(-0.5s – 2.0s)
58.7%
(0.0s – 2.0s)

48.0%

49.2%

62.5% / 58.5%

55.3% /56.6%

53.1%

50.0%

61.8% / 60.6%

58.0% / 59.2%

60.3%

50.0%

52.7% / 70.6%

55.5% / 58.6%

55.9%

53.4%

73.1% / 75.5%

64.3% / 69.0%

47.7%

51.7%

48.3% / 55.2%

51.2% / 55.7%

Compared to the guessing level of 50%, all recordings show better classification within certain intervals. Apart
from two subjects the average classification rates also show better performance than guessing level.
The classifiers using EMG based markers perform better than the ones based on cue related markers for subjects
2, 3 and 4. For subject 1 the difference between the two approaches is minimal. The preliminary results of 5 subjects
are promising and for that reason, further exploration seems viable. Larger studies need to be conducted to
determine and confirm the statistical significance of the above results.
A classification between the grasp and release versus rest allows better classification compared to grasp versus
release movement. Due to both grasp and release sharing the similarity of being a motion, not shared with rest
condition, this was expected. Yet it is shown that classification of grasping and releasing can be achieved using the
Emotiv EPOC on isometric muscle contractions. A significant change in classification rate between LDA and SVM
cannot be observed for EMG-marker based grasp vs. release movement. Compared to a classification of constant
grasping/releasing vs. rest with a similar setup reaching above 90% classification, the isometric muscle contraction
recorded here is less reliable to detect. While this might be due to the nature of the related brain activity, it may also
be due to poor understanding of those activities and therefore usage of wrong filters.
The EMG sensors for marker generation reach a classification rate of 98.2% between grasp, release and rest (33%
guessing level). However this value is based on training data of subjects selected for the EEG recording. Therefore it
should be seen as a required value from the subject, rather than an evaluation of the EMG system.
In conclusion, a novel EMG-assisted approach has been developed for classification of EEG data from hand
grasp and release movements. It shows feasibility for a more intuitive control of upper limb prosthetic terminal
device using low-cost BCI without the risk associated with invasive measurement.
Acknowledgements
The authors thank UniversitiTeknologi MARA, the Ministry of Science, Technology and Innovation Malaysia
[Ref. 100-RMI/SF 16/6/2 (3/2014)] and the Ministry of Education Malaysia [Ref. 600-RMI/FRGS 5/3 (77/2014)]
for funding the research work.

Gerrit Lange et al. / Procedia Technology 26 (2016) 374 – 381

References
[1] Van der Geer J, Hanraads JAJ, Lupton RA. The art of writing a scientific article. J Sci Commun 2000;163:51-9.
[2] Strunk Jr W, White EB. The elements of style. 3rd ed. New York: Macmillan; 1979.
[3] Mettam GR, Adams LB. How to prepare an electronic version of your article. In: Jones BS, Smith RZ, editors. Introduction to the electronic
age. New York: E-Publishing Inc; 1999. p. 281-304
[1] Bogue R. Exoskeletons and robotic prosthetics: a review of recent developments. Industrial Robot: An International Journal. 2009 Aug
21;36(5):421-7.
[2] Hinterberger T, Kübler A, Kaiser J, Neumann N, Birbaumer N. A brain–computer interface (BCI) for the locked-in: comparison of different
EEG classifications for the thought translation device. Clinical Neurophysiology. 2003 Mar 31;114(3):416-25.
[3] Michael D. Types of brain imaging techniques [Internet]. [cited2016 Jan 12] Available from http://psychcentral.com/lib/types-of-brainimaging-techniques/
[4] Boraud T, Bezard E, Bioulac B, Gross CE. From single extracellular unit recording in experimental and human parkinsonism to the
development of a functional concept of the role played by the basal ganglia in motor control. Progress in Neurobiology. 2002 Mar
31;66(4):265-83.
[5] Selim RB, Aatif MH, Peter WK, William OT. Handbook of EEG Interpretation. Springer Publishing Company; 2007
[6] Burle B, Spieser L, Roger C, Casini L, Hasbroucq T, Vidal F. Spatial and Temporal Resolutions of EEG: Is it really black and white? A scalp
current density view. International Journal of Psychophysiology. 2015 Sep 30;97(3):210-20.
[7] Johar K, Low CY, Hanapiah FA, Jaffar A, Idris F, Kasim MA. Towards the development of a electro-encephalography based neuroprosthetic
terminal device. JurnalTeknologi. 2015 Sep 13;76(4).
[8] Pfurtscheller G, Brunner C, Schlögl A, Da Silva FL. Mu rhythm (de) synchronization and EEG single-trial classification of different motor
imagery tasks. NeuroImage. 2006 May 15;31(1):153-9.
[9] Pfurtscheller G, Da Silva FL. Event-related EEG/MEG synchronization and desynchronization: basic principles. Clinical neurophysiology.
1999 Nov 1;110(11):1842-57.
[10]Nakamura A, Yamada T, Goto A, Kato T, Ito K, Abe Y, Kachi T, Kakigi R. Somatosensory homunculus as drawn by MEG. Neuroimage.
1998 May 31;7(4):377-86.
[11]Yousry TA, Schmid UD, Alkadhi H, Schmidt D, Peraud A, Buettner A, Winkler P. Localization of the motor hand area to a knob on the
precentralgyrus. A new landmark.Brain. 1997 Jan 1;120(1):141-57.
[12]Wang Y, Gao S, Gao X. Common spatial pattern method for channel selelction in motor imagery based brain-computer interface.
InEngineering in Medicine and Biology Society, 2005.IEEE-EMBS 2005. 27th Annual International Conference of the 2006 Jan 17 (pp.
5392-5395). IEEE.
[13]Li Y, Koike Y. A real-time BCI with a small number of channels based on CSP.Neural Computing and Applications. 2011 Nov
1;20(8):1187-92.
[14]Boelts J, Cerquera A, Ruiz-Olaya AF. Decoding of Imaginary Motor Movements of Fists Applying Spatial Filtering in a BCI Simulated
Application. Artificial Computation in Biology and Medicine. Springer International Publishing; 2015 Jun 1 p. 153-162
[15]Tong S, Thakor NV. Quantitative EEG analysis methods and clinical applications. Artech House; 2009.
[16]Müller-Putz GR, Pfurtscheller G. Control of an electrical prosthesis with an SSVEP-based BCI. Biomedical Engineering, IEEE Transactions
on. 2008 Jan;55(1):361-4.
[17]Ramoser H, Muller-Gerking J, Pfurtscheller G. Optimal spatial filtering of single trial EEG during imagined hand movement. Rehabilitation
Engineering, IEEE Transactions on. 2000 Dec;8(4):441-6.
[18]Thut G, Hauert CA, Viviani P, Morand S, Spinelli L, Blanke O, Landis T, Michel C. Internally driven vs. externally cued movement
selection: a study on the timing of brain activity. Cognitive Brain Research. 2000 Jun 30;9(3):261-9.
[19]Kiper DC, Knyazeva MG, Tettoni L, Innocenti GM. Visual stimulus–dependent changes in interhemispheric EEG coherence in ferrets.
Journal of Neurophysiology. 1999 Dec 1;82(6):3082-94.
[20]Thomas PK, Sears TA, Gilliatt RW.The range of conduction velocity in normal motor nerve fibres to the small muscles of the hand and
foot.Journal of neurology, neurosurgery, and psychiatry. 1959 Aug;22(3):175.
[21] Pololu [Internet]. [cited 2016 Jan 12] Available from https://www.pololu.com/file/.../Muscle_Sensor_v3_users_manual.pdf?
[22]Lei Y, Burget L, Ferrer L, Graciarena M, Scheffer N. Towards noise-robust speaker recognition using probabilistic linear discriminant
analysis. In Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on. 2012 Mar 25. p. 4253-4256.
[23]Emotiv[Internet]. [cited 2016 Jan 12] Available from https://emotiv.zendesk.com/hc/enus/article_attachments/200343895/EPOCUserManual2014.pdf
[24] Get Data Driven [Internet]. [cited 2016 Jan 12] Available from http://getdatadriven.com/ab-significance-test.

381

