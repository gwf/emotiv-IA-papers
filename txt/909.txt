Hindawi
Wireless Communications and Mobile Computing
Volume 2018, Article ID 8971206, 9 pages
https://doi.org/10.1155/2018/8971206

Research Article
Cognitive Load Assessment from EEG and Peripheral Biosignals
for the Design of Visually Impaired Mobility Aids
Charalampos Saitis ,1 Mohammad Zavid Parvez ,2 and Kyriaki Kalimeri
1

2

Audio Communication Group, Technical University of Berlin, Berlin, Germany
Data Science Lab, Institute for Scientific Interchange (ISI Foundation), Turin, Italy

2

Correspondence should be addressed to Charalampos Saitis; charalampos.saitis@campus.tu-berlin.de
Received 23 September 2017; Revised 10 January 2018; Accepted 30 January 2018; Published 28 February 2018
Academic Editor: Tao Gu
Copyright © 2018 Charalampos Saitis et al. This is an open access article distributed under the Creative Commons Attribution
License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly
cited.
Reliable detection of cognitive load would benefit the design of intelligent assistive navigation aids for the visually impaired
(VIP). Ten participants with various degrees of sight loss navigated in unfamiliar indoor and outdoor environments, while their
electroencephalogram (EEG) and electrodermal activity (EDA) signals were being recorded. In this study, the cognitive load of
the tasks was assessed in real time based on a modification of the well-established event-related (de)synchronization (ERD/ERS)
index. We present an in-depth analysis of the environments that mostly challenge people from certain categories of sight loss and we
present an automatic classification of the perceived difficulty in each time instance, inferred from their biosignals. Given the limited
size of our sample, our findings suggest that there are significant differences across the environments for the various categories of
sight loss. Moreover, we exploit cross-modal relations predicting the cognitive load in real time inferring on features extracted from
the EDA. Such possibility paves the way for the design on less invasive, wearable assistive devices that take into consideration the
well-being of the VIP.

1. Introduction
Visual impairment affects approximately 285 million individuals worldwide according to the WHO [1]. Assistive
navigation aids are essential to the visually impaired (VIP)
for improving their quality of life and increase their independence. Traditionally, VIP relied exclusively on the white
cane due to its simplicity; despite its reliability in obstacle
detection, it does not provide any information regarding
important aspects of navigation such as the distance, the
speed, or the shortest path to the destination [2]. New
technologies came to fill this gap, enhancing the traditional
assistive aids, aiming to improve the route planning [3],
navigating long distances [4], discovering landmarks [5],
and detecting obstacles [6–8]. Ranging from smartphone
applications to wearable devices, assistive navigation aids
promote greater independence and enable VIP to perform
tasks formerly impossible or difficult to accomplish [9]. Yet,
the focus of these aids is often on optimizing way-finding

or localization tasks without taking into consideration the
individual’s needs [10].
Building on our previous work [11, 12], in this study, we
place the focus entirely on the visually impaired, assessing
biomarkers that can predict in real time the mental effort of
the visually impaired while navigating in unfamiliar indoor
and outdoor urban environments. The challenges VIP experience during orientation and mobility tasks can be framed
according to the cognitive load theory [13], since, during
orientation and navigation tasks, a specific amount of space
is consumed by the working memory for the exact cognitive
demands necessary.
We designed two ad hoc orientation and mobility tasks
gathering a wide range of behavioral and biophysical signals
from 10 VIP with various categories of sight loss (see Table 1),
who volunteered to participate in our study. Collecting
electroencephalogram (EEG) signals, we assess the cognitive
load and task engagement in the performed task. EEG signals
are shown to be stable indicators of the cognitive load in a

2

Wireless Communications and Mobile Computing
Table 1: Category of vision impairment and gender of participants.

Category
VI-2
VI-3
VI-4
VI-5

Description
Vision is less than 10% and more than 5%
Vision is less than 5% and more than being able to count fingers less than one meter away
Not being able to count fingers less than one meter away
No light perception

Outdoor route
1 (F)
3 (F, F, M)
2 (F, M)
1 (F)

Indoor route
2 (F, M)
4 (F, F, M, F)
3 (F, M, F)
−

Based on the classi cation of visual impairment by the World Health Organization (http://apps.who.int/classifications/icd10/browse/2016/en/#/H53-H54).

Table 2: Descriptions and mobility challenges of the different indoor and outdoor scenes.
Route

Outdoor

Indoor

ID
A
B
C
D
E
F
G
H
A
B
C
D
E

Scene
Shopping street
Small street
Narrow alley
Urban park
Open space
Crossing road
Crossing street
construction
Door
Elevator
Corridor
Open space
Stairs

variety of tasks performed in controlled laboratory settings,
for instance, learning to navigate using hypertext and multimedia data [14–16] and learning to use complex maps during
hypermedia navigation [17]. Despite EEG’s ability to capture
the cognitive load when performing a task, its usability in
commercial assistive devices is still in its infancy. For this
reason, we collected a wide range of physiological signals,
such as skin conductance by means of a wearable bracelet.
Based on findings in the literature, skin conductance may
predict the performance in a task under stressful conditions
[18–20]; confirming such statement in “out-of-laboratory”
conditions brings great advantages in the design of assistive
devices.
We contribute to the existing literature by conducting
navigation experiments exclusively “in the wild,” where
the VIP participants navigated in predefined indoor and
outdoor routes previously unfamiliar to the them. These
routes included a large variety of obstacles and different urban
environments (see Table 2). A machine learning framework
was designed based on random forest classifiers to predict
the cognitive load of the participants for each time instance
inferring on physiological features extracted from the skin
conductance signals. The aim of this study is twofold; first,
we exploit possible effects that the various urban indoor
and outdoor environments may induce on people in relation
to their degree of sight loss and, second, to pinpoint easily
accessible biomarkers that robustly predict the cognitive load
of VIP when navigating in unfamiliar sites in the wild.
In line with the current literature [18–20], the emerging
cross-validated results suggest that physiological features

Challenges
People, ads, chairs, tables, poles
People, poles, ads
People, chairs, tables, street ads, trash bins
People
People
People
People
People
Automated doors (hinged and rotating)
Calling the elevator, selecting floor
People with noise, doors open suddenly
People
Find starting point of stairs

related to skin conductance are accurately and robustly
predicting the amount of cognitive load in real time. Taking
into consideration these findings, the design of assistive aids
adapts in real time to the requirements and personal needs of
the user.

2. Data Collection
2.1. Participants. A total of ten healthy visually impaired
adults with different degrees of sight loss participated in the
two mobility studies (6 females; average age = 41 yrs, range =
22–53 yrs). To help make them feel comfortable and safe, they
were encouraged to walk as usual using their white canes if
they wished so and were accompanied by their familiar O&M
instructor. Participants were instructed to avoid smoking
normal or e-cigarettes and consuming caffeine or sugar (e.g.,
coffee, coke, and chocolate) approximately one hour prior
to the walk. Recruitment was based on volunteering and all
VIP were capable of giving free and informed consent. The
study was approved by the National Bioethics Committee of
Iceland. All data was anonymized before analysis. Seven of
the participants walked both the outdoor and indoor routes,
one took part only in the outdoor study, and two completed
only the indoor task (see Table 1).
2.2. Indoor and Outdoor Routes. The indoor experiment was
conducted inside a building of the University of Iceland in
Reykjavik. With the assistance of VIP caretakers and O&M
instructors, we planned a route to take the VIP through
circumstances where different levels of stress were likely to

Wireless Communications and Mobile Computing
occur (i.e., of varying complexity and difficulty). Participants
walked the charted route three times for training purposes.
The route comprised five distinct environments representable
of a variety of indoor mobility challenges (see Table 2).
Indicatively, participants had to enter through automated
doors, use an elevator, move across a busy open space,
walk down a large spiral staircase, and walk through other
obstacles. The route was approximately 200 meters in length
and took on average 5 minutes to walk (range = 4–8 minutes).
The outdoor route was charted in the city center of Reykjavik in Iceland. It comprised eight distinct scenes defined so
as to cluster environmental and situational factors expected
to elicit similar affective reactions. For example, participants
had to walk on a busy shopping street, stroll through an
urban park, cross a major junction, and pass through narrow
sidewalks (see Table 2). The route was approximately 1 km
long and took on average 13 min 44 s to walk (range =
9–19 min).
2.3. Multimodal Biosignals. EEG signals were recorded using
the Emotiv EPOC+ (http://emotiv.com/epoc/), a mobile
headset with 16 dry electrodes registering over the 10-20
system locations AF3, F7, F3, FC5, T7, P3 (CMS), P7, O1,
O2, P8, P4 (DRL), T8, FC6, F4, F8, and FC4 (sampling
rate 𝑓𝑠 = 128 Hz). Given the practical constraints involved
in monitoring brain electrical activity in the wild, EPOC+
was chosen because it provides a good compromise between
performance (i.e., number of channels and scientific validity
of the acquired EEG signals) and usability (i.e., portability,
preparation time, and user comfort) with respect to other
commercial wireless EEG systems [21–24].
Along with the Emotiv headset, participants were asked
to wear the Empatica E4 wristband (https://www.empatica
.com/e4-wristband) [25]. E4 measures EDA as skin conductance through 2 ventral (inner) wrist electrodes (𝑓𝑠 =
4 Hz) and BVP through a dorsal (outer) wrist photoplethysmography (PPG) sensor (𝑓𝑠 = 64 Hz). E4 further reports
HR, extracted on board from BVP interbeat intervals. The
wristband also includes an infrared thermopile sensor and
a 3-axis accelerometer. E4 is currently the only commercial
multisensor device developed based on extended scientific
research in the areas of psychophysiology and affective computing. Additionally, it has a cable-free, watch-like design,
which makes it easier and more aesthetically pleasing to wear
and thus better fitted to use in the wild compared to other
wearable biosignal devices. Participants were asked to wear
the wristband on the nondominant hand to minimize motion
artifacts related to handling the white cane [26].
2.4. General Procedure. Participants walked the outdoor
route twice and the indoor route three times for training
purposes. In both studies directions were only provided
during the first walk to help the VIP familiarize with the
route. They were instructed to avoid unnecessary head
movements and hand gestures as well as talking to their O&M
instructor unless there was an emergency. Video and audio
were registered by means of a smartphone camera to facilitate
data annotation (observing behaviors across the different
environments and situations) and synchronization (start/end

3
of walk, environments, and obstacles). In the outdoor study,
GPS coordinates were additionally logged using a Garmin
GPSMAP-64s unit at a rate of 1 registration per second. Upon
completing the last walk, participants were asked to describe
stressful moments they experienced along the route.

3. Feature Extraction
3.1. EEG. The EEG data was first time-domain interpolated
using the Fast Fourier Transform (FFT) to account for
missing samples due to connectivity issues. Subsequently,
all signals were baseline-normalized by subtracting for each
participant and for each channel the mean of resting state registrations. These were obtained during a series of laboratory
studies with the same participants [27, 28].
Based on findings in the neuroscientific literature we
extracted a series of features descriptive of the cognitive
and the physiological state of the participants in each time
instance. The brain activity is characterized by rhythmic patterns across distinct frequency bands, the definition of which
can vary somewhat among studies. Here we analyzed EEG in
six bands, namely, delta (0.5–4 Hz), theta (4–7 Hz), alpha 1
(7–10 Hz), alpha 2 (10–13 Hz), beta (13–30 Hz), and gamma
(30–60 Hz). Beta activity is associated with psychological
and physical stress, whereas theta and alpha 1 (i.e., lower
alpha) frequencies reflect response inhibition and attentional
demands such as phasic alertness [29]. Alpha 2 (i.e., higher
alpha) is related to task performance in terms of speed,
relevance, and difficulty [30]. Gamma waves are involved
in more complex cognitive functions such as multimodal
processing or object representation [31]. Features related
to signal power and complexity were extracted using the
PyEEG open source Python module [32]. For each of the
14 EEG channels, we computed the Relative Intensity Ratio
as an indicator of relative spectral power in each of the six
frequency bands [33].
Having extracted the power band features from the EEG
signals, we estimated the event-related (de)synchronization
(ERD/ERS) index, a well-established measure of band power
change in EEG originally proposed by Pfurtscheller and
Aranibar [34]. It is defined as
baseline IBP − test IBP
ERD
∗ 100,
(%) =
ERS
baseline IBP

(1)

where IBP stands for interval band power. The baseline IBP
refers to a prestimulus time period without any task demands,
in our case the resting state, whereas the activation interval
(test IBP) refers to the time period while working on the
experimental task. We slightly modified the estimation of
the ERD/ERS index, defining test IBP as the time interval of
one second of our recorded data. In this way, we result with
one time point of ERD/ERS per second, where every time
point expresses the synchronization or desynchronization
according to the same baseline.
3.2. EDA. The skin conductance data was decomposed into
two continuous components, namely, phasic and tonic component [35]. This decomposition and subsequent extraction

4
of tonic and phasic electrodermal activity (EDA) features
were performed using the Ledalab toolbox (http://www.ledalab.de/). Overall, we extracted six features: mean tonic EDA
(TM) and the number of “spontaneous” SCRs (i.e., phasic
changes not traceable to specific stimulation), which are
known to be particularly suitable for longitudinal monitoring
of emotional stress-elicited EDA (i.e., tonic arousal); sum of
amplitudes of registered SCRs (AS) and average, maximum,
and cumulative phasic EDA (PM), which provide varying
indicators of instantaneous phasic arousal [26].
3.3. BVP and HR. The photoplethysmography sensor of the
E4 device measures the blood volume pulse (BVP) from
which it derives on board the heart rate (HR). We min-max
normalized both data streams to account for interindividual
differences [36].

4. Linear Mixed Model Analysis
4.1. Method. To examine differences in mental activity
between outdoor and indoor scenes of varying complexity
and obstacles in relation to the amount of vision loss, a linear
mixed model analysis was conducted for the alpha 1 (lower
alpha) and alpha 2 (upper alpha) bands in each of the two
routes (outdoor, indoor). Linear mixed models perform a
regression-like analysis while controlling for random variance caused by differences in factors such as participant and
electrode [37, 38]. We chose to focus on the alpha bands only
because it has been repeatedly observed that brain activity at
those frequencies is associated with cognitive load in a variety
of task demands: specifically, alpha activity has been shown to
fall in magnitude (i.e., alpha ERD increases) with higher task
difficulty (see [39] for a review).
Fixed factors examined in the analysis included type of
scene (Table 2) and category of vision impairment (Table 1).
For the latter, two broader categories of vision loss were
considered to better fit the linear models to the data: almost
blind (categories VI-5 and VI-4) and severely impaired
(categories VI-3 and VI-2). Random intercepts for each
participant and electrode position were added. Type III
Wald 𝐹-tests were used to test the significance of the fixed
factors and their interaction [40]. Pairwise comparisons of
group means were carried out with 𝑡-tests, using Bonferroniadjusted 𝑝 values where appropriate [41]. Before averaging
across conditions, a logarithmic transformation of singlecondition ERD/ERS values was applied to improve their
distributional characteristics.
4.2. Results. The across-participants average ERD/ERS values
for each environment and for each category of vision impairment are shown in Figure 1. For each subplot, mean values for
outdoor scenes are depicted in the left panel, whereas those
for indoor environments are drawn in the right panel. Type
III Wald 𝐹-test results from the four (two bands × two routes)
linear mixed models are reported in Table 3. Vision alone
was only a significant predictor of upper alpha ERD/ERS
in the outdoor route, although the interaction of vision and
scene was significantly influential for both lower and upper
alpha ERD/ERS in the outdoor route. The scene alone had

Wireless Communications and Mobile Computing
a significant effect on both bands and in both outdoor and
indoor scenarios.
Post hoc paired samples 𝑡-tests showed that ERD/ERS
in the lower alpha band was significantly higher for almost
blind than for severely impaired individuals for the outdoor
environments B [small street; 𝑡(13.53) = 2.43, 𝑝 = 0.030],
E [open space; 𝑡(10.87) = 2.75, 𝑝 = 0.019], and G [crossing
small street without traffic lights; 𝑡(14.78) = 2.86, 𝑝 = 0.012].
Similar trends were found for outdoor ERD/ERS in the upper
alpha band [B: 𝑡(20.51) = 4.13, 𝑝 = 0.001; E: 𝑡(15.85) = 2.14,
𝑝 = 0.048; G: 𝑡(25.92) = 4.20, 𝑝 < 0.001]. In addition,
upper alpha ERD/ERS was found to be significantly higher
for almost blind than for severely impaired participants for
the outdoor environments A [shopping street; 𝑡(13.52) =
2.35, 𝑝 = 0.035] and H [construction alley; 𝑡(24.07) =
2.47, 𝑝 = 0.021]. For the indoor environments, lower alpha
EDR/ERS was only significantly higher for almost blind than
for severely impaired individuals when walking up and down
stairs [scene E; 𝑡(16.83) = 2.23, 𝑝 = 0.040].
When averaging across the two VI groups, lower alpha
ERD/ERS was significantly higher when crossing a main traffic junction than when passing through the shopping street
[𝑡(846.34) = 3.23, 𝑝 = 0.036], small street [𝑡(846.47) = 3.27,
𝑝 = 0.032], and small street crossing scenes [𝑡(847.22) = 3.22,
𝑝 = 0.038]. ERD/ERS in the lower alpha band was higher
when passing through the shopping street than the small
street and higher for the latter than when crossing a small
street, but these differences were not found to be significant.
Similar trends were obtained for upper alpha ERD/ERS in
the outdoor model [3.68 < 𝑡(833.64–−834.56)< 4.44, 𝑝 <
0.007], while significantly higher upper alpha ERD/ERS was
also observed for the urban park scene compared to the
small street environment [𝑡(833.74) = 3.31, 𝑝 = 0.027].
For the indoor route, ERD/ERS in the lower alpha band was
significantly higher when using automated moving doors and
when taking the elevator than when walking along a narrow
corridor [𝑡(922.63) = 3.27, 𝑝 = 0.011 and 𝑡(922.43) =
3.48, 𝑝 = 0.005, resp.], navigating through an open space
[𝑡(922.57) = 5.06, 𝑝 < 0.001 and 𝑡(920.34) = 5.32, 𝑝 < 0.001,
resp.], and using the stairs [𝑡(914.80) = 5.15, 𝑝 < 0.001 and
𝑡(912.93) = 5.47, 𝑝 < 0.001, resp.]. Lower alpha ERD/ERS
was higher for the elevator than for the door scene, but not
significantly so. It was higher for the corridor than for the
stairs environments and higher for the latter than for the
open space scene, but these differences were also not found
to be significant. Upper alpha ERD/ERS was also significantly
higher when using automated moving doors and when
taking the elevator than in the other indoor environments
[3.19 < 𝑡(887.33–−893.52)< 7.13, 𝑝 < 0.015 and 3.22 <
𝑡(886.08–−893.01)< 7.27, 𝑝 < 0.014, respectively], while
trends similar to the outdoor model were observed for the
remaining indoor scene contrasts.
Overall, outdoor and indoor environments that were
more dynamic with respect to complexity and unexpected
obstacles, such as crossing a major road, strolling through an
open urban space, walking through a narrow alley with coffee
tables and advertisement boards, using an elevator, and going
through automatic doors, resulted in substantially higher
ERD values (i.e., lower relative power) across the two alpha

Wireless Communications and Mobile Computing

5

50
40

ERD/ERS (%)

30
20
10
0
−10
−20
−30
−40
−50
Severely impaired
F
G
H

Almost blind

Sev. impair.

C
E
A

B
D

C
A
B

Alm. blind
D
E

(a)

50
40

ERD/ERS (%)

30
20
10
0
−10
−20
−30
−40
−50
Severely impaired
F
G
H

Almost blind

Sev. impair.

C
E
A

B
D

C
A
B

Alm. blind
D
E

(b)

Figure 1: Average ERD/ERS values for each scene (Table 2) and for each category of vision impairment (severely impaired: visual acuity less
than 10% but greater than 2%; almost blind: visual acuity less than 2%). (a) Lower alpha band ERD/ERS. (b) Upper alpha band ERD/ERS. In
each subplot, outdoor scenes are depicted in the left panel and indoor environments are drawn in the right panel.

Table 3: Linear model type III Wald 𝐹-tests for ERD/ERS in the alpha-1 and alpha-2 bands, in the outdoor and indoor routes.
df
Intercept (I)
Vision Impair (VI)
Scene (S)
VI × S

1, 7.91
1, 6.02
7, 846.56
7, 846.36

I
VI
S
VI × S

1, 7.97
1, 6.05
7, 833.86
7, 833.90

𝐹
alpha-1, outdoor
620.84
2.61
2.83
5.15
alpha-2, outdoor
1027.09
7.38
5.39
7.30

𝑝

df

<0.001
0.157
0.006
<0.001

1, 8.21
1, 7.58
4, 916.92
4, 915.99

<0.001
0.035
<0.001
<0.001

1, 9.74
1, 7.37
4, 888.74
4, 887.90

𝐹
alpha-1, indoor
1074.04
2.62
14.58
1.09
alpha-2, indoor
903.41
1.23
20.92
1.16

𝑝
<0.001
0.147
<0.001
0.360
<0.001
0.302
<0.001
0.325

(e) Beta band

SCR

AS

SCRs

ISCR

AS

SCRs

SCR

AS

SCRs

ISCR
SCR

BVP

ISCR

BVP

0.0

PM

0.0

HR

0.1
SCRs

0.1
AS

0.2

ISCR

0.2

SCR

0.3

BVP

0.3

PM

0.4

HR

0.4

TM

0.5

EDA

0.5

TM

(d) Alpha 2 band

EDA

(c) Alpha 1 band

PM

HR

0.0

SCRs

0.0

AS

0.1
ISCR

0.1
SCR

0.2

BVP

0.3

0.2

PM

0.4

0.3

HR

0.4

TM

0.5

EDA

0.5

TM

(b) Theta band

EDA

(a) Delta band

BVP

0.0

PM

0.0

HR

0.1
SCRs

0.1
AS

0.2

SCR

0.2

ISCR

0.3

BVP

0.3

PM

0.4

HR

0.4

TM

0.5

EDA

0.5

TM

Wireless Communications and Mobile Computing

EDA

6

(f) Gamma band

Figure 2: Feature importances as emerging from the Gini criterion of each RF model. The error bars refer to the Gini value over 5-fold. Note
that EDA, mean tonic EDA (TM), and heart rate (HR) emerge as the most predictive biomarkers for the prediction of the cognitive load index
all the frequency bands showing the stability of the approach.

bands, which implies increased task difficulty. These cognitive
load “hotspots” are in full agreement with the scenes reported
as stressful by the participants themselves at the end of the
study.

5. Automatic Prediction of Cognitive Load
5.1. Classification Experiments. To automatically identify the
cognitive load of urban indoor and outdoor spaces experienced by VIP while walking through it based only on their
biosignals, we postulated the study as a supervised classification process. A widely used ensemble learning method
for classification was employed, namely, Random Forest (RF)
classifier [42], selected due to its ability to deal with possibly
correlated predictor variables and because it provides a
straightforward assessment of the variable importances.
The ERD/ERS index of cognitive load was averaged over
all electrodes per frequency band per second. The resulting

averaged index was binned in three chunks, namely, “Low,”
“Medium,” and “High” load. We trained a RF model to
predict the aforementioned labels of cognitive load index per
each band, inferring on the features extracted from the skin
conductance and blood volume pulse sensor. The adjustment
of the two most important parameters of RF was performed
by means of grid search parameter estimation with 5-fold
cross-validation. We exploited the effect of the number of
estimators [150, 300, 600] and the effect of the maximum
number of features [.5, 1, 2]∗ √Number Of Features. Overall,
the optimum number of estimators was 300 and the maximum number of features was set equal to the total number of
features for each experiment.
5.2. Results. Table 4 reports the classification results in terms
of AUROC weighted metric. Hereafter, we will refer to
AUROC weighted metric with the term “accuracy.” For each
frequency band, the average accuracy over 5-fold is reported,

Wireless Communications and Mobile Computing
Table 4: Classification AUROC weighted metric for all the environments across the various experiments. The reported numbers refer
to the mean AUROC over all folds in percentile and in parenthesis
the standard deviation is reported.
Frequency band
Delta
Theta
Alpha 1
Alpha 2
Beta
Gamma

AUROC weighted average (SD)
0.97 (0.00)
0.83 (0.00)
0.85 (0.00)
0.85 (0.00)
0.86 (0.00)
0.84 (0.00)

along with the respective standard deviation. We note that for
all frequency bands the performance of the models is quite
accurate and robust.
As mentioned, the ERD/ERS index employed for the
definition of the classes was averaged over all electrodes; in
literature, there are many studies associating specific electrodes to brain functions, for instance, 𝐶𝑧 to memory recall
tasks; however, the Emotiv EPOC+ used for the experiments
does not provide a full coverage of the cranial surface so as to
focus on specific electrodes. Following the exact same scheme
for the classification of the cognitive load states (“Low,”
“Medium,” and “High”) from the separate electrodes per
band we obtained accuracy values identical to the averaged
results per band.
Figure 2 depicts the most predictive features of EDA
and heart rate of the cognitive load. Note that the order
of importance and the relative amplitude of the “Gini”
importance value are comparable for all the frequency bands
showing the stability of the approach. These findings are in
line with the studies in the literature, where the skin resistance
is stated to be an important indicator of the cognitive load
[18–20].

6. Conclusions
This paper presents a framework for real-time automatic
assessment of cognitive load when visually impaired people
move and navigate in unfamiliar outdoor and indoor environments. The objective is to demonstrate the feasibility of
real-time tracking of mentally demanding tasks which can be
used as on the fly feedback to assistive devices. Mobility aids
for visually impaired people should be capable of implicitly
adapting not only to changing environments but also to
shifts in the cognitive load of the user in relation to different
environmental and situational factors.
The proposed framework is based on multimodal fusion
of brain and peripheral biosignal features. Using stressrelated features of the EDA signal and an EEG index of
cognitive load based on event-related (de)synchronization in
the alpha band (ERD/ERS), we identified the most important
cognitively demanding “hotspots” for the generic VIP population and for the specific categories of sight loss, pointing out
the particular needs/difficulties faced by each VIP category.
The high prediction rates in the multimodal classification
experiments (83–97% AUROC Weighted, Table 4) are very

7
encouraging of the proposed approach. Even if the chosen
urban and building sites did not represent all possible
different outdoor and indoor environments and situations in
terms of complexity and difficulty, the charted routes were
designed so as to combine most of the mobility challenges
faced by VIP.
Despite being promising, reported findings should be
considered with caution due to the limited number of
participants, which did not allow for an in-depth analysis of
specific stressors in each category of vision impairment. A
larger group study would need to be carried out to confirm
and quantify the trends obtained here. Furthermore, the
well-established Emotiv EPOC+ EEG headset has certain
limitations with respect to the quality of the recorded signal
during experiments involving physical activity “in the wild”
such as those presented here. Future steps of the present
study include refining the predictive model through exploring novel multimodal biosignal features for cognitive load
assessment and comparing different classifiers. Such findings
hopefully pave the way to emotionally intelligent mobile
technologies that take the concept of navigation one step
further, accounting not only for the shortest path but also for
the most effortless, least stressful, and safest one.

Conflicts of Interest
The authors declare that there are no conflicts of interest
regarding the publication of this article.

Acknowledgments
The authors wish to thank the administration and O&M
instructors at the National Institute for the Blind, Visually
Impaired, and Deaf in Iceland for their valuable input and
generous assistance and the visually impaired individuals
who took part in the study for their time and patience. The
research leading to these results has received funding from
the European Union’s Horizon 2020 Research and Innovation
Program under Grant Agreement no. 643636 “Sound of
Vision.” Charalampos Saitis acknowledges the Alexander
von Humboldt Foundation for support through a Humboldt
Research Fellowship.

References
[1] World Health Oganization (WHO) Media Centre, “Visual
Impairment and Blindness Fact Sheet no. 282, 2014,”
http://www.who.int/mediacentre/factsheets/fs282/en/Available
[Accessed February 13, 2014].
[2] R. William Wiener and E. Siffermann, “assessment,” in Foundations of orientation and mobility, pp. 272–275, 1997, assessment.
[3] A. Virtanen and S. Koskinen, “Noppa: navigation and guidance
system for the visually impaired,” in Proceedings of the 11th
World Congress and Exhibition on ITS, 2004.
[4] R. G. Golledge, J. M. Loomis, R. L. Klatzky, A. Flury, and X. L.
Yang, “Designing a personal guidance system to aid navigation
without sight; progress on the gis component,” International
Journal of Geographical Information Science, vol. 5, no. 4, pp.
373–395, 1991.

8
[5] A. Rouben and L. Terveen, Speech and Non-Speech Audio:
Navigational Information and Cognitive Load, Georgia Institute
of Technology, 2007.
[6] C. Jacquet, Y. Bellik, and Y. Bourda, “Electronic locomotion
aids for the blind: Towards more assistive systems,” Studies in
Computational Intelligence, vol. 19, pp. 133–163, 2006.
[7] Bay Advanced Technologies Ltd., “The Bat ’k’ Sonar-Cane,”
http://www.eastin.eu/en/searches/products/detail/database-vlibank/id-E21029.
[8] D. Dakopoulos and N. G. Bourbakis, “Wearable obstacle avoidance electronic travel aids for blind: a survey,” IEEE Transactions
on Systems, Man, and Cybernetics, Part C: Applications and
Reviews, vol. 40, no. 1, pp. 25–35, 2010.
[9] R. Velázquez, “Wearable assistive devices for the blind,” Lecture
Notes in Electrical Engineering, vol. 75, pp. 331–349, 2010.
[10] N. A. Giudice and G. E. Legge, “Blind navigation and the role of
technology,” in The Engineering Handbook of Smart Technology
for Aging, Disability, and dependence, A. Helal, M. Mokhtari,
and B. Abdulrazak, Eds., pp. 479–500, John Willey & Sons,
2008.
[11] C. Saitis and K. Kalimeri, “Identifying urban mobility challenges for the visually impaired with mobile monitoring of multimodal biosignals,” in Universal Access in Human-Computer
Interaction. Users and Context Diversity, M. Antona and C.
Stephanidis, Eds., pp. 616–627, Springer, 2016.
[12] K. Kalimeri and C. Saitis, “Exploring multimodal biosignal
features for stress detection during indoor mobility,” in Proceedings of the 18th ACM International Conference on Multimodal
Interaction, ICMI 2016, pp. 53–60, Japan, November 2016.
[13] J. Sweller, “Cognitive load during problem solving: effects on
learning,” Cognitive Science, vol. 12, no. 2, pp. 257–285, 1988.
[14] D. O. Bos et al., “Eeg-based emotion recognition,” The Influence
of Visual and Auditory Stimuli, vol. 56, 1, no. 3, p. 17, 2006.
[15] C. Berka, D. J. Levendowski, M. N. Lumicao et al., “EEG
correlates of task engagement and mental workload in vigilance,
learning, and memory tasks,” Aviation, Space, and Environmental Medicine, vol. 78, no. 5, pp. B231–B244, 2007.
[16] R. M. Nilsson and R. E. Mayer, “The effects of graphic organizers
giving cues to the structure of a hypertext document on users’
navigation strategies and performance,” International Journal of
Human-Computer Studies, vol. 57, no. 1, pp. 1–26, 2002.
[17] B. M. Scott and N. H. Schwartz, “Navigational spatial displays:
the role of metacognition as cognitive load,” Learning and
Instruction, vol. 17, no. 1, pp. 89–105, 2007.
[18] C. Setz, B. Arnrich, J. Schumm, R. La Marca, G. Tröster, and
U. Ehlert, “Discriminating stress from cognitive load using
a wearable eda device,” IEEE Transactions on Information
Technology in Biomedicine, vol. 14, no. 2, pp. 410–417, 2010.
[19] C. Mundell, J. Pablo Vielma, and T. Zaman, Predicting Performance under Stressful Conditions Using Galvanic Skin Response,
2016.
[20] Y. Shi, N. Ruiz, R. Taib, E. Choi, and F. Chen, “Galvanic skin
response (GSR) as an index of cognitive load,” in Proceedings of
the 25th SIGCHI Conference on Human Factors in Computing
Systems (CHI ’07), pp. 2651–2656, ACM, San Jose, Calif, USA,
May 2007.
[21] N. A. Badcock, P. Mousikou, Y. Mahajan, P. de Lissa, J. Thie, and
G. McArthur, “Validation of the emotiv EPOC EEG gaming
systemfor measuring research quality auditory ERPs,” PeerJ, vol.
1, no. 1, article e38, 2013.

Wireless Communications and Mobile Computing
[22] W. David Hairston, K. W. Whitaker, A. J. Ries et al., “Usability
of four commercially-oriented EEG systems,” Journal of Neural
Engineering, vol. 11, no. 4, p. 046018, 2014.
[23] S. Debener, F. Minow, R. Emkes, K. Gandras, and M. de Vos,
“How about taking a low-cost, small, and wireless EEG for a
walk?” Psychophysiology, vol. 49, no. 11, pp. 1617–1621, 2012.
[24] J. I. Ekandem, T. A. Davis, I. Alvarez, M. T. James, and J. E.
Gilbert, “Evaluating the ergonomics of BCI devices for research
and experimentation,” Ergonomics, vol. 55, no. 5, pp. 592–598,
2012.
[25] M. Garbarino, M. Lai, S. Tognetti, R. Picard, and D. Bender,
“Empatica E3 - A wearable wireless multi-sensor device for
real-time computerized biofeedback and data acquisition,” in
Proceedings of the 4th International Conference on Wireless
Mobile Communication and Healthcare - “Transforming healthcare through innovations in mobile and wireless technologies”,
Athens, Greece, November 2014.
[26] W. Boucsein, Electrodermal Activity, Springer, New York, NY,
USA, 2nd edition, 2012.
[27] S. Spagnol, O. I. Johannesson, A. Kristjansson et al., “Modelbased obstacle sonification for the navigation of visually
impaired persons,” in Proceedings of the 19th International
Conference on Digital Audio Effects, DAFx, pp. 309–316, Brno,
Czech Republic, September 2016.
[28] S. Spagnol, C. Saitis, K. Kalimeri, I. Omar, and R. Unnthorsson,
“Sonificazione di ostacoli come ausilio alla deambulazione di
non vedenti (Obstacle sonification as navigation aid for the
visually impaired),” in Proceedings of XXI Colloquio di Informatica Musicale (Colloquium on Music Informatics), Cagliari, Italy,
2016.
[29] W. J. Ray and H. W. Cole, “EEG alpha activity reflects attentional
demands, and beta activity reflects emotional and cognitive
processes,” Science, vol. 228, no. 4700, pp. 750–752, 1985.
[30] W. Klimesch, “EEG alpha and theta oscillations reflect cognitive and memory performance: a review and analysis,” Brain
Research Reviews, vol. 29, no. 2-3, pp. 169–195, 1999.
[31] A. Keil, M. M. Müller, W. J. Ray, T. Gruber, and T. Elbert,
“Human gamma band activity and perception of a gestalt,” The
Journal of Neuroscience, vol. 19, no. 16, pp. 7152–7161, 1999.
[32] F. S. Bao, X. Liu, and C. Zhang, “PyEEG: an open source python
module for EEG/MEG feature extraction,” Computational Intelligence and Neuroscience, vol. 2011, Article ID 406391, 2011.
[33] R. Quian Quiroga, S. Blanco, O. A. Rosso, H. Garcia, and
A. Rabinowicz, “Searching for hidden information with gabor
transform in generalized tonic-clonic seizures,” Electroencephalography and Clinical Neurophysiology, vol. 103, no. 4, pp.
434–439, 1997.
[34] G. Pfurtscheller and A. Aranibar, “Event-related cortical desynchronization detected by power measurements of scalp EEG,”
Electroencephalography and Clinical Neurophysiology, vol. 42,
no. 6, pp. 817–826, 1977.
[35] M. Benedek and C. Kaernbach, “A continuous measure of
phasic electrodermal activity,” Journal of Neuroscience Methods,
vol. 190, no. 1, pp. 80–91, 2010.
[36] J. T. Cacioppo and L. G. Tassinary, “Inferring psychological
significance from physiological signals,” American Psychologist,
vol. 45, no. 1, pp. 16–28, 1990.
[37] N. M. Laird and J. H. Ware, “Random-effects models for
longitudinal data,” Biometrics, vol. 38, no. 4, pp. 963–974, 1982.
[38] D. Bates, M. Mächler, B. M. Bolker, and S. C. Walker, “Fitting
linear mixed-effects models using lme4,” Journal of Statistical
Software , vol. 67, no. 1, 2015.

Wireless Communications and Mobile Computing
[39] P. Antonenko, F. Paas, R. Grabner, and T. van Gog, “Using electroencephalography to measure cognitive load,” Educational
Psychology Review, vol. 22, no. 4, pp. 425–438, 2010.
[40] J. Fox and W. Sanford, An R Companion to Applied Regression,
Sage, 2nd edition, 2011.
[41] R. V. Lenth, “Least-squares means: The R package lsmeans,”
Journal of Statistical Software , vol. 69, 2016.
[42] L. Breiman, “Random forests,” Machine Learning, vol. 45, no. 1,
pp. 5–32, 2001.

9

International Journal of

Rotating
Machinery

(QJLQHHULQJ
Journal of

Hindawi Publishing Corporation
http://www.hindawi.com

Volume 201

The Scientific
World Journal
Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

International Journal of

Distributed
Sensor Networks

Journal of

Sensors
Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Journal of

Control Science
and Engineering

Advances in

Civil Engineering
Hindawi Publishing Corporation
http://www.hindawi.com

Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Volume 2014

Submit your manuscripts at
https://www.hindawi.com
Journal of

Journal of

Electrical and Computer
Engineering

Robotics
Hindawi Publishing Corporation
http://www.hindawi.com

Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Volume 2014

VLSI Design
Advances in
OptoElectronics

International Journal of

Navigation and
Observation
Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Hindawi Publishing Corporation
http://www.hindawi.com

Hindawi Publishing Corporation
http://www.hindawi.com

Chemical Engineering
Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Volume 2014

Active and Passive
Electronic Components

Antennas and
Propagation
Hindawi Publishing Corporation
http://www.hindawi.com

$HURVSDFH
(QJLQHHULQJ

Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

+LQGDZL3XEOLVKLQJ&RUSRUDWLRQ
KWWSZZZKLQGDZLFRP

9ROXPH

Volume 201-

International Journal of

International Journal of

,QWHUQDWLRQDO-RXUQDORI

Modelling &
Simulation
in Engineering

Volume 2014

Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Shock and Vibration
Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

Advances in

Acoustics and Vibration
Hindawi Publishing Corporation
http://www.hindawi.com

Volume 2014

