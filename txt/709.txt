Cognitive hearing aids? Insights and possibilities
Eline Borch Petersen and Thomas Lunner
Citation: AIP Conference Proceedings 1703, 090001 (2015); doi: 10.1063/1.4939399
View online: http://dx.doi.org/10.1063/1.4939399
View Table of Contents: http://scitation.aip.org/content/aip/proceeding/aipcp/1703?ver=pdfcov
Published by the AIP Publishing
Articles you may be interested in
Task demands and cognitive abilities impact listening effort for older adult hearing aid users
J. Acoust. Soc. Am. 137, 2235 (2015); 10.1121/1.4920156
Integrating cognitive and peripheral factors in predicting hearing-aid processing effectiveness
J. Acoust. Soc. Am. 134, 4458 (2013); 10.1121/1.4824700
Predictors of auditory performance in hearing‐aid users: The role of cognitive function and auditory lifestyle
J. Acoust. Soc. Am. 120, 3125 (2006); 10.1121/1.4787675
Hearing aid
J. Acoust. Soc. Am. 76, 1282 (1984); 10.1121/1.391361
Hearing aid
J. Acoust. Soc. Am. 73, 2247 (1983); 10.1121/1.389477

This article is copyrighted as indicated in the article. Reuse of AIP content is subject to the terms at: http://scitation.aip.org/termsconditions. Downloaded to IP:
185.34.132.4 On: Wed, 20 Jan 2016 06:45:11

Cognitive Hearing Aids? Insights and Possibilities
Eline Borch Petersen*,†,** and Thomas Lunner*,†,**
†

*Eriksholm

Research Centre, Snekkersten, Denmark
Technical Audiology, Department of Experimental and Clinical Research, Linköping University, Linköping, Sweden
**Swedish Institute for Disability Research, Linnaeus Centre HEAD, Linköping University, Linköping, Sweden
Abstract. The working memory plays an important role in successfully overcoming adverse listening conditions and
should consequently be considered when designing and testing hearing aids. A number of studies have established the
relationship between hearing in noise and working memory involvement, but with the Sentence-final Word Identification
and Recall (SWIRL) test, it is possible to show that working memory is also involved in listening under favorable
conditions and that noise reduction has a positive influence in situation with very little noise. Although the capacity of the
working memory is a finite individual size, its involvement can differ with fatigue and other factors and individualization
of hearing aids should take this into account to obtain the best performance. A way of individually adapting hearing aids
is based on changes in the electrical activity of the brain (EEG). Here we present the possibilities that arise from using
EEG and show that ear-mounted electrodes is able to record useful EEG that can be explored for individualization of
hearing aids. Such an adaptation could be done based on changes in the electrical activity of the brain (EEG). Here we
present the possibilities that arise from using EEG and show that ear-mounted electrodes is able to record useful EEG that
can be explored for individualization of hearing aids.

INTRODUCTION
Adverse listening conditions can be brought on by a number of environmental factors such as background noise
level and informational content, as well as individual factors such as the listeners’ sensory hearing abilities and
cognitive capabilities. The working memory (WM) system is thought to play a crucial role in overcoming adverse
listening conditions by processing and storing auditory input. Storing auditory information refers to being able to put
words into sentences and knowing which subjects is discussed, while the processing refers to extracting relevant
information from the auditory input containing noise and other distracting elements. Under normal circumstances,
WM-rendered processing primarily deals with extracting useful information from an auditory signal degraded by
external sources. However, with the presence of a hearing impairment, the WM also has to deal with the internal
degradation that the impairment leads to.
The Ease of Language Understanding (ELU) model [12] is used to explain exactly how the working memory is
involved in listening. The multimodal input you receive when listening contains a mix of auditory, tactile, and visual
information. The first processing step is to rapidly and automatically match this to prior knowledge stored in the
long-term memory, making you able to comprehend the input implicitly, without much effort. Under adverse
listening conditions, this implicit matching procedure fails and the explicit WM processes are needed to successfully
overcome the situation. The explicit processing involves trying to extract meaning, prospectively as retrospectively,
from the incomplete input. This process is perceived as being more effortful, which is the reason that hearing
impaired persons often report being more tired after a day of listening.
The ability to perform this explicit processing, denoted WM capacity, has a large inter-subject variability,
meaning that the speech understanding in the same situation can vary greatly between subjects. It is possible to
quantify the WM capacity using a number of different tests, but for research within the field of hearing impairment,
the reading span test it widely used [3]. The test requires you to read, judge, and recall single words from a number
of sentences. The percentage of correctly recalled words serves as a measure of the WM capacity. Studies that have
incorporated the reading span test, report a significant increase in ability to overcome adverse listening conditions
with higher WM capacity, measured using the reading span test [1,6].

Mechanics of Hearing: Protein to Perception
AIP Conf. Proc. 1703, 090001-1–090001-4; doi: 10.1063/1.4939399
© 2015 AIP Publishing LLC 978-0-7354-1350-4/$30.00

This article is copyrighted as indicated in the article. Reuse of AIP content090001-1
is subject to the terms at: http://scitation.aip.org/termsconditions. Downloaded to IP:
185.34.132.4 On: Wed, 20 Jan 2016 06:45:11

HEARING AIDS AND COGNITION
Hearing aids are designed to preprocess the auditory input by amplifying it to make it audible, but it also
incorporates different helping systems aiming at decreasing the degradation of the input, i.e. noise reduction
algorithms and directional microphones. When testing the effect of the helping systems, this is often done using
hearing in noise tests incorporating very low SNRs, where the sensitivity for changes in percentage correct is high.
However, a study by Smeds et al [14], establishing the SNRs in different every-day situations, showed that situation
with very high background noise levels are rarely encountered by hearing impaired subjects. For a large majority of
the time, they are experiencing rather favorable listening environments, with background noise levels around 5-15
dBA. The traditional tests used to evaluate hearing aid performance is based on the ability to repeat sentences or
words presented in noise, i.e. they only address the processing part of the WM. If these tests are applied in more
every-day-like positive SNRs, a ceiling effect occurs since subjects can successfully repeat all sentences/words and
so no effect of hearing aid algorithms can be detected.
To be able to test differences between hearing aid algorithms or devices in more ecologically valid situations, a
new test design is needed that focus more on the storage part of the WM. The Sentence-final Word Identification
and Recall (SWIRL) test was developed for this purpose [9], inspired by [11, 13]. During the test, subjects are
presented with sentences in background noise individualized so 95% of all sentences are fully understood. The
subjects are asked to repeat the last word in each sentence and after the presentation of seven sentences, recall the
last word in each sentence. In this manner it is possible to investigate if any changes in hearing aid processing affect
the WMs ability to store, rather than process, information.
The SWIRL test was used to investigate if the presence of noise reduction could improve the recall performance.
A total of 25 elderly hearing impaired subjects (11 women, 14 men, mean age 70 years, SD=7.7) with symmetrical
moderate to moderately-severe acquired sensorineural hearing loss (average pure tone average 49.7 dB HL, SD= 9.9
dB HL), all wearing hearing aids were included in the test. The results showed that there is a significant effect of
noise reduction on the number of sentences recalled (p=0.0001). This shows that noise reduction does affect the
WM in releasing resources to perform the recall task.
Despite the obvious advantage of applying helping system, such as noise reduction, there is still the question of
when to turn them on. The drawback with any feature that manipulates the auditory input is that it creates unwanted
processing artifacts. Currently, helping systems are turned on based on estimated properties of in incoming auditory
input, trying to quantify e.g. the background noise level and auditory scene complexity. This generic approach does
not account for the fact that low WM persons might require the helping system to be turned at much lower
thresholds than high WM persons. Turning helping systems on for all subjects at a low threshold might create
annoying artifacts for the high WM persons. Ideally, it should be possible to individualize the hearing aids such that
the helping systems turn on exactly when a person is in need of them.

THE COGNITIVE HEARING AID
Individualization of hearing aids is possible at present by a time consuming adjustment of individual hearing aid
features, however this does not necessarily result in the ideal hearing aid settings. The degree of WM involvement,
denoted cognitive load, does not only rely on your individual capacity, but also on factors such as time of day, your
attention and intentions, and whether you just listen or if you perform multiple tasks at the same time. The ideal
hearing aid should therefore be able to continuously adjust to the cognitive load of the hearing aid user [7].
A commonly applied method for quantifying cognitive load is by measuring the electrical activity of the brain
using electroencephalography (EEG) [10]. EEG is favorable in that it instantaneously adapts to any change in the
auditory input, furthermore it is a direct measure, whereas most other measured occur as a consequence of the neural
adaptation. EEG equipment is often comprised of a cap with a varying number of electrodes which is positioned on
the scalp and requires either physical or wireless contact to a computer. Such a setup is not very applicable when it
comes to every-day long-term monitoring of cognitive load. Therefore, we have developed hearing aids fitted with
electrodes, which make it possible to record EEG from within the ear canal. Such a setup allows for monitoring of
the EEG whenever the hearing aids are worn and will make it possible to change hearing aid setting according to the
physiological input.
The quality of the EEG recorded using an in-the-ear device was investigated using a simple open/closed eyes
task were subjects sat with eyes open for 60 seconds and the eyes closed for 60 seconds. When closing the eyes, the
alpha activity (defined as activity within the frequency range 6-12 Hz), increase as a sign of deactivation/inhibition
of the visual cortex located in the occipital lobe (in the back of the head). Alpha activity is also associated with WM

This article is copyrighted as indicated in the article. Reuse of AIP content090001-2
is subject to the terms at: http://scitation.aip.org/termsconditions. Downloaded to IP:
185.34.132.4 On: Wed, 20 Jan 2016 06:45:11

processing, where difficult tasks triggers an increase in alpha activity as a way of inhibition task-irrelevant activity
in order to solve the task at hand [5]. We are therefore very interested in proving at the in-the-ear device is able to
capture changes in the alpha activity. Figure 1 shows data from a single subject during the open/closed eyes task.
From the time-frequency plots it is very clear that closing the eyes result in increased alpha activity, both over the
occipital electrode (Oz) and for the In The Ear (ITE) electrode. The graph on the right shows that the magnitude of
the activity is comparable for the two electrodes, proving at reliable EEG can be recorded from within the ear canal.
To illustrate the potential applications of in-the-ear EEG device for hearing aid usage, a small demonstration
based on the open/closed eyes task was made. The purpose was to show that it was possible to control hearing aid
setting based on EEG. The demonstration detects changes in alpha activity arising from opening and closing the
eyes and consequently change the hearing aid amplification. At present, the in-the-ear EEG device does not function
as a stand alone device, but must be attached to an existing EEG device, in this case the wireless EMOTIV headset
[4]. The in-the-ear EEG devices must be individually fitted, therefore the demonstration has only been tried for two
subjects, but for both subjects, it was possible to detect changes in alpha activity as a consequence of opening and
closing the eyes. The demonstration proved that controlling hearing aid features and settings is possible through the
use of EEG.

FIGURE 1. EEG from a single subject during the open/closed eyes task. (A) shows the time-frequency data for the
occipital electrode, Oz, the white line indicates the onset for eyes closed. (B) shows the corresponding time-frequency
plot for data recorded from an electrode positioned in the right ear, ITE. In (C) the Power Spectral Density (PSD) is
extracted from the time-frequency plots for the two electrodes and two conditions. The grey rectangle indicated the alpha
activity frequency range.

FUTURE APPLICATION OF A COGNITIVE HEARING AID
The field for auditory cognition is advancing rapidly in these years, revealing more and more possible applications
for a ‘cognitive hearing aid’. We have already mentioned cognitive load estimation which can be applied for
changing hearing aid settings, but there are many other areas of research interested in monitoring cognitive load.
Another recently emerging field is detection of attended speaker. Several studies have shown that it is possible to
detect which of two simultaneous speakers you attend to [2, 8]. At present hearing aids incorporate directionality
making it possible to focus the microphones to a particular location auditory scene analysis, but by being able to
detect exactly which speaker you want to attend to, the hearing aids can become much more efficient and
specialized.
The challenges of applying cognitive load estimation or attention modulation in hearing aid control lie in doing
only based on very few ear-mounted electrodes, but perhaps the largest challenge lie in making sure that only the
hearing aid only reacts to auditory changes or intentions. However, with the advances within the field of auditory
cognition, machine learning, and hardware, these challenges could be overcome.

This article is copyrighted as indicated in the article. Reuse of AIP content090001-3
is subject to the terms at: http://scitation.aip.org/termsconditions. Downloaded to IP:
185.34.132.4 On: Wed, 20 Jan 2016 06:45:11

REFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]

Akeroyd MA (2008) Are individual differences in speech reception related to individual differences in cognitive ability? A
survey of twenty experimental studies with normal hearing and hearing-impaired adults. Int J Audiol 47(Suppl 2):S53–S71
Choi I, Wang L, Bharadwai H, Shinn-Cunningham B (2014) Individual differences in attentional modulation of cortical
responses correlate with selective attention performance. Hear Res 314:10–19
Daneman M, Carpenter PA (1980) Individual differences in working memory and reading. J Verb Learn Verb Be 19:450–
466
Emotiv Systems, Emotiv-brain computer interface technology. http://emotiv.com
Klimesch W (1999) EEG alpha and theta oscillations reflect cognitive and memory performance: a review and analysis.
Brain Res Rev 29:169–195
Lunner T (2003) Cognitive function in relation to hearing aid use. Int J Audiol 42:S49–S58
Lunner T, Rudner M, Rönnberg J (2009) Cognition and hearing aids. Scand J Psychol 50:395–403
Mesgarani N, Change EF (2012) Selective cortical representation of attended speaker in multi-talker speech perception.
Nature 485:233–236
Ng EH, Rudner M, Lunner T, Pedersen MS, Rönnberg J (2013) Effects of noise and working memory capacity on memory
processing of speech for hearing-aid users. Int J Audiol 52:433–441
Obleser J, Wöstmann M, Hellbernd N, Wilsch A, Maess B (2012) Adverse listening conditions and memory load drive a
common alpha oscillatory network. J Neurosci 32:12376–12383
Pichora-Fuller MK, Schneider BA, Daneman M (1995) How young and old adults listen to and remember speech in noise.
J Acoust Soc Am 97:593–608
Rönnberg J, Rudner M, Foo C, Lunner T (2008) Cognition counts. A working memory system for ease of language
understanding (ELU). Int J Audiol 47(Suppl 2):S99–S105
Sarampalis A, Kalluri S, Edwards B, Hafter E (2009) Objective measures of listening effort: effects of background noise
and noise reduction. J Speech Lang Hear Res 52(Suppl 5):1230–1240
Smeds K, Wolters F, Rung M (2012) Estimation of realistic signal-to-noise ratios. International Hearing aid Research
Conference (IHCON), Lake Tahoe, California, USA

This article is copyrighted as indicated in the article. Reuse of AIP content090001-4
is subject to the terms at: http://scitation.aip.org/termsconditions. Downloaded to IP:
185.34.132.4 On: Wed, 20 Jan 2016 06:45:11

