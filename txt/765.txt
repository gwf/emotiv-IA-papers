INFORMATICA, 2018, Vol. 29, No. 2, 251–264
 2018 Vilnius University
DOI: http://dx.doi.org/10.15388/Informatica.2018.166

251

Predictor-Based Control of Human Response
to a Dynamic 3D Face Using Virtual Reality
Vytautas KAMINSKAS, Edgaras ŠČIGLINSKAS∗
Faculty of Informatics, Vytautas Magnus University
Vileikos g. 8, LT-44404, Kaunas, Lithuania
e-mail: vytautas.kaminskas@vdu.lt, edgaras.sciglinskas@vdu.lt
Received: December 2017; accepted: April 2018
Abstract. This paper introduces how predictor-based control principles are applied to the control
of human excitement signal as a response to a 3D face virtual stimuli. A dynamic human 3D face
is observed in a virtual reality. We use changing distance-between-eyes in a 3D face as a stimulus –
control signal. Human responses to the stimuli are observed using EEG-based signal that characterizes excitement. A parameter identiﬁcation method for predictive and stable model building with the
smallest output prediction error is proposed. A predictor-based control law is synthesized by minimizing a generalized minimum variance control criterion in an admissible domain. An admissible
domain is composed of control signal boundaries. Relatively high prediction and control quality of
excitement signals is demonstrated by modelling results.
Key words: dynamic virtual 3D face, human response, virtual reality, predictive input–output
model, generalized minimum variance control.

1. Introduction
Virtual environments already became a part of our daily life including applied computer
games, learning environments (Devlin et al., 2015), business and project management
environment (Mattioli et al., 2015), social networks and their games. These applications
and its multimedia elements are causing negative or positive emotions and are considered
as a virtual stimuli (Wrzesien et al., 2015). These stimuli may be used as a clue to regulate
human psychological, emotional and social state (Devlin et al., 2015) or even to treat
various mental diseases (Calvo et al., 2015). For this purpose, a control mechanism for
human state regulation or stabilization is needed.
EEG-based emotion signals (excitement, frustration, engagement/boredom) are characterized as reliable and quick response signals (Hondrou and Caridakis, 2012; Mattioli et
al., 2015; Sourina and Liu, 2011). However, foremost we need to compose and investigate
mathematical models describing dependencies between emotion signals as a reaction to
stimuli.
* Corresponding authors.

252

V. Kaminskas, E. Ščiglinskas

Predictive input-output structure models were proposed and investigated for exploring dependencies between virtual 3D face features and human reaction to them when dynamic virtual 3D face is observed without a virtual reality headset (Kaminskas et al., 2014;
Kaminskas and Vidugirienė, 2016; Vaškevičius et al., 2014). Predictive models are necessary in the design of predictor-based control systems (Astrom and Wittenmark, 1997;
Clarke, 1994; Kaminskas, 2007). Predictor-based control was applied to the control of
human emotion signals, when a dynamic 3D face is observed without a virtual reality
headset (Kaminskas et al., 2015; Kaminskas and Ščiglinskas, 2016).
This paper introduces a predictor-based control with a generalized minimum variance
control quality principles which are applied to the control of human response signal, when
a dynamic virtual 3D face as stimuli is observed using a virtual reality headset.

2. Experiment Planning and Cross-Correlation Analysis
A virtual 3D face with changing distance-between-eyes was used for input and EEG-based
pre-processed excitement signal of a volunteer was measured as output (Fig. 1). The output signal was recorded with Emotiv Epoc device. This device records EEG inputs from
14 channels (in accordance with the international 10–20 locations): AF3, F7, F3, FC5,
T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4 (Emotiv Epoc speciﬁcations, Mattioli et al.,
2015). Values of the output signal (excitement) vary from 0 to 1. If excitement is low, the
value is close to 0 and if it is high, the value is close to 1.
A dynamic stimulus was formed from a changing woman face (Kaminskas et al.,
2015). A 3D face created with Autodesk MAYA was used as a “neutral” one (Fig. 2,
middle). Other 3D faces were formed by changing distance-between-eyes in an extreme
manner (Fig. 2, top, bottom). The transitions between normal and extreme stages were
programmed. “Neutral” face has 0 value, largest distance-between-eyes corresponds to
value 3 and smallest distance-between-eyes corresponds to value – 3 (Fig. 2). At ﬁrst
“neutral” face was shown for 5 s, then the distance-between-eyes was increased continuously and in 10 s the largest distance between eyes was reached, then 5 s of steady face
was shown and after that the face came back to “normal” state in 10 s. Then “normal”
face was shown for 5 s, followed by 10 s of continuous change to the face with the smallest distance between-eyes, again 5 s of steady face was shown and in the next 10 s the
face came back to “normal”. The experiment was continued in the same way further using
3 s time intervals for steady face and 5 s for continuous change. Eight volunteers (four

Fig. 1. Input–output scheme.

Predictor-Based Control of Human Response to a Dynamic 3D Face UVR

253

Fig. 2. Experiment plan for a stimulus – testing input.

males and four females) were tested. Each volunteer was watching a changing virtual 3D
face with virtual reality headset and each experiment was approximately about 100 s long.
EEG-based excitement and changing distance-between-eyes signals were measured with
sampling period T0 = 0.5 s and recorded in real time.
To estimate the possible relation between human response (excitement) and virtual
3D face feature (distance-between-eyes) a cross-correlation analysis was performed. The
estimates of the maximum cross-correlation function values
max ryx [τ ] = max p
τ

τ

Ryx [τ ]
Ryy [0]Rxx [0]

(1)

are shown in Table 1. In Eq. (1) Ryx [τ ] is a cross-covariation function between distancebetween-eyes (x) and excitement (y) signals, and Ryy [τ ], Rxx [τ ] are auto-covariation
functions (Vaškevičius et al., 2014). Examples of cross-correlation functions are demonstrated in Fig. 3.
The shift of the maximum values of cross-correlation functions in relation to Ryx [0]
allows stating that there exists dynamic relationship between virtual 3D face feature
(distance-between-eyes) and human response (excitement) to them. High cross-correlation
values justify a possibility of linear dynamic relations.

V. Kaminskas, E. Ščiglinskas

254

Table 1
Maximum cross-correlation function values.
No.
volunteer

1
Female

2
Female

3
Female

4
Female

5
Male

6
Male

7
Male

8
Male

Max. values

0.90

0.68

0.66

0.50

0.83

0.81

0.81

0.48

Fig. 3. Examples of cross-correlation functions of males (left) and of females (right).

3. Input–Output Model
Dependency between human excitement signal as a response to a virtual 3D face feature (distance-between-eyes) changes is described by linear input-output structure model
(Kaminskas et al., 2014)


A z−1 yt = θ0 + B z−1 xt + εt ,

(2)

where

A(z−1 ) = 1 +

n
X

ai z−i ,

B(z−1 ) =

m
X

bj z−j ,

(3)

j =0

i=1

yt is an output (excitement), xt is an input (distance-between-eyes) signals respectively
observed as
yt = y(tT0 ),

xt = x(tT0 )

with sampling period T0 , εt corresponds to noise signal, z−1 is the backward-shift operator
(z−1 xt = xt −1 ) and θ0 is a constant value.
Eq. (2) can be expressed in the following expanded form
yt = θ0 +

m
X
j =0

bj xt −j −

n
X
i=1

ai yt −i + εt .

(4)

Predictor-Based Control of Human Response to a Dynamic 3D Face UVR

255

Parameters (coeﬃcients bj and ai , degrees m and n of the polynomials (3) and constant θ0 )
of the model (2) or (4) are unknown. Parameter identiﬁcation is performed in accordance
with the observations obtained during the experiments with the volunteers.

4. Parameter Identiﬁcation Method
The current estimates of the parameters can be obtained in the identiﬁcation process from
the condition (Kaminskas, 2007)
ĉt :

Q̃t (c) =

t
X
1
2
εk|k−1
(c) → min ,
cǫc
t −n

(5)

k=n+1

where
cT = [θ0 , b0 , b1 , . . . , bm , a1 , a2 , . . . , an ]

(6)

is a vector of the coeﬃcients of the polynomials (3) and θ0 ,
(7)

εt +1|t (c) = yt +1 − yt +1|t
is one-step-ahead output prediction error,



yt +1|t = θ0 + z 1 − A(z−1 ) yt + B z−1 xt +1

(8)

is one-step-ahead output prediction model,

c = ai : ziA < 1, i = 1, 2, . . . , n

(9)

is stability domain (unity disk) for the model (2), ziA is the roots of the polynomial
ziA :

A(z) = 0, i = 1, . . . , n,


A(z) = zn A z−1 ,

(10)

z is a forward-shift operator (zyt = yt +1 ), T is a vector transpose sign, sign |.| denotes
absolute value.
Predictive model (8) can be expressed in the form of linear regression
yt +1|t = β Tt c,

(11)

where
β Tt = [1, xt +1, xt , . . . , xt −m+1 , −yt , −yt −1, . . . , −yt −n ].

(12)

V. Kaminskas, E. Ščiglinskas

256

Considering Eq. (7) and Eq. (11), identiﬁcation criterion
Qt (c) =

t
X
1
t −n

yk − β Tk−1 c

k=n+1

2

(13)

is a quadratic form of the vector variable c.
Accordingly, solution of the minimization problem (5) is separated into two stages. In
the ﬁrst stage, which is application of the least squares method, parameter estimates are
calculated without evaluation of restrictions
ct =

 X
t

β k−1 β Tk−1

−1  X
t

k=n+1

k=n+1


yk β k−1 .

(14)

In the second stage, these estimates are projected into stability domain (9)
b
ct = Ŵct ,

(15)

where



1

Ŵ= 0
0

0
Ib
0


0
0 ,
γ Ia

0<γ 61

(16)

is a diagonal block-matrix of projection of the dimension (m + n + 2) × (m + n + 2),
Ib and Ia are correspondingly unity matrix dimension (m + 1) × (m + 1) and (n × n).
Factor γ in matrix (16) is calculated by equation
(17)

γ = min{1, γmax − γ0 },

where γmax kct k is the distance from the point 0 (origin) to the boundary of stability domain c in the direction of ct , k.k is the Euclidean norm sign, γ0 is a small and positive
constant. When n 6 2 (stability domain for the model (2) is deﬁned by linear inequations)
factor γ calculation was given (Kaminskas et al., 2014) and when n 6 3 (stability domain
is deﬁned by linear and quadratic inequations) factor γ calculation was given (Kaminskas
and Vidugirienė, 2016).
Estimates of the model orders (m̂, n̂) are deﬁned from the following conditions
(Kaminskas and Vidugirienė, 2016):
m̂ = min{m̃},

(18)

n̂ = min{ñ},

where m̃ and ñ are polynomial (3) degrees when the following inequalities are correct
σε [m, n + 1] − σε [m, n|
6 δε ,
σε [m, n]

n = 1, 2, . . . ,

σε [m + 1, n] − σε [m, n|
6 δε ,
σε [m, n]

m = 0, 1, . . . , n,

(19)

Predictor-Based Control of Human Response to a Dynamic 3D Face UVR

257

σ ǫ[m, n] is one-step-ahead prediction error standard deviation for model order (m, n),
δǫ[0.01, 0.1] is chosen constant value (which corresponds to a relative variation of predictions error standard deviation from 1% to 10%).
Validation of the predictive models (8) was performed for each of eight volunteers
(four males and four females). For the identiﬁcation of unknown parameters the ﬁrst 60
to 100 observations were used for each volunteer. For evaluation of the model order and
prediction accuracy all 185 observations were used. Each model is selected from twelve
possible models (when n = 1, 2, 3, m = 0, 1, 2, 3). The analysis of the experiment results
showed relations between distance-between-eyes and excitement and it can be described
using ﬁrst order (m̂ = 0, n̂ = 1) model
(20)

ŷt +1|t = θ̂0 + b̂0 xt +1 − â1 yt .

Prediction accuracies with predictive model (20) were correspondingly evaluated using the prediction error standard deviation, relative prediction error standard deviation and
average absolute relative prediction error (Vaškevičius et al., 2014):
v
u
u
σε = t

v
u
u
σ̃ε = t
|ε̄| =

N−1
2
1 X
yt +1 − ŷt +1|t ,
N − n t =n

(21)


N−1 
1 X yt +1 − ŷt +1|t 2
× 100%,
N − n t =n
yt +1

(22)

N−1
1 X yt +1 − ŷt +1|t
× 100%,
N − n t =n
yt +1

(23)

where N = 185. Parameter estimates and a predictor accuracy measures are provided in
Table 2. Figures 4 and 5 show examples of one-step-ahead prediction results when we are
using model (20) for four volunteers.
The analysis of the identiﬁcation results showed what relations between distancebetween-eyes and excitement is described by ﬁrst order (m̂ = 0, n̂ = 1) model (20). The
Table 2
Estimates of parameter and prediction accuracy measures.
No.

Volunteer

θ̂0

b̂0

â1

σε

σ̂ε (%)

|ε̄| (%)

1
2
3
4
5
6
7
8

Female
Female
Female
Female
Male
Male
Male
Male

0.0383
0.0042
0.0139
0.0383
0.0056
0.0152
0.0014
0.0162

−0.0115
0.0027
0.0060
−0.0142
−0.0061
−0.0104
−0.0028
−0.0064

−0.9431
−0.9674
−0.9244
−0.9152
−0.9935
−0.9833
−0.9972
−0.9698
Average

0.0391
0.0150
0.0258
0.0413
0.0252
0.0324
0.0298
0.0386
0.0309

9.2
10.0
8.7
10.9
9.8
11.4
11.0
9.3
10.0

7.3
7.2
6.5
7.4
7.3
8.9
8.3
7.0
7.5

V. Kaminskas, E. Ščiglinskas

258

Fig. 4. Example of one-step-ahead prediction results for female (right volunteer No. 1 and left No. 2).

Fig. 5. Example of one-step-ahead prediction results for male (right volunteer No. 5 and left No. 6).

validation results show that excitement can be predicted on average with less than 8% average absolute relative prediction error. Accordingly, input-output structure model (2), (3)
in the predictive form (8) can be applied to the design of prediction-based control system
of human excitement signal.

5. Generalized Minimum Variance Control
A predictor-based control law is synthesized by minimizing control quality criterion Qt
(xt +1 ) in an admissible domain x (Kaminskas, 2007)
xt∗+1 : Qt (xt +1 ) → min ,
xt+1ǫx


2
Qt (xt +1 ) = E yt +1 − yt∗+1 + qxt2+1 ,

x = xt +1 : xmin 6 xt +1 6 xmax , xt +1 − xt∗ 6 δt ,

(24)
(25)
(26)

where E is an expectation operator, yt∗+1 is a reference signal (reference trajectory for excitement signal), xmin and xmax are input signal boundaries (smallest and largest distancebetween-eyes), δt > 0 are the restriction values for the change rate of the input signal, and
sign |.| denotes absolute value, q > 0 are weight coeﬃcients.

Predictor-Based Control of Human Response to a Dynamic 3D Face UVR

259

Fig. 6. The scheme of a generalized minimum variance control with constraints.

Then solving the minimization problem (24)–(26) for one-step ahead prediction model
(8), the control law is described by equations:
(
min{xmax , xt∗ + δt , x̃t +1 }, if x̃t +1 > xt∗ ,
∗
xt +1 =
(27)
max{xmin , xt∗ − δt , x̃t +1}, if x̃t +1 < xt∗ ,


B̃ z−1 x̃t +1 = −L z−1 yt + yt∗+1 − θ0 ,
(28)


L(z−1 ) = z 1 − A(z−1 ) ,
(29)


(30)
B̃ z−1 = λ + B z−1 , λ = q/b0.
If the roots of polynomial
B̃(z) = zm B̃ z−1
are in the unity disk
zjB < 1,



zjB : B̃(z) = 0,

(31)

j = 1, . . . , m,

(32)

then from (28)–(30) the following equation is correct
x̃t +1 =


X
m
n
X
1
bj x̃t +1−j + yt∗+1 − θ0 .
ai yt +1−i −
b0 + λ
i=1

(33)

j =1

If a part or all of polynomial (31) roots do not belong to the unity disk, weight factor |λ|
is increased until all roots rely in the unity disk. The scheme of a generalized minimum
variance controller (27)–(30) is illustrated in Fig. 6.
When inserting the control signal, which is described by equations (28) and (30), to
the model (2) we get a closed-loop system equation






B z−1 + λA z−1 yt = B z−1 yt∗ − θ0 + εt .

(34)

V. Kaminskas, E. Ščiglinskas

260

It is clear from equation (34), what stability of the closed-loop system is dependent of
characteristic polynomial

D(z) = zd D z−1 ,



D z−1 = B z−1 + λA z−1 ,

d = max{m, n},

(35)

roots, all the roots must be inside the unity disk
ziD 6 1,

ziD : D(z) = 0,

i = 1, 2, . . . , d.

(36)

The analysis of characteristic polynomial equation (35) allows to state what having stable model in the process of the identiﬁcation (5)–(10), stability of a closed-loop system
is obtained with any arrangement of roots of the polynomial B(z−1 ), when the weight
factor |λ| is increased.
From equation (34) we get what permanent component of output signal in stationary
regime (yt∗ = y ∗ ) is

y = Kp y ∗ − θ0 ,

(37)

where

Kp =

B(1)
B(1) + λA(1)

(38)

is a gain of the transfer function of the reference signal yt∗ in a closed – loop
Wp (z−1 ) =

B(z−1 )
.
B(z−1 ) + λA(z−1 )

(39)

Considering the expression (38), weight factor λ is calculated by equation
λ=

K0 (1 − Kp )
,
Kp

(40)

where
K0 =

B(1)
A(1)

(41)

is a gain of the transfer function of the input-output model (2)
 B(z−1 )
W z−1 =
.
A(z−1 )

(42)

From equation (37) follows that sistematic control error
ep = y ∗ − y = (1 − Kp )y ∗ + Kp θ0

(43)

Predictor-Based Control of Human Response to a Dynamic 3D Face UVR

261

grows if Kp is signiﬁcantly lower than unit (weight factor |λ| or weight coeﬃcient q in
control criterion (25) are high). Accordingly, the gain Kp is selected from an interval
Kp ∈ [0.8, 1],

if (b0 > 0) ∧ (K0 > 0)or(b0 < 0) ∧ (K0 < 0)

(44)

Kp ∈ [1, 1.2],

if (b0 > 0) ∧ (K0 < 0)or(b0 < 0) ∧ (K0 > 0).

(45)

or

When Kp = 1 (λ = 0, q = 0), we get a minimum variance control, in other cases we
get a generalized minimum variance control.
Modelling experiments consisted of two phases. In the ﬁrst phase a human excitement
signal as a response to dynamical 3D face stimuli (testing input) were observed. According
with these observations parameter estimates of the predictive model (20) were calculated
using identiﬁcation. In the second phase, dynamical virtual 3D face features were formed
according with the control law (27) and (33) (control output). The control tasks were to
maintain high excitement levels (reference signals). In this case a control eﬃciency can
be evaluated by a relative measure
△y =

ȳc − ȳT
× 100%,
ȳT

(46)

where ȳT is an average of output ytT (excitement) as a response to testing input, and ȳc
is an average of output ytc (excitement) as a response to control input. These measures
are given in Table 3. Examples of excitement control results are shown in Fig. 7 and Fig.
8 (weight factor λ = −0.0224 and weight coeﬃcient q = 0.00026, when Kp = 0.9 or
λ = −0.2346, q = 0.00143, when Kp = 0.8).
Modelling results show that using predictor-based control with constraints a suﬃciently good quality of human excitement signal control can be reached. Excitement signal
level can be raised up on average to about 95% (when Kp = 1, minimum variance control) and about 85%–70% (when Kp = 0.9 and Kp = 0.8, generalized minimum variance
control) in comparison with testing input.
Table 3
Eﬃciency measure of excitement control.
No.

Vol.
Kp

1
2
3
4
5
6
7
8

Female
Female
Female
Female
Male
Male
Male
Male
Average

δt = 12/s

δt = 1.2/s

δt = 0.3/s

1

0.9

0.8

1

0.9

0.8

1

0.9

0.8

51.1
86.3
33.6
39
192.8
161.2
122.8
65.2
94

48.9
83.4
32.6
35.8
159.1
149.0
118.4
61.3
86.1

45.2
77.6
30.6
31.9
121.8
103.3
113.1
57.6
72.6

36.8
83.7
31.2
27.9
128.6
131.0
107.1
48.9
74.4

33.9
82.5
31.1
17.5
158.7
122.7
118.2
27.5
74.0

16.0
77.6
29.3
31.4
121.7
103.3
112.6
50.3
67.8

32.0
80.2
27.8
27.9
132.0
37.6
96.0
27.3
57.6

34.8
77.6
24.0
16.2
158.9
72.5
98.2
43.3
65.7

33.1
77.6
27.4
14.1
121.1
103.2
96.9
55.9
66.2

262

V. Kaminskas, E. Ščiglinskas

Fig. 7. Examples of excitement control for volunteer No. 1 (female). Output: reference signal yt∗ (solid line),
output signals ytc (dotted line) and ytT (dashed line). Input: control signal xt∗ (solid line) and testing input xt
(dashed line).

Control quality is inﬂuenced by a control signal variation speed which is limited by the
parameter δt of the admissible domain. This parameter allows decreasing control signal
variation which is usually high in minimum variance control systems without constraints.
Control signal variation decreases when a generalized minimum variance control is applied. In this case, the quality of control depends on a gain coeﬃcient in closed-loop
Kp (38), whose value deﬁnes weight factor λ in (30) or weight coeﬃcient q in control
criterion (25).
6. Conclusions
Experiment planning and cross-correlation analysis results demonstrated that there is a relatively high correlation between 3D face features observed using virtual reality (distancebetween-eyes) and human response (excitement) to the stimuli. The shift of the maximum
values of the cross-correlations functions in relation to origin allows stating that there exists linear dynamic relationship between distance-between-eyes and excitement signals.
Parameter identiﬁcation method for building stable input-output structure model is proposed. Identiﬁcation and validation results of one-step-ahead prediction model (8) show

Predictor-Based Control of Human Response to a Dynamic 3D Face UVR

263

Fig. 8. Examples of excitement control for volunteer No. 5 (male). Output: reference signal yt∗ (solid line),
output signals ytc (dotted line) and ytT (dashed line). Input: control signal xt∗ (solid line) and testing input xt
(dashed line).

that excitement can be predicted on average with less than 8% average absolute relative
prediction error.
Accordingly, input-output structure model (2) (3) in the predictive form (8) can be
applied to the design of predictor-based control system for controlling human excitement
signal as a response to a dynamic virtual 3D face. Control law is synthesized by minimizing generalized minimum variance control criterion in an admissible domain for input.
Calculation method of weight factor λ in control law (27)–(30) or weight coeﬃcient q
in control criterion (25) is proposed. This method is based on admissable value of the
systematic control error.
Suﬃciently good control quality of excitement signal, maintained signal level is at
average to about 90% (when Kp = 1, minimum variance control) and about 70% (when
Kp = 0.8, generalized minimum variance control with high weight coeﬃcient) higher
compared to testing input, is demonstrated by modelling results. Experiment results
demonstrated possibility to decrease variations of the control signal using a limited signal variation speed when decreasing constant δt in expression (27) or using a generalized
minimum variance control when increasing weight factor |λ|, which is calculated according to equation (40). However, in these cases, particularly applying minimum variance
control, control quality decreases.

264

V. Kaminskas, E. Ščiglinskas

References
Astrom, K.J., Wittenmark, B. (1997). Computer Controlled Systems – Theory and Design. 3rd ed.. Prentice Hall.
Calvo, R.A., D’Mello, S.K., Gratch, J., Kappas, A. (2015). The Oxford Handbook of Aﬀective Computing. Oxford
Library of Psychology. Oxford University Press.
Clarke, D.W. (1994). Advances in Model Predictive Control. Oxford Science Publications, UK.
Devlin, A.M., Lally, V., Sclaterb, M., Parusselc, K. (2015). Inter-life: a novel, three-dimensional, virtual learning
environment for life transition skills learning. Interactive Learning Environments, 23(4), 405–424.
Emotiv Epoc speciﬁcations. Brain-computer interface technology. Available at:
http://www.emotiv.com/upload/manual/sdk/EPOCSpeciﬁcations.pdf.
Hondrou, C., Caridakis, G. (2012). Aﬀective, natural interaction using EEG: sensors, application and future
Directions. In: Artiﬁcial Intelligence: Theories and Applications, Vol. 7297. Springer, Berlin, 331–338.
Kaminskas, V. (2007). Predictor-based self tuning control with constraints. In: Model and Algorithms for Global
Optimization, Optimization and Its Applications, Vol. 4. Springer, Berlin, pp. 333–341.
Kaminskas, V., Ščiglinskas, E. (2016). Minimum variance control of human emotion as reactions to a dynamic
virtual 3D face. In: AIEEE 2016: Proceedings of the 4th Workshop on Advances in Information, Electronic
and Electrical Engineering, Lithuania, Vilnius, pp. 1–6.
Kaminskas, V., Vidugirienė, A. (2016). A comparison of hammerstein – type nonlinear models for identiﬁcation
of human response to virtual 3D face stimuli. Informatica, 27(2), 283–297.
Kaminskas, V., Vaškevičius, E., Vidugirienė, A. (2014). Modeling human emotions as reactions to a dynamical
virtual 3D face. Informatica, 25(3), 425–437.
Kaminskas, V., Ščiglinskas, E., Vidugirienė, A. (2015). Predictor-based control of human emotions when reacting to a dynamic virtual 3D face stimulus. In: Proceedings of the 12th International Conference on Informatics in Control, Automation and Robotics, Vol. 1. France, Colmar, pp. 582–587.
Mattioli, F., Caetano, D., Cardoso, A., Lamounier, E. (2015). On the agile development of virtual reality systems.
In: Proceedings of the International Conference on Software Engineering Research and Practice (SERP).
pp. 10–16.
Sourina, O., Liu, Y. (2011). A fractal-based algorithm of emotion recognition from EEG using arousal-valence
model. In: Proceedings Biosignals, pp. 209–214.
Vaškevičius, E., Vidugirienė, A., Kaminskas, V. (2014). Identiﬁcation of human response to virtual 3D face
stimuli. Information Technologies and Control, 43(1), 47–56.
Wrzesien, M., Rodriguez, A., Rey, B., Alcaniz, M., Banos, R.M., Vara, M.D. (2015). How the physical similarity
of avatars can inﬂuence the learning of emotion regulation strategies in teenagers. Computers in Human
Behavior, 43, 101–111.

V. Kaminskas is a rector emeritus (2016) and honorary professor (2012) of Vytautas
Magnus University. He has PhD (1972) and DrSc (1983) degrees in the ﬁeld of technical
cybernetics and information theory. In 1984 he was awarded the title of the professor.
From 1991 he is a member of Lithuanian Academy of Science. His research interests
are dynamic system modelling, identiﬁcation and adaptive control. He is the author of 4
monographs and about 200 scientiﬁc papers of these topics.
E. Ščiglinskas is a PhD student. He graduated from the Faculty of Informatics of Vytautas
Magnus University in BSc (2013) and MSc (2015). His research interests are signal processing and system modelling, virtual reality and multimedia systems and its application.
He is the author of 3 scientiﬁc paper of these topics.

