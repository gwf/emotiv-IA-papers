Shall we care about the user’s
feelings? Influence of Affect and
Engagement on Visual Attention.
Abstract
Cezary Biele
Interactive Technologies
Laboratory, Information
Processing Institute
Al. Niepodleglosci 188B,
00-608 Warsaw, Poland
cbiele@opi.org.pl

Agata Kopacz
Interactive Technologies
Laboratory, Information
Processing Institute
Al. Niepodleglosci 188B,
00-608 Warsaw, Poland
akopacz@opi.org.pl

Krzysztof Krejtz
Interactive Technologies
Laboratory, Information
Processing Institute
Al. Niepodleglosci 188B,
00-608 Warsaw, Poland
kkrejtz@opi.org.pl

Paper presented at MIDI 2013 Conference, 24-25.06.2013,
Warsaw, Poland.

The present paper aims at describing the concept of how
the interaction with computer devices may benefit from
joint input of users emotional state and his/her eye
movements characteristics. We claim that emotions
regulate visual attention, changing its formal
characteristics and thus in turn influence the user’s
behaviour. We hypothesised that during interaction with
an interface, positive mood will enhance exploratory eye
movements. Participants of the study completed positive
or neutral mood induction procedure followed by free
viewing of classical paintings on computer screen. During
the whole experimental procedure, the users’ eye
movements as well as their brain activity were recorded.
Results confirm that positive mood changes the dynamics
of visual attention. When completing a computer task,
people’s eye movements indicate shift from ambient
toward more focal attention mode. However, positive
mood slows down that process, fostering visual
exploration of the presented stimuli. Obtained results are
discussed in the context of self-adaptive user interfaces
idea suggesting that the information about the users’
emotional state together with visual attention
characteristics and gaze information could be used as an
input channel in order to create better user experience.

Author Keywords
visual attention, affect, engagement, eye-tracking,
adaptive interfaces

ACM Classification Keywords
H.5.2 [Information interfaces and presentation]: User
Interfaces input devices and strategies..

General Terms
Human factors, Theory

Introduction
During interaction with computers users are flooded with
tons of visual information. Some of them are more salient
and some are just unnecessary interruptions. The later
often induce confusion and lower user’s satisfaction and
productivity, e.g. [5]. Modern trends in designing user
interface try to address this issue, however there is still
room for innovation.
A promising direction derives from the concepts of
gaze-contingent interfaces and affective computing.
Those try to employ user’s visual attention and affective
processes as an input sources for adaptive interfaces.
Most of these efforts aim at explicit use of the gaze as an
alternative input source in the process of interaction with
computers, e.g. eye typing systems [10], gaze tracking
games, painting applications, etc. However, eye
movements characteristics offer much more information
about the user than just what he/she is spotting at. That
implicates the need for addressing basic questions about
the relation between users’ individual state, i.e. emotions,
visual attention and behaviour in human-computer
interaction, e.g. [8] both in conceptual work as well
empirical research. The present paper rises the
fundamental issue of relation between emotions,

momentary engagement in the task and visual attention
characteristics during human computer interaction (HCI).
The idea of bringing emotions of the user as an input for
computer devices is not new, e.g. [4]. The notion
important for understanding this relation is the
information reduction. Emotions select the information
that comes to peoples perceptual system and thus limit
the options among which attention will choose.
Consequently, one may say that affect directs attention
toward some information and suppress those which are
incongruent with current emotional state, e.g. [6].
Moreover, positive affect broadens visual field resulting in
better recognition of stimuli presented in peripheral
regions [19]. In the context of HCI Broaden and Build
theory [3] claims that positive emotions enhance creative,
flexible, efficient thinking, and work productivity [15].
The concept of ambient/focal attention may help to
understand better relation between emotions and user’s
cognitive processes as well as behaviour. This concept
describes two modes of visual attention during information
acquisition: exploration and inspection. The ambient
mode is aimed at visual field exploration (scanning the
visual field). That leads to selection of a target narrow
space for further, more detailed inspection [17, 7].
Research showed that at the beginning of an image
inspection fixations are shorter and the following saccades
tend to have higher amplitudes ambient attention, while
after few seconds longer fixations are followed by smaller
saccadic amplitudes focal attention, e.g. [16].
Referring to ambient/focal attention modes and Broaden
and Build theory we hypothesise that during interaction
with an interface, positive mood will promote exploratory
eye movements (ambient mode) compared to neutral
mood which will lead to more focal attention.

Figure 1: Example of
Impressionism painting: Le
Moulin de la Galette by
Pierre-Auguste Renoir

Additionally, we expect that the influence of affect on
attention will be moderated by the momentary
engagement in the task. We hypothesise that engagement
will enhance the most optimal attentional mode for task
completion overriding the effect of emotions.

in two series. After each series participants were doing
puzzles with one of the pictures seen. The order of stimuli
presentation was randomized. Each stimulus was
presented for 30 seconds in full–screen mode. Examples of
used pictures are presented in the Figures 1 and 2.

Methodology

Apparatus.
All stimuli were presented on a computer monitor
(1680 × 1050 resolution; 22–inch LCD, 60 Hz refresh
rate) running with standard PC computer. Eye
movements were recorded at 120 Hz with an SMI eye
tracking system. SMIs Experiment Center software was
used to present stimuli and to synchronize with recorded
eye movements. SMIs BeGaze software was used for
fixations and saccades detection with a velocity based
algorithm. The peak velocity threshold was set to
40 deg / sec, the minimum saccade duration was set to 22
ms., and the minimum fixation duration was set to 50 ms.
During the experiment, brain activity of the participants
was also recorded, using Emotiv EPOC headset.

Participants.
Forty nine psychology students (31 male and 18 female,
aged M = 24.47, SD = 6.53) took part in the experiment
after signing the consent form. Six subjects were excluded
from the analysis due to eye tracking system calibration
problems resulting in low tracking ratio or due to
procedural problems.
Procedure and stimuli
Before experimental procedure, the calibration of eye
tracking device and fitting of EEG headset were executed.
During the whole procedure eye movements and brain
activity data were recorded. The whole procedure took
approximately 20 minutes to complete.
The procedure consisted of two stages: mood induction
and free viewing of art paintings on the computer screen.
Mood induction followed the procedure proposed by
Velten [18]. Participants were randomly assigned to one
of the experimental conditions: positive mood or neutral
mood. Participants in both condition were presented 20
positive or emotionally neutral sentences. Each sentence
was presented for 12 seconds on the computer screen.
The participants’ task was to read all sentences and find
for each of them relevant situations from their own life.
During reading, classical music pieces, emotionally
consistent with sentences, were played [12, 13].

Figure 2: Example of Bauhaus
painting: Das Undbild by Kurt
Schwitters

The free viewing task consisted of presentation of pictures
of six famous paintings (Impressionism and Bauhaus style)

Experimental design. Dependent and independent variables
The experimental design was mixed factorial. The main
independent variable was constituted by experimental
condition (positive vs. neutral mood). The main
within-subjects factor was the time of stimuli (30 sec)
divided into 6 equal portions each 5 second. One of the
newest approaches is to infer about the user’s engagement
from the brain activity from EEG signal [2, 1] Engagement
in the free viewing task, recorded by Emotive EPOC EEG
was treated as continuous independent variable.
Ambient–focal attention coefficient reflecting the relation
between current fixation duration and next saccade
amplitude [7, 9] was the main dependent variable.

Results

Emotions and visual attention mode
The first hypothesis posited that affect influences visual
attention mode. We claimed that people in positive mood
exhibit more exploratory eye movements (ambient mode
of visual attention) compared to users in neutral
emotional state. To test this hypothesis a mixed-design
analysis of variance was conducted. Experimental
condition (positive vs. neutral mood group) was treated
as the between-subjects fix factor and time spent with the
picture was treated as a within-subject independent
variable. The whole time of picture presentation
(t = 30s.) was collapsed into 6 groups each 5 second
length. The dependent variable in this analysis was a
focal/ambient attention coefficient.
Consistently with the hypothesis the analysis revealed
statistical significant effect of interaction between time
and experimental condition,
F (5, 205) = 2.83, p < 0.02, ηp2 = 0.049 (see Figure 3).

1.0

Ambient − Focal Attention Coefficint (mean)

The statistical analyses of collected data were conducted
using R language [11]. Data analyses focus on two types
of effects: the group differences in dynamics of
ambient/focal attention, and moderating role of personal,
momentary engagement on relation between
eye-movement characteristics and emotional state. To
test the hypotheses, mixed-design analysis of variance was
conducted and multiple regression analyses were
performed.

0.5

0.0

Condition
Positive mood
Neutral mood
5

10

15

20

25

30

Time (sec.)

Figure 3: The interaction effect of task duration and mood on
focal–ambient attention coefficient.

The post hoc comparisons between means in both
conditions run separately for each period of time showed
that significant difference occurred for the 4th period,
t(36.22) = 3.05, p < 0.01, meaning that participants in
positive mood condition exhibited less focal eye
movements (M = 0.32, SD = 0.28) than those in neutral
mood condition (M = 0.64, SD = 0.40). For the 6th
period the difference reached statistical tendency level,
t(36.22) = 1.86, p = 0.071, again positive condition
participants were lower on focal-ambient coefficient
(M = 0.55, SD = 0.38) than neutral mood group
(M = 0.85, SD = 0.64). The rest of pairwise
comparisons were not significant. To understand the
interaction term better, we conducted simple main effects

analysis separately for positive and neutral experimental
condition. For positive experimental condition the analysis
revealed statistically significant effect,
F (5, 95) = 19.88, p < 0.001, ηp2 = 0.387. For neutral
mood condition the simple main effect was also
statistically significant,
F (5, 110) = 22.94, p < 0.001, ηp2 = 0.462. The
comparison of both effects partial η 2 coefficients shows
that the effect for neutral condition is stronger, which
suggests that the shift from ambient to focal attention
mode for participants in this condition is more
pronounced.
The analysis also showed significant main effect of time,
F (5, 205) = 31.49, p < 0.001, ηp2 = 0.366 (see Figure 4).

Figure 4: The main effect of task duration on focal–ambient
attention coefficient.

Post hoc analyses indicated that the mean ambient/focal
attention coefficient significantly increases with time
stabilizing at the last 10 seconds. See table 1 for detailed
descriptive statistics in each time period and significance
of differences indicators.
Period
1
2
3
4
5
6

Time
5 sec.
10 sec.
15 sec.
20 sec.
25 sec.
30 sec.

M
-0.22
0.15
0.37
0.49
0.59
0.71

SD
0.24
0.28
0.30
0.37
0.43
0.55

p < 0.01
2,3,4,5,6
1,3,4,5,6
1,2,5,6
1,2,6
1,2,3
1,2,3,4

Table 1: Descriptive statistics and differences significance for
each time period on focal–ambient attention coefficient.

0.5
0.0
−0.5

Ambient / Focal Attention Coefficient (mean)

1.0

The main effect of experimental condition reached only
statistical tendency level,
F (1, 41) = 3.45, p = 0.7, ηp2 = 0.02. However, the pattern
of means difference was consistent with the hypothesis.
Participants in the positive mood condition exhibited
slightly more ambient eye movements
(M = 0.29, SD = 0.19) than participants in neutral mood
(M = 0.40, SD = 0.17).

5

10

15

20

Time (sec.)

25

30

To sum up obtained effects, users in positive mood exhibit
slightly less focal attention during exploring complex
stimuli presented on the computer screen compared to
neutral mood situation. More interestingly, the general
phenomenon of attentional mode shift from ambient
towards focal with the time course of the task is
quantified by users emotional state. All participants’ eye
movement patterns indicated that their attention shifts

from ambient, in the first 5-second period, toward more
focal mode, however, from the midpoint of task duration,
people in positive mood exhibit slightly more exploratory
eye movements than those in neutral mood condition.

0.4

0.6

0.8

1.0

Mood : Positive

0.8

Ambient − Focal Attention Coefficient

The moderating role of engagement for relation between
emotions and visual attention mode
We claimed that the momentary changes in the user’s
engagement into the task will moderate the relation
between his/her emotional state and characteristics of eye
movements. To test the hypothesis, we ran a multiple
regression analysis with ambient-focal attention coefficient
as the dependent variable and two predictors:
experimental condition and momentary user’s
engagement, including the interaction term between both
predictors. The analysis revealed that the tested model is
statistically significant,
F (3, 7583) = 8.56, p < 0.001, adjustedR2 = 0.002. The
engagement alone influences the ambient-focal coefficient,
b = −0.59, t(7583) = 3.37, p < 0.001, meaning that the
stronger momentary engagement in the task the less focal
eye movements are made. Also the effect of experimental
condition was significant,
b = −0.71, t(7583) = 4.12, p < 0.001, confirming previous
analysis that people in positive mood achieved lower focal
attention’s scores. More interestingly, we obtained a
significant interaction term of experimental condition and
momentary engagement,
b = 1.02, t(7583) = 3.64, p < 0.001 (see Figure 5).

0.2

Mood : Neutral

1.0

0.6

0.4

0.2

0.0

−0.2

−0.4

0.2

0.4

0.6

0.8

1.0

Engagement

Figure 5: The interaction effect of mood and momentary
engagement on focal–ambient attention coefficient.

The interaction term shows that the mood influences
characteristics of visual attention when users are not
engaged. While the engagement scores increases people in
positive mood become more focal and those in neutral
mood condition become more and more ambient.

Discussion and conclusions
Obtained study results confirm the hypotheses. Mood
influences the attention mode during human computer
interaction and this effect is moderated by the
engagement in the task.
Transition from focal and ambient attention observed
during the course of perception of the image is consistent

with the expectations. At the beginning of the
examination of the painting, users glance over its whole
surface. As they watch it further, they probably encounter
elements that capture their attention and start to watch
them more carefully. This increase in focality of attention
is observed both for users in positive and neutral mood.
But when we examine the time-course of the above
mentioned transition between focal-ambient attention
mode for users in different mood, we see that those in
positive mood glance over the picture for longer and
concentrate less on details towards the end of the viewing
time, compared to those in neutral mood. It confirms the
impact of mood on the attention characteristics. This
effect is in accordance with the results from the papers
showing that positive emotions increase the breadth of
visual attention, e.g. [14]. What is interesting, the
influence of emotions mentioned above is moderated by
the users’ engagement. If the users are engaged in the
task, the emotions do not change the parameters of
attention. This suggests that momentary engagement
overrides the effect of mood on ambient/focal attention
presumably forcing the users’ attention to the optimal
mode.
In the presented study we used a task of free viewing of
art paintings. To further investigate the observed effects,
it is necessary to conduct studies using different types of
stimuli and tasks, similar to the ones encountered during
real life human computer interaction, like web-browsing or
text editing. Then, the next step would be to use the data
about the users’ emotional state and engagement as a
continuous input for the adaptive interface systems. Such
input would allow the interface to change compatibly with
current attention mode (focal/ambient). Thanks to gaze
information it would be possible to establish the currently
seen area on the screen and change the parameters of the

surrounding interface according to the attention mode.
For example, knowing the fixation point on the screen it
would be possible to highlight or enlarge the focused area
and make the rest of the screen less obtrusive, e.g. by
dimming or disabling notifications.
Multimodal adaptive interfaces have the potential to
change the way of interaction with the technology but still
require both an extensive theoretical investigation and
well-designed empirical research.

Acknowledgments
We are grateful to Anna Niedzielska and Wojciech
Ciemniewski for their enormous help in conducting the
present study.

References
[1] Belle, A., Hargraves, R. H., and Najarian, K. An
automated optimal engagement and attention
detection system using electrocardiogram.
Computational and Mathematical Methods in
Medicine 2012 (2012), 1–12.
[2] Berka, C., Levendowski, D. J., Lumicao, M. N., Yau,
A., Davis, G., Zivkovic, V. T., Olmstead, R. E.,
Tremoulet, P. D., and Craven, P. L. Eeg correlates of
task engagement and mental workload in vigilance,
learning, and memory tasks. Aviation, Space, and
Environmental Medicine 78, 5 Suppl (2007),
B231–244.
[3] Frederickson, B., and Joiner, T. Positive emotions
trigger upward spirals toward emotional well-being.
Psychological Science 13 (2002), 172–175.
[4] Gockay, D., and Yildirim, G. Affective Computing
and Interaction: Psychological, Cognitive and
Neuroscientific Perspectives. Information Science
Reference, Hershey, New York, 2011.

[5] Iqbal, S., and Horvitz, E. Disruption and recovery of
computing tasks: Field study, analysis, and
directions. In ACM CHI 2007 (2007).
[6] Isaacowitz, D. The gaze of the optimist. Personality
and social psychology bulletin 31, 3 (2005), 407–415.
[7] Krejtz, I., Szarkowska, A., Krejtz, K., Walczak, A.,
and Duchowski, A. Audio description as an aural
guide of children’s visual attention: evidence from an
eye-tracking study. In Proceedings of the Symposium
on Eye Tracking Research and Applications, ETRA
’12, ACM (New York, NY, USA, 2012), 99–106.
[8] Krejtz, K., and Biele, C. Affect-gaze-gesture. a three
layer model of post-wimp interaction. In CHI 2013
Workshop on ”Gaze Interaction in the Post-WIMP
World”, ACM (2013).
[9] Krejtz, K., Krejtz, I., Duchowski, A., Szarkowska, A.,
and Walczak, A. Multimodal learning with audio
description: an eye tracking study of children’s gaze
during a visual recognition task. In Proceedings of
the ACM Symposium on Applied Perception, SAP
’12, ACM (New York, NY, USA, 2012), 83–90.
[10] Majaranta, P., and Räihä, K.-J. Twenty years of eye
typing: Systems and design issues. In Eye Tracking
Research and Applications Symposium, ETRA 2002,
ACM Press (2002), 15–22.
[11] R Development Core Team. R: A Language and
Environment for Statistical Computing. R
Foundation for Statistical Computing, Vienna,
Austria, 2011. ISBN 3-900051-07-0.
[12] Richell, R., and Anderson, M. Reproducibility of

[13]

[14]

[15]
[16]

[17]

[18]
[19]

negative mood induction: a self-referent plus musical
mood induction procedure and a
controllable/uncontrollable stress paradigm. J.
Psychopharmacol. (Oxford) 18, 1 (Mar 2004),
94–101.
Robinson, O., Grillon, C., and Sahakian, B. The
mood induction task: A standardized, computerized
laboratory procedure for altering mood state in
humans. Protocol Exchange (2012).
Rowe, G., Hirsh, J., and Anderson, A. Positive affect
increases the breadth of attentional selection. Proc.
Natl. Acad. Sci. U.S.A. 104, 1 (Jan 2007), 383–388.
Seligman, M. Authentic Happiness. Free Press, New
York, 2002.
Unema, P. J. A., Pannasch, S., Joos, M., and
Velichkovsky, B. Time course of information
processing during scene perception. Visual Cognition,
12(3) (1968), 473–494.
Velichkovsky, B. M., Joos, M., Helmert, J. R., and
Pannasch, S. Two Visual Systems and Their Eye
Movements: Evidence from Static and Dynamic
Scene Perception. In CogSci 2005: Proceedings of
the XXVII Conference of the Cognitive Science
Society (Stresa, Italy, July 2005), 2283–2288.
Velten, E. A laborator task for induction of mood
states. Behav Res Ther 6, 4 (1968), 473–482.
Wadlinger, H., and Isaacowitz, D. Looking happy:
The experimental manipulation of a positive visual
attention bias. Emotion 8 (2008), 121–126.

