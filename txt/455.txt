Impact of Perceived Quality and other Influencing
Factors on Emotional Video Experience
Jan-Niklas Antons1, Sebastian Arndt1, Katrien De Moor2, and Steffen Zander1
1

Quality and Usability Lab
Technische Universität Berlin
Berlin, Germany
jan-niklas.antons@tu-berlin.de, sebastian.arndt@tuberlin.de, steffenza@gmx.de

2

Department of Telematics
Norwegian University of Science and Technology
Trondheim, Norway
katrien.demoor@item.ntnu.no

Abstract—How quality, quality perception and emotions are
related, and what this may imply for research on Q, is a question
that to date still lacks an unambiguous answer. The study of this
relationship is challenging and requires validated emotional
stimuli as well as suitable methods and tools to evaluate their
emotional impact. This paper shares findings from an interlaboratory study (N=39), in which electroencephalography data
and self-report data on experienced affect, content likeability and
perceived quality were collected to evaluate the emotional impact
of stimuli from a publicly available database aimed at evoking
certain emotional responses. The results call for caution when
evaluating emotional impact of such stimuli, as both the selfreported and EEG data point to a number of influencing factors
that interfere with the emotion elicitation and need to be taken
into account in future research.

excerpts of 1 minute, which were evaluated in an interlaboratory study (N=32) [3]. The final 40 music video clips are
intended to evoke emotions in four quadrants of the arousalvalence plane: namely, Low Arousal Low Valence (LALV),
Low Arousal High Valence (LAHV), High Arousal Low
Valence (HALV) and High Arousal High Valence (HAHV).

Keywords—emotions; EEG; Electroencephalography; selfassessment; Quality of Experience (QoE); influencing factors

The EEG measures voltage by attaching electrodes to the
scalp of a participant. Since Berger discovered the EEG in
1929, it has been widely used for research of physiological
correlates of perceptual and attentional processes [6, 7]. EEG
data can mainly be analyzed in two different ways: on the one
hand, by looking at the Event-Related Potentials (ERP) which
are a time-locked reaction to an external stimulus measured as
a change in voltage, and on the other hand, by taking a closer
look at the spectrogram of spontaneous activity [8]. Following
[8] there are five different frequency ranges ascribed to
specific states of the brain: delta band (1–4 Hz), theta band (4–
8 Hz), alpha band (8–13 Hz), beta band (13–30 Hz), and the
gamma band (36–44 Hz). Activity in the delta band is mainly
present during sleep, theta band activity during light sleep.
Activity in the alpha band is related to relaxed wakefulness
and situations of decreased alertness. High arousal and
focused attention lead to a high power in the beta and gamma
bands [8].

I. INTRODUCTION
The new definition of Quality of Experience (QoE) as “the
degree of delight or annoyance of a person whose experiencing
involves an application, service, or system”, which is subjected
to a range of influencing factors [1], has triggered growing
interest in the relation between emotions, quality features and
quality perception. To date however, it is not clear yet whether,
how and under which circumstances - technical quality aspects
(e.g., video compression artefacts, stalling events…) may
influence users’ emotional states and thus, their QoE. Nor is it
already well-understood how the emotional connotation of the
experienced content itself, in interplay with other factors, may
influence QoE and the quality perception process.
The latter requires first of all sets of stimuli for which the
emotional connotation and emotional impact is known in
advance [2]. Secondly, the investigation of how QoE, quality
perception and emotions are correlated also has implications
for the evaluation of QoE, which typically does not include
measures of emotion and experienced affect. As a result,
additional measures and types of measurement need to be
embedded in the existing paradigms.
This paper touches upon both issues. It presents results
from an inter-laboratory study in which stimuli that were
selected in an existing and published database (DEAP: ‘a
Database for Emotion Analysis using Physiological signals’
[3]), were used to trigger emotional responses. It contains 40
music
video
clip

To capture the test subjects’ emotional responses to the
DEAP-stimuli, we used both self-assessment measures and
electroencephalography (EEG) data in our study. In addition to
the traditional subjective QoE measurements, the
electroencephalogram has proven to be a valuable tool for
research in the auditory and visual domains. The approach of
measuring brain signals can provide additional information
about underlying processes [4, 5].

For this study the main focus regarding the EEG is on
variations of the alpha frequency band power, which can be
used as an indicator of cognitive state. A higher power in the
alpha band corresponds to a reduced cognitive state. Therefore
the variation of the band power of the alpha band between 9 –
11 Hz levels will be analyzed.
Extracted alpha values from frontal electrodes can also be
used to assess the emotional state. Higher-level left frontal
power results in an increased asymmetry index. The
asymmetry index is the relationship between left frontal and
right frontal lobe activity and can be calculated by using the

All authors contributed equally to this paper.

978-1-4799-8958-4/15/$31.00 ©2015 IEEE

QoMEX 2015

corresponding
ln(alphaleft))[9].

alpha

proportions:

(ln(alpharight)

−

In our study, we use both a clinical grade EEG system and
a low-cost EEG device. Recently, such comparably
inexpensive consumer-oriented EEG devices (e.g., EmotivEPOC), have appeared on the market. In [10], the criteria
provided by the Emotiv EPOC System were successfully used
to infer the level of frustration of participants when presented
with audiovisual stimuli with varying quality. However, the
data quality when using consumer EEG products seems to be
lower compared to clinical devices. This may have important
implications for the results, and thus needs to be considered.
II. METHODOLOGY
The experiment was conducted at two labs: at lab A (TUB),
a clinical grade system from g.tec with 16 dry electrodes was
used, thus high data quality is to be expected. Lab B (NTNU)
used a consumer-grade product from Emotive (14 electrodes).
A. Stimuli
The stimuli consisted of the 40 original music videos
suggested by DEAP [3]. They had a resolution of 800x600px
and an average bit rate of 2600kB/s (min=830 kB/s; max=3522
kB/s). The frame rate varied between the videos from 15 fps to
30 fps. The audio bit rate was constant for all videos with 192
kB/s and a sampling frequency of 44 kHz.
B. Experimental procedure and test environment
The experimental procedure was the same as in the original
study [3] apart from some minor alterations. Participants gave
informed consent, read the instructions, and filled in a prequestionnaire which included socio-demo, physical conditionand current state-related questions. They were e.g., asked to
depict their mood using the Pick-a-Mood scale (PAM)[11].
Next, the electrodes were applied, the quality of the signals was
checked and the recording of the EEG signals started.
During the experiment, the ‘Presentation’ software program
was used to present the stimuli (in randomized order) and to
gather the participants’ ratings. The first trial was not recorded
and was included to make the participants more familiar with
the feedback system and the questions. Once everything was
clear, the experiment started. Every trial consisted of showing a
fixation cross for 5s, followed by the video. Following the
video, participants gave ratings concerning arousal, valence,
dominance (9-point version of the Self-Assessment Manikin),
likeability (7-point scale), memories triggered by the content
(positive, negative memories or none), and quality (9-point
ACR scale). There was a short break after the first set of 20
videos.
At lab A, the experiment was conducted in an ITU-T Rec.
P.910 conform room, with grey curtains and artificial daylight
lighting. Videos were shown on a 27’’ full HD display in their
original resolution. The test participants were seated four times
video height away from the monitor. Audio was presented via
circumaural headphones at a predefined level. At lab B the
experiment was conducted in a lab conform the requirements
for audiovisual quality assessments from recommendation

ITU-R BT.500, with artificial daylight illumination and grey,
sound-proof absorbing walls. Audio was presented over two
professional-grade active monitoring loudspeakers located at ±
30 degrees to the screen. Videos were shown in the original
resolution on a 19’’ LCD monitor. The participants were seated
at a viewing distance of four times video height. One
researcher was involved in the data gathering at both labs.
C. Participants
In total, 39 people participated in the experiment. 13
participants took part at lab A (8 male, 5 female) with a mean
age of 25.8 years (ranging from 20 to 32). Visual sight was
tested via Snellen and Ishihara plates no abnormalities were
observed. None reported any hearing impairments. At lab B, 26
participants took part (16 male, 10 female). The mean age was
25.69 (S. D. = 8.14, range 18-50). None reported any problems
in hearing or vision. Participants received an incentive (cinema
voucher) as compensation for their participation.
III.

ANALYSES AND RESULTS

A. Subjective evaluation
1. Emotion elicitation
First of all it was analyzed to what extent the stimuli were
effective in eliciting the intended emotional reactions. Figure 1
depicts the mean ratings for the stimuli on the arousal-valence
plane for all four affect elicitation conditions (HAHV, LAHV,
LALV and HALV).

Figure 1: Location of the stimuli on the valence – arousal
plane for both labs. Mean values over both labs are
plotted.
In case the affective elicitation would have worked entirely
as intended by the makers of the DEAP database, there should
be 10 videos in each of the quadrants. As can be observed
however, the elicitation worked less well than expected,
especially for the high arousal stimuli. The ratings are to a
large extent concentrated on the lower half of the arousal scale.
The boxplots (Figure 2) depicting the ratings for arousal,
valence, likeability and quality for each of the affect elicitation
conditions provide a more detailed and nuanced picture. To
investigate whether there are significant differences in arousal,
valence, dominance, liking and quality ratings between the
affect elicitation conditions, we conducted Friedman’s

ANOVA analyses, followed by post-hoc pairwise comparisons
using the Wilcoxon signed-rank test. For all dependent
measures, these yielded significant differences at the
Bonferroni-corrected level of p≤ .008, presented in Table 1.

stimuli inducing higher valence are associated with a more
positive quality perception.

Table 1. Wilcoxon signed-rank test results (test statistic T,
Bonferroni-corrected significance level p and effect size r)
for the six pair-comparisons and the 5 dependents.
As expected, for arousal we find that high arousal stimuli
arouse the participants more than low arousal stimuli (both
those characterized by low and high valence) and this effect is
statistically significant. Similarly and again, as expected,
valence is significantly higher in the high valence affect
elicitation conditions than when comparing to the stimuli that
are intended to induce low valence responses. Additionally, the
low valence but high arousing stimuli receive significantly
lower valence ratings than videos labelled as low arousal – low
valence. Overall, the category of HALV videos corresponds
with the lowest emotional valence, implying that the
participants felt least happy when seeing these videos.
The self-reported dominance also differs significantly
between the different conditions, except when comparing
HALV-HAHV and LALV-HALV stimuli. On average,
participants felt least dominant when watching videos from the
HALV condition. However, as we can observe in Figure 2, the
whole spectrum of the scale is used, indicating that there might
be differences between certain groups in terms of how these
videos impact the feeling of being in control or not.
As can be clearly observed in the boxplot for likeability in
Figure 2, the results also indicate that there are substantial
differences in the appreciation of the videos depending on their
affective load. These differences are all significant, with the
exception of videos that are intended to induce high valence:
whether they are strongly arousing or not does not matter, they
are highly appreciated in both cases. Again however, the
boxplots indicate a large spread of the opinions, indicating that
there might be other factors that need to be taken into account.
Finally, we also find significant effects of the affective load
of the videos on their perceived quality: the quality of the
HAHV videos is perceived as significantly better than that
those from the HALV and LALV quadrants. Additionally, the
quality of the low valence clips is evaluated as significantly
poorer than that of the LAHV videos. It seems therefore that

Figure 2. Boxplots for arousal, valence, dominance,
likeability and dominance for the four affect elicitation
conditions.
These overall findings confirm that the emotion elicitation
was effective: the stimuli covering different quadrants of the
valence-arousal space induce different affective responses.
However - as mentioned above and as was also the case in the
original DEAP study - the data presented here were recorded at
two different locations. When we consider the two subsets
individually, we can immediately see that there are differences
in the location of the stimuli on the valence – arousal plane (see
Figure 3).
We performed Mann-Whitney tests to compare these
results between the two recording locations. The findings
(presented in Table 2) indicate that – notwithstanding the
overall impact of the emotion elicitation – there are significant
differences between the two labs. Stimuli in the LALV
quadrant yield significantly different responses for all
dependent variables. When considering the stimuli in LAHV
and HAHV quadrant, the reported arousal, valence and
dominance are significantly different and the HALV stimuli
correspond with significantly different arousal, valence and
quality ratings between the two labs.
The above findings indicate that there may be confounding
factors that need to be investigated further and that require
careful consideration when evaluating whether the emotional
stimuli elicited the intended emotions.

Figure 3. Location of the stimuli on the valence – arousal
plane for both data subsets (values for lab A depicted by
squares, values for lab B depicted by rounds).

Figure 4. Mean arousal, valence, dominance and likeability
rating per quality category. Error bars: 95 % CI.
3.

Lab influences?

The further investigation of quality again brings up – as
already briefly indicated above - the recording location as a
factor that may influence the responses to the affective stimuli.
When considering the influence of the quality of the stimuli for
the individual subsets from lab A and B, the results are in some
cases even pointing in the opposite direction. For example, in
both subsets, the results indicate that the extent to which
participants felt aroused is significantly different for low vs.
high quality videos (see Figure 5). For lab B, we find that the
arousal is significantly higher when the video quality is higher
(T = 16, p < .01, r = -0.53). For location A on the other hand,
we find an opposite effect (T = 16, p < .01, r = -0.62).
Table 2. Mann-Whitney test results (test statistic U,
significance level p, effect size r) indicating the differences
between the labs for all dependents.
2.

Influence of quality?

The original dataset as used e.g., in the DEAP database
does not consider the possible impact of the quality of the
videos on the affective state. In this study, we included
perceived quality as an additional measure. We also use it as
input for computing a new video categorization variable. More
specifically, the videos with the lowest average ratings for
perceived quality were grouped in the low quality category,
whereas the 20 videos with the highest quality ratings were
grouped in the high quality category. We then use this new
categorization to check whether the video quality has an
influence on the affective responses to and appreciation of the
videos (see Figure 4). These analyses (using a Wilcoxon
signed-rank test) indicated that high quality videos yield a
significantly higher valence (Mdn = 6) than low quality videos
(Mdn = 5), T = 84, p < .01, r = -0.46). In addition, the
appreciation of high quality videos (Mdn = 5) is significantly
higher than that of low quality videos (Mdn = 4), T = 18, p <
.01, r = -0.57). See Figure 4, for the mean values of the
different ratings. We did not find statistical evidence indicating
an influence of the quality on the self-reported arousal and
dominance.

Even though these findings are not discussed in more detail
here, this observation further underlines the need for caution
when eliciting emotional responses in experiments and to
investigate the unintended potential impact of other factors.
4.

Influences of other factors?

We consider another example of a human factor that may
influence the emotional response and that may therefore
confound the impact of the emotion elicitation, namely the sex
of the participant. Our analyses indicate that male and female
participants’ emotional responses and evaluations of the
likeability and quality of the stimuli are significantly different,
both when considering the dataset as a whole as when
considering the two subsets. For the high arousal – low valence
stimuli for instance, we found that there are significant
differences between male and female participants in terms of
arousal, valence, dominance and likeability. The evoked
emotional reaction may not be the same for both sexes and
potential differences between males and females should
therefore consistently be considered and analyzed.
Apart from the above examples, additional factors were
found to be significantly related to the emotional responses
during the experiment (including e.g., the mood of the
participant before the experiment, his or her age, the number of
hours that the test subject slept the night before and whether the
stimulus brings back positive or negative memories for the test
subject).

videos. This was also a significant effect when calculating a
repeated measures ANOVA for level of valence as independent
variable and FAI as dependent variable (F(1,10) = 9.01, p <
0.05). For the data from lab B this effect could not be observed
at all (F(1, 25)=0.11, n.s.).
Differentiating the trials concerning their quality, a
significant effect could be obtained for lab B (F(1,25) = 4.24, p
< 0.05), no significant effect was on data from lab A (F(1,11) =
0.87, n.s.).
1.5

Frontal Asymmetry Index
High Valence
Low Valence

1

Figure 5. Mean arousal per quality category and per lab.
Error bars: 95 % CI.
It goes beyond the scope of this paper to discuss all these
factors in detail, yet our findings clearly confirm that the
investigation of emotional impact of stimuli is far from
straightforward, and show that observed relations or even
assumed causal links between the emotional stimulus and the
emotional response may be confounded by other, unidentified
factors. As a result, additional considerations and checks are
needed to minimize and understand the effect of such
confounding variables.
B. EEG data
The recorded EEG data were epoched from 2s before the
video started until the video ended after 60s. The data were
analyzed concerning its frontal asymmetry index (FAI) and the
alpha power level. For the FAI-analysis the electrode positions
F3 and F4 were used for the datasets from both labs. For the
alpha power analysis based on the judged quality of videos
(low/high), the electrode with the highest alpha power value
was selected (lab A, electrode PO3). The electrode for lab B
was then selected so that the scalp locations were as similar as
possible (O1). For the analysis of the duration of the
experiment on the cognitive state of participants, the electrode
P3 was used for lab A and the electrode P7 was used for lab B.
It was not possible to use electrodes at the same scalp location
due to the electrode arrangements of the two devices.
FAI: The EEG recordings of the first 10s from the video
start versus the last 10s of the video were compared. Therefore,
a frequency analysis on the data from the two time frames was
performed (i.e. 1 – 10 s, and 50 – 60 s). The power was
calculated in the alpha frequency band (8 – 12 Hz) using
Welch’s method. If the quotient was greater 10 or less -10, the
trials were rejected as they were suspected to contain artefacts.
Equation (1) represents the calculation of the quotient,
representing proportion of the FAI for the first versus the last
10 s of the video:

Equation 1. Alpha asymmetry index.
Following equation (1), the results can be seen in Figure 6.
Here, it can be observed that for the data from lab A videos
with high valence resulted in a lower FAI than low valence

0.5

0

-0.5

A

B

Figure 6. FAI for A (left) and B (right) for conditions of
high and low level of valence.
Alpha power analysis: In Figure 7, it can be observed that for
the data from lab A, videos in the low quality category yield a
higher alpha power (F(1,12) = 3.74, p < 0.1, ETA2 = 0.238).
For the data from lab B, this effect could not be observed
(F(1,24) = 1.64, n.s.). For this analysis the power of the data (8
– 12 Hz) of all videos in the corresponding quality categories
was calculated per participant. Analyzing if the duration of the
experiment was fatiguing for the participants (Figure 8), a
significant effect was found for lab A (F(2,24) = 3.89, p < 0.01,
ETA2 = 0.29), no significant effect was on data from lab B (B:
F(2,48) = 0.41, ns).

Figure 7. Power in the alpha frequency band for A (left)
and B (right) for conditions of high and low quality. Error
bars: 95 % CI
For this analysis the data of each participant’s session was
divided in three equal parts (approximately 13.5 minutes
each). Then consequently the power for each interval was
calculated.

on the recording location and recording equipment that was
used. Overall, the quality of the data recorded in lab A (with
medical-grade EEG system) was less noisy than that recorded
in lab B, in which a consumer-grade headset was used. The
recording equipment is thus also a factor that should not be
neglected. On the long run it would be interesting to use the
gained and in future consolidated information on influencing
factor to develop a mathematical model for the prediction of
emotional experience. This model could also take habituation
effects towards similar emotions over time into account.

Figure 8. Power in the Alpha frequency band for A (left)
and B (right) for the time intervals of the experiment.
Error bars: 95 % CI
IV.

DISCUSSION AND CONCLUSION

In this paper, we shared findings from an inter-laboratory
study (N=39) in which EEG data and self-report data on
experienced affect, content likeability and perceived quality
were collected to evaluate the emotional impact of the affective
stimuli from the publicly available DEAP database. For the
subjective data, results indicate that the stimuli were to a
certain extent successful in eliciting the intended emotional
responses, as significant differences between the four emotion
elicitation categories were found. However, additional analyses
showed that there are other factors that may confound this
effect as they may be also (partly) responsible for some of the
observed differences. These include e.g., perceived video
quality, the lab, and a set of human factors (e.g., sex, current
mood, memories associated with the content, age …).
Some of these findings are also reflected in the EEG data.
For the general alpha band power, three effects were found.
One showing that the EEG-data, which was recorded by lab B,
seem to be noisier compared to the data recoded at lab A, as no
significant difference was found for lab B. It was shown that in
the EEG-data recorded at lab A, a higher alpha power was
measured during the presentation of low quality videos. This
effect is assumed to be corresponding to a decreased alertness
and lower cognitive state of participants during the video
presentation in low quality conditions in comparison to the
videos with high quality. Again, in the data recorded at lab A, it
was found that the amount of alpha band power was increasing,
along with the course of the experiment. Therefore, it is
assumed that the participants had a lower cognitive state in the
end of the experiment compared to the beginning.
The FAI – being an indicator of emotional response
towards a stimulus – was higher for the low valence stimuli.
Low valence stimuli were thus associated with a rather
negative response than videos being classified as high valence.
Again, this effect was only significant for lab A and not B.
When classifying the videos concerning their experienced
quality, a similar trend for the FAI could be observed, leading
to the assumption that the lower quality videos led to rather
negative emotional responses than higher quality videos.
However, these findings again only hold for the data from lab
A. The results for the EEG data differ therefore also depending

The results and implications of the study are relevant for
the field of QoE. They call for caution when evaluating the
responses to stimuli which are assumed and intended to evoke
certain emotions, and to explicitly consider other influencing
factors, especially when in a next step, the goal is to use such
‘ground truth’ stimuli for investigating the relationship between
quality and emotions. Even though in practice it may not be
possible to rule out every possible confounding variable,
including more comprehensive descriptors of the test subjects
in the analyses, may at least allow identifying and accounting
for the impact of the most important ones.
ACKNOWLEDGMENT
We thank COST Action IC1003 QUALINET and the
presidents of TUB and NTNU for supporting this
collaboration.
REFERENCES
[1]
[2]

[3]
[4]
[5]

[6]
[7]

[8]

[9]
[10]
[11]

A. Raake and S. Egger, "Quality and Quality of Experience," in
Quality of Experience, S. Möller and A. Raake, Eds., ed: Springer
International Publishing, 2014, pp. 11-33.
R. Schleicher and J.-N. Antons, "Evoking Emotions and
Evaluating Emotional Impact," in Quality of Experience:
Advanced Concepts, Applications and Methods, S. Möller and A.
Raake, Eds., ed Berlin: Springer, 2014, pp. 121-132.
S. Koelstra, C. Muhl, M. Soleymani, et al., "DEAP: A Database
for Emotion Analysis Using Physiological Signals," IEEE
Transactions on Affective Computing, vol. 3, pp. 18-31, 2012.
J.-N. Antons, Neural Correlates of Quality Perception for
Complex Speech Signals: Springer International Publishing, 2015.
S. Arndt, J. N. Antons, R. Schleicher, et al., "Using
Electroencephalography to Measure Perceived Video Quality,"
Selected Topics in Signal Processing, IEEE Journal of, vol. 8, pp.
366-376, 2014.
H. Berger, "Über das Elektroencephalogramm des Menschen,"
European Archives of Psychiatry and Clinical Neuroscience, vol.
87, pp. 527-570, 1929.
C. Duncan, R. Barry, J. Connolly, et al., "Event-related potentials
in clinical research: Guidelines for eliciting, recording, and
quantifying mismatch negativity, P300 and N400," Clinical
Neurophysiology, vol. 120, pp. 1883-1903, 2009.
M. S. Coles and M. Rugg, "Event-Related Brain Potentials: an
Introduction," in Electrophysiology of Mind: Event-Related Brain
Potentials and Cognition, M. S. Coles and M. Rugg, Eds., ed
Oxford: Oxford University Press, 1995, pp. 1-33.
J. A. Coan and J. Allen, "Frontal EEG asymmetry as a moderator
and mediator of emotion," Biological Psychology, vol. 67, pp. 7–
50, 2004.
A.-N. Moldovan, I. Ghergulescu, S. Weibelzahl, et al., "Usercentered EEG-based Multimedia Quality Assessment," Proc.
BMSB, pp. 1-8, 2013.
P. M. A. Desmet, M. H. Vastenburg, D. Van Bel, et al., "Pick-AMood; development and application of a pictorial mood-reporting
instrument," in 8th International Design and Emotion Conference
(11-14 September 2012), London 2012.

