EAI Endorsed Transactions
on Pervasive Health and Technology

Research Article

Rehabilitation after Stroke using Immersive User Interfaces in
3D Virtual and Augmented Gaming Environments
E. Vogiatzaki 1,* and A. Krukowski 2
1
2

Research for Science, Art and Technology (RFSAT) Ltd, Sheffield, United Kingdom
Intracom S. A. Telecom Solutions, Peania, Greece

Abstract
Stroke is one of most common diseases of our modern societies with high socio-economic impact. Hence,
rehabilitation approach involving patients in their rehabilitation process while lowering costly involvement of
specialised human personnel is needed. This article describes a novel approach, offering an integrated rehabilitation
training for stroke patients using a serious gaming approach based on a Unity3D virtual reality engine combined with a
range of advanced technologies and immersive user interfaces. It puts patients and caretakers in control of the
rehabilitation protocols, while leading physicians are enabled to supervise the progress of the rehabilitation via
Personal Health Record. Possibility to perform training in a familiar home environment directly improves the
effectiveness of the rehabilitation. The work presented herein has been conducted within the "StrokeBack" project cofunded by the European Commission under the Framework 7 Program in the ICT domain.
Keywords: Rehabilitation; Stroke; Virtual Reality Therapy; User-Computer Interface; Personal Health Records; Experimental Games.
Received on 28 August 2014, accepted on 27 February 2015, published on 18 May 2015
Copyright © 2015 J. E. Vogiatzaki and A. Krukowski, licensed to ICST. This is an open access article distributed under the terms of
the Creative Commons Attribution licence (http://creativecommons.org/licenses/by/3.0/), which permits unlimited use, distribution
and reproduction in any medium so long as the original work is properly cited.
doi: 10.4108/phat.1.1.e7

1. Introduction and motivation

2. Concept of the “StrokeBack” project

Stroke affects about 2 Million [1] people every year in
Europe. For these people the effect of stroke is that they lose
certain physical and cognitive abilities at least for a certain
period. More than one third of these patients i.e. more than
670,000 people return to their home with some level of
permanent disability leading to a significant reduction of
quality of life, which affects not only the patients
themselves but also their relatives. This also increases costs
of the health care services associated with hospitalisation,
home services and rehabilitation. Therefore, there is a strong
need to improve ambulant care model, in particular, at the
home settings, involving the patients into the care pathway,
for achieving maximal outcome in terms of clinical as well
as quality of life.

The StrokeBack project addresses both of the indicated
problem areas. The goal of the project is the development of
a telemedicine system to support ambulant rehabilitation at
home settings for the stroke patients with minimal human
intervention. With StrokeBack, the patients would be able to
perform rehabilitation in their own home where they feel
psychologically better than in care centres. In addition, the
contact hours with a physiotherapist could be reduced thus
leading to a direct reduction of healthcare cost. By ensuring
proper execution of physiotherapy trainings in an automated
guided way modulated by appropriate clinical knowledge
and in supervised way only when necessary, StrokeBack
aims to empower and stimulates patients to exercise more
while achieving better quality and effectiveness than it
would be possible today. This way StrokeBack system is
expected to improve rehabilitation speed, while ensuring

*

Corresponding author. Email: rtd@rfsat.com

1

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

E. Vogiatzaki and A. Krukowski

high quality of life for patients by enabling them to continue
rehabilitation in their familiar home environments instead of
subjecting them to alien and stressful hospital settings. This
offers also means of reducing indirect healthcare cost as
well.
The concept of StrokeBack is complemented by a Patient
Health Record (PHR) system in which training
measurements and vital physiological and personal patient
data are stored. Thus, PHR provides all the necessary
medical and personal information for the patient that
rehabilitation experts might need in order to evaluate the
effectiveness and success of the rehabilitation, e.g. to deduce
relations between selected exercises and rehabilitation speed
of different patients as well as to assess the overall
healthiness of the patient. In addition, the PHR can be used
to provide the patient with mid-term feedback e.g. her/his,
rehabilitation speed compared to average as well as
improvements over last day/weeks, in order to keep patient
motivation high.
The StrokeBack project aims at increasing the
rehabilitation speed of stroke patients while patients are in
their own home. The benefit we expect from our approach is
twofold. Most patients feel psychologically better in their
own environment than in hospital and rehabilitation speed is
improved. Furthermore, we focus on increasing patients’
motivation when exercising with tools similar to a gaming
console.
The StrokeBack concept puts the patient into the centre of
the rehabilitation process. It aims at exploiting the fact the
patients feel better at home, that it has been shown that
patients train more if the training is combined with attractive
training environments [4][13]. First, the patients learn
physical rehabilitation exercises from a therapist at the care
centre or in a therapists’ practice. Then the patients can
exercise at home with the StrokeBack system monitoring
their execution and providing a real-time feedback on
whether the execution was correct or not. In addition, it
records the training results and vital parameters of the
patient. This data can be subsequently analysed by the
medical experts for assessment of the patient recovery.
Furthermore, the patient may also receive midterm feedback
on her/his personal recovery process. In order to ensure
proper guidance of the patient, the therapist also gets
information from the PHR to assess the recovery process
enabling him to decide whether other training sequences
should be used, which are then introduced to the patient in
the practice again.

improving lost motor skills (e.g. virtual driving), and others.
In order to increase the efficiency of the exercises advanced
haptic interfaces are developed, allowing direct body
stimulation and use of physical objects within virtual
settings, supplementing the visual stimulation.
Immersive environments have quickly been found
attractive for remote home-based rehabilitation giving raise
to both individual and monitored by therapists remotely.
Depending on the type of a physical interface, different
types of exercises are possible. Interfaces like Cyber Glove
[2] or Rutgers RMII Master [3] allow the transfer of
patient’s limb movement into the virtual gaming
environment. They employ a set of pressure-sensing servos,
one per finger, combined with motion sensing. This allows
therapists to perform e.g. range of motion, speed,
fractionation (e.g. moving individual fingers) and strength
(via pressure sensing) tasks. Games include two categories:
physical exercises (e.g. DigiKey, Power Putty) and
functional rehabilitation (e.g. Peg Board or Ball Game)
ones. They use computer monitors for visual feedback.
Cyber Glove has been used by Rehabilitation Institute of
Chicago [4] also for assessing the pattern of finger
movements during grasp and movement space determination
for diverse stroke conditions. Virtual environments are
increasingly used for functional training and simulation of
natural environments, e.g. home, work, outdoor. Exercises
may range from simple goal-directed movements [5] to
learn/train for execution of everyday tasks.
Current generation of post-stroke rehabilitation systems,
although exploiting latest immersive technologies tend to
proprietary approaches concentrating on a closed range of
exercise types, lacking thoroughly addressing the complete
set of disabilities and offering a comprehensive set of
rehabilitation scenarios. The use of technologies is also very
selective and varies from one system to another. Although
there are cases of using avatars for more intuitive feedback
to the patient, the use of complicated wearable devices
makes it tiresome and decreases the effectiveness of the
exercise [13]. In our approach we have been exploring novel
technologies for body tracing that exploit the rich
information gathered by combining wearable sensors with
visual feedback systems that are already commercially
available such as Microsoft Kinect [6] or Leap Motion [7]
user interfaces and 3D virtual, augmented and mixed reality
visualisation.
The environment we develop aims to provide a full 3D
physical and visual feedback through Mixed-Reality
interaction and visualisation technologies placing the user
inside of the training environment. Considering that
detecting muscle activity cannot be done without wearable
device support, our partner in the project, IHP GmbH, has
been developing a customizable lightweight embedded
sensor device allowing short-range wireless transmission of
most common parameters including apart from EMG, also
other critical medical signs like ECG, Blood Pressure, heart
rate etc. This way the training exercises become much more
intuitive in their approach by using exercise templates with
feedback showing correctness of performed exercises.
Therapists are then able to prescribe a set of the

3. Concept of game-based rehabilitation
The use of virtual, augmented or mixed reality environments
for training and rehabilitation of post-stroke patients opens
an attractive avenue in improving various negative effects
occurring because of brain traumas. Those include helping
in the recovery of the motor skills, limb-eye coordination,
orientation in space, everyday tasks etc. Training may range
from simple goal-directed limb movements aimed at
achieving a given goal (e.g. putting a coffee cup on a table),

2

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

Rehabilitation after Stroke using Immersive User Interfaces in 3D Virtual and Augmented Gaming Environments

rehabilitation exercises as treatment through the EHR/PHR
platform(s) thus offering means of correlating them with
changes of patient’s condition, thus improving effectiveness
of patients’ recovery.

A conceptual system architecture of the StrokeBack system
is presented in Figure 1. It contain a Patient System
deployed at home supporting physiological remote
monitoring of patient wellbeing, runs the rehabilitation
games and offers full integration with online Personal health
Record (PHR) used as a data repository for sharing
information between the patient and his/her physician(s).

4. The StrokeBack architecture

Figure 1. Concept architecture of StrokeBack system

It offers full support to immersive user interfaces like
Kinect [6], Leap Motion [7], Emotiv EEG [14] and other
ones, combined with a range of virtual and augmentation

systems in order to enable fully immersive gaming
experience. As shown in Figure 2 we support 3D Smart
TVs, AR/VR visors and 3D projectors.

3

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

E. Vogiatzaki and A. Krukowski

Figure 2. Physical architecture of a gaming subsystem

The system is geared to offer also fully support usage
also on mobile devices like smartphones, tablets etc. We
also develop an affordable integrated gaming solution for
both near field and full-body exercises, which we call the
“Smart Table (Figure 3). The clinician part of the system
provides access to back-office PHR data repository for
constant monitoring of patients’ condition. The current
design contains two Kinect sensors, one at table level for
supporting use of physical objects and one at the top for
upper body exercising.

Two displays are embedded, one flat for physical objects
while the top one for displaying more classical board games
controlled either with Kinect or other user interfaces.
The progress of their rehabilitation and other relevant
physiological data including audio-visual connection are
also provided, if needed. The back-office services are
currently based on open-source solutions like Open EMR
[8] platforms. Ultimately, they will be migrated to the
intLIFE core PHR service platform. The overall gaming
system has been designed using client-server approach
allowing us to store the game repository and game provision
of the PHR server, thus maximally lowering the load on the
client devices. This allowed us from one side to run games
on such devices as Smart TVs or Smartphones, while
offering us flexibility of maintaining the latest versions of
the games without the need of updating the clients.
However, since any networked based system needs to
anticipate that connectivity may not be always maintained,
we have built into our system two scenarios: when network
is constantly available and when it is not (Figure 4).

(a)
(b)
Figure 3. Concept (a) and actual (b) “Virtual Table”

4

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

Rehabilitation after Stroke using Immersive User Interfaces in 3D Virtual and Augmented Gaming Environments

Figure 4. Online & offline “game” management

In the former case, game server is executed remotely,
while in the latter one it can be executed locally and use
games downloaded earlier. Similarly, physiological data
and game progress info can be either uploaded on the fly
or pre-stored and uploaded when network link is reestablished.

during the exercises. Considering very small sizes of such
sensors (less than 5x5mm each) a development of
lightweight wireless energy-autonomous (employing
energy harvesting) may be possible.
Muscle activity poses problems for measurement since
it has been well known for many years [9] that the EMG
reflects effort rather than output and so becomes an
unreliable indicator of muscle force as the muscle
becomes fatigued. Consequently measurement of force, in
addition to the EMG activity, would be a considerable
step forward in assessing the effectiveness of
rehabilitation strategies and could not only indicate that
fatigue is occurring, but also whether the mechanism is
central or peripheral in origin [10]. Similarly,
conventional surface EMG measurement requires accurate
placement of the sensor over the target muscle, which
would be inappropriate for a sensor system integrated
within a garment for home use. Electrode arrays are,
however, now being developed for EMG measurement
and signal processing is used to optimise the signal
obtained. Several different solutions have been
investigated to offer sufficiently reliable, but also
economic muscle activity monitoring. Finally, we
concluded on using EMG sensors on the 2R sensor
platform from Shimmer for system development
purposes, while a dedicated solution made by IHP GmbH.
However, EMG is not the only sensor that is needed
for home hospitalisation of patients suffering from
chronic diseases like stroke. This requires novel
approaches to combining building blocks in a body sensor
network. Existing commercial systems provide basic
information about activity such as speed and direction of

5. Body sensing and user interfaces
In order to enable the tracking the correctness of
performed exercises automatically without the constant
assistance of the physicians, an automated means of
tracking and comparing patient’s body movement against
correct ones (templates) has to be developed. This is an
ongoing part of the work due to the changing
requirements from our physicians. Although many
methods are in existence, most of them employ elaborate
sets of wearable sensors and/or costly visual observations.
In our approach we initially intended to employ a
proprietary approach using visual-light scanning, but the
recent availability of new Kinect, Prime Sense and Leap
Motion sensors made us change our approach and use
existing infrared-LED solutions.
When better accuracy is required that offered by 3D
scanners then additional micro embedded sensor nodes
are employed, e.g. gyros (tilt and position calibration) and
inertial/accelerometers (speed changes). Such are readily
available for us in both EPOC EEG U/I from Emotiv
(used currently as a U/I, though intended to be used in the
future for seizure risk alerting) and on Shimmer EMG
sensor platform that we use for detecting muscle activity

5

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

E. Vogiatzaki and A. Krukowski

movement and postures. Providing precise information
about performance, for example relating movement to
muscle activity in a given task and detecting deviations
from normal, expected patterns or subtle changes
associated with recovery, requires a much higher level of
sophistication of data acquisition and processing and
interpretation. The challenge is therefore to design and
develop an integrated multimodal system along with highlevel signal processing techniques and optimisation of the
data extracted. The Kinect system has potential for use in
haptic interfacing [11] and has already been used in some
software projects, and Open Source software libraries are
available for browsers like Chrome [12] and
demonstrations of interfaces to Windows 7 [13] systems
have been shown.
The existing techniques for taking measurements on
the human body are generally considered to be adequate
for the purpose but are often bulky in nature and
cumbersome to mount, e.g., electro-goniometers, and they
can also be expensive to implement, e.g., VIACON
camera system. Their ability to be used in a home
environment is therefore very limited. In this context, we
have decided to address those deficiencies by extending
the state-of-the-art in the areas of:

The project has reached two years of its lifetime already
and the prototyping as well as integration of various
technologies have already started. This refers to
physiological monitoring with Shimmer sensors, gaming
user interfaces as well as the games themselves, focussing
on the Unity3D engine.

Figure 5. Integration of the overall “home” system

 Extending the application of existing sensor
technologies: For example, we tend to use
commercially available MEMS accelerometers with
integrated wireless modules to measure joint angles
on the upper and lower limbs in order to allow wirefree, low-cost sensor nodes that are optimized in
terms of their information content and spatial
location.
 Novel sensing methodologies to reduce the number
of sensors worn on the human body, while
maintaining good information quality. For example,
many homes now have at least one games console
(e.g. Xbox, Nintendo Wii etc.) as part of a typical
family home entertainment system. With the advent
of the Xbox Kinect system, the position and
movement of a human will be possible to be
monitored using a low-cost camera mounted on or
below the TV set.
 Easy system installation and calibration by nonexperts for use in a non-clinical environment, thus
making this solution suitable for use at home for the
first timer and with support or untrained caretakers
and family.
 Transparent verification of correct execution of
exercises by patients may be based on data recorded
by Body Area Networks (BAN), correlation of
prescribed therapies with medical condition thus
allows to determine their effectiveness on patient’s
condition, either it is positive or negative.

A sub-unit assembly diagram of the “Patients home
training place” is depicted in Figure 5. The blue and grey
rectangles designate respective elements, while green
ones are the user interfaces. The PTZ-camera features
pan-tilt-zoom. Arrows show the data flow. The
description of the user interfaces shown in this diagram
follows below.
Physiological sensing
The application support for physiological sensors has
been made for both standard and embedded computers as
well as mobile devices, e.g. on Android phones (Figure
6). For those we used SDK and relevant example software
from Shimmer.

Figure 6. ECG sensing with Shimmer2R
Since home based rehabilitation may increase the risk
of stroke re-occurrence we have decided to include EEG
sensor, a 2*7-node Emotiv EPOC EEG, which we use for

6. System prototyping

6

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

Rehabilitation after Stroke using Immersive User Interfaces in 3D Virtual and Augmented Gaming Environments

monitoring of brain signals, looking for “flashing”
activity between the two brain spheres, indicated by
participating physiotherapists as a sign of a likely preevent condition (Figure 7).

click). Such an interface allowed for the first game-based
rehabilitation of stroke patients suffering from limited
hand control. The tests were first made with Mario Bros
game where all controls were achieved purely with
movements of a single palm. The algorithm for analysing
wrist position and generating respective keyboard clicks
has been developed initially in Matlab and then ported to
PERL for deployment along with the Kinect server on an
embedded hardware.

(a)
(b)
Figure 7. Emotiv EEG (a), sample brain activity (b)
This device offers an additional benefit for being used
as a supplementary gaming interface, thus shifting
patient’s perception from its use as a preventive device to
enjoying and using for controlling games with the “power
of the mind”. It is not without a merit that Emotiv offers
also a Unity3D support for its device, not to mention
ongoing development of an even more powerful
INSIGHT [14] sensor version.
Currently apart from searching for clues indicating prestroke risks and as “mouse”-like user interface, we use
EPOC for establishing a correlation between the mental
intention to move a limb and the physical action. By
combining with data from EMG sensors we aim to detect
cases when patient’s brain correctly issues a signal to e.g.
to move an arm, but the patient cannot do it e.g. due to a
broken nerve connection.

Figure 8. Wrist position detection algorithm
The algorithm is shown in Figure 8. It is based on the
idea that assuming that the wrist is placed steadily on a
support (requirements from physiotherapists), the patients
palm would always have fingers closer to the Kinect than
the rest of a hand, this allowing easily to determine the
palm position and direction the fingers point. Under such
condition, we did not have to pay much attention to
Kinect calibration and could avoid fixing the relative
position of the hand support with respect to the Kinect
device. This allowed us to remove the background simply
by disregarding anything more distant than the average
palm length centred on the centre of gravity (i.e. centre of
the palm itself).
The line was then interpolated through remaining
points in 3D, whereby the closest point detected was
indicating the tip of the closest finger. The direction of the
line was equivalent to the movement of a hand in a given
direction allowing us to generate the correct keystroke
combination (w-a-s-d for N-W-S-E). Since the accuracy
was, better than 1/8 of the circle it allowed us to
determine also diagonal movements (double keystrokes,
i.e. wd-wa-sd-sa for NW-NE-SE-SW). A predefined time
delay was applied corresponding to control detection
“speed”.
Since classical rehabilitation required the use of
physical objects, like cubes of glasses we have
implemented subsequently a “cube stacking” game, where
patient had to use the physical cubes and place them
carefully onto the placeholders displayed on the computer
screen positioned flat on the table (later replaced with

Rehabilitation Games using the “Kinect Server”
The principal user interface used to control our games has
been Microsoft Kinect, the Xbox version at first and then
the Windows version when it has been first released in
early 2012. Its combination of distance sensing with the
RGB camera proved perfectly suitable for both full body
exercises (exploring its embedded skeleton recognition)
as well as for near-field exercises of upper limbs.
However since Kinect has not been designed for short
range scanning of partial bodies, the skeleton tracking
could not be used and hence we had to develop our own
algorithms that would be able to recognise arms, palms
and fingers and distinguish them from the background
objects. This has led to the development of the “Kinect
server” based on open source algorithms. The first
implementation has used Open NI (closed in April 2014
following the acquisition of PrimeSense by Apple [15])
drivers offering the opportunity for our software to be
built for both MS Windows and Linux platforms.
The main features of our implementation offers the
capabilities of restricting the visibility window, filtering
the
background
beyond
prescribed
distance,
distinguishing between separate objects etc. This way we
were able to implement the Kinect based interface where
following the requirements of our physiotherapists we
replaced the standard keyboard arrows with gestures of
the palm (up, down, left, right and open/close to make a

7

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

E. Vogiatzaki and A. Krukowski

overhead projection) as shown in Figure 9 where red
cubes and placeholders (grey squares) are visible. Here
Kinect sensor is placed to scan horizontally at table level,
thus allowing to detect XYZ coordinates of the physical
cubes. By matching projections with Kinect scan regions
this allows detection of correct placement of the cubes.

virtual balloon was rewarded with an animated explosion
of the balloon and a respective sound. Such a game
proved to be very enjoyable for the patients letting them
concentrate on perfecting their movements while
forgetting about their motor disabilities, increasing
effectiveness of their training.
Embedded Kinect Server
The limitations of the Kinect in terms of the compatibility
with certain Operating Systems, diversity of oftenincompatible drivers and restrictiveness to high-end
computing platforms has pushed us to investigating
alternative ways of interacting with Kinect devices. This
has led to the attempt to develop an “Embedded Kinect
Server” or EKS. Our idea was to use a micro embedded
computer like Raspberry PI [16] or similar and allow the
client device that was running the game to access data
from the EKS via local wireless (or wired) network. Such
an approach would allow us to remove the physical
connectivity restriction of the Kinect and allow 3D
scanning capability from any device as long as it was
connected to a network.
Various embedded platforms were investigated:
Raspberry PI, eBox 3350 [17], Panda board [18] (Figure
11) and many other ones. The tests have revealed the
inherent problem with the Kinect physical design that is
shared between the Xbox and the subsequent Windows
version that is the need to draw high current from USB
ports in order to power sensors despite separate power
supply still required.

Figure 9. Game using real cubes on a virtual board
The first level starts with one cube and placeholder
parallel to screen edge, then as the game progresses more
cubes are used and their requested position could be in
any direction. At the end, a score was calculated taking
into consideration both the time to place the cubes and the
accuracy of placing them over the placeholder. The score
was reported in the PHR allowing the physician to track
the progress of the patient from one exercise to another.
Another variant of the game introduced the possibility of
stacking cubes one on top of the other.
An alternative gaming approach to mixing virtual and
real objects was a game where patients were requested to
through a paper ball at the virtual circles displayed on the
screen as shown in Figure 10. The Kinect sensor
synchronised with location of projected object detects
physical ball reaching the distance of the wall. Combined
with its XY coordinated, this allows to detect the
collision.

(a)
(b)
Figure 11. Embedded Kinect Server deployment:
Panda board (a) and physical prototype integrated
with the MS Kinect for Windows sensor (b)

Hardware modifications of the Raspberry PI aimed to
increase the current supplied to its USB ports, use of
powered external USB hub and other work-around proved
all unsuccessful. To date only the Panda Board proved to
be the only embedded computer able to maintain the
Kinect connectivity and running our EKS. In our tests we
have managed to run the Mario Bros game on an Android
smartphone and use the Kinect wirelessly to control the
game by moving patient’s wrists.
Figure 10. Throwing real paper ball at virtual targets

Full-Body Games with Avateering
Subsequently we have investigated more advanced class
of games for stroke patients for full-body exercises. In
such a case we have chosen to build such games using 3D

Such a game allows patients to exercise the whole arm,
not just the wrist. Hitting the circle that represented a

8

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

Rehabilitation after Stroke using Immersive User Interfaces in 3D Virtual and Augmented Gaming Environments

engine and employ avateering approach, that is patient’s
body motion capture and its projection onto a virtual
avatar. When we have started our first implementation,
the MS Kinect SDK was not available yet and hence we
have explored various “hacks” built by the Kinect
developer community. The most applicable to our needs
appeared to be ZigFu [19], which was compatible with
Open NI drivers and easy to use under Unity3D [20]
editor. It proved easier than using commercial products
like Brekel [21] or Autodesk Motion Builder [22]. The
prototype system uses different environments, from
familiar home spaces in photorealistic quality [23]
(Figure 12) to generic hospital environments (Figure 13).

of following the expected movements. The two scenarios
are being subject to assessment by physiotherapists and
the decision as to which one will be used for the final
system implementation will be depended on evaluation
results.
An important advantage of Unity3D over other 3D
gaming engines like Cry Engine 3 or Unreal Engine is the
possibility to compile games to run either as stand-alone
or under from inside a WEB page. The latter approach
makes it easier for integrating games as therapies within
the PHR system accessible and controllable via WEB
browser. A use of this feature for exercises with a real
patient is shown in Figure 14.

Figure 14. Real patient playing game online using
WEB browser using Unity3D engine & ZigFu plug-in
Figure 12. Avateering in a “home” like environment

The Kinect Server and wrist controls have been integrated
into a number of games under Unity3D in order to
evaluate the adopted concepts with end users, such as into
an “Infinite Runner” [26], shown in Figure 15. It is
incentive based game combining rehabilitation with
entertainment. High scores (coins collected) correspond to
improvement in recovering hand movement capabilities.

Figure 13. Avateering aimed to repeat movements
of an instructor in a “hospital” like virtual environment

Scenes with one and two avatars were implemented.
The first one was intended as a base for self-training
exercises where instruction would be overlaid over the
avatar to indicate the movements that the patient would
need to perform in order to pass the exercise.
A two-avatar scenario was aimed to offer the side-byside exercise together with a virtual rehabilitator where
patient would need to follow the movements of the
“physician” seeing him/her-self at the same time. In both
cases, the score would be corresponding to the accuracy

Figure 15. Integrating Kinect Server and wristrecognition to control the “Infinite Runner” game
3D Stereoscopic Visualisation
In order to enhance the realism of the games developed
with Unity3D engine a stereoscopic projection was
implemented offering a sense of depth on supported 3D
displays. The current approach has been based on the

9

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

E. Vogiatzaki and A. Krukowski

 Patient starts the „Tele-rehabilitation“-session by
using the interaction-board (Kinect-based “touch
table”).

“camera to texture” projection feature available in a PRO
version of Unity3D.

 Patient selects the “autonomous training“, i.e.
without real time connection to the therapist, or
“with supervision“. In case of no supervised training
is scheduled or there is no connection to internet, an
“auto training“ mode is selected automatically.
 Patient selects an exercise game and runs it. She/he
may consider former trainings scores and adjust the
difficulty level. Some exercises may be accompanied
by music and the patient may be asked for the
desired music title. All actions follow a set of
permissions that have been configured by therapist
before.
 Patient executes the exercise in the autonomous
modus. The PHR monitors and analyses the
execution of tasks and exercises and generates
respective feedback. Finally, training results and
acquired scores are uploaded to PHR.

Figure 16. Stereoscopic projection using Unity3D
camera-to-texture feature [24]

It has been based on various published experiments [2425]. A dual virtual cameras placed near each other have
their images projected onto virtual screens, in turn
captured by a single output camera thus creating a side by
side display (Figure 16). Such an image is then suitable
for driving common 3D displays such as of the 3D Smart
TV (e.g. Samsung UE46F6400) or 3D projector (e.g.
Epson EH-TW5910) with frame-switching 3D glasses.
Both of those have been successfully tested with our
system. In the future tests we will evaluate also panoramic
virtual 3D visors (e.g. Oculus RIFT) and 3D augmented
glasses (e.g. VUZIX Star 1200XLD) for virtual and
mixed-reality games respectively.

 Patient executes the exercise with live-supervision of
the therapist. She/he is observed by the therapist,
may see the therapist on the screen via bidirectional
video communication and may receive comments
and training guidance in real-time.
 Patient can see the final evaluation and score of an
exercise after finishing it.
As expected Kinect has proven unreliable for near field
upper limb tracking requiring frequent re-calibration,
while Leap Motion offered sufficient precision for fingers
and palm tracking.

Integration of Leap-Motion User Interface
The latest addition to the portfolio of our user interfaces
has been the Leap Motion device. It has proven invaluable
for rehabilitation of upper limbs thanks to its superior
ability to detect close range distances over the Kinect. Our
developments have led us to use features already offered
by the Leap Motion SDK and the community
applications, e.g. the Touchless for Windows allowing
controlling mouse-like control of the Windows
applications. This has led us to experiments with standard
games used for the rehabilitation of stroke patients like
memory board game and experimenting with operating
virtual objects in a virtual 3D space using only your
fingers. Both of those have proven very enjoyable for our
patients.

7. Validation and preliminary evaluations
Both technical system validation tests and preliminary
evaluations by other project partners have been
performed. Regarding the evaluations of the home
rehabilitation system, we have used the following regime:
 Patient switches on the rehabilitation gaming device.

10

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

Rehabilitation after Stroke using Immersive User Interfaces in 3D Virtual and Augmented Gaming Environments

7. Conclusions and future work

[8]

In the frame of the project the most of the technologies
have been implemented, including integrated Smart Table
as in Figure 3(b), integration with PHR systems allowing
management of rehabilitation by physicians as well as a
range of user interfaces, not only based on a Kinect
sensor.
The initial technical validation tests have proven the
viability of the design approach adopted. The suitability
of Leap Motion for “Touch-Screen”-like applications and
game development under Unity3D has been confirmed.
Following the success of the technical system tests, the
clinical trials with real patients are being conducted since
September 2014 into early 2015. Primarily the focus is be
made on the motion capture and recording of the real
person (therapist) for subsequent use for demonstration of
correct exercises by animating his/her avatar as shown
earlier in Figure 13.
Furthermore a 3D hand model needs to be developed,
rigged and animated in order to allow its use in Unity3D
games. Subsequently the overall integration of the gaming
system will be performed whereby selection of games and
the necessary data exchange mechanism with the PHR
system will be developed. The most difficult work will be
related to the real-time comparison of avatar movements
for providing an accurate scoring of the correctness of
exercises, to be achieved in liaison with the
physiotherapists.

[9]

[10]

[11]

[12]

[13]

[14]
[15]

[16]

Acknowledgements.

[17]

The research leading to these results has received funding from
the European Union Seventh Framework Program (FP7/20072013) under grant agreement n° 288692-StrokeBack.

[18]

References
[1]
[2]

[3]

[4]

[5]

[6]

[7]

Book: P. Kirchhof, et al, “How Can We Avoid a Stroke
Crisis?” ISBN 978-1-903539-09-5, 2009.
WEB link: Virtual Technologies Inc. [Internet]. [Updated:
2010, cited: 2014 Aug 17]. Available from:
http://www.cyberglovesystems.com/all-products
Journal article: M. Bouzit, G. Burdea, G. Popescu, R.
Boian, “The Rutgers Master II—New Design ForceFeedback Glove”, IEEE/ASME Transactions on
Mechatronics, Vol. 7(2), 2002
WEB link: Rehabilitation Institute of Chicago [Internet].
[Updated/cited: 2014 Aug 17]. Available from:
http://www.ric.org/conditions/stroke/
Conference: M. McNeill, et al “Immersive virtual reality
for upper limb rehabilitation following stroke”, Systems,
IEEE International Conference on Man and Cybernetics,
ISBN: 0 7803 8566 7, 2004
WEB link: Microsoft Kinect [Internet]. [Updated/cited:
2014
Aug
17].
Available
from:
http://kinectforwindows.org
WEB link: Leap Motion [Internet]. [Updated/cited: 2014
Aug 17]. Available from: https://www.leapmotion.com

[19]
[20]

[21]

[22]

[23]

[24]

[25]

11

WEB link: Open EMR [Internet]. [Updated: 2012, cited:
2014 Aug 17]. Available from: http://www.open-emr.org
Journal article: R. Edwards and O. Lippold, “The relation
between force and integrated electrical activity in fatigued
muscle”, Journal of Physiology, Vol. 28, pp. 677-681,
1956.
Conference: R. Enkona and D. Stuart, “The contribution of
neuroscience to exercise studies”, Federation Proceedings,
Vol. 44, pp. 2279-2285, 1985.
Journal article: J. Giles, “Inside the race to hack the
Kinect”, The New Scientist, Volume 208, Issue 2789, pp.
22-23, ISSN 0262-4079, 2010.
WEB link: “MIT Media Lab Hacks the Kinect for Browser
Navigation with Gestures” [Internet]. [Updated: 2010 Nov
24, cited: 2014 Aug 17]. Available from:
http://www.readwriteweb.com/2010/11/24/kinect_browser
_navigation
Book: “Next-generation remote healthcare: A practical
system design perspective”, edited by Koushik Maharatna
et al, Chapter 6 by Artur Krukowski, Emmanouela
Vogiatzaki and Juan Mario Rodríguez, “Patient Health
Record (PHR) system”, Springer Science and Business
Media New York, Nov 2013
WEB link: Emotiv INSIGHT [Internet]. [Updated/cited:
2014 Aug 17]. Available from: http://emotivinsight.com
WEB link: “Apple acquires Israeli 3D chip developer
PrimeSense” [Internet]. [Updated: 2013 Nov 25, cited:
2014
August
17].
Available
from:
http://www.reuters.com/article/2013/11/25/us-primesenseoffer-apple-idUSBRE9AO04C20131125
WEB link: Raspberry PI [Internet]. [Updated/cited: 2014
Aug 17]. Available from: http://www.raspberrypi.org
WEB link: Roby Savvy eBox-3350MX [Internet].
[Updated: 2012 Jul 18, cited: 2014 Aug 17]. Available
from:
http://robosavvy.com/store/product_info.php/products_id/1
704
WEB link: Panda Board [Internet]. [Updated/cited: 2014
Aug 17]. Available from: http://www.pandaboard.org
WEB link: ZigFu for Unity3D [Internet]. [Updated/cited:
2014 Aug 17]. Available from: http://zigfu.com
WEB link: Unity3D game engine [Internet].
[Updated/cited: 2014 Aug 17]. Available from:
http://unity3d.com
WEB link: Kinect marker-less motion capture (Brekel)
[Internet]. [Updated: 2008, cited: 2014 Aug 17]. Available
from: http://www.brekel.com
WEB link: Motion Builder [Internet]. [Updated/cited: 2014
Aug
17].
Available
from:
http://www.autodesk.com/products/motionbuilder
WEB link: Virtual Room [Internet]. [Updated: 2014 Feb
26, cited: 2014 Aug 17]. Available from:
https://www.assetstore.unity3d.com/en/#!/content/6468
WEB link: Lloyd Hooson, “Unity 3D Stereoscopic
Development” [Internet]. [Updated: 2010, cited: 2014 Aug
17].
Available
from:
http://lloydhooson.co.uk/2010/01/12/unity-3dstereoscopic-development
WEB link: Human Interface Technology Laboratory
Australia (HIT Lab), “Stereoscopic 3D”, [Internet].

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

E. Vogiatzaki and A. Krukowski

[Updated: 2011 Jun 19, cited: 2014 Aug 17]. Available
from http://www.hitlab.utas.edu.au/wiki/Stereoscopic_3D
[26] WEB link: 3D Infinite Runner Toolkit [Internet].
[Updated: 2014, cited: 2014 Aug 28]. Available from:
http://u3d.as/content/dreamdev-studios/3d-infinite-runnertoolkit/5Nh

12

EAI Endorsed Transactions on
Pervasive Health and Technology
01 -05 2015 | Volume 01 | Issue 1 | e7

