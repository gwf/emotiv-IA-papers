Journal of Software

One Approach for Identification of Brain Signals for Smart
Devices Control
Georgi P. Dimitrov1, Galina S. Panayotova1 , Eugenia Kovatcheva1, Daniela Borissova2 and Pavel
Petrov3
1 University

of Library Studies and Information Technologies, Sofia, 1712, Bulgaria
of Information and Communication Technologies at Bulgarian Academy of Sciences,Acad. G. Bonchev
St., Bl. 2, 1113 Sofia, Bulgaria
3University of Economics - Varna, Knyaz Boris I Blvd. 77, 9002 Varna, Bulgaria
2Institute

* Corresponding author. Tel.: 0882415054; email: geo.p.dimitrov@gmail.com
Revised submitted June 19, 2018; accepted July 30, 2018.
doi: 10.17706/jsw.13.7.407-413
Abstract: Nowadays the UX design become on a next level. Together with new way of interaction are introduced

as finger and hand movement. The technology offer and thought-driven approach with so called brain-computer
interface (BCI). This possibility opens new challenges for uses as well as for designers and researchers.
More than 15 years there are devices for brain signal interception, such as EMotiv Epoc, Neurosky headset and
others. The reliable translation of user commands to the app on a global scale, with no leaps in advancement for
its lifetime, is a challenge. It is still un-solve for modern scientists and software developers. Success requires the
effective interaction of many adaptive controllers: the user's brain, which produces brain activity that encodes
intent; the BCI system, which translates that activity into the digital signals; the accuracy of aforementioned
system, computer algorithms to translate the brain signals to commands. In order to find out this complex and
monumental task, many teams are exploring a variety of signal analysis techniques to improve the adaptation of
the BCI system to the user. Rarely there are publications, in which are described the used methods, steps and
algorithms for discerning varying commands, words, signals and etc.
This article describes one approach to the retrieval, analysis and processing of the received signals. These data
are the result of researching the capabilities of Arduino robot management through the brain signals received by
BCI.
Key words: Integrated information systems, Brain Computer Interface, BCI, BIG Data, data processing, sensors,
EMotiv

1. Introduction
The main goal of this article is to highlight the ability to reliably discern the varying brain signals. In a
perspective, the clear signal identification will ensure development mathematical tools and algorithms for
electrical devices, such as wheelchairs and other similar devices needed by people with reduced communication
and motor abilities[1,2]. Also, research will enhance the utilization of the Internet of Things (IoT). Unfortunately,
the standard distributed with widespread BCI devices’ interface has a very limited command dictionary[3,4].
Our team analyses the necessary BCI signals for driving a remote control car. For the needs of our research, we
have determined eight simplified base commands - START, STOP, LEFT, RIGHT, FORWARD, BACKWARD,
FASTER and SLOWER. In this article the analyses of only two commands - START and STOP is described as well
as the differences between these two commands.
The brain emits ElectroEncephaloGraphic(EEG) signals, which are caught by the 5 electrodes of EMOTIV
Insight 5+ device. The raw EEG data is picked up by the electrode and are sent via the Bluetooth into the
407

Volume 13, Number 7, July 2018

Journal of Software

computer. This device can discern 5 signals( Fig. 1):
AF3 – Attention
T7 – Verbal memory
Q1 – Visual Processing
T8 – Emotional memory
AF4 – Judgment

Fig. 1. Map of the electrodes in Epoc Insight 5 chanels.
The received signals are store into database The application BrainData (Fig. 2) developed in university
laboratory maintain this process. The application features includes the possibilities for the simultaneous
recording and processing of BIG DATA[3]. This means different types of data are recorded at the same time, such
as: raw data from BCI, the subject shown at that moment, the video recording of the experiment and other. The
system allows interoperability - receiving the data from the BCI system, processing, exporting of the data to
other systems and communication with other apps, which can use these data.

Fig. 2. Brain data.
The steps of creation process are: 1) Obtaining an EEG signal; 2) Inserting data into a database; 3) Filtering
408

Volume 13, Number 7, July 2018

Journal of Software

and classification of EEG signals; 4) Processing of the data array; 5) Utilization of the already processed Smart
Device Management data. The focus here is on the step 3 only.

2. Methods
2.1. Data Collection
The used data are collected during BCI experiments and analyzed offline. It will be described later.
There are 3 examinees. During the experiment, each participant see 8 different pictures (commands). Pictures
are changed at different time intervals – 0.25, 0.5, 1 and 1.25 seconds in a random principle. Each participant,
after seeing the picture, mentally commands and executes it. As was mention above the two opposit commands –
START and STOP are observed. Each examinee made 7 attempts. Each command is shown more than 360 times
in total, or 120 times for each participant.
In real time the signals received from the Epoc are transferred via Bluetooth into the computer. Each trial are
recorded 129 rows of data into the database. The count of the records is shown on Table 1. The data are
obtained with SDK tool, provided by Emotiv ( github.com/Emotiv/ community-sdk). The collecting information
for the experiment, the commands, raw data and screen capture are recorded at the same time into the database,
then data are exported and processed using MathLab environment.
Table 1. Count of the Experiments
COMMAND
START
STOP
369
367
129
100396
99674

Count of the change pictures
Count of the rows whit signal data in one experiment
All count of records

2.2. Data Processing
This research gives a useful insight understanding of the meaning for each Emotiv EEG Sensor.
The raw data, received during the display of the “Stop” command are shown on Table 2.
Table 2 Raw data – “START”
AF3
4233.07
4233.52
……..
4229.48

T7
4572.24
4570.72
……..
4494.43

O1
4195.39
4225.62
……..
4231.28

T8
4188.37
4216.47
……..
4165.12

AF4
4172.35
4179.49
……..
4176.22

The raw data, received during the display of the “Stop” command are shown on Table 3.
Table 3 Raw data – “STOP”
AF3
4222.33
4253.96
…………
4209.40

T7
4555.69
4683.83
…………
4500.95

O1
4158.56
4149.65
…………
4244.27

T8
4197.81
4255.87
…………
4167.63

AF4
4153.63
4136.59
…………
4147.19

2.3. Filtering the Signal
A main characteristics of the data, which are used for research and analysis, are to be accurate and valid. It is
rarely possible because when data are copied from reality via a sensor/observer, through transmission and
finally stored, it is susceptible to corruption for many reasons[6,7]. During the experiments it is impossible for
the test subject to be permanently concentrated upon the given command. This leads to receiving unnecessary
or false data in the stream. The original raw data is showing on Figure 3. At first glance the signals have big
amplitudes. This data must be filtered.
The filtered stream of data are with exclusion of those whish values differ by 50% from the average (Figure 4).

409

Volume 13, Number 7, July 2018

Journal of Software

Figure 3 Raw data before filtering

Figure 4 Raw data after filtering

On the Table 4 is shown the count of the records before and after filtering and percent of the excluded rows.
Table 4 rows and filtered rows
START
100396
81432
19%

All rows with data
Filtered rows
% excluded records

STOP
96794
81395
16%

2.4. Processing Data
To distinguish data for different command is a crucial for this research, i.e. the identification of the data[8].
This is arrange by extracting the mean values, standard deviation and differentiate the meaning of the signal
values on the each channel. The availability of distinct differences would indicate the possibility of
distinguishing the incoming signals.
Mean value of the signal
The avg. values of each channel is calculated in a Mathlab environment:
The resulting avg. values are shown on Table 5.
Table 5. AVG Values for Each Command and Each of the Channels
AVA. values
START
STOP
4200,83764287520 4206,90253712517
4261,67373675012 4259,72984825013
4103,32124187518 4104,19762087510
4166,84227274986 4165,75719124990
4156,81051724984 4159,94656387485

AF3
T7
O1
T8
AF4

The graph for the resulting values is shown in the Fig. 5.

Fig. 5. AVG values for each command and each of the channels.
Standard deviation
The next step is calculating the standard deviation for each command and each of the channels.
The results show the following: The deviation is biggest at channel T7 and lowest at channels AF3 and AF4. In
other words, AF3 and AF4 have the most durable signals, as shown in Table 6 and Fig. 6.
410

Volume 13, Number 7, July 2018

Journal of Software

Table 6. STD Values for each Command and Each of the Channels
Chanel
AF3
T7
O1
T8
AF4

STDEV(„START”)
79.4551

STDEV(„STOP”)
78.2322

187.8361
100.1024
85.1357
63.4918

184.6027
98.2479
86.1827
62.3431

Fig. 6. Graph with STD values for each command and each of the channels.
The differences between the mean values in every channel
In a Mathlab environment we calculated the differences between the mean values of the signals for each
channel separately.
The resulting differences are shown in Table 7.
Table 7. Differences between the Values for Each Channel
START - STOP
-6.0649
1.9439
-0.8764
1.0851

AF3
T7
O1
T8

AF4

-3.1360

Down are shown the differences between the values of every command in each individual channel.

3. Conclusions
Identification of the separate brain signals and using this for interaction driven devices will increase in the
next years but first steps are done.
In this research application of several data processing as filtering, calculation of average values, average
deviation shows clear difference between channels of the signals for each command. This can be used for the
creation of suitable algorithms for the processing in real time. Using similar methods and approaches this will
give the opportunity, with the acquisition of an expansive database with suitable commands and their base
characteristics for the commandeering of remote controlled devices.
Our team hopes in the future to build the necessary knowledge base for the various commands required for
411

Volume 13, Number 7, July 2018

Journal of Software

direct device management using brain signals

Acknowledgements
This work is partly supported by the project PPNIP-2018-15 “Creating an model of interface for the
management of Smart Objects ”.

References
[1] Zhibin, T., William, H. B., & Qianru, Z., (2013). Real-time EEG signal processing based on TI’s TMS320C6713
DSK. Proceedings of the 120th ASEE Annual Conference@Exposition.
[2] Colombet, B., Woodman, M., Bénar, C. G., & Badier, J. M. (2016). AnyWave: A cross-platform and modular
software for visualizing and processing electrophysiological signals.
[3] Schalk, G., Brunner, P., Gerhardt, L. A., Bischof, H., & Wolpawa, J. R. (2008). Brain–computer interfaces
(BCIs): Detection instead of classification brain-computer interface research and development program.
Journal of Neuroscience Methods, 167, 51–62
[4] Plesinger, F., Jurco, J., Halamek, J., & Jurak, P. (2016). SignalPlant: An open signal processing software
platform. Physiol Meas.
[5] Tara ThiagarajanIs the Emotiv EPOC signal quality good enough for research?, Retrieved December 1, 2016,
from http://sapienlabs.co/emotiv-epoc-signal-quality-good-enough-research/
[6] Dennis, J. M., & Jonathan, R. (2011). Wolpaw, brain-computer interfaces for communication and control.
Communications of the ACM.
[7] Jaromir, S., Roman, Z., Roman, S., & Roman. J. (2015). Using brain - Computer interface for control robot
movement. Proceedings of the 29th European Conference on Modelling and Simulation.
[8] Murk, S., Rabel, T., Ahsan, Z., Muhammad, A. B., & Hinesh, K. Wirelss Brain Computer Interface Streams
Control Command.
Georgi Petrov Dimitrov is a doctor of modeling and simulation process and a professor of
computer science in the University of Library Studies and Information Technologies, Sofia,
Bulgaria. Deputy Dean of the Faculty of Information Systems and Technologies. He currently
works in area on Big Data, Web Data Analyst, IoT and etc. Prof. Dimitrov is the author of more
90 scientific publications, books and textbooks.
Galina Panayotova is a doctor of mathematics and professor of mathematical modeling in
the State University of Library Studies and Informational technologies and University “Prof. Dr.
As. Zlatarov”- Burgas.
Research interestsincluding: Nets and tissues in Finsler and Riemannian spaces;
Application of differential geometry in the theory of PDE;Use of information technologies and
applications in education; Mathematical and Computer Modeling. Prof. Panayotova is the
author of more 80 scientific publications, books and textbooks.
Eugenia Kovatcheva is an assoc. prof. at the University of Library Study and Information
Technologies. She is a Scientific Secretary of the Dept. of Information Science. Her
background is in the applications of Information Technologies and Cloud Computing in
education, and training; adaptive learning systems. Her areas of interest are in UX design and
Internet of Things, Digital Repository, Information, Knowledge and Innovation Management.
Daniela Borissova is currently associate professor at the Institute of Information and
Communication Technologies of Bulgarian Academy of Sciences. She has specializations in
Canada, Norway, Albania and Czech Republic. Her main research interests are related to
412

Volume 13, Number 7, July 2018

Journal of Software

decision support systems, modeling and optimization, e-learning, web design and development of web-based
applications.

Pavel Stoyanov Petrov is a doctor of economics and associate professor of computer science
in the "University of Economics - Varna", Varna, Bulgaria. Main research areas are: web
security technologies, AI, business intelligence and etc. Assoc. Prof. Petrov is author of more
than 60 scientific publications, books and textbooks.

413

Volume 13, Number 7, July 2018

