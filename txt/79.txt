GU J Sci, Part C, 8(2): 458-474 (2020)
Gazi Ãœniversitesi

Fen Bilimleri Dergisi
PART C: TASARIM VE TEKNOLOJÄ°
http://dergipark.gov.tr/gujsc

Recognition of Human Emotions by Machine Learning Method Using
Turkish Music Stimuli
Mehmet Bilal ER*

Harun Ã‡Ä°Ä

Harran University Faculty of Engineering, Department of Computer Engineering, Haliliye/ÅanlÄ±urfa

Graphical/Tabular Abstract

Article Info:
Research article
Received: 10/02/2020
Revision 03/05/2020
Accepted: 16/05/2020

In this study, experiments are carried out both on our own dataset and on the DEAP dataset, which
are widely used in the literature. Different types of Turkish songs were played to the participants.
By examining the electrical waves that occur in their brain's surface, happy, sad, relaxing and
angry mood states were recognized. Participants were asked to listen to music from different types
in a noiseless environment. To classify the emotions, electroencephalography (EEG) signals were
saved primarily from different channels. Certain features have been extracted from these signals.
Extracted features have been classified using machine learning algorithms.

Highlights
â€¢ EEG
â€¢ Emotion Recognition
â€¢ Machine Learning

Figure A. schema of the Steps of Emotion Recognition

Keywords
Recognizing Human
Emotions
EEG
Machine Learning
Signal Processing

Purpose: The aim of this study is to estimate the emotional state with machine learning and signal
processing techniques by measuring the electrical energy of the brain using Turkish music stimuli.
Theory and Methods: The proposed model for the recognition of human emotions while
listening to music is explained step by step. For the proposed model brain signal recording, feature
extraction calculations and classification types are given in the paper. Emotive recording device
was used to record brain signals. Support Vector Machines (DVM), K Nearest Neighbor (KNN)
and Artificial Neural Networks (ANN) machine learning algorithms were used to classify signals.
Results: We conduct an experiment, in a silent and dark environment, where 10 people
participated and they are required to listen to different types of music in order to record brain
signals. Four emotion labels have been used: angry, sad, happy or relaxing emotion. First,
recorded EEG signals passed a bandpass filter. Then, the classification was made by extracting
the feature from the filtered signals and the results are compared in section 5.
Conclusion: In this study, a new method is presented for emotion recognition on EEG signals
while listening to music using some signal processing and machine learning methods. According
to the results, it is shown that the proposed method can be used for the problem of recognizing
human emotions. It has been observed that the efficiency of the system increased depend on
increasing the number of samples and taking the recorded signals from humans at the right time
(morning). It is recommended to prepare EEG datasets by using music data as a stimulus for
future studies and to use deep learning models in the problem of recognition of human emotions.

*Corresponding author, e-mail: bilal.er@harran.edu.tr

DOI: 10.29109/gujsc.687199

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

459

GU J Sci, Part C, 8(2): 458-474 (2020)
Gazi Ãœniversitesi

Fen Bilimleri Dergisi
PART C: TASARIM VE TEKNOLOJÄ°
http://dergipark.gov.tr/gujsc

TÃ¼rk MÃ¼ziÄŸi UyaranlarÄ± KullanÄ±larak Ä°nsan DuygularÄ±nÄ±n Makine Ã–ÄŸrenmesi
YÃ¶ntemi Ä°le TanÄ±nmasÄ±
Mehmet Bilal ER*

Harun Ã‡Ä°Ä

Harran University Faculty of Engineering, Department of Computer Engineering, Haliliye/ÅanlÄ±urfa

Ã–z
Makale Bilgisi
AraÅŸtÄ±rma makalesi
BaÅŸvuru: 10/02/2020
DÃ¼zeltme: 03/05/2020
Kabul: 16/05/2020

Anahtar Kelimeler
Ä°nsan DuygularÄ±nÄ± TanÄ±ma
EEG
Makine Ã–ÄŸrenmesi
Sinyal Ä°ÅŸleme

Keywords
Recognizing Human
Emotions
EEG
Machine Learning
Signal Processing

MÃ¼zik, zaman ve frekansa gÃ¶re deÄŸiÅŸiklik gÃ¶steren Ã§ok Ã§eÅŸitli karmaÅŸÄ±k bileÅŸenlerden oluÅŸan bir
ses sinyalidir. MÃ¼ziÄŸin dinleyicide Ã§ok Ã§eÅŸitli duygular uyandÄ±rdÄ±ÄŸÄ± literatÃ¼rde yaygÄ±n olarak
kabul edilmektedir. Bir kiÅŸinin dinlediÄŸi mÃ¼ziÄŸe hÃ¼zÃ¼nlÃ¼ ya da mutlu duygu iÃ§eriyor demesi
gerÃ§ekte hissettiÄŸi duyguyu ortaya koymayabilir. Ancak mÃ¼zik dinleme anÄ±nda hissedilen
duyguya gÃ¶re beynin iÃ§inde meydana gelen elektriksel dalgalanmalar, algÄ±lanan gerÃ§ek duygunun
yapÄ±sÄ±nÄ± daha doÄŸru bir ÅŸekilde ortaya koyabilmektedir. Beyin sinyalleri kullanÄ±larak insan
duygularÄ±nÄ±n tespit edilmesi, birÃ§ok alanda gÃ¼ncel araÅŸtÄ±rma konusu olmuÅŸtur. Bu Ã§alÄ±ÅŸmada ise
mÃ¼zik parÃ§alarÄ± dinlenirken insan duygularÄ±nÄ±n tanÄ±nmasÄ± problemi ele alÄ±nmÄ±ÅŸtÄ±r. Deneyler hem
kendi veri setimiz Ã¼zerinde hem de literatÃ¼rde yaygÄ±n olarak kullanÄ±lan DEAP veri seti Ã¼zerinde
yapÄ±lmÄ±ÅŸtÄ±r. FarklÄ± tÃ¼rlerdeki TÃ¼rk mÃ¼ziÄŸi parÃ§alarÄ± katÄ±lÄ±mcÄ±lara dinletilerek beyinlerinde oluÅŸan
elektriksel dalgalar incelenerek mutlu, hÃ¼zÃ¼nlÃ¼, rahatlatÄ±cÄ± ve gergin duygu durumlarÄ± tanÄ±nmaya
Ã§alÄ±ÅŸÄ±lmÄ±ÅŸtÄ±r. KatÄ±lÄ±mcÄ±lardan gÃ¼rÃ¼ltÃ¼sÃ¼z bir ortamda farklÄ± tÃ¼rlerden mÃ¼zik parÃ§alarÄ± dinlemeleri
istenilmiÅŸtir. DuygularÄ±n sÄ±nÄ±flandÄ±rÄ±lmasÄ± iÃ§in Ã¶ncelikle farklÄ± kanallardan Elektroansefalografi
(EEG) sinyalleri alÄ±nmÄ±ÅŸtÄ±r ve elde edilen bu sinyaller Ã¼zerinden belirli Ã¶znitelikler Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.
Ã‡Ä±karÄ±lan Ã¶znitelikler Destek VektÃ¶r Makineleri (DVM), K En YakÄ±n KomÅŸu (KNN) ve Yapay
Sinir AÄŸlarÄ±nÄ± (YSA) makine Ã¶ÄŸrenmesi algoritmalarÄ± kullanÄ±larak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r. Veri setini
eÄŸitmek ve insan duygularÄ±nÄ± sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lan algoritmalardan en iyi doÄŸruluk oranÄ±
YSA ile elde edilmiÅŸtir. Elde edilen bulgulara gÃ¶re, kullanÄ±lan yÃ¶ntemin iyi performans gÃ¶sterdiÄŸi
gÃ¶zlemlenmiÅŸtir.

Recognition of Human Emotions by Machine Learning Method
Using Turkish Music Stimuli
Abstract
Music is an audio signal consisting of a wide variety of complex components which vary
according to time and frequency. It is widely accepted in the literature that music evokes a wide
variety of emotions in the audience. When a person says that the music they are listening to
contains sad or happy feelings, this may not reveal the feeling they actually feel. However,
according to the emotion felt during listening to music, fluctuations in electrical activity of the
brain can more accurately reveal the structure of perceived true emotion. Detecting human
emotions using brain signals has been the subject of current research in many areas. In this study,
the problem of detection human emotions while listening to music has been discussed.
Experiments are carried out both on our own dataset and on the DEAP dataset, which is widely
used in the literature. Different types of Turkish musicâ€™s were played to the participants. By
examining the electrical waves that occur in their brain's surface, happy, sad, relaxing and angry
mood states were recognized. Participants were asked to listen to music from different types in a
noiseless environment. To classification the emotions, electroencephalography (EEG) signals
were saved primarily from different channels. Certain features have been extracted from these
signals. Extracted features have been classified using machine learning algorithms for Support
Vector Machines (SVM), K nearest neighbor (KNN), and Artificial Neural Networks (ANN). The
best accuracy rate was obtained by ANN from algorithms used to train the data set and classify
human emotions. According to the results obtained, it was observed that the used method
performed well.

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

460

1. GÄ°RÄ°Å (INTRODUCTION)
MÃ¼zik, duygularÄ±n dili olarak bilinir ve dinleyicide neÅŸe, heyecan ve korku gibi farklÄ± duygusal tepkiler
ortaya Ã§Ä±karabilen gÃ¼Ã§lÃ¼ bir yÃ¶ntem olarak kabul edilmektedir [1]â€“[4]. Bir kiÅŸinin kendini Ã¼zgÃ¼n hissetmesi
durumunda mutlu bir mÃ¼zik dinlemesi kiÅŸinin duygu durumunun mutlu olarak deÄŸiÅŸmesine yardÄ±mcÄ±
olacaktÄ±r. MÃ¼zik dinleyen insanlarda belirli duygularÄ±n uyanmamasÄ± Ã§ok nadir gÃ¶rÃ¼nen bir durumdur.
MÃ¼zik hem duygularÄ± ifade etme hem de dinleyicide duygusal tepkiler uyandÄ±rma da etkili olduÄŸu iÃ§in
mÃ¼zikoloji, psikoloji, sinyal iÅŸleme gibi birÃ§ok alanda araÅŸtÄ±rma konusu olmuÅŸtur. NÃ¶rolojik Ã§alÄ±ÅŸmalar,
mÃ¼ziÄŸin beyin sistemini deÄŸerlendirmek iÃ§in Ã¶nemli bir araÃ§ olduÄŸunu ortaya koymuÅŸtur [5]. Ä°nsan
duygularÄ±nÄ±n hesaplamalarla tahmin edilmesi, yorumlanmasÄ± ve iÅŸlenmesi bir makine Ã¶ÄŸrenmesi alanÄ±dÄ±r.
AyrÄ±ca duygu durum analizleri saÄŸlÄ±k, gÃ¼venlik ve eÄŸitim gibi farklÄ± alanlarda da kullanÄ±lmaktadÄ±r. EEG
tabanlÄ± duygu tanÄ±ma Ã§alÄ±ÅŸmalarÄ± son zamanlarda insan-bilgisayar etkileÅŸimi alanÄ±nda Ã§ok fazla ilgi
gÃ¶rmÃ¼ÅŸtÃ¼r.
Duygu, bireyin dÃ¼ÅŸÃ¼ncelerinden oluÅŸur. Duygular, insanlarÄ±n dÃ¼ÅŸÃ¼nÃ¼rken, iletiÅŸim kurarken, Ã¶ÄŸrenirken ve
karar verirken dÄ±ÅŸ uyaranlara karÅŸÄ± vermiÅŸ olduklarÄ± tepkiler olarak ifade edilir. Bu yÃ¼zden duygular
insanlarÄ±n gÃ¼nlÃ¼k hayattaki davranÄ±ÅŸlarÄ±nÄ±n belirlenmesinde temel rol oynarlar. Ancak duygu, oldukÃ§a Ã¶znel
bir olgudur. Ã‡Ã¼nkÃ¼ farklÄ± insanlar dÄ±ÅŸ uyaranlara tepki olarak aynÄ± ortam ve koÅŸullarda farklÄ± tepkiler
verirler. BÃ¼tÃ¼n insan duygularÄ± birkaÃ§ temel duygudan Ã¼retilmektedir. Duygu, kategorik veya boyutsal
olarak iki ana gurup altÄ±nda incelenir. AyrÄ±k modeller olarak da bilinen kategorik modellerde duygularÄ±n
tanÄ±mlanmasÄ± iÃ§in tek kelime veya kelime gruplarÄ± kullanÄ±lÄ±r. Ä°ki boyutlu dÃ¼zlemde deÄŸerlilik ve uyarÄ±lma
deÄŸerleri Ã¶lÃ§Ã¼lÃ¼r [6], [7]. Bilim adamlarÄ± ve psikoloji uzmanlarÄ± farklÄ± Ã¶nerilerde bulunarak duygusal
modellerde insani duygularÄ± kategorik olarak altÄ± temel sÄ±nÄ±fa ayÄ±rmÄ±ÅŸlarÄ±dÄ±r. Bu sÄ±nÄ±flar; mutluluk, korku,
iÄŸrenme, Ã¼zÃ¼lme, neÅŸe ve Ã¶fke ÅŸeklindedir [8]. Bu araÅŸtÄ±rmada mutlu, hÃ¼zÃ¼nlÃ¼, rahat ve gergin gibi dÃ¶rt
temel duygu incelenmiÅŸtir. Duygu tanÄ±ma Ã¼Ã§ ana kategoride incelenebilir. Ä°lkinde yÃ¼z ifadeleri ya da
konuÅŸmalarÄ±n analizine odaklanÄ±lÄ±r. Bu gÃ¶rsel-iÅŸitsel temelli teknikler, duygularÄ±n temasÄ±z olarak
algÄ±lanmasÄ±nÄ± saÄŸlar. Ä°kinci tÃ¼r yaklaÅŸÄ±mlarda ise Ã§evresel fizyolojik sinyallere odaklanÄ±lÄ±r. Ã‡eÅŸitli
Ã§alÄ±ÅŸmalarda, elektrokardiyogram (EKG), solunum ve nabÄ±z gibi Ã§evresel fizyolojik sinyallerin farklÄ±
duygusal durumlarda deÄŸiÅŸiklik gÃ¶sterdiÄŸi ve otonom sinir sistemini etkilediÄŸi gÃ¶zlenmektedir. Ã‡evresel
fizyolojik sinyaller, gÃ¶rsel-iÅŸitsel tabanlÄ± yÃ¶ntemlerle karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, duygusal durumlarÄ± tahmin etmek
iÃ§in daha ayrÄ±ntÄ±lÄ± bilgi vermektedir [9], [10]. ÃœÃ§Ã¼ncÃ¼ tÃ¼r yaklaÅŸÄ±mlarda ise, EEG gibi merkezi sinir
sisteminden Ã¼retilen beyin sinyallerine odaklanÄ±lÄ±r. EEG sinyalleri kullanÄ±larak duygu durumunu tahmin
etmeyi amaÃ§layan birÃ§ok araÅŸtÄ±rma bulunmaktadÄ±r. EEG sinyalleri, elektrotlar kullanÄ±larak kafa derisinden
kaydedilir. Esas olarak mono-polar ve bipolar olmak Ã¼zere iki tÃ¼r EEG kaydÄ± vardÄ±r. Mono-polar kayÄ±t,
kafa derisindeki aktif elektrotlar ile bir referans elektrot arasÄ±ndaki voltaj farkÄ±nÄ± Ã¶lÃ§er. Ã–te yandan iki
kutuplu elektrotlar, iki aktif elektrot arasÄ±ndaki voltaj farkÄ±nÄ± saÄŸlamaktadÄ±r.

ï‚·
ï‚·
ï‚·

Bu Ã§alÄ±ÅŸmanÄ±n ana katkÄ±larÄ± aÅŸaÄŸÄ±daki gibidir:
MÃ¼zik parÃ§alarÄ± dinlerken kaydedilen EEG sinyalleri ile insan duygularÄ±nÄ± yansÄ±tan 4 sÄ±nÄ±ftan
oluÅŸan yeni bir veri seti oluÅŸturulmuÅŸtur.
MÃ¼zik dinletileri uyaran olarak kullanÄ±lmÄ±ÅŸtÄ±r. UyarÄ±lan EEG sinyalleri ile insan duygularÄ±nÄ±
tanÄ±masÄ± iÃ§in etkili bir yÃ¶ntem Ã¶nerilmiÅŸtir.
Makine Ã¶ÄŸrenmesinin duygularÄ± tanÄ±ma problemindeki etkin gÃ¼cÃ¼ ortaya koyulmuÅŸtur.

EEG sinyalleri kullanarak insan duygu tanÄ±ma sistemleri geliÅŸtirilmesi iÃ§in gÃ¶z Ã¶nÃ¼nde bulundurulmasÄ±
gereken bazÄ± kÄ±sÄ±tlamalar vardÄ±r. Bunlar;

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

ï‚·
ï‚·
ï‚·
ï‚·
ï‚·

461

Duygu algÄ±sÄ±nÄ±n Ã¶znel olmasÄ± ve tam olarak evrensel bir tanÄ±mÄ±nÄ±n yapÄ±lamamasÄ±ndan dolayÄ±
kullanÄ±lan duygu etiketlerinin sÄ±fat sayÄ±larÄ± sÄ±nÄ±rlÄ± olmalÄ±dÄ±r.
Uyaran olarak kullanÄ±lan mÃ¼ziklerin eÅŸit Ã¶rneklem frekansÄ±na sahip olmasÄ± gerekir.
Veri setindeki EEG kayÄ±tlarÄ±nÄ±n hepsi eÅŸit Ã¶rneklem frekansÄ±na sahip olmalÄ±dÄ±r.
Ä°nsanlarÄ±n mÃ¼ziklerden hissettikleri duygularÄ± ifade etmek iÃ§in, EEG kayÄ±tlarÄ±ndan Ã§Ä±karÄ±lan
Ã¶zelliklerin mÃ¼zikal duygularla iliÅŸkili olmasÄ±na dikkat edilmelidir.
EEG duraÄŸan bir sinyal olmadÄ±ÄŸÄ±ndan EEG'den elde edilen Ã¶zellik genellikle Ã§arpÄ±cÄ± bir ÅŸekilde
deÄŸiÅŸirken, duygulanma durumlarÄ± kademeli olarak deÄŸiÅŸir. Duygular belirli bir sÃ¼re iÃ§erisinde
anlamlÄ±lÄ±k kazandÄ±ÄŸÄ± iÃ§in EEG kayÄ±tlarÄ±nÄ±n sÃ¼resi Ã§ok kÄ±sa olmamalÄ±dÄ±r.

Bu makalenin geri kalanÄ± ÅŸu ÅŸekilde dÃ¼zenlenmiÅŸtir. BÃ¶lÃ¼m 2â€™de literatÃ¼rdeki duygu tanÄ±ma ile ilgili
Ã§alÄ±ÅŸmalar gÃ¶zden geÃ§irilmiÅŸtir ve aralarÄ±ndaki farklar ortaya koyulmaya Ã§alÄ±ÅŸÄ±lmÄ±ÅŸtÄ±r. BÃ¶lÃ¼m 3â€™de veri seti,
materyal ve metot tanÄ±tÄ±lmÄ±ÅŸtÄ±r. BÃ¶lÃ¼m 4â€™de araÅŸtÄ±rmada kullanÄ±lan insan duygu tanÄ±ma ile ilgili deneysel
uygulamalar verilmiÅŸtir. BÃ¶lÃ¼m 5â€™de ise araÅŸtÄ±rmanÄ±n bulgularÄ± tartÄ±ÅŸÄ±lmÄ±ÅŸtÄ±r ve insan duygu tanÄ±ma
modellerinin geliÅŸtirilmesi iÃ§in Ã¶nerilerde bulunulmuÅŸtur.
2. Ä°LGÄ°LÄ° Ã‡ALIÅMALAR (RELATED WORKS)
[11]â€™de APM veri tabanÄ± kullanÄ±larak deneklerden EEG kayÄ±tlarÄ± alÄ±nmÄ±ÅŸtÄ±r. OpenSMILE kullanÄ±larak
mÃ¼zik dosyalarÄ±ndan 5 farklÄ± Ã¶znitelik Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r. Deneklerden alÄ±nan EEG sinyallerinden 12 Ã¶znitelik
Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r ve son olarak bu Ã¶znitelikler Orman sÄ±nÄ±flandÄ±rÄ±cÄ± ile mutlu, hÃ¼zÃ¼nlÃ¼, rahat ve gergin olmak
Ã¼zere 4 ayrÄ± kategoride sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r. BaÅŸarÄ± oranÄ±nda %0.4â€™lÃ¼k bir artÄ±ÅŸ gÃ¶zlemlenmiÅŸtir.
[12]â€™de mÃ¼zikli video uyaranlarÄ±na maruz kalma sÄ±rasÄ±nda erkek ve kadÄ±nlarda ayrÄ± ayrÄ± EEG gÃ¼Ã§
spektrumlarÄ± ile beyin kaynaklarÄ±ndaki farklÄ±lÄ±klarÄ± karÅŸÄ±laÅŸtÄ±rmak amaÃ§lanmÄ±ÅŸtÄ±r. Deneklere hÃ¼zÃ¼nlÃ¼,
eÄŸlenceli ve iÃ§ karartÄ±cÄ± mÃ¼zik klipleri izletilmiÅŸ ve aynÄ± anda EEG sinyalleri kaydedilmiÅŸtir. Kaydedilen
bu EEG sinyalleri yedi ayrÄ± frekans bandÄ±nda incelenmiÅŸtir. Bu frekans bantlarÄ± teta (h: 4-7.5 Hz), alfa1
(A1: 8â€“10 Hz), alfa2 (A2: 10â€“12 Hz), beta1 (B1: 13-18 Hz), beta2 (B2: 18.5â€“21 Hz), beta3 (B3: 21,5â€“30
Hz) ve gama (C: 30,5â€“44 Hz) olmak Ã¼zere ortalama Fourier Ã§apraz spektral matrisler kullanÄ±larak
hesaplanmÄ±ÅŸtÄ±r. B2, B3 ve C frekans bantlarÄ±nda hÃ¼zÃ¼nlÃ¼ ve eÄŸlenceli mÃ¼zikler arasÄ±nda anlamlÄ± bir fark
olduÄŸu gÃ¶zlemlenmiÅŸtir. Uyaran dinletilere karÅŸÄ± beynin bazÄ± bÃ¶lgelerinde meydana gelen duygusal
tepkiler, B3 frekans bandÄ±nda daha yÃ¼ksek olduÄŸu gÃ¶zlemlenmiÅŸtir.
[13]â€™de frekans domeni Ã¶zellikleri iÃ§in Hamming penceresi ile kÄ±sa sÃ¼reli Fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼ kullanÄ±lmÄ±ÅŸtÄ±r.
GÃ¼Ã§ spektral yoÄŸunluÄŸu ve bant gÃ¼cÃ¼ frekans alanÄ±ndaki Ã¶zellikler olarak hesaplanmÄ±ÅŸtÄ±r. Zaman domeni,
frekans domeni ve wavelet domeni olmak Ã¼zere Ã¼Ã§ farklÄ± alandan on Ã¼Ã§ Ã¶znitelik Ã§Ä±karÄ±lmÄ±ÅŸ ve bunlar YSA,
DVM ve KNN olmak Ã¼zere Ã¼Ã§ farklÄ± sÄ±nÄ±flandÄ±rÄ±cÄ± ile dÃ¶rt farklÄ± duygu sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r. YSA'nÄ±n DVM
ve KNN sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±na kÄ±yasla en iyi doÄŸruluk oranÄ±nÄ± saÄŸladÄ±ÄŸÄ± gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.
[14]â€™de bir dizi Intrinsic Mode Functions (IMF) elde etmek iÃ§in video mÃ¼zikleri dinletilen deneklerin EEG
sinyalleri kaydedilmiÅŸtir. EEG sinyalleri Ã¼zerinde Ampirik Kip AyÄ±rÄ±ÅŸÄ±m ile Ã¶znitelik Ã§Ä±karma iÅŸlemi
gerÃ§ekleÅŸtirilmiÅŸtir. Daha iyi bir zaman frekans Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ elde etmek iÃ§in sadece baskÄ±n IMF'ler Ã¼zerinde
AyrÄ±k Wavelet DÃ¶nÃ¼ÅŸÃ¼mÃ¼ kullanÄ±lmÄ±ÅŸtÄ±r. Principal Component Analysis (PCA) ile boyutlar azaltÄ±lmÄ±ÅŸ,
Ã¶znitelik vektÃ¶rÃ¼ daha sonra DVM ile duygularÄ± sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r.
[15]â€™de mÃ¼zik ve duygu arasÄ±ndaki iliÅŸkinin analizinde boyut azaltma yÃ¶ntemi kullanÄ±lmÄ±ÅŸtÄ±r. Denekler
tarafÄ±ndan saÄŸlanan duygu etiketlerini iyileÅŸtirmek iÃ§in deneklerin EEG sinyalleri kaydedilmiÅŸtir. Daha
sonra Bilinear Multi Emotion - Similarity Preserving Embedding (BME-SPE) boyut azaltma yÃ¶ntemi
kullanÄ±larak yeni bir Ã¶ÄŸrenme planÄ± Ã¶nerilmiÅŸtir. Ã‡alÄ±ÅŸmada Ã‡in kÃ¼ltÃ¼rÃ¼ne ait mÃ¼zikler kullanÄ±lmÄ±ÅŸtÄ±r.
Ancak diÄŸer kÃ¼ltÃ¼rlere ait mÃ¼ziklerde de benzer duygular gÃ¶zlemlenmiÅŸtir. Ã–nerilen yÃ¶ntemde etkili
korelasyon tespit edilerek sÄ±nÄ±flandÄ±rmada yÃ¼ksek performans saÄŸlandÄ±ÄŸÄ± gÃ¶zlemlenmiÅŸtir.

462

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

[16]â€™da farklÄ± mÃ¼zik uyaranlarÄ± altÄ±nda EEG dinamiklerini araÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Ã‡alÄ±ÅŸmada iki tÃ¼r mÃ¼zik uyaranÄ±;
favori mÃ¼zik (deneklerin tercih ettiÄŸi mÃ¼zikler) ve rahatlatÄ±cÄ± (alfa binaural ritimlerden oluÅŸan mÃ¼zikler)
kullanÄ±lmÄ±ÅŸtÄ±r. MÃ¼ziÄŸin insan beyni Ã¼zerindeki yatÄ±ÅŸtÄ±rÄ±cÄ± etkilerinin deÄŸerlendirilmesi iÃ§in deneklerin EEG
kayÄ±tlarÄ± kullanÄ±lmÄ±ÅŸtÄ±r. Alfa bandÄ±nda mutlak gÃ¼Ã§, yaklaÅŸÄ±k entropi, Ã¶rnek entropi ve Ã¶n asimetri gibi farklÄ±
Ã¶znitelikler hesaplanmÄ±ÅŸtÄ±r. SonuÃ§lar rahatlatÄ±cÄ± mÃ¼ziÄŸin, favori mÃ¼ziÄŸe gÃ¶re daha iyi yatÄ±ÅŸtÄ±rÄ±cÄ± etkilere
sahip olduÄŸunu gÃ¶stermektedir. Ã–nce deneklerden ruh hallerini tespit eden bir anket doldurmalarÄ± istenmiÅŸ
ve Ã§alÄ±ÅŸmanÄ±n sonunda bu anketler gÃ¶z Ã¶nÃ¼ne alÄ±narak deÄŸerlendirme yapÄ±lmÄ±ÅŸtÄ±r.
[17]â€™de kiÅŸiselleÅŸtirilmiÅŸ bir mÃ¼zik duygu tanÄ±ma yaklaÅŸÄ±mÄ± Ã¶nerilmiÅŸtir. Ã–nerilen yaklaÅŸÄ±m, eÄŸitim
aÅŸamasÄ±, kiÅŸisel adaptasyon ve test aÅŸamasÄ±ndan oluÅŸmaktadÄ±r. MIRtoolbox kullanarak ses nesnelerinden
spektrum, spektral centroid, Mel Frequency Cepstral Coefficients (MFCC), tonalite, harmonik tÄ±nÄ± dahil
olmak Ã¼zere toplamda 141 boyutlu Ã¶zellik Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r. EEG Ã¶zniteliklerini elde etmek iÃ§in EEGLAB ve
Signal Processing Toolbox kullanÄ±lmÄ±ÅŸtÄ±r. Deneklere dinletilen mÃ¼zik verileri ve mÃ¼zik dinletilirken
kaydedilen EEG verilerinden elde edilen Ã¶znitelikler eÄŸitim aÄŸÄ±nÄ± oluÅŸturmak iÃ§in vektÃ¶r halinde ayrÄ± ayrÄ±
yapay sinir aÄŸÄ±na verilmiÅŸtir. %85 eÄŸitim % 15 ise test verileri iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Deneysel sonuÃ§lar
Ã¶nerilen yaklaÅŸÄ±mÄ±n etkili olduÄŸunu gÃ¶stermiÅŸtir.
[18]â€™de, deneklerin EEG sinyalleri kullanÄ±larak kendi seÃ§tikleri mÃ¼ziÄŸe dinamik duygusal tepkileri analiz
edilmiÅŸtir. Deneklerin sevdiÄŸi ve sevmediÄŸi mÃ¼zikler deneklere dinletilerek EEG sinyalleri kaydedilmiÅŸtir.
Daha sonra zamana gÃ¶re frekans lokalizasyonu ve Wavelet Paket Dekompozisyonu (WPD) kullanÄ±larak
EEG verileri analiz edilmiÅŸtir. BeÄŸenilen mÃ¼zik dinlenirken, beÄŸenilmeyen mÃ¼ziÄŸe kÄ±yasla F3, F4, F7 ve
F8â€™in Ã¶n elektrot lokasyonlarÄ±nda intheta bileÅŸeninde Ã¶nemli bir artÄ±ÅŸ gÃ¶zlemlenmiÅŸtir. Sevilmeyen mÃ¼zik
dinlenirken frontal beta bileÅŸen enerjisinde artÄ±ÅŸ gÃ¶zlenmiÅŸtir. Deneklerde beÄŸenilen mÃ¼zik iÃ§in
gÃ¶zlemlenen duygular benzerken beÄŸenilmeyen mÃ¼zikler iÃ§in Ã¶nemli bir benzerliÄŸin olmadÄ±ÄŸÄ±
gÃ¶zlemlenmiÅŸtir.
[19]â€™da CNN tarafÄ±ndan sÄ±nÄ±flandÄ±rÄ±lan EEG ham verilerinin doÄŸruluÄŸu deÄŸerlendirilmiÅŸtir. CNN'nin
Ã¶znitelik Ã§Ä±karabildiÄŸi dÃ¼ÅŸÃ¼nÃ¼lerek EEG ham verileri Ã¶n iÅŸleme yapÄ±lmadan doÄŸrudan CNNâ€™e verilmiÅŸtir.
Bu ÅŸekilde CNNâ€™in ham EEG verilerinden duygularÄ± tanÄ±yÄ±p tanÄ±mayacaÄŸÄ± test edilmiÅŸtir. EEG verilerinin
deÄŸiÅŸkenliÄŸini dikkate alan modellerin doÄŸruluÄŸunu deÄŸerlendirmek iÃ§in 11 katlÄ± Ã§apraz doÄŸrulama
kullanÄ±lmÄ±ÅŸtÄ±r. CNNâ€™in duygusal sÄ±nÄ±flarla ilgili veya ilgisiz olan bileÅŸenleri ayÄ±rt edici bir ÅŸekilde
Ã¶ÄŸrenebildiÄŸi ve % 20'nin Ã¼zerinde doÄŸrulukta tanÄ±yabildiÄŸi gÃ¶zlemlenmiÅŸtir.
[20]â€™de deneklere mÃ¼zik dinletilerek stres duygularÄ±nÄ± tahmin etmek iÃ§in Ã¶ÄŸrenme yÃ¶ntemi olarak CNN
kullanÄ±lmÄ±ÅŸtÄ±r. 7 deneÄŸe 10â€™ar dakikalÄ±k mÃ¼zik dinletilmiÅŸ ve EEG sinyalleri kaydedilmiÅŸtir. Kaydedilen
EEG sinyalleri fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼ ile zaman domeninden frekans domenine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r. Aktivasyon
fonksiyonu olarak ReLU kullanÄ±lmÄ±ÅŸtÄ±r. ArdÄ±ndan bu sinyaller derin Ã¶ÄŸrenme ile sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ ve %80â€™
e varan bir doÄŸruluk oranÄ± elde edilmiÅŸtir.
3. MATERYAL ve METOT (MATERIAL and METHODS)
3.1. EEG
Ä°nsan beyni, milyarlarca sinir hÃ¼cresinin birbirine baÄŸlandÄ±ÄŸÄ± karmaÅŸÄ±k bir sistemdir. Beyin hÃ¼creleri
elektriksel impulslarla birbirleriyle iletiÅŸim kurarlar. EEG, beyin tarafÄ±ndan Ã¼retilen elektriksel aktiviteyi
kafa derisi yÃ¼zeyine yerleÅŸtirilen elektrotlar aracÄ±lÄ±ÄŸÄ±yla kaydetmek iÃ§in kullanÄ±lan fizyolojik yÃ¶ntemdir.
1929'da Hans Berger, ilk insan beyni EEGâ€™ sini kaydetmiÅŸtir [21]. EEG, doktorlar ve bilim adamlarÄ±
tarafÄ±ndan beyin fonksiyonlarÄ±nÄ± incelemek ve nÃ¶rolojik hastalÄ±klarÄ± teÅŸhis etmek iÃ§in yaygÄ±n olarak
kullanÄ±lmaktadÄ±r. Bir EEG kayÄ±t iÅŸleminde, beyin dalgasÄ± paternleri izlenir ve kaydedilir. EEG testi
sÄ±rasÄ±nda, elektrot olarak adlandÄ±rÄ±lan kÃ¼Ã§Ã¼k dÃ¼z metal diskler teller ile kafa derisine sabitlenir ve daha
sonra her elektrot bir EEG kayÄ±t makinesine baÄŸlanÄ±r. Elektrotlar beyindeki elektriksel impulslarÄ± analiz
eder ve sonuÃ§larÄ± kaydeden bir bilgisayara sinyaller gÃ¶nderir. KullanÄ±mlarÄ±na baÄŸlÄ± olarak, paralel olarak

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

463

veri kaydedebilen Ã§ok kanallÄ± EEG kayÄ±t cihazlarÄ± 256 ya kadar elektrot iÃ§erebilir. Her kanal bir EEG kaydÄ±
sÄ±rasÄ±nda bir sinyal Ã¼retir [22]. Bir EEG kaydÄ±ndaki elektriksel dÃ¼rtÃ¼ler, tepe noktalarÄ± ve Ã§ukur noktalarÄ±
olan dalgalÄ± Ã§izgiler gibi gÃ¶rÃ¼nÃ¼r [23]. Bu Ã§izgiler, doktorlarÄ±n anormal kalÄ±plarÄ±n olup olmadÄ±ÄŸÄ±nÄ± hÄ±zlÄ± bir
ÅŸekilde deÄŸerlendirmesini saÄŸlar. Herhangi bir dÃ¼zensizlik nÃ¶bet veya diÄŸer beyin bozukluklarÄ±nÄ±n bir
belirtisi olabilir. Ä°ÅŸaret iÅŸleme tekniklerini kullanarak normal ve anormal bir kiÅŸinin beyin aktivitesi kolayca
ayÄ±rt edilebilir.
Normal bir EEG sinyalinin frekans aralÄ±ÄŸÄ± 1 Hz-100 Hz'dir, ancak 100 Hz Ã§ok nadir gÃ¶rÃ¼lÃ¼r. Sinyalin
genliÄŸi ise genel olarak 10 Î¼V - 100 Î¼V arasÄ±ndadÄ±r. EEG'nin karakteristik Ã¶zellikleri, bireyin kendisi, yaÅŸÄ±
ve Ã¶znenin zihinsel durumu gibi birÃ§ok faktÃ¶re baÄŸlÄ±dÄ±r [24].
3.1.1. EEG Dalga Åekli (EEG Wave Shape)
Beyin yÃ¼zeyinde meydana gelen elektriksel aktiviteler, EEG makinesinin ekranÄ±nda, voltaj olarak Ã¶lÃ§Ã¼len
deÄŸiÅŸen frekans ve genlikteki dalga formlarÄ± olarak gÃ¶rÃ¼nÃ¼r. EEG aktivitesi mikrovolt (mV) cinsinden
Ã¶lÃ§Ã¼len sinyallerdir. YaÅŸadÄ±ÄŸÄ±mÄ±z andaki duruma gÃ¶re beynimizde farklÄ± ÅŸekillerde elektriksel
dalgalanmalar olur ve durumlara gÃ¶re farklÄ± frekans kalÄ±plarÄ± oluÅŸur. EEG sinyalleri frekans genlik ve
ÅŸekilleri bakÄ±mÄ±ndan sÄ±nÄ±flandÄ±rÄ±lÄ±r. Beyin dalgasÄ± hÄ±zÄ± Hertz (saniyedeki devir) cinsinden Ã¶lÃ§Ã¼lÃ¼r ve yavaÅŸ,
orta ve hÄ±zlÄ± dalgalarÄ± tanÄ±mlayan frekans bantlara ayrÄ±lÄ±r. Frekans aralÄ±klarÄ±na baÄŸlÄ± olarak, beÅŸ tip dalga
tanÄ±mlanabilir. SÄ±rasÄ±yla dÃ¼ÅŸÃ¼k frekanstan yÃ¼ksek frekansa doÄŸru; delta (Î´), teta (Î¸), alfa (Î±), beta, (Î²), ve
gamma (Î³) ÅŸeklindedir. Bu frekans bantlarÄ± tablo 1â€™deki gibidir.
Tablo 1. DalgalarÄ±n Frekans AralÄ±klarÄ±
Dalga
Delta
Teta
Alfa
Beta
Gama

Frekans
0-4 HZ
4-8 HZ
8-13 HZ
13-30 HZ
>30 HZ

EEG Sinyalleri kafanÄ±n neresinden alÄ±ndÄ±ÄŸÄ±na baÄŸlÄ± olarak iki tÃ¼re ayrÄ±labilir vardÄ±r. Bunlar, kafa derisinden
alÄ±nan EEG sinyalleri ve kafa iÃ§inden alÄ±nan EEG sinyalleridir. Kafa derisinden alÄ±nan EEG iÃ§in, kafa
derisinin Ã¼zerine iyi mekanik ve elektriksel temasÄ± olan kÃ¼Ã§Ã¼k elektrotlar yerleÅŸtirilir. KafatasÄ± iÃ§inden EEG
sinyali almak iÃ§in ameliyat sÄ±rasÄ±nda beyine implant edilen Ã¶zel elektrotlar kullanÄ±lÄ±r. Beynin mimarisi
Ã¼niform olmamasÄ± ve korteksin fonksiyonel yapÄ±ya sahip olmasÄ±ndan dolayÄ± kaydedilen EEG sinyalleri
elektrotlarÄ±nÄ±n konumuna baÄŸlÄ± olarak deÄŸiÅŸebilir. EEG sinyalleri kayÄ±t edilmeden Ã¶nce elektrotlarÄ±n
yerleÅŸtirilmesine dikkat edilmelidir. ElektrotlarÄ±n kafa derisinin Ã¼zerine nasÄ±l yerleÅŸtirileceÄŸi Ã¶nemli bir
sÃ¼reÃ§tir, Ã§Ã¼nkÃ¼ farklÄ± tÃ¼rdeki aktivitelerin iÅŸlenmesinden farklÄ± beyinsel korteks loblarÄ± sorumludur. Kafa
derisi elektrot lokalizasyonu iÃ§in yaygÄ±n olarak kullanÄ±lan elektrot yerleÅŸtirme yÃ¶ntemlerinden biri,
Amerikan Elektroensefalografik TopluluÄŸu tarafÄ±ndan standart hale getirilmiÅŸ olan 10-20 elektrot sistemidir
[25]. Bu sistemi kullanarak, kafa derisi Ã¼zerine toplam 21 elektrot yerleÅŸtirilir. Åekil 1â€™de, uluslararasÄ± 1020 sistemine gÃ¶re beyindeki elektrot pozisyonunu gÃ¶stermektedir. Her bÃ¶lge lobu tanÄ±mlamak iÃ§in bir harf
ve yarÄ±m kÃ¼re konumunu tanÄ±mlamak iÃ§in bir sayÄ± kullanÄ±r. F, T, C, P ve O harfleri sÄ±rasÄ±yla Frontal,
Temporal, Central, Parietal ve Oksipital anlamÄ±na gelir. â€œZâ€ orta hatta yerleÅŸtirilen bir elektrodu ifade eder.
Ã‡ift rakamlar saÄŸ yarÄ±m kÃ¼re Ã¼zerindeki elektrot pozisyonlarÄ±nÄ± belirtirken, tek rakamlar sol yarÄ±m kÃ¼re
Ã¼zerindekileri gÃ¶sterir.

464

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

Åekil 1. UluslararasÄ± 10-20 elektrot yerleÅŸtirme sistemi
3.2. Ã–nerilen YÃ¶ntem (Proposed Method)
MÃ¼zik dinlerken EEG sinyalleri kaydedilen deneklerin, duygu durumlarÄ±nÄ±n tanÄ±nmasÄ± iÃ§in Ã¶nerilen sistem
dÃ¶rt adÄ±mdan oluÅŸmaktadÄ±r. Bu iÅŸlem adÄ±mlarÄ±; sÄ±rasÄ± ile veri toplama, sinyal Ã¶niÅŸleme, Ã¶znitelik Ã§Ä±karma
ve sÄ±nÄ±flandÄ±rma ÅŸeklinde yapÄ±lmaktadÄ±r. MÃ¼zik dinlenmesi sÄ±rasÄ±nda beyin Ã¼zerinde oluÅŸan elektriksel
aktiviteler, EEG sinyal okuyucu kullanÄ±larak kafa derisi Ã¼zerinden kaydedilir. Kaydedilen EEG sinyalleri
daha sonra dÄ±ÅŸ ortamdan gelen gÃ¼rÃ¼ltÃ¼lerin giderilmesi ve ham EEG verilerinin iÅŸlenebilir hale
getirilebilmesi iÃ§in sinyaller Ã¶n iÅŸlemden geÃ§irilir. EEG sinyalleri Ã¶n iÅŸleme tabi tutulduktan sonra Ã¶znitelik
Ã§Ä±karÄ±lÄ±r. Son olarak, Ã§Ä±karÄ±lan Ã¶znitelikler sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± eÄŸitmek ve insan duygularÄ±nÄ± tanÄ±mak iÃ§in
kullanÄ±lÄ±r. Her adÄ±mÄ±n detayÄ± aÅŸaÄŸÄ±daki alt bÃ¶lÃ¼mlerde aÃ§Ä±klanmÄ±ÅŸtÄ±r Ã–nerilen yÃ¶ntem ÅŸekil 2â€™ de verilmiÅŸtir.
EEG KayÄ±t

Sinyal Ã–n Ä°ÅŸleme

Ã–zellik
Ã§Ä±karma

SÄ±nÄ±flandÄ±rma

Åekil 2. Duygu TanÄ±ma AdÄ±mlarÄ±
3.2.1. Uyaran ve KatÄ±lÄ±mcÄ±lar (Stimulus and Subjects)
16 adet sesli mÃ¼zik dinletisi, EEG tabanlÄ± duygu tanÄ±ma deneyi iÃ§in harici bir uyarÄ±cÄ± olarak kullanÄ±lmÄ±ÅŸtÄ±r.
TÃ¼m mÃ¼zik dinletileri MP3 formatÄ±ndadÄ±r ve Ã¶rnekleme hÄ±zÄ± 320 kbps'dir. Bu Ã§alÄ±ÅŸmada kullanÄ±lan
mÃ¼zikler, TÃ¼rk Sanat MÃ¼ziÄŸi, TÃ¼rk Halk MÃ¼ziÄŸi, TÃ¼rk Pop ve TÃ¼rk Caz MÃ¼ziÄŸi olmak Ã¼zere dÃ¶rt tÃ¼rden
oluÅŸmaktadÄ±r. SeÃ§ilen tÃ¼rler fark edilebilir duygular Ã¼retmektedir. FarklÄ± kÃ¼ltÃ¼rlere sahip toplam on
katÄ±lÄ±mcÄ± gÃ¶nÃ¼llÃ¼ olarak Ã§alÄ±ÅŸmaya katÄ±lmÄ±ÅŸtÄ±r. On saÄŸlÄ±klÄ± denekten beÅŸi erkek beÅŸi ise kadÄ±ndÄ±r. TÃ¼m
katÄ±lÄ±mcÄ±lar 20 ila 25 yaÅŸ arasÄ±ndadÄ±r ve katÄ±lÄ±mcÄ±larÄ±n herhangi bir beyin hastalÄ±ÄŸÄ± rahatsÄ±zlÄ±ÄŸÄ±
bulunmamaktadÄ±r ve normal iÅŸitme gÃ¼cÃ¼ne sahiptir. Deneyden Ã¶nce, katÄ±lÄ±mcÄ±lara Ã§alÄ±ÅŸmanÄ±n kapsamÄ± ve
prosedÃ¼rÃ¼ hakkÄ±nda bilgi verilmiÅŸtir.
3.2.2. EEG Veri Toplama (EEG Data Collection)
Bu Ã§alÄ±ÅŸmada EEG sinyallerini alabilmek iÃ§in EMOTIV EPOC+ kulaklÄ±ÄŸÄ± kullanÄ±lmÄ±ÅŸtÄ±r. EMOTIV EPOC+
insan beyni araÅŸtÄ±rmasÄ± iÃ§in tasarlanmÄ±ÅŸtÄ±r. Bu EEG kayÄ±t cihazÄ± kullanÄ±mÄ± kolay bir tasarÄ±mla, hÄ±zlÄ± ve
profesyonel olarak yÃ¼ksek kalitede beyin verilerine eriÅŸim saÄŸlar. Bu cihazda toplam 14 kanal vardÄ±r ve 5
dakikaya kadar kayÄ±t alabilmektedir. Cihaz 128 Ã¶rnekleme frekansÄ±yla veri alabilmektedir. Bluetooth
baÄŸlantÄ±sÄ± ile Matlab Ã¼zerinde hazÄ±rlanan yazÄ±lÄ±m kullanÄ±larak ham EEG verileri kaydedilmiÅŸtir. TÃ¼m EEG
kayÄ±tlarÄ± izole ve gÃ¼rÃ¼ltÃ¼sÃ¼z bir odada alÄ±nmÄ±ÅŸtÄ±r. Åekil 3'de gÃ¶sterildiÄŸi gibi mÃ¼zik dinlerken Emotiv Epoc+
kulaklÄ±ÄŸÄ±ndan EEG sinyalleri kaydedilmiÅŸtir.

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

465

Åekil 3. EMOTIV EPOC
Cihazdaki elektrotlar uluslararasÄ± 10-20 sistemine gÃ¶re beynin Ã§eÅŸitli bÃ¶lgelerinde konumlandÄ±rÄ±larak EEG
kayÄ±tlarÄ± alÄ±nmÄ±ÅŸtÄ±r. Her katÄ±lÄ±mcÄ±ya, 30 saniyelik bÃ¶lÃ¼mlerden oluÅŸan toplam 16 adet mÃ¼zik dinletilmiÅŸtir.
Her katÄ±lÄ±mcÄ±ya her tÃ¼rden birer birer dÃ¶rt mÃ¼zik dinletilmiÅŸtir ve her mÃ¼zikten sonra 10 saniye sessizlik
saÄŸlanmÄ±ÅŸtÄ±r. Bu mÃ¼zikler katÄ±lÄ±mcÄ±ya dinletilirken dinleyicinin EEG kayÄ±tlarÄ± alÄ±nmÄ±ÅŸtÄ±r ve her mÃ¼zik
sonunda hissettiÄŸi duygu sorularak alÄ±nan EEG kaydÄ± hissedilen duyguya gÃ¶re etiketlenmiÅŸtir. Duygu
tanÄ±ma ve sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n eÄŸitimi iÅŸlemi iÃ§in manuel olarak etiketlenen duygu etiketleri kullanÄ±lmÄ±ÅŸtÄ±r.
Åekil 4â€™de katÄ±lÄ±mcÄ±lar iÃ§in EEG veri toplama aÅŸamasÄ±ndaki genel yapÄ± ifade edilmiÅŸtir. KayÄ±tlar gÃ¼nÃ¼n
farklÄ± saatlerinde alÄ±nmÄ±ÅŸtÄ±r. Veri seti, her sÄ±nÄ±fta eÅŸit sayÄ±da kayÄ±t olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r. Ä°lk deneyde
sabah saatlerinde toplam 160 kayÄ±t, ikinci deneyde ise Ã¶ÄŸlen saatlerinde toplam 160 kayÄ±t alÄ±nmÄ±ÅŸtÄ±r. Veri
setindeki her sÄ±nÄ±ftaki kayÄ±t sayÄ±sÄ±nÄ± aynÄ± olmasÄ±nÄ± saÄŸlamak iÃ§in her deneydeki 144 kayÄ±t dikkate alÄ±nmÄ±ÅŸtÄ±r.

Åekil 4. EEG KayÄ±t Alma SÃ¼reci
AyrÄ±ca bu Ã§alÄ±ÅŸmada DEAP veri kÃ¼mesi kullanÄ±lmÄ±ÅŸtÄ±r. DEAP veri seti duygularÄ±n deÄŸerlendirilmesi iÃ§in
birden fazla fizyolojik sinyal iÃ§erir. 32 denekten EEG verisi toplanmÄ±ÅŸtÄ±r. EEG sinyalleri, her biri 60 saniye
sÃ¼ren mÃ¼zik videosu gÃ¶sterilerek kaydedilmiÅŸtir [26]. Daha sonra sinyaller 128 Hz'e Ã¶rneklenip, bant
geÃ§iren filtreler kullanÄ±larak gÃ¼rÃ¼ltÃ¼ giderilmiÅŸtir. DEAP veri kÃ¼mesi, Russellâ€™in duygu modeline gÃ¶re
sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r. DEAP veri kÃ¼mesinde, 1-9 Ã¶lÃ§eÄŸinde deÄŸerlilik ve uyarÄ±lma adlÄ± iki tÃ¼r etiket vardÄ±r.
Etiketlerden 1-4 deÄŸerliliÄŸi, 5-9 ise uyarÄ±lma Ã¶lÃ§eÄŸini temsil eder. Derecelendirme 5'ten bÃ¼yÃ¼k veya ona
eÅŸitse etiket â€œyÃ¼ksekâ€ olarak, 5'ten kÃ¼Ã§Ã¼kse etiket â€œdÃ¼ÅŸÃ¼kâ€ olarak ayarlanmÄ±ÅŸtÄ±r. Veri setinde toplam dÃ¶rt
sÄ±nÄ±f etiket vardÄ±r: yÃ¼ksek uyarÄ±lma dÃ¼ÅŸÃ¼k deÄŸerlik, dÃ¼ÅŸÃ¼k uyarÄ±lma yÃ¼ksek deÄŸerlik, yÃ¼ksek uyarÄ±lma
yÃ¼ksek deÄŸerlik ve dÃ¼ÅŸÃ¼k uyarÄ±lma dÃ¼ÅŸÃ¼k deÄŸerlik.

466

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

3.3. EEG Sinyal Ã–n Ä°ÅŸleme ve Ã–znitelik Ã‡Ä±karma (EEG Signal Preprocessing and Feature
Extraction)
Ä°nsan kafa derisinden kaydedilen EEG sinyalleri beyin dalgalarÄ±nÄ±n, seslerin ve farklÄ± dÄ±ÅŸ gÃ¼rÃ¼ltÃ¼lerin
birleÅŸiminden oluÅŸur. EEG sinyalleri ile insan beyni aktivitesini araÅŸtÄ±rmak iÃ§in 0Hz-50Hz bandÄ±nÄ±
kullanÄ±rÄ±z. Ã–zellik Ã§Ä±karÄ±mÄ± ve sÄ±nÄ±flandÄ±rma iÃ§in kaliteli, gÃ¼rÃ¼ltÃ¼sÃ¼z sinyallere sahip olmak gerekir. GÃ¼rÃ¼ltÃ¼
azaltmak iÃ§in kaydettiÄŸimiz sinyaller, 1.0 Hz-50 Hz arasÄ±nda band geÃ§iÅŸine sahip bir filtre kullanÄ±larak
sinyaller analiz iÃ§in uygun hale getirilmiÅŸtir.
Filtreden geÃ§irilen sinyallerden Ã¶znitelik Ã§Ä±karabilmek iÃ§in ilk olarak sinyal belli uzunluktaki Ã§erÃ§evelere
ayrÄ±lmÄ±ÅŸtÄ±r. Sinyalindeki iÅŸaretler zamana baÄŸlÄ± olarak sÃ¼rekli deÄŸiÅŸmektedir. Bu yÃ¼zden sinyallerinin
karakteristik Ã¶zelliklerini belirleyen parametreler Ã§ok kÃ¼Ã§Ã¼k zaman diliminde kararlÄ± kalmaktadÄ±r. Bu
Ã§alÄ±ÅŸmada EEG sinyalleri 25 ms uzunluklarda Ã§erÃ§evelere bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r. AyrÄ±ca her Ã§erÃ§eve kendinden bir
Ã¶nceki Ã§erÃ§evenin bir kÄ±smÄ±nÄ± Ã¶rtecek ÅŸekildedir. Ã‡erÃ§evelerinin birbirini Ã¶rtmesinin amacÄ± Ã§erÃ§eveler arasÄ±
geÃ§iÅŸin yumuÅŸak olmasÄ±nÄ± saÄŸlamaktÄ±r [27]. EÄŸer bu Ã¶rtÃ¼ÅŸme olmasaydÄ± birbirini izleyen iki Ã§erÃ§eveyi
izlediÄŸimiz zaman veya bu Ã§erÃ§evedeki sinyalleri iÅŸlenirken Ã§erÃ§eveler arasÄ±ndaki Ã¶zellik deÄŸiÅŸimi kesintiye
veya sÄ±Ã§ramaya neden olabilecekti. AyrÄ±ca komÅŸu Ã§erÃ§evelerin parametre deÄŸerlerinin farkÄ± da daha yÃ¼ksek
olacaktÄ±. Bu nedenlerden dolayÄ± Ã§erÃ§eveler birbirini Ã¶rtecek ÅŸekildedir. Bu Ã§alÄ±ÅŸmada Ã§erÃ§evelerin Ã¶rtÃ¼ÅŸme
oranÄ± bir Ã§erÃ§evenin %50 si kadar olarak seÃ§ilmiÅŸtir.
Bir sinyale Ã§erÃ§eveleme uygulandÄ±ktan sonra pencereleme iÅŸlemi uygulanÄ±r. AmaÃ§ her bir Ã§erÃ§evenin
baÅŸÄ±nda sonunda oluÅŸan sÃ¼reksizliÄŸi Ã¶nlemektir. Her Ã§erÃ§evedeki ses sinyalinin orta bÃ¶lgesi gÃ¼Ã§lendirilir
uÃ§ bÃ¶lgeler ise zayÄ±flatÄ±lÄ±r. Bu Ã§alÄ±ÅŸmada yaygÄ±n olarak kullanÄ±lan â€œHamming penceresiâ€ kullanÄ±lmÄ±ÅŸtÄ±r.
â€œHamming Pencerelemeâ€ sayesinde sinyalin merkez bÃ¶lgesi daha belirgin hale gelir. UÃ§ kÄ±sÄ±mlarda sÄ±fÄ±ra
yaklaÅŸtÄ±rÄ±lÄ±r. Hamming Penceresi sinyalin uÃ§ bÃ¶lgelerdeki istenmeyen radyasyonlarÄ± en aza indir [28].
AyrÄ±ca sinyali Fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼ne uygun hale getiren fonksiyondur. Hamming fonksiyonun Ã§alÄ±ÅŸma
mantÄ±ÄŸÄ± hamming penceresi ile Ã§erÃ§evelenmiÅŸ ses sinyali Ã§arpÄ±lÄ±r ve sonunda pencerelenmiÅŸ sinyal elde
edilir. Hamming pencere formÃ¼lÃ¼ denklem 1â€™de verilmiÅŸtir.
ğ‘›

ğ‘¤[ğ‘›] = 0.54 âˆ’ 0.46 âˆ— cos (2 âˆ— ğœ‹ âˆ— ) , ğ‘: ğ‘ƒğ‘’ğ‘›ğ‘ğ‘’ğ‘Ÿğ‘’ ğ‘¢ğ‘§ğ‘¢ğ‘›ğ‘™ğ‘¢ÄŸğ‘¢
ğ‘

(1)

ğ‘›: 0, 1, 2 â€¦ â€¦ ğ‘ âˆ’ 1

Hamming penceresinden sonra sinyale Fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼ uygulanmÄ±ÅŸtÄ±r. Sinyal iÅŸlemede dÃ¶nÃ¼ÅŸÃ¼m bir
sinyalin baÅŸka parametrelerle ifade edilmesi anlamÄ±na gelir. Fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼ bir sinyalin zaman
domaininden frekans domainine dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ saÄŸlar. Fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼ sinyal iÅŸlemede sinyalin iÃ§indeki
bilgileri elde etmek iÃ§in Ã§ok Ã¶nemli bir yÃ¶ntemdir. Sinyali oluÅŸturan bileÅŸenleri (frekans, genlik, faz)
kosinÃ¼s ve sinÃ¼s fonksiyonlarÄ±nÄ±n toplamÄ± olarak ifade etmeye yarar. Bu Ã§alÄ±ÅŸmada HÄ±zlÄ± Fourier
DÃ¶nÃ¼ÅŸÃ¼mÃ¼ kullanÄ±lmÄ±ÅŸtÄ±r. Bu adÄ±mda N Ã¶rnekten oluÅŸan her Ã§erÃ§eve HÄ±zlÄ± Fourier dÃ¶nÃ¼ÅŸÃ¼mÃ¼ uygulanarak
zaman domainden frekans domainine geÃ§irilmiÅŸtir. N Ã¶rnekli bir kÃ¼me denklem 2â€™deki gibi tanÄ±mlanÄ±r. Son
aÅŸamada N Ã¶rnekten oluÅŸan her Ã§erÃ§eve Ã¼zerinden istatistiksel hesaplamalar yapÄ±lmÄ±ÅŸtÄ±r.
âˆ’2ğœ‹ğ‘—ğ‘˜ğ‘› / ğ‘
ğ‘‹ğ‘› = âˆ‘ğ‘âˆ’1
,
ğ‘˜=0 ğ‘¥ğ‘˜ ğ‘’

n = 0, 1, 2, â€¦ . . . , N âˆ’ 1

(2)

Her Ã§erÃ§evenin standart sapmasÄ±, maksimum deÄŸeri, minimum deÄŸeri ortalamasÄ± ve kare ortalamalarÄ±nÄ±n
karekÃ¶kÃ¼ hesaplanmÄ±ÅŸtÄ±r.
3.4. Yapay Sinir AÄŸlarÄ± (Artificial Neural Networks)
YSA, insan beyninin akÄ±llÄ± veri iÅŸleme yeteneÄŸinden ilham alÄ±narak oluÅŸturulmuÅŸtur. YSA beyindeki
nÃ¶ronlarÄ±n birbirleri ile etkileÅŸimini taklit ederek motive edilmiÅŸtir [29]. NÃ¶ronlardan oluÅŸan, iliÅŸkili nÃ¶ron
baÄŸlantÄ±larÄ± iÃ§eren ve matematiksel bir model olan YSA modeli ÅŸekil 5â€˜te gÃ¶sterilmiÅŸtir. AÄŸ oluÅŸumunda

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

467

kullanÄ±lan nÃ¶ronlar arasÄ±nda oluÅŸturulan baÄŸlantÄ±lar aÄŸÄ±rlÄ±k denen sayÄ±sal deÄŸerler ile iliÅŸkilendirilir. Her
aÄŸÄ±rlÄ±k, aÄŸda transfer edilen ve sinyal ile Ã§arpÄ±lan belirli bir deÄŸere sahiptir [30], [31]. YSAâ€™lar, problem
hakkÄ±nda bilgi sahibi olmaksÄ±zÄ±n girdi ve Ã§Ä±ktÄ± verileri arasÄ±ndaki doÄŸrusal olmayan iliÅŸkileri tanÄ±mak iÃ§in
eÄŸitilebilirler. EÄŸitimden sonra YSAâ€™nÄ±n Ã§alÄ±ÅŸma sÃ¼resi son derece hÄ±zlÄ±dÄ±r, Ã§Ã¼nkÃ¼ yalnÄ±zca birkaÃ§ basit,
birbirine baÄŸlÄ± iÅŸlem birimi iÃ§ermektedir. YSAâ€™larÄ±n model tanÄ±ma, genelleme ve enterpolasyon yapabilme
Ã¶zellikleri vardÄ±r. Bu nedenle eÄŸitilen aÄŸa bilinmeyen bir girdi uygulandÄ±ÄŸÄ±nda uygun bir Ã§Ä±ktÄ± Ã¼retebilirler.
Deterministik hata ve sistem modelleri yerine yalnÄ±zca simÃ¼le edilmiÅŸ eÄŸitim verileri gerektirirler [32].

g(w1 ,b1 ,x)

ï¢1

ï
X

ï

g(wi ,bi ,x)

ï

ï¢i

ï

Y

g(wN ,bN ,x)

ï¢N
Åekil 5: Yapay Sinir AÄŸlarÄ±
3.5. Destek VektÃ¶r Makineleri (Support Vector Machines)
DVM Vapnikâ€™in istatistiksel Ã¶ÄŸrenme teorisinden nemalanan lineer ve lineer olmayan Ã§izgiler ile
ayrÄ±ÅŸtÄ±rÄ±labilen en iyi makine Ã¶ÄŸrenme tekniklerinden biridir [33]. Bu teknik hem sÄ±nÄ±flandÄ±rma hem de
regresyon analizi iÃ§in kullanÄ±labilir ve kÃ¼Ã§Ã¼k Ã¶rneklerin sÄ±nÄ±flandÄ±rÄ±lmasÄ± iÃ§in hesaplamalÄ± bir Ã¶ÄŸrenme
yÃ¶ntemidir [34]. DVM de Ã¶ncelikle girdi verileri daha yÃ¼ksek boyutlu bir alana alÄ±nÄ±r ve bu alanda iki sÄ±nÄ±f
arasÄ±nda bir en uygun ayÄ±rÄ±cÄ± hiper dÃ¼zlem oluÅŸturulur [35]. DVM ile Ã¶ncelikle bir dÃ¼zlemde bulunan
sÄ±nÄ±flandÄ±rÄ±lacak veri gruplarÄ± arasÄ±nda bir sÄ±nÄ±r Ã§izgisi belirlenir. Bu sÄ±nÄ±rÄ±n belirleneceÄŸi yer ise bu veri
gruplarÄ±nÄ±n Ã¼yelerine en uzak bir yer olmalÄ±dÄ±r. Basit bir ÅŸekilde tanÄ±mlamak gerekirse DVM bu sÄ±nÄ±rÄ±n nasÄ±l
Ã§izileceÄŸini belirler. Algoritmik olarak DVM, yapÄ±sal risk minimizasyonuna dayalÄ± kÄ±sÄ±tlanmÄ±ÅŸ bir kuadratik
optimizasyon problemini Ã§Ã¶zerek veri kÃ¼meleri arasÄ±nda optimal ayÄ±rma hiper dÃ¼zlemi (f (x) = 0)
oluÅŸturmaktadÄ±r [36].
3.6. K En YakÄ±n KomÅŸu (K Nearest Neighbor)
BÃ¼yÃ¼k Ã¶lÃ§ekli bir veri kÃ¼mesinden, bir sorgu Ã¶rneÄŸine en Ã§ok benzer bir veri alt kÃ¼mesi bulmayÄ± amaÃ§layan
KNN algoritmalarÄ±; boyut indirgeme, model sÄ±nÄ±flama ve gÃ¶rÃ¼ntÃ¼ alÄ±mÄ± gibi geniÅŸ kapsamlÄ± uygulamalarda
temel bir bileÅŸen olarak kullanÄ±lmaktadÄ±r [37],[38]. KNN, bir veri kÃ¼mesindeki Ã¶rneklerin genellikle benzer
Ã¶zelliklere sahip diÄŸer Ã¶rneklerin yakÄ±nÄ±nda bulunacaÄŸÄ± ilkesine dayanan, Ã¶rnek tabanlÄ± bir Ã¶ÄŸrenme
algoritmasÄ±dÄ±r [39]. Bu algoritma ile yeni bir nokta verisini sÄ±nÄ±flandÄ±rmak iÃ§in bu nokta verisine en yakÄ±n
k tane eÄŸitim noktasÄ± bulunur. SÄ±nÄ±flandÄ±rma iÅŸlemi, komÅŸularÄ±nÄ±n oy Ã§oÄŸunluÄŸuyla yapÄ±lÄ±r; sÄ±nÄ±flandÄ±rma
iÅŸlemi yapÄ±lacak bir eleman, bir uzaklÄ±k fonksiyonuyla Ã¶lÃ§Ã¼len en yakÄ±n komÅŸular arasÄ±nda en yakÄ±n olan
sÄ±nÄ±fa daÄŸÄ±tÄ±lÄ±r [40]. KNN algoritmasÄ±nÄ±n formÃ¼lÃ¼ denklem 3â€™te gÃ¶sterilmiÅŸtir.

ğ‘¥(ğ‘¥, ğ‘¦) = âˆšâˆ‘ğ‘—=1 ğ‘¤ğ‘— (ğ‘¥ğ‘— âˆ’ ğ‘§ğ‘— )2

(3)

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

468

Denklem 3â€™te; wj- j boyutuyla iliÅŸkilendirilen aÄŸÄ±rlÄ±ktÄ±r. Her boyut iÃ§in aÄŸÄ±rlÄ±k seÃ§ilir ve karesel uzaklÄ±k
fonksiyonu belirtilir. Åekil 6 â€˜da Test Ã¶rneÄŸinin sÄ±nÄ±flandÄ±rÄ±lmasÄ±nda, k= 1 veya k = 3 olarak seÃ§ildiÄŸinde
pozitif sÄ±nÄ±fta, k = 2 olarak seÃ§ildiÄŸinde negatif sÄ±nÄ±fta olduÄŸu gÃ¶rÃ¼lmektedir.

k=3
k=2
k=1
Test Ã–rnek

Åekil 6: K-NN DiyagramÄ±
4. DENEYSEL UYGULAMALAR (EXPERÄ°MENTAL APPLÄ°CATÄ°ONS)
4.1. Deneysel SonuÃ§lar (Experimental Results)
Bu Ã§alÄ±ÅŸmada sÄ±nÄ±flandÄ±rma iÅŸlemi iÃ§in, YSA, DVM ve KNN kullanÄ±larak 5-kat Ã§apraz doÄŸrulama
uygulanmÄ±ÅŸtÄ±r. DVM'ler polinom ve radyal temelli fonksiyon Ã§ekirdekleri kullanÄ±larak eÄŸitilmiÅŸtir. YSA,
iki farklÄ± Ã§ekirdekle eÄŸitilmiÅŸ DVM'ler ve KNNâ€™den elde edilen sonuÃ§lar karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Ã–nerilen
yÃ¶ntemin baÅŸarÄ±m kriterleri doÄŸruluk, kesinlik, hassasiyet ve F-skoru oranlarÄ±na dayalÄ± olarak yapÄ±lmÄ±ÅŸtÄ±r.
SÄ±nÄ±flandÄ±rma problemlerindeki deÄŸerlendirme Ã¶lÃ§Ã¼tleri, karÄ±ÅŸÄ±klÄ±k matrisi adÄ± verilen her sÄ±nÄ±f iÃ§in doÄŸru
ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ Ã¶rnek sayÄ±larÄ±nÄ±n bulunduÄŸu bir matris kullanÄ±larak yapÄ±lÄ±r. YP, YN, DP ve DN
kavramlarÄ± aÅŸaÄŸÄ±da belirtildiÄŸi gibi tanÄ±mlanabilir:
â€¢
â€¢
â€¢
â€¢

YanlÄ±ÅŸ pozitifler (YP): negatif sÄ±nÄ±ftan olan, pozitif olarak tahmin edilen Ã¶rnekler.
YanlÄ±ÅŸ negatifler (YN): gerÃ§ek sÄ±nÄ±fÄ± pozitif olan negatif olarak tahmin edilen Ã¶rnekler.
DoÄŸru pozitifler (DP): pozitif sÄ±nÄ±fa ait doÄŸru tahmin edilen Ã¶rnekler.
DoÄŸru negatifler (DN): negatif sÄ±nÄ±fa ait olarak doÄŸru tahmin edilen Ã¶rnekler.
|ğ·ğ‘|+|ğ·ğ‘ƒ|

DoÄŸruluk = |ğ‘Œğ‘|+|ğ‘Œğ‘ƒ|+|ğ·ğ‘|+|ğ·ğ‘ƒ|

(4)

Hassasiyet Ã¶lÃ§Ã¼mÃ¼, ikili problemlerde her bir sÄ±nÄ±f iÃ§in sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n etkinliÄŸini deÄŸerlendirir. GerÃ§ek
pozitif oran olarak bilinen hassasiyet, pozitif sÄ±nÄ±fa ait tahmin edilen verilerin gerÃ§ek pozitif verilerine
oranÄ±dÄ±r. Hassasiyet Ã¶lÃ§Ã¼mÃ¼ denklem 5â€™de verilmiÅŸtir.
|ğ·ğ‘ƒ|

Hassasiyet = |ğ‘Œğ‘|+|ğ·ğ‘ƒ|

(5)

Kesinlik (P), pozitif bir tahminin doÄŸru olma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin eden bir Ã¶lÃ§Ã¼dÃ¼r. Kesinlik Ã¶lÃ§Ã¼mÃ¼ denklem
6â€™de verilmiÅŸtir.
|ğ·ğ‘ƒ|

Kesinlik(P) = |ğ·ğ‘ƒ|+|ğ‘Œğ‘ƒ|

(6)

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

469

F-skoru, pozitif kestirim oranÄ± ve duyarlÄ±lÄ±k Ã¶lÃ§Ã¼lerinin uyumlu bir ortalamasÄ± olup denklem 7â€™de
gÃ¶sterildiÄŸi gibi hesaplanÄ±r.
F âˆ’ skor =

2âˆ—|ğ·ğ‘ƒ|

(7)

2âˆ—|ğ·ğ‘ƒ|+|ğ‘Œğ‘ƒ|+|ğ‘Œğ‘|

YukarÄ±da verilen denklemler genellikle performans deÄŸerlendirme Ã¶lÃ§Ã¼tlerinin hesaplanmasÄ± iÃ§in
kullanÄ±lmaktadÄ±r. AyrÄ±ca bu hesaplama Ã¶lÃ§Ã¼leri ikili sÄ±nÄ±fa ait veri setlerinde kullanÄ±lmak amacÄ±yla
geliÅŸtirilmiÅŸtir. Ancak ikiden fazla sÄ±nÄ±fa ait sÄ±nÄ±flandÄ±rma problemlerinin Ã§Ã¶zÃ¼mÃ¼ iÃ§in genel olarak bu
yÃ¶ntemlerin genelleÅŸtirilmiÅŸ halleri kullanÄ±lmaktadÄ±r. Modelin performansÄ±nÄ± Ã¶lÃ§mek ve deneklerin gÃ¼nlÃ¼k
ruh hallerinin kayÄ±tlar Ã¼zerinde etkileri iÃ§in Ã¼Ã§ farklÄ± deney yapÄ±lmÄ±ÅŸtÄ±r. Ä°lk deneyde kayÄ±tlarÄ±n hepsi farklÄ±
gÃ¼nlerin sabah saatlerinde alÄ±nmÄ±ÅŸtÄ±r. Ä°kinci deneyde kayÄ±tlar farklÄ± gÃ¼nlerin Ã¶ÄŸlen saatlerinde alÄ±nmÄ±ÅŸtÄ±r.
ÃœÃ§Ã¼ncÃ¼n deneyde ise sabah ve Ã¶ÄŸlen saatlerinde alÄ±nan kayÄ±tlar birleÅŸtirilmiÅŸtir. HazÄ±rlamÄ±ÅŸ olduÄŸumuz
veri seti kullanarak gerÃ§ekleÅŸtirmiÅŸ olduÄŸumuz deneylerden elde edilen sÄ±nÄ±flandÄ±rma sonuÃ§larÄ± Tablo 2,
Tablo 3 ve Tablo 4â€™de verilmiÅŸtir. AyrÄ±ca deneylerden elde edilen sÄ±nÄ±flandÄ±rma sonuÃ§larÄ±nÄ±n
karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± ÅŸekil 10â€™da verilmiÅŸtir. Ã–nerilen yÃ¶ntemin uygulamasÄ±, Ä°7 2.50GHz iÅŸlemci, 12GB hafÄ±za
ve NVIDIA 940M GPU donanÄ±m Ã¶zelliklerine sahip makine Ã¼zerinde yapÄ±lmÄ±ÅŸtÄ±r. Uygulama iÃ§in gerekli
yazÄ±lÄ±m kodlarÄ± matlab2018a kullanÄ±larak hazÄ±rlanmÄ±ÅŸtÄ±r.
Tablo 2â€™de deney 1 (sabah saatlerindeki kayÄ±tlar)â€™den elde edilen sÄ±nÄ±flandÄ±rma sonuÃ§larÄ± verilmiÅŸtir. AyrÄ±ca
deney1â€™den elde edilen en iyi sÄ±nÄ±flandÄ±rma sonucuna ait karÄ±ÅŸÄ±klÄ±k matrisi ÅŸekil 7â€™de verilmiÅŸtir.
Tablo 2. Deney 1â€™den Elde Edilen SÄ±nÄ±flandÄ±rma SonuÃ§larÄ±

Model

Verinin EÄŸitim ve
Test iÃ§in FarklÄ±
oranlarda BÃ¶lÃ¼nmesi

DoÄŸruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

74,32
78,44
71,91
75,63
70,14
73,26
65,77
68,12

75,80
78,30
72,59
75,91
70,65
72,71
67,70
70,68

74,31
78,47
71,53
75,70
70,14
72,92
65,97
68,06

74,45
78,33
71,41
75,58
69,94
72,64
65,98
68,40

Åekil 7: Deney 1â€™den elde edilen en iyi sÄ±nÄ±flandÄ±rma sonucuna ait karÄ±ÅŸÄ±klÄ±k matrisi
Tablo 3â€™de deney 2 (Ã¶ÄŸlen saatlerindeki kayÄ±tlar)â€™den elde edilen sÄ±nÄ±flandÄ±rma sonuÃ§larÄ± verilmiÅŸtir. AyrÄ±ca
Deney 2â€™den elde edilen en iyi sÄ±nÄ±flandÄ±rma sonucuna ait karÄ±ÅŸÄ±klÄ±k matrisi ÅŸekil 8â€™de verilmiÅŸtir.

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

470

Tablo 3. Deney 2â€™den Elde Edilen SÄ±nÄ±flandÄ±rma SonuÃ§larÄ±

Model

Verinin EÄŸitim ve
Test iÃ§in FarklÄ±
oranlarda BÃ¶lÃ¼nmesi

DoÄŸruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

71,62
73,52
69,54
72,22
71,36
72,73
66,15
67,87

72,27
73,32
69,96
72,37
72,84
73,09
65,17
69,37

71,53
73,61
69,45
72,22
71,53
72,92
65,98
68,06

71,39
73,35
69,25
71,93
71,62
72,59
65,27
68,00

Åekil 8: Deney 2â€™den elde edilen en iyi sÄ±nÄ±flandÄ±rma sonucuna ait karÄ±ÅŸÄ±klÄ±k matrisi
Tablo 4â€™de deney 3 (sabah + Ã¶ÄŸlen saatlerinde alÄ±nan kayÄ±tlar)â€™den elde edilen sÄ±nÄ±flandÄ±rma sonuÃ§larÄ±
verilmiÅŸtir. AyrÄ±ca Deney 3â€™den elde edilen en iyi sÄ±nÄ±flandÄ±rma sonucuna ait karÄ±ÅŸÄ±klÄ±k matrisi ÅŸekil 9â€™da
verilmiÅŸtir.
Tablo 4. Deney 3â€™den Elde Edilen SÄ±nÄ±flandÄ±rma SonuÃ§larÄ±

Model

Verinin EÄŸitim ve
Test iÃ§in FarklÄ±
oranlarda BÃ¶lÃ¼nmesi

DoÄŸruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

77,34
79,42
75,91
78,65
73,13
77,23
68,76
69,14

77,53
79,53
76,67
75,86
73,53
77,95
69,25
71,26

77,43
79,51
76,04
91,67
72,92
77,08
68,75
69,10

77,29
79,12
76,18
83,02
73,12
77,13
68,58
69,08

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

471

Åekil 9: Deney 3â€™den elde edilen en iyi sÄ±nÄ±flandÄ±rma sonucuna ait karÄ±ÅŸÄ±klÄ±k matrisi
Tablo 2, Tablo 3 ve Tablo 4â€™deki sonuÃ§lara gÃ¶re, eÄŸitim verisinin arttÄ±rÄ±lmasÄ± ile birlikte sÄ±nÄ±flandÄ±rma
doÄŸruluÄŸu da artmÄ±ÅŸtÄ±r. Bu sonuÃ§lardan yola Ã§Ä±karak, deneylerde kullanÄ±lan Ã¶rnek sayÄ±sÄ±nÄ±n arttÄ±rÄ±lmasÄ±
modelin doÄŸruluÄŸunu da arttÄ±rmÄ±ÅŸtÄ±r. AyrÄ±ca Tablo 2â€™deki veriler Tablo 3â€™deki veriler ile kÄ±yaslandÄ±ÄŸÄ±nda
sabah saatlerinde alÄ±nan kayÄ±tlardan daha fazla sÄ±nÄ±flandÄ±rma baÅŸarÄ±mÄ± elde edilmiÅŸtir. Bu durum farklÄ±
saatlerdeki ruh hallerinin sÄ±nÄ±flandÄ±rma Ã¼zerindeki etkisini gÃ¶stermektedir.

Åekil 10: Deneylerden Elde Edilen En Ä°yi SÄ±nÄ±flandÄ±rma SonuÃ§larÄ±nÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±
Tablo 5â€™de DEAP veri setinden elde edilen sÄ±nÄ±flandÄ±rma sonuÃ§larÄ± verilmiÅŸtir. AyrÄ±ca bu veri kÃ¼mesinden
elde edilen sonuÃ§larÄ±n Ã¶nceki Ã§alÄ±ÅŸmalarla karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± tablo 6â€™da verilmiÅŸtir.
Tablo 5. DEAP veri setinden Elde Edilen SÄ±nÄ±flandÄ±rma SonuÃ§larÄ±

Model

Verinin EÄŸitim ve
Test iÃ§in FarklÄ±
oranlarda BÃ¶lÃ¼nmesi

DoÄŸruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

69,23
70,12
67,16
68,24
64,41
66,32
64,23
65,36

69,58
70,46
67,42
68,67
64,62
66,57
64,61
65,61

69,42
70,24
67,35
68,42
64,51
66,46
64,45
65,52

69,12
70,02
67,12
68,11
64,24
66,15
64,07
65,14

472

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

Tablo 6. DEAP Veri seti iÃ§in Performans KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±
Metod
[41]
[42]
[43]
Ã–nerilen YÃ¶ntem

SÄ±nÄ±flandÄ±rÄ±cÄ±
CapsNet
Random Forest
DVM
YSA

DoÄŸruluk %
68,20
72,07
60,50
70,12

Tablo 6'te gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi, Ã¶nerilen yÃ¶ntemin literatÃ¼rde kullanÄ±lan diÄŸer iki yÃ¶ntemden daha iyi performans
gÃ¶sterdiÄŸi gÃ¶zlenmektedir. Bu bilgiler Ä±ÅŸÄ±ÄŸÄ±nda, Ã¶nerilen mimarinin insan duygularÄ±nÄ±n EEG ile
tanÄ±nmasÄ±nda etkili bir ÅŸekilde kullanÄ±labileceÄŸi gÃ¶rÃ¼lmektedir.
5. SONUÃ‡LAR (RESULTS)
Bu Ã§alÄ±ÅŸmada, bazÄ± sinyal iÅŸleme metotlarÄ± ve makine Ã¶ÄŸrenmesi yÃ¶ntemleri kullanÄ±larak mÃ¼zik dinlerken
EEG sinyalleri Ã¼zerinden duygu tanÄ±ma iÃ§in yeni bir yÃ¶ntem sunulmuÅŸtur. Sessiz ve karanlÄ±k ortamda 10
kiÅŸinin katÄ±lÄ±m saÄŸladÄ±ÄŸÄ± bir deney yapÄ±lmÄ±ÅŸtÄ±r. FarklÄ± mÃ¼zik tÃ¼rlerinden seÃ§ilen ÅŸarkÄ±lar eÅŸit Ã¶rneklem
frekansÄ±na getirilerek deneye katÄ±lan kiÅŸilere dinletilmiÅŸtir. Deneklere mÃ¼zik dinletilirken aynÄ± anda bu
deneklerin EEG sinyalleri EEG kayÄ±t cihazÄ± ile bilgisayar ortamÄ±na kaydedilmiÅŸtir. Duygular belirli bir sÃ¼re
iÃ§erisinde anlamlÄ±lÄ±k kazandÄ±ÄŸÄ± iÃ§in her EEG kaydÄ± 30 saniye olarak alÄ±nmÄ±ÅŸtÄ±r. Dinletilen her ÅŸarkÄ±nÄ±n
sonunda deneÄŸin hissettiÄŸi duygu kendisine sorulmuÅŸ ve deneÄŸe ait kaydedilen EEG sinyalleri
etiketlenmiÅŸtir. Duygu algÄ±sÄ±nÄ±n Ã¶znel olmasÄ±ndan dolayÄ± dÃ¶rt adet duygu etiketi kullanÄ±lmÄ±ÅŸtÄ±r. Bu etiketler
gergin, hÃ¼zÃ¼nlÃ¼, mutlu veya rahatlatÄ±cÄ± duygu olarak tanÄ±mlanmÄ±ÅŸtÄ±r. Etiketlenerek kaydedilen EEG
sinyalleri, Ã¶ncelikle bant geÃ§iren filtreden geÃ§irilmiÅŸtir. Daha sonra filtrelenmiÅŸ sinyallerden Ã¶znitelik
Ã§Ä±karÄ±larak sÄ±nÄ±flandÄ±rma iÅŸlemi yapÄ±lmÄ±ÅŸtÄ±r ve sonuÃ§lar karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. SÄ±nÄ±flandÄ±rÄ±cÄ± olarak YSA, DVM
ve KNN kullanÄ±lmÄ±ÅŸtÄ±r. En iyi sÄ±nÄ±flandÄ±rma baÅŸarÄ±sÄ± ortalama olarak %79,42 olarak YSA ile kendi veri
setimiz Ã¼zerinden elde edilmiÅŸtir. AyrÄ±ca DEAP veri seti kullanÄ±larak %70,12 doÄŸruluk elde edilmiÅŸtir.
SonuÃ§lara gÃ¶re, Ã¶nerilen yÃ¶ntemin insan duygularÄ±nÄ± tanÄ±ma problemi iÃ§in kullanÄ±labileceÄŸi belirtilmiÅŸtir.
Gelecekti Ã§alÄ±ÅŸmalar iÃ§in uyaran olarak mÃ¼zik verileri kullanÄ±larak EEG veri setleri hazÄ±rlanmasÄ± ve derin
Ã¶ÄŸrenme modellerinin insan duygularÄ±nÄ±n tanÄ±nma probleminde kullanÄ±lmasÄ± Ã¶nerilmektedir.
KAYNAKLAR (REFERENCES)
[1]

C. C. Pratt, Music as the language of emotion. Oxford, England: The Library of Congress, 1952.

[2]

R.-F. Day, C.-H. Lin, W.-H. Huang, and S.-H. Chuang, â€œEffects of music tempo and task difficulty on multiattribute decision-making: An eye-tracking approach,â€ Comput. Human Behav., vol. 25, no. 1, pp. 130â€“143,
Jan. 2009, doi: 10.1016/J.CHB.2008.08.001.

[3]

G. Varotto, P. Fazio, D. R. Sebastiano, G. Avanzini, S. Franceschetti, and F. Panzica, â€œMusic and emotion:
An EEG connectivity study in patients with disorders of consciousness,â€ in 2012 Annual International
Conference of the IEEE Engineering in Medicine and Biology Society, 2012, pp. 5206â€“5209, doi:
10.1109/EMBC.2012.6347167.

[4]

D. HURON, â€œIs Music an Evolutionary Adaptation?,â€ Ann. N. Y. Acad. Sci., vol. 930, no. 1, pp. 43â€“61, 2001,
doi: 10.1111/j.1749-6632.2001.tb05724.x.

[5]

I. Peretz and R. J. Zatorre, â€œBrain Organization for Music Processing,â€ Annu. Rev. Psychol., vol. 56, no. 1,
pp. 89â€“114, 2005, doi: 10.1146/annurev.psych.56.091103.070225.

[6]

S. M. AlarcÃ£o and M. J. Fonseca, â€œEmotions Recognition Using EEG Signals: A Survey,â€ IEEE Trans. Affect.
Comput., vol. 10, no. 3, pp. 374â€“393, 2019, doi: 10.1109/TAFFC.2017.2714671.

[7]

P. J. Lang, â€œThe emotion probe: Studies of motivation and attention.,â€ American Psychologist, vol. 50, no. 5.
American Psychological Association, US, pp. 372â€“385, 1995, doi: 10.1037/0003-066X.50.5.372.

[8]

R. W. Picard, Affective Computing. The MIT Press, 2000.

[9]

L. Shu et al., â€œA Review of Emotion Recognition Using Physiological Signals,â€ Sensors (Basel)., vol. 18, no.
7, p. 2074, Jun. 2018, doi: 10.3390/s18072074.

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

473

[10]

A. M. Bhatti, M. Majid, S. M. Anwar, and B. Khan, â€œHuman emotion recognition and analysis in response to
audio music using brain signals,â€ Comput. Human Behav., vol. 65, pp. 267â€“275, Dec. 2016, doi:
10.1016/J.CHB.2016.08.029.

[11]

F. Zhang, H. Meng, and M. Li, â€œEmotion extraction and recognition from music,â€ 2016 12th International
Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD). IEEE, 2016,
doi: 10.1109/fskd.2016.7603438.

[12]

A. Goshvarpour and A. Goshvarpour, â€œEEG spectral powers and source localization in depressing, sad, and
fun music videos focusing on gender differences,â€ Cogn. Neurodyn., vol. 13, no. 2, pp. 161â€“173, 2018, doi:
10.1007/s11571-018-9516-y.

[13]

A. M. Bhatti, M. Majid, S. M. Anwar, and B. Khan, â€œHuman emotion recognition and analysis in response to
audio music using brain signals,â€ Comput. Human Behav., vol. 65, pp. 267â€“275, Dec. 2016, doi:
10.1016/J.CHB.2016.08.029.

[14]

C. Shahnaz, Shoaib-Bin-Masud, and S. M. S. Hasan, â€œEmotion recognition based on wavelet analysis of
Empirical Mode Decomposed EEG signals responsive to music videos,â€ 2016 IEEE Region 10 Conference
(TENCON). IEEE, 2016, doi: 10.1109/tencon.2016.7848034.

[15]

Y. Liu et al., â€œWhat Strikes the Strings of Your Heart?â€“Multi-Label Dimensionality Reduction for Music
Emotion Analysis via Brain Imaging,â€ IEEE Trans. Auton. Ment. Dev., vol. 7, no. 3, pp. 176â€“188, 2015, doi:
10.1109/tamd.2015.2429580.

[16]

R. Nawaz, H. Nisar, and Y. V. Voon, â€œThe Effect of Music on Human Brain; Frequency Domain and Time
Series Analysis Using Electroencephalogram,â€ IEEE Access, vol. 6, pp. 45191â€“45205, 2018, doi:
10.1109/access.2018.2855194.

[17]

J.-L. Hsu, Y.-L. Zhen, T.-C. Lin, and Y.-S. Chiu, â€œAffective content analysis of music emotion through EEG,â€
Multimed. Syst., vol. 24, no. 2, pp. 195â€“210, 2017, doi: 10.1007/s00530-017-0542-0.

[18]

G. Balasubramanian, A. Kanagasabai, J. Mohan, and N. P. G. Seshadri, â€œMusic induced emotion using
wavelet packet decompositionâ€”An EEG study,â€ Biomed. Signal Process. Control, vol. 42, pp. 115â€“128,
2018, doi: 10.1016/j.bspc.2018.01.015.

[19]

M. Yanagimoto and C. Sugimoto, â€œRecognition of persisting emotional valence from EEG using
convolutional neural networks,â€ 2016 IEEE 9th International Workshop on Computational Intelligence and
Applications (IWCIA). IEEE, 2016, doi: 10.1109/iwcia.2016.7805744.

[20]

C.-Y. Liao, R.-C. Chen, and S.-K. Tai, â€œEmotion stress detection using EEG signal and deep learning
technologies,â€ 2018 IEEE International Conference on Applied System Invention (ICASI). IEEE, 2018, doi:
10.1109/icasi.2018.8394414.

[21]

S. Vaid, P. Singh, and C. Kaur, â€œEEG Signal Analysis for BCI Interface: A Review,â€ 2015 Fifth International
Conference on Advanced Computing & Communication Technologies. IEEE, 2015, doi:
10.1109/acct.2015.72.

[22]

Siuly, â€œANALYSIS AND CLASSIFICATION OF EEG SIGNALS,â€ UNIVERSITY OF SOUTHERN
QUEENSLAND, 2012.

[23]

B. Farnsworth, â€œWhat is EEG
https://imotions.com/blog/what-is-eeg.

[24]

S. D. Puthankattil, P. Joseph, U. R. Acharya, and C. Lim, â€œEEG signal analysis: a survey,â€ J. Med. Syst., vol.
34, pp. 195â€“212, Apr. 2010, doi: 10.1007/s10916-008-9231-z.

[25]

H. . Jasper, â€œThe Ten-Twenty Electrode System of the International Federation,â€ Electroencephalogr. Clin.
Neurophysiol., vol. 10, pp. 371â€“375, 1958.

[26]

S. Koelstra et al., â€œDEAP: A Database for Emotion Analysis ;Using Physiological Signals,â€ IEEE Trans.
Affect. Comput., vol. 3, no. 1, pp. 18â€“31, 2012, doi: 10.1109/T-AFFC.2011.15.

[27]

B. S. Atal, â€œAutomatic recognition of speakers from their voices,â€ Proc. IEEE, vol. 64, no. 4, pp. 460â€“475,
1976, doi: 10.1109/proc.1976.10155.

[28]

S. Gupta, J. Jaafar, W. F. Wan Ahmad, and A. Bansal, â€œFeature Extraction Using Mfcc,â€ Signal Image

(Electroencephalography)

and

How

Does

it

Work?â€

474

Mehmet Bilal ER, Harun Ã‡Ä°Ä/ GU J Sci, Part C, 8(2):458-474 (2020)

Process. An Int. J., vol. 4, pp. 101â€“108, Aug. 2013, doi: 10.5121/sipij.2013.4408.
[29]

S. I.-J. Chien, Y. Ding, and C. Wei, â€œDynamic Bus Arrival Time Prediction with Artificial Neural Networks,â€
J. Transp. Eng., vol. 128, no. 5, pp. 429â€“438, 2002, doi: 10.1061/(asce)0733-947x(2002)128:5(429).

[30]

S. M. J. Pappu and S. N. Gummadi, â€œArtificial neural network and regression coupled genetic algorithm to
optimize parameters for enhanced xylitol production by Debaryomyces nepalensis in bioreactor,â€ Biochem.
Eng. J., vol. 120, pp. 136â€“145, 2017, doi: 10.1016/j.bej.2017.01.010.

[31]

Q. Yang, S. Le Blond, R. Aggarwal, Y. Wang, and J. Li, â€œNew ANN method for multi-terminal HVDC
protection relaying,â€ Electr. Power Syst. Res., vol. 148, pp. 192â€“201, 2017, doi: 10.1016/j.epsr.2017.03.024.

[32]

D. Niebur and A. J. Germond, â€œPower flow classification for static security assessment,â€ Proceedings of the
First International Forum on Applications of Neural Networks to Power Systems. IEEE, doi:
10.1109/ann.1991.213502.

[33]

â€œSupport Vector Machines, 1992; Boser, Guyon, Vapnik,â€ in SpringerReference, Springer-Verlag.

[34]

A. Widodo and B.-S. Yang, â€œSupport vector machine in machine condition monitoring and fault diagnosis,â€
Mech. Syst. Signal Process., vol. 21, no. 6, pp. 2560â€“2574, 2007, doi: 10.1016/j.ymssp.2006.12.007.

[35]

E. Kabir, Siuly, and Y. Zhang, â€œEpileptic seizure detection from EEG signals using logistic model trees,â€
Brain Informatics, vol. 3, no. 2, pp. 93â€“100, 2016, doi: 10.1007/s40708-015-0030-2.

[36]

B. SchÃ¶lkopf and A. J. Smola, Smola, A.: Learning with Kernels - Support Vector Machines, Regularization,
Optimization and Beyond. MIT Press, Cambridge, MA, vol. 98. 2001.

[37]

Y. Zhang, X. Ji, and S. Zhang, â€œAn approach to EEG-based emotion recognition using combined feature
extraction method,â€ Neurosci. Lett., vol. 633, pp. 152â€“157, 2016, doi: 10.1016/j.neulet.2016.09.037.

[38]

H. JÃ©gou, M. Douze, and C. Schmid, â€œProduct Quantization for Nearest Neighbor Search,â€ IEEE Trans.
Pattern Anal. Mach. Intell., vol. 33, no. 1, pp. 117â€“128, 2011, doi: 10.1109/tpami.2010.57.

[39]

T. Cover and P. Hart, â€œNearest neighbor pattern classification,â€ IEEE Trans. Inf. Theory, vol. 13, no. 1, pp.
21â€“27, 1967, doi: 10.1109/tit.1967.1053964.

[40]

C. Li et al., â€œUsing the K-Nearest Neighbor Algorithm for the Classification of Lymph Node Metastasis in
Gastric Cancer,â€ Comput. Math. Methods Med., vol. 2012, pp. 1â€“11, 2012, doi: 10.1155/2012/876545.

[41]

H. Chao, L. Dong, Y. Liu, and B. Lu, â€œEmotion Recognition from Multiband EEG Signals Using CapsNet,â€
Sensors, vol. 19, no. 9, p. 2212, 2019, doi: 10.3390/s19092212.

[42]

V. Gupta, M. D. Chopda, and R. B. Pachori, â€œCross-Subject Emotion Recognition Using Flexible Analytic
Wavelet Transform From EEG Signals,â€ IEEE Sens. J., vol. 19, no. 6, pp. 2266â€“2274, 2019, doi:
10.1109/jsen.2018.2883497.

[43]

X. Li, D. Song, P. Zhang, Y. Zhang, Y. Hou, and B. Hu, â€œExploring EEG Features in Cross-Subject Emotion
Recognition,â€ Front. Neurosci., vol. 12, 2018, doi: 10.3389/fnins.2018.00162.

