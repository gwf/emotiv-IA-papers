GU J Sci, Part C, 8(2): 458-474 (2020)
Gazi Üniversitesi

Fen Bilimleri Dergisi
PART C: TASARIM VE TEKNOLOJİ
http://dergipark.gov.tr/gujsc

Recognition of Human Emotions by Machine Learning Method Using
Turkish Music Stimuli
Mehmet Bilal ER*

Harun ÇİĞ

Harran University Faculty of Engineering, Department of Computer Engineering, Haliliye/Şanlıurfa

Graphical/Tabular Abstract

Article Info:
Research article
Received: 10/02/2020
Revision 03/05/2020
Accepted: 16/05/2020

In this study, experiments are carried out both on our own dataset and on the DEAP dataset, which
are widely used in the literature. Different types of Turkish songs were played to the participants.
By examining the electrical waves that occur in their brain's surface, happy, sad, relaxing and
angry mood states were recognized. Participants were asked to listen to music from different types
in a noiseless environment. To classify the emotions, electroencephalography (EEG) signals were
saved primarily from different channels. Certain features have been extracted from these signals.
Extracted features have been classified using machine learning algorithms.

Highlights
• EEG
• Emotion Recognition
• Machine Learning

Figure A. schema of the Steps of Emotion Recognition

Keywords
Recognizing Human
Emotions
EEG
Machine Learning
Signal Processing

Purpose: The aim of this study is to estimate the emotional state with machine learning and signal
processing techniques by measuring the electrical energy of the brain using Turkish music stimuli.
Theory and Methods: The proposed model for the recognition of human emotions while
listening to music is explained step by step. For the proposed model brain signal recording, feature
extraction calculations and classification types are given in the paper. Emotive recording device
was used to record brain signals. Support Vector Machines (DVM), K Nearest Neighbor (KNN)
and Artificial Neural Networks (ANN) machine learning algorithms were used to classify signals.
Results: We conduct an experiment, in a silent and dark environment, where 10 people
participated and they are required to listen to different types of music in order to record brain
signals. Four emotion labels have been used: angry, sad, happy or relaxing emotion. First,
recorded EEG signals passed a bandpass filter. Then, the classification was made by extracting
the feature from the filtered signals and the results are compared in section 5.
Conclusion: In this study, a new method is presented for emotion recognition on EEG signals
while listening to music using some signal processing and machine learning methods. According
to the results, it is shown that the proposed method can be used for the problem of recognizing
human emotions. It has been observed that the efficiency of the system increased depend on
increasing the number of samples and taking the recorded signals from humans at the right time
(morning). It is recommended to prepare EEG datasets by using music data as a stimulus for
future studies and to use deep learning models in the problem of recognition of human emotions.

*Corresponding author, e-mail: bilal.er@harran.edu.tr

DOI: 10.29109/gujsc.687199

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

459

GU J Sci, Part C, 8(2): 458-474 (2020)
Gazi Üniversitesi

Fen Bilimleri Dergisi
PART C: TASARIM VE TEKNOLOJİ
http://dergipark.gov.tr/gujsc

Türk Müziği Uyaranları Kullanılarak İnsan Duygularının Makine Öğrenmesi
Yöntemi İle Tanınması
Mehmet Bilal ER*

Harun ÇİĞ

Harran University Faculty of Engineering, Department of Computer Engineering, Haliliye/Şanlıurfa

Öz
Makale Bilgisi
Araştırma makalesi
Başvuru: 10/02/2020
Düzeltme: 03/05/2020
Kabul: 16/05/2020

Anahtar Kelimeler
İnsan Duygularını Tanıma
EEG
Makine Öğrenmesi
Sinyal İşleme

Keywords
Recognizing Human
Emotions
EEG
Machine Learning
Signal Processing

Müzik, zaman ve frekansa göre değişiklik gösteren çok çeşitli karmaşık bileşenlerden oluşan bir
ses sinyalidir. Müziğin dinleyicide çok çeşitli duygular uyandırdığı literatürde yaygın olarak
kabul edilmektedir. Bir kişinin dinlediği müziğe hüzünlü ya da mutlu duygu içeriyor demesi
gerçekte hissettiği duyguyu ortaya koymayabilir. Ancak müzik dinleme anında hissedilen
duyguya göre beynin içinde meydana gelen elektriksel dalgalanmalar, algılanan gerçek duygunun
yapısını daha doğru bir şekilde ortaya koyabilmektedir. Beyin sinyalleri kullanılarak insan
duygularının tespit edilmesi, birçok alanda güncel araştırma konusu olmuştur. Bu çalışmada ise
müzik parçaları dinlenirken insan duygularının tanınması problemi ele alınmıştır. Deneyler hem
kendi veri setimiz üzerinde hem de literatürde yaygın olarak kullanılan DEAP veri seti üzerinde
yapılmıştır. Farklı türlerdeki Türk müziği parçaları katılımcılara dinletilerek beyinlerinde oluşan
elektriksel dalgalar incelenerek mutlu, hüzünlü, rahatlatıcı ve gergin duygu durumları tanınmaya
çalışılmıştır. Katılımcılardan gürültüsüz bir ortamda farklı türlerden müzik parçaları dinlemeleri
istenilmiştir. Duyguların sınıflandırılması için öncelikle farklı kanallardan Elektroansefalografi
(EEG) sinyalleri alınmıştır ve elde edilen bu sinyaller üzerinden belirli öznitelikler çıkarılmıştır.
Çıkarılan öznitelikler Destek Vektör Makineleri (DVM), K En Yakın Komşu (KNN) ve Yapay
Sinir Ağlarını (YSA) makine öğrenmesi algoritmaları kullanılarak sınıflandırılmıştır. Veri setini
eğitmek ve insan duygularını sınıflandırmak için kullanılan algoritmalardan en iyi doğruluk oranı
YSA ile elde edilmiştir. Elde edilen bulgulara göre, kullanılan yöntemin iyi performans gösterdiği
gözlemlenmiştir.

Recognition of Human Emotions by Machine Learning Method
Using Turkish Music Stimuli
Abstract
Music is an audio signal consisting of a wide variety of complex components which vary
according to time and frequency. It is widely accepted in the literature that music evokes a wide
variety of emotions in the audience. When a person says that the music they are listening to
contains sad or happy feelings, this may not reveal the feeling they actually feel. However,
according to the emotion felt during listening to music, fluctuations in electrical activity of the
brain can more accurately reveal the structure of perceived true emotion. Detecting human
emotions using brain signals has been the subject of current research in many areas. In this study,
the problem of detection human emotions while listening to music has been discussed.
Experiments are carried out both on our own dataset and on the DEAP dataset, which is widely
used in the literature. Different types of Turkish music’s were played to the participants. By
examining the electrical waves that occur in their brain's surface, happy, sad, relaxing and angry
mood states were recognized. Participants were asked to listen to music from different types in a
noiseless environment. To classification the emotions, electroencephalography (EEG) signals
were saved primarily from different channels. Certain features have been extracted from these
signals. Extracted features have been classified using machine learning algorithms for Support
Vector Machines (SVM), K nearest neighbor (KNN), and Artificial Neural Networks (ANN). The
best accuracy rate was obtained by ANN from algorithms used to train the data set and classify
human emotions. According to the results obtained, it was observed that the used method
performed well.

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

460

1. GİRİŞ (INTRODUCTION)
Müzik, duyguların dili olarak bilinir ve dinleyicide neşe, heyecan ve korku gibi farklı duygusal tepkiler
ortaya çıkarabilen güçlü bir yöntem olarak kabul edilmektedir [1]–[4]. Bir kişinin kendini üzgün hissetmesi
durumunda mutlu bir müzik dinlemesi kişinin duygu durumunun mutlu olarak değişmesine yardımcı
olacaktır. Müzik dinleyen insanlarda belirli duyguların uyanmaması çok nadir görünen bir durumdur.
Müzik hem duyguları ifade etme hem de dinleyicide duygusal tepkiler uyandırma da etkili olduğu için
müzikoloji, psikoloji, sinyal işleme gibi birçok alanda araştırma konusu olmuştur. Nörolojik çalışmalar,
müziğin beyin sistemini değerlendirmek için önemli bir araç olduğunu ortaya koymuştur [5]. İnsan
duygularının hesaplamalarla tahmin edilmesi, yorumlanması ve işlenmesi bir makine öğrenmesi alanıdır.
Ayrıca duygu durum analizleri sağlık, güvenlik ve eğitim gibi farklı alanlarda da kullanılmaktadır. EEG
tabanlı duygu tanıma çalışmaları son zamanlarda insan-bilgisayar etkileşimi alanında çok fazla ilgi
görmüştür.
Duygu, bireyin düşüncelerinden oluşur. Duygular, insanların düşünürken, iletişim kurarken, öğrenirken ve
karar verirken dış uyaranlara karşı vermiş oldukları tepkiler olarak ifade edilir. Bu yüzden duygular
insanların günlük hayattaki davranışlarının belirlenmesinde temel rol oynarlar. Ancak duygu, oldukça öznel
bir olgudur. Çünkü farklı insanlar dış uyaranlara tepki olarak aynı ortam ve koşullarda farklı tepkiler
verirler. Bütün insan duyguları birkaç temel duygudan üretilmektedir. Duygu, kategorik veya boyutsal
olarak iki ana gurup altında incelenir. Ayrık modeller olarak da bilinen kategorik modellerde duyguların
tanımlanması için tek kelime veya kelime grupları kullanılır. İki boyutlu düzlemde değerlilik ve uyarılma
değerleri ölçülür [6], [7]. Bilim adamları ve psikoloji uzmanları farklı önerilerde bulunarak duygusal
modellerde insani duyguları kategorik olarak altı temel sınıfa ayırmışlarıdır. Bu sınıflar; mutluluk, korku,
iğrenme, üzülme, neşe ve öfke şeklindedir [8]. Bu araştırmada mutlu, hüzünlü, rahat ve gergin gibi dört
temel duygu incelenmiştir. Duygu tanıma üç ana kategoride incelenebilir. İlkinde yüz ifadeleri ya da
konuşmaların analizine odaklanılır. Bu görsel-işitsel temelli teknikler, duyguların temasız olarak
algılanmasını sağlar. İkinci tür yaklaşımlarda ise çevresel fizyolojik sinyallere odaklanılır. Çeşitli
çalışmalarda, elektrokardiyogram (EKG), solunum ve nabız gibi çevresel fizyolojik sinyallerin farklı
duygusal durumlarda değişiklik gösterdiği ve otonom sinir sistemini etkilediği gözlenmektedir. Çevresel
fizyolojik sinyaller, görsel-işitsel tabanlı yöntemlerle karşılaştırıldığında, duygusal durumları tahmin etmek
için daha ayrıntılı bilgi vermektedir [9], [10]. Üçüncü tür yaklaşımlarda ise, EEG gibi merkezi sinir
sisteminden üretilen beyin sinyallerine odaklanılır. EEG sinyalleri kullanılarak duygu durumunu tahmin
etmeyi amaçlayan birçok araştırma bulunmaktadır. EEG sinyalleri, elektrotlar kullanılarak kafa derisinden
kaydedilir. Esas olarak mono-polar ve bipolar olmak üzere iki tür EEG kaydı vardır. Mono-polar kayıt,
kafa derisindeki aktif elektrotlar ile bir referans elektrot arasındaki voltaj farkını ölçer. Öte yandan iki
kutuplu elektrotlar, iki aktif elektrot arasındaki voltaj farkını sağlamaktadır.





Bu çalışmanın ana katkıları aşağıdaki gibidir:
Müzik parçaları dinlerken kaydedilen EEG sinyalleri ile insan duygularını yansıtan 4 sınıftan
oluşan yeni bir veri seti oluşturulmuştur.
Müzik dinletileri uyaran olarak kullanılmıştır. Uyarılan EEG sinyalleri ile insan duygularını
tanıması için etkili bir yöntem önerilmiştir.
Makine öğrenmesinin duyguları tanıma problemindeki etkin gücü ortaya koyulmuştur.

EEG sinyalleri kullanarak insan duygu tanıma sistemleri geliştirilmesi için göz önünde bulundurulması
gereken bazı kısıtlamalar vardır. Bunlar;

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)







461

Duygu algısının öznel olması ve tam olarak evrensel bir tanımının yapılamamasından dolayı
kullanılan duygu etiketlerinin sıfat sayıları sınırlı olmalıdır.
Uyaran olarak kullanılan müziklerin eşit örneklem frekansına sahip olması gerekir.
Veri setindeki EEG kayıtlarının hepsi eşit örneklem frekansına sahip olmalıdır.
İnsanların müziklerden hissettikleri duyguları ifade etmek için, EEG kayıtlarından çıkarılan
özelliklerin müzikal duygularla ilişkili olmasına dikkat edilmelidir.
EEG durağan bir sinyal olmadığından EEG'den elde edilen özellik genellikle çarpıcı bir şekilde
değişirken, duygulanma durumları kademeli olarak değişir. Duygular belirli bir süre içerisinde
anlamlılık kazandığı için EEG kayıtlarının süresi çok kısa olmamalıdır.

Bu makalenin geri kalanı şu şekilde düzenlenmiştir. Bölüm 2’de literatürdeki duygu tanıma ile ilgili
çalışmalar gözden geçirilmiştir ve aralarındaki farklar ortaya koyulmaya çalışılmıştır. Bölüm 3’de veri seti,
materyal ve metot tanıtılmıştır. Bölüm 4’de araştırmada kullanılan insan duygu tanıma ile ilgili deneysel
uygulamalar verilmiştir. Bölüm 5’de ise araştırmanın bulguları tartışılmıştır ve insan duygu tanıma
modellerinin geliştirilmesi için önerilerde bulunulmuştur.
2. İLGİLİ ÇALIŞMALAR (RELATED WORKS)
[11]’de APM veri tabanı kullanılarak deneklerden EEG kayıtları alınmıştır. OpenSMILE kullanılarak
müzik dosyalarından 5 farklı öznitelik çıkarılmıştır. Deneklerden alınan EEG sinyallerinden 12 öznitelik
çıkarılmıştır ve son olarak bu öznitelikler Orman sınıflandırıcı ile mutlu, hüzünlü, rahat ve gergin olmak
üzere 4 ayrı kategoride sınıflandırılmıştır. Başarı oranında %0.4’lük bir artış gözlemlenmiştir.
[12]’de müzikli video uyaranlarına maruz kalma sırasında erkek ve kadınlarda ayrı ayrı EEG güç
spektrumları ile beyin kaynaklarındaki farklılıkları karşılaştırmak amaçlanmıştır. Deneklere hüzünlü,
eğlenceli ve iç karartıcı müzik klipleri izletilmiş ve aynı anda EEG sinyalleri kaydedilmiştir. Kaydedilen
bu EEG sinyalleri yedi ayrı frekans bandında incelenmiştir. Bu frekans bantları teta (h: 4-7.5 Hz), alfa1
(A1: 8–10 Hz), alfa2 (A2: 10–12 Hz), beta1 (B1: 13-18 Hz), beta2 (B2: 18.5–21 Hz), beta3 (B3: 21,5–30
Hz) ve gama (C: 30,5–44 Hz) olmak üzere ortalama Fourier çapraz spektral matrisler kullanılarak
hesaplanmıştır. B2, B3 ve C frekans bantlarında hüzünlü ve eğlenceli müzikler arasında anlamlı bir fark
olduğu gözlemlenmiştir. Uyaran dinletilere karşı beynin bazı bölgelerinde meydana gelen duygusal
tepkiler, B3 frekans bandında daha yüksek olduğu gözlemlenmiştir.
[13]’de frekans domeni özellikleri için Hamming penceresi ile kısa süreli Fourier dönüşümü kullanılmıştır.
Güç spektral yoğunluğu ve bant gücü frekans alanındaki özellikler olarak hesaplanmıştır. Zaman domeni,
frekans domeni ve wavelet domeni olmak üzere üç farklı alandan on üç öznitelik çıkarılmış ve bunlar YSA,
DVM ve KNN olmak üzere üç farklı sınıflandırıcı ile dört farklı duygu sınıflandırılmıştır. YSA'nın DVM
ve KNN sınıflandırıcılarına kıyasla en iyi doğruluk oranını sağladığı görülmüştür.
[14]’de bir dizi Intrinsic Mode Functions (IMF) elde etmek için video müzikleri dinletilen deneklerin EEG
sinyalleri kaydedilmiştir. EEG sinyalleri üzerinde Ampirik Kip Ayırışım ile öznitelik çıkarma işlemi
gerçekleştirilmiştir. Daha iyi bir zaman frekans çözünürlüğü elde etmek için sadece baskın IMF'ler üzerinde
Ayrık Wavelet Dönüşümü kullanılmıştır. Principal Component Analysis (PCA) ile boyutlar azaltılmış,
öznitelik vektörü daha sonra DVM ile duyguları sınıflandırmak için kullanılmıştır.
[15]’de müzik ve duygu arasındaki ilişkinin analizinde boyut azaltma yöntemi kullanılmıştır. Denekler
tarafından sağlanan duygu etiketlerini iyileştirmek için deneklerin EEG sinyalleri kaydedilmiştir. Daha
sonra Bilinear Multi Emotion - Similarity Preserving Embedding (BME-SPE) boyut azaltma yöntemi
kullanılarak yeni bir öğrenme planı önerilmiştir. Çalışmada Çin kültürüne ait müzikler kullanılmıştır.
Ancak diğer kültürlere ait müziklerde de benzer duygular gözlemlenmiştir. Önerilen yöntemde etkili
korelasyon tespit edilerek sınıflandırmada yüksek performans sağlandığı gözlemlenmiştir.

462

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

[16]’da farklı müzik uyaranları altında EEG dinamiklerini araştırılmıştır. Çalışmada iki tür müzik uyaranı;
favori müzik (deneklerin tercih ettiği müzikler) ve rahatlatıcı (alfa binaural ritimlerden oluşan müzikler)
kullanılmıştır. Müziğin insan beyni üzerindeki yatıştırıcı etkilerinin değerlendirilmesi için deneklerin EEG
kayıtları kullanılmıştır. Alfa bandında mutlak güç, yaklaşık entropi, örnek entropi ve ön asimetri gibi farklı
öznitelikler hesaplanmıştır. Sonuçlar rahatlatıcı müziğin, favori müziğe göre daha iyi yatıştırıcı etkilere
sahip olduğunu göstermektedir. Önce deneklerden ruh hallerini tespit eden bir anket doldurmaları istenmiş
ve çalışmanın sonunda bu anketler göz önüne alınarak değerlendirme yapılmıştır.
[17]’de kişiselleştirilmiş bir müzik duygu tanıma yaklaşımı önerilmiştir. Önerilen yaklaşım, eğitim
aşaması, kişisel adaptasyon ve test aşamasından oluşmaktadır. MIRtoolbox kullanarak ses nesnelerinden
spektrum, spektral centroid, Mel Frequency Cepstral Coefficients (MFCC), tonalite, harmonik tını dahil
olmak üzere toplamda 141 boyutlu özellik çıkarılmıştır. EEG özniteliklerini elde etmek için EEGLAB ve
Signal Processing Toolbox kullanılmıştır. Deneklere dinletilen müzik verileri ve müzik dinletilirken
kaydedilen EEG verilerinden elde edilen öznitelikler eğitim ağını oluşturmak için vektör halinde ayrı ayrı
yapay sinir ağına verilmiştir. %85 eğitim % 15 ise test verileri için kullanılmıştır. Deneysel sonuçlar
önerilen yaklaşımın etkili olduğunu göstermiştir.
[18]’de, deneklerin EEG sinyalleri kullanılarak kendi seçtikleri müziğe dinamik duygusal tepkileri analiz
edilmiştir. Deneklerin sevdiği ve sevmediği müzikler deneklere dinletilerek EEG sinyalleri kaydedilmiştir.
Daha sonra zamana göre frekans lokalizasyonu ve Wavelet Paket Dekompozisyonu (WPD) kullanılarak
EEG verileri analiz edilmiştir. Beğenilen müzik dinlenirken, beğenilmeyen müziğe kıyasla F3, F4, F7 ve
F8’in ön elektrot lokasyonlarında intheta bileşeninde önemli bir artış gözlemlenmiştir. Sevilmeyen müzik
dinlenirken frontal beta bileşen enerjisinde artış gözlenmiştir. Deneklerde beğenilen müzik için
gözlemlenen duygular benzerken beğenilmeyen müzikler için önemli bir benzerliğin olmadığı
gözlemlenmiştir.
[19]’da CNN tarafından sınıflandırılan EEG ham verilerinin doğruluğu değerlendirilmiştir. CNN'nin
öznitelik çıkarabildiği düşünülerek EEG ham verileri ön işleme yapılmadan doğrudan CNN’e verilmiştir.
Bu şekilde CNN’in ham EEG verilerinden duyguları tanıyıp tanımayacağı test edilmiştir. EEG verilerinin
değişkenliğini dikkate alan modellerin doğruluğunu değerlendirmek için 11 katlı çapraz doğrulama
kullanılmıştır. CNN’in duygusal sınıflarla ilgili veya ilgisiz olan bileşenleri ayırt edici bir şekilde
öğrenebildiği ve % 20'nin üzerinde doğrulukta tanıyabildiği gözlemlenmiştir.
[20]’de deneklere müzik dinletilerek stres duygularını tahmin etmek için öğrenme yöntemi olarak CNN
kullanılmıştır. 7 deneğe 10’ar dakikalık müzik dinletilmiş ve EEG sinyalleri kaydedilmiştir. Kaydedilen
EEG sinyalleri fourier dönüşümü ile zaman domeninden frekans domenine dönüştürülmüştür. Aktivasyon
fonksiyonu olarak ReLU kullanılmıştır. Ardından bu sinyaller derin öğrenme ile sınıflandırılmış ve %80’
e varan bir doğruluk oranı elde edilmiştir.
3. MATERYAL ve METOT (MATERIAL and METHODS)
3.1. EEG
İnsan beyni, milyarlarca sinir hücresinin birbirine bağlandığı karmaşık bir sistemdir. Beyin hücreleri
elektriksel impulslarla birbirleriyle iletişim kurarlar. EEG, beyin tarafından üretilen elektriksel aktiviteyi
kafa derisi yüzeyine yerleştirilen elektrotlar aracılığıyla kaydetmek için kullanılan fizyolojik yöntemdir.
1929'da Hans Berger, ilk insan beyni EEG’ sini kaydetmiştir [21]. EEG, doktorlar ve bilim adamları
tarafından beyin fonksiyonlarını incelemek ve nörolojik hastalıkları teşhis etmek için yaygın olarak
kullanılmaktadır. Bir EEG kayıt işleminde, beyin dalgası paternleri izlenir ve kaydedilir. EEG testi
sırasında, elektrot olarak adlandırılan küçük düz metal diskler teller ile kafa derisine sabitlenir ve daha
sonra her elektrot bir EEG kayıt makinesine bağlanır. Elektrotlar beyindeki elektriksel impulsları analiz
eder ve sonuçları kaydeden bir bilgisayara sinyaller gönderir. Kullanımlarına bağlı olarak, paralel olarak

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

463

veri kaydedebilen çok kanallı EEG kayıt cihazları 256 ya kadar elektrot içerebilir. Her kanal bir EEG kaydı
sırasında bir sinyal üretir [22]. Bir EEG kaydındaki elektriksel dürtüler, tepe noktaları ve çukur noktaları
olan dalgalı çizgiler gibi görünür [23]. Bu çizgiler, doktorların anormal kalıpların olup olmadığını hızlı bir
şekilde değerlendirmesini sağlar. Herhangi bir düzensizlik nöbet veya diğer beyin bozukluklarının bir
belirtisi olabilir. İşaret işleme tekniklerini kullanarak normal ve anormal bir kişinin beyin aktivitesi kolayca
ayırt edilebilir.
Normal bir EEG sinyalinin frekans aralığı 1 Hz-100 Hz'dir, ancak 100 Hz çok nadir görülür. Sinyalin
genliği ise genel olarak 10 μV - 100 μV arasındadır. EEG'nin karakteristik özellikleri, bireyin kendisi, yaşı
ve öznenin zihinsel durumu gibi birçok faktöre bağlıdır [24].
3.1.1. EEG Dalga Şekli (EEG Wave Shape)
Beyin yüzeyinde meydana gelen elektriksel aktiviteler, EEG makinesinin ekranında, voltaj olarak ölçülen
değişen frekans ve genlikteki dalga formları olarak görünür. EEG aktivitesi mikrovolt (mV) cinsinden
ölçülen sinyallerdir. Yaşadığımız andaki duruma göre beynimizde farklı şekillerde elektriksel
dalgalanmalar olur ve durumlara göre farklı frekans kalıpları oluşur. EEG sinyalleri frekans genlik ve
şekilleri bakımından sınıflandırılır. Beyin dalgası hızı Hertz (saniyedeki devir) cinsinden ölçülür ve yavaş,
orta ve hızlı dalgaları tanımlayan frekans bantlara ayrılır. Frekans aralıklarına bağlı olarak, beş tip dalga
tanımlanabilir. Sırasıyla düşük frekanstan yüksek frekansa doğru; delta (δ), teta (θ), alfa (α), beta, (β), ve
gamma (γ) şeklindedir. Bu frekans bantları tablo 1’deki gibidir.
Tablo 1. Dalgaların Frekans Aralıkları
Dalga
Delta
Teta
Alfa
Beta
Gama

Frekans
0-4 HZ
4-8 HZ
8-13 HZ
13-30 HZ
>30 HZ

EEG Sinyalleri kafanın neresinden alındığına bağlı olarak iki türe ayrılabilir vardır. Bunlar, kafa derisinden
alınan EEG sinyalleri ve kafa içinden alınan EEG sinyalleridir. Kafa derisinden alınan EEG için, kafa
derisinin üzerine iyi mekanik ve elektriksel teması olan küçük elektrotlar yerleştirilir. Kafatası içinden EEG
sinyali almak için ameliyat sırasında beyine implant edilen özel elektrotlar kullanılır. Beynin mimarisi
üniform olmaması ve korteksin fonksiyonel yapıya sahip olmasından dolayı kaydedilen EEG sinyalleri
elektrotlarının konumuna bağlı olarak değişebilir. EEG sinyalleri kayıt edilmeden önce elektrotların
yerleştirilmesine dikkat edilmelidir. Elektrotların kafa derisinin üzerine nasıl yerleştirileceği önemli bir
süreçtir, çünkü farklı türdeki aktivitelerin işlenmesinden farklı beyinsel korteks lobları sorumludur. Kafa
derisi elektrot lokalizasyonu için yaygın olarak kullanılan elektrot yerleştirme yöntemlerinden biri,
Amerikan Elektroensefalografik Topluluğu tarafından standart hale getirilmiş olan 10-20 elektrot sistemidir
[25]. Bu sistemi kullanarak, kafa derisi üzerine toplam 21 elektrot yerleştirilir. Şekil 1’de, uluslararası 1020 sistemine göre beyindeki elektrot pozisyonunu göstermektedir. Her bölge lobu tanımlamak için bir harf
ve yarım küre konumunu tanımlamak için bir sayı kullanır. F, T, C, P ve O harfleri sırasıyla Frontal,
Temporal, Central, Parietal ve Oksipital anlamına gelir. “Z” orta hatta yerleştirilen bir elektrodu ifade eder.
Çift rakamlar sağ yarım küre üzerindeki elektrot pozisyonlarını belirtirken, tek rakamlar sol yarım küre
üzerindekileri gösterir.

464

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

Şekil 1. Uluslararası 10-20 elektrot yerleştirme sistemi
3.2. Önerilen Yöntem (Proposed Method)
Müzik dinlerken EEG sinyalleri kaydedilen deneklerin, duygu durumlarının tanınması için önerilen sistem
dört adımdan oluşmaktadır. Bu işlem adımları; sırası ile veri toplama, sinyal önişleme, öznitelik çıkarma
ve sınıflandırma şeklinde yapılmaktadır. Müzik dinlenmesi sırasında beyin üzerinde oluşan elektriksel
aktiviteler, EEG sinyal okuyucu kullanılarak kafa derisi üzerinden kaydedilir. Kaydedilen EEG sinyalleri
daha sonra dış ortamdan gelen gürültülerin giderilmesi ve ham EEG verilerinin işlenebilir hale
getirilebilmesi için sinyaller ön işlemden geçirilir. EEG sinyalleri ön işleme tabi tutulduktan sonra öznitelik
çıkarılır. Son olarak, çıkarılan öznitelikler sınıflandırıcıları eğitmek ve insan duygularını tanımak için
kullanılır. Her adımın detayı aşağıdaki alt bölümlerde açıklanmıştır Önerilen yöntem şekil 2’ de verilmiştir.
EEG Kayıt

Sinyal Ön İşleme

Özellik
çıkarma

Sınıflandırma

Şekil 2. Duygu Tanıma Adımları
3.2.1. Uyaran ve Katılımcılar (Stimulus and Subjects)
16 adet sesli müzik dinletisi, EEG tabanlı duygu tanıma deneyi için harici bir uyarıcı olarak kullanılmıştır.
Tüm müzik dinletileri MP3 formatındadır ve örnekleme hızı 320 kbps'dir. Bu çalışmada kullanılan
müzikler, Türk Sanat Müziği, Türk Halk Müziği, Türk Pop ve Türk Caz Müziği olmak üzere dört türden
oluşmaktadır. Seçilen türler fark edilebilir duygular üretmektedir. Farklı kültürlere sahip toplam on
katılımcı gönüllü olarak çalışmaya katılmıştır. On sağlıklı denekten beşi erkek beşi ise kadındır. Tüm
katılımcılar 20 ila 25 yaş arasındadır ve katılımcıların herhangi bir beyin hastalığı rahatsızlığı
bulunmamaktadır ve normal işitme gücüne sahiptir. Deneyden önce, katılımcılara çalışmanın kapsamı ve
prosedürü hakkında bilgi verilmiştir.
3.2.2. EEG Veri Toplama (EEG Data Collection)
Bu çalışmada EEG sinyallerini alabilmek için EMOTIV EPOC+ kulaklığı kullanılmıştır. EMOTIV EPOC+
insan beyni araştırması için tasarlanmıştır. Bu EEG kayıt cihazı kullanımı kolay bir tasarımla, hızlı ve
profesyonel olarak yüksek kalitede beyin verilerine erişim sağlar. Bu cihazda toplam 14 kanal vardır ve 5
dakikaya kadar kayıt alabilmektedir. Cihaz 128 örnekleme frekansıyla veri alabilmektedir. Bluetooth
bağlantısı ile Matlab üzerinde hazırlanan yazılım kullanılarak ham EEG verileri kaydedilmiştir. Tüm EEG
kayıtları izole ve gürültüsüz bir odada alınmıştır. Şekil 3'de gösterildiği gibi müzik dinlerken Emotiv Epoc+
kulaklığından EEG sinyalleri kaydedilmiştir.

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

465

Şekil 3. EMOTIV EPOC
Cihazdaki elektrotlar uluslararası 10-20 sistemine göre beynin çeşitli bölgelerinde konumlandırılarak EEG
kayıtları alınmıştır. Her katılımcıya, 30 saniyelik bölümlerden oluşan toplam 16 adet müzik dinletilmiştir.
Her katılımcıya her türden birer birer dört müzik dinletilmiştir ve her müzikten sonra 10 saniye sessizlik
sağlanmıştır. Bu müzikler katılımcıya dinletilirken dinleyicinin EEG kayıtları alınmıştır ve her müzik
sonunda hissettiği duygu sorularak alınan EEG kaydı hissedilen duyguya göre etiketlenmiştir. Duygu
tanıma ve sınıflandırıcının eğitimi işlemi için manuel olarak etiketlenen duygu etiketleri kullanılmıştır.
Şekil 4’de katılımcılar için EEG veri toplama aşamasındaki genel yapı ifade edilmiştir. Kayıtlar günün
farklı saatlerinde alınmıştır. Veri seti, her sınıfta eşit sayıda kayıt olacak şekilde tasarlanmıştır. İlk deneyde
sabah saatlerinde toplam 160 kayıt, ikinci deneyde ise öğlen saatlerinde toplam 160 kayıt alınmıştır. Veri
setindeki her sınıftaki kayıt sayısını aynı olmasını sağlamak için her deneydeki 144 kayıt dikkate alınmıştır.

Şekil 4. EEG Kayıt Alma Süreci
Ayrıca bu çalışmada DEAP veri kümesi kullanılmıştır. DEAP veri seti duyguların değerlendirilmesi için
birden fazla fizyolojik sinyal içerir. 32 denekten EEG verisi toplanmıştır. EEG sinyalleri, her biri 60 saniye
süren müzik videosu gösterilerek kaydedilmiştir [26]. Daha sonra sinyaller 128 Hz'e örneklenip, bant
geçiren filtreler kullanılarak gürültü giderilmiştir. DEAP veri kümesi, Russell’in duygu modeline göre
sınıflandırılmıştır. DEAP veri kümesinde, 1-9 ölçeğinde değerlilik ve uyarılma adlı iki tür etiket vardır.
Etiketlerden 1-4 değerliliği, 5-9 ise uyarılma ölçeğini temsil eder. Derecelendirme 5'ten büyük veya ona
eşitse etiket “yüksek” olarak, 5'ten küçükse etiket “düşük” olarak ayarlanmıştır. Veri setinde toplam dört
sınıf etiket vardır: yüksek uyarılma düşük değerlik, düşük uyarılma yüksek değerlik, yüksek uyarılma
yüksek değerlik ve düşük uyarılma düşük değerlik.

466

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

3.3. EEG Sinyal Ön İşleme ve Öznitelik Çıkarma (EEG Signal Preprocessing and Feature
Extraction)
İnsan kafa derisinden kaydedilen EEG sinyalleri beyin dalgalarının, seslerin ve farklı dış gürültülerin
birleşiminden oluşur. EEG sinyalleri ile insan beyni aktivitesini araştırmak için 0Hz-50Hz bandını
kullanırız. Özellik çıkarımı ve sınıflandırma için kaliteli, gürültüsüz sinyallere sahip olmak gerekir. Gürültü
azaltmak için kaydettiğimiz sinyaller, 1.0 Hz-50 Hz arasında band geçişine sahip bir filtre kullanılarak
sinyaller analiz için uygun hale getirilmiştir.
Filtreden geçirilen sinyallerden öznitelik çıkarabilmek için ilk olarak sinyal belli uzunluktaki çerçevelere
ayrılmıştır. Sinyalindeki işaretler zamana bağlı olarak sürekli değişmektedir. Bu yüzden sinyallerinin
karakteristik özelliklerini belirleyen parametreler çok küçük zaman diliminde kararlı kalmaktadır. Bu
çalışmada EEG sinyalleri 25 ms uzunluklarda çerçevelere bölünmüştür. Ayrıca her çerçeve kendinden bir
önceki çerçevenin bir kısmını örtecek şekildedir. Çerçevelerinin birbirini örtmesinin amacı çerçeveler arası
geçişin yumuşak olmasını sağlamaktır [27]. Eğer bu örtüşme olmasaydı birbirini izleyen iki çerçeveyi
izlediğimiz zaman veya bu çerçevedeki sinyalleri işlenirken çerçeveler arasındaki özellik değişimi kesintiye
veya sıçramaya neden olabilecekti. Ayrıca komşu çerçevelerin parametre değerlerinin farkı da daha yüksek
olacaktı. Bu nedenlerden dolayı çerçeveler birbirini örtecek şekildedir. Bu çalışmada çerçevelerin örtüşme
oranı bir çerçevenin %50 si kadar olarak seçilmiştir.
Bir sinyale çerçeveleme uygulandıktan sonra pencereleme işlemi uygulanır. Amaç her bir çerçevenin
başında sonunda oluşan süreksizliği önlemektir. Her çerçevedeki ses sinyalinin orta bölgesi güçlendirilir
uç bölgeler ise zayıflatılır. Bu çalışmada yaygın olarak kullanılan “Hamming penceresi” kullanılmıştır.
“Hamming Pencereleme” sayesinde sinyalin merkez bölgesi daha belirgin hale gelir. Uç kısımlarda sıfıra
yaklaştırılır. Hamming Penceresi sinyalin uç bölgelerdeki istenmeyen radyasyonları en aza indir [28].
Ayrıca sinyali Fourier dönüşümüne uygun hale getiren fonksiyondur. Hamming fonksiyonun çalışma
mantığı hamming penceresi ile çerçevelenmiş ses sinyali çarpılır ve sonunda pencerelenmiş sinyal elde
edilir. Hamming pencere formülü denklem 1’de verilmiştir.
𝑛

𝑤[𝑛] = 0.54 − 0.46 ∗ cos (2 ∗ 𝜋 ∗ ) , 𝑁: 𝑃𝑒𝑛𝑐𝑒𝑟𝑒 𝑢𝑧𝑢𝑛𝑙𝑢ğ𝑢
𝑁

(1)

𝑛: 0, 1, 2 … … 𝑁 − 1

Hamming penceresinden sonra sinyale Fourier dönüşümü uygulanmıştır. Sinyal işlemede dönüşüm bir
sinyalin başka parametrelerle ifade edilmesi anlamına gelir. Fourier dönüşümü bir sinyalin zaman
domaininden frekans domainine dönüşümünü sağlar. Fourier dönüşümü sinyal işlemede sinyalin içindeki
bilgileri elde etmek için çok önemli bir yöntemdir. Sinyali oluşturan bileşenleri (frekans, genlik, faz)
kosinüs ve sinüs fonksiyonlarının toplamı olarak ifade etmeye yarar. Bu çalışmada Hızlı Fourier
Dönüşümü kullanılmıştır. Bu adımda N örnekten oluşan her çerçeve Hızlı Fourier dönüşümü uygulanarak
zaman domainden frekans domainine geçirilmiştir. N örnekli bir küme denklem 2’deki gibi tanımlanır. Son
aşamada N örnekten oluşan her çerçeve üzerinden istatistiksel hesaplamalar yapılmıştır.
−2𝜋𝑗𝑘𝑛 / 𝑁
𝑋𝑛 = ∑𝑁−1
,
𝑘=0 𝑥𝑘 𝑒

n = 0, 1, 2, … . . . , N − 1

(2)

Her çerçevenin standart sapması, maksimum değeri, minimum değeri ortalaması ve kare ortalamalarının
karekökü hesaplanmıştır.
3.4. Yapay Sinir Ağları (Artificial Neural Networks)
YSA, insan beyninin akıllı veri işleme yeteneğinden ilham alınarak oluşturulmuştur. YSA beyindeki
nöronların birbirleri ile etkileşimini taklit ederek motive edilmiştir [29]. Nöronlardan oluşan, ilişkili nöron
bağlantıları içeren ve matematiksel bir model olan YSA modeli şekil 5‘te gösterilmiştir. Ağ oluşumunda

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

467

kullanılan nöronlar arasında oluşturulan bağlantılar ağırlık denen sayısal değerler ile ilişkilendirilir. Her
ağırlık, ağda transfer edilen ve sinyal ile çarpılan belirli bir değere sahiptir [30], [31]. YSA’lar, problem
hakkında bilgi sahibi olmaksızın girdi ve çıktı verileri arasındaki doğrusal olmayan ilişkileri tanımak için
eğitilebilirler. Eğitimden sonra YSA’nın çalışma süresi son derece hızlıdır, çünkü yalnızca birkaç basit,
birbirine bağlı işlem birimi içermektedir. YSA’ların model tanıma, genelleme ve enterpolasyon yapabilme
özellikleri vardır. Bu nedenle eğitilen ağa bilinmeyen bir girdi uygulandığında uygun bir çıktı üretebilirler.
Deterministik hata ve sistem modelleri yerine yalnızca simüle edilmiş eğitim verileri gerektirirler [32].

g(w1 ,b1 ,x)

1


X



g(wi ,bi ,x)



i



Y

g(wN ,bN ,x)

N
Şekil 5: Yapay Sinir Ağları
3.5. Destek Vektör Makineleri (Support Vector Machines)
DVM Vapnik’in istatistiksel öğrenme teorisinden nemalanan lineer ve lineer olmayan çizgiler ile
ayrıştırılabilen en iyi makine öğrenme tekniklerinden biridir [33]. Bu teknik hem sınıflandırma hem de
regresyon analizi için kullanılabilir ve küçük örneklerin sınıflandırılması için hesaplamalı bir öğrenme
yöntemidir [34]. DVM de öncelikle girdi verileri daha yüksek boyutlu bir alana alınır ve bu alanda iki sınıf
arasında bir en uygun ayırıcı hiper düzlem oluşturulur [35]. DVM ile öncelikle bir düzlemde bulunan
sınıflandırılacak veri grupları arasında bir sınır çizgisi belirlenir. Bu sınırın belirleneceği yer ise bu veri
gruplarının üyelerine en uzak bir yer olmalıdır. Basit bir şekilde tanımlamak gerekirse DVM bu sınırın nasıl
çizileceğini belirler. Algoritmik olarak DVM, yapısal risk minimizasyonuna dayalı kısıtlanmış bir kuadratik
optimizasyon problemini çözerek veri kümeleri arasında optimal ayırma hiper düzlemi (f (x) = 0)
oluşturmaktadır [36].
3.6. K En Yakın Komşu (K Nearest Neighbor)
Büyük ölçekli bir veri kümesinden, bir sorgu örneğine en çok benzer bir veri alt kümesi bulmayı amaçlayan
KNN algoritmaları; boyut indirgeme, model sınıflama ve görüntü alımı gibi geniş kapsamlı uygulamalarda
temel bir bileşen olarak kullanılmaktadır [37],[38]. KNN, bir veri kümesindeki örneklerin genellikle benzer
özelliklere sahip diğer örneklerin yakınında bulunacağı ilkesine dayanan, örnek tabanlı bir öğrenme
algoritmasıdır [39]. Bu algoritma ile yeni bir nokta verisini sınıflandırmak için bu nokta verisine en yakın
k tane eğitim noktası bulunur. Sınıflandırma işlemi, komşularının oy çoğunluğuyla yapılır; sınıflandırma
işlemi yapılacak bir eleman, bir uzaklık fonksiyonuyla ölçülen en yakın komşular arasında en yakın olan
sınıfa dağıtılır [40]. KNN algoritmasının formülü denklem 3’te gösterilmiştir.

𝑥(𝑥, 𝑦) = √∑𝑗=1 𝑤𝑗 (𝑥𝑗 − 𝑧𝑗 )2

(3)

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

468

Denklem 3’te; wj- j boyutuyla ilişkilendirilen ağırlıktır. Her boyut için ağırlık seçilir ve karesel uzaklık
fonksiyonu belirtilir. Şekil 6 ‘da Test örneğinin sınıflandırılmasında, k= 1 veya k = 3 olarak seçildiğinde
pozitif sınıfta, k = 2 olarak seçildiğinde negatif sınıfta olduğu görülmektedir.

k=3
k=2
k=1
Test Örnek

Şekil 6: K-NN Diyagramı
4. DENEYSEL UYGULAMALAR (EXPERİMENTAL APPLİCATİONS)
4.1. Deneysel Sonuçlar (Experimental Results)
Bu çalışmada sınıflandırma işlemi için, YSA, DVM ve KNN kullanılarak 5-kat çapraz doğrulama
uygulanmıştır. DVM'ler polinom ve radyal temelli fonksiyon çekirdekleri kullanılarak eğitilmiştir. YSA,
iki farklı çekirdekle eğitilmiş DVM'ler ve KNN’den elde edilen sonuçlar karşılaştırılmıştır. Önerilen
yöntemin başarım kriterleri doğruluk, kesinlik, hassasiyet ve F-skoru oranlarına dayalı olarak yapılmıştır.
Sınıflandırma problemlerindeki değerlendirme ölçütleri, karışıklık matrisi adı verilen her sınıf için doğru
ve yanlış sınıflandırılmış örnek sayılarının bulunduğu bir matris kullanılarak yapılır. YP, YN, DP ve DN
kavramları aşağıda belirtildiği gibi tanımlanabilir:
•
•
•
•

Yanlış pozitifler (YP): negatif sınıftan olan, pozitif olarak tahmin edilen örnekler.
Yanlış negatifler (YN): gerçek sınıfı pozitif olan negatif olarak tahmin edilen örnekler.
Doğru pozitifler (DP): pozitif sınıfa ait doğru tahmin edilen örnekler.
Doğru negatifler (DN): negatif sınıfa ait olarak doğru tahmin edilen örnekler.
|𝐷𝑁|+|𝐷𝑃|

Doğruluk = |𝑌𝑁|+|𝑌𝑃|+|𝐷𝑁|+|𝐷𝑃|

(4)

Hassasiyet ölçümü, ikili problemlerde her bir sınıf için sınıflandırıcının etkinliğini değerlendirir. Gerçek
pozitif oran olarak bilinen hassasiyet, pozitif sınıfa ait tahmin edilen verilerin gerçek pozitif verilerine
oranıdır. Hassasiyet ölçümü denklem 5’de verilmiştir.
|𝐷𝑃|

Hassasiyet = |𝑌𝑁|+|𝐷𝑃|

(5)

Kesinlik (P), pozitif bir tahminin doğru olma olasılığını tahmin eden bir ölçüdür. Kesinlik ölçümü denklem
6’de verilmiştir.
|𝐷𝑃|

Kesinlik(P) = |𝐷𝑃|+|𝑌𝑃|

(6)

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

469

F-skoru, pozitif kestirim oranı ve duyarlılık ölçülerinin uyumlu bir ortalaması olup denklem 7’de
gösterildiği gibi hesaplanır.
F − skor =

2∗|𝐷𝑃|

(7)

2∗|𝐷𝑃|+|𝑌𝑃|+|𝑌𝑁|

Yukarıda verilen denklemler genellikle performans değerlendirme ölçütlerinin hesaplanması için
kullanılmaktadır. Ayrıca bu hesaplama ölçüleri ikili sınıfa ait veri setlerinde kullanılmak amacıyla
geliştirilmiştir. Ancak ikiden fazla sınıfa ait sınıflandırma problemlerinin çözümü için genel olarak bu
yöntemlerin genelleştirilmiş halleri kullanılmaktadır. Modelin performansını ölçmek ve deneklerin günlük
ruh hallerinin kayıtlar üzerinde etkileri için üç farklı deney yapılmıştır. İlk deneyde kayıtların hepsi farklı
günlerin sabah saatlerinde alınmıştır. İkinci deneyde kayıtlar farklı günlerin öğlen saatlerinde alınmıştır.
Üçüncün deneyde ise sabah ve öğlen saatlerinde alınan kayıtlar birleştirilmiştir. Hazırlamış olduğumuz
veri seti kullanarak gerçekleştirmiş olduğumuz deneylerden elde edilen sınıflandırma sonuçları Tablo 2,
Tablo 3 ve Tablo 4’de verilmiştir. Ayrıca deneylerden elde edilen sınıflandırma sonuçlarının
karşılaştırılması şekil 10’da verilmiştir. Önerilen yöntemin uygulaması, İ7 2.50GHz işlemci, 12GB hafıza
ve NVIDIA 940M GPU donanım özelliklerine sahip makine üzerinde yapılmıştır. Uygulama için gerekli
yazılım kodları matlab2018a kullanılarak hazırlanmıştır.
Tablo 2’de deney 1 (sabah saatlerindeki kayıtlar)’den elde edilen sınıflandırma sonuçları verilmiştir. Ayrıca
deney1’den elde edilen en iyi sınıflandırma sonucuna ait karışıklık matrisi şekil 7’de verilmiştir.
Tablo 2. Deney 1’den Elde Edilen Sınıflandırma Sonuçları

Model

Verinin Eğitim ve
Test için Farklı
oranlarda Bölünmesi

Doğruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

74,32
78,44
71,91
75,63
70,14
73,26
65,77
68,12

75,80
78,30
72,59
75,91
70,65
72,71
67,70
70,68

74,31
78,47
71,53
75,70
70,14
72,92
65,97
68,06

74,45
78,33
71,41
75,58
69,94
72,64
65,98
68,40

Şekil 7: Deney 1’den elde edilen en iyi sınıflandırma sonucuna ait karışıklık matrisi
Tablo 3’de deney 2 (öğlen saatlerindeki kayıtlar)’den elde edilen sınıflandırma sonuçları verilmiştir. Ayrıca
Deney 2’den elde edilen en iyi sınıflandırma sonucuna ait karışıklık matrisi şekil 8’de verilmiştir.

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

470

Tablo 3. Deney 2’den Elde Edilen Sınıflandırma Sonuçları

Model

Verinin Eğitim ve
Test için Farklı
oranlarda Bölünmesi

Doğruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

71,62
73,52
69,54
72,22
71,36
72,73
66,15
67,87

72,27
73,32
69,96
72,37
72,84
73,09
65,17
69,37

71,53
73,61
69,45
72,22
71,53
72,92
65,98
68,06

71,39
73,35
69,25
71,93
71,62
72,59
65,27
68,00

Şekil 8: Deney 2’den elde edilen en iyi sınıflandırma sonucuna ait karışıklık matrisi
Tablo 4’de deney 3 (sabah + öğlen saatlerinde alınan kayıtlar)’den elde edilen sınıflandırma sonuçları
verilmiştir. Ayrıca Deney 3’den elde edilen en iyi sınıflandırma sonucuna ait karışıklık matrisi şekil 9’da
verilmiştir.
Tablo 4. Deney 3’den Elde Edilen Sınıflandırma Sonuçları

Model

Verinin Eğitim ve
Test için Farklı
oranlarda Bölünmesi

Doğruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

77,34
79,42
75,91
78,65
73,13
77,23
68,76
69,14

77,53
79,53
76,67
75,86
73,53
77,95
69,25
71,26

77,43
79,51
76,04
91,67
72,92
77,08
68,75
69,10

77,29
79,12
76,18
83,02
73,12
77,13
68,58
69,08

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

471

Şekil 9: Deney 3’den elde edilen en iyi sınıflandırma sonucuna ait karışıklık matrisi
Tablo 2, Tablo 3 ve Tablo 4’deki sonuçlara göre, eğitim verisinin arttırılması ile birlikte sınıflandırma
doğruluğu da artmıştır. Bu sonuçlardan yola çıkarak, deneylerde kullanılan örnek sayısının arttırılması
modelin doğruluğunu da arttırmıştır. Ayrıca Tablo 2’deki veriler Tablo 3’deki veriler ile kıyaslandığında
sabah saatlerinde alınan kayıtlardan daha fazla sınıflandırma başarımı elde edilmiştir. Bu durum farklı
saatlerdeki ruh hallerinin sınıflandırma üzerindeki etkisini göstermektedir.

Şekil 10: Deneylerden Elde Edilen En İyi Sınıflandırma Sonuçlarının Karşılaştırılması
Tablo 5’de DEAP veri setinden elde edilen sınıflandırma sonuçları verilmiştir. Ayrıca bu veri kümesinden
elde edilen sonuçların önceki çalışmalarla karşılaştırılması tablo 6’da verilmiştir.
Tablo 5. DEAP veri setinden Elde Edilen Sınıflandırma Sonuçları

Model

Verinin Eğitim ve
Test için Farklı
oranlarda Bölünmesi

Doğruluk
%

Kesinlik
%

Hassasiyet
%

F-skoru
%

YSA
YSA
DVM (Polinom)
DVM (Polinom)
DVM (RBF)
DVM (RBF)
KNN
KNN

%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20
%70 - %30
%80 - %20

69,23
70,12
67,16
68,24
64,41
66,32
64,23
65,36

69,58
70,46
67,42
68,67
64,62
66,57
64,61
65,61

69,42
70,24
67,35
68,42
64,51
66,46
64,45
65,52

69,12
70,02
67,12
68,11
64,24
66,15
64,07
65,14

472

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

Tablo 6. DEAP Veri seti için Performans Karşılaştırılması
Metod
[41]
[42]
[43]
Önerilen Yöntem

Sınıflandırıcı
CapsNet
Random Forest
DVM
YSA

Doğruluk %
68,20
72,07
60,50
70,12

Tablo 6'te görüldüğü gibi, önerilen yöntemin literatürde kullanılan diğer iki yöntemden daha iyi performans
gösterdiği gözlenmektedir. Bu bilgiler ışığında, önerilen mimarinin insan duygularının EEG ile
tanınmasında etkili bir şekilde kullanılabileceği görülmektedir.
5. SONUÇLAR (RESULTS)
Bu çalışmada, bazı sinyal işleme metotları ve makine öğrenmesi yöntemleri kullanılarak müzik dinlerken
EEG sinyalleri üzerinden duygu tanıma için yeni bir yöntem sunulmuştur. Sessiz ve karanlık ortamda 10
kişinin katılım sağladığı bir deney yapılmıştır. Farklı müzik türlerinden seçilen şarkılar eşit örneklem
frekansına getirilerek deneye katılan kişilere dinletilmiştir. Deneklere müzik dinletilirken aynı anda bu
deneklerin EEG sinyalleri EEG kayıt cihazı ile bilgisayar ortamına kaydedilmiştir. Duygular belirli bir süre
içerisinde anlamlılık kazandığı için her EEG kaydı 30 saniye olarak alınmıştır. Dinletilen her şarkının
sonunda deneğin hissettiği duygu kendisine sorulmuş ve deneğe ait kaydedilen EEG sinyalleri
etiketlenmiştir. Duygu algısının öznel olmasından dolayı dört adet duygu etiketi kullanılmıştır. Bu etiketler
gergin, hüzünlü, mutlu veya rahatlatıcı duygu olarak tanımlanmıştır. Etiketlenerek kaydedilen EEG
sinyalleri, öncelikle bant geçiren filtreden geçirilmiştir. Daha sonra filtrelenmiş sinyallerden öznitelik
çıkarılarak sınıflandırma işlemi yapılmıştır ve sonuçlar karşılaştırılmıştır. Sınıflandırıcı olarak YSA, DVM
ve KNN kullanılmıştır. En iyi sınıflandırma başarısı ortalama olarak %79,42 olarak YSA ile kendi veri
setimiz üzerinden elde edilmiştir. Ayrıca DEAP veri seti kullanılarak %70,12 doğruluk elde edilmiştir.
Sonuçlara göre, önerilen yöntemin insan duygularını tanıma problemi için kullanılabileceği belirtilmiştir.
Gelecekti çalışmalar için uyaran olarak müzik verileri kullanılarak EEG veri setleri hazırlanması ve derin
öğrenme modellerinin insan duygularının tanınma probleminde kullanılması önerilmektedir.
KAYNAKLAR (REFERENCES)
[1]

C. C. Pratt, Music as the language of emotion. Oxford, England: The Library of Congress, 1952.

[2]

R.-F. Day, C.-H. Lin, W.-H. Huang, and S.-H. Chuang, “Effects of music tempo and task difficulty on multiattribute decision-making: An eye-tracking approach,” Comput. Human Behav., vol. 25, no. 1, pp. 130–143,
Jan. 2009, doi: 10.1016/J.CHB.2008.08.001.

[3]

G. Varotto, P. Fazio, D. R. Sebastiano, G. Avanzini, S. Franceschetti, and F. Panzica, “Music and emotion:
An EEG connectivity study in patients with disorders of consciousness,” in 2012 Annual International
Conference of the IEEE Engineering in Medicine and Biology Society, 2012, pp. 5206–5209, doi:
10.1109/EMBC.2012.6347167.

[4]

D. HURON, “Is Music an Evolutionary Adaptation?,” Ann. N. Y. Acad. Sci., vol. 930, no. 1, pp. 43–61, 2001,
doi: 10.1111/j.1749-6632.2001.tb05724.x.

[5]

I. Peretz and R. J. Zatorre, “Brain Organization for Music Processing,” Annu. Rev. Psychol., vol. 56, no. 1,
pp. 89–114, 2005, doi: 10.1146/annurev.psych.56.091103.070225.

[6]

S. M. Alarcão and M. J. Fonseca, “Emotions Recognition Using EEG Signals: A Survey,” IEEE Trans. Affect.
Comput., vol. 10, no. 3, pp. 374–393, 2019, doi: 10.1109/TAFFC.2017.2714671.

[7]

P. J. Lang, “The emotion probe: Studies of motivation and attention.,” American Psychologist, vol. 50, no. 5.
American Psychological Association, US, pp. 372–385, 1995, doi: 10.1037/0003-066X.50.5.372.

[8]

R. W. Picard, Affective Computing. The MIT Press, 2000.

[9]

L. Shu et al., “A Review of Emotion Recognition Using Physiological Signals,” Sensors (Basel)., vol. 18, no.
7, p. 2074, Jun. 2018, doi: 10.3390/s18072074.

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

473

[10]

A. M. Bhatti, M. Majid, S. M. Anwar, and B. Khan, “Human emotion recognition and analysis in response to
audio music using brain signals,” Comput. Human Behav., vol. 65, pp. 267–275, Dec. 2016, doi:
10.1016/J.CHB.2016.08.029.

[11]

F. Zhang, H. Meng, and M. Li, “Emotion extraction and recognition from music,” 2016 12th International
Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD). IEEE, 2016,
doi: 10.1109/fskd.2016.7603438.

[12]

A. Goshvarpour and A. Goshvarpour, “EEG spectral powers and source localization in depressing, sad, and
fun music videos focusing on gender differences,” Cogn. Neurodyn., vol. 13, no. 2, pp. 161–173, 2018, doi:
10.1007/s11571-018-9516-y.

[13]

A. M. Bhatti, M. Majid, S. M. Anwar, and B. Khan, “Human emotion recognition and analysis in response to
audio music using brain signals,” Comput. Human Behav., vol. 65, pp. 267–275, Dec. 2016, doi:
10.1016/J.CHB.2016.08.029.

[14]

C. Shahnaz, Shoaib-Bin-Masud, and S. M. S. Hasan, “Emotion recognition based on wavelet analysis of
Empirical Mode Decomposed EEG signals responsive to music videos,” 2016 IEEE Region 10 Conference
(TENCON). IEEE, 2016, doi: 10.1109/tencon.2016.7848034.

[15]

Y. Liu et al., “What Strikes the Strings of Your Heart?–Multi-Label Dimensionality Reduction for Music
Emotion Analysis via Brain Imaging,” IEEE Trans. Auton. Ment. Dev., vol. 7, no. 3, pp. 176–188, 2015, doi:
10.1109/tamd.2015.2429580.

[16]

R. Nawaz, H. Nisar, and Y. V. Voon, “The Effect of Music on Human Brain; Frequency Domain and Time
Series Analysis Using Electroencephalogram,” IEEE Access, vol. 6, pp. 45191–45205, 2018, doi:
10.1109/access.2018.2855194.

[17]

J.-L. Hsu, Y.-L. Zhen, T.-C. Lin, and Y.-S. Chiu, “Affective content analysis of music emotion through EEG,”
Multimed. Syst., vol. 24, no. 2, pp. 195–210, 2017, doi: 10.1007/s00530-017-0542-0.

[18]

G. Balasubramanian, A. Kanagasabai, J. Mohan, and N. P. G. Seshadri, “Music induced emotion using
wavelet packet decomposition—An EEG study,” Biomed. Signal Process. Control, vol. 42, pp. 115–128,
2018, doi: 10.1016/j.bspc.2018.01.015.

[19]

M. Yanagimoto and C. Sugimoto, “Recognition of persisting emotional valence from EEG using
convolutional neural networks,” 2016 IEEE 9th International Workshop on Computational Intelligence and
Applications (IWCIA). IEEE, 2016, doi: 10.1109/iwcia.2016.7805744.

[20]

C.-Y. Liao, R.-C. Chen, and S.-K. Tai, “Emotion stress detection using EEG signal and deep learning
technologies,” 2018 IEEE International Conference on Applied System Invention (ICASI). IEEE, 2018, doi:
10.1109/icasi.2018.8394414.

[21]

S. Vaid, P. Singh, and C. Kaur, “EEG Signal Analysis for BCI Interface: A Review,” 2015 Fifth International
Conference on Advanced Computing & Communication Technologies. IEEE, 2015, doi:
10.1109/acct.2015.72.

[22]

Siuly, “ANALYSIS AND CLASSIFICATION OF EEG SIGNALS,” UNIVERSITY OF SOUTHERN
QUEENSLAND, 2012.

[23]

B. Farnsworth, “What is EEG
https://imotions.com/blog/what-is-eeg.

[24]

S. D. Puthankattil, P. Joseph, U. R. Acharya, and C. Lim, “EEG signal analysis: a survey,” J. Med. Syst., vol.
34, pp. 195–212, Apr. 2010, doi: 10.1007/s10916-008-9231-z.

[25]

H. . Jasper, “The Ten-Twenty Electrode System of the International Federation,” Electroencephalogr. Clin.
Neurophysiol., vol. 10, pp. 371–375, 1958.

[26]

S. Koelstra et al., “DEAP: A Database for Emotion Analysis ;Using Physiological Signals,” IEEE Trans.
Affect. Comput., vol. 3, no. 1, pp. 18–31, 2012, doi: 10.1109/T-AFFC.2011.15.

[27]

B. S. Atal, “Automatic recognition of speakers from their voices,” Proc. IEEE, vol. 64, no. 4, pp. 460–475,
1976, doi: 10.1109/proc.1976.10155.

[28]

S. Gupta, J. Jaafar, W. F. Wan Ahmad, and A. Bansal, “Feature Extraction Using Mfcc,” Signal Image

(Electroencephalography)

and

How

Does

it

Work?”

474

Mehmet Bilal ER, Harun ÇİĞ/ GU J Sci, Part C, 8(2):458-474 (2020)

Process. An Int. J., vol. 4, pp. 101–108, Aug. 2013, doi: 10.5121/sipij.2013.4408.
[29]

S. I.-J. Chien, Y. Ding, and C. Wei, “Dynamic Bus Arrival Time Prediction with Artificial Neural Networks,”
J. Transp. Eng., vol. 128, no. 5, pp. 429–438, 2002, doi: 10.1061/(asce)0733-947x(2002)128:5(429).

[30]

S. M. J. Pappu and S. N. Gummadi, “Artificial neural network and regression coupled genetic algorithm to
optimize parameters for enhanced xylitol production by Debaryomyces nepalensis in bioreactor,” Biochem.
Eng. J., vol. 120, pp. 136–145, 2017, doi: 10.1016/j.bej.2017.01.010.

[31]

Q. Yang, S. Le Blond, R. Aggarwal, Y. Wang, and J. Li, “New ANN method for multi-terminal HVDC
protection relaying,” Electr. Power Syst. Res., vol. 148, pp. 192–201, 2017, doi: 10.1016/j.epsr.2017.03.024.

[32]

D. Niebur and A. J. Germond, “Power flow classification for static security assessment,” Proceedings of the
First International Forum on Applications of Neural Networks to Power Systems. IEEE, doi:
10.1109/ann.1991.213502.

[33]

“Support Vector Machines, 1992; Boser, Guyon, Vapnik,” in SpringerReference, Springer-Verlag.

[34]

A. Widodo and B.-S. Yang, “Support vector machine in machine condition monitoring and fault diagnosis,”
Mech. Syst. Signal Process., vol. 21, no. 6, pp. 2560–2574, 2007, doi: 10.1016/j.ymssp.2006.12.007.

[35]

E. Kabir, Siuly, and Y. Zhang, “Epileptic seizure detection from EEG signals using logistic model trees,”
Brain Informatics, vol. 3, no. 2, pp. 93–100, 2016, doi: 10.1007/s40708-015-0030-2.

[36]

B. Schölkopf and A. J. Smola, Smola, A.: Learning with Kernels - Support Vector Machines, Regularization,
Optimization and Beyond. MIT Press, Cambridge, MA, vol. 98. 2001.

[37]

Y. Zhang, X. Ji, and S. Zhang, “An approach to EEG-based emotion recognition using combined feature
extraction method,” Neurosci. Lett., vol. 633, pp. 152–157, 2016, doi: 10.1016/j.neulet.2016.09.037.

[38]

H. Jégou, M. Douze, and C. Schmid, “Product Quantization for Nearest Neighbor Search,” IEEE Trans.
Pattern Anal. Mach. Intell., vol. 33, no. 1, pp. 117–128, 2011, doi: 10.1109/tpami.2010.57.

[39]

T. Cover and P. Hart, “Nearest neighbor pattern classification,” IEEE Trans. Inf. Theory, vol. 13, no. 1, pp.
21–27, 1967, doi: 10.1109/tit.1967.1053964.

[40]

C. Li et al., “Using the K-Nearest Neighbor Algorithm for the Classification of Lymph Node Metastasis in
Gastric Cancer,” Comput. Math. Methods Med., vol. 2012, pp. 1–11, 2012, doi: 10.1155/2012/876545.

[41]

H. Chao, L. Dong, Y. Liu, and B. Lu, “Emotion Recognition from Multiband EEG Signals Using CapsNet,”
Sensors, vol. 19, no. 9, p. 2212, 2019, doi: 10.3390/s19092212.

[42]

V. Gupta, M. D. Chopda, and R. B. Pachori, “Cross-Subject Emotion Recognition Using Flexible Analytic
Wavelet Transform From EEG Signals,” IEEE Sens. J., vol. 19, no. 6, pp. 2266–2274, 2019, doi:
10.1109/jsen.2018.2883497.

[43]

X. Li, D. Song, P. Zhang, Y. Zhang, Y. Hou, and B. Hu, “Exploring EEG Features in Cross-Subject Emotion
Recognition,” Front. Neurosci., vol. 12, 2018, doi: 10.3389/fnins.2018.00162.

