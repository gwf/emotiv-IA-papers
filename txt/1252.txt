International Journal of Computer Applications (0975 – 8887)
Volume 180 – No.20, February 2018

A Survey on Emotion Recognition from EEG Signals for
Autism Spectrum Disorder
N. Mohanapriya
Assistant Professor,
Department of Computer
Science and Engineering,
Vivekanandha College of
Engineering for Women,
Namakkal, Tamilnadu, India

L. Malathi, PhD
Associate Professor
Department of Computer
Science and Engineering,
Vivekanandha College of
Engineering for Women,
Namakkal, Tamilnadu, India

B. Revathi
PG Scholar,
Department of Computer
Science and Engineering,
Vivekanandha College of
Engineering for Women,
Namakkal, Tamilnadu, India

ABSTRACT

2. LITERATURE REVIEW

Children with Autism Spectrum Disorder (ASD) cannot
express their emotions explicitly; this makes it difficult for the
parents and caretakers associated with these children to
understand the child’s behavior, leading to a major setback in
the child’s early developmental stages. To identify the autism
for child initial stages can help early diagnosis. Delayed
detection of child autism leads to incurable. This paper
analysis the existing works on detection of autism spectrum
disorder from EEG signal. Various filtering technique and
classification are presented. The experiment for were
conducted for support vector machine (SVM), k-nearest
neighbor (KNN), linear discriminant analysis (LDA), deep
learning, Naive Bayes, Random Forest, deep-learning
classification algorithms. Here the deep learning algorithm
gives better results for autism recognition with the emotions
such as happy, calm, anger and scared. As the no of medical
records increases the conventional techniques is not suitable
for handle large number data.

In [1] authors Niranjana Krupa, Karthik Anantharam, Manoj
Sanker, Sameer Datta and John Vijay Sagar in this paper
“Recognition of emotions in autistic children using
physiological signals” The protocols used for acquiring
signals from the autistic children and details of the total
number of samples recorded are explained. A systematic and
an efficient protocol were followed during the data acquisition
phase. Only the children in the age group of 3 to 12 were
considered for data acquisition. The samples from Autistic
children needed for the research were acquired at the
Department of Child and Adolescent Psychiatry (CAP) at the
National Institute of Mental Health and Neuro Sciences
(NIMHANS), Bangalore, India and Academy for Severe
Handicaps and Autism (ASHA), Bangalore, India. The initial
pilot study was carried out at SHA. After the successful
completion of our pilot study we received an approval by the
Ethical Review Board of NIMHANS to carry out the
proposed study at NIMHANS for the duration of six months.
Samples from control subjects were recorded from children
who belong to the same age group as those of children with
Autism. The whole data acquisition process has been carried
out only after obtaining informed consent

Keywords
EEG Signal, Emotion Recognition, Autism Spectrum
Disorder, Deep Learning, classification

1. INTRODUCTION
Autism is a neuron developmental disorder characterized by
impaired social interaction, impaired verbal and non-verbal
communication, and restricted and repetitive behavior. Parents
usually notice signs in the first two years of their child’s life.
These signs often develop gradually, though some children
with autism reach their developmental milestones at a normal
pace and then regress. The diagnostic criteria require that
symptoms become apparent in early childhood, typically
before age three.
Emotion plays an important role in our daily life and work. In
this paper focused on emotion recognition from human brain
activity
and
measured
by
EEG
signals.
Electroencephalography (EEG) is an electrophysiological
monitoring method to record electrical activity of the brain.
An emotion is a mental and physiological state associated
with a wide variety of feelings, thoughts, and behavior. An
emotion is a subjective experience which makes studying
emotions one of the most confused and still open fields of
research in psychology. Deep learning is part of a broader
family of machine learning methods based on learning data
representations, as proposed to task-specific algorithms.
Learning can be supervised, partially supervised or
unsupervised.

A wearable wristband for acquire physiological signal and an
algorithm, using a support vector machine (SVM) classifier,
that will calculate emotional states such as neutral, happy &
interest of children with autism. A support vector machine
classifier wires the recognition of the three emotions on
neutral, happy and interest in children among autism.
Determining the particular emotional status from the
physiological answer is a classification problem somewhere
the attribute are the physiological features extract from the
physiological signals mention above and the goal function is
the particular emotional status being qualified. This paper
discusses a non-invasive, safe method to be aware of and map
emotions in children through Autism. Robust systems
comprise of a wearable wristband embedded with sensors to
acquire data and a classification algorithm to recognize
emotions was considered and developed successfully, with
accuracy of good in later age children, and inefficient for less
than three years child.
In [2] authors K. G. Smitha, A. P. Vinod in this paper “Facial
emotion recognition system for autistic children: a feasible
study based on FPGA implementation” Children through
autism spectrum disorder have complexity in understanding
the emotional and mental state starting the facial expression of
the people they interact. The inability to recognize other
people’s emotion wills setback their interpersonal

32

International Journal of Computer Applications (0975 – 8887)
Volume 180 – No.20, February 2018
communication. The portability of the system resolve makes
positive ease of use and real-time emotion recognition and
that determination help for direct feedback while
communicate with caretaker. Principal component analysis
(PCA) has been recognized as the least complex quality
extraction algorithm to be implementing in hardware. In this
paper, we present an in depth study of the performance of
serial and parallel implementation of PCA in order to identify
the most possible method for recognition of a portable
emotion detector for autism children. In this paper, we have
compare two hardware-efficient implementations. Jacobi’s
iteration which is the parallel implementation is completed
hardware efficient by calculating only the diagonal and upper
triangular matrix by exploit the symmetry property of the
covariance matrix. We have compared the PCA of the two
future emotion detectors along with the implementation
existing in the same word length of 8 bits. In this paper, we
provide a evaluation between serial and parallel method of
principal component analysis method in order to realize which
among them will be the best method for recognition of a
moveable emotion detector for autism children.

selecting the most suitable features for the chosen network
architecture. It is used to several neural networks techniques
and Doesn’t work well for images and speech signals.

In [3] authors Felix Albu, Daniela Hagiescu, Liviu Vladutu,
Mihaela-Alexandra Puica in this paper “neural network
approaches for children’s emotion Recognition in intelligent
learning applications” The feature vector is formed with the
following parameters the short term energy, the zero-crossing
rate, the spectral roll-off, spectral centroid and 13 Mel
Frequency Costrel Coefficients. The first element is the short
term energy. This parameter is computed for each frame of 10
ms of speech. It is widely used for silence periods detection
and audio classes discrimination. The energy of voiced frames
is higher than that of unvoiced frames. The spectral roll-off is
a measure of the spectral shape and it is defined as the
frequency below which 80% of the magnitude distribution is
concentrated. The Dartmouth Database of Children Faces,
which contains thousands of images taken for 100 children
(50 boys and 50 girls) ages 5 to 15 years old showing 8 facial
expressions: anger, disgust, fear, happy, neutral, pleased, sad
and surprise. The first step is to detect the landmarks on
children’s faces, thus distinguishing the elements of interest
on the face: eyes, eyebrows and mouth. By muscle
contraction, shape of these elements and distance between
them changes for different emotional states. The differences
are small, there can be seen that a negative expression has a
smaller mouth and closer eyebrows and a positive expression
has a wider mouth and eyebrows are spread apart

In [5] authors Keiran M. Rump, Joyce L. Giovannelli, Nancy
J. Minshew , Mark S. Strauss in this paper “The Development
of Emotion Recognition in Individuals With Autism” Emotion
recognition was investigated in typically developing
individuals and individuals with autism. Experiment tested
children with brief video displays of facial expressions that
varied in subtlety. Whereas the performance of control
individuals was best in the adult group, the performance of
individuals with autism was similar in all age groups. Results
are discussed with respect to underlying cognitive processes
that may be affecting the development of emotion recognition
in individuals with autism. This was the first study to look at
the ability to recognize facial expressions in young children
through to adults in both typically developing individuals and
individuals with autism. In contrast to prior research, this
study controlled for the subtlety of the expressions and
required participants make judgments of only briefly
presented dynamic expressions.

The children emotion recognition performance of several
neural networks approach is described. The Radial Basis
Function (RBF), Probabilistic Neural Networks (PNN) and
Support Vector Machines (SVM) variant were tested on
record speech signals and face detected images. For the
language sign the MFCC and other parameter were computed
in concert with their mean and standard difference in order to
obtain the feature vector for the neural network input. For
image input parameters for emotion detection consisted in
several distance computed between certain facial appearance
using space coordinate for eyes, eyebrows and lips.
They have shown similar performance to RBF network in our
emotion detection simulation. In this paper we evaluate
several network structures for an emotion recognition
application. The emotion recognition is based on record
speech signals and face detected images. And investigate the
robustness of the classification rate to clamor on both speech
and image signals. Next to be focused on correlating the
results using images and speech and improve the results by

In [4] authors Paul Fergus, Basma Abdulaimma, Chris Carter,
Sheena Round “Interactive Mobile Technology for Children
with Autism Spectrum Condition (ASC)” Mobile Computing
has been gradually more used to support children with autism.
These higher technologies with their associated features
provide a comfortable and inexpensive solution for autistic
children and their family. The portability, flexibility and
availability of features have opened up new opportunity for
enhancing and inspiring the quality of support to ease autistic
children deficiency. Autistic children are known for their
destruction in understanding and interpreting the emotional
facial expression. This paper posits a 3D animation solution
develop for mobile device. The animation has been built to
the desires of children with autism. Facial animations have
been implemented with warning to improve the major
difficulty in understanding and recognizing emotions in facial
expressions.

In [6] authors Raja Majid Mehmood, Ruoyu Du 2 and Hyo
Jong Lee “Optimal Feature Selection And Deep Learning
Ensembles Method For Emotion Recognition From Human
Brain EEG Sensors” In this paper to recognize emotional state
by analyzing the skin texture of electroencephalography
(EEG) signals, which are generated from EEG sensor that
non-invasively measure the electrical activity of neurons
inside the human brain, and select the optimal mixture of
these features for recognition. The Hjorth parameters activity,
mobility, and complexity were used to measure the signal
activity of the time run data. We selected the optimal EEG
features using a balanced one-way ANOVA after calculate the
Hjorth parameter for different frequency ranges. The optimal
features are further processed for emotion categorization
using support vector machine (SVM), linear discriminant
analysis (LDA), k-nearest neighbor (KNN), Naïve Bayes,
Random Forest, deep-learning. The categorization process
was performed using Waikato Environment for Knowledge
Analysis (WEKA) software. All selected classifiers were
trained and tested over the group of four emotions. We used
the default setting available in WEKA for both classifier. In
this paper, we proposed an EEG feature extraction and
selection method for emotion happy, calm, sad, and scared
recognition. To select the optimal feature set, we analyze the
extract feature set using a balanced one-way ANOVA (pvalue < 0.05) method. To further improve emotion recognition
performance, we need to explore additional feature

33

International Journal of Computer Applications (0975 – 8887)
Volume 180 – No.20, February 2018
combination with more emotional program in the arousal–
valence domain.
In [7] authors Yongbin Gaol, Hyo Jong Lee, Raja Majid
Mehmood in this paper “Deep Learning Of EEG Signals For
Emotion Recognition” EEG-based emotion research is in a
preliminary stage. A total of 21 subjects (12 male and 9
female) participated in this experiment. All subjects were
students at the same institute and were from 12 to 14 years
old. The selected subjects were first informed of the purpose
of our study and the experimental procedure. The subjects
were then given a brief introduction and completed consent
forms. After the recorded EEG data of each subject were
verified, the EEG signals were preprocessed using the
EEGLAB toolbox provided by SCCN Lab. The main
preprocessing steps consisted of artifact rejection, filtering,
and epoch selection from the raw EEG data. The EEG signals
were recorded using the Emotiv-EPOC system. This device
has a maximum of 16 electrodes and collects 128 samples
every second. We used 14 electrodes to record the neural
activity of the brain. In addition, the common mode sense
(CMS) active electrode and driven right leg (DRL) passive
electrode were attached on the mastoid bone behind the ears
to create an average reference channel (CMS/DRL).
Tomography has shown that each brain region has a different
simultaneous emotional response, so decided to record all
EEG channels.
In this paper to recognize emotional state by analyzing the
skin texture of electroencephalography (EEG) signals, which
are generated from EEG sensor that non-invasively measure
the electrical activity of neurons inside the human brain, and
select the optimal mixture of these features for recognition.
The Hjorth parameters activity, mobility, and complexity
were used to measure the signal activity of the time run data.
We selected the optimal EEG features using a balanced oneway ANOVA after calculate the Hjorth parameter for
different frequency ranges. The optimal features are further
processed for emotion categorization using support vector
machine (SVM), linear discriminant analysis (LDA), knearest neighbor (KNN), Naïve Bayes, Random Forest, deeplearning.
The categorization process was performed using Waikato
Environment for Knowledge Analysis (WEKA) software. All
selected classifiers were trained and tested over the group of
four emotions. We used the default setting available in
WEKA for both classifier. In this paper, we proposed an EEG
feature extraction and selection method for emotion happy,
calm, sad, and scared recognition. To select the optimal
feature set, we analyze the extract feature set using a balanced
one-way ANOVA (p-value < 0.05) method. To further
improve emotion recognition performance, we need to explore
additional feature combination with more emotional program
in the arousal–valence domain. In this method the emotion
recognition is improved but used less no of features used.
In [8], Emotion Recognition from Face Dataset Using Deep
Neural Nets, This paper is facial emotion recognition using
face dataset consisting of four classes of emotions happy,
angry, neutral and sad with different models of deep neural
networks. The raw pixels values of all images in CMU face
images dataset. The pixels values were are represented by
higher level concepts in Restricted Boltzmann Machine, Deep
Belief Networks and Stacked Auto encoder. This model could
learn to recognize emotion with considerably higher accuracy
compare two models. We have used the CMU face image
dataset which consists of 640 black and white face images.
Each images consisted in pose, emotional expression, size and

eyes. RBM is hidden layer and visible layer. The DBN
contains two hidden layers and a visible layer. The Deep
learning blocks such as RBM, DBN and SAE+SM learn the
representations formed by the pixels and predict the existence
of emotion. The results show that the SAE+SM could learn to
recognize facial emotions with an accuracy of 99.68% with
only 19 hidden nodes in both the auto encoders. However,
even by varying the no hidden nodes in hidden layers of RBM
and DBN in the range [50, 3000] in steps of 50, the
recognition accuracy did not exceed 25.52%. Therefore, we
conclude that RBM and DBM could be good in feature
extraction, but they are not good in feature classification. On
the other hand, SAE+SM is good in feature extraction as well
as feature classification.
C. Petrantonakis, et.al., [9], Emotion Recognition from Brain
Signals Using Hybrid Adaptive Filtering and Higher Order
Crossings Analysis, A feature extraction method for a userindependent emotion recognition system, namely, HAF-HOC,
from electroencephalograms (EEGs). A novel filtering
procedure, namely, Hybrid Adaptive Filtering (HAF), for an
efficient extraction of the emotion-related EEG-characteristics
was developed by applying Genetic Algorithms to the
Empirical Mode Decomposition-based representation of EEG
signals. In addition, Higher Order Crossings (HOCs) analysis
was employed for feature extraction realization from the
HAF-filtered signals. The introduced HAF-HOC scheme
incorporated four different classification methods to
accomplish a robust emotion recognition performance. EEG
data is six basic emotions are happiness, surprise, anger, fear,
disgust and sadness have been acquired from 16 healthy
subjects using three EEG channels.
Experimental results from the application of the HAF-HOC to
the collected EEG data and comparison with previous
approaches have shown that the HAF-HOC scheme clearly
surpasses the latter in the field of emotion recognition from
brain signals. This work combined HAF with HOCs analysis
to initially process the EEG signals for enhancing the
underlying emotion information, by incorporating EMD and
GA-based techniques and then applying a feature extraction
analysis that resulted in a HOC-based feature vector with
increased classification potential. The best results were
obtained using SVM for the hardest case of differentiating
among the six basic emotions. The comparison of the
introduced HAF-HOC method with other relevant feature
extraction and emotion recognition robustness and
consistency to more effectively discriminate emotions from
EEG signals. It achieved maximum classification but emotion
effective is less.
In [10] authors Pascal Ackermann, Christian Kohlschei_, Jo´
A´ gila Bitsch, Klaus Wehrle and Sabina Jeschke in this paper
“EEG-based Automatic Emotion Recognition: Feature
Extraction, Selection and Classification Methods” Automatic
emotion recognition is an interdisciplinary research field
which deals with the algorithmic detection of human affect
evaluation of human emotion is often done using oral
feedback or questionnaires during doctor-patient sessions.
EEG channel locations and frequency bands are best suited
for is an issue of ongoing research. Here to evaluate the use of
state of the art feature extraction, feature selection and
classification algorithms for EEG emotion classification using
data from the de facto standard dataset. This work for Support
Vector Machines (SVM) and Random Forests (RF) are
applied as two very different state of classification algorithms
which are trained using features algorithm are Short-time
Fourier Transform (STFT), Higher Order Crossing (HOC) and

34

International Journal of Computer Applications (0975 – 8887)
Volume 180 – No.20, February 2018
Hilbert-Huang Spectrum (HHS). STFT-based features were
obtained from the original signal which is being internally
decomposed. HOC features were additionally retrieved from
the original signal. Random Forests are also applied for
classification which is a representative of the feature selection
class of embedded methods meaning that these kinds of
classification algorithms.

obtained using scale emotion based EEG database called
DEAP. This is extracted from data using numerical measures
such as Shannon Entropy and advanced order auto-regressive
model was well to extract features. The model was used for
classify human emotion. The algorithm proposed was tested
on a target multimodal dataset prepared by Queen Mary
University of London for the taxonomy of human affective
states. This dataset commonly recognized as the DEAP
dataset is prepared by recording EEG signals of 32
participants though watching 40 different kinds of music
videos. The present work can be additional extended in
different ways such as online EEG data acquirement using
custom-made wearable EEG headset, explore on the
optimization of the proposed algorithm. Different perspectives
towards emotion representation and it is not conceivable that a
practical SOM-based face recognition system.

In [11] authors Aravind E Vijayan, Deepak Sen, Sudheer A.P
in this paper “EEG-based Emotion Recognition using
Statistical measures and Auto-regressive modeling” A novel
approach towards classification of various human emotions
based on statistically weighed autoregressive modeling of
Electroencephalogram (EEG) signals is discussed. This
algorithm was proven to be greater to many correlated works,
in distinctive different emotions such as happiness, fear,
sadness. The conclusion discussed is based on the results
Table 1. Comparison Analysis of Emotion Recognition Algorithms
S. No

Title

1

Recognition of emotions in autistic
children using physiological signals

Algorithm

Merits

Demerits
Inefficient for less
than three years
child.

Support Vector Machine

Accuracy is good in
later age children

2

Facial emotion recognition system
for autistic children: a feasible study
based on FPGA implementation

Principal component analysis

hardware-efficient of
emotion
recognition
architectures is
implemented

Low accuracy

3

Neural network approaches for
children’s emotion Recognition in
intelligent learning applications

1.Radial Basis Function
2.Support Vector Machine
3.Probabilistic Neural
Networks

used to several neural
networks techniques

Doesn’t work well
for images and
speech signals

Autism Spectrum Condition

Produce well-validated
and high-quality works

In efficient for real
time applications

Analysis of variance

Hidden notes used this
algorithm

Accuracy is very low

Emotion recognition is
improved

Here less no of
features used

4

5

Interactive Mobile Technology for
Children with Autism Spectrum
Condition (ASC)
The Development of Emotion
Recognition in Individuals With
Autism

6

Optimal feature selection and Deep
Learning Ensembles Method for
emotion recognition from human
brain EEG sensors

7

Deep Learning Of EEG Signals For
Emotion Recognition

8

Emotion Recognition from Face
Dataset Using Deep Neural Nets

9

Emotion Recognition from Brain
Signals Using Hybrid Adaptive
Filtering and Higher Order
Crossings Analysis

10

EEG-based Automatic Emotion
Recognition: Feature Extraction,
Selection and Classification
Methods

1.Support vector machine
2.k-nearest neighbors
3. linear discriminant
analysis, 4. Naïve Bayes
5. Random Forest
1.Support vector machine
2.k-nearest neighbors
3.artifical neural network
1.Restricted Boltzmann
Machine
2. Deep Belief Networks

Hidden nodes in this
method used to increase
performance

supports for
detection of other
emotion
Feature classification
is not efficient in this
algorithm

1. Quadratic Discriminant
Analysis
2. k-Nearest Neighbor
3. Support Vector Machine
4. Mahalanobis Distance

Achieved maximum
classification

Emotion effective is
less

1.Support vector machine
2.random forest
3.ranked multipliable rule

Produce well-validated
and high-quality works

It is not set of
electrodes to identify
specific emotions

Produce more accuracy

35

International Journal of Computer Applications (0975 – 8887)
Volume 180 – No.20, February 2018
Table 2: Accuracy of ASD algorithms
Algorithm

Accuracy (%)

SVM

90.0%

RBFNN

83.06%

PNN

80.58%

KNN

83.06%

Deep learning

92.1%

Accuracy (%)
94%
92%
90%
88%
86%
84%
82%
80%
78%
76%
74%
SVM

RBFNN

PNN

KNN

Deep
learning

Figure 1. Accuracy Comparison
Table 3: Comparison Analysis of Emotion Classification
Algorithm

Emotions

Accuracy (%)

SVM

happy, calm, sad, and scared

84.25%

KNN

Happy, sad, love and anger

60.8%

ANN

happy, calm, sad, and scared

60%

DBN

happy, anger, neutral and sad

88.24%

QDA

happiness, surprise, anger, fear, disgust, sadness

76.6%

Table 3: Comparison

Sensitivity
Algorithm

Sensitivity

80%
70%
60%

ML-SVM

70%

50%
40%

NB

70.9%

30%
20%
10%

RF

50%

0%
ML-SVM

NB

RF

PNN

Algorithm
PNN

58.75%
Figure 2: Sensitivity Comparison

36

International Journal of Computer Applications (0975 – 8887)
Volume 180 – No.20, February 2018
Table 4: Comparison Analysis of Specificity
Algorithm

Specificity

Specificity
80%
70%

SVM

60%

60%
50%

LR

71.30%

40%
30%

QDA

53.00%

20%
10%
0%

RMR

65.34%

SVM

LR
QDA
Algorithm

RMR

Figure 3: Specificity Comparison

4. CONCLUSION
In this paper, presented different frequency bands, EEG
channel locations and feature extraction algorithms for their
suitability in EEG-based emotion recognition. Various feature
extraction algorithms were applied. The features were found
to be valuable feature extraction algorithms for classifying
EEG data according to emotions felt. Further we showed the
increased importance of features and EEG locations
corresponding to the pre frontal and left temporal lobe for
EEG emotion classification which coincides with findings
from neuroscience and related work. SVM, linear
discriminant analysis, random forest, naïve Bayes, decision
making algorithms are applied on the EEG dataset and the
deep learning given better accuracy for finding the artesian
child with the sad, happy, angry and scared emotions.

5. REFERENCES
[1] Niranjana Krupa, Karthik Anantharam, Manoj Sanker
Sameer Datta John Vijay Sagar, “Recognition of
emotions in autistic children uses physiological signals”,
in Received: 21 July 2015 /Accepted: 8 March 2016.
[2] K. G. Smitha A. P. Vinod, “Facial emotion recognition
system for autistic children: a feasible study based on
FPGA implementation”, International Federation for
Medical and Biological Engineering 2015.
[3] Felix Albu, Daniela Hagiescu, Liviu Vladutu, MihaelaAlexandra Puica, “Neural Network Approaches For
Children’s Emotion Recognition In Intelligent Learning
Applications”, Proceedings of edulearn15 Conference
6th-8th July 2015.
[4] Paul Fergus, Basma Abdulaimma, Chris Carter, Sheena
Round, “Interactive Mobile Technology for Children
with Autism Spectrum Condition (ASC)”, in 2014.

IJCATM : www.ijcaonline.org

[5] Keiran M. Rump, Joyce L. Giovannelli, Nancy J.
Minshew, Mark S. Strauss, “The Development of
Emotion Recognition in Individuals with Autism”, Child
Development, September/October 2009, Volume 80,
Number 5, Pages 1434–1447.
[6] Raja Majid Mehmood, Ruoyu Du and Hyo Jong Lee,
“Optimal feature selection and Deep Learning Ensembles
Method for emotion recognition from human brain EEG
sensors”, journal of Citation information: DOI
10.1109/ACCESS.2017.2724555, IEEE.
[7] Yongbin Gaol, Hyo Jong Lee, Raja Majid Mehmood,
“Deep Learning Of EEG Signals For Emotion
Recognition”, in IEEE International Conference, 2015.
[8] Olga Sourina, Yisi Liu, “A Fractal-Based Algorithm of
Motion Recognition from EEG Using Arousal-Alence
ModeL”, in 2011.
[9] Panagiotis C. Petrantonakis, Leontios J. Hadjileontiadis,
“Emotion Recognition from Brain Signals Using Hybrid
Adaptive Filtering and Higher Order Crossings
Analysis”, IEEE transactions on affective computing,
vol. 1, no. 2, 2010.
[10] Pascal Ackermann, Christian Kohlschein, Jo´ A´ gila
Bitschx, Klaus Wehrlex and Sabina Jeschke, “EEGbased Automatic Emotion Recognition: Feature
Extraction, Selection and Classification Methods”, in
InternationalConference,2016.
[11] Aravind E Vijayan, Deepak Sen, Sudheer A.P “EEGbased Emotion Recognition using Statistical measures
and Auto-regressive modeling”, 2015 IEEE International
Conference
on
Computational
Intelligence
&
Communication Technology, 978-1-4799-6023-1/15
$31.00 © 2015 IEEE.

37

