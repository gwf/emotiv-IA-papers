ISSN 1870-4069

Selección de parámetros en el enfoque de bolsa
de caracterı́sticas para clasificación de habla
imaginada en electroencefalogramas
Jesús S. Garcı́a-Salinas, Luis Villaseñor-Pineda, Carlos A. Reyes-Garcı́a,
Alejandro A. Torres-Garcı́a
Instituto Nacional de Astrofı́sica Óptica y Electrónica,
Laboratorio de Bioseñales y Cómputo Médico, México
{jss.garcia,villasen,kargaxxi,alejandro.torres}@inaoep.mx

Resumen. El uso de las interfaces cerebro-computadora como un nuevo canal de comunicación ha despertado un gran interés, no obstante aún
hay muchos retos por resolver para alcanzar una comunicación natural.
En el caso particular de las BCIs basadas en habla imaginada aún se presentan dificultades para analizar las señales cerebrales. En este trabajo
se explora una representación de bolsa de caracterı́sticas para identificar
patrones en la señal cerebral adquirida a través de electroencefalogramas.
Esta técnica ha demostrado ser útil en tareas relacionadas. Sin embargo,
determinar la bolsa de caracterı́sticas más adecuada al problema depende
de diversos parámetros. El presente trabajo describe el uso de algoritmos
genéticos para encontrar la configuración más adecuada para la clasificación de habla imaginada. Los resultados, calculados en una base de datos
de habla imaginada de 27 sujetos, muestran la pertinencia del método
alcanzando resultados comparables con el estado del arte.
Palabras clave: interfaces cerebro-computadora, electroencefalogramas
(EEG), habla imaginada, bolsa de caracterı́sticas, algoritmos genéticos.

Parameter Selection in Bag of Features to Classify
Imagined Speech on Electroencephalograms
Abstract. The use of brain-computer interfaces as a new communication channel has become an interest topic, nevertheless, there are many
challenges to achieve a natural communication. In the particular case of
imagined speech BCIs, there are difficulties to analyze the brain signals.
In this work, a bag of features representation to identify patterns in
electroencephalograms is explored. This method has shown to be useful
in similar tasks. Nevertheless, to determine the most adequate bag of
features to the problem depends on many parameters. The present work
describes the use of genetic algorithms to find an adequate configuration
to imagined speech classification. The results, obtained from an imagined speech database of 27 subjects, show the relevance of the method
achieving results which are comparable with related work.
pp. 123–133; rec. 2017-03-02; acc. 2017-05-06

123

Research in Computing Science 140 (2017)

Jesús S. García-Salinas, Luis Villaseñor-Pineda, Carlos A. Reyes-García, Alejandro A. Torres-García

Keywords: brain-computer interfaces, electroencephalograms, imagined
speech, bag of features, genetic algorithms.

1.

Introducción

Cada vez existe un mayor interés en las interfaces cerebro computadora
(BCI). Inicialmente se despertó este interés al brindar un nuevo canal de comunicación a personas con discapacidad. No obstante, debido a la reducción de
costos de los dispositivos para lectura de la señal cerebral, esta nueva forma de
comunicación puede ser utilizada por cualquier persona.
Para controlar un dispositivo a través de una BCI, el usuario debe producir
un patrón de actividad cerebral, ya sea evocado internamente o por un estı́mulo
externo, el cual será identificado por el sistema y transformado en comandos
para dicho dispositivo. La lectura de la actividad cerebral puede realizarse con
diferentes instrumentos, en particular en este trabajo se utiliza el electroencefalograma (EEG) para registrar la señal electrofisiológica. Además, este trabajo
se orienta a analizar la señal cerebral evocada por el habla imaginada, es decir,
cuando el sujeto imagina la dicción de la palabra sin emitir ni articular sonidos.
A pesar de contar con diferentes métodos computacionales para el procesamiento, caracterización y clasificación de las señales cerebrales en EEG [10]
el análisis de las señales cerebrales resultado del habla imaginada, presentan
propiedades que complican su análisis [8]. Distintas soluciones se han propuesto
para realizar esta tarea, sin embargo, aún existen retos importantes para lograr
una comunicación natural y fluida mediante una BCI basada en habla imaginada.
El presente trabajo muestra la generación de una representación del habla
imaginada a partir del método de bolsa de caracterı́sticas. Las bolsas de caracterı́sticas tienen como objetivo lograr una caracterización automática al obtener,
en primera instancia, unidades caracterı́sticas de la señal, y posteriormente
generar un patrón representativo a partir de ellas. De esta forma, el método encuentra un conjunto de unidades caracterı́sticas representativo de cada clase (i.e.
cada palabra imaginada), y estos conjuntos son usados para el reconocimiento
y clasificación del vocabulario imaginado por el sujeto. El descubrimiento de las
unidades caracterı́sticas se realiza a partir de la señal utilizando algún método de
clustering. Los prototipos calculados se consideran las unidades caracterı́sticas,
comúnmente llamadas codewords. Cada codeword es una entrada del diccionario
general, llamado codebook.
Para la generación de las codewords es necesario tener en cuenta el método
de extracción de caracterı́sticas de la señal cerebral, además de definir a priori el
tamaño del codebook. El objetivo de los experimentos mostrados en este trabajo
consiste en encontrar la configuración más apropiada entre las combinaciones
posibles de estos parámetros. Para ello, se utilizó un algoritmo genético evaluado
sobre una base de datos de habla imaginada (5 palabras) de 27 sujetos. En
un intento por generalizar los parámetros, el método es aplicado a todos los
sujetos utilizando los mismos parámetros, y la evaluación se realizó obteniendo
la exactitud promedio de entre todos ellos. Los resultados obtenidos, a pesar de
Research in Computing Science 140 (2017)

124

ISSN 1870-4069

Selección de parámetros en el enfoque de bolsa de características para clasificación de habla ...

ser preliminares, muestran la factibilidad del método, al discriminar segmentos
representativos de la señal para las distintas palabras en habla imaginada.

2.
2.1.

Trabajo relacionado
Primeros enfoques

La comunicación a través de señales cerebrales comenzó con la detección
de potenciales eléctricos indirectamente relacionados al proceso cognitivo del
habla. Uno de los primeros trabajos reportados, presentado en [3], hace uso de
la activación o bloqueo de los ritmos alfa, un rango de frecuencias de la señal
cerebral, para generar código Morse. Esto requiere entrenamiento previo que
consiste en manipular la configuración oculomotora para lograr el control de los
ritmos alfa.
En [4] se utilizan señales P300 para detectar respuestas visuales sobre caracteres mediante un alfabeto en una pantalla, este sistema detecta la respuesta del
cerebro a un estı́mulo visual que se mueve a través de esta pantalla, la respuesta
cerebral permite determinar el caracter que el sujeto desea comunicar.
2.2.

Habla imaginada

Métodos anteriormente usados en BCIs involucran que el usuario aprenda a
generar señales cerebrales especı́ficas, o aprovechan la respuesta cerebral natural
a cierto estı́mulo externo. Una BCI basada en habla imaginada, trabaja con la
señal evocada por el proceso cognitivo del habla, con la gran ventaja que el
sujeto no tiene que aprender a generar señales cerebrales especı́ficas.
A continuación se presentan diversos trabajos relacionados al habla imaginada. Cabe hacer notar que cada uno de ellos difieren no sólo en el método usado,
sino también en la evaluación, donde se experimentó con diferentes conjuntos de
sujetos y distintos vocabularios de palabras imaginadas.
La clasificación de palabras imaginadas fue presentada inicialmente en [14],
donde se analizan las señales EEG y EMG para clasificar siete palabras (first,
second, third, yes, no, right, left). La caracterización se baso en la Transformada
Rápida de Fourier (FFT) y filtros pasa banda, para después aplicar la Transformada Inversa de Fourier (IFFT). La clasificación se realizó mediante mı́nimos
cuadrados para comparar la señal con un prototipo creado a partir de la media
de las muestras, obteniendo una exactitud promedio de 52.57 ± 20 para cinco
sujetos.
En [2] se propone la clasificación de dos vocales imaginadas a traves de
patrones espaciales comunes (CSP), Support Vector Machines (SVM) y filtros
pasa banda, logrando una exactitud promedio de 62.6 ± 8.3 para tres sujetos.
En [16] se utilizó un vocabulario en español de cinco palabras (arriba, abajo,
izquierda, derecha, seleccionar ), se utilizaron canales de EEG cercanos al área
de lenguaje y se aplicó un filtro pasa banda entre 4 y 25 hz. La caracterización
se realizó mediante la Transformada Wavelet Discreta (DWT) y se entrenaron
ISSN 1870-4069

125

Research in Computing Science 140 (2017)

Jesús S. García-Salinas, Luis Villaseñor-Pineda, Carlos A. Reyes-García, Alejandro A. Torres-García

cuatro clasificadores: Naive Bayes, Random Forest, Support Vector Machines y
Bagging Random Forest, y se obtuvo una exactitud de 41.96±3 para tres sujetos.
Un esquema más simple, mostrado en [13], clasifica entre dos palabras en
árabe (Si, No). Se analizaron los ritmos alfa y beta de un EEG de un solo canal
mediante dos métodos, el primero obtiene datos estadı́sticos de la señal (mı́nimo,
máximo y media) y el segundo aplica la DWT con seis niveles de descomposición.
La clasificación se llevo a cabo mediante SVM, Linear Discriminant Analysis
(LDA), Self-Organized Maps (SOM), Multilayer Perceptron y ensambles de ellos,
la exactitud promedio obtenida fue de 56 para un conjunto de siete sujetos.
Recientemente, en [17] se exploraron diversas familias wavelet y clasificadores
para clasificación multiclase de cinco palabras (arriba, abajo, izquierda, derecha,
seleccionar ). Se implementó una selección de canales automática basada en
inferencia difusa para reducir el conjunto de datos y obtuvo una exactitud de
68.18 ± 16.

2.3.

Bolsa de caracterı́sticas

Este método está basado en el enfoque tradicional de cuantificación vectorial
(Vector Quantization) cuyo objetivo es lograr una caracterización automática de
la señal, discretizando su representación. En el área de análisis de señales se han
presentado diferentes variantes y adaptaciones; y recibe diferentes nombres de
acuerdo a su área de aplicación como, por ejemplo, bolsa de patrones, bolsa de
imágenes o bolsa de segmentos.
En breve, la señal es segmentada y las unidades representativas son generadas
mediante una técnica de clustering, los prototipos de cada clúster reciben el
nombre de codewords y en conjunto forman el codebook. Una vez generado el
codebook, se toma la señal segmentada y por cada segmento se identifica aquella
codeword más similar. Una vez codificada la señal se calcula un histograma de
las codewords presentes en la señal (véase la siguiente sección para su descripción
formal).
En el caso especı́fico de señales de EEG, la bolsa de caracterı́sticas fue usada
por [18], con el uso de señales de EEG (y EKG) para detección de epilepsia.
Las señales fueron obtenidas mediante un EEG de un solo canal y se extrajeron
caracterı́sticas mediante la DWT, posteriormente fueron agrupadas mediante
k-means. Los histogramas se crearon mediante 1-Nearest Neighbor y finalmente
se clasificó con un clasificador 1-Nearest Neighbor, la exactitud obtenida fue de
87.8 ± 2.3.
En [12], se presenta una modificación al método de clustering, al que llaman
Bag of Super-Features o Bolsa de Super-Caracterı́sticas. El método consiste en
generar clústers para cada una de las clases y posteriormente unirlos. Realizar esta división y calcular de esta forma el codebook reduce la pérdida de información
de las clases [9].
Research in Computing Science 140 (2017)

126

ISSN 1870-4069

Selección de parámetros en el enfoque de bolsa de características para clasificación de habla ...

3.
3.1.

Método
Bolsa de caracterı́sticas

Una serie de tiempo está definida por xi = (xi1 , xi2 , ..., xip ), para p muestras.
Cada instancia xi esta asociada con una clase y i para i = 1, 2, ..., n y y i ∈
{1, 2, ..., C} donde n es el número de instancias y C es el número de clases. Para
extraer patrones locales, es necesario deslizar una ventana w sobre las series
de tiempo, el deslizamiento m no puede ser mayor al tamaño de la ventana
m ≤ w. Las subsecuencias extraı́das serán d p−w+1
e, por lo tanto, el conjunto de
m
p−w+1
datos tendrá n(d m e) subsecuencias. A continuación se aplica un algoritmo
de clustering con k centroides, que serán los codewords de nuestro codebook
K ∈ R(w×d) [7].
El método propuesto está basado en el trabajo presentado en [18] al que le
fueron realizadas adaptaciones, el esquema general se muestra en la fig. 1, y se
aplica individualmente a cada uno de los sujetos en la base de datos, y finalmente
los resultados son promediados en un intento por observar de forma general los
resultados alcanzados por el modelo para todos los sujetos.

Fig. 1. Diagrama del método.

El resultado es la exactitud total de clasificación de las palabras imaginadas
en el conjunto de datos. En nuestro caso, es la exactitud la que se toma como
función objetivo en el algoritmo genético, y con ello determinar los valores más
adecuados para el conjunto de parámetros en cada una de sus etapas.
Datos. El conjunto de datos fue obtenido en [6], se registraron los EEG de 27
sujetos hablantes nativos de español a través de un kit EPOC de la compañı́a
Emotiv que cuenta con 14 canales (AF3, AF4, F3, F4, F7, F8, FC5, FC6, P7, P8,
T7, T8, O1, O2) y una frecuencia de muestreo de 128 Hz. Los datos consisten en 5
palabras imaginadas (”arriba”, ”abajo” ”izquierda”, ”derecha” y ”seleccionar”)
repetidas 33 veces cada una, con un tiempo de descanso entre cada repetición.
Los datos fueron procesados mediante la Referencia Promedio Común (CAR),
por sus siglas en inglés, para reducir el ruido obtenido en la toma de muestras.
ISSN 1870-4069

127

Research in Computing Science 140 (2017)

Jesús S. García-Salinas, Luis Villaseñor-Pineda, Carlos A. Reyes-García, Alejandro A. Torres-García

El CAR es una técnica computacionalmente simple y ha demostrado superar
algunas técnicas de referenciado eléctrico [11]. También se aplicó un filtro pasa
bajas Butterworth con corte en 50 Hz, para eliminar algunos artefactos.
Ya que cada conjunto de datos está conformado de 14 canales, se procesó
cada señal de forma independiente, es decir, el procesamiento fue realizado a
cada una de ellas por separado. Cabe señalar que para el proceso de creación del
clasificador se tomaron, para cada sujeto, 25 repeticiones aleatoriamente para
entrenamiento y generación del codebook, y las 8 restantes fueron utilizadas para
pruebas de clasificación.
Extracción de caracterı́sticas. La extracción de caracterı́sticas de la señal
se llevó a cabo mediante una ventana en movimiento, con un tamaño W y
un desplazamiento M que podı́a tener sobreposición pero no saltos, es decir,
M ≤ W donde M > 0, W ≥ 8, además se tiene un lı́mite superior de 128, que
es la frecuencia de muestreo de la señal.
En este caso se utilizaron únicamente los coeficientes obtenidos por la transformada rápida de Fourier [5] y la energı́a relativa de la transformada Wavelet,
C = F F T, DW T . La transformada Wavelet es la integral de una señal multiplicada por versiones escaladas y desplazadas de una función wavelet. Una vez
obtenidos los coeficientes de la DWT, se obtiene la energı́a relativa mediante el
método mostrado en [15].
Clustering. El algoritmo de clustering utilizado fue k-means++ [1], a partir
de cada una de las señales se obtuvieron K prototipos o codewords que forman
el codebook.
Cabe señalar que para conformar el codebook se aplicó el clustering por
separado a cada una de las clases (i. e. las palabras a reconocer), el número de
clústers se divide entre el número de clases para tener una distribución equitativa
de los clústers, una vez generados los prototipos de cada una de las clases son
concatenados para formar el codebook.
Generación de histogramas. Una vez generado el codebook, el siguiente paso
es codificar los segmentos de las señales, esto es, decidir a cual de los elementos del
codebook son más parecidos. Esta asignación se realiza utilizando una búsqueda
del vecino mas cercano (1-NN) tomando como medida la distancia Euclidiana.
Una vez asignados los codewords, se genera un histograma por cada señal.
Los histogramas fueron etiquetados según la palabra imaginada a la que corresponden, y esta información fue utilizada para crear el clasificador. En nuestro
caso se utilizó el método de Naive Bayes Multinomial.
3.2.

Algoritmo genético

Dada la combinatoria entre los parámetros para calcular la bolsa de caracterı́sticas, se aplicó un algoritmo genético para determinar la configuración más
Research in Computing Science 140 (2017)

128

ISSN 1870-4069

Selección de parámetros en el enfoque de bolsa de características para clasificación de habla ...

adecuada. Los parámetros a definir en la generación de la bolsa de caracterı́sticas
son entonces: el tipo de extracción de caracterı́sticas (C = FFT, DWT), el
tamaño de ventana para la extracción de caracterı́sticas (8 ≤ W ≤ 128), el
desplazamiento de la ventana (8 ≤ M ≤ 128), y el número de clústers (K ≤
1000); dando un total de 4 parámetros.

Fig. 2. Ejemplo de un individuo del algoritmo genético.

La función objetivo del algoritmo se orientó a reducir el error de clasificación
promedio de todos los sujetos.
El tamaño de población y las generaciones se fijaron en 100, la fracción de
cruce de individuos es de 80 % y se lleva a cabo tomando una mezcla de promedios
pesados de los padres. El proceso de selección se lleva a cabo mediante una
función estocástica uniforme que se mueve a través del conjunto de individuos
con un número de pasos fijo. Además, se considera un elitismo de 2 %, es decir,
2 individuos pasan sin alteraciones a la siguiente generación. Las probabilidades
de mutación de un sujeto en cada generación es de 1 %. Este sujeto será alterado
aleatoriamente para diversificar los parámetros obtenidos.
No se definieron lı́mites de tiempo o de aptitud que detuvieran la ejecución
del algoritmo, es decir, el algoritmo podrá continuar hasta completar las generaciones ignorando el tiempo y la exactitud obtenida en cada generación. El único
criterio de paro es no encontrar un cambio en el promedio de aptitud después
de 20 generaciones, en este caso el algoritmo habrá llegado a un estancamiento
y detendrá su ejecución, tomando el mejor sujeto hasta ese instante.

4.

Experimentos y resultados

Los resultados de clasificación se obtuvieron separando aleatoriamente el 75 %
de las instancias para entrenamiento y 25 % para pruebas. Se clasificaron cinco
clases que corresponden a cada una de las palabras imaginadas mediante un
clasificador Naive Bayes Multinomial.
El algoritmo genético obtuvo como parámetros óptimos: una caracterización
C mediante FFT, un tamaño de codebook K de 75, una ventana W de tamaño
40 con un desplazamiento M de 8. Tomando en cuenta estos parámetros se
obtuvieron los resultados de clasificación mostrados en la figura 4.
Como es de esperar, el algoritmo genético minimiza la aptitud del método en
cada generación, en este caso se reduce el error de clasificación. En la figura 3 se
puede observar la aptitud obtenida en cada generación del algoritmo genético,
ISSN 1870-4069

129

Research in Computing Science 140 (2017)

Jesús S. García-Salinas, Luis Villaseñor-Pineda, Carlos A. Reyes-García, Alejandro A. Torres-García

se llegó a un estancamiento de la aptitud en la generación número setenta y uno,
es decir, la variación de la exactitud obtenida en cada generación fue menor a
1 × 10−6 .

Fig. 3. Comportamiento del algoritmo genético.

El experimento con los parámetros obtenidos fue repetido diez veces, la
exactitud promedio alcanzada se muestra en la figura 4. La exactitud se obtiene
del total obtenido por las cinco clases. La desviación del promedio representa la
desviación de las exactitudes de los veintisiete sujetos.

Fig. 4. Exactitud promedio para 10 iteraciones del método al aplicarlo a cada uno de
los 27 sujetos de nuestra base de datos.

Para tener una idea de como se comporta la clasificación a nivel de palabras,
se presenta una matriz de confusión promedio en la tabla 2. La matriz se calculó
al promediar y normalizar con los resultados obtenidos de todos los sujetos
considerando las 10 iteraciones del método.
Research in Computing Science 140 (2017)

130

ISSN 1870-4069

Selección de parámetros en el enfoque de bolsa de características para clasificación de habla ...

Tabla 1. Resultados promedio de exactitud para 10 iteraciones por sujetos con su
desviación estándar, comparado con los resultados alcanzados en [17].
Sujeto Método propuesto Torres et al. 2016
1
65.3 ± 5.5
88.38
2
45.3 ± 5.5
50.77
3
80.3 ± 4.5
69.74
4
83.8 ± 7.6
77.46
5
59.3 ± 6.5
73.34
6
39.5 ± 6.3
40
7
80.8 ± 7.7
70.62
8
83.5 ± 6.8
89.7
9
61.5 ± 3.8
81.21
10
77.0 ± 6.2
70.92
11
83.0 ± 6.9
90.33
12
76.5 ± 5.6
75.11
13
58.0 ± 6.9
66.65
14
48.3 ± 8.1
48.01
15
74.5 ± 9.3
85.44
16
51.3 ± 6.0
63.53
17
73.8 ± 7.8
67.87
18
68.3 ± 4.7
81.8
19
43.5 ± 5.2
46.76
20
61.0 ± 6.6
83.09
21
59.0 ± 6.7
48.42
22
67.0 ± 2.8
70.33
23
54.3 ± 4.6
63.2
24
52.0 ± 9.1
57.46
25
55.0 ± 6.2
29.78
26
70.5 ± 7.2
67.24
27
55.0 ± 7.0
83.64
Prom.
64.0 ± 13.24
68.18 ± 15.9

Tabla 2. Matriz de confusión promedio considerando todos los sujetos.
Arriba
0.73
0.11
0.04
0.06
0.05

ISSN 1870-4069

Abajo Izquierda Derecha Seleccionar
0.12
0.05
0.06
0.06
Arriba
0.62
0.08
0.14
0.06
Abajo
0.08
0.60
0.14
0.15
Izquierda
0.16
0.14
0.58
0.08
Derecha
0.08
0.15
0.06
0.67
Seleccionar

131

Research in Computing Science 140 (2017)

Jesús S. García-Salinas, Luis Villaseñor-Pineda, Carlos A. Reyes-García, Alejandro A. Torres-García

Como puede observarse la palabra con menor confusión es arriba y la de
mayor confusión es derecha. Cabe notar que esta última palabra se confunde
principalmente con las palabras abajo e izquierda.

5.

Conclusiones

Los parámetros obtenidos con el algoritmo genético lograron una configuración que permitió crear representaciones basadas en bolsa de caracterı́sticas cuya
clasificación fue comparable con lo reportado en el estado del arte. La exactitud
promedio alcanzada fue de 64 ± 13.24 para 5 palabras imaginadas por 27 sujetos.
Como se muestra en la figura 3, el algoritmo logró converger a una solución
óptima en menos generaciones de las esperadas, esto abre la posibilidad de
aumentar el número de parámetros. Entre los parámetros a añadir pueden considerarse los parámetros propios de las técnicas de extracción de caracterı́sticas.
Por ejemplo, la familia Wavelet o el número de niveles de descomposición. Por
otro lado, aún falta observar el resultado al aplicar el método de forma individual,
es decir, ajustar los parámetros a cada sujeto. Esto podrı́a mejorar los resultados
individuales de clasificación pero incidir sobre las conclusiones generales sobre
los parámetros del método.
Como trabajo futuro, se desea explorar con distintos métodos en algunas
de las etapas en el cálculo del coodebook. Por ejemplo, utilizar un método de
clustering, como Expectation Maximisation, esto permitirı́a eliminar el parámetro
de tamaño de clúster del algoritmo genético. Ası́ como la modificación en la
generación de histogramas, donde es posible considerar secuencias de codewords,
incluyendo de esta forma información temporal de la señal.
Agradecimientos. Los autores agradecen al Consejo Nacional de Ciencia y
Tecnologı́a (CONACyT) por al apoyo a esta investigación a través de la beca #
702603 y del proyecto 2016-01-2228. Asimismo, agradecen al apoyo del Ministerio
de Asuntos Exteriores y de Cooperación Internacional de Italia y la Agencia
Mexicana de Cooperación Internacional para el Desarrollo (AMEXCID) bajo el
proyecto MX14MO06 INAOE-Universidad de Florencia.

Referencias
1. Arthur, D., Vassilvitskii, S.: K-means++: The advantages of careful
seeding. In: Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms. pp. 1027–1035. SODA ’07, Society for
Industrial and Applied Mathematics, Philadelphia, PA, USA (2007),
http://dl.acm.org/citation.cfm?id=1283383.1283494
2. DaSalla, C.S., Kambara, H., Sato, M., Koike, Y.: Single-trial classification of vowel
speech imagery using common spatial patterns. Neural Networks 22(9), 1334 – 1339
(2009),
http://www.sciencedirect.com/science/article/pii/S0893608009000999,
brain-Machine Interface
Research in Computing Science 140 (2017)

132

ISSN 1870-4069

Selección de parámetros en el enfoque de bolsa de características para clasificación de habla ...

3. Dewan, E.M.: Occipital alpha rhythm eye position and lens accommodation.
Nature 214, 975–977 (1967)
4. Farwell, L., Donchin, E.: Talking off the top of your head: toward
a mental prosthesis utilizing event-related brain potentials. Electroencephalography and Clinical Neurophysiology 70(6), 510 – 523 (1988),
http://www.sciencedirect.com/science/article/pii/0013469488901496
5. Frigo,
M.,
Johnson,
S.G.:
The
design
and
implementation
of
fftw3.
Proceedings
of
the
IEEE
93(2),
216–231
(2005),
http://ieeexplore.ieee.org/abstract/document/1386650/
6. González Castañeda, E., Torres-Garcı́a, A., Reyes-Garcı́a, C., Villaseñor-Pineda,
L.: Applying Brain Signals Sonification for Automatic Classification. Revista
Mexicana de Ingenierı́a Biomédica 36(3), 233–248 (Sep 2015)
7. Gui, Z.W., Yeh, Y.R.: Time Series Classification with Temporal Bag-of-Words
Model, pp. 145–153. Springer International Publishing, Cham (2014)
8. Klonowski, W.: Everything you wanted to ask about eeg but were afraid
to get the right answer. Nonlinear Biomedical Physics 3(1), 1 – 5 (2009),
http://dx.doi.org/10.1186/1753-4631-3-2
9. Lazebnik, S., Raginsky, M.: Supervised learning of quantizer codebooks by information loss minimization. IEEE Transactions on Pattern Analysis and Machine
Intelligence 31(7), 1294–1309 (July 2009)
10. Lotte, F., Congedo, M., Lécuyer, A., Lamarche, F., Arnaldi, B.: A review of
classification algorithms for eeg-based brain-computer interfaces. Journal of Neural
Engineering 4(2), R1 (2007), http://stacks.iop.org/1741-2552/4/i=2/a=R01
11. Ludwig, K.A., Miriani, R.M., Langhals, N.B., Joseph, M.D., Anderson, D.J., Kipke,
D.R.: Using a common average reference to improve cortical neuron recordings
from microelectrode arrays. Journal of Neurophysiology 101(3), 1679–1689 (2009),
http://jn.physiology.org/content/101/3/1679
12. Plinge, A., Grzeszick, R., Fink, G.A.: A bag-of-features approach to acoustic event
detection. In: 2014 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP). pp. 3704–3708 (May 2014)
13. Salama, M., Lashin, H., Gamal, T.: Recognition of unspoken words using electrode
electroencephalograhic signals. COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications pp. 51–55 (2014)
14. Suppes, P., Lin, L.Z., Bing, H.: Brain wave recognition of words. Proceedings of the National Academy of Sciences 94(26), 14965 – 14969 (1997),
http://www.pnas.org/content/94/26/14965.abstract
15. Torres-Garcı́a, A., Reyes-Garcı́a, C., Villaseñor-Pineda, L., Ramı́rez, J.: Análisis
de señales electroencefalográficas para la clasificación de habla imaginada. Revista
mexicana de ingenierı́a biomédica 34(1), 23–39 (2013)
16. Torres-Garcı́a, A.A., Reyes-Garcı́a, C.A., Villaseñor-Pineda, L.: Toward a silent
speech interface based on unspoken speech. Proceedings of biosignals pp. 370 –
373 (2012)
17. Torres-Garcı́a,
A.A.,
Reyes-Garcı́a,
C.A.,
Villaseñor-Pineda,
L.,
Garcı́a-Aguilar, G.: Implementing a fuzzy inference system in a
multi-objective {EEG} channel selection model for imagined speech
classification. Expert Systems with Applications 59, 1 – 12 (2016),
http://www.sciencedirect.com/science/article/pii/S0957417416301774
18. Wang, J., Liu, P., She, M.F., Nahavandi, S., Kouzani, A.: Bagof-words
representation
for
biomedical
time
series
classification.
Biomedical Signal Processing and Control 8(6), 634 – 644 (2013),
http://www.sciencedirect.com/science/article/pii/S174680941300089X
ISSN 1870-4069

133

Research in Computing Science 140 (2017)

