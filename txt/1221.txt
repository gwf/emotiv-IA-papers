Journal of Robotics, Networking and Artificial Life, Vol. 4, No. 2 (September 2017) 124–128
___________________________________________________________________________________________________________

Experiments on Classification of Electroencephalography (EEG) Signals in Imagination of
Direction using Stacked Autoencoder
Kenta Tomonaga, Takuya Hayakawa, Jun Kobayashi

Department of Systems Design and Informatics, Kyushu Institute of Technology,
Kawazu 680-4, Iizuka, 820-8502, Japan
E-mail: jkoba@ces.kyutech.ac.jp
lab.jkoba.net

Abstract
This paper presents classification methods for electroencephalography (EEG) signals in imagination of direction
measured by a portable EEG headset. In the authors’ previous studies, principal component analysis extracted
significant features from EEG signals to construct neural network classifiers. To improve the performance, the
authors have implemented a Stacked Autoencoder (SAE) for the classification. The SAE carries out feature
extraction and classification in a form of multi-layered neural network. Experimental results showed that the SAE
outperformed the previous classifiers.
Keywords: electroencephalography, stacked autoencoder, neural network, portable EEG headset, imagination of
direction

extraction with Principal Component Analysis (PCA)
and several neural networks for the classification.4,5 We
validated the performance and confirmed that the best
classification rate of the method using the medical EEG
device was still better than those of our methods.
To achieve higher classification rate, we have
implemented a Stacked Autoencoder (SAE) for feature
extraction and classification of EEG signals in
imagination of direction measured by the portable EEG
device. G. E. Hinton et al. said that deep autoencoder
networks can reduce the dimensionality of data much
better than PCA.6 Therefore, we introduced a SAE to
our study on classification of EEG signals in
imagination of direction. Here we describe the
implemented SAE and show results of comparative
experiments that validate its effectiveness.

1. Introduction
Electroencephalography (EEG) is a non-invasive way
for measuring human brain activity. A lot of studies on
Brain Computer Interface (BCI) have been making use
of EEG because of its greater availability than invasive
ways. In addition, portable and low-cost EEG devices
have been developed and readily accessible nowadays.
There are, however, unclear points in the accuracy of
those portable EEG devices.1,2 Therefore, the potential
of applications using the devices should be explored.
Seto et al. studied on classification of EEG signals
in imagination of direction measured by a medical EEG
device.3 Following their study, we have employed a
portable EEG headset to record EEG signals in
imagination of direction, and implemented feature

Copyright © 2017, the Authors. Published by Atlantis Press.
This is an open access article under the CC BY-NC license (http://creativecommons.org/licenses/by-nc/4.0/).
124

Journal of Robotics, Networking and Artificial Life, Vol. 4, No. 2 (September 2017) 124–128
___________________________________________________________________________________________________________

2. EEG Data Acquisition and Preprocessing
Fig. 1 shows a wireless portable EEG headset developed
by Emotiv Inc., named EPOC.7 We used the headset for
EEG data acquisition in our preceding studies.4,5 EPOC
has 14 electrodes and two reference electrodes,
recording EEG signals at a sampling rate of 128 Hz.
The electrodes are placed on the scalp according to an
extended 10-20 system for EEG measurement as shown
in Fig. 2.

Fig. 1. Emotiv EPOC (wireless portable EEG headset)

Fig. 3. Experimental environment

Fig. 4. Arrows indicating directions
(up, down, right, and left)

Fig. 2. Electrode placement of EPOC

Nine male university students participated in
experiments as subjects for EEG data acquisition. Their
average age was 21.9 years. Fig. 3 shows the
experimental environment. During the experiments, a
subject imagined one figure of arrows shown in Fig. 4.
The obtained EEG signals were preprocessed to produce
input vectors to a classifier. Fig. 5 is a flowchart of the
preprocessing. The input vectors are composed of 23
elements. See Refs. 4 and 5 for more details about the
EEG data acquisition and preprocessing.

Fig. 5. Flowchart of preprocessing

125

Journal of Robotics, Networking and Artificial Life, Vol. 4, No. 2 (September 2017) 124–128
___________________________________________________________________________________________________________

3. Classification with Stacked Autoencoder

Fig. 7 depicts the configuration of the SAE with two
hidden layers adopted in this study. The hidden layers
were pretrained in the way of learning autoencoder. The
first thing we conducted was to train an autoencoder
with the preprocessed EEG signals for 1000 epochs so
that it could output signals identical to the input ones.
The encoder part of the trained autoencoder was utilized
as the pretrained first hidden layer of the SAE shown in
Fig. 7, which generates signals from the EEG ones by
reduction of dimensionality. Subsequently, we obtained
by backpropagation for 1000 epochs another
autoencoder producing signals further extracted from
the output of the pretrained first hidden layer. The
encoder part of the second autoencoder was set up as the
pretrained second hidden layer in the SAE.
As stated above, the SAE in an initial state was
composed of the pretrained encoders as the hidden
layers. In addition, an output layer having four nodes
representing the four directions was added to the
network. The activation function of the output layer was
softmax function, while Rectified Linear Unit (ReLU)
for the hidden layers. The input layer had 23 nodes
because input vectors to the SAE was made up of 23
elements produced from the preprocessed EEG signals.
The number of nodes of the first and second hidden
layers were tentatively set to 20 and 10, respectively.
Searching the optimum number of hidden layers and
their nodes is a future work.
Finally, in order to achieve EEG signal classifiers,
we conducted supervised learning, fine-tuning the initial
SAE for 1000 or 10000 epochs using the preprocessed
EEG signals with target values in one-hot representation
indicating the imagined direction.

4,5

In our previous studies, we applied PCA to the
preprocessed EEG data for reducing the dimension, and
then trained three-layered neural networks by means of
backpropagation for 1000 or 10000 epochs with the
dimensionally-reduced data as feature vectors and target
values representing the direction a subject imagined.
This classification method is called “PCA-NN” in this
paper.
We have introduced deep neural networks in order
to achieve better classification performance than the
PCA-NN. Although training a deep neural network was
difficult for backpropagation due to vanishing gradient
problem, pretraining weights between nodes of a deep
neural network can be a solution to the problem.
Stacked Autoencoder (SAE) is a way of
constructing a deep neural network, in which deep
architectures are initialized by stacking pretrained
autoencoders. Fig. 6 illustrates a typical autoencoder
that is an hourglass-shaped three-layered neural
network. This neural network has the same number of
nodes in the input and output layers, and the network is
trained by backpropagation so that it can yield output
values equal to given input ones. Autoencoder is an
unsupervised learning method, which can be used for
dimensionality reduction as mentioned above. The
anterior part between the input and hidden layers of an
autoencoder works as encoder, compressing input
signals and extracting significant information from
them. In SAE, the encoder parts of pretrained
autoencoders are stacked for initializing a deep neural
network.

Fig. 6. Autoencoder

Fig. 7. Stacked Autoencoder with two hidden layers

126

Journal of Robotics, Networking and Artificial Life, Vol. 4, No. 2 (September 2017) 124–128
___________________________________________________________________________________________________________

Table 2. Classification rate percentages of SAE

4. Results and Discussion

Electrode
AF3
F7
F3
FC5
T7
P7
O1
O2
P8
T8
FC6
F4
F8
AF4

The classification rates of the classifiers were evaluated
with 5-fold cross validation. Table 1 and Table 2 show
the evaluation results for the EEG signals obtained from
one of the subjects. In the PCA-NNs, the PCA kept
features with a 90% cumulative contribution ratio, and
trimmed off the others. The PCA process resulted in
producing 17-dimensional feature vectors. Therefore,
the NNs of the PCA-NN were composed of 17-17-4
nodes in the input, hidden, and output layers. On the
other hand, the structure of the SAEs were 23-20-10-4;
the number of the input nodes was 23 that is equal to the
dimension of the preprocessed input vector.
As shown in Table 1, the maximum classification
rate by the PCA-NNs was 35.0% at FC5 electrode. It
appears that overfitting caused the poor performance in
some of the PCA-NNs trained for 10000 epochs.
Table 2 shows the classification rates of the SAEs. It
clarified that the SAEs achieved better classification
performance than the PCA-NNs. One of the SAEs
realized 61.7% classification rate at FC5 electrode.
Nevertheless, the work by Seto et al. using a medical
EEG device3 is still better than the results obtained in
this study.
It would be expected for improvement that a deeper
SAE could provide superior performance than the SAEs
with only two hidden layer used in this study. In
addition, we will use denoising autoencoders8,9 to
extract more relevant features for the classification of
EEG signals.

Epoch 1000
25.8
29.2
26.7
35.0
33.3
31.7
25.0
25.0
34.2
30.0
25.8
27.5
24.2
26.7

Epoch 10000
34.2
49.2
40.0
61.7
40.8
41.7
33.3
30.8
29.2
32.5
34.2
33.3
32.5
35.0

5. Conclusion
We implemented the SAEs for classification of EEG
signals in imagination of direction, and compared the
performance with those of the NNs trained using the
feature vectors extracted by PCA. The results
demonstrated that the SAEs achieved the improvement,
however the achievement of the preceding study using a
medical EEG device is still better than ours using the
portable EEG headset. There remains much to explore a
way to select the number of layers in the SAEs and to
adopt denoising autoencoders as future work.
References
1. M. Duvinage et al., A P300-based quantitative
comparison between the Emotiv Epoc headset and a
medical EEG device, in Proc. of the 9 th IEEE/IASTED
Int. Conf. on Biomedical Engineering (Innsbruck,
Austria, 2012).
2. M. Duvinage et al., Performance of the Emotiv Epoc
headset for P300-based applications, BioMedical
Engineering On Line 12(56) (2013).
3. Y. Seto et al., Classification by EEG frequency
distribution in imagination of directions, in Proc. of the
18th Int. Conf. on Knowledge-Based and Intelligent
Information & Engineering Systems (2014), pp. 1300–
1306.
4. K. Tomonaga et al., Experiments on classification of
electroencephalography (EEG) signals in imagination of
direction using a wireless portable EEG headset, in Proc.
of Int. Conf. on Control, Automation and Systems (Busan,
South Korea, 2015), pp. 1805–1810.

Table 1. Classification rate percentages of PCA-NN
Electrode
AF3
F7
F3
FC5
T7
P7
O1
O2
P8
T8
FC6
F4
F8
AF4

Epoch 1000
35.8
56.7
41.7
55.8
40.8
37.5
30.0
28.3
24.2
45.0
39.2
34.2
35.0
36.7

Epoch 10000
25.8
26.7
29.2
25.8
26.7
27.5
25.8
25.0
28.3
25.8
26.7
24.2
24.2
23.3

127

Journal of Robotics, Networking and Artificial Life, Vol. 4, No. 2 (September 2017) 124–128
___________________________________________________________________________________________________________

5. S. Wakamizu et al., Experiments on Neural Networks
with
Different
Configurations
for
Electroencephalography
(EEG)
Signal
Pattern
Classifications in Imagination of Direction, in Proc. of
IEEE Int. Conf. on Control System, Computing and
Engineering (Penang, Malaysia, 2015), pp. 477–481.
6. G. E. Hinton and R. R. Salakhutdinov, Reducing the
Dimensionality of Data with Neural Networks, Science
313 (2006), pp. 504–507.

7. Emotiv EPOC, https://emotiv.com/epoc.php.
8. P. Vincent et al., Extracting and Composing Robust
Features with Denoising Autoencoders, in Proc. of the
25 th Int. Conf. on Machine Learning (Helsinki, Finland,
2008), pp. 1096–1103.
9. P. Vincent et al., Stacked Denoising Autoencoders:
Learning Useful Representations in a Deep Network with
a Local Denoising Criterion, J. of Machine Learning
Research 11 (2010), pp. 3371–2408.

128

