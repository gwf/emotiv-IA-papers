App Stores for the Brain:
Privacy & Security in Brain-Computer Interfaces∗
Tamara Bonaci1 , Ryan Calo2 and Howard Jay Chizeck1
Abstract—An increasing number of Brain-Computer Interfaces (BCIs) are being developed in medical and nonmedical
fields, including marketing, gaming and entertainment industries.
BCI-enabled technology carries a great potential to improve and
enhance the quality of human lives. It provides people suffering
from severe neuromuscular disorders with a way to interact with
the external environment. It also enables a more personalized
user experience in gaming and entertainment.
These BCI applications are, however, not without risk. Established engineering practices set guarantees on performance,
reliability and physical safety of BCIs. But no guarantees or
standards are currently in place regarding user privacy and
security. In this paper, we identify privacy and security issues
arising from possible misuse or inappropriate use of BCIs. In
particular, we explore how current and emerging non-invasive
BCI platforms can be used to extract private information, and we
suggest an interdisciplinary approach to mitigating this problem.
We then propose a tool to prevent this side-channel extraction of
users’ private information. This is a first step towards making
BCI-enabled technologies secure and privacy preserving.

I.

I NTRODUCTION

A large number of Brain-Computer Interfaces (BCIs) are
currently under development, or being proposed, for both medical and non-medical applications. These applications include
advertising, market surveys, focus groups and gaming. For example, in 2008, the Nielsen Company acquired Neuro-Focus,
for the development of neural engineering technologies aimed
at better understanding customer needs and preferences [6].
In May 2013, Samsung, in collaboration with the University
of Texas, demonstrated how BCIs could be used to control
mobile devices [12]. In the same month, the first neurogaming
conference gathered more than 50 involved companies [7]. In
September 2013, Neuroware company presented Neurocam,
a wearable EEG system equipped with a camera, used to
detect users’ emotions. The system is set to automatically start
recording moments of interest based on inferred information
from users’ neural signals [9].
Several neural engineering companies, including Emotiv [3] and NeuroSky [8] currently offer low-cost, consumergrade BCIs and software development kits. These companies
have recently introduced the concept of BCI “app stores” [31],
with the purpose of facilitating expansion of BCI applications.
Future BCIs will likely be simpler to use and will require less
*This work is supported by Award Number EEC-1028725 from the National
Science Foundation. The content is solely responsibility of the authors and
does not necessarily represent the official views of the National Science
Foundation.
1 Department of Electrical Engineering, University of Washington, Seattle,
WA, USA {tbonaci, chizeck}@uw.edu
2 School of Law, University of Washington, Seattle, WA, USA
{rcalo}@uw.edu

978-1-4799-4992-2/14/$31.00 c 2014 IEEE

training time and user effort, while enabling faster and more
accurate translation of users’ intended messages.
This development raises, however, new questions about
privacy and security. At the 2012 USENIX Security Symposium, researchers introduced the first BCI-enabled malicious
application, referred to as “brain spyware”. The application
was used to extract private information, such as credit card
PINs, dates of birth and locations of residence, from users’
recorded EEG signals [31].
As BCI technology spreads further (towards becoming
ubiquitous), it is easy to imagine more sophisticated ”spying” applications being developed for nefarious purposes.
Leveraging recent neuroscience results (e.g., [11], [17], [26],
[37]), it may be possible to extract private information about
users’ memories, prejudices, religious and political beliefs, as
well as about their possible neurophysiological disorders. The
extracted information could be used to manipulate or coerce
users, or otherwise harm them. The impact of “brain malware”
could be severe, in terms of privacy and other important
values. A question arises: is it in the public interest to allow
anyone to have an unrestricted access to the private information
extractable from neural signals? And if not, how should we
grant such access, and how can this be managed, regulated or
otherwise controlled?
While federal law protects medical information [14] and
generally guards against unfair or deceptive practices [5], few
rules or standards currently limit access to BCI-generated
data. Importantly, platforms are immunized for apps that thirdparties submit, such that BCI-manufactures are not necessarily
incentivized, from a legal vantage, to police against abusive
apps.
We believe emerging BCI privacy concerns call for a coordinated response by engineers and neuroscientists, lawyers and
ethicists, government and industry. Ideally, devices, algorithms,
standards and regulations can be designed to mitigate BCI
privacy problems and ethical challenges. The first step towards
doing so should be an open discussion between ethicists, legal
experts, neuroscientists and engineers.
To facilitate the interdisciplinary discussion, in this paper
we first give an overview of the BCI technologies in Section II.
We then, in Section III, present current ethical and legal issues,
and in Setion IV privacy and security considerations in neural
engineering. We next present a comprehensive model of an
attacker that exploits BCI technology to extract users’ private
information in Section V. In Section VI, we motivate the need
for a coordinated approach to protect BCI systems, and discuss
some legal and regulatory steps to enhance privacy and security
of users, including striking a potentially different balance with
respect to BCI apps than other third-party software. In Section

BCI SYSTEM

VII, we introduce one engineering approach to containing BCIenabled attacks. Finally, section VIII concludes the paper.

SIGNAL PROCESSING
SIGNAL
ACQUISITION

II.

Digitized
signal

Feature
extraction

Translation
algorithm

OVERVIEW OF BCI T ECHNOLOGIES
Neuroprosthesis
control

A Brain-Computer Interface (BCI) is a communication
system between the brain and the external environment. In this
system, messages between an individual and an external world
do not pass through the brain’s normal pathways of peripheral
nerves and muscles. Instead, messages are typically encoded
in electrophysiological signals, such as electroencephalograms
(EEG), signals directly measuring electrical potentials produced by neural synaptic activities [41]–[43].

Neuroprosthesis

P300 Speller
control
P300 Speller

Neurogame
control
Neurogame

The initial motivation for the development of BCIs came
from the growing recognition of the needs of people with
disabilities, and of potential benefits BCIs might offer. The
first BCI was developed in the 1970s [42]. Since then, many
research programs have focused on the development of BCIs,
for assistance, augmentation and repair of cognitive and sensorimotor capabilities of people with severe neuromuscular
disorders, such as spinal cord injuries or amyotrophic lateral
sclerosis.
In recent years, however, BCIs have seen a surge in popularity in fiction, gaming, entertainment and marketing. There
are currently several consumer-grade BCI-based systems (e.g.,
Emotive System [3], NeuroSky [8], and g-tec Medical Engineering [4]) offering relatively low-cost EEG-based BCIs and
software development kits to support and facilitate expansion
of BCI-enabled applications. The supported applications can
broadly be classified into: (i) accessibility tools, such as mindcontrolled mouse and keyboard, (ii) hands-free arcade games,
such as Brain Bats, mind-controlled Pong game [2], and (iii)
“serious games”, i.e., games with purpose other than pure
entertainment, such as attention and memory training [45].
BCIs are also emerging as a tool for personalized entertainment. It has been known for a while that the ability
to infer about a user’s cognitive processes and emotional
responses, such as satisfaction, boredom or confusion, enables
the development of more adaptive and responsive entertainment products. There already exist several gaming consoles
that use pressure, motion, or gaze sensors to make inferences
about a user’s behavioral states [31]. Very recently researchers
from Taiwan have proposed a method of predicting success
of an online game by analyzing a user’s electromyographic
(EMG) signals (i.e., electrical signals produced by a user’s
skeletal muscles) over the first 45 minutes of the game [17].
In addition to the gaming and entertainment industries,
in recent years market research companies have also shown
an increased interest in BCI-enabled technologies. In 2008,
for example, the Nielsen company has introduced the Mynd,
an EEG-based BCI device specifically developed for market
research [31]. It is reasonable to expect more and more
information about users’ cognitive and behavioral processes,
as well as their emotional states will be extracted (with
and without permission) for a variety of entertainment and
marketing studies, as BCI-enabled applications become more
widespread.

Fig. 1.

High-level block diagram of a typical brain-computer interface.

A. Components of a BCI
A BCI is a system used to translate electrophysiological
signals, reflecting activity of central nervous system, into a
user’s intended messages that act on the external world [42].
From an engineering perspective, it is a communication system,
consisting of inputs (user’s neural activity), outputs (external
world commands), and components translating inputs to outputs, known as signal acquisition and signal processing. A
high-level block diagram of a typical BCI is depicted in Figure
1. Current BCIs have information transmission rate between 10
and 25 bits/minute [42].
Based on the recording location, BCIs can be divided into:
(i) invasive, (ii) moderately invasive, and (iii) non-invasive
systems. Invasive BCIs involve electrodes or electrode arrays
that are directly implanted into the brain during a surgery.
They enable the highest quality measurements of neural activity. Moderately invasive BCIs, such as electrocorticography
(ECoG) are implanted inside the skull, typically on top of
the brain. They provide signals of lower noise and higher
selectivity than non-invasive BCIs, which record neural signals
from the scalp. Most non-invasive BCIs are based on electroencephalography (EEG). While known to be susceptible to
noise and signal distortion, EEG signals are easily measurable.
In addition, EEG-based BCIs have relatively low cost and
low risk, which makes them the most widely used BCI
devices [41].
Signal processing component of a BCI typically consists
of two parts: feature extraction and decoding (translation)
algorithms. Feature extraction part processes recorded neural
signals, in order to extract signal features, assumed to reflect
specific aspects of a user’s current neural signal. Decoding
algorithms take those abstracted feature vectors and transform
them into application-specific commands. Depending on the
application, many different decoding algorithms are being used
in BCIs. As pointed out in [42], effective decoding algorithms
are able to adapt to: (1) individual user’s signal features,
(2) spontaneous variations in recorded signal quality, and (3)
adaptive capacities of the brain (neural plasticity).

III.

E THICAL AND L EGAL C ONSIDERATIONS OF N EURAL
E NGINEERING

With an increasing number of neural engineering applications, specifically BCIs and neural imaging, researchers have
recognized the need to address emerging ethical and legal
questions [20], [22], [24], [25], [27], [38]. In 2003, Jonsen introduced neuroethics as “a discipline that aligns the exploration
and discovery of neurobiological knowledge with human value
system”. It was recognized neuroethics will have to address
questions related to (a) incidental findings, (b) surrogate and
biomarkers of diseases, and (c) commercialization of cognitive
neuroscience [25].
In 2005, The Committee on Science and Law considered
possible legal implications of neural engineering [38]. An
emphasis was put on privacy implications of neural imaging,
in particular on the use of neural imaging in non-medical
research. The committee recognized neuromarketing, defined
as the field of marketing research that studies consumers’
sensorimotor, cognitive, and affective response to marketing
stimuli [10] and brain fingerprinting, defined as a technique
that purports to determine the truth by detecting information
stored in the brain [38], as emerging non-medical areas using
neural imaging data. The committee observed there are important similarities between genetic and brain data, in that:
(1) “both genetic and brain data hold out the promise of
prediction (not only disease, but also behavior)”, and (2) “both
types of information expose unique and personal, and to a
large extent, uncontrollable aspects of a person that previously
were unobservable” [38]. Based on these observations, the
committee proposed exploring and leveraging for neuroethics
those medical, ethical and legal rules already set forth in
genetic research.
In [22], Farahany observed modern neuroscience and neural engineering pose an novel set of legal challenges to the
existing Self-Incrimination doctrine of the Fifth Amendment,
which states that “no person shall be compelled to prove a
charge from his own mouth, but a person may be compelled to
provide real or physical evidence” [22]. The author presented
several examples, showing how is modern neuroscience expected to facilitate evidence collection during criminal investigation. The presented examples strongly indicate the traditional
border between testimonial and physical evidence becomes
blurry when applied to the evidences collected by neural
engineering techniques.
Finally, at the 2011 Ethicomp conference, Whalstrom et al.
introduced the question of BCI privacy. The authors reviewed
European Union’s privacy directives and analyzed how do its
legal context and requirements apply to the emerging BCI
privacy issues [40].
IV.

P RIVACY AND S ECURITY I SSUES IN N EURAL
E NGINEERING

A. Neural Signals for Identification and Authentication
Based on the observation that neural signals of each individual are unique and can therefore be used for biometrics [29],
many researchers have recognized potential benefits of using
neural data for user identification and authentication [29],
[32]–[34], respectively defined as the identity selection out of a

set of identities (identification) and verification that the claimed
identity is valid (authentication). EEG signals have shown to
be particularly useful for these applications.
In [34], a method using α-rhythm was proposed for identification, and correct classification scores in the range of 72%
to 84% were reported. Further, an EEG-based identification
method that uses data collected only from the two frontal
electrodes was proposed in [36]. In [35], the authors present an
overview of biometric identification methods based on EEG,
electrocardiogram (ECG) and the skin conductance signals,
also known as electrodermal response (EDR).
In [29], the practicability of different mental tasks for
authentication was investigated, and it was shown that some
tasks are more appropriate for authentication than others.
Finally, [16] proposed neural data can be used to prevent
coercion attacks (also known as rubber hose cryptanalysis),
where users are forced to reveal cryptographic secrets known
to them. The proposed approach is based on the idea of implicit
learning. Instead of asking users to consciously memorize a
secret and use it for identification and authentication, in this
approach the users are identified and authenticated based on
specific patterns that they have learned and can use without
ever being aware they know them.
B. Neurosecurity
In 2009, Denning et al. [21] recognized that “the use of
standard engineering practices, medical trials, and neuroethical
evaluations during the design process can create systems that
are safe and that follow ethical guidelines; unfortunately, none
of these disciplines currently ensure that neural devices are
robust against adversarial entities trying to exploit these devices to alter, block, or eavesdrop on neural signals”. Potential
security threats that can be mounted against implanted neural
devices were identified, and the term “neurosecurity” was introduced as “the protection of the confidentiality, integrity, and
availability of neural devices from malicious parties with the
goal of preserving the safety of a person’s neural mechanisms,
neural computation, and free will” [21].
C. Brain Spyware - BCI-enabled Malicious Application
At the 2012 USENIX Security Symposium, Martinovic
et al. [31] presented the first malicious software designed to
detect a user’s private information using a BCI. They referred
to is as the “brain spyware”. The authors used a commercially
available BCI to present users with visual stimuli and record
their EEG neural signals. They focused on the P300 response,
and analyzed the recorded signals in order to detect users’:
(a) 4-digit PINs, (b) bank information, (c) months of birth, (d)
locations of residence, and (e) if they recognized the presented
set of faces.
While the authors of [31] have focused only on the P300
response, it is not hard to imagine brain spyware applications
being developed to extract private information about users’
memories, prejudices and beliefs, but also about their possible
neurophysiological disorders. Currently, there does not seem to
exist a way to resist these attacks. Moreover, recent results [28]
show that attempts at willful deception can themselves be
detected from an individual’s neural signals. Going a step
further, the same authors [28] show that non-invasive brain

Fig. 2. A simplified diagram of a compromised BCI system. We distinguish between two types of attackers: (1) an attacker who exploits the legitimate feature
extraction and decoding (translation) algorithms (denoted as solid color blocks in the diagram), and (2) an attacker who implements additions algorithms for
malicious applications and either replaces or supplements the legitimate BCI resources (denoted as dotted-background blocks in the diagram).

stimulators, emitting imperceptible DC electrical currents, can
be used to make a user’s responses noticeably slower when
attempting to lie.
Thus, there is a growing need to address the potential
privacy and security risks arising from the use of BCIs, in
both medical and non-medical applications. As a first step, we
are exploring which components of the EEG signal can be
used to infer private information about a user, and quantifying
the amount of exposed information.
V.

extraction and decoding algorithms that are intended for the
legitimate BCI applications.
The second type of an attacker extracts users’ private information by adding or replacing the legitimate BCI components.
Such an attacker implements additional feature extraction and
decoding algorithms, and either replaces or supplements the
existing BCI components with the additional malicious code.
As can be observed from the Figure, the difference between
the two attacker types is only in the structure of the “brain
malware” component.

T HREAT M ODEL

Consider an example model of an attacker who uses
BCIs to extract private information about users. We assume
this will involve non-invasive BCI devices, mostly intended
for consumer use. Manufacturers of non-invasive EEG-based
BCIs generally distribute software development kits and guides
with their products, as well as technical support. Their intention is to promote application development, but such “opendevelopment” platforms may compromise user privacy and security, since there is currently no review process, standards and
guidelines in place to protect users, nor technical protection to
restrict inappropriate or malicious BCI use.
As depicted in Figure 1, a typical BCI system consists of
three main components: (R1) an acquisition system, (R2) an
application, and (R34) a signal processing system, where the
signal processing system consists of (R3) feature extraction
and (R4) decoding (translation) algorithm components. The
existing BCI open-development platforms typically grant every
application developer full control over all four of these components. For the discussion of this paper, we will assume an
attacker has an access to all of these resources (R1)–(R4). We
next consider how an attacker uses these resources to develop
malicious applications.
A. Types of Attackers
In Figure 2, two types of attackers are shown (as described
in the caption). We distinguish between these types based on
the way an attacker analyzes recorded neural signals. The
first type of an attacker extracts users’ private information
by hijacking the legitimate components of a BCI system.
Such an attacker exploits for malicious purposes those feature

B. Methods of Extracting Private Information
We consider scenarios where an attacker interacts with
users by presenting them with specific sets of stimuli, and
recording their responses to the presented stimuli. In the
current literature, there are several well-established methods
of presenting stimuli to users:
•

Oddball paradigm - a technique where users are
asked to react to specific stimuli, referred to as target
stimuli, hidden as rare occurrences in a sequence of
more common, non-target stimuli [23].

•

Guilty knowledge test - a technique based on the
hypothesis that a familiar stimulus evokes a different
response when viewed in the context of similar, but
unfamiliar items [44].

•

Priming - a technique that uses an implicit memory
effect where one stimulus may have an influence on
a person’s response to a later stimulus [39].

We assume an attacker can use any of these methods to
facilitate extraction of private information. In addition, an
attacker can present malicious stimuli in an overt (conscious)
fashion, as well as in a subliminal (unconscious) way, with
subliminal stimulation defined as the process of affecting
people by visual or audio stimuli of which they are completely
unaware [15]. Ways of achieve unawareness typically include
reducing a stimulus intensity or duration below the required
level of conscious awareness.

Fig. 3. A simplified diagram of a BCI with the “BCI Anonymizer” subsystem. Legitimate interpretation component (denoted as solid blocks in the diagram)
requests data and receives response from the “BCI Anonymizer” (denoted as dashed background blocks in the diagram). Malicious components, added by the
adversary (denoted as dotted background blocks in the diagram), may request data, but will not receive response from the “BCI Anonymizer”. In addition, an
attacker cannot access states and functionality of “BCI Anonymizer” components .

C. Examples of “Brain Malware” Information Misuse
Private information about BCIs users, extracted using
“brain malware”, may be of interest to multiple parties, those
using it for greater good and potential improvement of the
quality of humans lives, but also to those using it to increase
their own (financial) gains, as well as those using it simply to
harm others. One can easily imagine the following examples
of concerning BCIs use:
Example 1: As exemplified in Farahaney’s work [22],
an access to an individual’s memories and emotional
responses might be used by police enforcement and
government agencies during criminal investigation, as
well as for crime and terrorism prevention.
Example 2: BCI-recorded neural signals may be used
in a variety of entertainment and relaxation applications. A person’s emotional response and satisfaction/annoyment level may, for example, be used to
provide better (more accurate) music and/or movie
recommendations. Similarly, information about a person’s activity and anxiety levels may be used to tailor
a more personalized training routine or a relaxation
session.
Example 3: Personal information, extracted from
neural signals, could also be used for targeted advertisement, where in addition to (or instead of) information about a person’s activities on the Internet, an
advertiser/retailer would have a real-time access to a
person’s level of interest, satisfaction, or frustration
with the presented material.
Example 4: On the other end of the spectrum, however, the extracted information about a person’s memories, prejudices, beliefs or possible disorders could
be used to manipulate a person or coerce her/him into
doing something.
Example 5: Finally, the extracted neural information
could also be used to cause physical or emotional harm
to a person. Examples of such actions have already
been observed in the literature. Denning et al. [21],
presented the case of individuals who placed flashing
animations on epilepsy support webpages, eliciting
seizures in some patients with photosensitive epilepsy.

VI.

T HE N EED FOR A C OORDINATED P REVENTION
A PPROACH

Issues arising from misuse or inappropriate use of BCI
technology most likely do not pose a critical concern yet,
considering their limited use outside of research communities.
However, existing and emerging privacy and security threats
may be viewed as an attack on human rights to privacy
and dignity [13]. Thus, they deserve immediate attention and
careful consideration.
We suggest that methods to prevent and mitigate BCIenabled privacy and security threats must be developed now,
in the early design phase. Doing so will allows us to keep
up with Privacy-by-Design [1] values, as well as with general
values of privacy-enhancing technologies.
We view the development of prevention and mitigation
tools as an interdisciplinary effort, involving neuroscientists,
neural engineers, ethicists, as well as legal, security and privacy
experts. The first step of this interdisciplinary approach should
be an open discussion, aimed at answering the following
questions: (i) Who all should be allowed an access to individuals’ neural signals? (ii) Which components of these neural
signals should those entities have an access to? (iii) How noisy,
distorted or distilled should these components be made before
making them available? (iv) Which purposes are the entities
allowed to use the neural signals for? and (v) What are the
risks associated with the misuse of the provided components,
i.e., what amount of private information can be extracted from
the provided components?
We expect the answers to questions (i)–(v) will lead to a
“triangle” approach towards enhancing privacy and security
of BCI technology. On one vertex of the triangle, we expect
to have legal experts and ethicists, defining a set of laws and
policies to govern legal use of neural signals. As an example of
possible legal intervention, the law could examine should the
BCI platforms indeed be immunized for the apps they sell, or
is some other balance between manufacturers and application
developers more appropriate for BCI technologies.
On the second vertex, we expect to have a group of
neuroscientists and engineers, in charge of developing and
establishing a set of industry and research standards, methods,
processes and practices for secure and privacy-preserving BCI

systems. One such practice may, for example, require there
to exist a centralized authority in charge of reviewing and
validating every BCI application before allowing its use in
general population.
Finally, at the third vertex we expect BCI systems manufacturers and application developers, developing, implementing
and using engineering practice, methods and tools, in order to
prevent and mitigate specific classes of security and privacy
attacks. Clearly the IEEE, and its standards process, could have
a role here.
VII.

We view the development of these prevention and mitigation tools as an interdisciplinary effort, involving neuroscientists, neural engineers, ethicists, as well as legal, privacy
and security experts. This paper represents an initial step
towards facilitating the necessary interdisciplinary discussion
and starting the effort to make BCI systems inherently privacy preserving and secure. We are currently examining the
best legal and policy infrastructure BCIs, and experimenting
with engineering approaches that could lead to best privacy
enhancing practices.
R EFERENCES

BCI A NONYMIZER

One engineering approach to enhancing neural privacy and
security is the use of the “BCI Anonymizer” [18]. The basic
idea of the “BCI Anonymizer” is to pre-process neural signals,
before they are stored and transmitted, in order to remove all
information except specific intended BCI commands. Unintended information leakage is prevented by never transmitting
and never storing raw neural signals and any signal components that are not explicitly needed for the purpose of BCI
communication and control.
The “BCI Anonymizer” can be realized either in hardware
or in software, as a part of the user’s BCI device, but not
as part of any external network or computational platform.
It thus acts as a secured and trusted software or hardware
subsystem that takes the raw neural signal and decomposes it
to specific components. Upon request, instead of the complete
recorded neural signal, the “BCI Anonymizer” provides a BCI
application only with a needed subset of requested signal
components. A block diagram of a BCI system with the
proposed “BCI Anonymizer” component is depicted in Figure
3. A critical task in the development of this approach is the
development of fast and accurate signal processing tools for
real time decomposition of neural signals.
The described approach is similar to the approaches taken
in the smartphone security, where an attacker, using a malicious smartphone app, can attempt to access a user’s private
identifying information (PII), such as a user’s location or
address book entries. In the smartphone industry, such attacks
on a user’s privacy are typically prevented by limiting an access
to the phone’s operating system and a user’s PII. In other
words, an application has an access only to a limited subset
of PII data and operating system states and functionalities
(for examples of current prevention and mitigation strategies,
please see e.g., [19], [30]). Neural signals, acquired by BCI
recording electrodes, have a similar role as a user’s smartphone
PII data, in that they contain information beyond the intended
information.
VIII.

C ONCLUSION

Privacy and security threats arising from the use of BCIenabled technologies may not pose a critical concern at this
moment, given a fairly limited deployment of BCI systems
outside of research and medical communities. We believe,
however, the right time to address these issues is now, and
propose that methods to prevent and mitigate BCI-enabled
privacy and security threats should be developed in the early
design phase, and embedded throughout the entire life of the
technology.

[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]

[17]
[18]
[19]

[20]
[21]
[22]
[23]

[24]
[25]

[26]
[27]

Privacy by Design (last accessed January 19, 2014).
Brain Bats: Mind-Controlled Pong (last accessed: January 19, 2014).
Emotiv Systems (last accessed: January 19, 2014).
g-tec Medical Engineering (last accessed: January 19, 2014).
Federal Trade Commission Act.
NeuroFocus (last accessed: January 14, 2014).
NeuroGaming 2013 Conference and Expo (last accessed: May 10,
2013).
NeuroSky (last accessed: January 19, 2014).
Neurocam(last accessed: January 19, 2014).
What is Neuromarketing? A Discussion and Agenda for Future Research.
How the Brain Translates Money into Force: a Neuroimaging Study of
Subliminal Motivation.
Samsung Demos a Tablet Controlled by Your Brain (last accessed:
January 19, 2014).
The Universal Declaration of Human Rights (last accessed January 26,
2014).
The Health Insurance Portability and Accountability Act of 1996
(HIPAA) Privacy and Security Rules, 1996.
R. B. Baldwin. Kinetic Art: On the Use of Subliminal Stimulation of
Visual Perception. Leonardo, pages 1–5, 1974.
H. Bojinov, D. Sanchez, P. Reber, D. Boneh, and P. Lincoln. Neuroscience Meets Cryptography: Designing Crypto Primitives Secure
Against Rubber Hose Attacks. In Proceedings of the 21st USENIX
Security Symposium. USENIX, 2012.
Y.-T. Chiu. Mind Reading to Predict the Success of Online Games,
February 2013.
H.J. Chizeck and T. Bonaci. Brain-computer interfaces anonymizer. US
Patent Application, February 2014.
B.-G. Chun and P. Maniatis. Augmented Smartphone Applications
through Clone Cloud Execution. In the Proceedings of the 12th
Conference on Hot Topics in Operating Systems. USENIX Association,
2009.
J. Contreras-Vidal. Ethical Considerations Behind Brain-Computer
Interface Research, December 2012.
T. Denning, Y. Matsuoka, and T. Kohno. Neurosecurity: Security and
Privacy for Neural Devices. Neurosurgical Focus, 27(1):1–4, 2009.
N. Farahany. Incriminating Thoughts. Stanford Law Review, 64:11–17,
2011.
S.A. Huettel and G. McCarthy. What is Odd in the Oddball Task?
Prefrontal Cortex is Activated by Dynamic Changes in Response
Strategy. Neuropsychologia, 42(3):379–386, 2004.
J. Illes, M.P. Kirschen, J.D.E. Gabrieli, et al. From Neuroimaging to
Neuroethics. Nature Neuroscience, 6(3):205–205, 2003.
J. Illes and E. Racine. Imaging or Imagining? A Neuroethics Challenge
Informed by Genetics. The American Journal of Bioethics, 5(2):5–18,
2005.
M. Inzlicht, I. McGregor, J.B. Hirsh, and K. Nash. Neural Markers of
Religious Conviction. Psychological Science, 20(3):385–392, 2009.
A. R. Jonsen. The Birth of Bioethics. Oxford University Press, USA,
2003.

[28]

[29]

[30]

[31]

[32]

[33]

[34]

[35]

[36]

[37]

[38]
[39]

[40]

[41]

[42]

[43]
[44]

[45]

B. Luber, C. Fisher, P.S. Appelbaum, M. Ploesser, and S.H. Lisanby.
Non-invasive Brain Stimulation in the Detection of Deception: Scientific
Challenges and Ethical Consequences. Behavioral Sciences & the Law,
27(2):191–208, 2009.
S. Marcel and J.R. Millán. Person Authentication Using Brainwaves
(EEG) and Maximum A Posteriori Model Adaptation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(4):743–752,
2007.
C. Marforio, A. Francillon, and S. Capkun. Application Collusion
Attack on the Permission-based Security Model and its Implications
for Modern Smartphone Systems. Department of Computer Science,
ETH Zurich, 2011.
I. Martinovic, D. Davies, M. Frank, D. Perito, T. Ros, and D. Song. On
the Feasibility of Side-Channel Attacks with Brain-Computer Interfaces.
In the Proceedings of the 21st USENIX Security Symposium. USENIX,
2012.
R. Palaniappan and K.V.R. Ravi. A New Method to Identify Individuals
Using Signals From the Brain. In the Proceedings of the 4th Joint
Conference on Information, Communications and Signal Processing.,
volume 3, pages 1442–1445, 2003.
R.B. Paranjape, J. Mahovsky, L. Benedicenti, and Z. Koles. The Electroencephalogram as a Biometric. In the Proceedings of the Canadian
Conference on Electrical and Computer Engineering, volume 2, pages
1363–1366, 2001.
M. Poulos, M. Rangoussi, V. Chrissikopoulos, and A. Evangelou.
Person Identification Based on Parametric Processing of the EEG. In the
Proceedings of the 66th IEEE International Conference on Electronics,
Circuits and Systems, volume 1, pages 283–286, 1999.
K. Revett and S. T. de Magalhães. Cognitive Biometrics: Challenges
for the Future. In Global Security, Safety, and Sustainability, pages
79–86. Springer, 2010.
A. Riera, A. Soria-Frisch, M. Caparrini, C. Grau, and G. Ruffini. Unobtrusive Biometric System Based on Electroencephalogram Analysis.
EURASIP Journal on Advances in Signal Processing, 2008, 2007.
J.P. Rosenfeld, J.R. Biroschak, and J.J. Furedy. P300-based Detection of
Concealed Autobiographical Versus Incidentally Acquired Information
in Target and Non-target Paradigms. International Journal of Psychophysiology, 60(3):251–259, 2006.
The Committee on Science and Law. Are Your Thoughts Your Own?:
Neuroprivacy and the Legal Implications of Brain Imaging, 2005.
M. van Vliet, C. Mühl, B. Reuderink, and M. Poel. Guessing What’s
on Your Mind: Using the N400 in Brain Computer Interfaces. Brain
Informatics, pages 180–191, 2010.
K. Wahlstrom, N. B. Fairweather, and H. Ashman. Brain-Computer
Interfaces: A Technical Approach to Supporting Privacy. In the
Proceedings of the 12th International Ethicomp Conference: The Social
Impact of Social Computing, 2011.
J. R. Wolpaw, N. Birbaumer, W. J. Heetderks, D. J. McFarland, P. H.
Peckham, G. Schalk, E. Donchin, L. A. Quatrano, C. J. Robinson, and
T. M. Vaughan. Brain-Computer Interface Technology: A Review of
the First International Meeting. IEEE Transactions on Rehabilitation
Engineering, 8(2):164–173, 2000.
J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and
T. M. Vaughan. Brain-Computer Interfaces for Communication and
Control. Clinical Neurophysiology, 113(6):767–791, 2002.
J. R. Wolpaw and E. W. Wolpaw. Brain-Computer Interfaces: Principles
and Practice. OUP USA, 2012.
P.R. Wolpe, K.R. Foster, and D.D. Langleben. Emerging Neurotechnologies for Lie-detection: Promises and Perils. The American Journal
of Bioethics, 10(10):40–48, 2010.
M.-S. Yoh, J. Kwon, and S. Kim. NeuroWander: A BCI Game in the
Form of Interactive Fairy Tale. In the Proceedings of the 12th ACM
International Conference Adjunct Papers on Ubiquitous Computing,
pages 389–390. ACM, 2010.

