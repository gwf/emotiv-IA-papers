Hindawi
Computational Intelligence and Neuroscience
Volume 2018, Article ID 6265108, 11 pages
https://doi.org/10.1155/2018/6265108

Research Article
Multiclass Motor Imagery Recognition of Single Joint in
Upper Limb Based on NSGA- II OVO TWSVM
Shan Guan , Kai Zhao

, and Fuwang Wang

School of Mechanical Engineering, Northeast Electric Power University, 132012 Jilin, China
Correspondence should be addressed to Shan Guan; guanshan1970@163.com
Received 19 April 2018; Accepted 7 June 2018; Published 28 June 2018
Academic Editor: PlaÌcido R. Pinheiro
Copyright Â© 2018 Shan Guan et al. This is an open access article distributed under the Creative Commons Attribution License,
which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
In the study of the brain computer interface (BCI) system, electroencephalogram (EEG) signals induced by different movements of
the same joint are hard to distinguish. This paper proposes a novel scheme that combined amplitude-frequency (AF) information
of intrinsic mode function (IMF) with common spatial pattern (CSP), namely, AF-CSP to extract motor imagery (MI) features, and
to improve classification performance, the second generation nondominated sorting evolutionary algorithm (NSGA-II) is used to
tune hyperparameters for linear and nonlinear kernel one versus one twin support vector machine (OVO TWSVM). This model is
compared with least squares support vector machine (LS-SVM), back propagation (BP), extreme learning machine (ELM), particle
swarm optimization support vector machine (PSO-SVM), and grid search OVO TWSVM (GS OVO TWSVM) on our dataset; the
recognition accuracy increased by 5.92%, 22.44%, 22.65%, 8.69%, and 5.75%. The proposed method has helped to achieve higher
accuracy in BCI systems.

1. Introduction
BCI is a technology that enables the brain to establish
communication and control directly between human brain
and computer or other electronic devices without the help
of peripheral nerves and limbs [1, 2]. BCI technology not
only enhances the ability of disabled patients to communicate
with the outside world in the field of medical rehabilitation
[3, 4], but also has wide applications in smart home, mass
consumption and entertainment, military, and other fields.
At present, the research direction of BCI system is mainly in
the following aspects: sensorimotor (SMR) [5], slow cortical
potential (SCP) [6], P300 event-related potential [7], and
steady-state visual evoked potential (SSVEP) [8]. The most
widely used is the SMR BCI system based on motor imagery.
The ğœ‡ (8-13Hz) and ğ›½ (13-30Hz) rhythms in EEG signals
will cause a phenomenon named event-related desynchronization (ERD) and event-related synchronization (ERS)
when motor imagery occurs [9, 10]. This means that the
rhythmic activities of the brain represent frequency specific
changes may consist either of decreases or of increases of

power in given frequency bands. The ERD/ERS phenomenon
is an important basis for the BCI systems of motor imagery.
In order to improve the classification accuracy of the
BCI system, researchers have studied the feature extraction
methods and classification methods of EEG signals [11â€“15].
The most commonly used feature extraction methods include
wavelet packet transform (WT), Fourier transform (FT), CSP
[16, 17], and autoregressive (AR) model. The classification
methods include linear discriminant analysis (LDA), support
vector machine (SVM), neural network (NN), and so on.
Wang et al. used the convolution neural network (CNN) to
recognize the image of the brain topographic map of three
kinds of motor imagery movements of the upper limb, flexion
wrist, and wrist external rotation, and the highest recognition
rate in the three classification experiments is 67.89% [18]. Roy
et al. carried out Hilbert transform for two kinds of motor
imagery of shoulder and elbow joint and used discrete wavelet
transformation to extract features; SVM gets the highest
recognition rate of 84.91% in the five recognition methods
[19]. Sachin et al. used empirical mode decomposition (EMD)
to extract the energy features of left and right hand motor

2

Computational Intelligence and Neuroscience

AF4

AF3
F7

F8

F4

F3

Emotiv Epoc+

FC5

FC6

T7

T8
CMS

DRL

P7

P8
O1

(a)

O2

(b)

Figure 1: (a) Experimental photos and Emotiv Epoc+ and (b) Emotiv 14 electrodes located over 10-20 international system positions.

imagery EEG signals and classified them using LS-SVM;
the recognition rate is no less than 95.56% [20]. Tang et al.
used PSO to optimize the hidden-layer visible deep stacking
network (HVDSN) to recognize the left and right hand motor
imagery EEG signals; the recognition rate is no less than
89.84% [21]. Although the above studies have achieved high
recognition results, most of the research focuses on hands and
feet motor imagery, few studies have been conducted based
on multiclass motor imagery of single joint.
In this paper, we propose a method to improve accuracy
of motor imagery BCI using AF-CSP and an optimized OVO
TWSVM classifier. The proposed method is composed of a
total of four stages. First, a notch filter and common average
reference (CAR) are used to remove noise in EEG signal.
Second, EMD is used to obtain IMF, and FFT is used to obtain
AF information of the IMF. Third, the NSGA-II is used to tune
hyperparameters for linear and nonlinear OVO TWSVM.
Finally, an optimized OVO TWSVM classifier is evaluated
using laboratory data sets (three kinds of motor imagery of
shoulder flexion, extension, and abduction) and compared
with state-of-the-art algorithms (LS-SVM, BP, ELM, PSOSVM, and GS OVO TWSVM).

2. Materials and Methods
Emotiv Epoc+ is used to collect EEG data of motor imagery.
It is a portable EEG acquisition device with a sampling rate
of 128Hz. It has fourteen electrode channels (AF3, F7, F3,
FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, and AF4) and
two inference electrodes (CMS, DRL), and the electrode
placement follows the international 10-20 standard. Experimental photos, equipment, and the Emotiv 14 electrodes are
located over 10-20 international system positions as shown in
Figure 1. This experiment collected three kinds of EEG signals
of one joint: imagination of shoulder flexion, extension, and
abduction, as shown in Figure 2.
Seven subjects participated in this experimental study.
These subjects were in good health. During the experiment,
subjects were naturally placed with both hands, trying to
avoid body or head movement. During the experiment,
subjects carried out motor imagery under the outside cue,

a single experiment collected EEG signal for 5 seconds, and
then take 5-7 seconds to have a rest; each action repeated
acquisition 20 times. The experimental process is shown in
Figure 3. The dimension of EEG is high and the amount of
data is large, in order to reduce the computational complexity.
In this paper, the EEG signals collected from four electrode
channels of FC5, F3, F4, and FC6 were selected for the
following motor imagery analysis.

3. Theories and Methods
3.1. Data Preprocessing. EEG signals contain a variety of
noise, and it is necessary to perform spatial filtering before
feature extraction of the signal. First, the 50Hz notch filter
is used to remove the power frequency noise. McFarland
et al. compared four kinds of spatial filtering technology to
improve the SNR of EEG signal, and the conclusion shows
the superiority of CAR and large Laplacian methods [21]; this
paper uses CAR method as the spatial filter. The calculation
of CAR is to subtract the average of all the electrodes from the
selected channel. The formula for calculation is as follows:
1 4
ğ‘‰ğ‘–ğ¶ğ´ğ‘… = ğ‘‰ğ‘–ğ‘…ğ´ğ‘Š âˆ’ âˆ‘ğ‘‰ğ‘—ğ‘…ğ´ğ‘Š
4 ğ‘—=1

(1)

where ğ‘‰ğ‘–ğ¶ğ´ğ‘… is filtered potential and ğ‘‰ğ‘–ğ‘…ğ´ğ‘Š is the potential of
the ğ‘– electrode.
3.2. Empirical Mode Decomposition. EMD is used to stabilize
the nonstationary signals and obtain IMF. The specific EMD
decomposition process is given in document [22]. EEG signal
can be decomposed into IMF components after the empirical
mode decomposition, and the expression is as follows:
ğ‘

ğ‘† (ğ‘¡) = âˆ‘ğ¶ğ‘– (ğ‘¡) + ğ‘…ğ‘› (ğ‘¡)

(2)

ğ‘–=1

where ğ‘†(ğ‘¡) represents the original EEG signal, ğ¶ğ‘– (ğ‘¡) is the ğ‘–ğ‘¡â„
IMF, and ğ‘…ğ‘› (ğ‘¡) is residual components after screening.
Taking the 1-4s data of the F3 electrode channel in
Figure 3, as an example, use EMD method to decompose

Computational Intelligence and Neuroscience

3

Extension
Abduction
Flexion

(a)

(b)

(c)

Figure 2: Three movements of shoulder joint: (a) flexion, (b) extension, and (c) abduction.

Rest 5-7 seconds

where ğ‘ˆğ¶ is the eigenvector matrix and ğ´ ğ¶ is the eigenvalue
diagonal matrix. Whitening matrix ğ‘ƒ is calculated in

Rest 5-7 seconds

data collection

data collection

ğ‘‡
ğ‘ƒ = ğ´âˆ’1/2
ğ¶ ğ‘ˆğ¶

Figure 3: Timing for experimental process.

the denoised signal, and the IMF component is shown in
Figure 4(a). Figure 4(b) is the AF domain information for
the IMF component after FFT. From Figure 4(b), we can see
that the ğœ‡ and ğ›½ rhythms of the motor imagery are mainly
distributed in IMF1 and IMF2. In this paper, the sampled data
of the selected 4 electrode channels are decomposed by EMD,
respectively, do FFT to IMF1 and IMF2 of each electrode
channel, and construct the ğ‘–ğ‘¡â„ experiment EEG data matrix
ğ‘‹ğ‘– (ğ‘– = ğ‘ Ã— ğ‘€), where ğ‘ corresponds to this article is 8 and
ğ‘€ is the selected information of ğœ‡ and ğ›½ rhythms.
3.3. Common Spatial Pattern. The traditional CSP algorithm
is essentially looking for a spatial filter to obtain more obvious
eigenvectors after the signal passed through the filter, which
makes a kind of signal variance reach a maximum, and
another signal reaches a minimum. This method achieves the
purpose of distinguishing two types of signals. Combining AF
information of IMF with CSP to form AF-CSP and applying
one versus one (OVO) strategy to AF-CSP make AF-CSP
suitable for multiple classification problems, and the specific
process is as follows:
ğ‘…=

ğ‘‹ğ‘– ğ‘‹ğ‘–ğ‘‡
ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘’ (ğ‘‹ğ‘– ğ‘‹ğ‘–ğ‘‡ )

(3)

where ğ‘‡ is transpose operator. Then calculate the mixed space
covariance matrix ğ‘…ğ‘ of the two types motor imagery ğ‘…ğ‘™ , ğ‘…ğ‘Ÿ
as follows:

(6)

The whitening matrix causes eigenvalues of transformed
matrix be equal one, so we calculate transformed covariance
matrixes ğ‘†ğ‘— and ğ‘†ğ‘˜ in
ğ‘†ğ‘— = ğ‘ƒğ‘…ğ‘™ ğ‘ƒğ‘‡

(7)

ğ‘†ğ‘˜ = ğ‘ƒğ‘…ğ‘Ÿ ğ‘ƒğ‘‡

(8)

After whitening, the matrixes ğ‘†ğ‘— and ğ‘†ğ‘˜ have the same
eigenvector, and the following formula can be obtained after
the eigenvalue decomposition:
ğ‘†ğ‘— = ğµğ´ ğ‘‡ ğµğ‘‡

(9)

ğ‘†ğ‘˜ = ğµğ´ ğ‘… ğµğ‘‡

(10)

The desired spatial filter is obtained by the upper form
ğ‘Š = (ğµğ‘‡ ğ‘ƒ)ğ‘‡ , and we can get a new data matrix after filtering
by ğ‘Š: ğ‘ğ‘Ã—ğ‘€ = ğ‘Šğ‘Ã—ğ‘€ğ‘‹ğ‘– .Feature vectors can be obtained by
ğ‘“ğ‘ = log (

var (ğ‘ğ‘ )
âˆ‘2ğ‘š
ğ‘–

var (ğ‘ğ‘– )

)

(11)

where ğ‘ğ‘ (ğ‘ = 1, . . . , 2ğ‘š). The dimension of ğ‘“ğ‘ can not
exceed ğ‘ at most; in this paper, we set ğ‘š = 2, so we can get a
vector of four dimensions.
Combined with OVO strategy, eigenvectors constructed
between every two types of actions are
ğ‘“1 = [ğ¹1 , ğ¸1 ]

(12)

(4)

ğ‘“2 = [ğ¹2 , ğ´ 1 ]

(13)

Eigenvalue decomposition for covariance of mixed space
is as follows:

ğ‘“3 = [ğ¸2 , ğ´ 2 ]

(14)

ğ‘…ğ¶ = ğ‘ˆğ¶ğ´ ğ¶ğ‘ˆğ¶ğ‘‡

where ğ‘“1 represents the eigenvector obtained after AF-CSP
transformation of flexion (F 1 ) and extension (E1 ) of shoulder

ğ‘…ğ¶ = ğ‘…ğ‘™ + ğ‘…ğ‘Ÿ

(5)

4

Computational Intelligence and Neuroscience
10
IMF1

50
0

0
1.5

2.0

2.5

3.0

3.5

4.0

0

2.0

2.5

3.0

3.5

4.0

2.5

3.0

3.5

4.0

0
2.0

2.5

3.0

3.5

40

50

60

70

0

10

20

30

40

50

60

70

0

10

20

30

40

50

60

70

0

10

20

30

40

50

60

70

0

10

20

30

40

50

60

70

0

10

20

30

40

50

60

70

10
5

4.0
150
IMF5

0

100
50
0

1.5

2.0

2.5

3.0

3.5

4.0
10
IMF6

âˆ’10
âˆ’20
âˆ’30
1.0

0

0
1.5

100

âˆ’100
1.0
0

30

5
Amplitude (î‹®V)

2.0

IMF4

Amplitude (î‹®V)

1.5

20

âˆ’20
1.0
200

20

10

0
âˆ’50
1.0
40

10

1
0

1.5

IMF3

âˆ’20
1.0
50

0

2
IMF2

âˆ’50
1.0
20

5

1.5

2.0

2.5

3.0

3.5

4.0

5
0

Frequency (Hz)

Time (s)
(a)

(b)

Figure 4: (a) IMF obtained from 3s EEG signals after EMD decomposition. (b) Amplitude-frequency domain information corresponds to
per IMF of Figure 4(a).

joint. ğ‘“2 represents the eigenvector obtained after AF-CSP
transformation of flexion (F 2 ) and abduction (A1 ) of shoulder
joint. ğ‘“3 represents the eigenvector obtained after AF-CSP
transformation of extension (E2 ) and abduction (A2 ) of
shoulder joint.
Figure 5 shows one example of the eigenvector ğ‘“1 constructed by AF-CSP of subject B, and ğ‘“1 is constructed by two
MI tasks of shoulder joint flexion and extension. In Figure 5,
the lateral axis represents the sequence number of experiments and the vertical axis represents the eigenvalue. We
can see clearly from Figure 5 that the selected 4-dimensional
feature vectors constructed by AF-CSP are distinctly distinguishable. The final eigenvector constructed by the AF-CSP
method is
ğ¹1 ğ¹2
]
[
]
[
ğ‘“ = [ ğ¸1 ğ¸2 ]
]
[
[ğ´ 1 ğ´ 2 ]

(15)

3.4. Twin Support Vector Machine. TWSVM, which is developed on the basis of traditional SVM, is a new machine
learning method [23]. For the two-classification problem,
TWSVM constructs a hyperplane for every class of samples,
so that each class sample is closest to its own hyperplane
and far away from another hyperplane. TWSVM solves twoclassification problem by solving a set of quadratic programming problems (QPPs), and SVM solves all classification
problems by solving one QPP. This strategy makes TWSVM
work 4 times faster than a standard SVM [24].
Combine OVO strategy with standard TWSVM to get
OVO TWSVM, and the OVO TWSVM has a better classification performance than the OVO SVM [25]. For ğ‘˜
class classification problem, the algorithm constructs a twoclassification TWSVM subclassifier between any two classes
of samples. Each subclassifier in OVO TWSVM needs only
two classes of samples for training. Two hyperplanes are
needed to train two types of sample ğ‘– and ğ‘—, such as
ğ‘¥ğ‘‡ ğ‘¤ğ‘–ğ‘— + ğ‘ğ‘–ğ‘— = 0

(16)

Computational Intelligence and Neuroscience

Eigenvalue

0
âˆ’1
âˆ’2
0
âˆ’2
âˆ’4
0
âˆ’1
âˆ’2
0
âˆ’2
âˆ’4

5
Subclassifier 1

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

Class 2
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

ğ‘¥ğ‘‡ ğ‘¤ğ‘—ğ‘– + ğ‘ğ‘–ğ‘— = 0

(17)

where ğ‘¤ğ‘–ğ‘— and ğ‘¤ğ‘—ğ‘– are two normal vectors of hyperplanes and
ğ‘ğ‘–ğ‘— and ğ‘ğ‘—ğ‘– are two hyperplanes. It is generally obtained by
solving the following two-quadratic programming problem:
min
s.t.
min
s.t.

1 óµ„©óµ„©
óµ„©2 ğ‘ğ‘–ğ‘—
óµ„©óµ„©ğ´ ğ‘– ğ‘¤ğ‘–ğ‘— + ğ‘’ğ‘–ğ‘—(1) ğ‘ğ‘–ğ‘— óµ„©óµ„©óµ„© + ğ‘’ğ‘–ğ‘—(2)ğ‘‡ ğœ‰ğ‘–ğ‘—
óµ„©
2óµ„©
2
(ğ´ ğ‘– ğ‘¤ğ‘–ğ‘— +

ğ‘’ğ‘–ğ‘—(2) ğ‘ğ‘–ğ‘— )

+ ğœ‰ğ‘–ğ‘— â‰¥

ğ‘’ğ‘–ğ‘—(2) ,

(18)

ğœ‰ğ‘–ğ‘— â‰¥ 0

1 óµ„©óµ„©
óµ„©2 ğ‘ğ‘—ğ‘–
óµ„©óµ„©ğ´ ğ‘— ğ‘¤ğ‘—ğ‘– + ğ‘’ğ‘–ğ‘—(2) ğ‘ğ‘—ğ‘– óµ„©óµ„©óµ„© + ğ‘’ğ‘–ğ‘—(2)ğ‘‡ ğœ‰ğ‘—ğ‘–
óµ„©
2óµ„©
2
(ğ´ ğ‘— ğ‘¤ğ‘—ğ‘– +

ğ‘’ğ‘–ğ‘—(1) ğ‘ğ‘—ğ‘– )

+ ğœ‰ğ‘—ğ‘– â‰¥

ğ‘’ğ‘–ğ‘—(2) ,

s.t.

Class 3

ğœ‰ğ‘—ğ‘– â‰¥ 0

1 óµ„©óµ„©
óµ„©2 ğ‘ğ‘–ğ‘—
óµ„©óµ„©ğ¾ (ğ´ ğ‘– , ğ¶ğ‘‡ ) ğ‘¤ğ‘—ğ‘– + ğ‘’ğ‘–ğ‘—(1) ğ‘ğ‘—ğ‘– óµ„©óµ„©óµ„© + ğ‘’ğ‘–ğ‘—ğ‘‡ ğœ‰ğ‘–ğ‘—
óµ„©
óµ„©
2
2

(20)

(ğ¾ (ğ´ ğ‘– , ğ¶ğ‘‡ ) ğ‘¤ğ‘—ğ‘– + ğ‘’ğ‘–ğ‘—(2) ğ‘ğ‘—ğ‘– ) + ğœ‰ğ‘—ğ‘– = ğ‘’ğ‘–ğ‘—(2) , ğœ‰ğ‘–ğ‘— â‰¥ 0
1 óµ„©óµ„©
óµ„©2 ğ‘ğ‘—ğ‘–
óµ„©óµ„©ğ¾ (ğ´ ğ‘– , ğ¶ğ‘‡ ) ğ‘¤ğ‘—ğ‘– + ğ‘’ğ‘–ğ‘—(2) ğ‘ğ‘—ğ‘– óµ„©óµ„©óµ„© + ğ‘’ğ‘–ğ‘—ğ‘‡ ğœ‰ğ‘—ğ‘–
óµ„©
óµ„©
2
2

use OVO TWSVM. First, calculate the distance from the dot
to the two hyperplanes of subclassifier 1; because the dot is
close to the hyperplane of class 1, class 1 gets 1 vote. Second,
calculate the distance from the dot to the subclassifier 2 in
the same manner; since the dot is close to one hyperplane
of subclassifier 2 in class 1, class 1 gets 1 more vote. Third,
calculate the distance from the dot to the subclassifier 3;
because the dot is close to one hyperplane of subclassifier 3 in
class 2, class 2 got 1 vote and class 3 got 0 vote. OVO TWSVM
classify the classified sample into class 1.
For the three-classification problem of this article,
three OVO TWSVM subclassifiers need to set 6 penalty
parameters: ğ‘11 , ğ‘12 , ğ‘21 , ğ‘22 , ğ‘31 , and ğ‘32 .This article sets
ğ‘11 =ğ‘21 =ğ‘31 , ğ‘12 =ğ‘22 =ğ‘32 .

(19)

where ğ‘ğ‘–ğ‘— is a penalty parameter and ğ‘’ğ‘–ğ‘— is a column vector of
1.
For the nonlinear separable phenomenon of training data,
OVO TWSVM needs to solve the following optimization
problems when training two samples of ğ‘– and ğ‘—:

min

Subclassifier 3

Figure 6: The sketch map of OVO TWSVM.

Figure 5: Twenty sets of four-dimensional eigenvectors ğ‘“1 obtained
by AF-CSP method of flexion and extension of shoulder joint.

s.t.

Subclassifier 2

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
Sequence number of experiments
F1
E1

min

Class 1

3.5. Multiobjective Genetic Algorithm. The core of the multiobjective genetic algorithm is to coordinate the relationship
between the target functions and to make the target functions
reach the Pareto optimal set. The quality of a solution in the
Pareto optimal set is defined according to the dominance
criterion. Any solution ğœ† of the Pareto optimal set can be seen
as an acceptable solution. If a solution ğœ† 1 is no worse than
ğœ† 2 in all objectives and ğœ† 1 is better than ğœ† 2 in at least one
objective, then we define ğœ† 1 dominates ğœ† 2 . The multiobjective
optimization problem can be stated as
Maxmize

(21)

(ğ¾ (ğ´ ğ‘– , ğ¶ğ‘‡ ) ğ‘¤ğ‘—ğ‘– + ğ‘’ğ‘–ğ‘—(1) ğ‘ğ‘—ğ‘– ) + ğœ‰ğ‘—ğ‘– = ğ‘’ğ‘–ğ‘—(1) , ğœ‰ğ‘—ğ‘– â‰¥ 0

Taking three-classification problem in two-dimensional
space as an example to illustrate the process of OVO TWSVM
with Figure 6. Taking ğ‘– and ğ‘— in (21) and (22) as 1 and 2
and solving them, we can get a two-class OVO TWSVM that
classifies class 1 and class 2, i.e., subclassifier 1 in Figure 6.
The subclassifier 2 and the subclassifier 3 can be obtained
by a similar method, which constitute the OVO TWSVM for
solving the three-classification problem together. Taking the
green dot in the figure as an example to illustrate how to

ğ¹ (ğœ”) = {ğ‘“1 (ğœ”) , ğ‘“2 (ğœ”) , . . . , ğ‘“ğ‘› (ğœ”)}

(22)

where ğ‘“1 (ğœ”), ğ‘“2 (ğœ”), . . . , ğ‘“ğ‘› (ğœ”) are the ğ‘› objective functions
and ğœ” represents the parameters of the model.
The NSGA algorithm based on the fitness sharing technique proposed by Goldberg is based on the principle of nondominated sorting to classify individuals in the population.
And it can obtain a uniformly distributed Pareto optimal
set or noninferior solution. However, the shortcomings of
the algorithm are that the computational complexity is high
and the sharing parameters need to be designated by human
beings. Therefore, Deb's NSGA-II algorithm, which introduces fast nondominated sorting and elitist strategy to define
crowding distance instead of fitness sharing, reduces the
complexity of the algorithm and improves the computation

6

Computational Intelligence and Neuroscience
Crowded distance calculation ï¼ï¼®+1

Non-dominated sorting

ï¼ï¼®

ï¼†1

ï¼†1

ï¼†2

ï¼†2
ï¼†3

ï¼†3

Table 1: NSGA- II preset parameters.
Parameter
P
CR
MR

ï¼†3

Name
Population size
Crossover rate
Mutation rate

Preset value
100
0.9
0.1

Rejected

ï¼ï¼®

Figure 7: The steps of NSGA-II algorithm.

efficiency. NSGA-II overcomes three shortcomings of NSGA:
the computational complexity which dropped from O(MN 3 )
to O(MN 2 ) (where M is the number of objectives and N is
the population size), an elitist-preserving approach, and no
sharing parameters which need to be specified. More details
can be seen at [26].
Figure 7 describes the application of the dominance criterion in the NSGA-II algorithm. NSGA-II algorithm starts
from an initialization population ğ‘ƒğ‘¡ and each individual in a
population is no worse than the remaining individuals in the
population. The following steps combine the NSGA- II with
OVO TWSVM to optimize the classification results of OVO
TWSVM. And then generate offspring ğ‘‚ğ‘¡ from ğ‘ƒğ‘¡ through
binary tournament selection, crossover, and mutation. Once
a foreign source is obtained, the algorithm will combine the
current population and the current generation into a group
and classify them according to the nondominated sorting and
crowding distance. ğ‘ optimal solutions can be obtained in
the final set.

4. Analysis of Experimental Results
4.1. Construction of the Objective Function. Using NSGA- II
to optimize the parameters, this paper uses the correct rate to
construct the target function. The objective function is given
as follows:
ğ¶ğ‘ğ¹
(23)
ğ¶ğ‘…ğ¹ =
Ã— 100
ğ‘‡ğ‘ğ¹
ğ¶ğ‘…ğ¸ =

ğ¶ğ‘ğ¸
Ã— 100
ğ‘‡ğ‘ğ¸

(24)

ğ¶ğ‘…ğ´ =

ğ¶ğ‘ğ´
Ã— 100
ğ‘‡ğ‘ğ´

(25)

(ğ¶ğ‘ğ¹ + ğ¶ğ‘ğ¸ + ğ¶ğ‘ğ´)
Ã— 100
(ğ‘‡ğ‘ğ¹ + ğ‘‡ğ‘ğ¸ + ğ‘‡ğ‘ğ´)

(26)

ğ¶ğ‘… =

CRF, CRE, and CRA represent the correct rate of flexion,
extension and abduction, CNF, CNE, and CNA represent the
correct action number of flexion, extension, and abduction,
and TNF, TNE, and TNA represent the total number of
flexion, extension, and abduction. CR represents the total
correct rate.
4.2. Processing Steps. In the training phase, as the search
process goes deep, the whole population tends to gather the

global Pareto optimal set until the maximum evolutionary
algebra is reached. The process of multiobjective optimization
usually has the following steps:
(1) The dataset can be divided into a training set and a
test set (50% for training, 50% for testing) or 5-fold cross
validation, and in this article we use 5-folder cross validation
in the whole analysis process.
(2) Change the parameters of the OVO TWSVM and run
the target function.
(3) Set evolution algebra or stop criteria [27].
(4) Analyze the global optimal set to get the optimal
parameters.
Table 1 shows the preset parameters of NSGA-II algorithm. The population size of the article is 100 and the
crossover rate and mutation rate are 0.9 and 0.1.
Table 2 shows the range of penalty parameters and kernel
function width for OVO TWSVM.
Table 3 shows the partial Pareto optimal set of the subject
A and the corresponding OVO TWSVM model parameters
using the NSGA-II algorithm.
Figure 8 shows the Pareto optimal fronts constructed
by all nondominated solutions when seven subjects reach
the optimal recognition rate. The mark points represent the
optimum solution.
Figure 9 shows the evolutionary convergence curve of
different subjects. It can be seen from the figure that five of the
seven subjects achieved the highest recognition rate within
200 generations, they are subjects A, B, C, E, and F, and their
accuracies are 91.66%, 95.00%, 90.00%, 85.00%, and 85.00%.
All the subjects continued to increase the evolution algebra
until the 600 generations. It was found that two subjects D
and G had converged in the 200 generation, namely, 85%
and 88.33%, respectively. The recognition rate of subjects F
increased to 85% in the 400 generations and remained stable
within 600 generations.
Figure 10 shows the accuracy of the OVO TWSVM classification using the linear kernel and the RBF kernel, respectively, along with the corresponding penalty parameters c1, c2
and kernel function width ğœ†, and S represent different subject.
As can be seen from Figure 10, OVO TWSVM based on RBF
kernel achieved the highest recognition rate on six subjects,
up to 95% on subject B. Subject D's highest recognition
rate appeared in linear kernel based OVO TWSVM, but the
recognition result was only 3.33% less than that of RBF kernel
based OVO TWSVM. Therefore, this paper chooses RBF
kernel based OVO TWSVM as the final recognition model.
4.3. Comparison with Other Methods. Literature [20] uses
LS-SVM to classify the motor imagery EEG signals; this
paper applies the model to our own dataset for classification.
Fivefold cross validation for each person's data, the results,

Computational Intelligence and Neuroscience

7

Table 2: OVO TWSVM parameter range.
Parameter
c1
c2
ğœ†

Name
Penalty parameter 1
Penalty parameter 2
RBF kernel function

Lower limit
2âˆ’3
2âˆ’3
2âˆ’20

Upper limit
23
23
23

Table 3: Pareto optimal set of subject A and the corresponding model parameters.
c1
0.2031
5.0102
5.4325
6.7280
4.1136
4.8389
3.6172

c2
0.0100
5.7356
6.6230
7.7008
0.0100
7.3435
4.8072

ğœ†
0.7810
0.1130
0.2384
0.7514
0.6551
0.2332
0.1111

CRF
0.95
0.40
0.75
0.95
0.95
0.80
0.45

CRE
0.85
0.20
1.00
0.95
0.85
1.00
0.15

CRA
0.90
1.00
0.65
0.85
0.90
0.60
1.00

CR
0.9000
0.5333
0.8000
0.9166
0.9000
0.8000
0.5333

Table 4: Comparison between AF-CSP and EMD-CSP.
Subjects
AF-CSP
EMD-CSP

A
91.66
88.33

B
95.00
88.33

C
90.00
81.66

D
85.00
76.67

and the corresponding parameter settings are shown in
Figure 11. Where ğ‘ is the penalty parameter, ğ‘” is the kernel
function width. As can be seen from Figure 11, LS-SVM with
RBF kernel has the highest recognition rate of 92.09% on
subject B, five other subjects were over 75%, and the worst
recognition rate on subject F is 66.66%. Based on the above
results, it can be considered that this method performs well
on the data sets of different subjects.
We also use BP with momentum, ELM, PSO-SVM, and
grid search OVO TWSVM to classify the datasets. The result
of the classification is shown in Figure 12. It can be seen
from Figure 12 that the proposed method (88.57%Â±3.61%)
has the highest average recognition rate among the seven
subjects compared to other recognition algorithms. LS-SVM
(79.64%Â±7.47%), GS OVO TWSVM (79.99%Â±7.76%), and
PSO-SVM (75.95%Â±7.86%) have similar average recognition
effect on seven subjects, and the average classification results
of BP (61.70%Â±6.62%) and ELM (61.42%Â±5.37%) in this
dataset are lower than that of SVM classifier. This shows that
SVM classifier has a great advantage in small sample machine
learning.
Since the time domain signal is more similar, especially
in the single joint motor imagery EEG signal, in this paper,
we combine amplitude-frequency (AF) domain information
with CSP, namely, AF-CSP to get feature vectors. Different
from the traditional method of combining time domain
signal with CSP to construct feature vector, AF information
can reveal further the difference between different actions in
frequency domain and amplitude range; thus, CSP can get
stronger feature extraction ability. In this paper, we compare
the classification rate using AF-CSP and CSP directly after
EMD, as shown in Table 4. As can be seen from Table 3,
the proposed method has achieved a higher recognition rate

E
85.00
88.33

F
85.00
83.34

G
86.67
73.34

Mean
88.57%Â±3.61%
82.85%Â±5.61%

among the 5 subjects, and it might be interpreted that AF-CSP
is a more effective feature extraction method.
In order to distinguish the significance of the proposed
method in this article, the one-way analysis of variance
(ANOVA) method was used to compare with the other
five algorithms. The p-value values are shown in Table 5,
where p1, p2, p3, p4, and p5 represent the p-values between
the proposed method and LS-SVM, BP, ELM, PSO-SVM,
and grid search OVO TWSVM. When pâ‰¤0.05, there is a
significant difference in the recognition effect between the
two algorithms. It can be seen from Table 5 that the p-values
between the proposed method and the five-other methods are
significantly less than 0.01, which proves that the proposed
algorithm has significant classification in improvement performance compared with other algorithms.

5. Discussion
Common spatial pattern is widely used in motor imagery
to extract EEG features [28]. This method uses supervised
learning to obtain two types of filter to separate two motor
imagery tasks. In recent years, several methods like CSSP
[29], RCSP [30], SSCSP [31], FERCSP [32], SBCSP [33], and
FBCSP [34] have been used to improve conventional CSP. But
the drawback of CSP is that it needs a lot of electrodes. AFCSP, which taking into account the AF information in the
EEG signals, uses only four electrode channels to achieve a
better recognition effect than conventional CSP.
And an optimized OVO TWSVM using NSGA-II is used
to improve the accuracy of motor imagery; the mean accuracy
of the proposed method is 88.57%Â±3.61%. However, since
there are no articles consistent with the contents of this paper,
we can only discuss articles that are similar to our research

8

Computational Intelligence and Neuroscience
Subject B

0.8
0.6
0 0 0.2 0.4
(%)
E
R
C

0.5
(%)

1

0.8

0.95
0.85 0.9
(%)
CRE

1

1

1

0.8

0.8

0.6
0.4
0.2
1
0.8

CRF 0.5
(%)

0

CRA (%)

0.90
0.85
0.80
0.9
0.85
1
0.8
0.9
CRF
0.75
0.7 0.8
(%)
0.7 0.5 0.6
)
%
(
CRE

1

0.4
0.2
1

0.8
0.6
CRF
0.4
0.2
(%)

0.4

0

0.6 0.8
0.2 0.4
(%)
CRE

1

Subject G

0.6

0.4 0.6
0 0.2
(%)
CRE

1
0.8
0.6
0.4
0.2
0
1
0.8
CRF 0.6
(%)

Subject F

CRA (%)

CRA (%)

Subject E

0.95

CRA (%)

CRF

1

1
0.98
0.96
0.94
0.92
0.9
1
0.95
0.9
CRF
0.85
(%)
0.8

Subject D

Subject C

CRA (%)

1
0.9
0.8
0.7
0.6
0.5
1

CRA (%)

CRA (%)

Subject A

0.9 1
0.7 0.8
)
%
0.5 0.6
(
CRE

1
0.8
0.6
0.4
0.2
0
1

CRF

0.5
(%)

0

0.8
0.6
0.4
0 0.2
(%)
E
R
C

1

Figure 8: The Pareto optimal front of seven subjects based on RBF kernel OVO TWSVM.
Table 5: p-value score based on RBF kernel OVO TWSVM and five other methods.
p1

p2

p3

p4

p5

A
B
C

1.06e-05
3.80e-02
1.07e-07

3.90e-07
9.72e-06
6.27e-09

6.29e-08
6.97e-13
3.60e-11

2.78e-08
1.00e-03
3.55e-05

7.22e-05
5.33e-04
2.37e-07

D
E

2.84e-05
1.00e-04

3.99e-07
3.64e-12

9.81e-07
3.04e-06

6.09e-07
1.84e-06

3.00e-04
2.61e-11

F
G

3.88e-07
3.00e-04

8.30e-08
3.82e-09

9.84e-08
7.56e-06

5.93e-06
4.91e-05

3.40e-03
5.94e-07

Subject

Table 6: Mean confusion matrices of seven subjects for the proposed method.

Flexion
Extension
Abduction

Flexion
90.71
5.50
3.93

Extension
7.57
82.14
10.26

Abduction
3.50
5.79
90.71

contents. Literature [18] points out that the manual extraction of features in the traditional biological signal pattern
recognition model may produce information loss; thus, CNN
with deep learning is introduced to identify of changes in the
brain topographic map. The results show that three kinds of
motor imagery in the hand are 65.51% and the kappa value
in this experiment is 0.481. However, there is still a great
deal of uncertainty about the intention recognition of single
hand. In [19], the wavelet coefficients are calculated from
EEG signals as feature and employed including quadratic
discriminant analysis, naive Bayes quadratic, decision tree, K
nearest neighbors, and SVM classifiers to identify shoulder
and elbow joint movement. The highest recognition rate
is 84.91%, using the SVM classifier. The weakness of this
study is that it only recognizes the shoulder and elbow joint

movements of one hand and there is no further analysis of the
complex movement of the single joint.
It should be noted that we use AF-CSP to extract features
and enhance the feature extraction ability of CSP. OVO
TWSVM is used to identify three types of upper limb
movement; the lowest recognition rate is 85.00%. Compared
with the current research, we have made a more in-depth
analysis of single joint multiclass motor imagery. A more
sophisticated analysis can be done using the mean confusion
matrices given in Table 6 and the kappa value calculated
by Table 6 is 0.82. It appears that the extension action is
more difficult to distinguish with flexion and abduction of the
shoulder joint using the proposed method. The flexion and
extension of the shoulder joint obtain high recognition rate
by the proposed method.
In addition, [35] proposes a novel correlation-based
time window selection (CTWS) algorithm which considers
the variation in the time latency during the MI task for
MI-based BCI. CTWS adjusts the starting points of time
window for both training and test samples using correlation
analysis and shows significantly improvement than feature
extraction algorithms without CTWS. As the feature extraction algorithms in the structure of the CTWS algorithm is
substitutable, the focus of the next work is to combine CTWS

Computational Intelligence and Neuroscience

9

100
120

96

100

94

80

Accuracy (%)

Accuracy (%)

98

92
90
88

60
40

86

20

84

0
R
L R
A
L R
B
L R
L R
C
L R
D
L R
Sub
E
ject
L
F
G

82
80

0

20

40

A
B
C
D

60

80 100 120 140 160 180 200
Generation number
E
F
G

100
90
80
70
60
50
40
30
20
10
0

Accuracy (%)

Accuracy (%)

g S ter

e
m
ra
Pa

Figure 11: LS-SVM recognition rate diagram for different kernel
functions.

Figure 9: Evolutionary convergent fold line chart for different
subjects.

R
L R
A
L R
B
L
R
C
L R
D
Sub
L R
ject
E
L
R
F
L
G

c

110
100
90
80
70
60
50
40
30
20
10
0

A

B

LS SVM
BP
ELM
S
î‹­ r
c2 ete
c1 ram
Pa

Figure 10: OVO TWSVM recognition effect diagram of different
kernel function types.

with AF-CSP to increase the recognition rate of the extension
and applying this model to the BCI systems.

6. Conclusion
This paper proposes AF-CSP replace the traditional EMDCSP method. The main idea of this method is to analyze the ğœ‡
and ğ›½ rhythm information contained in each IMF component
after EMD decomposition and extract corresponding AF
information. This preprocessing method not only removes
the influence of irrelevant frequency bands, but also strengthens the feature extraction ability of CSP. Secondly, this paper
also uses NSGA-II to optimize the OVO TWSVM parameter

C

D
Subject

E

F

G

PSO SVM
GS OVO TWSVM
NSGA- II OVO TWSVM

Figure 12: Comparison of recognition rates of different methods.

optimization process. Compared with other evolutionary
strategies, the Pareto optimal set obtained by NSGA-II can
make OVO TWSVM more robust. In the future, we may use
this technology to evaluate the classification of real-time BCI
and apply this method for reach and grasp tasks of a robotic
arm. In order to improve the recognition rate of the method,
we may use clustering or dimensionality reduction method to
get a more obvious feature vector.

Data Availability
The data used to support the findings of this study are
available from the corresponding author upon request.

Conflicts of Interest
The authors declare that they have no conflicts of interest.

10

References
[1] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller,
and T. M. Vaughan, â€œBrain-computer interfaces for communication and control,â€ Clinical Neurophysiology, vol. 113, no. 6, pp.
767â€“791, 2002.
[2] N. Birbaumer, â€œBreaking the silence: brain-computer interfaces
(BCI) for communication and motor control,â€ Psychophysiology,
vol. 43, no. 6, pp. 517â€“532, 2006.
[3] J. Kalcher, D. Flotzinger, C. Neuper, S. GoÌˆlly, and G.
Pfurtscheller, â€œGraz brain-computer interface II: towards communication between humans and computers based on online
classification of three different EEG patterns,â€ Medical & Biological Engineering & Computing, vol. 34, no. 5, pp. 382â€“388,
1996.
[4] J. R. Wolpaw and D. J. McFarland, â€œMultichannel EEG-based
brain-computer communication,â€ Electroencephalography and
Clinical Neurophysiology, vol. 90, no. 6, pp. 444â€“449, 1994.
[5] B. Blankertz, C. Sannelli, S. Halder et al., â€œNeurophysiological
predictor of SMR-based BCI performance,â€ NeuroImage, vol. 51,
no. 4, pp. 1303â€“1309, 2010.
[6] N. Birbaumer, N. Ghanayim, T. Hinterberger et al., â€œA spelling
device for the paralysed,â€ Nature, vol. 398, no. 6725, pp. 297-298,
1999.
[7] J. D. Bayliss, â€œUse of the evoked potential P3 component for control in a virtual apartment,â€ IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 11, no. 2, pp. 113â€“116,
2003.
[8] U. Hoffmann, J.-M. Vesin, T. Ebrahimi, and K. Diserens, â€œAn
efficient P300-based brain-computer interface for disabled subjects,â€ Journal of Neuroscience Methods, vol. 167, no. 1, pp. 115â€“
125, 2008.
[9] G. Pfurtscheller, â€œEEG Rhythms - Event-Related Desynchronization and Synchronization,â€ in Rhythms in Physiological
Systems, vol. 55, pp. 289â€“296, Springer, Berlin, Germany, 1991.
[10] G. Pfurtscheller and F. H. L. da Silva, â€œEvent-related EEG/MEG
synchronization and desynchronization: basic principles,â€ Clinical Neurophysiology, vol. 110, no. 11, pp. 1842â€“1857, 1999.
[11] L. F. Nicolas-Alonso and J. Gomez-Gil, â€œBrain computer interfaces, a review,â€ Sensors, vol. 12, no. 2, pp. 1211â€“1279, 2012.
[12] D. Coyle, G. Prasad, and T. M. McGinnity, â€œA time-series
prediction approach for feature extraction in a brain-computer
interface,â€ IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 13, no. 4, pp. 461â€“467, 2005.
[13] T. Kayikcioglu and O. Aydemir, â€œA polynomial fitting and k-NN
based approach for improving classification of motor imagery
BCI data,â€ Pattern Recognition Letters, vol. 31, no. 11, pp. 1207â€“
1215, 2010.
[14] K. K. Ang and C. Guan, â€œEEG-Based Strategies to Detect Motor
Imagery for Control and Rehabilitation,â€ IEEE Transactions on
Neural Systems and Rehabilitation Engineering, vol. 25, no. 4, pp.
392â€“401, 2017.
[15] P. MartÄ±Ìn-Smith, J. Ortega, J. Asensio-Cubero, J. Q. Gan, and
A. Ortiz, â€œA supervised filter method for multi-objective feature selection in EEG classification based on multi-resolution
analysis for BCI,â€ Neurocomputing, vol. 250, pp. 45â€“56, 2017.
[16] Y. Zhang, G. Zhou, J. Jin, X. Wang, and A. Cichocki, â€œOptimizing spatial patterns with sparse filter bands for motor-imagery
based brain-computer interface,â€ Journal of Neuroscience Methods, vol. 255, pp. 85â€“91, 2015.

Computational Intelligence and Neuroscience
[17] C. Park, C. C. Cheong-Took, and D. P. Mandic, â€œAugmented
complex common spatial patterns for classification of noncircular EEG from motor imagery tasks,â€ IEEE Transactions on
Neural Systems and Rehabilitation Engineering, vol. 22, no. 1, pp.
1â€“10, 2014.
[18] W. Wang, S. Sun, C. Li, and Z. Tang, â€œRecognition of upper limb
motion intention of EEG signal based on convolutional neural
network,â€ Journal of Zhejiang University, vol. 7, no. 51, pp. 1381â€“
1389, 2017.
[19] R. Rinku, A. Konar, and N. Tibarewala, â€œClassification of leftright arm and shoulder joint- elbow joint motor imagery data,â€
in Proceedings of the National Conference on Telecommunication
& Control Engineering, 2012.
[20] S. Taran, V. Bajaj, D. Sharma, S. Siuly, and A. Sengur, â€œFeatures
based on analytic IMF for classifying motor imagery EEG
signals in BCI applications,â€ Measurement, vol. 116, pp. 68â€“76,
2018.
[21] X. Tang, N. Zhang, J. Zhou, and Q. Liu, â€œHidden-layer visible
deep stacking network optimized by PSO for motor imagery
EEG recognition,â€ Neurocomputing, vol. 234, pp. 1â€“10, 2017.
[22] N. E. Huang, Z. Shen, S. R. Long et al., â€œThe empirical mode
decomposition and the Hilbert spectrum for nonlinear and
non-stationary time series analysis,â€ Proceedings of the Royal
Society of London A: mathematical, Physical and Engineering
Sciences, vol. 454, no. 1971, pp. 903â€“995, 1998.
[23] R. Khemchandani and S. Chandra, â€œTwin support vector
machines for pattern classification,â€ IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29, no. 5, pp. 905â€“
910, 2007.
[24] S. Ding, J. Yu, B. Qi, and H. Huang, â€œAn overview on twin
support vector machines,â€ Artificial Intelligence Review, vol. 42,
no. 2, pp. 245â€“252, 2014.
[25] D. Tomar and S. Agarwal, â€œA comparison on multi-class classification methods based on least squares twin support vector
machine,â€ Knowledge-Based Systems, vol. 81, pp. 131â€“147, 2015.
[26] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, â€œA fast
and elitist multiobjective genetic algorithm: NSGA-II,â€ IEEE
Transactions on Evolutionary Computation, vol. 6, no. 2, pp. 182â€“
197, 2002.
[27] A. R. J. Clark and R. M. Everson, â€œMulti-objective learning
of Relevance Vector Machine classifiers with multi-resolution
kernels,â€ Pattern Recognition, vol. 45, no. 9, pp. 3535â€“3543, 2012.
[28] Z. J. Koles, M. S. Lazar, and S. Z. Zhou, â€œSpatial patterns underlying population differences in the background EEG,â€ Brain
Topography, vol. 2, no. 4, pp. 275â€“284, 1990.
[29] S. Lemm, B. Blankertz, G. Curio, and K.-R. MuÌˆller, â€œSpatiospectral filters for improving the classification of single trial
EEG,â€ IEEE Transactions on Biomedical Engineering, vol. 52, no.
9, pp. 1541â€“1548, 2005.
[30] F. Lotte and C. Guan, â€œRegularizing common spatial patterns to
improve BCI designs: unified theory and new algorithms,â€ IEEE
Transactions on Biomedical Engineering, vol. 58, no. 2, pp. 355â€“
362, 2011.
[31] Y. Shin, S. Lee, J. Lee, and H.-N. Lee, â€œSparse representationbased classification scheme for motor imagery-based braincomputer interface systems,â€ Journal of Neural Engineering, vol.
9, no. 5, Article ID 056002, 2012.
[32] S. Yuxi, L. Yali, and W. Shengjin, â€œFilter ensemble regularized
common spatial pattern for EEG classification,â€ in Proceedings
of the Seventh International Conference on Digital Image Processing (ICDIP â€™15), vol. 9631, International Society for Optics and
Photonics, 2015.

Computational Intelligence and Neuroscience
[33] Q. Novi, C. Guan, T. H. Dat, and P. Xue, â€œSub-band common spatial pattern (SBCSP) for brain-computer interface,â€ in
Proceedings of the 3rd International IEEE/EMBS Conference on
Neural Engineering (CNE â€™07), pp. 204â€“207, IEEE, Kohala Coast,
Hawaii, USA, May 2007.
[34] K. K. Ang, Z. Y. Chin, C. Wang, C. Guan, and H. Zhang, â€œFilter
bank common spatial pattern algorithm on BCI competition IV
datasets 2a and 2b,â€ Frontiers in Neuroscience, vol. 6, 9 pages,
2012.
[35] J. Feng, E. Yin, J. Jin et al., â€œTowards correlation-based time
window selection method for motor imagery BCIs,â€ Neural Networks, vol. 102, pp. 87â€“95, 2018.

11

Advances in

Multimedia
Applied
Computational
Intelligence and Soft
Computing
Hindawi
www.hindawi.com

Volume 2018

The Scientific
World Journal
Hindawi Publishing Corporation
http://www.hindawi.com
www.hindawi.com

Volume 2018
2013

Mathematical Problems
in Engineering
Hindawi
www.hindawi.com

Volume 2018

Engineering
Journal of

Hindawi
www.hindawi.com

Volume 2018

Hindawi
www.hindawi.com

Modelling &
Simulation
in Engineering
Hindawi
www.hindawi.com

Volume 2018

Advances in

Artificial
Intelligence
Hindawi
www.hindawi.com

Volume 2018

Volume 2018

Advances in
International Journal of

Reconfigurable
Computing

Hindawi
www.hindawi.com

Fuzzy
Systems

Submit your manuscripts at
www.hindawi.com

Hindawi
www.hindawi.com

Volume 2018

Volume 2018

Journal of

Hindawi
www.hindawi.com

International Journal of

Advances in

Scientific
Programming

Engineering
Mathematics

Human-Computer
Interaction
Volume 2018

Hindawi
www.hindawi.com

Computer Networks
and Communications

Volume 2018

Hindawi
www.hindawi.com

Advances in

Civil Engineering
Volume 2018

Hindawi
www.hindawi.com

Volume 2018

Hindawi
www.hindawi.com

Volume 2018

International Journal of

Biomedical Imaging

International Journal of

Robotics
Hindawi
www.hindawi.com

Journal of

Computer Games
Technology

Journal of

Volume 2018

Hindawi
www.hindawi.com

Electrical and Computer
Engineering
Volume 2018

Hindawi
www.hindawi.com

Volume 2018

Hindawi
www.hindawi.com

Volume 2018

Computational Intelligence
and Neuroscience
Hindawi
www.hindawi.com

Volume 2018

