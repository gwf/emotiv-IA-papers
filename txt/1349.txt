sensors
Article

Quaternion-Based Signal Analysis for Motor Imagery
Classification from Electroencephalographic Signals
Patricia Batres-Mendoza 1 , Carlos R. Montoro-Sanjose 2,3 , Erick I. Guerra-Hernandez 1 ,
Dora L. Almanza-Ojeda 4, *, Horacio Rostro-Gonzalez 1,3 , Rene J. Romero-Troncoso 3,5
and Mario A. Ibarra-Manzano 3,4
1

2
3

4
5

*

Laboratorio de Sistemas Bioinspirados, Departamento de Ingeniería Electrónica, DICIS, Universidad de
Guanajuato, Carr. Salamanca-Valle de Santiago KM. 3.5 + 1.8 Km., Salamanca 36885, Mexico;
p.batresmendoza@ugto.mx (P.B.-M.); ei.guerrahernandez@ugto.mx (E.I.G.-H.); hrostrog@ugto.mx (H.R.-G.)
Departamento de Arte y Empresa, DICIS, Universidad de Guanajuato, Carr. Salamanca-Valle de Santiago
KM. 3.5 + 1.8 Km., Salamanca 36885, Mexico; cmontoro@ugto.mx
Cuerpo Académico de Telemática, DICIS, Universidad de Guanajuato, Carr. Salamanca-Valle de Santiago
KM. 3.5 + 1.8 Km., Salamanca 36885, Mexico; troncoso@hspdigital.org (R.J.R.-T.);
ibarram@ugto.mx (M.A.I.-M.)
Laboratorio de Procesamiento Digital de Señales, Departamento de Ingeniería Electrónica, DICIS,
Universidad de Guanajuato, Carr. Salamanca-Valle de Santiago KM. 3.5 + 1.8 Km., Salamanca 36885, Mexico
Departamento de Ingeniería Electrónica, DICIS, Universidad de Guanajuato, Carr. Salamanca-Valle de
Santiago KM. 3.5 + 1.8 Km., Salamanca 36885, Mexico
Correspondence: dora.almanza@ugto.mx; Tel.: +52-464-647-9940

Academic Editor: Vittorio M. N. Passaro
Received: 27 January 2016; Accepted: 29 February 2016; Published: 5 March 2016

Abstract: Quaternions can be used as an alternative to model the fundamental patterns of
electroencephalographic (EEG) signals in the time domain. Thus, this article presents a new
quaternion-based technique known as quaternion-based signal analysis (QSA) to represent EEG
signals obtained using a brain-computer interface (BCI) device to detect and interpret cognitive
activity. This quaternion-based signal analysis technique can extract features to represent brain
activity related to motor imagery accurately in various mental states. Experimental tests in which
users where shown visual graphical cues related to left and right movements were used to collect
BCI-recorded signals. These signals were then classified using decision trees (DT), support vector
machine (SVM) and k-nearest neighbor (KNN) techniques. The quantitative analysis of the classifiers
demonstrates that this technique can be used as an alternative in the EEG-signal modeling phase to
identify mental states.
Keywords: quaternion-based signal analysis (QSA); electroencephalography (EEG); motor imagery;
brain-computer interface (BCI)

1. Introduction
The interest in establishing direct communication between the brain and other external devices
using electroencephalographic (EEG) signals has increased with the use of brain-computer interface
(BCI) systems. According to Wolpaw [1], “BCI interfaces allow to record the brain signals of an
individual, extract their characteristics and turn them into artificial outputs that operate outside or in
your own body”. In other words, the interface establishes a channel of communication and control
between an individual and an external device. BCI systems use EEG activity to perform various
tasks, such as controlling cursor movements [2], browsing the web [3,4], selecting letters or icons [5–8],
communicating with virtual environments (e.g., in games) [9,10], robot navigation [11–13], controlling
a wheelchair [14–17] or operating prosthetics [18–20], among others.
Sensors 2016, 16, 336; doi:10.3390/s16030336

www.mdpi.com/journal/sensors

Sensors 2016, 16, 336

2 of 17

By nature, EEG signals are non-linear and non-stationary. Usually, these signals are processed
and analyzed using various mathematical methods to gather information regarding the frequency
components and, in turn, the functional relationships between brain areas. The most-commonly used
techniques in the analysis are the fast Fourier transform (FFT), power spectral density (PSD), Hjorth
parameters and the discrete wavelet transform (DWT). Several strategies have been presented to
analyze brain signals by extracting and classifying EEG signals for cognitive-movement detection
purposes. For instance, Hongyu [21] presents an on-line classification method for BCI based on
common spatial patterns (CSP) for feature extraction, using support vector machine (SVM) as a
classifier for imagined hand and foot movements achieving accuracy results of 86.3%, 91.8% and 92.0%
with three subjects. Similarly, Bhattacharyya [22] conducted a study of comparative performance
analysis of different classifiers, linear discriminant analysis (LDA), quadratic discriminant analysis
(QDA), k-nearest neighbor (KNN), linear SVM, radial basis function (RBF) SVM and naïve Bayesian)
to differentiate EEG signals for left-right limb movement, with SVM being the most accurate at 82.14%.
In turn, Jiralerspong [23] conducted an experimental test of three mental states using FFT with a
hamming window function that resulted in a 72% recognition rate. These strategies show good
accuracy rates, but the information is extracted within a frequency or time-frequency domain, thereby
losing vital information. On the other hand, some studies have been conducted based on multi-scale
entropy (MSE) analysis to detect features of biological signals, as shown in [24], where Costa, et al.
present a generalization of multi-scale entropy to analyze the structure of time series of heartbeats.
Similarly, Mossabber [25] uses multivariate multi-scale entropy (MMSE) as a generalization of MSE to
be adapted for biological and physical systems. Morabito, et al. [26] also use a multivariate multi-scale
methodology to assess the complexity of physiological systems by means of permutation entropy
whereby time series are processed in segments. However, the analysis does not appear to analyze
several signals at the same time, and the performance of signals is based on patterns, which results in
magnitude being weighted differently.
An alternative would be to conduct the signal analysis within a time domain. Quaternions can be
an alternative to model EEG signals because they provide us with a mathematical notation to represent
object orientations and rotations three-dimensionally, which makes it possible to represent EEG
multichannel signals beyond what traditional methods allow. Recent studies have used quaternion
algebra with traditional methods. For instance, Furman [27] uses the so-called quaternion Fourier
transform (QFT) to process 3D images, and claims that the rotation operation is faster than when
using a matrix-based method. In addition, Zhao [28] uses quaternion principle component analysis
(QPCA) to represent EEG multichannel epilepsy signals with better results than those obtained using a
traditional approach.
There are some considerable advantages in using quaternions, and thus a new technique to
represent EEG signals visually using quaternion algebra to classify brain activity in relation to
visual cues is presented here. The visual representation, extraction and classification of EEG features
correspond to the cognitive activity recorded as the brain processes motor images. Motor imagery
can be defined as a mental process linked to a motor action without any overt motor output [29].
In the case of this study, three kinds of visual cues were used: left, right and waiting time. As a
result, EEG signals gathered using the BCI device were divided into blocks that contained information
from only four of the 14 sensors. Each block was represented using quaternions to extract the signal
features, and were later classified (off-line) using three techniques: KNN, SVM and decision trees (DT).
Finally, the various classification results obtained when detecting classes were used to validate the
performance levels.
This paper is organized as follows: Section 2 is an introduction to quaternions, BCI systems and
classifiers; Section 3 includes a description the QSA technique; Section 4 accounts for the experimental
tests; Section 5 features a discussion of the QSA implementation results; and Section 6 ends with
some conclusions.

Sensors 2016, 16, 336

3 of 17

2. Preliminaries
This section provides a brief but accurate description of the key elements used to develop the
study that is, quaternion algebra and the BCI device used to acquire the brain signals.
2.1. Quaternions
Quaternions were proposed in 1843 by Hamilton [30], as a set of four constituents (one real
component and three imaginary) of the form: q = w + ix + jy + kz, where w, x, y, z P R and i, j, k are
symbols of three imaginary quantities known as imaginary units. These units follow these rules:
i2 “ j2 “ k2 “ ijk “ ´1

(1)

ij “ k, jk “ i, ki “ j
ji “ ´k, kj “ ´i, ik “ ´j
A quaternion can be described as:
q “ ps ` vq, v “ px, y, zq

(2)

where s and v are known as the quaternion’s scalar and vector, respectively. When s = 0, q is known as
a pure quaternion.
Table 1 summarizes the basic operations of quaternion algebra, where q and p are two quaternions,
whilst the dot and the cross represent the usual scalar and vector products.
Table 1. Operations using quaternions q and p.
Operation
Addition
Multiplication
Scalar product
Conjugate
Norm
Inverse

Formulae
`
˘
` q ` p “ s q ` s p , vq ` v p
˘
Â
q
p “ sq s p ´ vq ¨`v p , s p vq ` s˘q v p ` vq ˆ v p
q ¨ p “ `sq s p , vq ˘¨ v p
q “ sq , ´vq b
a Â
a Â
||q|| “ q q “
q q“
s2q ` ||vq ||2
q
q´1 “
||q||2

Note that the multiplication of quaternions is a not a commutative operation; instead, it is
associative and distributive in relation to the addition.
Quaternions with a norm equal to one are known as unit (or normalized) quaternions. If q is a
unit quaternion, it can be written as [31]:
q “ cosθ ` sinθ e, ||e|| “ 1

(3)

where cosθ “ s, sinθ “ ||v|| and u “ v{||v||. Equally, the previous equation can be used to
represent vector rotations.
q “ cosθ ` sinθ e “ ba´1
(4)
where a and b are any two vectors having the same length, the angle between a and b is θ, e is
perpendicular to both a and b, and a, b, and e form a right-handed set.
For a rotation of angle θ around a unit vector a, q must be formed thus:
q “ cos

ˆ ˙
ˆ ˙
θ
θ
` a sin
2
2

(5)

Sensors 2016, 16, 336

4 of 17

Furthermore, the operation to be performed on a vector r to produce a rotated vector r’ is:
Sensors 2016, 16, 336

r1 “ qrq´1 “

ˆ ˙˙ ˆ
ˆ ˙
ˆ ˙˙
ˆ
ˆ ˙
θ
θ
θ
θ
` a sin
r cos
´ a sin
cos
2
2
2
2

4 of 17(6)

Equation
(6)(6)
is aisuseful
representation
that
makes
the
rotation
Equation
a useful
representation
that
makes
the
rotationofofa avector
vectoreasier.
easier.We
Wecan
cansee
seethat
that r
r isisthe
theoriginal
originalvector,
vector,r’r’isisthe
therotated
rotatedquaternion,
quaternion,and
andqqisisthe
thequaternion
quaternionthat
that defines
defines the
the rotation.
rotation.
System
2.2.2.2.
BCIBCI
System
BCI
devicescapture
capture brain signals
thatthat
willwill
be subsequently
processed
and analyzed.
BCI
devices
signalsofofindividuals
individuals
be subsequently
processed
and
Depending
on how signals
captured,
BCI devices
classified
invasiveasand
non-invasive.
The
analyzed.
Depending
on howare
signals
are captured,
BCIare
devices
are as
classified
invasive
and nonEmotiv
Epoc
headset
(Figure
1a)
is
a
non-invasive
mobile
BCI
device
with
a
gyroscopic
sensor
and
invasive. The Emotiv Epoc headset (Figure 1a) is a non-invasive mobile BCI device with a gyroscopic 14
EEGand
channels
(electrodes)
and two reference
with a 128with
Hz sample
sensor
14 EEG
channels (electrodes)
and twochannels
reference(CMS/DRL
channels (CMS/DRL
a 128 Hzfrequency).
sample
The distribution
of sensorsofinsensors
the headset
based on
the international
10–20 electrode
placement
frequency).
The distribution
in theisheadset
is based
on the international
10–20 electrode
system with
two with
sensors
as sensors
referenceasfor
proper placement
the head. This
device
obtains
the brain
placement
system
two
reference
for properonplacement
on the
head.
This device
activity
an individual,
is able to detect
and
process
theirand
thoughts,
and expressions
obtains
theofbrain
activity ofand
an individual,
and is
able
to detect
processfeelings
their thoughts,
feelings in
real
time. Based
10–20
system,
the10–20
channels
are: the
AF3,channels
F7, F3, FC5,
P8,T7,
T8,P7,
FC6,
and
expressions
in on
realthe
time.
Based
on the
system,
are: T7,
AF3,P7,
F7,O1,
F3,O2,
FC5,
F8,P8,
and
(Figure
O1,F4,
O2,
T8,AF4
FC6,
F4, F8,1b).
and AF4 (Figure 1b).

(a)

(b)

Figure 1. BCI System: (a) Emotiv Epoc headset; and (b) Emotiv Epoc electrode arrangement.
Figure 1. BCI System: (a) Emotiv Epoc headset; and (b) Emotiv Epoc electrode arrangement.

2.3. Description of Classifiers
2.3. Description of Classifiers
In this study, we used several classification algorithms: decision tree, support vector machine
In this study, we used several classification algorithms: decision tree, support vector machine
and k-nearest neighbor. DT [32–34] is a widely-used and easy-to-implement classification technique
and k-nearest neighbor. DT [32–34] is a widely-used and easy-to-implement classification technique
used to analyze data for prediction purposes. It consists of a set of conditions or rules organized in a
used to analyze data for prediction purposes. It consists of a set of conditions or rules organized in
hierarchical structure where the final decision can be determined following conditions established
a hierarchical structure where the final decision can be determined following conditions established
from the root to its leaves. SVM [35–37] refers to supervised learning models used to classify data
from the root to its leaves. SVM [35–37] refers to supervised learning models used to classify data into
into two categories by finding an optimal hyperplane that separates two possible values for the
two categories by finding an optimal hyperplane that separates two possible values for the variable
variable ∈ +1, −1}. If the data can be separated linearly, the hyperplanes divide SVM input data
y P t`1, ´1u. If the data can be separated linearly, the hyperplanes divide SVM input data into two
into two initial subgroups by assigning {−1, +1} tags. KNN [38] is a non-parametric approach used to
initial subgroups by assigning {´1, +1} tags. KNN [38] is a non-parametric approach used to solve
solve classification and regression problems, based on the assumption that an object’s class is the
classification and regression problems, based on the assumption that an object’s class is the same as
same as that of its closest neighbors.
that of its closest neighbors.
Both decision trees and KNN are designed to handle multi-class problems, which is not the case
Both decision trees and KNN are designed to handle multi-class problems, which is not the
for the SVM classifier as this is an algorithm originally developed for use with two classes only.
case for the SVM classifier as this is an algorithm originally developed for use with two classes only.
However, the classification can be expanded to more than two classes by combining binary classifiers,
However, the classification can be expanded to more than two classes by combining binary classifiers,
that is, by generating a classifier for the d classes available. For instance, it could be used thus:
that is, by generating a classifier for the d classes available. For instance, it could be used thus: classifier
classifier 1 (class 0 vs. class 1 and class 2), classifier 2 (class 1 vs. class 0 and class 2), classifier 3 (class
1 (class 0 vs. class 1 and class 2), classifier 2 (class 1 vs. class 0 and class 2), classifier 3 (class 2 vs. class 0
2 vs. class 0 and class 1). A decision function is used subsequently to group them and assess the class
they belong to following this criterion: class 0 (1 0 0), class 1 (0 1 0) and class 2 (0 0 1).
3. Proposed Method
In signal-pattern recognition, each sample is represented by a collection of descriptors that will

Sensors 2016, 16, 336

5 of 17

and class 1). A decision function is used subsequently to group them and assess the class they belong
to following this criterion: class 0 (1 0 0), class 1 (0 1 0) and class 2 (0 0 1).
3. Proposed Method
In signal-pattern recognition, each sample is represented by a collection of descriptors that will be
segmented and classified. Thus, the characterization of signals, in this case EEG signals, is essential to
determine the performance and accuracy of the final classification process. As mentioned in Section 1,
the analysis in the frequency domain is a common technique used when extracting features of EEG
signals; for instance, the Fourier transform, short Fourier transform or wavelet transform are commonly
used. However, the use of quaternion algebra is proposed as a novel tool to extract EEG-signal features
that simplifies the final classification task.
EEG signals can be described using quaternion-based rotations and orientations, as shown earlier.
Vector rotations are usually described by the rotation matrix or Euler angles [39], and quaternions can
be advantageous for three reasons: (1) they avoid ambiguities in the data; (2) they allow a more accurate
representation of the data; and (3) they require fewer calculations than other rotational techniques.
The proposed so-called quaternion-based signal analysis (QSA) method described in Algorithm
1 (Table 2) can be used to model multichannel EEG signals using quaternions, taking a set of input
signals as a single entity, and converting it into a pure quaternion.
Table 2. QSA Method for training and classifying EEG signals.
Algorithm 1
1.
2.
3.
4.

Inputs: dt, signals, nblocks, pr
y(t) Ð segments of signals
quat Ð signals (nblocks)
For each yi (t) do

a
b
c
d
e
f

q(t) Ð quat(t)
r(t) Ð quat(t-dt)
qrot (t) Ð nrot (q(t), r(t))
qmod (t) Ð mod(qrot (t))
Mi,j Ð f j (qmod (t)) {j = 1, . . . , m}
ci Ð { c=(1,2,3,...,n)|yi (t) P c}

End for
#k
5.
Mk,j Ð{ Mi,j |
“%t}
#i
#l
6.
Ml,j Ð { Mi,j |{l} ℘ {k} , “ 1 ´ % t}
#i
7.
[Ĉk , pr] = ProcQSA( pr, Mk,j , ck )
8.
9.
10.

[Ĉl , pr] = ProcQSA(pr, Ml,j , cl )
ˇ
(
#{Ck ˇCk “ Ĉk
%rt =
# tCk u
ˇ
(
#{Cl ˇCl “ Ĉl
%rv =
# tCl u

Function ProcQSA(pr, Mt, c)
1.
2.
3.

if pr == true thena. R = training(Mt,c)b. pr = false
elseb. R = classify(Mt)end if
return [R,pr]

Thus, the multichannel EEG information is represented using quaternions to characterize signals
recorded for 10 min during each test, and classified after further processing subsequently.
Algorithm 1 can be described as follows: Line 1 defines the input data: delta (dt) movements in
time t, signals to be analyzed (signals) and blocks with the channels to be analyzed (nblocks), where
each block includes signals from four channels, and pr is a flag to indicate whether the sample is being

Sensors 2016, 16, 336

6 of 17

used during validation or training. Line 2 calculates the segments matrix y(t) defined by changes
between the three classes (left, right and waiting time) from the pool of signals contained in nblocks.
The quaternions array quat, at line 3, is created using the channels included in nblocks. Line 4 dictates
that for each segment yi , q(t) and r(t) are formed considering that q(t) is an array with n quaternions
(line 4a) and r(t) is an array with n pure quaternions moved according to a dt value (line 4b). After
this, the rotation qrot (t) is calculated using quaternions q(t) and r(t) (line 4c), which produces an array
of n rotated quaternions. Line 4d calculates the scalar array qmod (t) from the module qrot (t), which
contains n scalar elements that will be used at line 4e to form a matrix with Mi,j features, where index
i corresponds to the analyzed segment and index j is one of the m features to be analyzed using the
equations included in Table 3. Line 4f gives shape to vector ci using the classes assigned to each
segment yi . In addition, matrix Mk,j is created using k-th data for the training phase at a %t rate (line 5)
and matrix Ml,j , together with the remainder of the original matrix Mij , is used to create the validation
where index l corresponds to the elements used in the validation process in a 1´%t proportion to
the analyzed segment (line 6). Thus, in lines 7 and 8 data are trained and/or validated by calling the
function ProcQSA() and returning a vector R using classes Ĉk (class aimed for training purposes) and
Ĉl (class aimed for validation purposes). In the function ProcQSA(), during the training phase, matrix
Mt data are assessed using DT, KNN or SVM classifiers, adjusting the parameters for each classifier.
Finally, the accuracy percentages are calculated during the training and validation phases (lines 9
and 10).
Table 3. Statistical features extracted using quaternions.
Statistical Features
Mean pµq

Equation
Σ p qmod q
N
ř
ř
2
p pqmod q2 ´ µq ` pqmod q2
“
2N
Σ p qmod q 2
“
N
ř
1
“
1 ` pqmod q2
ř
= pqmod ´ µq3
ř
= pqmod ´ µq4
“

` ˘
Variance σ2
Contrast pconq
Homogeneity pHq
Cluster Shade pcsq
Cluster prominence pcpq

Table 3 shows the formulae used to extract features by Haralick [40] and adapted for use with
quaternion algebra to implement the QSA model.
Equation (7) shows matrix M with its features vector. In this matrix columns correspond to features
and rows to samples. The features vector consists of the average, variance, contrast and homogeneity.
»
—
—
M“—
—
–

µ1 σ12
µ2 σ22
..
..
.
.
µi σi2

con1
con2
..
.
coni

H1
H2
..
.
Hi

fi
ffi
ffi
ffi
ffi
fl

(7)

4. Description of the Experimental Tests
This section outlines the steps followed to implement the proposed QSA method (Algorithm 1)
with EEG signals obtained from various participants for the purposes of detecting three mental states:
thinking “left”, “right” and “waiting time”, with no need for any movement or word.
First of all, the technique consists in representing the EEG signals as a single quaternion.
For experimental testing, one channel of the EEG signal is used as the real component and three
more channels as the imaginary components. After that, feature computation provides the input data
for the KNN, SVM and DT classifiers.

Sensors 2016, 16, 336
Sensors 2016, 16, 336
Sensors 2016, 16, 336

7 of 17
7 of 17
7 of 17

EEG
using
the the
Emotiv
EpocEpoc
headset
(shown
above above
in Figure
The1a).
graphic
EEG signals
signalsare
areacquired
acquired
using
Emotiv
headset
(shown
in 1a).
Figure
The
EEG signals are acquired using the Emotiv Epoc headset (shown above in Figure 1a). The
user
interface
used
to
analyze
the
acquired
signals
is
Python-based,
and
the
feature
selection
graphic user interface used to analyze the acquired signals is Python-based, and the feature selection
graphic user interface used to analyze the acquired signals
is Python-based, and the feature selection
and
and extraction
extraction is
is programmed
programmed using
usingMatlab
MatlabR2014a
R2014a®®®.. The
The following
following subsections
subsections include
include detailed
detailed
and extraction is programmed using Matlab R2014a . The following subsections include detailed
descriptions
descriptions of
of each
each stage
stage of
of the
the block
block diagram
diagram(Figure
(Figure2).
2).
descriptions of each stage of the block diagram (Figure 2).

Figure
2. Block
diagram
of of
the overall
EEG
signal
classification
strategy.
Figure
2. Block
diagram
overall
EEG
signal
classification
strategy.
Figure
2. Block
diagram
of thethe
overall
EEG
signal
classification
strategy.

4.1. EEG
EEG Signal Acquisition
Acquisition
4.1.
4.1. EEG Signal
Signal Acquisition
For signal
signal acquisition purposes,
purposes, the BCI’s
BCI’s cognitive mode
mode was used,
used, given that
that motor activities
activities
For
For signal acquisition
acquisition purposes, the
the BCI’s cognitive
cognitive mode was
was used, given
given that motor
motor activities
were one
one of the
the cognitive processes
processes involved in
in producing movement,
movement, which was
was the key
key focus of
of
were
were one of
of thecognitive
cognitive processes involved
involved in producing
producing movement, which
which was the
the key focus
focus of
the
tests.
The
experiment
was
conducted
with
10
participants
of
several
ages,
both
male
and
female.
the
the tests.
tests. The
The experiment
experiment was
was conducted
conducted with
with 10
10 participants
participants of
of several
several ages,
ages, both
both male
male and
and female.
female.
The
time
for
each
individual
test
was
10
consecutive
minutes,
during
which
three
elements
appeared
The
Thetime
time for
for each
each individual
individual test
test was
was 10
10 consecutive
consecutive minutes,
minutes, during
during which
which three
three elements
elements appeared
appeared
on the
the screen: an
an arrow pointing
pointing to the
the left and
and moving in
in that direction,
direction, a cross representing
representing rest
on
on the screen:
screen: an arrow
arrow pointing to
to the left
left and moving
moving in that
that direction, aa cross
cross representing rest
rest
time
and
an
arrow
pointing
to
the
right
and
moving
in
that
direction
(see
Figure
3).
The
left and
and right
time
time and
and an
an arrow
arrow pointing
pointingto
tothe
the right
right and
and moving
movingin
in that
that direction
direction(see
(seeFigure
Figure3).
3). The
The left
left and right
right
arrows alternate
alternate after appearing
appearing for 10
10 s (test mode)
mode) with aa 55 ss rest
rest time in
in between during
during which aa
arrows
arrows alternate after
after appearing for
for 10 ss (test
(test mode) with
with a 5 s rest time
time in between
between during which
which a
cross
appeared
at
the
center
of
the
screen.
In
other
words,
a
total
of
40
arrows
were
shown
alternately
cross
appeared
at
the
center
of
the
screen.
In
other
words,
a
total
of
40
arrows
were
shown
alternately
cross appeared at the center of the screen. In other words, a total of 40 arrows were shown alternately
for 10
10 min, with
with 5 s breaks between
between each alternation.
alternation. The purpose
purpose of the
the experiment was
was to make
make the
for
for 10 min,
min, with 55 ss breaks
breaks between each
each alternation. The
The purpose of
of the experiment
experiment was to
to make the
the
participant think
think or imagine
imagine movement while
while the arrow
arrow appeared on
on the screen.
screen. In addition,
addition, during
participant
participant think or
or imagine movement
movement while the
the arrow appeared
appeared onthe
the screen. In
In addition, during
during
the test
test mode, participants
participants were asked
asked to remain
remain motionless and
and avoid sharp
sharp body movements
movements that
the
the test mode,
mode, participants were
were asked to
to remain motionless
motionless and avoid
avoid sharp body
body movements that
that
could interfere
interfere with the
the signal being
being recorded, which
which they did,
did, but were
were then allowed
allowed to move
move freely
could
could interfere with
with the signal
signal being recorded,
recorded, which they
they did, but
but were then
then allowed to
to move freely
freely
duringrest
rest time.States
States 0, 1 and2 were
2 were
used
refer
to the
three
elements:
waiting
(0),(1)
left (1)
during
used
to to
refer
to the
three
elements:
waiting
timetime
(0), left
during resttime.
time. States0,0,1 1and
and 2 were
used
to
refer
to the
three
elements:
waiting
time
(0), leftand
(1)
and
right
(2)
during
the
classification
phase.
right
(2) during
the classification
phase.
and right
(2) during
the classification
phase.

Figure 3. Visual cues with timing scheme.
Figure 3.
3. Visual
Visual cues
cues with
with timing
timing scheme.
scheme.
Figure

The number of samples recorded during the EEG data acquisition phase from each of the 10
The number of samples recorded during the EEG data acquisition phase from each of the 10
The number
of samples
recorded
during
theofEEG
data
acquisition
phase
each ofEpoc
the
participants
amounts
to 76,800,
considering
eight
the 14
available
channels
onfrom
the Emotiv
participants amounts to 76,800, considering eight of the 14 available channels on the Emotiv Epoc
10
participants
amounts
to
76,800,
considering
eight
of
the
14
available
channels
on
the
Emotiv
device in relation to activity in the motor and frontal areas of the brain. Later, the samples were
device in relation to activity in the motor and frontal areas of the brain. Later, the samples were
Epoc
device(Table
in relation
activity
in blocks
the motor
and frontal
areasthen
of the
brain.
Later, in
theAlgorithm
samples were
combined
4) to to
form
signal
(nblocks)
that were
used
as input
1 in
combined (Table 4) to form signal blocks (nblocks) that were then used as input in Algorithm 1 in
combined
(Table
to formwith
signal
(nblocks) that were then used as input in Algorithm 1 in order
order to find
the4)
channel
theblocks
best performance.
order to find the channel with the best performance.
to find the channel with the best performance.
Figure 4 shows the signals acquired from block 1 for 5 s.

Sensors 2016, 16, 336

8 of 17

Sensors 2016, 16, 336

8 of 17

Table 4. Signal blocks.

Block
1
2
Block
3
41
2
5
3
64
75
86
97
8
109
10

BCI Channel
Table
FC5 4. Signal
FC6 blocks.
P7

FC5
FC6
T7
BCI Channel
FC6
FC5
P7
FC5
FC6
P7
FC6
FC5
T7
FC5
FC6
T7
F3
F4
FC5
FC6
FC5
P7
F3
F4
FC5
FC6
FC5
T7
F4
F3 FC5
FC5
F3
F4
F3
F4
F4
F3 FC5
T7
F4
F3
FC5
T7
T8
FC5
F4
F3
T7
T7
T8
P7
T7
T8
FC5
T7

T8

P7

P8
T8
P8
P8T8
T8
FC6
P8
FC6
T8
FC6
FC6
FC6T8
FC6
FC6
T8
FC6P8
P8

Figure 4 shows the signals acquired from block 1 for 5 s.

P8

E E G S ig n als

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

FC5

FC6

P7

0

Time(s)

Figure
Epoc device
device for
for 55s.s.
Figure4.4.Example
Exampleofofblock
block11EEG
EEGsignals
signalsfrom
fromfour
fourchannels
channels captured
captured by
by the
the Emotiv
Emotiv Epoc

4.2. QSA Method Implementation
4.2. QSA Method Implementation
After acquiring the data in the previous step, the next phase consisted of extracting EEG signal
After acquiring the data in the previous step, the next phase consisted of extracting EEG signal
features to find the desired classes (thinking “left”, “right” and “waiting time”). First, the QSA
features to find the desired classes (thinking “left”, “right” and “waiting time”). First, the QSA method
method was implemented (Algorithm 1) to represent EEG signal blocks as shown in Table 4, and to
was implemented (Algorithm 1) to represent EEG signal blocks as shown in Table 4, and to extract
extract the features related to the cues shown. In these experiments pre-processing was not required.
the features related to the cues shown. In these experiments pre-processing was not required. Thus,
Thus, to detect sharp changes between classes a segments matrix y(t) was obtained using 1200
to detect sharp changes between classes a segments matrix y(t) was obtained using 1200 samples for
samples for each 10 s acquired for “left” and “right” classes, and 600 samples for the “waiting time”
each 10 s acquired for “left” and “right” classes, and 600 samples for the “waiting time” class obtained
class obtained for each 5 s-long breaks. In addition, the quaternion (quat) emerged from block signals
for each 5 s-long breaks. In addition, the quaternion (quat) emerged from block signals considering
considering the first channel as the scalar component and the remaining ones as the imaginary
the first channel as the scalar component and the remaining ones as the imaginary components, as
components, as shown in Figure 5. Later, q(t) and r(t) were calculated, the latter with its relevant dt
shown in Figure 5. Later, q(t) and r(t) were calculated, the latter with its relevant dt movement. As for
movement. As for the movement, several tests were conducted using different dt values for each
the movement, several tests were conducted using different dt values for each block. In other words,
block. In other words, a dt movement of 1 to 10 was used in multiples of 7.8 ms (sample period) at
a dt movement of 1 to 10 was used in multiples of 7.8 ms (sample period) at point in time t to find
point in time t to find out its impact on the classification accuracy percentage. Rotation qrot was
out its impact on the classification accuracy percentage. Rotation qrot was calculated using q(t) and
calculated using q(t) and r(t), as well as qmod using the result of rotation qrot. Once the module was
r(t), as well as qmod using the result of rotation qrot . Once the module was obtained, the four features
obtained, the four features included in Table 3 (Mean, Contrast, Homogeneity and Variance) were
included in Table 3 (Mean, Contrast, Homogeneity and Variance) were calculated to generate matrix
calculated to generate matrix Mi,j and vector ci (where i represents the segments of y(t) and j represents
Mi,j and vector ci (where i represents the segments of y(t) and j represents the features). The resulting
the features). The resulting matrix Mi,j was using during the training and classification process to infer
matrix Mi,j was using during the training and classification process to infer the mental state and the
the mental state and the required class.
required class.

Sensors 2016, 16, 336

9 of 17

Sensors 2016, 16, 336

9 of 17

Figure 5. Creating the quaternion using elements of block 1, with FC5 channel as the scalar component
Figure 5. Creating the quaternion using elements of block 1, with FC5 channel as the scalar component
and FC6, P7 and P8 as the imaginary components.
and FC6, P7 and P8 as the imaginary components.

4.3. Classification
4.3. Classification
During the training and validation stages, several samples were taken to create submatrix Mk,j
During the training and validation stages, several samples were taken to create submatrix Mk,j
using 30% of Mi,j on condition that the data contained examples of the three classes required, that is,
using 30% of Mi,j on condition that the data contained examples of the three classes required, that is,
“left” (1), “right” (2) and “waiting time” (0). In addition, to create matrix Mm,n during the piloting
“left” (1), “right” (2) and “waiting time” (0). In addition, to create matrix Mm,n during the piloting phase,
phase, 70% of the data were used. In this study, the training and validation process was conducted
70% of the data were used. In this study, the training and validation process was conducted using
using three classifiers: (1) decision tree based on input and predictor variables; (2) SVM using a
three classifiers: (1) decision tree based on input and predictor variables; (2) SVM using a kernel-type
kernel-type Gaussian RBF with a default scaling factor; and (3) KNN, which uses the Euclidean
Gaussian RBF with a default scaling factor; and (3) KNN, which uses the Euclidean distance with a
distance with a number of default Matlab-selected neighbors. The classification process was repeated
number of default Matlab-selected neighbors. The classification process was repeated 20 times for
20 times for each of the 10 movements mentioned in each block. The methodology was applied to
each of the 10 movements mentioned in each block. The methodology was applied to each of the
each of the 10 participants with the following results: 10 participants × 10 blocks × 10 dt × 20 repeats.
10 participants with the following results: 10 participants ˆ 10 blocks ˆ 10 dt ˆ 20 repeats.
Considering all these parameters, a detailed analysis of the performance and best accuracy for
Considering all these parameters, a detailed analysis of the performance and best accuracy for
each classifier for various signal blocks and movements is presented in the following sections.
each classifier for various signal blocks and movements is presented in the following sections.
5. Results and Discussion
5. Results and Discussion
The accuracy percentages obtained during the classification phase are shown in Table 5. The
The accuracy percentages obtained during the classification phase are shown in Table 5. The table
table presents the accuracy rate for the three classifiers for each dt movement. As can be seen, with a
presents the accuracy rate for the three classifiers for each dt movement. As can be seen, with a
movement dt = 4, DT is the classifier with the best classification percentages at 84.92%, followed by
movement dt = 4, DT is the classifier with the best classification percentages at 84.92%, followed by
KNN at 84.34%. In contrast, when the movement was dt = 2, KNN was 84.39%. Finally, SVM recorded
KNN at 84.34%. In contrast, when the movement was dt = 2, KNN was 84.39%. Finally, SVM recorded
the lowest classification percentages, such as 77.49% for dt = 4.
the lowest classification percentages, such as 77.49% for dt = 4.
Table 5. Accuracy rate for DT, KNN and SVM classifiers with dt movement.
Table 5. Accuracy rate for DT, KNN and SVM classifiers with dt movement.

Classification Accuracy
Classification Accuracy
DT
KNN
SVM
dt
DT
KNN
SVM
dt
MAX MAX
MEAN
MEAN MIN
MIN MAX
MAX
MEANMIN
MIN MAX
MAX MEAN
MEANMEAN
MIN MIN
1
0.9572
0.8490
0.7662
0.9440
0.8418
0.7857
0.7815
0.7748
1
0.9572 0.8490
0.7662 0.9440 0.8418
0.7857 0.7815 0.7748
0.0000 0.0000
2
0.9551
0.8473
0.7633
0.9490
0.8439
0.7852
0.7843
0.7749
0.0000 0.0000
2
0.9551
0.8473
0.7633
0.9490
0.8439
0.7852 0.7843
0.7749
3
0.9471
0.8476
0.7660
0.9474
0.8429
0.7851
0.7837
0.7754
0.7662 0.7662
3
0.9471
0.8476
0.7660
0.9474
0.8429
0.7851 0.7837
0.7754
4
0.9507 0.8492
0.7686 0.9487 0.8434
0.7826 0.7828 0.7749
0.7633
4
0.9507
0.8492
0.8434 0.7836
0.7826 0.7822
0.7828
5
0.9516
0.84780.7686
0.7628 0.9487
0.9468 0.8432
0.7750 0.7749
0.7660 0.7633
5
0.9516
0.8478
0.8432 0.7777
0.7836 0.7809
0.7822
6
0.9468
0.84630.7628
0.7658 0.9468
0.9457 0.8412
0.7743 0.7750
0.7686 0.7660
7
0.9534
0.84740.7658
0.7638 0.9457
0.9484 0.8424
0.7749 0.7743
0.7628 0.7686
6
0.9468
0.8463
0.8412 0.7876
0.7777 0.7836
0.7809
8
0.9495
0.8478
0.7760
0.9473
0.8418
0.7837
0.7820
0.7753
0.7658 0.7628
7
0.9534
0.8474
0.7638
0.9484
0.8424
0.7876 0.7836
0.7749
9
0.9504 0.8471
0.7722 0.9499 0.8427
0.7849 0.7855 0.7748
0.7638
8
0.9495
0.8478
0.7760
0.9473
0.8418
0.7837 0.7820
0.7753
0.7658
10 0.9568 0.8475
0.7649 0.9490 0.8433
0.7879 0.7828 0.7747
0.7753
9
0.9504
0.8471
0.7722
0.9499
0.8427
0.7849 0.7855
0.7748
0.7638
10 0.9568
0.8475
0.7649
0.9490
0.8433
0.7879 0.7828
0.7747
0.7753
Figure 6, in turn, shows the graphs that correspond to Table 5 data. Figure 6a shows the symmetry
of data
for the
classifiers.
In addition,
in Figure
6, bothto(a)Table
and (b)
showFigure
that data
DT and
Figure
6, three
in turn,
shows the
graphs that
correspond
5 data.
6a for
shows
the
KNN
are
both
close
to
84%,
while
the
SVM
mean
was
recorded
as
78%.
symmetry of data for the three classifiers. In addition, in Figure 6, both (a) and (b) show that data for
DT and KNN are both close to 84%, while the SVM mean was recorded as 78%.

Sensors 2016, 16, 336
Sensors 2016, 16, 336

10 of 17
10 of 17

A ccu racy rate fo r D T , K N N an d S V M classifiers
0.96
0.94
Accuracy (Normalized %)

0.92
0.9
0.88
0.86
0.84
0.82
0.8
0.78
0.76
1

2

Classifiers

(a)

3

(b)

Figure
6. Graphical
representation
of accuracy
rates:
(a) for
DT DT
(1), (1),
KNN
(2) (2)
andand
SVM
(3);(3);
andand
(b) (b)
Figure
6. Graphical
representation
of accuracy
rates:
(a) for
KNN
SVM
accuracy
with
delta
movement.
accuracy with delta movement.

On the other hand, Figure 6b shows the accuracy of the various classifiers. Note that parameter
On the other hand, Figure 6b shows the accuracy of the various classifiers. Note that parameter
“dt” does not alter the accuracy of the results and as a result does not affect the QSA model.
“dt” does not alter the accuracy of the results and as a result does not affect the QSA model.
Table 6 shows the signal block performance results for the 10 blocks under analysis. Block 1 had
Table 6 shows the signal block performance results for the 10 blocks under analysis. Block 1 had
the best results for DT and KNN with an accuracy in excess of 86% for both classifiers at movements
the best results for DT and KNN with an accuracy in excess of 86% for both classifiers at movements of
of 1 and 3. As for SVM, it achieved an accuracy rate of 78% in block 4 with a movement dt = 8.
1 and 3. As for SVM, it achieved an accuracy rate of 78% in block 4 with a movement dt = 8.
Table 6. Best accuracy rates for signal blocks using classifiers DT, KNN and SVM.
Table 6. Best accuracy rates for signal blocks using classifiers DT, KNN and SVM.
Signal Blocks
Classifier
1
2
3
4
5Signal Blocks
6
7
8
9
10
Classifier
1
20.8635 3 0.8514 4 0.85205 0.8437
6
7
8
9
10
DT
0.8644 0.8519
0.8516
0.8485
0.8509
0.8531
DT
0.8514
0.85200.8396
0.8437 0.8451
0.8516 0.8431
0.8485 0.8509
KNN
0.8651 0.8644
0.8101 0.8519
0.86090.8635
0.8418
0.8457
0.8394 0.8531
0.8490
KNN
0.8418
0.84570.7774
0.8396 0.7784
0.8451 0.7784
0.8431 0.8394
SVM
0.7799
0.7781 0.8651
0.7770 0.8101
0.77900.8609
0.7780
0.7784 0.8490
0.7775
SVM
0.7781 0.7770 0.7790 0.7799 0.7780 0.7774 0.7784 0.7784 0.7784 0.7775

Table 7 shows that block 1 achieved the best average results for DT and KNN, unlike SVM which
Table
that
block
performed
at 7itsshows
best in
block
3. 1 achieved the best average results for DT and KNN, unlike SVM which
performed at its best in block 3.
Table 7. Average accuracy rate for signal blocks using classifiers DT, KNN and SVM.
Table 7. Average accuracy rate for signal blocks using classifiers DT, KNN and SVM.
Signal Blocks
Classifier
1
2
3
4
5
6
7
8
9
10
Signal Blocks
DT Classifier
0.8584
0.8472
0.8575 0.8467 0.8477 0.8398 0.8489 0.8417
0.8463
0.8478
1
2
3
4
5
6
7
8
9
10
KNN
0.8599
0.8370
0.8553
0.8371
0.8408
0.8357
0.8432
0.8363
0.8357
0.8457
DT
0.8584 0.8472 0.8575 0.8467 0.8477 0.8398 0.8489 0.8417 0.8463 0.8478
SVM
0.7752 0.8599
0.7752 0.8370
0.77600.8553
0.7753
0.7739 0.8357
0.7754 0.8457
0.7746
KNN
0.83710.7741
0.8408 0.7741
0.8357 0.7739
0.8432 0.8363
SVM

0.7752 0.7752 0.7760 0.7753 0.7741 0.7741 0.7739 0.7739 0.7754 0.7746

Figure 7 shows the behavior of blocks by classifier. As can be seen, blocks 1 and 3 stand out for
all three classifiers. In contrast, block 6 shows a poor performance for DT at 84.44%, block 9 produced
Figure 7 shows the behavior of blocks by classifier. As can be seen, blocks 1 and 3 stand out for all
poor results for KNN at 83.04% and block 7 did likewise for SVM at 77.02%.
three classifiers. In contrast, block 6 shows a poor performance for DT at 84.44%, block 9 produced
poor results for KNN at 83.04% and block 7 did likewise for SVM at 77.02%.
Therefore, the best accuracy results were obtained by block 1 with a movement dt = 4. Table 8 and
Figure 8 show the behavior of data obtained for each participant in block 1.

Sensors 2016, 16, 336

11 of 17

Sensors 2016, 16, 336

11 of 17
A ccu racy rate fo r D ecisio n T ree
0.87
0.86

Accuracy (Normalized %)

0.85
0.84
0.83
0.82
0.81
0.8
0.79
0.78
0.77

1

2

3

4

5

Blocks

6

7

8

9

7

8

9

10

(a)
A ccu racy rate fo r K N N
0.87
0.86

Accuracy (Normalized %)

0.85
0.84
0.83
0.82
0.81
0.8
0.79
0.78
0.77

1

2

3

4

5

Blocks

6

10

(b)
A ccu racy rate fo r S V M
0.87
0.86

Accuracy (Normalized %)

0.85
0.84
0.83
0.82
0.81
0.8
0.79
0.78
0.77

1

2

3

4

5

Blocks

6

7

8

9

10

(c)
Figure 7. Graphical representation of accuracy rates for: (a) DT; (b) KNN and (c) SVM for different blocks.
Figure 7. Graphical representation of accuracy rates for: (a) DT; (b) KNN and (c) SVM for
different blocks.

Therefore, the best accuracy results were obtained by block 1 with a movement dt = 4. Table 8
and Figure 8 show the behavior of data obtained for each participant in block 1.
Table 8. Accuracy rate for 10 subjects using classifiers DT, KNN and SVM (block 1 and dt = 4).

Table 8. Accuracy rate for 10 subjects using classifiers DT, KNN and SVM (block 1 and dt = 4).
Subjects
Classifier
Subjects
Classifier
1
2
3
4
5
6
7
8
9
10
1
2
3
4
5
6
7
8
9
10
0.94270.8425
0.8425 0.8324
0.8324 0.8291
0.8291 0.8662 0.8672
DT DT 0.9427
0.8672 0.8649
0.8649 0.8098
0.80980.7632
0.76320.8574
0.8574
KNN 0.9471
0.94710.8313
0.8313 0.7946
0.7946 0.8122
0.8122 0.8534
KNN
0.8534 0.8508
0.8508 0.8642
0.8642 0.7875
0.78750.7735
0.77350.8473
0.8473
SVM
0.7625
0.7702
0.7710
0.7797
0.7811
0.7687
0.7818
0.7788
0.7581
SVM
0.7625
0.7702
0.7710
0.7797
0.7811
0.7687
0.7818
0.7788
0.75810.7831
0.7831

metrics, such as recognition rate (RT) and error rate (ET). However, according to Ibarra [41], these
metrics do not always suffice to assess a classification method. For instance, in some cases the estimate
of the recognition rate may not contain enough information to be assessed. Therefore, further metrics
ought to be used, such as sensitivity (Sd) and specificity (Spd), and four complementary performance
metrics:
accuracy
(Ad), false alarm rate (FAd), positive probability (PPd) and negative probability
Sensors
2016, 16,
336
12 of 17
(NPd), where subscript d corresponds to the class in point.
D T accu racy rate fo r b lo ck 1
1

Accuracy (Normalize %)

0.95

0.9

0.85

0.8

0.75

1

2

3

4

5

6

Displacement dt

7

8

9

10

(a)
K N N accuracy rate fo r b lo ck 1
1

Accuracy (Normalized %)

0.95

0.9

0.85

0.8

0.75

1

2

3

4

Sensors 2016, 16, 336

5

6

Displacement dt

7

8

9

10

13 of 17

(b)
S V M accu racy rate fo r b lo ck 1

1

Accuracy (Normalized %)

0.95

0.9

0.85

0.8

0.75

1

2

3

4

5

6

Displacement dt

7

8

9

10

(c)
Figure 8. Graphical representation of accuracy rates for block 1 using: (a) DT; (b) KNN and (c) SVM
Figure 8. Graphical representation of accuracy rates for block 1 using: (a) DT; (b) KNN and (c) SVM
for block 1 and dt = 4.
for block 1 and dt = 4.

The sensitivity metric assesses how aptly the classifier can recognize samples from the class in
point. Specificity, also known as real negative rate, measures whether the classifier can recognize
samples that do not belong to the class in point. Accuracy assesses the number of samples classified
within the class in point that actually belong to it. The false alarm rate records fake positives or type-I
errors. Positive probability is concerned with the proportion of samples within the class in point that
has been classified correctly compared to the samples that do not belong to the class in point and
have been misclassified. This latter metric is weighted considering the number of samples in each

Sensors 2016, 16, 336

13 of 17

Subject 1 consistently achieved the best results compared to the remaining participants
because this was the only participant that was trained using the BCI device and data-acquisition
system. However, considering that the remaining participants had no training, their results were
good nonetheless.
The performance obtained by the three classifiers has been compared using various assessment
metrics, such as recognition rate (RT) and error rate (ET). However, according to Ibarra [41], these
metrics do not always suffice to assess a classification method. For instance, in some cases the estimate
of the recognition rate may not contain enough information to be assessed. Therefore, further metrics
ought to be used, such as sensitivity (Sd ) and specificity (Spd ), and four complementary performance
metrics: accuracy (Ad ), false alarm rate (FAd ), positive probability (PPd ) and negative probability
(NPd ), where subscript d corresponds to the class in point.
The sensitivity metric assesses how aptly the classifier can recognize samples from the class in
point. Specificity, also known as real negative rate, measures whether the classifier can recognize
samples that do not belong to the class in point. Accuracy assesses the number of samples classified
within the class in point that actually belong to it. The false alarm rate records fake positives or type-I
errors. Positive probability is concerned with the proportion of samples within the class in point that
has been classified correctly compared to the samples that do not belong to the class in point and have
been misclassified. This latter metric is weighted considering the number of samples in each class.
Negative probability measures the proportion of samples classified as not belonging to the class in
point. This metric is weighted considering the number of samples in each class.
RT “

# tc|c “ ĉu
# tcu

(8)

ET “

# tc| c ‰ ĉu
# tcu

(9)

Sd “

# tc| c “ d & c “ ĉu
# tc| c “ d u

(10)

Spd “

# tc|c ‰ d & c “ ĉu
# tc|c ‰ d u

(11)

Ad “

# tc| c “ d & c “ ĉu
# tc|ĉ “ d u

(12)

FAd “

# tc|c ‰ d & c ‰ ĉu
# tc|c ‰ d u

(13)

Sd
1 ´ Spd

(14)

1 ´ Sd
Spd

(15)

PPd “

NPd “

The results are presented in Table 9, highlighting the best score delivered by each performance
measure using the three classifiers.
Note that in Table 9 the DT classifier shows the best performance for the recognition, sensitivity,
specificity, accuracy and positive probability rates. The results for KNN are similar to those for DT,
but the former shows a better accuracy performance with class 0. The SVM classifier shows the worst
performance in recognition and error, but has a better performance in sensitivity with class 1 and
accuracy for class 0. The error rates are 15.25% for DT, 16.38% for KNN, and 22.65% for SVM, all of
them still within an acceptable range.
To sumrize, the results of testing this new method with 10 participants 20 times per participant
using 30%–70% of the data have been presented. The average performance accuracy was 84.75%
when using the DT classifier. The same test was performed using DT and SVM classifiers that

Sensors 2016, 16, 336

14 of 17

yielded an accuracy rate of 83.62% for KNN and 77.35% for the SVM classifier. After exhaustive
tests of the proposed technique, the results show that this methodology for monitoring, representing
and classifying EEG signals can be usefully applied for the purposes of having individuals control
external devices.
Table 9. Comparison of eight performance measures for the three classifiers using signal block 1,
for dt = 4. The best performance results are highlighted in bold.
Performance Measures

DT

KNN

SVM

RT
ET
S0
S1
S2
Sp0
Sp1
Sp2
A0
A1
A2
FA0
FA1
FA2
PP0
PP1
PP2
NP0
NP1
NP2

0.8475
0.1525
1
0.6505
0.6701
0.6598
0.9064
0.8972
0.9978
0.6944
0.6663
0.3402
0.0936
0.1028
4.1122
8.3456
8.6331
0
0.3830
0.3647

0.8362
0.1638
1
0.6344
0.6349
0.6343
0.8964
0.8926
0.9979
0.6548
0.5002
0.3657
0.1036
0.1074
3.5360
6.6754
8.4926
0
0.4094
0.4107

0.7735
0.2265
1
0.8775
0.0938
0.4948
0.7427
0.9638
0.9979
0.6317
0.1404
0.5052
0.2573
0.0362
1.9911
3.3885
0.9183
0
0.1524
0.9343

6. Conclusions
Representing rotations in three-dimensional spaces using quaternions is computationally more
efficient, both in terms of storage space required and the number of necessary operations. Thus, the
results presented in this article show that QSA can be used as a tool to extract EEG signal features to
identify “left” and “right” accurately using DT and KNN classifiers, even though admittedly the tests
were conducted in a semi-controlled environment.
This study has presented the QSA method to obtain features of EEG signals and to represent
motor instructions. The differences between these features were assessed using DT, SVM and KNN
classifiers. The best classification results were obtained using DT. The QSA technique opens up new
modeling and classification opportunities to process both biosignals and other types of signals for
BCI devices. The QSA technique requires greater levels of independence between signals embedded
into each quaternion for best results. In the future, this technique should be modified to reduce the
number of samples needed to obtain a class and thus the analysis and processing times. In addition,
the number of cognitive classes should be increased to include facial and emotional expressions in
tests as well.
Acknowledgments: Horacio Rostro Gonzalez wishes to acknowledge the funds provided by the Mexican Secretaría
de Educación Pública (SEP) and the University of Guanajuato (UG) within their Nuevo Profesor de Tiempo Completo
(NPTC) and Convocatoria Institucional 2015 programs. The authors also wish to express their gratitude to the
Engineering Division (DICIS) of the University of Guanajuato for the funds provided to cover the costs of
publishing in open access.

Sensors 2016, 16, 336

15 of 17

Author Contributions: Ibarra-Manzano proposed and described the theoretical use of the QSA technique;
Batres-Mendoza and Guerra-Hernandez programmed the QSA and the classifiers; Batres-Mendoza and
Montoro-Sanjosé designed and prepared the experiments; Batres-Mendoza and Almanza-Ojeda tested and
analyzed the metrics of the data; and Rostro-Gonzalez and Rene J. Romero-Troncoso contributed the BCI System,
its use and the theoretical explanation of the classifiers for implementing them. All the authors contributed to
writing the manuscript; and Montoro-Sanjose and Almanza-Ojeda carried out the proofreading of the paper.
Conflicts of Interest: The authors declare no conflict of interest.

Abbreviations
The following abbreviations are used in this manuscript:
EEG
QSA
BCI
DT
KNN
SVM
FFT
PSD
DWT
CSP
QFT
QPCA
RBF
RT
ET
S
Sp
A
PP
NP
FA
QDA
LDA
MSE
MMSE

Electroencephalography
Quaternion-based signal analysis
Brain computer interface
Decision tree
K-nearest neighbor
Support vector machine
Fast Fourier transform
Power spectral density
Discrete wavelet transform
Common spatial patterns
Quaternion Fourier transform
Quaternion principle component analysis
Radial basis function
Recognition rate
Error rate
Sensivity
Specificity
Accuracy
Positive probability
Negative probability
False alarm
Quadratic discriminant analysis
Linear discriminant analysis
Multi-scale entropy
Multivariate multi-scale entropy

References
1.

2.

3.
4.
5.

6.

Wolpaw, J.R.; Birbaumer, N.; Heetderks, W.J.; McFarland, D.J.; Peckham, P.H.; Schalk, G.; Donchin, E.;
Quatrano, L.A.; Robinson, C.J.; Vaughan, T.M. Brain-Computer interface technology: A review of the first
international meeting. IEEE Trans. Rehabil. Eng. 2000, 8, 164–173. [CrossRef] [PubMed]
Kanoh, S.; Miyamoto, K.; Yoshinobu, T. A P300-based BCI system for controlling computer cursor movement.
In Proceedings of the 33rd Annual International Conference of the IEEE Engineering in Medicine and Biology
Society (EMBC), Boston, MA, USA, 30 August–3 September 2011; pp. 6405–6408.
Escolano, C.; Antelis, J.M.; Minguez, J. A Telepresence Mobile Robot Controlled With a Noninvasive
Brain–Computer Interface. IEEE Trans. Syst. Man Cybern. B Cybern. 2012, 42, 793–804. [CrossRef] [PubMed]
Leeb, R.; Tonin, L.; Rohm, M.; Desideri, L.; Carlson, T.; Millan, J.D.R. Towards Independence: A BCI
Telepresence Robot for People With Severe Motor Disabilities. IEEE Proc. 2015, 103, 969–982. [CrossRef]
See, A.R.; Chen, S.-C.; Ke, H.-Y.; Su, C.-Y.; Hou, P.-Y.; Liang, C.K. Hierarchical character selection for a
brain computer interface spelling system. In Proceedings of the 3rd International Conference on Innovative
Computing Technology (INTECH), London, UK, 29–31 August 2013; pp. 415–420.
Wang, Y.; Li, J.; Jian, R.; Gu, R. Channel selection based on amplitude and phase characteristics for P300-based
brain-computer interface. In Proceedings of the 6th International Conference on Biomedical Engineering
and Informatics (BMEI), Hangzhou, China, 16–18 December 2013; pp. 202–207.

Sensors 2016, 16, 336

7.

8.

9.

10.

11.

12.

13.

14.

15.

16.

17.

18.
19.

20.

21.

22.

16 of 17

Samizo, E.; Yoshikawa, T.; Furuhashi, T. Improvement of spelling speed in P300 speller using transition
probability of letters. In Proceedings of the Joint 6th International Conference on Soft Computing and
Intelligent Systems (SCIS) and 13th International Symposium on Advanced Intelligent Systems (ISIS), Kobe,
Japan, 20–24 November 2012; pp. 163–166.
Amcalar, A.; Cetin, M. A brain-computer interface system for online spelling. In Proceedings of the IEEE 18th
Signal Processing and Communications Applications Conference (SIU), Diyarbakir, Turkey, 22–24 April 2010;
pp. 196–199.
Munoz, J.E.; Chavarriaga, R.; Villada, J.F.; Sebastian Lopez, D. BCI and motion capture technologies for
rehabilitation based on videogames. In Proceedings of the IEEE Global Humanitarian Technology Conference
(GHTC), San Jose, CA, USA, 10–13 October 2014; pp. 396–401.
Muñoz, J.E.; Villada, J.F.; Muñoz, C.D.; Henao, O.A. Multimodal system for rehabilitation aids using
videogames. In Proceedings of the IEEE Central America and Panama Convention (CONCAPAN XXXIV),
Panama City, Panama, 12–14 November 2014; pp. 1–7.
Vourvopoulos, A.; Liarokapis, F. Robot Navigation Using Brain-Computer Interfaces. In Proceedings of
the IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications
(TrustCom), Liverpool, UK, 25–27 June 2012; pp. 1785–1792.
Upadhyay, R.; Kankar, P.K.; Padhy, P.K.; Gupta, V.K. Robot motion control using Brain Computer Interface.
In Proceedings of the 2013 International Conference on Control, Automation, Robotics and Embedded
Systems (CARE), Jabalpur, India, 16–18 December 2013; pp. 1–5.
Chae, Y.; Jo, S.; Jeong, J. Brain-actuated humanoid robot navigation control using asynchronous
Brain-Computer Interface. In Proceedings of the IEEE/EMBS 5th International Conference on Neural
Engineering (NER), Cancun, Mexico, 27 April–1 May 2011; pp. 519–524.
Chai, R.; Ling, S.H.; Hunter, G.P.; Nguyen, H.T. Mental non-motor imagery tasks classifications of brain
computer interface for wheelchair commands using genetic algorithm-based neural network. In Proceedings
of the 2012 International Joint Conference on Neural Networks (IJCNN), Brisbane, Australia, 10–15 June 2012;
pp. 1–7.
Chai, R.; Ling, S.H.; Hunter, G.P.; Tran, Y.; Nguyen, H.T. Classification of wheelchair commands using brain
computer interface: Comparison between able-bodied persons and patients with tetraplegia. In Proceedings
of the 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society
(EMBC), Osaka, Japan, 3–7 July 2013; pp. 989–992.
Chai, R.; Ling, S.H.; Hunter, G.P.; Nguyen, H.T. Toward fewer EEG channels and better feature extractor of
non-motor imagery mental tasks classification for a wheelchair thought controller. In Proceedings of the
34th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),
San Diego, CA, USA, 28 August–1 September 2012; pp. 5266–5269.
Kim, H.S.; Chang, M.H.; Lee, H.J.; Park, K.S. A comparison of classification performance among the various
combinations of motor imagery tasks for brain-computer interface. In Proceedings of the 6th International
IEEE/EMBS Conference on Neural Engineering (NER), San Diego, CA, USA, 6–8 November 2013;
pp. 435–438.
Ofner, P.; Muller-Putz, G.R. Using a Noninvasive Decoding Method to Classify Rhythmic Movement
Imaginations of the Arm in Two Planes. IEEE Trans. Biomed. Eng. 2015, 62, 972–981. [CrossRef] [PubMed]
Tavella, M.; Leeb, R.; Rupp, R.; del Millan, J.R. Towards natural non-invasive hand neuroprostheses for daily
living. In Proceedings of the 32nd Annual International Conference of the IEEE Engineering in Medicine
and Biology Society (EMBC), Buenos Aires, Argentina, 1–4 September 2010; pp. 126–129.
Ofner, P.; Muller-Putz, G.R. Decoding of velocities and positions of 3D arm movement from EEG.
In Proceedings of the 34th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), San Diego, CA, USA, 28 August–1 September 2012; pp. 6406–6409.
Sun, H.; Xiang, Y.; Sun, Y.; Zhu, H.; Zeng, J. On-line EEG classification for brain-computer interface based
on CSP and SVM. In Proceedings of the 3rd International Congress on Image and Signal Processing (CISP),
Yantai, China, 16–18 October 2010; pp. 4105–4108.
Bhattacharyya, S.; Khasnobish, A.; Chatterjee, S.; Konar, A.; Tibarewala, D.N. Performance Analysis of LDA,
QDA and KNN Algorithms in Left-Right Limb Movement Classification from EEG Data. In Proceedings
of the 2010 International Conference on Systems in Medicine and Biology (ICSMB), Kharagpur, India,
16–18 December 2010; pp. 126–131.

Sensors 2016, 16, 336

23.

24.
25.
26.

27.

28.

29.
30.
31.
32.
33.
34.
35.

36.

37.

38.

39.
40.
41.

17 of 17

Jiralerspong, T.; Liu, C.; Ishikawa, J. Identification of three mental states using a motor imagery based brain
machine interface. In Proceedings of the 2014 IEEE Symposium on Computational Intelligence in Brain
Computer Interfaces (CIBCI), Orlando, FL, USA, 9–12 December 2014; pp. 49–56.
Costa, M.D.; Goldberger, A.L. Generalized Multiscale Entropy Analysis: Application to Quantifying the
Complex Volatility of Human Heartbeat Time Series. Entropy 2015, 17, 1197–1203. [CrossRef]
Ahmed, M.U.; Mandic, D.P. Multivariate multiscale entropy: A tool for complexity analysis of multichannel
data. Phys. Rev. E Stat. Nonlinear Soft Matter Phys. 2011, 84, 3067–3076. [CrossRef] [PubMed]
Morabito, F.C.; Labate, D.; La Foresta, F.; Bramanti, A.; Morabito, G.; Palamara, I. Multivariate Multi-Scale
Permutation Entropy for Complexity Analysis of Alzheimer’s Disease EEG. Entropy 2012, 14, 1186–1202.
[CrossRef]
Ell, T.A. Quaternion Fourier Transform: Re-tooling Image and Signal Processing Analysis. In Quaternion
and Clifford Fourier Transforms and Wavelets, 1st ed.; Hitzer, E., Sangwine, S.J., Eds.; Birkhäuser Basel: Basel,
Switzerland, 2013; pp. 3–14.
Zhao, Y.; Hong, W.; Xu, Y.; Zhang, T. Multichannel Epileptic EEG Classification Using Quaternions and
Neural Network. In Proceedings of the First International Conference on Pervasive Computing Signal
Processing and Applications (PCSPA), Harbin, China, 17–19 September 2010; pp. 568–571.
Pfurtscheller, G.; Neuper, C. Motor imagery and direct brain-computer communication. IEEE Proc. 2001, 89,
1123–1134. [CrossRef]
Hamilton, W.R. On quaternions. Proc. R. Ir. Acad. 1847, 3, 1–16.
Pujol, J. Hamilton, Rodrigues, Gauss, Quaternions, and Rotations: A Historical Reassessment.
Commun. Math. Anal. 2012, 13, 1–14.
Kotsiantis, S. A hybrid decision tree classifier. J. Intell. Fuzzy Syst. 2014, 26, 327–336.
White, R.L. Astronomical Applications of Oblique Decision Trees. AIP Conf. Proc. 2008, 1082, 37–43.
Elnaggar, A.A.; Noller, J.S. Application of Remote-sensing Data and Decision-Tree Analysis to Mapping
Salt-Affected Soils over Large Areas. Remote Sens. 2010, 2, 151–165. [CrossRef]
Xu, H.; Song, W.; Hu, Z.; Chen, C.; Zhao, X.; Zhang, J. A speedup SVM decision method for online EEG
processing in motor imagery BCI. In Proceedings of the 10th International Conference on Intelligent Systems
Design and Applications (ISDA), Cairo, Egypt, 29 November–1 December 2010; pp. 149–153.
Labate, D.; Palamara, I.; Mammone, N.; Morabito, G.; La Foresta, F.; Morabito, F.C. SVM classification of
epileptic EEG recordings through multiscale permutation entropy. In Proceedings of the 2013 International
Joint Conference on Neural Networks (IJCNN), Dallas, TX, USA, 4–9 August 2013; pp. 1–5.
Li, K.; Zhang, X.; Du, Y. A SVM based classification of EEG for predicting the movement intent of human
body. In Proceedings of the 10th International Conference on Ubiquitous Robots and Ambient Intelligence
(URAI), Jeju, Korea, 30 October–2 November 2013; pp. 402–406.
NirmalaDevi, M.; Appavu, S.; Swathi, U.V. An amalgam KNN to predict diabetes mellitus. In Proceedings of
the 2013 International Conference on Emerging Trends in Computing, Communication and Nanotechnology
(ICE-CCN), Tuticorin, India, 25–26 March 2013; pp. 691–695.
Diebel, J. Representing Attitude: Euler Angles, Unit Quaternions, and Rotation Vectors; Technical Report; Stanford
University: Stanford, CA, USA, 2006.
Haralick, R.M.; Shanmugam, K.; Dinstein, I. Textural Features for Image Classification. IEEE Trans. Syst.
Man Cybern. 1973, 3, 610–621. [CrossRef]
Ibarra-Manzano, M. Vision Multi-Caméras Pour la Detection d´obstacles sur un Robot de Service: Des
Algorithms à un Système Integer. Ph.D. Thesis, University of Toulouse, Toulouse, France, January 2011.
© 2016 by the authors; licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons by Attribution
(CC-BY) license (http://creativecommons.org/licenses/by/4.0/).

