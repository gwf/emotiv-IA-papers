Loizides, F., Naughton, L., Wilson, P., Loizou, M., Yang, S. , Hartley, T.,
Worrallo, A. and Zaphiris, P. (2017) Interactive Reading Using Low Cost
Brain Computer Interfaces. In: 16th IFIP TC.13 International Conference
on Human-Computer Interaction: INTERACT 2017, Mumbai, India, 25-29
Sept 2017, pp. 450-454. ISBN 9783319680583 (doi:10.1007/978-3-31968059-0_49)
This is the author’s final accepted version.
There may be differences between this version and the published version.
You are advised to consult the publisher’s version if you wish to cite from
it.

http://eprints.gla.ac.uk/147376/

Deposited on: 06 October 2017

Enlighten – Research publications by members of the University of Glasgow
http://eprints.gla.ac.uk

1

Article

2

Project MindReader: Reading Using Affordable BCI

3

Fernando Loizides , Liam Naughton, Paul Wilson, Shufan Yang and Michael Loizou

4
5

fernando.loizides@wlv.ac.uk, L.Naughton@wlv.ac.uk, PaulJWilson@wlv.ac.uk, Michael.Loizou2@wlv.ac.uk,
S.Yang@wlv.ac.uk

6

Abstract:

7
8
9
10
11
12
13
14
15
16

“Although Brain computer interface (BCI) devices are beginning to aim at the consumer level, their
cognitive usability is still limited, especially for a physically-disabled person. To improve usability
of BCI interfaced devices, we employed the Emotiv Epoc, a low-priced electroencephalography
(EEG) headset, to design and build a proof-of-concept document reader system that allows users to
navigate the document without the need of physical actions. Our prototype has been implemented
and evaluated with 12 participants who were trained to navigate documents using brain signals
acquired by Emotive EEG. In addition to testing cognitive actions of participants, we also proposed
an automata theory based benchmark to model the participants’ behaviours. Furthermore, our
framework is also able to identify every software bottleneck and to provide future ways for
improvement.”

17
18
19

Keywords: Brain Computer Interface; Document Reader; Affordable; BCI

20

1. Introduction

21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44

BCIs produce a way of communicating brain activity, which can help physically disabled people
make use of more common assistive technologies. When an individual thinks of an action they wish
to make, such as pushing a mouse device, electrical activity produced by the brain penetrates the
skull and can be measured on the scalp using electrodes. This is called
electroencephalography (EEG). Different actions (and specifically action intents – which is the
intention or desire to stimulate an action) are associated with different patterns of electrical activity.
These associated patterns of electrical brain activity, enable the actions or intent of the user to be
interpreted without the physical action occurring.
Affordable brain-computer interface technology has only recently become accessible to users
with limited and experimental software. This subject therefore, although emerging, has only seen
limited (yet promising) research. The effects of affordable brain computer interface technology being
integrated into people's lives can have a positive impact in the way that both non-disabled and
disabled people interact with their surroundings through technology. This social aspect has not yet
been researched. Inclusive design such as this can allow individuals to live better, more comfortable
and productive lives, enabling them to interact better in society. Beyond the affordable physical
interaction, the research can play a positive psychological, social and emotional role for disabled
people. The applications of a brain computer interface is primarily to introduce another level of
multimodality to a user. The work is therefore not limited in findings to those individuals with
disabilities but rather produces a basis and foundation that will ultimately be used to enable those
people within the disability spectrum.
In this paper we propose a framework using an affordable, non-intrusive method to investigate
cognitive control usability for EEG enabled BCI devices. Firstly an affordable prototype is
implemented to investigate the efficacy of allowing quadriplegic patients elementary control over a

45
46
47
48
49
50
51
52
53
54
55
56

document reader thus reinstating autonomy to the individual without the need for assistive care. By
detecting EEG activity from a brain computer interface (BCI) and mapping the cognitive functions to
physical actions, users are able to navigate through a document without any movement from their
limbs. The initial phase of testing is to improve the validity of our framework using an in-suited
software (see details in section 3). In future we will improve the prototype to make it easier for users
which then will be tested by paraplegic and quadriplegic individuals.
The work presented in this paper is organized as follows: The background and related work
section describes the required background knowledge of BCI devices; The prototype and the user
study description is then outlined; The results and discussion regarding to user actions with a
mathematical automata based theory language are presented a) to create a foundation for visual
inspection, b) to evaluate action impacts and improvements c) to increase the ecological validity of
the findings by therefore allowing wide communication of the work to other disciplines.

57

2. Background and Related work

58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91

A brain computer interface (BCI) devices provide a new channel for communication and control,
which can offer a new range of assistive and rehabilitative applications for people who suffer from
motor impairment [1, 2]. Traditionally the BCI area related research is based on expensive and
complex prototypes such as the Graz brain-computer interface II [3, 4]. The cost for conducting
research using EEG based BCI devices was still relatively high for individuals and require a number
of specially trained people to set up[5,6].
During the last decade, more affordable/consumer BCI devices have been released and used for
academic research purposes. These include: the Neurosky Mindset headset 1 , used to enhance
cognitive functions and increase satisfaction within a game called ‘Neuro Wander’ [7]; the Myndplay
Brainband, used to elicit different mind states of participants viewing emotional videos [8]; and the
OpenBCI system, used for investigating optimal electrode placement for motor imagery applications
[9].
The Emotiv Epoc2 device is inexpensive, commercially available and has been used extensively
in the past for similar types of research with good results [10-15]. This device is used to measure the
engagement level of users using the physiological reading method [10] and is an innovative approach
that aims to enhance the user’s learning experience by measuring the engagement of the user.
Stytsenko et al reported that Epoc was “able to acquire real EEG data which is comparable to the one
acquired by using conservative EEG devices” [16]. Their research team also used this device for
measuring and evaluating user experience [11]. These measures were used as part of a simulation
where the users were controlling the movement of a simulated robot. The engagement data showed
that each test provided a different kind of experience for users and an unbalanced experience between
the users. Epoc was also used for evaluating if a low priced commercial device can be used as an
interface for users with no impairments for controlling assistive technology devices with their
thoughts [12]. The results supported this as all of the participants achieved positive success rates at
the end of the training period.

Duvinage et al’s work reported a high signal-to-noise ratio problem of Emotive Epoc, but they
demonstrated that Epoc was capable of recording EEG [15]. They warned that the device would be
more suitable for non-critical applications rather than prosthetics or rehabilitation as it may cause
serious consequences if the control fails or lacks accuracy [15]. Furthermore, Taylor et al produced
results which “found the system to perform significantly better than chance for all mental actions,
and improve over time with additional training data” [17].

1

http://neurosky.com/biosensors/eeg-sensor/ - Accessed March 2016

2

https://emotiv.com/epoc.php - Accessed March 2016

92

3. Materials and Methods

93

3. 1 Prototype

94
95
96
97
98

The prototype system architecture consists of four key components. These are:
1. Emotiv Epoc EEG Headset

99
100
101
102
103
104
105
106
107
108
109
110
111

2.

EmoKey Software

3.

Epoc Control Panel

4.

MindReader Software

The Emotiv Epoc Headset is used to receive raw EEG data and brain patterns from the
individual and send the signal to the Epoc Control Panel. The BCI contains 14 channels (See electrodes
AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4 in Figure 3) and 2 reference points (In the
CMS/DRL noise cancellation configuration P3/P4 locations). It uses a sequential sampling rate of 2048
Hz, a bandwidth of 0.2 – 43Hz, digital notch filters (at 50Hz and 60Hz) and a dynamic range of 8400
μV(pp). The P300 evoked potential causes a 300ms delay after a relevant sensory stimulus.
The Control Panel then clears the noise and separates distinct and recognizable pattern actions
such as “think push”, “think pull”, “think lift”, “smile” and “Clench”. Upon detecting on of the
selected patterns that constitute a specific action, the control panel then triggers the (customized)
Emokey Software.
Emokey Software translates the thought actions to physical keyboard keystrokes. In turn,
keystrokes are detected by the MindReader Software which instigates navigational actions on the
document reader.

112
113

Figure 1. Key Components to Operate MindReader System

114
115
116
117
118
119
120
121
122
123
124
125
126

Our prototype software MindReader is written in C# through WinForms under the .NET
framework. The specific release (Beta V.01) presented in the paper and used for the user testing
comprises of a document reader that loads a series of documents that have been translated to images
from PDFs. Although the MindReader code is not open source yet, we are plan to publish the source
code in near future.
In this work, MindReader software produces a two page reading format (See Figure 2) for the
user but can be adapted beforehand to a single page view. The software currently in its beta stage
allows for user testing controls; namely, the investigator can imitate a “start task” trigger which will
take readings such as location, navigation speed and user intent (actions performed). The software is
also able to use simple key strokes or buttons to move between the pages but these are only visible
as an addition for future work involving the integration of eye-tracking equipment with BCI devices.
Users should be able to navigate forward and backward one page at a time, controlled by the Emotiv
Epoc.

127
128

Figure 2. MindReader Beta Version 0.1

129

Code snippets of the navigating algorithm can be found below (C#):

130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154

// initialise timer and record at 100ms

aTimer.Elapsed += new ElapsedEventHandler(OnTimedEvent);
aTimer.Interval = 100;

// append all details of time to file when state changes

hour = DateTime.Now.Hour;
min = DateTime.Now.Minute;
sec = DateTime.Now.Second;
TimeSpan time = new TimeSpan(hour, min, sec);
File.AppendAllText(file_times, time.ToString());
File.AppendAllText(file_times, ",");

// append all details of location to file during all intervals

File.AppendAllText(file_pages, pageisat.ToString());
File.AppendAllText(file_pages, ",");

// change page state when EEG pattern indicates next page
if (e.KeyCode == Keys.R)
{
Next.PerformClick();
}
pageisat = pageisat + 1;
pictureBox1.Image = WindowsFormsApplication1.Properties.Resources.Page5;
pictureBox2.Image = WindowsFormsApplication1.Properties.Resources.Page6;

155
156
157

Figure 3. Emotiv Epoc Electrode placements from [20]. CMS and DRL are ground and work as reference point
in our experiment.

158

3.2. Experiments

159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181

To test the prototype we chose 14 participants to take part in our study. 2 of the participants
were asked to be pilot subjects to fine tune the testing variables such as the amount of saline solution
needed on the BCI pads, time required per test and the sensitivity settings on all the software that
needed to communicate.
The 12 main participants (5 female – 7 male) were given a short description of the experiment
and each was given a choice of actions that they could choose from in order to calibrate the forward
and backward actions. Specifically, participants could choose from Think Push, Think Pull, Lift,
Clench and Smile. Once the participant had chosen a set of actions, they would then be calibrated to
the specific individual, a process that took no more than 5 minutes per participant (See Figure 3).
‘Signatures’ classify user EEG input into mapped expressions and intentions. A default signature
is known as the universal signature and is an average estimation of the predicted readings that any
user would produce in terms of brain activity for a given action. For our calibration we rejected the
universal signature in place for a per participant, trained signature. These are called baseline
signatures. In order to create the baseline signatures performance metrics require the user to train the
system by performing the desired action before it can be detected.
All 14 electrode placements were placed on the users’ head with 2 noise cancelling points (See
Figure 3 - CMS and DRL). Motor action thoughts were prevalent with readings elevated on the
primary motor cortex and supplementary motor area during training. The Premotor cortex also
spiked in activity during the training exercises. The algorithm used to capture each user’s individual
signature is internal to the custom software from the BCI headset and is beyond the scope of this
study. In future we will refine the individual electrode readings to allow us to focus on specific
electrode readings only and work towards our own universal signatures.

182
183

Figure 4. User Interacting with MindReader

184
185
186
187
188
189
190
191
192
193
194
195
196

Once the BCI connection was established and calibrated, our prototype software MindReader
was loaded with a document containing 16 pages in a two page view (book style view) and the
participants were then given a set of tasks to complete. These tasks were:
TASK 1 – Navigate to the Contents Page – this was page 1

197
198
199
200

TASK 10 – Feel free to browse the magazine. (For the qualitative feedback)
No think–aloud comments were permitted. After the tasks a semi-structured interview was
conducted for qualitative feedback.

201

4. Results

202
203
204
205
206
207
208

To test the validity of our work, raw data samples of EEG activity were recorded. It was used
to establish a baseline of the actions that the users were able to select EEG level in terms of a specific
action their chosen. The users were recorded in a ‘neutral state’ and then their EEG activity was
recorded with five options: Smile, Clench, Pull, Push and Lift. Afterwards a statistical t-test was used
to identify elevation in EEG between neutral states and action states. Most of the actions produced
statistically significant changes in the readings from the majority of the electrodes (See Figure 5).

TASK 2 – Navigate back to the beginning (page 0)
TASK 3 – Navigate to Page 6
TASK 4 - Navigate back to the beginning (page 0)
TASK 5 – Navigate to Page 12
TASK 6 - Navigate back to the beginning (page 0)
TASK 7 – Navigate to the last Page
TASK 8 - Navigate back to the beginning (page 0)
TASK 9 – Answer the question: How many babies do female goats give birth to? (the answer is on
page 2)

209
210
211
212
213
214
215
216
217
218
219
220
221
222
223

Smile
Clench
Pull
Push
Lift

AF3

F7

F3

FC5

T7

P7

O1

O2

P8

T8

FC6

F4

F8

AF4

< 0.01
0.89134
< 0.01
< 0.01
0.654926

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
0.392256
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

0.343301
< 0.01
< 0.01
0.343301
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

Figure 5: T-Test of neutral state verses actions states of electrode EEG readings (p <0.01 n = 1200)

We can report on the high level of noise that occurs from the different regions of the EEG activity
but can verify that the F3 and F4 regions associated mostly with motor actions produced also
significant differences which can give evidence towards the successful use of motor intentions EEG
to control the virtual actions of our software [18].
We also checked specifically for EMG contamination [19] from testing the active readings
between the F3/F4 and AF3/AF4 electrodes during active thoughts by the participants. An example
can be seen in Figure 6 - Left. We wanted to check for elevation of the F3/F4 electrodes closer to the
motor cortex. The results can be seen in Figure 6 - Right. All the tests were statistically significant
with a t-test revealing p < 0.01 (n = 1200). All the results were statistically significant to the 0.01 level
with 1200 samples for all actions.

4600
4400

Smile
Clench
Pull
Push
Lift

4200
4000
3800
3600
F3

224
225
226
227
228
229
230
231
232
233
234
235

AF3

F3 AF3

F4 AF4

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

< 0.01
< 0.01
< 0.01
< 0.01
< 0.01

Figure 6: (left) Readings (in μV microVolts) of an active state of the user thinking ‘Lift’ of the F3 and AF3
electrodes. (Right) statistical difference in F3/F4 and AF3/AF4 electrodes during action thoughts P <
0.01, n = 1200.

In this section we present the raw data and make observations based on the performance of the
participants via visual inspection. Tasks 1,2,5,6,7 and 8 are reported on. The remaining two tasks (3
and 4) do not produce data that adds to the findings and therefore were not included in the results.
Figure 7 presents an overview of the tasks and the time taken, as well as the errors that were made in
taking the tasks.

Task Number Number Minimum Maximum
Error

Errors

Free

Time

Time(seconds)

(seconds)

1

9

1

2

8

2

7

5

2

7

5

8

9

8

29

236

6

8

4

7

41

7

8

18

8

40

8

11

1

8

50

Figure 7. Data Overview (including time and errors)

237

Task 1

238
239
240
241

Figure 8 shows the results obtained when the participants were asked to navigate from the first
to the next page. Clearly there are great variations in the times taken, the minimum time being 2
seconds, and the maximum 8 seconds. Only one participant made the error of moving onto the second
page, the others navigated to page 1 directly.

242
243

Figure 8. Task One Results

244

Task 2

245
246
247
248

Figure 9 shows the results obtained when the participants were asked to navigate from the
second page to the start. Again there are great variations in the times taken, the minimum time being
2 seconds, and the maximum 7 seconds. Seven of the ten participants completed the task without
error. Two participants made 2 errors each. The remaining participant did not attempt the task.

249
250

Figure 9. Task 2 Results

251

Task 5

252
253
254
255
256
257
258

Figure 10 illustrates the patterns taken by the twelve participants when asked to navigate to page
six. Clearly there is great diversity, 8 of the 12 participants navigated to page 6 without error, but
the time taken to do this varied from 8 to 29 seconds. The number of errors made by the other 4
participants varied from 1 to 5. There is no evidence of a relationship between the number of errors
made and the time taken to complete the task, and it would appear that errors are equally likely to
occur at any stage of the task.

259
260

Figure 10. Task 5 Results

261

Task 6

262
263
264

Figure 11 illustrates the patterns taken by the twelve participants when asked to navigate from
page six back to the start. Again there is great diversity. 8 of the 12 participants sucsessfully navigated
from page 6 to the start without error, but the time taken to do this varied from 7 to 41 seconds,

265
266

the other 4 participants each made exactly one error. Times varied between 9 and 41 seconds, and
there appears to be little or no relationship between errors being made and completion time.

267
268

Figure 11. Task 6 Results

269

Task 7

270
271
272
273
274

Figure 12 illustrates the patterns taken by the twelve participants when they were asked to
navigate from the start to the end (page 8). Unsurprisingly, the results are similar to those of task 5,
where participants had to navigate to page 6. Eight of the twelve participants navigated to page 8
without error. One participant failed to commence the task and the other three made 2, 6 and 9 errors.
Completion times, (excluding the person who failed to start) varied between 8 and 40 seconds.

275
276

Figure 12. Task 7 Results

277

Task 8

278
279

Figure 13 illustrates the patterns obtained when the participants were asked to navigate back to
the start from the end. One participant (represented by the green line of the top diagram) appears not

280
281

to have properly attempted the task. All of the remaining participants completed the task without
error, in times varying from 8 seconds to 50 seconds.

282
283

Figure 13. Task 8 Results

284

Task 9

285
286
287

In this task, participants were asked to `` Answer the question: How many babies do female
goats give birth to?’’ The answer was on page 2. It would appear that there was confusion about the
nature of this task as few participants navigated to page two and stopped (See Figure 12).

288
289

Figure 14. Task 9 Results

290

5. Automata Theory Based Evaluation Model

291
292
293
294
295

In addition to testing the validity of our document reader prototype system, we also presented
a framework to analyse user actions. Our aim is to describe a universal framework which can be
modified and applied to a variety of situations. We introduce
a collection of tools and techniques based on Automata Theory, an area on the boundary of
theoretical computer science and mathematics. Automata Theory is often used to model computation,

296
297
298
299
300
301
302
303
304
305

but in this work we demonstrate how it can be used to model the human behavior [21]. A finite
automaton can be pictured by a directed graph called a state transition diagram with nodes
representing states and arrows labeled by letters of the alphabet.
We use states Q= {0,1,2,3,4,5,6} corresponding to the pages. If a participant is at page q , his/her
movement can either to page q+1 via transition R or to page q-1 via transition L. The initial state in
the model is state s which does not correspond to a page in the document. It serves as a start state
only. Each task begins by moving via an empty transition ε from state s to the required start page.
Then the task is accomplished by a sequence of transitions from the start state to the accepting state.
In the initial model (See Figure 15) it is possible to make an empty transition to every state and ever
state is classified as an accepting state.

306
307

Figure 15. Total Transition Model

308
309

To carry out a task we restrict the possibilities for empty transitions and we restrict the set of
accepting states (See Figure 16).

310
311
312
313
314

Figure 16. Single Transition Possibility Model
There is only one empty transition available; from state s to state 0 . The task terminates
successfully when the participant navigates to page 6. Thus the only accepting state is now state 6.
The restricted model from the overall model above for tasks 1,2,5,6,7 and 8 are shown in Figure 17.

Task 1

Task 2

Task 5

Task 6

Task 7

Task 8

315

Figure 17. Restricted Model Variations Based on the Assigned Tasks

316
317
318
319

A notion of optimality exists in the above tasks. For example, task 6 requires the user to navigate
from page 6 to page 0. The optimal solution here is to perform the sequence of transitions LLLLLL.
In task 7 the optimal sequence of transitions is RRRRRRRR. The variety if terms of sequences of
transitions used by the participants is summarized in the graphs in the previous Section.

320

6. Conclusions and Future Work

321
322
323
324
325
326
327
328
329
330
331
332
333
334
335

We described the prototype of document reader to identify the efficacy in using affordable brain
computer interfaces to control elementary functions. This work included with a) creating a prototype
document reader which could be controlled with affordable commercial BCI equipment b) testing
with 12 participants to identify the successful use of the software in order to improve cognitive
usability.
Our experiment results demonstrate that participants can navigate through the pages of a
document reader in order, although minimal calibration is needed and errors were present (such as
overshooting pages). We have also modelled the user behavior for further identifying software
bottlenecks and transfer the finding into other software with navigation capabilities.
We present our results as a pilot testing. The main aim of the study was to show reasonable
evidence of the efficacy of using affordable BCI equipment to control basic actions of a document
reader. The number of participants (12) means that there is limited scope in this study for in depth
comparisons. In future, an experiment with a much larger participants will be conducted.
Specifically the future work will include with (a) reducing errors through improving the software

336
337
338
339
340
341
342
343
344
345
346
347

algorithms and by testing further hardware variations; (b) answering behavioural and interactivity
questions such as “Is getting further in the magazine of proportional effort to getting to an earlier
page?” The sequential nature of the experiment means that it is likely that participants “improved”
as they progressed from task to task. These learning effects can be minimized by randomizing the
tasks in future experiments. “Do different tasks seem to give more difficulties than others and why?”
This can be tackled by changes test variables such as assigning longer tasks.
Furthermore, we will also introduce our improved document reader assistive system to
quadraplegic patients. We also plan to include further compliments to the setup that will give further
autonomy and freedom to users, such as pairing the BCI with an eye-tracker for gaze / fixation
recognition. Further software, such as internet browsers are also being developed based on the same
principles.

348

Acknowledgments: ANON

349

Author Contributions: ANON

350

Conflicts of Interest: ANON

351

References

352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386

1.

2.
3.

4.

5.

6.

7.

8.
9.

10.

11.

12.

GUGER, C., EDLINGER, G., HARKAM, W., NIEDERMAYER, I. & PFURTSCHELLER, G. 2003. How
many people are able to operate an EEG-based brain-computer interface (BCI)? Neural Systems and
Rehabilitation Engineering, IEEE Transactions on, 11, 145-147.
MÜHL, C., SCHERER, R., LÉCUYER, A., PERRONNET, L., GROSSE-WENTRUP, M. & LOTTE, F.
Which factors drive successful BCI skill learning? 6th International BCI conference, 2014.
MAYNARD, E. M., NORDHAUSEN, C. T. & NORMANN, R. A. 1997. The Utah intracortical electrode
array: a recording structure for potential brain-computer interfaces. Electroencephalography and clinical
neurophysiology, 102, 228-239.
KALCHER, J., FLOTZINGER, D., NEUPER, C., GÖLLY, S. & PFURTSCHELLER, G. 1996. Graz braincomputer interface II: towards communication between humans and computers based on online
classification of three different EEG patterns. Medical and biological engineering and computing, 34, 382388.
BLANKERTZ, B., DORNHEGE, G., KRAULEDAT, M., MÜLLER, K.-R., KUNZMANN, V., LOSCH, F.
& CURIO, G. 2006. The Berlin Brain-Computer Interface: EEG-based communication without subject
training. Neural Systems and Rehabilitation Engineering, IEEE Transactions on, 14, 147-152.
MCFARLAND, D. J., LEFKOWICZ, A. T. & WOLPAW, J. R. 1997. Design and operation of an EEGbased brain-computer interface with digital signal processing technology. Behavior Research Methods,
Instruments, & Computers, 29, 337-345.
YOH, M.-S., KWON, J. & KIM, S. NeuroWander: a BCI game in the form of interactive fairy tale.
Proceedings of the 12th ACM international conference adjunct papers on Ubiquitous computingAdjunct, 2010. ACM, 389-390
DE MAN, J. 2014. Analysing Emotional Video Using Consumer EEG Hardware. Human-Computer
Interaction. Advanced Interaction Modalities and Techniques. Springer.
SURYOTRISONGKO, H. & SAMOPA, F. 2015. Evaluating OpenBCI Spiderclaw V1 Headwear's
Electrodes Placements for Brain-Computer Interface (BCI) Motor Imagery Application. Procedia
Computer Science, 72, 398-405.
ANDUJAR, M & GILBERT, JE 2013, 'Let's learn!: enhancing user's engagement levels through passive
brain-computer interfaces', in CHI'13 Extended Abstracts on Human Factors in Computing Systems, pp.
703-8.
CRAWFORD, CS, ANDUJAR, M, JACKSON, F, REMY, S & GILBERT, JE 2015, 'User Experience
Evaluation Towards Cooperative Brain-Robot Interaction', in Human-Computer Interaction: Design and
Evaluation, Springer, pp. 184-93.
LIEVESLEY, R, WOZENCROFT, M & EWINS, D 2011, 'The Emotiv EPOC neuroheadset: an
inexpensive method of controlling assistive technologies using facial expressions and thoughts?',
Journal of Assistive Technologies, vol. 5, no. 2, pp. 67-82.

387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407

13.
14.

15.
16.

17.
18.
19.
20.

MCMAHAN, T, PARBERRY, I & PARSONS, TD 2015, 'Modality specific assessment of video game
player’s experience using the Emotiv', Entertainment Computing, vol. 7, pp. 1-6.
LIAROKARPIS, F, DEBATTISTA, K, VOURVOPOULOS, A, PETRIDIS, P & ENE, A 2014, 'Comparing
interaction techniques for serious games through brain “computer interfaces: A user perception
evaluation study', Entertainment Computing, vol. 5, no. 4, pp. 391-9.
Duvinage, Matthieu, et al. "Performance of the Emotiv Epoc headset for P300-based
applications." Biomedical engineering online 12.1 (2013): 1.
Taylor, Grant S., and Christina Schmidt. "Empirical evaluation of the Emotiv EPOC BCI headset for
the detection of mental actions." Proceedings of the Human Factors and Ergonomics Society Annual
Meeting. Vol. 56. No. 1. SAGE Publications, 2012.
Stytsenko, Kirill, Evaldas Jablonskis, and Cosima Prahm. "Evaluation of consumer EEG device Emotiv
EPOC." MEi: CogSci Conference 2011, Ljubljana. 2011.
Pope, Kenneth J., et al. "Relation of gamma oscillations in scalp recordings to muscular activity." Brain
topography 22.1 (2009): 13-17.
Goncharova, Irina I., et al. "EMG contamination of EEG: spectral and topographical
characteristics." Clinical neurophysiology 114.9 (2003): 1580-1593.
H. Ekanayake, “Scalp locations covered by emotiv epoc,” last visited on 2016-09 [Online].Available:

http://neurofeedback.visaduma.info/images/fig_emotivpositions.gif
21.

Chakraborty, P., Saxena, P. C., Katti, C. P. 2011. Fifty Years of Automata Simulation: A Review. ACM
Inroads, 2(4):59–70.

