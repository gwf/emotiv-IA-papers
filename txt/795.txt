Singapore Management University

Institutional Knowledge at Singapore Management University
Research Collection School Of Information Systems

School of Information Systems

6-2016

Jasper: Sensing gamers' emotions using
physiological sensors
Sinh HUYNH
Singapore Management University, npshuynh.2014@phdis.smu.edu.sg

Youngki LEE
Singapore Management University, YOUNGKILEE@smu.edu.sg

Taiwoo PARK
Michigan State University

Rajesh Krishna BALAN
Singapore Management University, rajesh@smu.edu.sg

DOI: https://doi.org/10.1145/2934646.2934648

Follow this and additional works at: https://ink.library.smu.edu.sg/sis_research
Part of the Software Engineering Commons
Citation
HUYNH, Sinh; LEE, Youngki; PARK, Taiwoo; and BALAN, Rajesh Krishna. Jasper: Sensing gamers' emotions using physiological
sensors. (2016). MobiGames '16: Proceedings of the 3rd Workshop on Mobile Gaming, Singapore, June 30. 1-6. Research Collection
School Of Information Systems.
Available at: https://ink.library.smu.edu.sg/sis_research/3305

This Conference Proceeding Article is brought to you for free and open access by the School of Information Systems at Institutional Knowledge at
Singapore Management University. It has been accepted for inclusion in Research Collection School Of Information Systems by an authorized
administrator of Institutional Knowledge at Singapore Management University. For more information, please email libIR@smu.edu.sg.

Published in MobiGames '16: Proceedings of the 3rd Workshop on Mobile Gaming, Singapore, June 30, 2016. New York: ACM
Pages 1-6. ISBN: 978-1-4503-4325-1
http://dx.doi.org/10.1145/2934646.2934648

Jasper: Sensing Gamers’ Emotions Using
Physiological Sensors
Sinh Huynh† , Youngki Lee† , Taiwoo Park‡ , Rajesh Krishna Balan†
†

Singapore Management University, ‡ Michigan State University

ABSTRACT

feelings during game play. However, accurate and effective
emotion sensing is still an open research challenge.
A widely-adopted approach to evaluate user emotions is
self-assessments using questionnaires or interviews [3][12].
However, this approach solely relies on users’ subjective responses, and hardly capture in-situ emotions while users feel
them on the spot. Another approach is to automatically
recognize emotions from facial expressions, body languages,
and gestures [9]. This vision-based approach is limited in
that users’ expression does not necessarily reflect what they
actually feel (i.e. people can manipulate their expression).
In addition, the vision-based approach is computationally
expensive and causes privacy concerns.
In this study, we explore an approach of using physiological signals to recognize emotions of mobile gamers. This
approach is advantageous over the two aforementioned approaches. First, it enables in-situ assessment of emotions
during the game play without any user’s active involvement
or attention. Second, once successfully developed, it could
enable more objective measurement of emotions. The periphery physiological signals such as electrodermal activity
or blood circulation are involuntary and activated by the
autonomic nervous system (ANS), hence, those signals are
useful to detect actual inner emotions and robust to expression manipulation (e.g. social making).
We aim at building a automated emotion assessment system, Jasper, that can (1) recognize mobile gamers’ emotions
using commodity wearable devices, and (2) suggest game designers on how game components need to be adjusted to enhance player’s emotional experience. More specifically, we
conducted a user study in which participants play a same
Android game (Tank 1990) with various settings of difficulty
level and social playing mode to study how these two game
components influence emotions of gamers. We also examined how physiological signals from three different channels
including Galvanic Skin Conductance (GSR), photoplethysmography (PPG), and electroencephalogram (EEG) are associated with gaming emotions. Our studies conducted with
22 mobile game players show that Jasper can classify the 3
levels of excitement at an accuracy of 77.38% and the binary
states of happiness at an accuracy of 73.21%.
The contribution of this paper is as follows:

This paper aims to develop a system that evaluates the emotional experience of gamers based on physiological changes.
A within-subject experiment with 22 participants has been
designed to investigate the effects of difficulty level and social
playing mode on player emotions and to examine the correlation between each emotion and the physiological changes.
We demonstrate the feasibility of using commodity wearable
physiological sensing devices to recognize mobile gamer’s
emotion. Specifically, our system performs 3-level excitement classification at an accuracy of 77.38% and binary
classification of happiness state at an accuracy of 73.21%.
These classification results show the potential of using commodity wearable sensing devices as a valuable evaluation
tool for game designers to gauge user emotions and develop
personalized gaming experience.

CCS Concepts
•Human-centered computing → Handheld game consoles; Ubiquitous and mobile computing design and
evaluation methods; •Applied computing → Computer games;

Keywords
Mobile Gaming; Wearable; Physiological Sensing; Emotion
Recognition

1.

INTRODUCTION

People play games to feel various emotions [9]. Often,
people make a decision to keep playing a mobile game based
on how they feel in the very first few plays. Game designers
also understand the importance of emotions, and use them
as one of the main design factors to trigger positive positive game experiences [14]. In this light, assessing gamers’
emotions can serve as an important premitive in developing and improving games. Furthermore, real-time sensing of
emotions can enable adaptive game play based on personal
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

• We conducted an exploratory user study with 22 gamers
to show various game components (e.g. difficulty level,
social playing mode) can affect gamers’ emotions. This
confirms that understanding emotions of gamers is important for the design and evaluation of various game
components, and motivate us to build Jasper.

MobiGames’16, June 26 2016, Singapore, Singapore
c 2016 ACM. ISBN 978-1-4503-4325-1/16/06. . . $15.00
DOI: http://dx.doi.org/10.1145/2934646.2934648

1

• This study is one of the early works that apply emotion
sensing techniques to the mobile game domain. There
has been a rich body or prior studies to show the correlation between physiological patterns and emotional
states [6][7][13]. However, those work did not focus
on gaming aspect. Also, we leverage commodity wearable sensors (not the specialized physiological sensor
devices) to build a practical solution to assess gamers’
emotion during game play in a natural way.

type of enemy tank four times to destroy it. As the difficulty setting increases from easy level to medium level and
hard level, the enemy tanks move faster and there also more
tanks of harder types. In the multiplayer mode, two Android
phones are connected via Wifi Direct. Both players have to
shoot enemy tanks and defend the base together, and if one
player shoots the other, the victim would be unable to move
for a while, but can still shoot.
Participants: Twenty-two male participants took part in
the user study. The average age was 26 (standard deviation
of 3.2) with a minimum of 19 and a maximum of 32. All
participants were frequent smartphone users. When asked
to rate how often they played games on their mobile phones,
all 22 subjects played at least a few times a week.
Procedure: The study procedure was as follows: we first
introduced and explained the process of the study, the rules
of Tank 1990 game that participants about to play. After
the training session, participants started the experiment by
watching a 2-minute neutral video of relaxing natural scene
with soothing music to elicit the neutral mental state. Subsequently, they were asked to play three game sessions with
three difficulty levels in single-player mode and three game
sessions in multi-player mode. We randomized the order of
difficulty level setting (easy, medium, hard) in three game
sessions for each social playing mode. Each game session
usually lasted from 2 to 4 minutes. In case some participants lost their game too fast, they were asked to play again
with the same setting. Participants were also asked to watch
a neutral video between two social playing modes and at the
end of the experiment.

• We presented initial results that a combination of features extracted from EEG and GSR signals can be used
to recognize popular emotions in mobile game context
including excitement and happiness.

2.

MOTIVATION

Understanding the effect of each game component on emotions of gamers will enable developers to delivery the best
gaming experience. There are multiple components of game
design that developers need to consider to create games with
enjoyable experience such as game storyline, challenge, social interaction, sound and visual effects. In this work, we
focus on social playing mode (single-player and multi-player)
and difficulty setting (easy, medium or hard level) as two
quantitative game components would possibly affect emotional experience of gamers. In order to investigate how
game settings can influence players’ emotions, we conducted
a within-subject study in which participants played the same
game under various conditions of difficulty setting and social
playing mode.
Study tasks: We chose a simple and interactive game in
Arcade category on Google Play, Tank 1990 HD. This game
is an Android version of Battle City, a popular game on
1990 Nintendo video game console (Super Nintendo Entertainment System). During the game session, a player controls a tank using virtual multi-touch gamepad by pressing
buttons on the left side of the screen to navigate the tank
and button on the right side to control his tank to shoot.
The player tank originally positioned at the bottom of the
screen next to player’s base. The enemy tanks attempt to
destroy the player’s base which is represented on the map
as an eagle symbol, as well as the player tank itself. The
objective of the game is to destroy all enemy tanks and keep
the base safe, but the game ends if the player’s base is destroyed or the player loses all available lives. There are four

Figure 2: Screenshot of self-assessment application.
After each game or video session, participants filled out
a self-assessment to indicate how they felt during the session. They were asked to consider the statement such as
‘I felt bored’, and rate their intensity of the corresponding
emotion in the statement on a 5 point scale (1-Not at all,
2-Slightly, 3-Moderately, 4-Very, 5-Extremely) as shown in
Figure 2. The same technique was used to assess other emotional states including excitement, happiness, frustration,
amusement, pleasure, relaxation, and the state of being challenged that the participants felt during game sessions. After
completing three game sessions of the single-player mode, we
asked participants to evaluate which difficulty level match
their competence.
Data analysis: Figure 3 shows the average and the standard error of the self-reported ratings that corresponding to
the state of ‘being challenged’. The left chart indicates that
participants felt significantly more challenged when they
played the game with higher difficulty level in both single-

Figure 1: Screenshot of Tank 1990 interface.
progressively harder types of enemy tank: the harder the
more bullets the player tank need to shoot to destroy that
tank. For example, the player needs to shoot the hardest

2

INTENSITY (LOW TO HIGH)

INTENSITY (LOW TO HIGH)

player and multi-player modes. As can be seen in the right
chart, self-reported challenge level corresponding to singleplayer game sessions was significantly higher compared to
multi-player mode. It suggests that participants felt less
challenged while playing the game in a team.
5

5
Single mode
4

Team mode

4

3

3

2

2

Easy

Medium
Hard
DIFFICULTY LEVEL

Mid competence

4

High competence

3
2

Easy

Medium
DIFFICULTY LEVEL

Hard

Figure 4: Self-reported excitement level
tions based on selected features. The output of our system
Single Team
PLAYING MODE
Server

Figure 3: Self-reported challenge level
We run a two-way ANOVA test for each emotional state
to see if it is significantly affected by difficulty level and social mode. The test confirms the impacts of difficulty level
(p = 0.01) and social playing mode (p < 0.001) on how challenging the game was (this validates the difficulty setting in
our study). The test results show that there is a main effect of difficulty setting on gamer’s frustration (p < 0.001 )
and the effect of social playing mode on the happiness level
of gamers (p = 0.02). For other emotions including excitement, amusement, relaxation, and pleasure, there is no main
or interaction effect of difficulty level and social interaction.
Using two-way ANOVA, we also test whether gamers’ competence changes their emotions while playing the game with
different difficulty settings. The result shows that there is an
interaction effect of difficulty level and gamer’s competence
on their excitement level. We summarize a few interesting
key findings from this user study:
(1) As the difficulty level increase, players feel more frustrated, but it is not necessarily a negative game experience
as many players also feel more excited at the same time.
(2) When playing in teams, gamers feel less challenged
and happier compared to when they play in single-player
mode.
(3) Players feel most excited when the difficulty level matches
to their gaming competence (Figure 4).
These findings indicate that gamers feel differently while
playing a same game under different settings and even a
single change in game configuration can significantly affect
emotions of gamers. Moreover, if developers can assess the
emotions of gamers, they will be able to adjust the game
configuration to optimize the gaming experience (either for
all gamers in general or for each individual).

3.

Low competence

1

1

1

5

Processing
Preprocessing
(segmenting, filtering,
noise removing)

Feature Extraction
Emotion
Recognizers

Developers

Gamers
Bio-signals

Emotions
(excitement, happiness,
frustration, amusement)

Games

EEG channel
GSR channel
PPG channel

Adaptation
Manager

…
Specification
(game configuration,
target emotions)

Figure 5: Jasper system overview
is represented as a compound emotional state such as state
of being slightly happy and highly excited at the same time.
We believe that the recognized emotional states of gamers
would be valuable feedback for game designers to improve
their games. In our vision, we would like to advance the
system by developing an adaptation strategy based on the
data of recognized emotions and corresponding game configuration from multiple gamers playing various types games.
The adaption manager would analyze game designers’ specifications (target emotions for a game and game elements in
designing process) and provide the designers hints to tune
their game configuration so that they can optimize their
players’ experience.

3.1

Physiological Sensors

The current implementation of our Jasper collect physiological data input from two sensing devices: Shimmer3 sensing unit and Emotiv Epoc+ headset. These two devices are
chosen because they are capable of capturing physiological
changes that have been shown to be useful in recognizing
short-term emotions [7] [10]. Additionally, they are commodity wearable devices that users can easily wear them
while playing games on smartphone and the physiological
signals can be streamed wirelessly to smartphone or computer via Bluetooth.
Shimmer3 Sensing Unit
The Shimmer wearable sensing device is mounted to user’s
left wrist. The device includes a Galvanic Skin Response
(GSR) sensor which contacts with two fingers of left hand

Jasper OVERVIEW

Figure 5 shows the system overview of Jasper. The input data is physiological signals from three channels including Galvanic Skin Conductance (GSR), photoplethysmography (PPG), and electroencephalogram (EEG) which are
captured by commodity wearable sensing devices. The data
is first preprocessed (e.g. segmenting, noise removing, filtering) and then is used to compute meaningful features from
various domains (e.g. time-series, frequency, geometric analysis, sub-band spectra). For each emotion, there is a respective classifier which classifies the intensity level of that emo-

3

(a) Emotiv headset

and environment temperature. The SCR is more useful for
emotion recognition as it is linearly correlated with the intensity of arousal responding to internal/external stimuli [6].
We compute both DC features (e.g. mean value, standard
deviation) and SCR features (e.g. number of SCR, mean
value and standard deviation of SCR amplitudes compared
to the baseline). The SCR features are extracted from the
low-passed GSR signal using a cutoff frequency of 0.4Hz.
Electroencephalogram: To extract the EEG frequency
range relevant for emotion recognition task, EEG raw signals are band-pass filtered. The lower threshold of the filter
is set to 1 Hz (high-pass) to eliminate linear trends in signal
recording while an upper threshold of 30 Hz (low-pass) cut
off high-frequency noise such as muscle artifacts. We focus
on this frequency range as the alpha (8 - 12Hz) and beta
(12 - 30Hz) bands are highlighted in literature research as
particular useful areas to extract information for emotion
recognition for both valence and arousal [6]. We compute
spectral power of these two band and various combination
features for each of fourteen channels: sub-alpha power (8 10 Hz, 10 - 12Hz ), sub-beta power (12 - 16 Hz, 16 - 20 Hz,
20 - 30 Hz), alpha power, beta power, alpha and beta power,
alpha to beta ratio. The valence level (negative and positive)
of emotion that users experience while playing games may
also be revealed in the asymmetrical frontal EEG signals .
Generally, the right hemisphere is more active during the
experience of negative emotions while the left hemisphere
is more active during positive emotions [13]. Therefore, we
compute the differences in fractal dimension of the frontal
channel pairs (F3-F4, AF3-AF4, FC5-FC6, T7-T8, F7-F8).
Fractal dimension of each EEG channel is calculated using
Higuchi’s method (HFD).
Because each individual body responses to the emotional
stimuli in a different way and the variation of each individual’s physiological signals is also different. All the extracted
features are normalized to reduce the individual differences
in physiological changes by the following z-score normalization formula:
x−µ
z=
σ
where µ is the mean, σ is the standard deviation, x is the
feature value and z is the normalized value.

(b) Shimmer device

Figure 6: Sensing devices
to measure skin conductance and a photoplethysmography
(PPG) sensor ring which is attached to index finger to sense
the changes in blood flow during heart activity controlled
by heart’s pumping action. The two sensors collect data at
a rate of 256Hz.
Emotiv Epoc+
The Emotiv Epoc+ headset [1] has 14 electrodes locating
at AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4,
F8, AF4 (CMS/DRL as references) following the American
Electroencephalographic Society Standard. The sampling
rate of the Emotiv headset is 128Hz. The bandwidth of the
device is 0.2-45Hz and the A/D converter is with 16 bits
resolution.

Figure 7: EEG electrodes position
Along with the physiological sensors, we use a laptop to
receive all the sensing signals via Bluetooth and do the processing tasks.

3.2
3.2.1

3.2.2

Emotion Classification

For each target emotion (e.g. amusement, frustration),
those features that have a too low correlation (less than
0.05) will be removed from the corresponding feature set
that is used to recognize that emotion. We then run a
correlation-based heuristic search algorithm [5] to select best
feature subset from the remained features for the classification model. This feature selection algorithm evaluates the
merit of feature subset using Pearson correlation formula
and search for the feature subset with the highest merit using Best-First-Search with maximum 5 times of consecutive
non-improving loop. In this study, because of the limited
number of data sample, we use simple classification algorithms such as Random Forrest and J48 to build the classification models (one for each emotion). Each classifier classifies the intensity level of a discrete emotion, usually is a
binary state. The compound emotional state is a combination of many classification results, for example, being slight
frustrated and highly excited at the same time.

Emotion Recognition
Preprocessing and Feature Extraction

From three physiological channels, 125 features are calculated from various analysis domains, including time series
statistics, frequency domain, geometric analysis, sub-band
spectra and fractal dimension. In this section, we describe
the feature extraction methods in details.
Photoplethysmography: We compute the beat-to-beat
interval series and heart rate from PPG signal using peak
detection. Heart Rate Variability (HRV) features including
time-domain features and geometric features are extracted
from the beat-to-beat intervals.
Galvanic Skin Response: GSR signal composes of DC
level component and the skin conductance response (SCR).
The DC level is considered as an indicator of the general
activity of the sweat glands influenced by body temperature

4

4.

EXPERIMENTAL RESULTS

Excitement

Happiness

Actual

Physiological data including EEG signals from the Emotiv Epoc+, GSR and PPG signals from the Shimmer device
is collected in the same experiment described in Section 2.
We observed that the three physiological channel signals in
our study all contain various types of artifacts such as momentary noise because of participants’ movement which usually occurred at the beginning and at the end of each game
session. Therefore, for all subject and channels, the physiological signals were segmented into samples of 120 seconds,
which obtained by taking the middle part of each signal.
All the 2-minute game and baseline video samples were
labeled based on participants’ self-reported ratings. We labeled the level of excitement of each sample by treating reports of level 5 (extremely excited) and level 4 (highly excited) as high level; reports of level 3 (moderately excited)
as mid level; and reports of level 2 (slightly excited) and
level 1 (not excited at all) as low level. For happiness level,
we treated reports of level 1 (not happy at all) and level
2 (slightly happy) as low level and the others as high level
(binary state of happiness).

Actual

Low level
High level

Recognized
Low level
High level
50
28
17
73

pressive as previous research have reported higher accuracies
of valence and arousal binary classification [6][10]. However,
it is important to note that previous works used stimuli with
clear distinguishable emotional states. For instance, Kim
et al.[6] used different songs which were explicitly chosen
to evoke high/low valence and arousal states or Soleymani
et al.[13] conducted a study using standard tagged emotional videos to elicit discrete emotions from participants.
In this work, we focus on differentiating more subtle emotional states when participants playing the same game under
different settings of difficulty level and social playing mode.

5.

RELATED WORK

Physiological signals such as skin conductance, skin temperature, cardiovascular activity, and brain wave activity
have been studied extensively as potential metrics to measure emotions. Researchers have reported some physiological patterns that are highly correlated with certain emotional states, for example, galvanic skin response is a linear
correlate to arousal [8]. Many research works have examined
the use of physiological measures to detect the emotions that
associated with variety of task such as music listening [6],
image and clip viewing [4]. However, many of them labeled
the physiological data based on the tag of emotion elicitor
(e.g. sad song, exciting video clip), which may not reflect
the actual subjective emotions of participants.
Some previous works also have examined the physiological
responses of different game conditions. Specifically, Mandryk
et al.[11] investigated the correlation between physiological
changes and different interactive play environments, and
showed some interesting findings such as GSR and Electromyography (EMG) of the jaw were higher when playing
against a friend, over playing against a computer as gamers
felt more challenged. Chanel et al.[2] confirmed that players
feels differently while playing a same game with different difficulty levels. But instead of recognizing subjects’ reported
emotions, the authors used EEG and peripheral bio-signals
to classify three emotional states that are associated with
three difficulty levels (which may differ among subjects) at
an accuracy of 63%.

Table 1 shows the selected features for each target emotion. There is no combination of features was selected for
frustration level classification as the heuristic search returned
only one feature the with the highest correlation with frustration level (HDF feature of EEG sub-channel T7 with the
correlation of 0.23). Most of the selected features were extracted from EEG signals while there is only one selected
GSR feature and no HRV features from PPG signals are
selected. We observed that both PPG and GSR signals contained many artifacts caused by the variation of the force
participant use to hold the mobile device during game sessions. Particularly, the PPG sensor ring was worn at participant’s index finger tip which contacted with the phone’s
back in the experiment (participant hold the phone horizontally by two hands to play the Tank 1990 game). This
resulted in inaccurate beat-to-beat interval detection and
HRV feature extraction.
J48
72.62%
71.42%

High level
1
12
80

Table 4: Confusion matrix of Happiness classification

Best features for classifications
EEG features: spectra alpha(F7),
HFD(F8), spectra alpha&beta(T7),
HFD(T8), spectra alpha(FC6),
spectra alpha&beta(FC6)
GSR feature: SCR count
EEG features: spectra alpha(F8),
spectra alpha&beta(FC6), HFD(T7),
spectra alpha&beta(FC5), HFD(FC6),
spectra beta(T7), HFD(T8), HFD(AF4)
GSR feature: SCR count

SVM
77.38%
70.83%

Recognized
Mid level
6
21
9

Table 3: Confusion matrix of Excitement classification

Table 1: Selected features for emotion classification

Excitement
Happiness

Low level
Mid level
High level

Low level
29
8
2

Random Forest
77.38%
73.21%

6.

DISCUSSION

Players seek games for enjoyment and for emotional experiences such as an adrenaline rush or an amusing adventure.
What is fascinating is that players willingly engage in an
experience that is likely to even involve negative emotions
such as frustration and fear [15]. Different game genres and
other game elements should be considered in the future work

Table 2: Accuracy of emotion classification
With all selected features shown in Table 1, we performed
3-level excitement and binary happiness classification using
different algorithms, 10-fold cross validation (Table 2).
At first glance, these classification accuracies appear unim-

5

to see whether we can use physiological sensors to recognize
a more diverse set of emotions.
Recognizing mobile players’ emotions not only enables
game designers to evaluate and improve their games but also
can help them to develop games that can automatically adjust themselves to provide a personalized gaming experience
based on player’s affective states. In both cases, knowing
how a player feels while playing games is not enough, game
designers also need to understand how each game component can affect their players’ affective states so that they
can improve their games or develop games with customized
UX based on players’ emotions. For example, if most players
start to feel bored after playing a certain game for a while,
the designers of that game need to identify which game components should be tuned and how should they tune those
components so that the game becomes more exciting but not
too frustrating for players. We plan to develop an adaptation manager which can provide game designers suggestions
on how to optimize their game’s configuration for player’s
emotional experience specification based on statistical analysis of data collected from many gamers playing games with
various settings.
We notice two limitations of using physiological sensors
in our study. First, collecting physiological signals requires
subject to bodily connected with the sensors. Although the
sensors used in this study is commodity wearables, these
sensors are not familiar with common users and may cause
some discomforts. We consider using the bio-sensors that are
already embedded in wearables such as the smart watch or
wrist-band (e.g. Microsoft band) as an alternative. Second,
the physiological signals contain many motion artifacts, especially, the GSR and PPG sensors (from Shimmer sensing
device) are very sensitive to finger movement artifacts during game sessions. Future work needs to develop an effective
technique to remove those motion artifacts to enhance the
emotion classification accuracy.

7.

[3]

[4]

[5]

[6]

[7]

[8]
[9]
[10]

[11]

[12]
[13]

CONCLUSION

This paper has investigated the feasibility of using physiological sensors to evaluate gamers’ experience under different game conditions. In particular, we conducted a user
study to examine the effects of difficulty level and social interaction on players’ emotional states. The results suggest
that players are most excited if the game’s difficulty level
matches their competence and they feel happier when playing in a team compared to when playing in single-player
mode. More importantly, we have demonstrated the potential of using commodity wearable bio-sensor devices to evaluate mobile player’s emotional experience under different
game settings. Our system can classify 3-level excitement
and binary state of happiness at the accuracies of 77.38%
and 73.21% respectively.

8.

[14]

[15]

ACKNOWLEDGMENTS

This research is supported by the National Research Foundation, Prime Minister’s Office, Singapore under its IDM
Futures Funding Initiative.

9.

REFERENCES

[1] Emotiv. http://www.emotiv.com.
[2] G. Chanel, C. Rebetez, M. Bétrancourt, and T. Pun.
Emotion assessment from physiological signals for

6

adaptation of game difficulty. Systems, Man and
Cybernetics, Part A: Systems and Humans, IEEE
Transactions on, 41(6):1052–1063, 2011.
B. Fulton and M. Medlock. Beyond focus groups:
Getting more useful feedback from consumers. In
Proc. Game Dev. Conf, 2003.
J. J. Gross and R. W. Levenson. Hiding feelings: the
acute effects of inhibiting negative and positive
emotion. Journal of abnormal psychology, 106(1):95,
1997.
M. A. Hall and L. A. Smith. Feature subset selection:
a correlation based filter approach. In International
Conference on Neural Information Processing and
Intelligent Information Systems, pages 855–858, 1997.
J. Kim and E. André. Emotion recognition based on
physiological changes in music listening. Pattern
Analysis and Machine Intelligence, IEEE Transactions
on, 30(12):2067–2083, 2008.
K. H. Kim, S. Bang, and S. Kim. Emotion recognition
system using short-term monitoring of physiological
signals. Medical and biological engineering and
computing, 42(3):419–427, 2004.
P. J. Lang. The emotion probe: studies of motivation
and attention. American psychologist, 50(5):372, 1995.
N. Lazzaro. Why we play games: Four keys to more
emotion without story. 2004.
Y. Liu, O. Sourina, and M. K. Nguyen. Real-time
eeg-based emotion recognition and its applications. In
Transactions on computational science XII, pages
256–277. Springer, 2011.
R. L. Mandryk, K. M. Inkpen, and T. W. Calvert.
Using psychophysiological techniques to measure user
experience with entertainment technologies. Behaviour
& information technology, 25(2):141–158, 2006.
C. Marshall and G. B. Rossman. Designing qualitative
research. Sage publications, 2014.
M. Soleymani, S. Asghari-Esfeden, M. Pantic, and
Y. Fu. Continuous emotion detection using eeg signals
and facial expressions. In Multimedia and Expo
(ICME), 2014 IEEE International Conference on,
pages 1–6. IEEE, 2014.
G. N. Yannakakis and A. Paiva. Emotion in games.
Handbook on Affective Computing, pages 459–471,
2014.
E. Zimmerman and K. Salen. Rules of play: Game
design fundamentals, 2003.

