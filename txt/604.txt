Studies in Informatics and Control, 29(3) 337-351, September 2020

ISSN: 1220-1766 eISSN: 1841-429X

337

Recursive Identification Based on OS-ELM for Emotion
Recognition and Prediction of Difficulties in Video Games
Hayfa BLAIECH1*, Noureddine LIOUANE2
1
National Engineering School of Monastir ENIM, Laboratory of Automatic,
Signal and Image Processing (LARATSI), Tunisia
hayfaelblaiech@gmail.com (*Corresponding author)
2
National Engineering School of Monastir ENIM, University of Monastir, Tunisia
noureddine.liouane@enim.rnu.tn
Abstract: The aim of this paper is to recognize human emotions from physiological electroencephalography (EEG)
signal. Indeed, this paper demonstrates that neural networks in conjunction with recursive least squares can be
used sprucely for the identification of emotional states. In this regards, this report uses online sequential extreme
learning machine to conceive the present emotion recognition system. To validate the efficiency of this machine
learning, the performance of various popular feature extraction methods with the Database for Emotion Analysis
using Physiological Signals DEAP dataset, and two newly developed EEG datasets are systematically evaluated for
this study. The first emotional experience was to conceive an emotional dataset containing the samples EEG of six
selected emotion states (neutrality, amusement, surprise, compassion, attraction, and disgust), and the second one
was to predict the difficulties encountered during playing a hard game. This has the goal to detect the concentration
and anger emotional states. The purpose of this paper is to improve the accuracy of emotion recognition based on
different emotional states. The features are extracted from the delta, theta, alpha and beta bands. Based on the analysis
of the identification system, the most significant features are extracted for each emotional state. The selected ones
are then utilized in the emotion classification system. The present recognition system has 80% accuracy when using
the DEAP database, 74.07% accuracy when using the first database, and obtains 61.11% accuracy when predicting
difficulties in video games.
Keywords: Recursive identification, OS-ELM, Emotion Recognition, EEG signals, Video games, Feature extraction.

1. Introduction
Affective computing is one of the hottest topics in
the field of human-computer interaction. It affects
computer science, psychology and cognitive
science. Affective computing, introduced by
(Picard, 2000), seeks to give space to emotion in
the field of computing (machines, robots, virtual
agents). It is about giving a computer the ability
of recognizing and interpreting personal emotions
and affective behaviors, developing one’s ability
to respond intelligently to human emotion, helping
in decision-making, and enhancing interaction
and making it more effective and more natural.
(Picard, 2000) split this affective computing into
two research paths: the modeling of emotional
processes in computational systems, and the design
of systems allowing the automatic recognition
of emotion. The first way is to generate virtual
emotion in computational systems to improve
communication with a human user. These
computational systems can be virtual agents or
expressive avatars. The second pathway discusses
the recognition of emotion. It concerns how to use
physiological and somatic indices to determine
the user’s emotion, utilizing visual and acoustic
signal sensors. This recognition of the emotional
state may play a major role in the system or
improve the outcome of a system. Similarly,
https://doi.org/10.24846/v29i3y202007

affective computing enhances the brain computer
interaction systems with the ability of detecting,
processing, and responding to the users’ affective
states utilizing physiological signals. To measure
emotion, the three emotional components must
be estimated: cognitive (self report of the subject
using self-report instruments such as questionnaires
and Self Assessment Manikin (SAM) (Barrett
& Russel, 1998), behavioral (facial expression
like Facial Action Coding System (FACS) and
Electromyography (EMG)), and physiological
(cardiac rhythm, physiological signals, respiration,
etc.). In this paper, the cognitive component will
be inserted in the emotional experience done from
EEG signals. The EEG signals will represent the
physiological component. In this paper, the focus
is on the emotion recognition from physiological
EEG signals. The individual’s variations in
emotion as well as the different parameters of
emotion, such as time, context, space and culture,
make this issue very challenging. Moreover, human
emotion is very complicated. In some cases, facial
expressions do not give the exact emotion, which
reveal the importance of analyzing EEG signals.
The paper is written as follows. In section 2, some
related works from the specialized literature are
mentioned. In section 3, the machine learning
ICI Bucharest © Copyright 2012-2020. All rights reserved

338

Hayfa Blaiech, Noureddine Liouane

based on Recursive Online Sequential Extreme
Learning Machine (OS-ELM) is presented, and
a novel algorithm based on the combination
between recursive identification and OS-ELM is
proposed. In section 4, the experimental process
followed for the construction of the two novel
EEG databases based on discrete emotion and
for the prediction of difficulties in video games is
described. In section 5, the steps of the conception
of the emotional recognition system formed by a
recursive identification system and a classification
system are presented. The results of the DEAP
database and our two new databases are discussed
and compared with other studies in section 6.
Finally, a conclusion of the present work is given
in section 7.

2. Related Work
In this section, the related work on
emotion recognition systems based on EEG signals
and other modalities is reviewed. Emotion
recognition systems use two types of emotion
models. Some studies have utilized the discrete
model, yet others have used the valence arousal
model. From the new works in facial expression
recognition systems the authors (Yang et. al,
2018) can be cited as they presented the results
of recognition of seven emotional states (neutral,
joy, sadness, surprise, anger, fear, disgust) based
on facial expressions. They used the coefficients
describing elements of facial expressions,
registered for six subjects, as features. The features
have been calculated for three dimensional face
model. The classification of features was performed
using k-nearest neighbors (KNN) classifier and
multilayer perceptron (MLP) neural network.
They achieved 96% accuracy in the classification
of emotions for random division of data and
73% accuracy in the classification for “natural”
division of data. Also the authors in (Palaniswamy
et al., 2018) proposed a technique for emotion
recognition from facial expressions in images with
simultaneous pose, illumination and age variation
in real time. They considered the emotions anger,
disgust, happy, surprise, and neutrality. The
feature vectors that were formed from images
from the CMU-MultiPIE database for pose
and illumination were used for training the
classifier. For real-time implementation, Raspberry
Pi II was used, which can be placed on a robot to
recognize emotions in interactive real-time
applications. The proposed method includes face
https://www.sic.ici.ro

detection using Viola Jones Haar cascade, Active
Shape Model (ASM) for feature extraction,
and AdaBoost for classification in real-time.
They obtained 96%. Another example is the
work of (Ng et al. 2015), which classifies the
emotions expressed by the primary human
subject in static images extracted from movies.
They follow a transfer learning approach for
deep Convolutional Neural Network (CNN)
architectures. They obtained an overall accuracy
of 48.5% in the validation set and 55.6% in the
test set. Concerning features extraction methods,
the deep learning has recently become a hot
research topic and has achieved state-of-the-art
performance for a variety of applications (Li &
Deng, 2018). Deep learning have been made in
order to capture high-level abstractions through
hierarchical architectures of multiple nonlinear
transformations and representations. Up to now
emotion recognition systems have had lack of
performance in developing real-world application
systems. To compare the present results to the
ones of other works, only three publicly available
emotion EEG datasets can be found. The public
datasets are MAHNOB HCI (Balconi et al.,
2015), DEAP (Koelstra et al., 2012) and SEED
(Petrantonakis et al., 2009). In this study, an
emotion recognition system based on several
recursive identification subsystems is conceived,
and the DEAP dataset is chosen to validate the
effectiveness of our results.

3. ELM and OS-ELM
3.1 ELM
ELM machine is a type of neural network that
guarantees the automatic learning of a linear model.
The ELM method is used for tracking the target
of this paper. ELM can provide the automatic
learning of a linear model. It is characterized
by a single layer of hidden nodes, where the
weights of hidden nodes connected to the inputs
are randomly distributed and are always fixed.
These machines have shown good generalization
performance, robustness and controllability
as well as a learning process which is much
faster than the networks formed using gradient
backpropagation. In the past years there have
been many encouraging results in the application
of ELM to predict protein-protein interactions
(You et al., 2013), to recognize epileptic EEG
models (Song & Zhang, 2013), to estimate EEG-

339

Recursive Identification Based on OS-ELM for Emotion Recognition and Prediction of Difficulties in...

based vigilance (Shi & Lu, 2013), to detect
transmembrane beta-barrel chains (Savojardo et
al., 2011), and to diagnose the thyroid disease (Li
et al., 2012), etc.
ELM algortihm
For N given training samples, an activation function
g(x) and a m number of hidden neurons are taken to
perform the learning of neurons as follows:
1. Random initialization of input weights
Wi and bias bi for all m number of nodes/
neurons, where i=1, 2....m;
2. Calculation of hidden layer output matrix H
by applying X over all m number of hidden
neurons using W and b with activation
function g as g(W X +b);

that it is suitable for target detection (Zhang et
al., 2017). OS-ELM was explored in order to
be used in the flood forecasting on the Neckar
River, Germany (Yadav et al., 2016). The authors
in (AlDahoul & Htike, 2011) demonstrated
that batch and OS-ELM algorithms are able to
decode pattern activities from the visual cortex. In
addition, OS-ELM was applied in watermarking
(Singh et al., 2015).
OS-ELM algorithm
OS-ELM consists of two main phases:
initialization and sequential learning.
Initialization phase:
-

Random initialization of input weights Wi
and bias Bi for all m numbers of nodes/
neurons, where i=1, 2....m.

-

Sequential learning phase:

3. Calculation of output weight β = H *T (1),

(

)

−1

where H * = H T H
H T and T=Output
layer. Here, the objective of ELM is to
minimize the training error as well as the
norm of the output weights (Huang et al.,
2012) in the following equation:
Minimize: H β − T 2 and β

(2)

where,

 g (W1 X 1 + b1 )  g (Wm X 1 + bm ) 


H =
…
…
…

 g (W1 X N + b1 )  g (Wm X N + bm ) 
N ×m

 β1T 
 T1 
 
β =  
T =   
 β mT 
TN  N ×k
  m×k

(3)
(4)

3.2 OS-ELM
When the sequential modification of ELM is based
on the recursive least-square algorithm, it refers
to OS-ELM. OS-ELM can learn data one-by-one
or chunk-by-chunk (a block of data) with a fixed
or varying chunk size. OS-ELM has proven its
efficiency in several studies. For example, it is
used for predicting job failure in cloud computing
(Liu et al., 2017). Also, the authors in (Li et al.,
2017) used the OS-ELM in gas utilization ratio
prediction in blast furnaces. Furthermore, OSELM has some advantages including fast-speed
and incremental learning, which demonstrate

For the ( k + 1) chunk of new observation, N k +1
denotes the number of the training data in the
th
( k + 1) chunk.
th

(a) Calculate the partial hidden layer output
matrix Hk+1 by using same Moore-Penrose inverse
formula used in ELM.
k +1
(b) Calculate the output weight matrix β ( ) as
in equation (Liang et al., 2006) as follows:

β ( k +1) =
β ( k ) + M k +1 H k' +1 (Tk'+1 − H k +1β ( k )

(5)

where

(

M k +1 =
M k − M k H k' +1 I + H k +1M k H k' +1

)

−1

H k +1M k

(6)

3.3 Proposed Algorithm of Recursive
Identification based OS-ELM
In the present method the same initializing phase
of OS-ELM is maintained. For the sequential
phase we follow the next algorithm:
-

Sequential learning phase

The size of the chunk is 1.
The return variable is initialized at zero

Px = zero (1, number of Inputs )

(7)

ICI Bucharest © Copyright 2012-2020. All rights reserved

340

Hayfa Blaiech, Noureddine Liouane

For the ( k + 1) chunk of new observation, N k +1
denotes the number of the training data in the
th
( k + 1) chunk.
th

(a) The input is composed of the new value
of the database and the returned variable (the
system output)

Pl =  Pk +1 ; Px' 

(8)

where Pk +1 is the training data in the

( k + 1)

th

chunk.

(b) Calculate the partial hidden layer output
matrix H k +1 by applying the same MoorePenrose inverse formula used in ELM, applying
the sigmoid function

(

'

'

H = SigActFun Pl , IW , Bi

)

(9)

(c) Calculate the output weight matrix β
in the next equation:

(

( k +1) ,

as

)

β ( k +1) =
β ( k ) + M k +1 H k' +1 Tk'+1 − H k +1β ( k ) (10)

(

Where
=
M k +1 pinv M k + H k' +1 * H k +1
(d) Px = H k +1 * β

)

( k +1)

(11)
(12)

A diagram resuming the algorithm is presented
in Figure 1.

Figure 1. Diagram of recursive emotion
identification system based on OS-ELM

4. Data and Experimental Process
One of the alternatives presented in this paper is
the construction of a new database. A process is
followed for analyzing EEG signals. The goal is
to recognize human emotion. In this emotional
experience, the same steps of the work (Blaiech et
al., 2013) are maintained. However, the emotion
induction protocol is changed. The difference was
that the subjects do not have any idea either on the
video sequence to be watched, or on the emotion
stimulus. The steps of this process consist in
https://www.sic.ici.ro

collecting the personal information of the subjects,
recording EEG signals, and then processing these
signals. A protocol of emotion induction based on
the EEG signals is established.
The experimental process was divided on two
tasks, the first one was to induce the six emotions
(neutrality, amusement, surprise, compassion,
attraction, and disgust), and the second one was to
predict the difficulties in video games by applying
the subjects to play a selected video game having
several difficulties (Table 1).
Table 1. Characteristics of used emotional
EEG databases
Databases

Emotions

Stimuli

DEAP
database

amusement, joy, love,
sadness,shock

Videos

Our first
database

neutrality, amusement,
surprise, compassion,
attraction, disgust

Pictures,
videos

Our second
database

Concentration and
anger

Videogames

4.1 Collection of Personal Information
The personal information of subjects is collected:
each subject must fill the form of personal
information containing their name, age, gender,
handedness, education, alcohol/ tea/ coffee
consumption, environment,...).

4.2 EEG Recording
The Emotiv EPOC headset is used to acquire
EEG data. This headset belongs to the REGIM
laboratory. It contains 14 electrodes (AF3, F7, F3,
FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8 and
AF4) and 2 reference electrodes. These electrodes
are placed according to the standard layout of the
10-20 system. This system refers to the spacing of
the electrodes varying from 10 or 20% according
to the morphology of the individual.

4.3 Emotion Induction Protocol
4.3.1 First Emotional Experience
For neutrality, neutral pictures are used (Geneva
Affective PicturE Database (Dan-Glauser et al.,
2011)). Amusement, surprise, compassion, attraction,
and disgust are induced using video sequences.

Recursive Identification Based on OS-ELM for Emotion Recognition and Prediction of Difficulties in...

341

4.3.2 Second Emotional Experience

5. Proposed Method of Identification

In this experience, each subject is submitted
to play a selected video game named Hardest
Game Ever (Anon, 2015). This game contains
several steps of difficulties that can induce the
concentration and anger as emotion states.

The methodology used in this approach is the
following (Figure 3):
-

Cut the EEG data by conserving 2/3 of data
for learning and 1/3 for testing;

4.4 Sample and Procedure

-

Apply the Independent Component Analysis
(ICA) on the input EEG data;

4.4.1 First Emotional Experience

-

Extract the frequency bands (delta, theta, alpha
and beta) using Fast Fourier Transform (FFT);

-

Extract the 16 features previously mentioned;

-

Measure the sensitivity of each feature over
the bands: delta, theta, alpha and beta;

-

Select the most effective/sensitive features;

-

Localize the emotions in the cortex by analyzing
the sensitivity rate of each EEG channel;

-

Extract the results of sensitivity, specificity
and accuracy of the emotional recursive
identification system by applying the
recursive OS-ELM algorithm;

-

Retest each emotion by the recursive
OS-ELM algorithm by fusing the features;

-

Classify the results obtained from the
identification systems, with and without
considering emotion overlapping;

-

Measure the performance of the system.

The database samples are formed from nine
participants aged from 11 to 61 (five men and
four women). For the first experience, each
participant is submitted to watch an aleatory
video sequence. Then the variation in the values
of EEG signals is observed. This aleatory
sequence is composed of six segments relative
to emotional states : neutrality, amusement,
surprise, compassion, attraction and disgust.
Each segment lasts 60 seconds and represents
a well-determined stimulus of emotion. At the
end of each segment, an image is displayed for
three seconds to distinguish the transition from
one segment to another (Figure 2 a).

For i = 1:6 emotions

(a) First emotional experience

The Hardest Game Ever

(b) Second emotional experience
Figure 2. Experimental process

4.4.2 Second Emotional Experience
For the second experience, each subject plays
the selected game during 3 minutes. The Hardest
Game Ever is hard, but very entertaining as each
level can be accomplished. Next level is more
difficult than the previous one (Figure 2 b). The
latest minute of each record is retained in the
samples in order to better detect the concentration
and anger emotional states.

4.5 Self-Report
After each test, each subject is asked to provide a
self-report, by describing which emotions he/she
felt while watching the video sequences.

Figure 3. Emotional recognition system workflow
ICI Bucharest © Copyright 2012-2020. All rights reserved

342

Hayfa Blaiech, Noureddine Liouane

This algorithm is applied on the DEAP database
to validate its effectiveness. Then it is applied
on a novel database constructed in this paper.
The performance measures are computed as
these formulas:

Accuracy =+
(TP TN ) / ( N + P )

(13)

Sensitivity = TP / P

(14)

Specificity = TN / N

(15)

N: Number of negative tests; P: Number of positive
tests; TP: Positive tests; TN: Negative tests
In this application, a set of discrete emotion
models is used.

5.1 Cutting EEG Data
In this study, the total of EEG data for each
second is 128 data (128 pieces of information).
EEG recording time for each trial is 60 seconds
or more for both picture stimuli and video stimuli. EEG data is cut according to the differences
in the length of data for each trial. EEG data is
cut to 60 seconds (7680 data) for each trial. 2/3
of these data (5120 data) are designed for learning, and 1/3 (2560 data) is designed for testing.
These data are treated chunk by chunk (size: 5
seconds) as follows: 5s are taken (640 data) of
the signal. Next, this part of signal is denoised.
Then the feature is extracted. After that, the data
samples of the signal are incremented. Thus,
4480 data are obtained as an input to the machine learning, and 1920 data are obtained for
testing. There are 14 channels in each trial and
7680 EEG data in each channel.

the EEG signal to extract the desired frequency
bands. In the literature, six standard EEG bands
have been defined, namely: delta, theta, alpha, mu,
beta and gamma. Each of them is more prominent
in different situations. According to present goals,
the delta (1-4 Hz), theta (4-8 Hz), alpha (8-13
Hz) and beta (13-30 Hz) bands will be needed,
which are the most specific waves in the emotion
search. The values of these waves are sought in 14
channels detected by the Emotiv EPOC headset.

5.3 Feature Extraction
After denoising and applying FFT on each signal,
the features will be extracted from the theta, alpha
and beta bands. In this study four features were
extracted for each frequency band: the standard
deviation (std), the average value (mean), the
average value from the squared frequency band
(power), and the sum of squared frequency
band (energy). Indeed, the work will focus on
16 features.

5.4 Emotional State Identification
Recursive OS-ELM is employed for emotion
identification. The properties of the system are
presented in Table 2.
Table 2. Recursive OS-ELM properties
Number of inputs

2

Number of input neurons

2

Number of hidden neurons

5

Activation function

Sigmoid function

5.2 Denoising Methods

For each subject, there is a signal of 60 seconds. 40
seconds will be used for learning and 20 seconds
for testing. The number of samples utilized for each
subject in each database is presented in Table 3.

ICA is employed to denoise the EEG data (Jung
et al., 2000). A bandpass filtering is applied to

Figure 4 presents the variation in the beta
parameter beta during the training of one EEG

Table 3. Number of samples for each subject
Databases

https://www.sic.ici.ro

Nbr of samples for
training for each subject

Nbr of samples for testing
for each subject

Positive
tests

Negative
tests

Positive
tests

Negative
tests

DEAP
database

4480x1

4480x4

1920x1

1920x4

Our 1st
database

4480x1

4480x5

1920x1

1920x5

Our 2nd
database

4480x1

4480x1

1920x1

1920x1

343

Recursive Identification Based on OS-ELM for Emotion Recognition and Prediction of Difficulties in...

channel in one experiment. As it is shown,
it can be noticed an increase with learning
positive values and a decrease with learning
negative values.

8
7
6
5

2.5
HN1
HN2
HN3
HN4
HN5

2

4
3
2

1.5

1
0

1

0

0.5

1

1.5

2

2.5

3
4

x 10

Figure 6. Estimated value during training of one
EEG channel AF4 in one experiment

0.5

0

-0.5

5.5 Feature Selection
0

0.5

1

1.5

2

2.5

3
4

x 10

Figure 4. Variation in beta parameter (having 5
hidden neurons) during training of one EEG channel
AF4 in one experiment

Figure 5 illustrates the variation in an error
during the training of one EEG channel in one
experiment. For both positive and negative data,
the curve tends to 0.
10

8

6

4

2

0

-2

-4

-6

-8

0

0.5

1

1.5

2

2.5

3
4

x 10

Figure 5. Variation in error during training of one
EEG channel AF4 in one experiment

Figure 6 depicts the estimated value during the
training of one EEG channel in one experiment.
It can be seen that the signal goes up when the
emotion (positive example) is elicited and is about
0 when the negative examples are elicited. In the
ideal case, the outputs in positive data must be
equal to 10, and for negative data they must be
equal to 0.

For the applications performing in real time,
dimensionality reduction can help to increase the
speed and stability of the identification system.
Hence, the frequency bands, channels and
features, which have the highest rate of sensitivity
are chosen. The selected ones will be used in the
classification model for emotion recognition.

5.6 Emotional State Classification
A classifier has been set up. This classifier is
composed of several subsystems of identification
created in this work. The number of these subsystems
is the number of emotional states taken for each
experiment. They are put in parallel, and each one is
constructed using the recursive OS-ELM algorithm.
This classifier has two main contributions: The first
is to better improve the recognition rate, and the
second is to get closer to the reality of emotion. In
fact, a person can have two or three emotional states
at the same time with different degrees (like being
in love and sad at the same time, or being amused
and joyful at the same time). This shows emotion
overlapping. This classifier can give the percentage
of the recognition of each emotional state felt at a
time (e.g. 40% sadness and 70% love).
The decision of this classifier is developed as follows:
-

The output is the emotion having the
maximum percentage over all emotion
identification systems.

-

In case that the output of the classifier is
lower than 10% and the difference between
the latest emotions is lower than 5%, it is
considered that there is an overlap of emotion
and a new output of the classifier from the
latest emotion is sought.

ICI Bucharest © Copyright 2012-2020. All rights reserved

344

Hayfa Blaiech, Noureddine Liouane

The classifier is described in Figure 7. Emotion
recognition systems are presented in Table 4. The
number of systems is relative to the number of
emotions. The design of this emotion recognition
system is adequate with all types of applications.
It can be adapted to an emotion recognition system
based on one emotion. It can also be used for a
multi-emotion recognition system.

recorded. The EEG sensors were placed on the
head of each participant. Then, the experimenter
began recording the physiological signals, and
the participant started the experiment. Each
participant had to view 40 videos presented in
40 trials. At the end of each trial, the participants
performed a self assessment using SAM (Bradley
& Lang, 1994), and the thumbs down / thumbs
up symbols were utilized for precising liking
levels (Koelstra et al., 2012). In this experiment,
an emotion representation model based on
five discrete emotional states from the DEAP
database is adopted: amusement, joy, love,
sadness and shock. We retain 21 subjects from
the DEAP database.
6.1.1 Study of Best Features and

Band Frequency

Figure 7. Model of emotion classifier
Table 4. Emotion recognition systems
Emotion
recognition
systems

DEAP database

1

Amusement

Neutrality

2

Joy

Amusement

Our database

3

Love

Surprise

4

Sadness

Compassion

5

Shock

Attraction

6

-

Disgust

6. Results and Discussions
In order to validate the efficiency of the recursive
OS-ELM utilized in this study, these algorithms are
firstly evaluated with the publicly available emotion
dataset, the DEAP dataset. The performance of the
present method is compared with the one of other
methods used in the existing studies on the same
emotion EEG dataset.

6.1 Experimental Results on
DEAP Database
The DEAP database contains 32 healthy
participants who participated in the experiment.
32-channel EEG signals, 4-channel EMGs, 4
Electrooculography (EOG) signals, a 2-channel
Galvanic Skin Response (GSR) signal, 2
Electroretinogram (ERG) signals, the temperature
in a single channel, a single channel respiration
rate and 1-channel blood volume pressure were
https://www.sic.ici.ro

In this step there is an attempt to visualize the
sensitivity rate of each feature over 21 subjects
from the DEAP database. Each feature for each
emotional state (amusement, joy, love, sadness
and shock) is learned and tested. By analyzing
the results, it can be deduced that delta band has
no sensitivity in the emotional mechanism. For
this, in the rest of the work, the delta band will
be neglected. It can be noticed that the beta band
has a better recognition rate than the other bands,
except sadness where there is a balance between
the alpha and beta bands. This can explain the
great relationship of the alpha and beta bands with
the emotional mechanism.
It can also be noticed that the energy features of
the theta, alpha and beta frequency bands (the
sum of squared frequency band) have the best
recognition rates among the other features.

6.1.2 Localisation of Emotion in Cortex
Based on the sensitivity rate of each sensor from the
cortex, the distributions of the EEG channels
are analyzed and the best ones (the channels
having the best recognition rates) are kept.
These channels are used in the test phase of the
recursive identification system. The distribution
of channels varies between subjects and between
emotional states. The average distribution of
channels over all subjects through emotional
states is computed. By observing the distribution
of the EEG channels, it can be noticed that the
frontal part of the cortex is the most responsible

Recursive Identification Based on OS-ELM for Emotion Recognition and Prediction of Difficulties in...

part for emotion. Except “love”, which
concentrates on the parietal lobe of the cortex,
the occipital lobe concerns “shock”. On the
other hand, the alpha band is found mostly in
“amusement”, “joy” and “shock”. Moreover,
the band beta is present in most of the emotional
states, except “amusement” where the rate
of recognition is low. The theta band mainly
concern “sadness”. Table 5 summarizes the list
of dominant electrodes for each emotional state,
working on the average values of the sensitivity
of 21 subjects.
Table 5. List of dominant electrodes for each
emotional state from DEAP database
Emotions

Theta

Alpha

Beta

Dominant electrodes
Amusement

-

AF3

-

Joy

-

F7

AF4

Love

-

-

P8

Sadness

F3

-

AF4

Shock

-

O2

F8

6.1.3 Results of Identification System
In this part, the results of the emotional
identification system over all subjects are
presented. The sensitivity, specificity and accuracy
rates are measured over the five emotional states
extracted from the DEAP database: amusement,
joy, love, sadness and shock. The results indicate
that features obtained from beta frequency bands
perform better than the ones obtained from
other frequency bands, which implies that beta
oscillation of brain activity is more related with
the processing of these three emotional states
than other frequency oscillation as described in
(Guntekin & Başar, 2010). Also the fusion of
features (energy of theta, alpha and beta) has
a good rate of accuracy. The best results of the
accuracy of our identification system for each
emotion are summarized in Table 6.

345

Table 6. Average accuracy of recursive OS-ELM for each
emotion from energy of beta band and the fusion method
Amusement

Joy

Love

Sadness

Shock

67.66

70.03

87.62

85.17

61.35

68.75

78.95

78.64

Beta energy
Train
(%)

Accuracy

69.81

73.06

71.90

Fusion of energy band
Accuracy

85.85

85.76

86.99

Beta energy
Test
(%)

Accuracy

62.87

Accuracy

79.63

63.74

63.05

Fusion of energy band
77.55

77.36

6.1.4 Results of Classification System
Table 7 presents the rate of emotion recognition
by using a classifier composed of five classes
according to the five emotional states employed.
Each class refers to an emotional state. It can be
noticed that the fusion method of frequency bands
gives a rate of recognition higher than the one
obtained by using independent frequency bands.
The recognition rate in the learning and testing
step is of 98.09% and of 67.61%, respectively,
without considering the emotion overlap in the
test step. Whereas, by considering the emotion
overlap, the rates are of 100% for training and of
80% for testing.
Table 7. Accuracy Rate of classification system with
and without considering emotions overlap
Classification
Without emotion
overlap

Considering
emotions overlap

Features
Theta
Alpha
Beta
Fusion
Theta
Alpha
Beta
Fusion

Training
accuracy
66.66
64.76
65.71
98.09
89.52
84.76
88.57
100

Testing
accuracy
27.61
28.57
42.85
67.61
55.23
55.23
69.52
80.00

6.1.5 Comparison with Other Studies
In Table 8, the results of the present study are
compared to those of some other studies working
on the DEAP database.

Table 8. Comparison with some studies using DEAP Database
Reference

Emotions

Method

Accuracy

(Zhang et al., 2016)

Discrete emotions

SVM

59.13%

(Kumar et al., 2016)

Arousal valence model

Bispectrum analysis, LS-SVM, ANN
64.84%
(Linear and RBF kernels)

(Atkinson & Campos, 2015)

Arousal valence model

MRMR, SVM, genetic algorithm-SVM

73.14%

The present method

Discrete emotions

Recursive OS-ELM

80.00%

ICI Bucharest © Copyright 2012-2020. All rights reserved

346

Hayfa Blaiech, Noureddine Liouane

6.2 Experimental Results on the First
Database: Identifiying Selected
Emotional States
Following the analysis of the performance of
features, the feature energy considered the most
efficient is used in the rest of this work. Only the
theta, alpha and beta bands are kept.

6.2.1 Neural Signatures and
Stable Patterns
To observe the neural patterns associated with
emotion processing, the energy features are
projected to the scalp to find temporal dynamics
of frequency oscillations and stable patterns across
subjects. Figure 8 depicts the average neural
patterns for the neutrality, amusement, surprise,
compassion, attraction and disgust emotional
states. The results prove that neural signatures
associated with different emotional states do exist.
The lateral temporal and the frontal areas activate
more for the amusement and surprise emotions
than for the neutrality emotion. The energy of
the prefrontal area enhances for the compassion
emotion over other emotions. While the neural
Amusement

Neutral
af3
f7 f3
fc5
t7

af4
f4 f8
fc6
t8

p7

p8
o1

af3
f7 f3
fc5
t7

af3
f7 f3
fc5
t7

p8

af3
f7 f3
fc5
t7

p8
o1

o2

af3
f7 f3
fc5
t7

p8
o1

af4
f4 f8
fc6
t8

p7

p8

af3
f7 f3
fc5
t7

af3
f7 f3
fc5
t7

af3
f7 f3
fc5
t7

af3
f7 f3
fc5
t7

af4
f4 f8
fc6
t8

p7

p8
o1

af3
f7 f3
fc5
t7

af4
f4 f8
fc6
t8

p7

p8
o1

af3
f7 f3
fc5
t7

o2

af3
f7 f3
fc5
t7

o2

Beta

af3
f7 f3
fc5
t7

p8
o2

af4
f4 f8
fc6
t8

p7

p8
o1

af3
f7 f3
fc5
t7

af3
f7 f3
fc5
t7

af4
f4 f8
fc6
t8

p7

o2

p8
o1

o2

af3
f7 f3
fc5
t7

o2

af3
f7 f3
fc5
t7

af3
f7 f3
fc5
t7

o2

o2

Disgust

p8
o1

p8
o1

af4
f4 f8
fc6
t8

p7

af4
f4 f8
fc6
t8

p7

o2

Attraction

p8
o1

p8
o1

af4
f4 f8
fc6
t8

p7

Surprise

af4
f4 f8
fc6
t8

p7

o2

Compassion

af4
f4 f8
fc6
t8

p7
o1

af3
f7 f3
fc5
t7

o2

Disgust

p8
o1

p8
o1

af4
f4 f8
fc6
t8

p7

Disgust

af4
f4 f8
fc6
t8

Amusement

Neutral

af4
f4 f8
fc6
t8

p7

o2

Attraction

Compassion
af3
f7 f3
fc5
t7

p8
o1

o2

Theta
Surprise

af4
f4 f8
fc6
t8

p7

o2

p8
o1

p8
o1

af4
f4 f8
fc6
t8

p7

o2

p7

o2

Delta
Amusement

Neutral

af3
f7 f3
fc5
t7

Attraction

p8
o1

p8
o1

af4
f4 f8
fc6
t8

p7

o2

Surprise

af4
f4 f8
fc6
t8

p7

o2

Compassion

af4
f4 f8
fc6
t8

p7

o2

af3
f7 f3
fc5
t7

o1

Disgust

af4
f4 f8
fc6
t8

p7

o2

p8
o1

Amusement

Neutral

af4
f4 f8
fc6
t8

p7

o2

Attraction

af4
f4 f8
fc6
t8

p7
o1

p8
o1

Compassion
af3
f7 f3
fc5
t7

Surprise

af4
f4 f8
fc6
t8

p7

o2

patterns of the surprise emotion are similar to the
one of the amusement emotion, as they both have
less activation in the left areas, the neural patterns
of the compassion, attraction and disgust emotions
have higher responses at parietal and occipital
sites. As seen in the specialized literature, the
authors in (Klimesh et al., 1998) prove that EEG
alpha activity reflects attentional processing and
beta activity reflects emotional and cognitive
processes. When participants watched stimuli
provoking emotion processing, and needed more
concentration and more motivation, the energy of
beta enhanced. The present results are consistent
with the findings of the existing work (Jenke
et al., 2014). Secondly, the average rates of the
sensitivity of each EEG channel from the cortex
are analyzed. The distribution of channels over
all subjects of our database is computed. Table
9 summarizes the list of dominant sensors (if
they exist) for each emotion. Through this table
it can be found that “neutrality” is concentrated
in the right frontal site of the cortex. The right
frontal site concerns also “compassion” and
“attraction”. “Compassion” is founded as well
concentrated in the left parietal site and the right

af3
f7 f3
fc5
t7

af4
f4 f8
fc6
t8

p7

p8
o1

o2

Alpha

Figure 8. The average neural patterns over all subjects for different emotions from the first database
https://www.sic.ici.ro

Recursive Identification Based on OS-ELM for Emotion Recognition and Prediction of Difficulties in...

temporal site, while “amusement” and “disgust”
are concentrated in the occipital site.
Concerning the frequency bands, it can be
found that the frequency theta is sensitive
to “compassion” and “disgust”. The alpha
band can differentiate between “neutrality”,
“amusement”, “compassion” and “attraction”,
while the beta band can differentiate between
“neutrality” and “compassion”.
Table 9. List of dominant electrodes for each
emotion from the first database
Emotions
Neutrality
Amusement
Surprise
Compassion
Attraction
Disgust

Theta
Alpha
Beta
Dominant electrodes
AF4
AF4
O1
T8
AF4
FC6, P7
F4
O2
-

347

and “disgust”. By observing the results during the
learning and testing phases, it can be noticed that
“neutrality” and “compassion” take a good rate
of accuracy when the theta energy feature is used,
whereas, “amusement” and “disgust” take good
rates of accuracy when using the beta energy.
The alpha energy feature gives good accuracy
for “surprise” and “attraction”. Added to that, the
results fusing all the energy bands are presented.
It can be noted that the fusion method gives better
results than using independent frequency bands.
The best rates of accuracy are illustrated in Table
10. It can be noted that the beta energy and the
fusion method give the best results.

6.2.3 Results of Classification System

6.2.2 Results of Identification System
The rates of sensitivity, specificity and accuracy are
computed over all the subjects including “neutrality”,
“amusement”, “surprise”, “compassion”, “attraction”

Table 11 presents the rate of emotion recognition
by using a classifier composed by 6 classes. Each
class refers to an emotional state. It can be noticed
that the fusion method of frequency bands gives
a recognition rate higher than using independent
frequency bands. The recognition rate is of
87.03% in the learning step and of 40.74% in the
testing step without considering emotion overlap.

Table 10. Mean of accuracy rates over subjects using beta energy and fusion method
Neut.
(1)

Amus.
(2)

(1)

Surp.
(2)

(1)

Compas.
(2)

Attrac.

Disgust

(1)

(2)

(1)

(2)

(1)

(2)

70.50

16.66

70.64

16.66

78.66

45.18

79.58

20.25

82.26

19.62

87.91

46.34

64.44

16.66

73.05

16.66

70.33

43.19

19.25

79.79

19.25

74.98

44.71

Beta energy
Train
(%)

Accuracy

68.40

16.66

77.10

20.54

72.51

21.17

Fusion of features
Accuracy

83.65

16.66

84.61

23.55

85.11

Accuracy

65.06

16.66

75.81

16.43

71.95

Accuracy

75.71

16.66

78.08

19.33

81.41

21.27
Beta energy

Test
(%)

20.55

Fusion of features
20.87

75.58

(1): Our method, (2):SVM

Table 11. Accuracy rate of classification system with and without considering emotion overlap

Without
emotion overlap

Considering
emotions
overlap

Features

Train Accuracy

Test Accuracy

Theta

35.18

16.66

Alpha

40.74

20.37

Beta

46.29

18.51

Fusion

87.03

40.74

Theta

81.48

55.55

Alpha

77.77

50

Beta

81.48

68.51

Fusion

100

74.07

ICI Bucharest © Copyright 2012-2020. All rights reserved

348

Hayfa Blaiech, Noureddine Liouane

When considering the emotion overlap, the rate is
of 100% for training and of 74.07% for testing.

6.3 Experimental Results on the Second
Database: Predicting Difficulties in
Video Games
6.3.1 Neural Signatures
and Stable Patterns
Figure 9 depicts the average neural patterns for
the neutral emotion and the state describing the
difficulties encountered while playing video
game. The results prove that neural signatures
associated with these two states do exist. While
playing the game, the energy of the prefrontal area
enhances. Also the temporal and occipital sites of
the right area activate more. The present results
are congruent to those of the existing studies
(Berntson et al., 2011) which evocate that negative
emotions are associated more with the right rather
than to the left hemispheric activity. Secondly,
the average rates of the sensitivity of each EEG
channel from the cortex are computed. The results
of the distribution of channels over all the subjects
of this database are presented in Table 12. By
observing the dominant sensors over emotions, it
can be noticed that “neutrality” concentrates in the
frontal site in the theta band and the right frontal
site in the beta band. Concerning the emotions
generated by the difficulties encountered in the

video games, which are the concentration and
anger states, it can be noticed that these states are
found in the right fontal site of the cortex in the
theta, alpha and beta bands.
Table 12. List of dominant electrodes for each
emotion from the second database
Emotions

Theta

Alpha

Beta

-

AF4

Dominant electrodes
Neutrality

FC5

Concentration and Anger AF4,FC6 AF4,FC6

AF4

6.3.2 Results of Identification System
The rates of sensitivity, specificity and accuracy
are computed over all the subjects including
“neutrality” and the emotion state depicting the
difficulties encountered in the video games which
is “concentration with anger”. These figures show
that the energy features of the beta band and of the
fusion method take the best rates of sensitivity,
specificity and accuracy (Table 13).

6.3.3 Results of Classification System
Table 14 illustrates the results obtained from the
classifier composed by two classes referring to the
two emotion states “neutrality” and “concentration
with anger”. The feature energy of beta has the
best recognition rates of 94.44% in the training
phase and of 61.11% in the testing phase.

Delta

Theta

Beta

Alpha

Figure 9. The average neural patterns over all subjects for different emotions from the second database
(Predicting difficulties in video game)
https://www.sic.ici.ro

Recursive Identification Based on OS-ELM for Emotion Recognition and Prediction of Difficulties in...

349

Table 13. Average accuracy of recursive OS-ELM for each emotion from energy of beta band and our
fusion method
Neutral

Concentration and Anger

Our method
Train
(%)

Test
(%)

Accuracy

72.50

Accuracy

81.43

Accuracy

52.15

Accuracy

50.88

SVM
Beta energy
58.70
Fusion of features
60.41
Beta energy
52.90
Fusion of features
51.41

Our method

SVM

61.45

51.55

70.57

64.76

52.83

48.25

51.50

55.27

Table 14. Accuracy Rate of classification system

Without emotion
overlap

Features

Train Accuracy

Test Accuracy

Theta

83.33

38.88

Alpha

72.22

44.44

Beta

94.44

61.11

Fusion

100

44.44

6.4 Discussion
This novel algorithm of identification, based on the
principle of recursivity and OS-ELM, has better
results than those of the algorithms from other
studies using the DEAP database. By testing the
DEAP database, the results are analyzed and the
best features are selected. The energy features
have the best rates of accuracy in comparison
with the mean, the standard deviation and the
power. It can be deduced that the beta band is
the most responsible for emotion identification.
Firstly, a new database is created to incite new
emotions that do not exist in the DEAP database
such as “disgust”, “surprise” and “compassion”.
Secondly, subjects having our culture and from
our environment are used. Thirdly, a hard video
game that contain several stages is chosen, to
identify the difficulties encountered when playing.
Then the concentration and anger emotion states
that the subjects feel while playing video games
are detected. From the two emotional experiences
it can be deduced that the beta band is mostly
sensitive to emotional states, and that the delta
band has no sensitivity to emotional states.
The present fusion method has the best results
of emotion identification, as well as the best
classification rates, while the feature energy of beta
has the best rates of accuracy in predicting
difficulties in video games. Furthermore, the

classifier improves the recognition rates. The
SVM method was applied in the present samples
(Schölkopf et al. 2002) (Tables 10 and 13). By
comparing the recursive identification method
based on OS ELM, to the SVM method, it was
found that the present method has the best rates
of identification.

7. Conclusion
In this paper a novel algorithm based on OS-ELM
and recursive identification has been proposed.
This algorithm has been validated on the publicly
DEAP database. Two new databases have been
constructed. In fact, two emotional experiences
using the emotiv epoc headset have been
accomplished. In the first step, six emotional states
have been induced by utilizing image and video
stimuli. In the second step, we incited the subjects
to play a hard video game. The goal was to predict
the difficulties encountered when playing and to
identify the concentration and anger emotional
states. The present learning algorithm has been
applied on two new databases and the results of
this experience have been analyzed by observing
the localization of these emotional states in
the cortex. Some parts of the lobe cranial
responsible of some emotional states have
been noticed. This work has been divided in
two parts: identification and classification. In the
ICI Bucharest © Copyright 2012-2020. All rights reserved

350

Hayfa Blaiech, Noureddine Liouane

identification part, each emotion (identified
or not) has been treated independently. For the
classification part, the performance has been
measured by computing the highest recognition
rates of each identification system. Finally, the
present method has been compared to the SVM
method and it has been proved that the method
employed in this paper has had the best rates of
identification. This system has achieved good
recognition rates: 80% when using the DEAP

database, 74.07% when utilizing this first newly
database, and 61.11% when predicting difficulties
in video games. a perspective of this work, the
number of emotional states can be enlarged by
treating other more complex ones. The human
emotion of other cultures cannot be treated yet.
In a next step, this algorithm will be implemented
in a Field Programmable Gate Arrays (FPGA)
platform in order to gain the time of execution.

REFERENCES
AlDahoul, N., & Htike, Z. (2015). Online Sequential
Extreme Learning Machine Based Functional
Magnetic Resonance Imaging Decoder, Advanced
Science Letters, 21(11), 3489-3493.
Anon (2015). Hardest Game Ever. Available
at:
<https://www.hardestgameever.net/>,
last
accessed: 2018.
Atkinson, J. & Campos, D. (2015). Improving BCIbased emotion recognition by combining EEG
feature selection and kernel classifiers, Expert
Systems with Appications, 47, 35-41. DOI: 10.1016/j.
eswa.2015.10.049.
Balconi, M., Grippa, E. & Vanutelli, M. E. (2015).
What hemodynamic (fNIRS), electrophysiological
(EEG) and autonomic integrated measures can tell us
about emotional processing, Brain and Cognition, 95,
67-76. DOI: 10.1016/j.bandc.2015.02.001
Barrett, L. F. & Russell, J. A. (1998). Independence
and bipolarity in the structure of current affect, Journal
of Personality and Social Psychology, 74(4), 967-984.
Berntson, G. G., Norman, G. J. & Cacioppo, J. T.
(2011). Comment: laterality and evaluative bivalence:
a neuroevolutionary perspective, Emotion Review, 3,
344–346.
Blaiech, H., Neji, M., Wali, A. & Alimi, M. A. (2013).
Emotion Recognition by Analysis of EEG Signals.
In The 13th International conference on Hybrid
Intelligent Systems, HIS 2013, December 04-06, 2013,
Hammamet-Tunisia (pp. 312-318). DOI: 10.1109/
HIS.2013.6920451

Güntekin, B. & Basar, E. (2010). Event-related beta
oscillations are affected by emotional eliciting stimuli,
Neuroscience letters, 483(3), 173-178.
Huang, G. B., Zhou, H., Ding, X. & Zhang, R.
(2012). Extreme Learning Machine for Regression
and Multiclass Classification, IEEE Transactions on
Systems, Man, And Cybernetics – Part B: Cybernetics,
42(2), 513-529.
Jenke, R., Peer, A. & Buss, M. (2014). Feature
extraction and selection for emotion recognition from
EEG, IEEE Transactions on Affective Computing,
5(3), 327–339.
Jung, T.-P., Makeig, S., Humphries, C., Lee, T.-W.,
McKeown, M., Iragui, V. & Sejnowski, T. (2000).
Removing electroencephalographic artifacts by blind
source separation, Psychophysiology, 37(2), 163-178.
Klimesch, W., Doppelmayr, M., Russegger, H.,
Pachinger, T. & Schwaiger, J. (1998). Induced alpha
band power changes in the human EEG and attention,
Neuroscience letters, 244(2), 73–76.
Koelstra S., Muhl, C., Soleymani, M., Lee, J. S.,
Yazdani, A., Ebrahimi, T, Pun, T., Nijholt, A. &
Patras, I. (2012). DEAP: a database for emotion
analysis; using physiological signals, IEEE
Transactions Affective Computing, 3(1), 18- 31. DOI:
10.1109/T-AFFC.2011.15
Kumar, N., Khaund, K. & Hazarika, S. M. (2016).
Bispectral Analysis of EEG for Emotion Recognition,
Procedia Computer Science, 84, 31-35. DOI:
10.1016/j.procs.2016.04.062.

Bradley, M. M. & Lang, P. J. (1994). Measuring
emotion: the selfassessment manikin and the semantic
differential, Journal of Behavior Therapy and
Experimental Psychiatry, 25(1), 49-59.

Li, L. N., Ouyang, J. H., Chen, H. L &, Liu, D.Y.
(2012). A computer aided diagnosis system for thyroid
disease using extreme learning machine, Journal of
Medical Systems, 3(5), 3327–3337.

Dan-Glauser, E. S. & Scherer, K. R. (2011). The
Geneva affective picture database (GAPED): a
new 730-picture database focusing on valence and
normative significance, Behavior Research Methods,
43(2), 468-477.

Li. S. & Deng W. (2018). Deep Facial Expression
Recognition: A Survey, ArXiv, abs/1804.08348.

https://www.sic.ici.ro

Li, Y., Zhang, S., Yin, Y., Xiao, W. & Zhang, J.
(2017). A Novel Online Sequential Extreme Learning

Recursive Identification Based on OS-ELM for Emotion Recognition and Prediction of Difficulties in...

Machine for Gas Utilization Ratio Prediction in Blast
Furnaces, Sensors, 17(8), 1847.
Liang, N., Huang, G. & Saratchandran, P. &
Sundararajan, N. (2006). A Fast and Accurate Online
Sequential Learning Algorithm for Feedforward
Networks, IEEE Transactions on Neural Networks,
17(6), 1411-142. DOI: 10.1109/TNN.2006.880583
Liu, C., Han, J., Shang, Y., Liu, C., Cheng, B. &
Chen, J. (2017). Predicting of Job Failure in Compute
Cloud Based on Online Extreme Learning Machine:
A Comparative Study, IEEE Access, 5, 9359-9368.
DOI: 10.1109/ACCESS.2017.2706740
Ng, H.-W. & Nguyen, D., Vonikakis, V. & Winkler,
S. (2015). Deep Learning for Emotion Recognition
on Small Datasets Using Transfer Learning. In
ACM International Conference on Multimodal
Interaction, Seattle, Washington, USA (pp. 443-449).
DOI: 10.1145/2818346.2830593
Palaniswamy, S. & and Tripathi, S. (2018). Emotion
Recognition from Facial Expressions using Images
with Pose, Illumination and Age Variation for HumanComputer/Robot Interaction, Journal of ICT Research
and Applications, 12(1), 14-34.
Petrantonakis, P. C. & Hadjileontiadis, L. J. (2009).
EEG-Based Emotion Recognition Using Hybrid
Filtering and Higher Order Crossings. In: 2009 3rd
International Conference on Affective Computing
and Intelligent Interaction and Workshops, 10-12
September 2009, Amsterdam (pp. 1-6). DOI: 10.1109/
ACII.2009.5349513
Picard, R. W. (2000). Affective Computing. Cambridge,
MA: The MIT Press.
Savojardo, C., Fariselli, P. & Casadio, R. (2011).
Improving the detection of transmembrane betabarrel chains with n-to-1 extreme learning machines,
Bioinformatics, 27(22), 3123–3128.
Schölkopf, S. (2002). Learning with Kernels: Support
Vector Machines, Regularization, Optimization and
Beyond. MIT Press.

351

Shi, L. C. & Lu, B. L. (2013). EEG-based vigilance
estimation using extreme learning machines,
Neurocomputing, 102, 135–143.
Singh, R.P., Dabas, N., Chaudhary, V., Nagendra
(2015) Online Sequential Extreme Learning Machine
for Watermarking. In: Cao, J., Mao, K., Cambria, E.,
Man, Z. & Toh, K. A. (eds.), Proceedings of ELM2014 Volume 2. Proceedings in Adaptation, Learning
and Optimization, vol 4, 115-124. Springer, Cham.
DOI: 10.1007/978-3-319-14066-7_12
Song, Y. D. & Zhang, J. X. (2013). Automatic
recognition of epileptic EEG patterns via extreme
learning machine and multiresolution feature
extraction, Expert Systems with Applications, 40(14),
5477–5489.
Yadav, B., Ch, S., Mathur, S. & Adamowski, J. (2016).
Discharge forecasting using an Online Sequential
Extreme Learning Machine (OS-ELM) model: A case
study in Neckar River, Germany, Measurement, 92,
433–445.
Yang, D., Alsadoon, A., Prasad, P.W.C., Singh, A. K.
& Elchouemi, A. (2018). An Emotion Recognition
Model Based on Facial Recognition in Virtual
Learning Environment, Procedia Computer Science,
125, 2-10.
You, Z. H., Lei, Y. K., Zhu, L., Xia, J. F. & Wang,
B. (2013). Prediction of protein-protein interactions
from amino acid sequences with ensemble extreme
learning machines and principal component analysis,
BMC Bioinformatics, 14, 1-11. Article number: S10.
Zhang, J., Chen, M., Zhao, S., Hu, S., Shi, Z. & Cao,
Y. (2016). ReliefF-Based EEG Sensor Selection
Methods for Emotion Recognition, Sensors, 16(10),
1558. DOI: 10.3390/s16101558
Zhang, J., Feng, L. & Yu, L. (2017). A novel target
tracking method based on OS-ELM, Multidimensional
Systems and Signal Processing, 28(3), 1091-1108.

ICI Bucharest © Copyright 2012-2020. All rights reserved

