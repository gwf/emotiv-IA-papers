Bulletin of Electrical Engineering and Informatics
Vol. 7, No. 2, June 2018, pp. 279~285
ISSN: 2302-9285, DOI: 10.11591/eei.v7i2.678



279

Robot Motion Control Using the Emotiv EPOC EEG System
Sandy Akbar Dewangga, Handayani Tjandrasa, Darlis Herumurti
Department of Informatics Sepuluh Nopember Institute of Technology (ITS), Indonesia

Article Info

ABSTRACT

Article history:

Brain-computer interfaces have been explored for years with the intent of
using human thoughts to control mechanical system. By capturing the
transmission of signals directly from the human brain or
electroencephalogram (EEG), human thoughts can be made as motion
commands to the robot. This paper presents a prototype for an
electroencephalogram (EEG) based brain-actuated robot control system using
mental commands. In this study, Linear Discriminant Analysis (LDA) and
Support Vector Machine (SVM) method were combined to establish the best
model. Dataset containing features of EEG signals were obtained from the
subject non-invasively using Emotiv EPOC headset. The best model was
then used by Brain-Computer Interface (BCI) to classify the EEG signals into
robot motion commands to control the robot directly. The result of the
classification gave the average accuracy of 69.06%.

Received Sep 09, 2018
Revised Mar 02, 2018
Accepted Mar 16, 2018
Keywords:
Brain–computer interface
Electroencephalogram (EEG)
Emotiv epoc
Linear discriminant analysis
Support vector machine

Copyright © 2018 Institute of Advanced Engineering and Science.
All rights reserved.

Corresponding Author:
Sandy Akbar Dewangga,
Department of Informatics,
Sepuluh Nopember Institute of Technology (ITS), Surabaya, Indonesia.
Email: sssandy.ad@gmail.com

1.

INTRODUCTION
A brain-computer interface (BCI) system provides a communication between human brain and a
computer by interpreting the intention of the brain via EEG signals.The feasibility of the technique was first
demonstrated using brain activity acquired from the intracranial electrodes implanted in the motor cortex of
rats [1], and monkeys [2]-[5]. The main problems for the development of reliable signal translation methods
are due to the variability of mental activities such as motoric imagery activity and subject characteristics.
In some studies, EEG signals were preprocessed by applying Single Channel Independent
Component Analysis (SCICA) [6] and Empirical Mode Decomposition (EMD) [7], the features were
extracted using the summation of several power spectrum components before classification. Higuchi fractal
dimension was used for classifying the EEG signals recorded from the subjects before and after meditation
[8]. Another study was to analyze early Alzheimer EEGs by utilizing the power spectral analysis and other
complexity features [9]. Learning styles of 68 participants were assessed via Kolb’s Learning Style
Inventory, and the EEG signals were recorded from the prefrontal cortex. The alpha and theta spectral
centroid frequencies were utilized as the inputs of k-nearest neighbor classifier to divide the participants into
four learning groups, i.e. diverger, assimilator, converger, and accommodator groups [10].
Recently, the most developed technology is Brain Computer Interface (BCI) application. The EEG
recorded based on imagery activities is translated by an automation system to derive the original motoric or
other cognitive-related intentions. One study in this field was implemented by employing bandpass filter and
Common Spatial Pattern (CSP) for noise filtering. Then, the features were extracted using Principle
Component Analysis (PCA), and classified by applying Interval Type-2 Fuzzy Logic System [11]. EEG
signals of left and right hand movement imagination were extracted by obtaining the DWT coefficients of the
EEG beta band. The features were classified into two classes using probabilistic and back propagation neural
networks [12].

Journal homepage: http://journal.portalgaruda.org/index.php/EEI/index

280



ISSN: 2302-9285

Another application, the assessment of different stimulus modalities of video games using Emotiv
EEG showed that intensity game play was related to the frequency bands. During high-intensity events, beta
and gamma power was significantly increased compared to low intensity events [13]. EEG signals captured
by the Emotiv Epoc Headset were applied to control the Spykee mobile robot via a wireless communication.
The pattern recognition was carried out by the echo state network [14]. The BCI system for controlling a
LEGO Mindstorms NXT robot using Neurosky headset and Emotiv Epoch was evaluated based on
participant’s experience with a descriptive label on a 7-point scale. The result had the average of 4.2 and the
standard deviation of 1.2 for controlling the robot to move forward and to end the track [15].
The Emotiv EPOC system was studied for the capability to recognize the P300 event-related
potential for P300-speller based on the oddball paradigm [16]. The Emotiv EPOC system was also tested and
compared with the medical grade system for the auditory ERP research [17] and the P300 speller-like system
[18]. The P300 event-related potentials for disable Subjects using stimuli of the six-choice P300 paradigm
were classified using singular spectrum analysis (SSA) and multilayer perceptron (MLP) [19], andwavelet
transform, MLP, and soft margin SVM [20].
This study employed the Emotiv EPOC to control a mobile robot to move forward, backward, turn
right, turn left, and neutral, via EEG imagery motion. The Emotiv EPOC headset has 14 saline electrodes and
2 reference electrodes which are used to collect EEG data from the subject, and transmit the data wirelessly
to a computer for processing. Initially, EEG signals of imagery motion were recorded and processed off-line
to train the classification system, which consisted of Linear Discriminant Analysis (LDA) and Support
Vector Machine (SVM). Then the obtained model was applied to predict the class of the real-time EEG
signals and the result was translated into one of the five motion commands. Since the recognition of the EEG
signals was used to control a mobile robot in real-time processing, the sampled EEG signals of 14 channels
(after normalization every 0.5 s) were used directly as the feature vector of the classifier.

2.

MATERIAL
Raw EEG data were obtained from the EEG data recording of mental command thought of a test
subject using the Emotiv EPOC. EEG data recording process was done by using Emotiv Xavier testbench
software. The use of Emotiv EPOC device by a test subject is shown in Figure 1.

Figure 1. The test subject used Emotiv EPOC headset to record EEG data

EEG was recorded when the test subject thought certain mental commands by imagining the
movement of the object. The test subject must focus, relax, and there are not many disturbing movements
when doing the mental commands. We used “Mental Command Suite” to help the test subject do the mental
commands that allowed the test subject to control the motion of a 3-dimensional cube using his mind. The 3D
cube can move up, down, left and right according to the test subject's mind, as shown in Figure 2. The mental
command suite is included in Emotiv Xavier software.
From the process of recording the data, we obtained raw EEG data consisting of 5 classes of motion:
neutral, forward, backward, turn right and turn left. Each class had 5 minutes of data and 14 features (of 14
Emotiv EPOC sensor channels), as shown in Figure 3. The EEG sampling rate was 128 Hz.

BEEI, Vol. 7, No. 2, June 2018 : 279 – 285

BEEI

ISSN: 2302-9285

Figure 2. A 3D cube model as a tool to facilitate
test subjects in performing the mental command:
a) turn left command, b) turn right command, c)
forward command, d) backward command



281

Figure 3. The raw EEG data that recorded by 14 saline
electrodes

3.

RESEARCH METHOD
The system classification to control the mobile robot is illustrated in Figure 4. It consisted of three
stages, i.e. preprocessing, processing, and post-processing. The recorded EEG called the raw EEG was used
to train the classifier off-line. Then, the model of the classifier predicted the on-line class of the real-time
EEG.

Figure 4. Flowchart of the system

3.1. Preprocessing
This stage aimed to eliminate the noise signal and to normalize the data before the data were
processed further. The processes that were carried out at this stage was Butterworth bandpass filtering and
Robot Motion Control Using the Emotiv EPOC EEG System (Sandy Akbar Dewangga)

282



ISSN: 2302-9285

normalizing data. Butterworth bandpass filters are causal and of various orders. We used a Butterworth
bandpass filter of 4th order with lower and upper cutoff frequencies 29 Hz and 40Hz, respectively.
The EEG data from the Emotiv EPOC had 14 attributes from 14 electrode channels and sampled at
128 Hz. The data were then normalized separately for each channel. Normalization was performed every 0.5
s of data (64 samples) using the following formula,
(1)
where the number 30 is the average signal amplitude of the headset.
3.2. Processing
This stage aimed to get the model that was used in the classification process of real-time EEG data.
The processes carried out at this stage were to train the combined classifier, i.e. linear discriminant analysis
(LDA) and support vector machine (SVM). The interface to process data training is shown in Figure 5.
The selection of training data was determined as random sequences of length N seconds of each
class of commands. The N second length sequence was determined by the duration of recording the training
data. Then the raw EEG data were obtained by combining all sequences from each class of commands. For
testing data, we used the whole EEG data. Illustration of the selection of training data can be seen in Figure
6.

Figure 5. The interface of BCI’s data training process

Figure 6. Illustration of the selection of training data

We applied this raw EEG data as the LDA input. The LDA projection was then used as the SVM
data input. Support Vector Machine is basically a binary classifier. Because the classification had more than
two classes, multiple SVMs with a one-against-one scheme were built. After the SVM training, we obtained
the model for classifying real-time EEG data. The output class was then translated to a motion command.
The motion command class determination was performed every 0.5 s for 64 samples of EEG data. The
display of the real-time EEG classification process is shown in Figure 7.

BEEI, Vol. 7, No. 2, June 2018 : 279 – 285

BEEI



ISSN: 2302-9285

283

Figure 7. Display of the real-time EEG classification process

3.3. Post-processing
After the classification process, motion commands were sent to move the robot. The next command
was sent to the robot if the class obtained was different from the previous one. The motion command was
sent in the form of a single character and transmitted via serial communication. The robot used was a
wheeled robot that could move forward, backward, turn right, and turn left. The robot was connected
wirelessly with BCI program using XBee PRO transmitter. The physical form of the robot and transmitter
can be seen in Figure 8.

Figure 8. The motion command was sent from BCI to the robot wirelessly (a) A wheeled robot that could
move forward, backward, turn right and turn left (b) Transmitter robot XBee PRO which connected the robot
with a Brain Computer Interface (BCI) wirelessly

4.

RESULTS AND DISCUSSION
For the first scenario, the system was tested for the classification process of the combined LDA and
SVM by varying the recording duration. Lower and upper cutoff frequencies were 29 Hz and 40 HZ,
respectively. The results indicated that, the accuracy was better for longer duration of time up to 25 s and the
accuracy for the neutral position was the highest, as shown in Table 1.

Table 1. Accuracy for Various Recording Times
Recording Time
(second)
5
8
10
15
20
25
30
40
50
60

Forward
(%)
61.11
54.32
63.79
64.38
65.39
70.99
69.02
70.83
64.53
67.56

Backward
(%)
58.96
57.93
63.35
66.49
69.99
64.59
60.50
66.78
65.06
54.75

Right
(%)
61.09
60.53
64.01
69.29
68.25
66.81
61.31
70.02
67.45
69.50

Left
(%)
63.56
61.05
60.21
62.69
64.59
71.21
64.78
65.80
58.89
68.95

Neutral
(%)
74.08
73.02
81.59
83.80
83.23
85.75
90.54
81.47
90.72
87.24

Average
Accuracy (%)
63.76
61.37
66.59
69.33
70.29
71.87
69.23
70.98
69.33
69.60

Robot Motion Control Using the Emotiv EPOC EEG System (Sandy Akbar Dewangga)

284



ISSN: 2302-9285

For the second scenario, the classification process was also performed using various values for
lower and upper cutoff frequencies of the Butterworth bandpass filter. Both test variables were combined and
performed for 10 iterations for each combination. Each combination was tested using a 30 second recording
time. Detailed testing of the accuracy of this scenario is shown in Table 2. Based on the results of this
scenario, the most optimal average accuracy was 70.28% for lower and upper cutoff frequencies 28 Hz and
39 Hz, respectively.

Table 2. The results of Classification Accuracy
No.
1
2
3
4
5
6
7
8
9
10

Lower cutoff
frequency (Hz)
16
22
31
33
29
29
29
29
28
30

Upper cutoff
frequency (Hz)
40
40
40
40
37
39
45
43
39
40

Average
Accuracy (%)
45.55
58.91
68.43
67.42
67.32
69.69
63.70
65.17
70.28
68.55

For the third scenario, the classification was carried out for 2, 3, 4, and 5 classes with a 30 s
recording time. The average accuracy for 2, 3, 4, and 5 classes was 89.45%, 82.50%. 76.30%, and 67.52%,
respectively.
All of the above scenarios applied the combined LDA and SVM. The combined LDA and SVM
produced a good model for classifying EEG data for mental commands to control robot motion. The
classification of 5 classes with a 30 s recording time, showed that the combined LDA and SVM yielded
better accuracy than using only LDA and SVM separately. The average accuracy for LDA, SVM, and the
combined LDA and SVM were 56.13%, 67.42%, and 69.06%, respectively.

5.

CONCLUSION
From the results, it can be concluded that classifying EEG mental command data using a
combination of LDA and SVM provides better performance than using LDA and SVM separately. This can
produce an accuracy of at least 60% by varying the cutoff frequencies of the Butterworth bandpass filter by
about 29 Hz and 40 Hz for lower and upper cutoff frequencies. The recording time of 25 or 30 seconds
maintains its accuracy greater than 65%. The experiments show that smaller number of classes provide
greater accuracy with the maximum average accuracy of 89.45%.

REFERENCES
[1] Chapin JK, Moxon KA, Markowitz RS, Nicolelis MAL. Real-time Control of a Robot Arm using Simultaneously
Recorded Neurons in the Motor Cortex. Nature Neurosci. 2: 664–670, 1999.
[2] Wessberg J. et al. Real-time Prediction of Hand Trajectory by Ensembles of Cortical Neurons in Primates. Nature.
408: 361–365, 2000.
[3] Taylor DM, Tillery SIH, Schwartz AB. Direct Cortical Control of 3D Neuroprosthetic Devices. Science. 296: 1829–
1832, 2002.
[4] Serruya MD, Hatsopoulos NG, Paninski L, Fellows MR, Donoghue J. Instant Neural Control of a Movement Signal.
Nature. 416: 141–142, 2002.
[5] Nicolelis MAL. Brain-machine Interfaces to Restore Motor Function and Probe Neural Circuits. Nature Rev.
Neurosci. 4: 417–422, 2003.
[6] Tjandrasa H, Djanali S. Classification of EEG Signals Using Single Channel Independent Component Analysis,
Power Spectrum, and Linear Discriminant Analysis. Lecture Notes in Electrical Engineering (LNEE), Springer
387: 259-268, 2016.
[7] Tjandrasa H, Djanali S, Arunanto FX. Feature extraction using combination of intrinsic mode functions and power
spectrum for EEG signal classification. 2016 9th International Congress on Image and Signal Processing,
BioMedical Engineering and Informatics (CISP-BMEI). Datong. 1498–1502, 2016.
[8] Harne BP. Higuchi Fractal Dimension Analysis of EEG Signal before and after OM Chanting to Observe Overall
Effect on Brain. International Journal of Electrical and Computer Engineering. 4: 585-592, 2014.
[9] McBride JC et al. Spectral and Complexity Analysis of Scalp EEG Characteristics for Mild Cognitive Impairment
and Early Alzheimer’s Disease. Computer Methods and Programs in Biomedicine. 114: 153–163, 2014.

BEEI, Vol. 7, No. 2, June 2018 : 279 – 285

BEEI

ISSN: 2302-9285



285

[10] Ali MSAM, Jahidin AH, Tahir NM, Taib MN. Learning Style Classification via EEG Sub-band Spectral Centroid
Frequency Features. International Journal of Electrical and Computer Engineering. 4: 931-938, 2014.
[11] Budiman WY, Tjandrasa H, Navastara DA. Classification of EEG signals using Common Spatial Pattern-Principle
Component Analysis and Interval Type-2 Fuzzy Logic System. 2016 International Conference on Information,
Communication Technology and Systems (ICTS), Surabaya. 85–89, 2016.
[12] Hossain ABMA, Rahman MW, Riheen MA. Left and Right Hand Movements EEG Signals Classification Using
Wavelet Transform and Probabilistic Neural Network. International Journal of Electrical and Computer
Engineering. 5: 92-10, 2015.
[13] McMahan T, Parberry I, Parsons TD. Modality specific assessment of video game player’s experience using the
Emotiv. Entertainment Computing. 7:1–6, 2015.
[14] Grude S, Freeland M, Yang C, Ma H. Controlling mobile Spykee robot using Emotiv Neuro Headset. Proceedings of
the 32nd Chinese Control Conference. Xi’an. 2013.
[15] Vourvopoulos A, Liarokapis F. Robot Navigation using Brain-Computer Interfaces. IEEE 11th International
Conference on Trust, Security and Privacy in Computing and Communications. 1785-1792, 2012.
[16] Ekanayake H. P300 and Emotiv EPOC: Does Emotiv EPOC capture real EEG?. Retrieved from:
http://neurofeedback.visaduma.info/emotivresearch.htm. 2010.
[17] Badcock NA, Mousikou P, Mahajan Y, Lissa PD, Thie J, McArthur G. Validation of the Emotiv EPOC EEG
gaming system for measuring research quality auditory ERPs. Peer J, 2013.
[18] Duvinage M, Castermans T, Petieau M, Hoellinger T, Cheron G, and Dutoit T. Performance of the Emotiv Epoc
headset for P300-based applications. BioMedical Engineering OnLine. 2013.
[19] Tjandrasa H, Djanali S, Arunanto FX. Classification of P300 in EEG Signals for Disable Subjects Using Singular
Spectrum Analysis. International Conference on Intelligent Informatics and BioMedical Sciences (ICIIBMS).
Okinawa. 2017.
[20] Tjandrasa H, Djanali S. Classification of P300 Event-Related Potentials Using Wavelet Transform, MLP, and Soft
Margin SVM. The 10th International Conference on Advanced Computational Intelligence (ICACI). Xiamen. 2018.

Robot Motion Control Using the Emotiv EPOC EEG System (Sandy Akbar Dewangga)

