JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

Internet of Things Meets Brain-Computer
Interface: A Unified Deep Learning Framework
for Enabling Human-Thing Cognitive Interactivity

arXiv:1805.00789v3 [cs.HC] 22 Oct 2018

Xiang Zhang, Student Member, IEEE, Lina Yao, Member, IEEE, Shuai Zhang, Student Member, IEEE,
Salil Kanhere, Member, IEEE, Michael Sheng, Member, IEEE, and Yunhao Liu, Fellow, IEEE
Abstract—A Brain-Computer Interface (BCI) acquires brain signals, analyzes and translates them into commands that are relayed to
actuation devices for carrying out desired actions. With the widespread connectivity of everyday devices realized by the advent of the
Internet of Things (IoT), BCI can empower individuals to directly control objects such as smart home appliances or assistive robots,
directly via their thoughts. However, realization of this vision is faced with a number of challenges, most importantly being the issue of
accurately interpreting the intent of the individual from the raw brain signals that are often of low fidelity and subject to noise. Moreover,
pre-processing brain signals and the subsequent feature engineering are both time-consuming and highly reliant on human domain
expertise. To address the aforementioned issues, in this paper, we propose a unified deep learning based framework that enables
effective human-thing cognitive interactivity in order to bridge individuals and IoT objects. We design a reinforcement learning based
Selective Attention Mechanism (SAM) to discover the distinctive features from the input brain signals. In addition, we propose a
modified Long Short-Term Memory (LSTM) to distinguish the inter-dimensional information forwarded from the SAM. To evaluate the
efficiency of the proposed framework, we conduct extensive real-world experiments and demonstrate that our model outperforms a
number of competitive state-of-the-art baselines. Two practical real-time human-thing cognitive interaction applications are presented
to validate the feasibility of our approach.
Index Terms—Internet of Things, Brain-Computer Interface, deep learning, cognitive.

F

1

I NTRODUCTION

I

T is expected that by 2020 over 50 billion devices will be
connected to the Internet. The proliferation of the Internet
of Things (IoT) is expected to improve efficiency and impact
various domains including home automation, manufacturing and
industries, transportation and healthcare [1]. Individuals will have
the opportunity to interact and control a wide range of everyday
objects through various means of interactions including applications running on their smartphone or wearable devices, voice
and gestures. Brain-Computer Interface (BCI) 1 is emerging as a
novel alternative for supporting interaction bewteen IoT objects
and individuals. BCI establishes a direct communication pathway
between human brain and an external device thus eliminating
the need for typical information delivery methods [2]. Recent
trends in BCI research have witnessed the translation of human
thinking capabilities into physical actions such as mind-controlled
wheelchairs and IoT-enabled appliances [3], [4]. These examples
suggest that the BCI is going to be a major aiding technology in
human-thing interaction [5].

•

•
•

Xiang Zhang, Lina Yao, Shuai Zhang, Salil Kanhere are with the School
of Computer Science and Engineering, University of New South Wales,
Kensington, NSW 2052, Australia.
E-mail: xiang.zhang3, shuai.zhang@student.unsw.edu.au
{lina.yao, salil.kanhere}@unsw.edu.au
Michael Sheng is with the Department of Computing, Macquarie University, Sydney, NSW 2109, Australia. E-mail: michael.sheng@mq.edu.au
Yunhao Liu is with the Department of Computer Science and Engineering,
Michigan State University, MI 48824, USA. E-mail: yunhao@cse.msu.edu

Copyright (c) 2012 IEEE. Personal use of this material is permitted. However,
permission to use this material for any other purposes must be obtained from
the IEEE by sending a request to pubs-permissions@ieee.org.
1. The BCI mentioned in this paper refers to non-invasive BCI.

BCI-based cognitive interactivity offers several advantages.
One is the inherent privacy arising from the fact that brain activity
is invisible and thus impossible to observe and replicate [6]. The
other is the convenience and real-time nature of the interaction,
since the human only needs to think of the interaction rather than
undertake the corresponding physical motions (e.g., speak, type,
gesture) [7].
However, the BCI-based human-thing cognitive interactivity
faces several challenges. While the brain signals can be measured
using a number of technologies such as Electroencephalogram
(EEG) [2], Functional Near-Infrared Spectroscopy (fNIR) [8],
and Magnetoencephalography (MEG) [9], all of these methods
are susceptible to low fidelity and are also easily influenced by
environmental factors and sentiment status (e.g., noise, concentration) [10]. In other words, the brain signals generally have very
low signal-to-noise ratios, and inherently lack sufficient spatial
or temporal resolution and insight on activities of deep brain
structures [5]. As a result, while current cognitive recognition systems can achieve about 70-80% accuracy, this is not sufficient to
design practical systems. Second, data pre-processing, parameter
selection (e.g., filter type, filtering band, segment window, and
overlapping), and feature engineering (e.g., feature selection and
extraction both in the time domain and frequency domain) are all
time-consuming and highly dependent on human expertise in the
domain [11].
To address the aforementioned issues, in this paper, we propose a unified Deep Learning (DL) [12] framework for enabling
human-thing cognitive interactivity. As shown in Figure 1, our
framework measures the user’s brain activity (such as EEG,
FNIRS, and MEG) through a specific brain signal collection

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015
Brain Activity

2

IoT Scenarios
Cloud Server

Smart
City

EEG

FNIRS

Internet

Internet

Smart
Hospital

Smart
Home

MEG
DL-based Framework

Fig. 1: Schematic diagram of cognitive IoT framework

equipment. The raw brain signals are forwarded to the cloud server
via Internet access. The cloud server uses a person-dependent pretrained deep learning model for analyzing the raw signals. The
analysis results interpreted signals could be used for actuating
functions in a wide range of IoT applicants such as smart city [13]
(e.g., transportation control, agenda schedule), smart hospital [14],
[15] (e.g., emergency call, anomaly mentoring), and smart home
[16], [17] (e.g., appliances control, assistive robot control).
The proposed unified deep learning framework aims to interpret the subjects’ intent and decode it into the corresponding
commands which are discernible for the IoT devices. Based on
our previous study [5], [18], for each single brain signal sample,
the self-similarity is always higher than the cross-similarity, which
means that the intra-intent cohesion of the samples is stronger than
the inter-intent cohesion. In this paper, we propose a weighted average spatial Long Short-Term Memory (WAS-LSTM) to exploit
the latent correlation between signal dimensions. The proposed
end-to-end framework is capable of modeling high-level, robust
and salient feature representations hidden in the raw human brain
signal streams and capturing complex relationships within data.
The main contributions of this paper are highlighted as follows:
•

•

•

We propose a unified deep learning based framework to
interpret individuals’ brain activity for enabling humanthing cognitive interactivity. To our best knowledge, we are
the very first work that bridging BCI and IoT to investigate
end-to-end cognitive brain-to-thing interaction.
We apply deep reinforcement learning, with designed
reward, state, and action model, to automatically discover
the most distinguishable features from the input brain signals. The discovered features are forwarded to a modified
deep learning structure, in particular, the proposed WASLSTM, to capture the cross-dimensional dependency in
order to recognize user’s intention.
We also present two operational prototypes of the proposed framework: a brain typing system and a cognitive
controlled smart home service robot, which demonstrate
the efficacy and practicality of our approach.

and shuffle processing; 2) the selective attention learning; 3) the
sequential LSTM-based classification. In the following, we will
first discuss the motivations of the proposed method and then
introduce the aforementioned components in details.
2.1

Motivation

How to exploit the latent relationship between EEG signal dimensions is the main focus of the proposed approach. The signals
belonging to different cognitions are supposed to have different
inter-dimension dependent relationships which contain rich and
discriminative information. This information is critical to improve
the distinctive signal pattern discovery.
In practice, the EEG signal is often arranged as 1-D vector, the
signal is less informative for the limited and fixed element arrangement. The elements order and the number of elements in each
signal vector can affect the element dependency. For example,
the inter-dimension dependency in {0,1,2,3,4} and {1,2,3,4,0}
are not reciprocal; similarly, {0,1,2,3,4} and {0,1,1,2,3,4} are not
reciprocal. In many real-world scenarios, the EEG data are concatenated following the distribution of biomedical EEG channels.
Unfortunately, the practical channel sequence, with the fixed order
and number, may not be suitable for inter-dimension dependency
analysis. Therefore, we propose the following three techniques to
amend the drawback.
First, we replicate and shuffle the input EEG signal vector on
dimension-wise in order to provide as much latent dependency as
possible among feature dimensions (Section 2.2).
Second, we introduce a focal zone as a Selective Attention
Mechanism (SAM), where the optimal inter-dimension dependency for each sample only depends on a small subset of features.
Here, the focal zone is optimized by deep reinforcement learning
which has been shown to achieve both good performance and
stability in policy learning (Section 2.3).
Third, we propose the WAS-LSTM classifier by extracting the
distinctive inter-dimension dependency (Section 2.4).
2.2

Data Replicate and Shuffle

Suppose the input EEG data can be denoted by X =
{(xi , yi ), i = 1, 2, · · · I} where (xi , yi ) denotes the 1-D EEG
signal, called one sample in this paper, and I denotes the number
of samples. In each sample, the feature xi ∈ RK contains K
elements and the corresponding ground truth yi ∈ R is an integer
that denotes the sample’s category. Different categories correspond
to various brain activities. xi can be described as a vector with K
elements, xi = {xik , k = 1, 2, · · · , K}.
To provide more potential inter-dimension spatial dependencies, we propose a method called Replicate and Shuffle (RS).
RS is a two-step feature transformation method which maps xi
to a higher dimensional space x0i with more complete element
combinations:
0

2

T HE P ROPOSED F RAMEWORK

In this section, we present the cognition detection framework in
detail. The subjects’ brain activity can be measured by a number
of methods like EEG, fMRI, MEG. In this paper, we exploit
EEG due to its unique features such as low-cost, low-energy,
privacy, and portability. The proposed framework is depicted in
Figure 2. The main focus of the approach is to exploit the latent
dependency among different signal dimensions. To this end, the
proposed framework contains several components: 1) the replicate

xi ∈ RK → x0i ∈ RK , K 0 > K
In the first step (Replicate), we replicate xi for h = K 0 %K + 1
times where % denotes remainder operation. Then we get a new
vector with length as h∗K which is not less than K 0 ; in the second
step (Shuffle), we randomly shuffle the replicated vector in the first
step and intercept the first K 0 element to generate x0i . Theoretically, compared to xi , the number and order of elements in x0i are
more diverse. For instance, set xi = {1, 3, 4, 2}, in which the four
elements are arranged in a fixed order and limited combinations,

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

3

Fig. 2: Flowchart of the proposed framework. The focal zone x̄i is a selected fragment from x0i to feed in the state transition and the reward
model. In each step t, one action is selected by the state transition to update st based on the agent’s feedback. The reward model evaluates the
quality of the focal zone to the reward rt . The dueling DQN is employed to find the optimal focal zone x̄∗i which will be feed into the LSTM
based classifier to explore the inter-dimension dependency and predict the sample’s label yi0 . F CL denotes Fully Connected Layer. The State
Transition contains four actions: left shifting, right shifting, extend, and condense. The dashed line indicates the focal zone before the action
while the solid line indicates the position of the focal zone after the action.

it is difficult to mine the latent pattern in xi ; however, set the
replicated and shuffled signal as x0i = {3, 1, 2, 3, 4, 4, 1, 2}, the
equal difference characteristic is easy to be found in the fragment
{1, 2, 3, 4} (the 2-nd to 5-th elements of x0i ). Therefore, a major
challenge in this work is to discover the fragment with rich
distinguishable information. To solve this problem, we propose a
attention based selective mechanism which is detailed introduced
in Section 2.3.

2.3

Selective Attention Mechanism

In the next process, we attempt to find the optimal dependency
which includes the most distinctive information. But K 0 , the
length of x0i , is too large and is computationally expensive. To
balance the length and the information content, we introduce the
attention mechanism [19] to emphasize the informative fragment
in x0i and denote the fragment by x̄i , which is called focal
zone. Suppose x̄i ∈ RK̄ and K̄ denotes the length of the focal
zone. For simplicity, we continue to denote the k -th element by
x̄ik in the focal zone. To optimize the focal zone, we employ
deep reinforcement learning as the optimization framework for its
excellent performance in policy optimization [20].
Overview. As shown in Figure 2, the focal zone optimization
includes two key components: the environment (including state
transition and reward model), and the agent. Three elements
(the state s, the action a, and the reward r) are exchanged in
the interaction between the environment and the agent. In the
following we elaborate these three elements which are crucial to
our proposed deep reinforcement learning model:
•

The state S = {st , t = 0, 1, · · · , T } ∈ R2 describes
the position of the focal zone, where t denotes the time
stamp. In the training, s0 is initialized as s0 = [(K 0 −
K̄)/2, (K 0 + K̄)/2]. Since the focal zone is a shifting
fragment on 1-D x0i , we design two parameters to define
the state: st = {starttidx , endtidx }, where starttidx and

•

•

•

endtidx separately denote the start index and the end index
of the focal zone2 .
The action A = {at , t = 0, 1, · · · , T } ∈ R4 describes
which the agent could choose to act on the environment.
In our case, we define 4 categories of actions for the focal
zone (as described in the State Transition part in Figure 2): left shifting, right shifting, extend, and condense.
Here at time stamp t, the state transition only choose
one action to implement following the agent’s policy π :
st+1 = π(st , at ).
The reward R = {rt , t = 0, 1, · · · , T } ∈ R is calculated by the reward model, which will be detailed later.
The reward model Φ: rt = Φ(st ) receives the current
state and returns an evaluation as the reward.
We employ the Dueling DQN (Deep Q Networks [21])
as the optimization policy π(st , at ), which is enabled
to learn the state-value function efficiently. Dueling
DQN learns the Q value V (st ) and the advantage
function A(st , at ) and combines them: Q(st , at ) ←
V (st ), A(st , at ). The primary reason we employ a dueling DQN to optimize the focal zone is that it updates
all the four Q values at every step while other policy only
updates one Q value at each step.

Reward Model. Next, we introduce the design of the reward
model, which is one important contribution of this paper. The
purpose of the reward model is to evaluate how the current
state impacts our final target which refers to the classification
performance in our case. Intuitively, the state which can lead to
the better classification performance should have a higher reward:
rt = F(st ). As a result, in the standard reinforcement learning
framework, the original reward model regards the classification
accuracy as the reward. F refers to the WAS-LSTM. Note, WASLSTM focuses on the spatial dependency between different dimensions at the same time-point while the normal LSTM focuses
2. E.g., for a random x0i = [3, 5, 8, 9, 2, 1, 6, 0], the state {starttidx =
2, endtidx = 5} is sufficient to determine the focal zone as [8, 9, 2, 1].

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

on the temporal dependency between a sequence of samples
collected at different time-points. However, WAS-LSTM requires
considerable training time, which will dramatically increase the
optimization time of the whole algorithm. In this section, we
propose an alternative method to calculate the reward: construct a
new reward function rt = G(st ) which is positively related with
rt = F(st ). Therefore, we can employ G to replace F . Then,
the task is changed to construct a suitable G which can evaluate
the inter-dimension dependency in the current state st and feedback the corresponding reward rt . We propose an alternative G
composed by three components: the autoregressive model [22] to
exploit the inter-dimension dependency in x0i , the Silhouette Score
[23] to evaluate the similarity of the autoregressive coefficients,
and the reward function based on the silhouette score.
The autoregressive model [22] receives the focal zone x̄i and
specifies that how the last variable depends on its own previous
values. Then, to evaluate how rich information is taken in the
autoregressive coefficients, we employ silhouette score [24] sst to
interpret the consistence of ϕ. The silhouette score measures how
similar an object is to its own cluster compared to other clusters
and a high silhouette value indicates that the object is well matched
to its own cluster and poorly matched to neighboring clusters.
Specifically, in our case, the higher silhouette score means that ϕ
can be better clustered and the focal zone x̄i is be easier classified.
At last, based on the sst ∈ [−1, 1], we design a reward function:

esst +1
K̄
−β 0
e2 − 1
K
The function contains two parts, the first part is a normalized
exponential function with the exponent sst + 1 ∈ [0, 1], which
encourages the reinforcement learning algorithm to search the
better st w that leads to a higher sst . The motivation of the
exponential function is that: the reward growth rate is increasing
with the silhouette score’s increase3 . The second part is a penalty
factor for the focal zone length to keep the bar shorter and the β
is the penalty coefficient.
In summary, the aim of focal zone optimization is to learn the
optimal focal zone x̄∗i which can lead to the maximum reward.
The optimization totally iterates N = ne ∗ ns times where ne
and ns separately denote the number of episodes and steps [21].
ε-greedy method [25] is employed in the state transition.
rt =

2.4

Weighted Average Spatial LSTM Classifier

In this section, we propose Weighted Average Spatial LSTM
classification for two purposes. The first attempt is to capture
the cross-relationship among feature dimensions in the optimized
focal zone x̄∗i . The LSTM-based classifier is widely used for
its excellent sequential information extraction ability which is
approved in several research areas such as natural language processing [26]. Compared to other commonly employed spatial feature extraction methods, such as Convolutional Neural Networks,
LSTM less dependent on the hyper-parameters setting. However,
the traditional LSTM focuses on the temporal dependency among
a sequence of samples. Technically, the input data of traditional
LSTM is 3-D tensor shaped as [nb , nt , K̄] where nb and nt denote
the batch size and the number of temporal samples, separately.
In this paper, we transpose the input data as [nb , nt , K̄] →
[nb , K̄, nt ] following the equation (AT )ijk = Aikj , in which
3. For example, for the same silhouette score increment 0.1, sst : 0.9 → 1.0
can earn higher reward increment than sst : 0.1 → 0.2.

4

(a)

(b)

Fig. 3: EEG data collection: (a) collection scenario and (b) the
gathered EEG signal
TABLE 1: IMAGERY ACTION, LABEL, AND CORRESPONDING
COMMANDS IN CASE STUDIES
Imagery Action

Label

Typing Commands

Robot Commands

Upward
Downward
Leftward
Rightward
Middle Cycle
Eye-closed

0
1
2
3
4
5

Up
Cancel
Left
Right
Nothing
Confirm

Forward
Turn Left
Grasp
Loose
Nothing
Stop/Start

form, each sample has shape [K̄, nt ] and the WAS-LSTM pays
attention to each sample column and explores the latent dependencies between the various elements in the same column. WASLSTM aims to capture the dependency among various dimensions
at one temporal point, therefore, we set nt = 1.
The second advantage of WAS-LSTM is that it could stabilize
the performance of LSTM via moving average method. In LSTM,
each cell’s output contains the information before it, however,
the neural network’s convergence and stability are fluctuated
over different times of training. To enhance the convergence and
stability, we calculate the LSTM outputs Oi by averaging the
weighted past two outputs instead of only the final one (Figure 2):

Oi = w1 Oi(K̄−1) + w2 OiK̄
where w1 and w2 are the corresponding weights which can adjust
the importance proportion of Oi(K̄−1) and OiK̄ . The weights can
be automatically learned by the neural network [27] or be manually set. In this paper, we simply manually set w1 = w2 = 0.5
in order to save computing resources. The predicted label is
calculated by yi0 = L(x̄∗i ) where L denotes the LSTM algorithm.
`2 -norm (with parameter λ) is adopted as regularization to prevent
overfitting. The sigmoid activation function is used on hidden
layers. The loss function is cross-entropy and is optimized by the
AdamOptimizer algorithm.

3

E XPERIMENTS

In this section, we design local real-world experiments to evaluate the efficiency and effectiveness of the proposed framework.
First, the experimental setting is reported. Then, we compare our
model with competitive state-of-the-art baselines and evaluate the
performance in detail. Finally, we investigate the impact of crucial
factors such as the framework latency and the reward model.
3.1

Experimental Setting

We conduct the EEG collection by using a portable and easy-touse commercialized Emotiv Epoc+ headset. The headset contains

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

5

10 1

Testing time (s)

10 0

10 -1

10 -2

10 -3

(a)

SVM CNN RNN

(b)

RF

Hsu Tabar Martis ours

(c)

Fig. 4: Recognition results: (a) confusion matrix, (b) ROC curves with AUC scores, and (c) latency

14 channels and the sampling rate is 128 Hz. The local dataset
can be accessed from this link4 . This experiment is carried out
using 7 subjects (4 males and 3 females) aged from 23 to 26.
During the experiment, the subject wearing the Emotiv Epoc+5
EEG collection headset, faces the computer screen and focuses
on the corresponding hint which appears on the screen (shown
in Figure 3a). EEG signals are recorded when the subject is
imaging certain actions (without any physical action). The certain
actions contains: upward arrow, downward arrow, leftward arrow,
rightward arrow, and a cycle. Beyond that, the EEG signals that
the subject stays relaxation with eye closed are also recorded. In
total, there are 6 categories of EEG signals. The imagery action
associated with brain activities and the corresponding labels used
in this paper are listed in Table 1. In summary, this experiment
contains 241,920 samples with 34,560 samples for each subject.
For each participant, the dataset is divided into a training set and
a testing set. The training set contains 31,104 samples and the
testing set contains 3,456 samples. The classification results are
evaluated by a number of metrics including accuracy, precision,
recall, F-1 score, confusion matrix, ROC (Receiver Operating
Characteristic) curve, AUC (Area Under Curve) score.

TABLE 2: OVERALL COMPARISON WITH THE STATE-OF-THEART BASELINES. DL DENOTES DEEP LEARNING.
Baselines

Non-DL

DL
The stateof-the-art

•

•

3.2

Overall Comparison and Analysis

In the training stage, based on the tuning experience, the hyperparameters setting are listed as follows. In the selective attention
learning: the order of autoregressive is 3; K̄ = 128, the Dueling
DQN has 4 layers and the node number in each layer are: 2
(input layer), 32 (FCL), 4 (A(st , at )) + 1 (V (st )), 4 (output).
The decay parameter γ = 0.8, ne = ns = 50, N = 2, 500,
 = 0.2, learning rate= 0.01, memory size = 2000, length
penalty coefficient β = 0.1, and the minimum length of focal
zone is set as 10. In the deep learning classifier: the node number
in the input layer equals to the number of feature dimensions,
three hidden layers with 164 nodes, two layers of LSTM cells (164
cells) and one output layer (6 nodes). The learning rate = 0.001,
`2 -norm coefficient λ = 0.001, forget bias = 0.3, batch size = 9,
and iterate for 1000 iterations.
To demonstrate the efficiency of our approach, we compare
our model with several competitive state-of-the-art methods:
•

Hsu [28] extracts several potential features, including amplitude modulation, spectral power and asymmetry ratio,

4. https://drive.google.com/open?id=0B9MuJb6Xx2PIM0otakxuVHpkWkk
5. https://www.emotiv.com/product/emotiv-epoc-14-channel-mobile-eeg/

Methods
SVM
RF
KNN
AB
LDA
LSTM
GRU
CNN
[28]
[29]
[30]
WAS-LSTM
SAM+WAS-GRU
Ours

Acc
0.2569
0.8041
0.8539
0.2506
0.2595
0.2609
0.2521
0.725
0.8965
0.7894
0.8891
0.9026
0.9135
0.9363

Metrics
Pre
Rec
0.2737 0.2569
0.8071 0.8041
0.8563 0.8539
0.2039 0.2506
0.2761 0.2595
0.2447 0.2348
0.271
0.2696
0.724
0.7237
0.9011 0.8926
0.7938 0.8013
0.8932 0.8765
0.9125 0.9003
0.9188 0.9395
0.9394 0.9398

F1-score
0.2577
0.8048
0.8544
0.1557
0.2618
0.2354
0.2701
0.7238
0.8968
0.7975
0.8848
0.9064
0.9378
0.9396

adaptive autoregressive model, and wavelet fuzzy approximate entropy (wfApEn), followed by a SVM classifier, to
classify the binary motor imagery EEG signals.
Tabar et al. [29] combine convolutional neural networks
(CNN) and stacked Autoencoder (SAE) to automatically
classify EEG data.
Martis et al. [30] artificially extract several nonlinear
features on different EEG frequency bands (including
delta, theta, lower alpha, upper alpha, lower beta, upper
beta and lower gamma) and forward to SVM with radial
basis function kernel.

Table 2 shows the overall comparison between our approach
with non-DL baselines, DL baselines, and the state-of-the-art
models. RF denotes Random Forest, AdaB denotes Adaptive
Boosting, LDA denotes Linear Discriminant Analysis. In addition,
the key parameters of the baselines are listed here: Linear SVM
(C = 1), RF (n = 200), KNN (k = 3). In LSTM, nsteps = 5,
another set is the same as the WAS-LSTM classifier, along with
the GRU (Gated Recurrent Unit). The CNN contains 2 stacked
convolutional layers (both with stride [1, 1], patch [2, 2], zeropadding, and the depth are 4 and 8, separately.), one pooling layer
(stride [1, 2], zero-padding), and one fully connected layer (164
nodes). Relu activation function is employed in the CNN.
The observations in Table 2 show that our approach outperforms all the baselines by achieving the highest accuracy of
0.9363 on the 6-class classification. In addition, our model (SAM
+WAS-LSTM) performs better than the solo WAS-LSTM, which
demonstrates that the selective attention mechanism has a positive
contribution to the classification. The confusion matrix, ROC
curves, and AUC scores of the proposed framework are reported

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

6

10 4

0.98

T1
T2

0.96

Training Time (s)

Accuracy

0.94
0.92
0.9
0.88

10 3

10 2

two real-world cognitive IoT prototypes, namely, (1) a brain typing
system (2) mind-controlled assistive robot for the smart home.
4.1

Brain Typing System

0.86
0.3

0.32

0.34

0.36

0.38

0.4

0.42

10 1

1

2

3

4

5

6

7

8

State

Reward

Fig. 5: The relationship between the classifier accuracy
and the reward. The correlationship coefficient is 0.8258
while the p-value is 0.0115.

Fig. 6: Reward model training
time in various states. T1 and
T2 separately denote the training time in reward model G
and F .

in Figure 4. We can observe that the last class, representing the
eye-closed state, obtains the best performance compared to other
5 classes. This demonstrates that the eye-closed state is the easiest
to be recognized, which is reasonable while all the other classes
are in eye-open state and are easier to be interrupted by the
environmental factors. Moreover, through the results comparison
of SAM+WASGRU and our model (SAM+WASLSTM) (Table 2),
we can observe that the latter achieves higher performance which
indicates (0.9363 > 0.9135) the LSTM slightly outperforms GRU
in our scenarios. The reason can be inferred is that LSTM can
remember longer sequences than GRU.
3.3

Impact of Key Factor

3.3.1 Latency
To design effective and real-world cognitive interactive applications, both the accuracy and latency of intent recognition are
equally important. Subsequently, we compare the latency of the
proposed framework with several typical state-of-the-art algorithms and the results are presented in Figure 4c. It is observed
that our approach has competitive latency compared with other
methods. The overall latency is less than 1 second. The deep
learning based techniques in this work do not explicitly lead to
extra latency.
3.3.2 Reward Model
Furthermore, we conduct extensive experiments to demonstrate
the efficiency of the proposed reward model G . First, we measure
a batch of data pairs of the reward (represents the reward of G )
and the WAS-LSTM classifier accuracy (represents the reward
of F ). The relationship between the reward and the accuracy is
shown in Figure 5. The figure illustrates that the accuracy has an
approximately linear relationship with the reward. The correlations
coefficient is 0.8258 (with p-value as 0.0115), which shows that
the accuracy and reward are highly positive related. As a result,
we can estimate arg max F by arg max G . Moreover, another
x̄∗

x̄∗

experiment is carried out to measure the single step training time
of two reward models G and F . The training times are marked as
T1 and T2, respectively. Figure 6 qualitatively shows that T2 is
much higher than T1 (8 states represent 8 different focal zones).
Quantitatively, the sum of T1 over 8 states is 35, 237.41 seconds
while the sum of T2 is 601.58 seconds. These results demonstrate
that the proposed approach, designing a G to approximate and
estimate the F , saves 98.3% = 1 − 601.58/35237.41 training
time in focal zone optimization.

4

C ASE S TUDY

Inspired by the high accuracy and low latency of our proposed
framework for human intent recognition, we proceed to develop

Due to the high intent recognition accuracy, we develop an online
brain typing system to convert user’s thoughts to texts. The video
demo clip can be found at the given link6 . The brain typing
system (Figure 7a) consists of two components: the pre-trained
deep learning model and the online BCI system. The pre-trained
deep learning model, which is trained offline, aims to accurately
recognize the user’s typing intent in real time. The online system
contains 5 components: the EEG headset, the client 1 (data
collector), the server, the client 2 (typing command receiver), and
the typing interface. The user wears the Emotiv EPOC+ headset
which collects EEG signals and sends the data to client 1 through
a Bluetooth connection. The raw EEG signals are transported to
the server through a TCP connection.
Specifically, the typing interface (up right corner in Figure 7a)
can be divided into three levels: the initial interface, the subinterface, and the bottom interface. All the interfaces have similar
structure: three character blocks (separately distributed in left, up,
and down directions), a display block, and a cancel button. The
display block shows the typed output and the cancel button is used
to cancel the last operation. The typing system in total includes
27 = 3 ∗ 9 characters (26 English alphabets and the space bar)
and all of them are separated into 3 character blocks (each block
contains 9 characters) in the initial interface. Overall, there are
3 alternative selections and each selection will lead to a specific
sub-interface which contains 9 characters. Again, the 9 = 3 ∗ 3
characters are divided into 3 character blocks and each of them
is connected to a bottom interface. In the bottom interface, each
block represents only one character.
In the brain typing system, there are 5 commands to control
the interface: ‘left’, ‘up’, ‘right’, ‘cancel’, and ‘confirm’. Each
command corresponds to a specific motor imagery EEG category
(as shown in Table 1). Since the user can hardly concentrate for
a long time (usually, less than 10 seconds), the brain activity may
represent none of the valid commands sometimes. Nevertheless,
the proposed deep learning framework cannot distinguish the
invalid brain activity, we leave one specific brain category to
represent the invalid signal. If the individual’s brain signal is not in
any of the 5 valid categories, it is classified as the invalid category
and the brain typing system will do nothing under this situation7 .
Moreover, based on the experiments results in Section 3.2, the
eye-closed state has the highest precision and accuracy, therefore,
we select this state as the confirmation command for the reason
that ‘confirmation’ is the most crucial command in typing system.
To type every single character, the interface is supposed to accept
6 commands. Consider typing the letter ‘I’ as an example. The
sequence of commands to be entered is as follows: ‘left’ (choose
the left block with characters A ∼ I ), ‘confirm’, ‘right’ (choose
the right block with characters G ∼ I ), ‘confirm’, ‘right’ (choose
the right block with characters I ), ‘confirm’.
In our practical deployment, the sampling rate of Emotiv
EPOC+ headset is set as 128Hz, which means the server can
receive 128 EEG recordings each second. Since the brainwave
signal varies rapidly and is very easy to be affected by noises,
6. https://youtu.be/Dc0StUPq61k
7. Similarly, in the cognitive robot case, the robot will remain the previous
state under the invalid command.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

7

User intent

DL framework

EEG

Client 2

Deep Learning
Model

Server

Client 1

Typing
Interface

Data
base

Object with RFID tag

Sensor hive

WLAN

Desired Object

Robot

Cognitive robot

Intent

Starting point

(a)

Navigation path

Terminal point

(b)

Fig. 7: Human-thing cognitive applications: (a) brain typing system and (b) cognitive robot in IoT scenario

the EEG data stream is sent to server every half second, which
means that the server receives 64 EEG samples each time. The
64 EEG samples are classified by the deep learning framework
and generate 64 categories of intents. we calculate the mode
of 64 intents and regard the mode as the final intent decision.
Furthermore, to achieve steadiness and reliability, the server sends
the command to client 2 only if three consecutive decisions remain
consistent. After the command is sent, the command list will
be reset and the system will wait until the next three consistent
decisions are made.
4.2

Cognitive Robot

Another important application for BCI-inspired Internet of Things
is extending the orientation of smart homes by integrating the
subject’s intent and the real-world IoT objects to effectively
control things of interest (TOIs).
To demonstrate the feasibility of the proposed framework, we
report the second use case as implementing cognitive interactivity
in an IoT-based smart home system. The IoT-based smart home
is equipped with sensors, wherein IR sensors, ambient sound,
heat, as well as contact sensors are mounted on furniture and
used in the home environment in a non-intrusive manner. In our
case, within the smart home environment which is perceived by
the embedded sensor-networks, a simulated robot is cognitively
navigated to perform a routine task. In the specific scenario, the
robot, learns user’s intent from EEG recordings via the proposed
framework, to take the IoT object (e.g., a can of beverage) from
a table in the kitchen and put it in a table in the living room.
The desired object is aggregate with RFID tag which helps to
identify the location. The IoT scenario is depicted in Figure 7b
and the demo can be found at here8 . The user’s intent is carried
in the EEG recordings which are forwarded to the deep learning
based framework for interpretation. The recognized intent is send
to sensor hive through WLAN to navigate the robot to get the
desired object. Starting from the table near the kitchen, the PR2
robot receives action commands (as shown in Table 1) and walks
forward until the specific position with the auxiliary of RFID tag.
Then, the robot grasps the object, turns back and walks along the
path to the table in living room and unlooses hands to put the
beverage on the table. The simulation result shows that the robot
can 100% precisely grasp and unloose object according to the
path planned in the subject’s mind. The simulation platform is in
8. https://youtu.be/VZYX1095Vkc

Gazebo toolbox and the robot controlling program is powered by
Robot Operating System (ROS). This case randomly selects some
EEG raw data from Subject 1 dataset as simulation inputs.

5

D ISCUSSION

Here we present several open challenges: 1) the experiment only
contains 7 subjects limited by the practical conditions, a larger
and more diverse dataset is necessary to illustrate the effects of
the proposed model; 2) the SAM component with focal zone is
designed to automatically explore the latent dimension sequence
of the input EEG data, nevertheless, the employment of SAM
increases the training time resulted from more iterations of the
LSTM cell; 3) most importantly, the RS stage shuffles the order
and replicate the number of input dimensions to discover the
optimal order in order to the best performance, but the optimal
order can not be guaranteed to appear after the RS, thus try more
times if the classification result is unsatisfactory; 4) the WASLSTM exploits the spatial information among EEG channels, thus
a number of channels are required to provide enough information.

6

C ONCLUSION

We propose a unified deep learning framework to bridge BrainComputer Interface and Internet of Things in order to enable
cognitive interactivity. We propose WAS-LSTM to extract interdimension dependency among the input signal of the human brain
activities which are selected by the selective attention mechanism.
We conduct real-world experiments to evaluate the proposed
framework and the results demonstrate that our model outperforms
the state-of-the-art baselines. Furthermore, our experience in developing two case studies, namely the brain typing system and
the cognitive robot, are reported in the paper. These case studies
validate the feasibility of the proposed framework.

R EFERENCES
[1]
[2]
[3]
[4]

L. Yao, Q. Z. Sheng, and S. Dustdar, “Web-based management of the
internet of things,” IEEE Internet Computing, vol. 19, no. 4, pp. 60–67,
2015.
A. Vallabhaneni, T. Wang, and B. He, “Brain—computer interface,” in
Neural engineering. Springer, 2005, pp. 85–121.
A. Teles, M. Cagy, F. Silva, M. Endler, V. Bastos, and S. Teixeira, “Using
brain-computer interface and internet of things to improve healthcare for
wheelchair users.”
B. Jagadish, M. Kiran, and P. Rajalakshmi, “A novel system architecture
for brain controlled iot enabled environments,” in e-Health Networking,
Applications and Services (Healthcom), 2017 IEEE 19th International
Conference on. IEEE, 2017, pp. 1–5.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]
[13]

[14]

[15]

[16]

[17]

[18]

[19]
[20]

[21]

[22]
[23]

[24]

[25]

[26]

[27]

[28]

X. Zhang, L. Yao, Q. Z. Sheng, S. S. Kanhere, T. Gu, and D. Zhang,
“Converting your thoughts to texts: Enabling brain typing via deep
feature learning of eeg signals,” in PerCom 2018.
B. Nguyen, D. Nguyen, W. Ma, and D. Tran, “Investigating the possibility
of applying eeg lossy compression to eeg-based user authentication,” in
IJCNN 2017. IEEE, 2017, pp. 79–85.
T. Nakamura, V. Goverdovsky, and D. P. Mandic, “In-ear eeg biometrics
for feasible and readily collectable real-world person authentication,”
IEEE Transactions on Information Forensics and Security, vol. 13, no. 3,
pp. 648–661, 2018.
M. A. Rahman and M. Ahmad, “Evaluating the connectivity of motor
area with prefrontal cortex by fnir spectroscopy,” in ECCE. IEEE,
2017, pp. 296–300.
M. Iijima and N. Nishitani, “Cortical dynamics during simple calculation
processes: a magnetoencephalography study,” Clinical Neurophysiology
Practice, vol. 2, pp. 54–61, 2017.
M. A. Rahman and M. Ahmad, “A straight forward signal processing
scheme to improve effect size of fnir signals,” in ICIEV. IEEE, 2016,
pp. 439–444.
E. Haselsteiner and G. Pfurtscheller, “Using time-dependent neural
networks for eeg classification,” IEEE transactions on rehabilitation
engineering, vol. 8, no. 4, pp. 457–463, 2000.
Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, vol. 521,
no. 7553, p. 436, 2015.
M. Angelidou, “Smart city planning and development shortcomings,”
Tema. Journal of Land Use, Mobility and Environment, vol. 10, no. 1,
pp. 77–94, 2017.
K. Dhariwal and A. Mehta, “Architecture and plan of smart hospital
based on internet of things (iot),” Int. Res. J. Eng. Technol, vol. 4, no. 4,
pp. 1976–1980, 2017.
X. Zhang, L. Yao, C. Huang, S. Wang, M. Tan, G. Long, and C. Wang,
“Multi-modality sensor data classification with selective attention,” IJCAI, 2018.
A. Al-Ali, I. A. Zualkernan, M. Rashid, R. Gupta, and M. Alikarar, “A
smart home energy management system using iot and big data analytics
approach,” IEEE Transactions on Consumer Electronics, vol. 63, no. 4,
pp. 426–434, 2017.
L. Yao, Q. Z. Sheng, B. Benatallah, S. Dustdar, X. Wang, A. Shemshadi,
and S. S. Kanhere, “Wits: an iot-endowed computational framework for
activity recognition in personalized smart homes,” Computing, pp. 1–17,
2018.
X. Zhang, L. Yao, C. Huang, Q. Z. Sheng, and X. Wang, “Intent
recognition in smart living through deep recurrent neural networks,” in
International Conference on Neural Information Processing. Springer,
2017, pp. 748–758.
P. Cavanagh et al., “Attention-based motion perception,” Science, vol.
257, no. 5076, pp. 1563–1565, 1992.
V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.
Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski et al.,
“Human-level control through deep reinforcement learning,” Nature, vol.
518, no. 7540, p. 529, 2015.
Z. Wang, T. Schaul, M. Hessel, H. Van Hasselt, M. Lanctot, and
N. De Freitas, “Dueling network architectures for deep reinforcement
learning,” arXiv preprint arXiv:1511.06581, 2015.
H. Akaike, “Fitting autoregressive models for prediction,” Annals of the
institute of Statistical Mathematics, vol. 21, no. 1, pp. 243–247, 1969.
A. Laurentini, “The visual hull concept for silhouette-based image
understanding,” IEEE Transactions on pattern analysis and machine
intelligence, vol. 16, no. 2, pp. 150–162, 1994.
L. Lovmar, A. Ahlford, M. Jonsson, and A.-C. Syvänen, “Silhouette
scores for assessment of snp genotype clusters,” BMC genomics, vol. 6,
no. 1, p. 35, 2005.
M. Tokic, “Adaptive ε-greedy exploration in reinforcement learning
based on value differences,” in Annual Conference on Artificial Intelligence. Springer, 2010, pp. 203–210.
F. A. Gers and E. Schmidhuber, “Lstm recurrent networks learn simple
context-free and context-sensitive languages,” IEEE Transactions on
Neural Networks, vol. 12, no. 6, pp. 1333–1340, 2001.
X. Zhang, L. Yao, S. S. Kanhere, Y. Liu, T. Gu, and K. Chen, “Mindid:
Person identification from brain waves through attention-based recurrent
neural network,” ACM Conference on Pervasive and Ubiquitous Computing (UbiComp), 2018.
W.-Y. Hsu, “Assembling a multi-feature eeg classifier for left–right
motor imagery data using wavelet-based fuzzy approximate entropy for
improved accuracy,” IJNS, vol. 25, no. 08, p. 1550037, 2015.

8

[29] Y. R. Tabar and U. Halici, “A novel deep learning approach for classification of eeg motor imagery signals,” Journal of neural engineering,
vol. 14, no. 1, p. 016003, 2016.
[30] R. J. Martis, J. H. Tan, C. K. Chua, T. C. Loon, S. W. J. YEO,
and L. Tong, “Epileptic eeg classification using nonlinear parameters
on different frequency bands,” Journal of Mechanics in Medicine and
Biology, vol. 15, no. 03, p. 1550040, 2015.
Xiang Zhang is currently a Ph.D. student (since
2016) at School of Computer Science and
Engineering, University of New South Wales
(UNSW). He received the Master degree (in
2016) from Harbin Institute of Technology (HIT),
China. His research interests mainly in Deep
learning, Brain-Computer Interface (BCI), Internet of Things (IoT), and Human Activity Recognition.
Lina Yao received the PhD degree in computer
science from the University of Adelaide, Australia. She is currently a lecturer in the School
of Computer Science and Engineering, UNSW.
Her research interests lie in machine learning
and data mining with applications to the Internet
of Things, Brain-Computer Interface (BCI), information filtering and recommending, and human
activity recognition. She is a member of the IEEE
and the ACM.
Shuai Zhang is a PhD student at the School of
Computer Science and Engineering, University
of New South Wales , as well as at Data61,
CSIRO. He received a Bachelor degree from
the School of Information Management, Nanjing
University. His major research interests lie in the
field of recommender systems, deep learning
and internet of things. He is a student member
of the IEEE and ACM.
Salil Kanhere received his Ph.D. from Drexel
University. He is an associate professor in the
School of Computer Science and Engineering
at UNSW. His research interests include the
Internet of Things, pervasive computing, crowd
sourcing, sensor networks, and security. He has
published 170 peer-reviewed articles and delivered over 20 tutorials and keynote talks. He is a
Senior Member of ACM. He is a recipient of the
Humboldt Research Fellowship.
Michael Sheng is a full Professor and Head of
Department of Computing at Macquarie University. Before moving to Macquarie, Michael spent
10 years at School of Computer Science, the
University of Adelaide (UoA). Michael holds a
PhD degree in computer science from the University of New South Wales (UNSW) and did his
post-doc as a research scientist at CSIRO ICT
Centre. From 1999 to 2001, Sheng also worked
at UNSW as a visiting research fellow.
Yunhao Liu received his BS degree in Automation Department from Tsinghua University, and
an MA degree in Beijing Foreign Studies University, China. He received an MS and a Ph.D.
degree in Computer Science and Engineering at
Michigan State University, USA. Yunhao is now
MSU Foundation Professor and Chairperson of
Department of Computer Science and Engineering, Michigan State University, and holds Chang
Jiang Chair Professorship (No Pay Leave) at
Tsinghua University.

