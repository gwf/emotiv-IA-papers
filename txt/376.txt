Inge Cuc, vol. 11 no. 2, pp 74-83, July - December, 2015

Control of a Mobile Robot Through
Brain Computer Interface*
Control de Móvil Robótico Mediante
Interfaz Cerebro Computador
DOI: http://dx.doi.org/10.17981/ingecuc.11.2.2015.08
Research article - Reception Date: January 30, 2015 - Acceptance Date: September 16, 2015

Robinson Jiménez Moreno

Master in Industrial Automation. GAV Group, Universidad Militar Nueva Granada – UMNG.
Bogotá (Colombia). robinson.jimenez@unimilitar.edu.co

Jorge Rodríguez Alemán

Student of Mechatronics Engineering. GAV Group, Universidad Militar Nueva Granada – UMNG.
Bogotá (Colombia). roboticanaval@hotmail.com
To reference this paper:
R. Jiménez Moreno and J. Rodríguez Alemán., “Control of a Mobile Robot Through Brain Computer Interface,”
INGE CUC, vol. 11, no. 2, pp. 74-83, 2015. DOI: http://dx.doi.org/10.17981/ingecuc.11.2.2015.08

Abstract— This paper poses a control interface to command the movement of a mobile robot according to signals captured from the user’s brain. These signals are
acquired and interpreted by Emotiv EPOC device, a
14-electrode type sensor which captures electroencephalographic (EEG) signals with high resolution, which,
in turn, are sent to a computer for processing. One
brain-computer interface (BCI) was developed based on
the Emotiv software and SDK in order to command the
mobile robot from a distance. Functionality tests are
performed with the sensor to discriminate shift intentions of a user group, as well as with a fuzzy controller to
hold the direction in case of concentration loss. As conclusion, it was possible to obtain an efficient system for
robot movements.
Keywords— Brain Computer Interface -BCI, Emotiv
Epoc, Mobile Robot, Arduino, EEG.

Resumen— En este artículo se presenta una interfaz de
control que permite comandar el movimiento de un robot
móvil en función de la captura de señales provenientes del
cerebro del usuario. Dichas señales son adquiridas e interpretadas por medio del dispositivo Emotiv Epoc, el cual
cuenta con 14 sensores tipo electrodo que captan señales
electroencefalográficas (EEG) de alta resolución, que después son enviadas a un equipo de cómputo para ser procesadas. Se desarrolla una interfaz cerebro-computador
(BCI) basada en el software y SDK del desarrollador del
Emotiv mediante la cual se comanda de forma remota el
robot móvil. Se realizan pruebas de funcionalidad con el
sensor para discriminar una intención de desplazamiento
por parte de un grupo de usuarios y un controlador difuso
para sostener la dirección en casos de perdida de la concentración. Como conclusión, se logra obtener un sistema
eficiente para la manipulación del robot.
Palabras clave— Interfaz Cerebro Computador, Emotiv
Epoc, Robot Móvil, Arduino, EEG.

Research article derived from the research project: “Control de un móvil robótico mediante señales de EEG”. Funded by the Vicerectorate of Research of the Universidad Militar Nueva Granada. Starting date: July, 2014. Compleition date: December, 2014.

*

74

©
The author; licensed Universidad de la Costa - CUC.
INGE CUC vol. 11 no.2, pp. 74-83. July - December, 2015 Barranquilla. ISSN 0122-6517 Printed, ISSN 2382-4700 Online
DOI: http://dx.doi.org/10.17981/ingecuc.11.2.2015.08

Inge Cuc, vol. 11 no. 2, pp 74-83, July - December, 2015

I. Introduction
Human interaction with its environment is determined by the perception people have of their surroundings; in turn, this perception is defined by the
sensory experience abstracted through the senses.
This abstraction takes place in the brain, and it is
here where the signals that will allow any action
are produced. By means of the current technology
available, one way to interact with the environment
is through Brain-Computer Interfaces (BCI). This
type of interface offers a more natural manner of
controlling mechatronic prostheses, for instance. A
BCI is based on the neuronal activity from the brain; this is captured through a series of sensors and
processed by a computer later with the objective of
generating a stimulus or control action over a physical and distant device [1].
Many are the developments regarding BCI. An
analysis of the algorithms required between the
EEG signal capture and the establishment of useful
data for a BCI is explored in [2], where the large
amount of evidence allows focusing on applications
based on these algorithms. In [3], a review of the
feasible applications for BCI use is carried through;
among these fields are control and communication,
entertainment, and motor substitution and recovery
control systems.
Amidst the applications found in the literature
review, some novelties as the one presented in [4],
where a BCI aimed at teaching tasks to a humanoid
robot regarding object manipulation (e.g. according
to visual characteristics as color) are put forward.
In [5], an application to manipulate an avatar in
a virtual environment using a BCI is posed. More
specialized applications are used as control support
for people’s movements [6]. In this case, a portable
exoskeleton was created; it used commands received by the EEG sensor Emotiv EPOC, which is an
EEG signal capture device, and created a BCI that
provided the instructions for the exoskeleton’s movements.
The Emotiv EPOC has been used in numerous
applications involving BCI, among them [7], [8],
[9], [10], [11], and [12] stand out. This peripheral’s
potential distinguishes EEG signals by capturing
them through 14 electrode sensors that allow the
identification of different intentions from a user’s
thoughts.
This paper expounds the use of this sensor for a
BCI application that seeks to control the direction
in the displacement of a mobile robot: forward, backward, left, and right movement in agreement with
the user’s thoughts. A fuzzy controller is added to
ease abrupt actions from the mobile’s engines when
the movement intention is lost or confusing.
This work constitutes the progress of a research
carried out by the group regarding the inclusion
of mechatronic systems in medicine, where robotic
agents have started to be included for teleoperation

[13] and some manners to achieve a more natural
control of them are being explored. In this sense,
BCI improvements are perceived as tools for a natural handling between the user and a mechatronic
system.
The paper is divided into five sections: section
II explains the development of the BCI for signal
acquisition through Emotiv Epoc; section III describes how the previous data is used to control the
mobile robot, as well as the techniques applied provided the movement’s control signal is lost; section
IV sets forth the results obtained from the movement trials of the mobile using the BCI; and finally,
conclusions are posed in section V.
II. Methods and M aterials
This section introduces the materials used for the
development of this BCI. These are: the Emotiv
Epoc headset, the software of the development, the
communication system, and the mobile robot.
The Emotiv Epoc is a multi-sensorial headset
with 14 electrodes and two references. It receives
the EEG signals from the user’s brain. In the beginning, Emotiv Epoc was launched as an innovative control system for videogame interaction. Fig. 1
shows the Emotiv Epoc, and its main characteristics
are explained in [14].

Fig. 1. Emotiv Epoc Headset.
Source: Author.

The human brain emits waves with certain patterns as a result of external stimuli or mental states; amongst the main waves produced the following
stand out: alpha, beta, theta, gamma, and delta.
Alpha waves range between the 8 and 12 Hz and
they are related to imaginative, creative, and meditative states. Beta waves, 12 to 30 Hz, involve
concentration, stress, or excitement states. Theta
waves, between the 4 and 7 Hz, are present during
relaxation and deep meditation. Delta waves, 0.5 to
4 Hz, represent the deep stage of sleep; and gamma waves, 25 to 100 Hz, are present during high
level information processing states. The operation of
Emotiv Epoc is based on the recognition and translation of such brain waves.

75

Control of a Mobile Robot Through Brain Computer Interface

Regarding the software, it can be divided into
three parts: the EmoComposer, the Cognitiv Detection Suite, and the Visual Studio. Emotive developer provides an SDK (Software Development Kit)
for Windows with a software called EmoComposer,
which depending on the signals received from the
sensor allows determining the state of each electrode and interpreting the information generated by
the user as of the brain waves; these are received
as numeric values corresponding to the different intentions of the user. The application’s environment
is observed in Fig. 2, where the main development
features are illustrated and a learning training can
be generated for different kinds of users.
Another Emotiv environment is the Cognitiv Detection Suite. This software permits the assessment
of the brain waves information in real time with the

purpose of differentiating every attempt for completing an action on a real or virtual object. Once the
system is trained in these matters, the pertinent
signals are received to be characterized as direction
commands for the mobile’s intended movement.
For the integration of the BCI and the controlled
hardware, an application was developed on Visual
Studio (Fig. 3) where an algorithm was programed
to, first, capture the EmoComposer’s information,
and then, process and send it in a serial manner to
the communications module of the mobile command
in accordance with the user’s intentions to guide the
mobile.
Fig. 4 shows the EmoComposer’s output string
generated by simulating a cognitive intention of the
user, in this case, a forward move.

Fig. 2. EmoComposer Environment.
Source: Author.

Fig. 3. Visual Studio Environment for Serial Transmission.
Source: Author.

76

Inge Cuc, vol. 11 no. 2, pp 74-83, July - December, 2015

Fig. 4. Forward Action Simulation through EmoComposer.
Source: Author.

A RS232 protocol system entitles communication
between the BCI and the mobile robot. In this system the brain signals values that correspond to the
respective displacement directions of the mobile are
delivered through an 8-bit frame to an XBee Pro series1 radiofrequency module, which in turn, operates with an IEEE 802.15.4 standard. XBee has a
transmission power of 60mW, a receiver sensitivity
of -100 dBm, and a range of 1 km in open spaces.
Two devices are used, the transmitter and the receiver, in a simplex communication where only the BCI
sends information to the mobile.
The mobile device moves thanks to two DC engines attached to each wheel, thus, this mobile has
a differential configuration with a central rotating
wheel which can move freely. This can be appreciated in Fig. 5.

The mobile’s control system is based on a microcontrolled Arduino MEGA 2560 board with the following features:
• Microcontroller ATmega328
• Operating voltage of 5V
• Digital 14-pin I/O (6 may provide PWM output)
• 6 pins for analog input
• 40 mA DC current per I/O pin
• Flash Memory 32 KB
• 1 UART port
• 1 KB EEPROM memory (ATmega328)
• 16 MHz Clock Speed
This board’s low cost and small size were important selection factors. Additionally, this board fulfills the project’s needs since it provides two PWM
channels, one for each engine, and a serial port to
receive direction control signals.
III. Movement Control
In order to establish the mobile’s movements, Emo
Control Panel was adopted so as to define the corresponding levels for the actions executed by the
user when guiding the robot. The system was represented through a virtual cube that moves forward,
backwards, to the left, and to the right, in accordance with the manipulation possibilities of the mobile
robot. The different values for the discrimination of
each action are represented in Table I.

Fig. 5. Mobile Robot.
Source: Author.

Table I. Decision T hresholds for Direction

As the mobile robot has a differential configuration, (1) presents the kinematic model that describes
this functioning [15].

(1)
		

ACTION

VALUE

FORWARD

2

BACKWARD

4

LEFT

32

RIGHT

64
Source: Author.

77

Control of a Mobile Robot Through Brain Computer Interface

Fig.6 shows the result of thinking about a
forward movement in terms of the virtual cube visualiztion (left); the EEG information panel and
the sensor distribution are also displayed (right).
For the forward movement intention, the activation
signals correspond to the AF3, F7, F8, and AF4
sensors.
Likewise, Fig. 7 illustrates the backward movement of the cube, for this reason, the orange facet of
the cube covers the entire animation screen. Emotiv sensors evidence the highest amplitude response in AF4, a high peak when compared to F8, F4,

FC6, T8, T7, F3, and F7 sensors, which in turn, present a significant amplitude variation regarding the
remaining sensors.
Fig. 8 exemplifies the behavior for a left movement
intention. An important and uniform variation in
all the sensors is observed, however, a difference in
the timing is manifested; sensors AF4, F4, FC6, and
T8 respond sooner than the rest.
For a right turn, shown in Fig. 9, higher response
values are appreciated in sensors AF4, F8, F4, FC6,
T8, and F8; the amplitudes in this case are rather
low if compared to the previous actions.

Fig. 6. Forward Movement.
Source: Author.

Fig. 7. Backward Movement.
Source: Author.

78

Inge Cuc, vol. 11 no. 2, pp 74-83, July - December, 2015

Fig. 8. Left Movement.
Source: Author.

Fig. 9. Right Movement.
Source: Author.

Fig. 10. Surface View.
Source: Author.

79

Control of a Mobile Robot Through Brain Computer Interface

Since movement, derived from a user’s thought,
requires concentration in order to be recognized and
a suitable intensity of the signals captured by the
electrodes, sometimes there might be a lack of signal reception or confusion in the intention of movement. To reduce these obstacles, a fuzzy supervision
system is implemented to check on signal presence,
if the signal requires enduring or changing, or if on
the contrary, there is signal absence. For this, the
control surface shown in Fig. 10 is applied.
The basis of rules regulating this surface are illustrated in Fig. 11 and they are related to the duration
of time in which the control signal is being received (or
not) and the type of signal. The domain of discourse
for input and output has three functions: for time, the
linguistic tags are little, medium, and much; for signal, no signal, hold, and change; and for output, stop,
continue, change.

IV. Results
To validate the effectiveness of the implemented
interface, the direction control is tested initially
for each of the characterizations attained. Fig. 12
to Fig. 15 show the testing process for each threshold found in the BCI training, hence, allowing a
forward (Fig. 12), left (Fig. 13), backward (Fig. 14),
and right (Fig. 15) movements.
Concerning the mobile’s manageability, the discrimination ability for the desired movements is assessed. For this, a 10-repetition exercise is carried
through for each movement and five users. Results
are presented in Table II.
Table Ii. Repetition T est for Bci Users
RIGHT

LEFT

FORWARD

BACKWARD

USER 1

9

8

9

7

USER 2

8

7

9

8

USER 3

7

8

8

7

USER 4

8

8

9

9

USER 5

9

9

8

9

AVERAGE

8.2

8

8.6

8

Source: Author

Fig. 11. Basis of Rules.
Source: Author.

The basis of rules implementation for the fuzzy
controller is included within the microcontrol system by
using Mamdani’s inference algorithm, as indicated in
[16].

As it can be observed, average values evidence an
80% of success rate in user’s intention identification.
For a constant right movement and a sudden signal
lost, the controller holds the current course.
Once witnessed that the BCI allowed guiding the
mobile in accordance with the user’s intention, a
test route was outlined to assess its performance in
the face of different kinds of users (Fig. 16).

Fig. 12. Forward Movement.
Source: Author.

80

Inge Cuc, vol. 11 no. 2, pp 74-83, July - December, 2015

Fig. 13. Left Movement.
Source: Author.

Fig. 14. Backward Movement.
Source: Author.

Fig. 15. Right Movement.
Source: Author.

81

Control of a Mobile Robot Through Brain Computer Interface

A future pragmatic application for this interface
can be oriented for wheelchair control by disabled
people.
References
[1]

[2]

[3]

Fig. 16. Test Route.
Source: Author.

Time and deviation percentage was measured
for the five users (Table III). The highest precisions
(accurately following the established route) are related to higher time values due to concentration and
response requirements from the user. However, the
user with the least time value (30 s) was able to finish the route with a good precision level.

[4]

[5]

Table Iii. User’s Bci Response
User

1

2

3

4

5

Time (seg)

35

43

30

35

46

Precision (%)

90

90

84

91

94

[6]

Source: Author.

Control signals received through Cognitiv Detection Suite software do not vary significantly among
users; this means, users activate the same regions,
but concentration levels produce activation threshold variations, thus, deriving in a different control
action for each user.
V. Conclusions
An Emotive Epoc-based BCI was implemented
to control the movements of a mobile robot using
thoughts. This sensor demonstrated its effectiveness for the command of mechatronic systems.
A fuzzy interface system avoided random shifts
of the mobile provided the original intention was
not identified; likewise, it allowed gradual direction
changes for a more accurate control of the movements.
There were not significant variations in BCI use
among users, although a different control level in
each user was observed. This difference is linked to
shape variations in the brain waves between users.
However, this did not affect the thresholds established during the training process for each direction
shift; hence, route completion was accomplished by
every user.

82

[7]

[8]

[9]

[10]

[11]

[12]

B. He, S. Gao, H. Yuan, and J. R. Wolpaw, “Brain–Computer Interfaces,” in Neural Engineering, 2nd ed., New
York: Springer, 2013, pp. 87–151.DOI: 10.1007/978-14614-5227-0_2
F. Lotte, M. Congedo, A. Lécuyer, F. Lamarche, and B.
Arnaldi, “A review of classification algorithms for EEGbased brain-computer interfaces.,” J. Neural Eng., vol.
4, no. 2, pp. R1–R13, Jun. 2007. DOI: 10.1088/17412560/4/2/R01
J. D. R. Millán, R. Rupp, G. R. Müller-Putz, R. MurraySmith, C. Giugliemma, M. Tangermann, C. Vidaurre, F.
Cincotti, A. Kübler, R. Leeb, C. Neuper, K.-R. Müller, and
D. Mattia, “Combining Brain-Computer Interfaces and
Assistive Technologies: State-of-the-Art and Challenges.,” Front. Neurosci., vol. 4, Jan. 2010. DOI: 10.3389/
fnins.2010.00161
C. I. Penaloza, Y. Mae, M. Kojima, and T. Arai, “BMI-based framework for teaching and evaluating robot skills,”
in 2014 IEEE International Conference on Robotics and
Automation (ICRA), 2014, pp. 6040–6046. DOI: 10.1109/
ICRA.2014.6907749
B. B. Longo, A. B. Benevides, J. Castillo, and T. BastosFilho, “Using Brain-Computer Interface to control an
avatar in a Virtual Reality Environment,” in 5th ISSNIPIEEE Biosignals and Biorobotics Conference (2014): Biosignals and Robotics for Better and Safer Living (BRC),
2014, pp. 1–4. DOI: 10.1109/BRC.2014.6880960
J. Webb, Z. G. Xiao, K. P. Aschenbrenner, G. Herrnstadt,
and C. Menon, “Towards a portable assistive arm exoskeleton for stroke patient rehabilitation controlled through
a brain computer interface,” in 2012 4th IEEE RAS &
EMBS International Conference on Biomedical Robotics
and Biomechatronics (BioRob), 2012, pp. 1299–1304.
DOI: 10.1109/BioRob.2012.6290674
M. Perakakis and A. Potamianos, “Affective evaluation
of a mobile multimodal dialogue system using brain
signals,” in 2012 IEEE Spoken Language Technology Workshop (SLT), 2012, pp. 43–48. DOI: 10.1109/
SLT.2012.6424195
E. J. Rechy-Ramirez, H. Hu, and K. McDonald-Maier,
“Head movements based control of an intelligent wheelchair in an indoor environment,” in 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO),
2012, pp. 1464–1469. DOI:10.1109/ROBIO.2012.6491175
A. G. Risangtuni and A. Widyotriatmo, “Towards online
application of wireless EEG-based open platform Brain
Computer Interface,” in 2012 IEEE Conference on Control, Systems & Industrial Informatics, 2012, pp. 141–
144. DOI: 10.1109/CCSII.2012.6470489
Y. Liu, X. Jiang, T. Cao, F. Wan, P. U. Mak, P.-I. Mak,
and M. I. Vai, “Implementation of SSVEP based BCI with
Emotiv EPOC,” in 2012 IEEE International Conference
on Virtual Environments Human-Computer Interfaces
and Measurement Systems (VECIMS) Proceedings,
2012, pp. 34–37. DOI: 10.1109/VECIMS.2012.6273184.
N. Chumerin, N. V. Manyakov, M. van Vliet, A. Robben,
A. Combaz, and M. Van Hulle, “Steady-State Visual
Evoked Potential-Based Computer Gaming on a Consumer-Grade EEG Device,” IEEE Trans. Comput. Intell.
AI Games, vol. 5, no. 2, pp. 100–110, Jun. 2013. DOI:
10.1109/TCIAIG.2012.2225623
N. S. M. Puzi, R. Jailani, H. Norhazman, and N. M. Zaini, “Alpha and Beta brainwave characteristics to binaural beat treatment,” in 2013 IEEE 9th International Colloquium on Signal Processing and its Applications, 2013,
pp. 344–348. DOI: 10.1109/CSPA.2013.6530069

Inge Cuc, vol. 11 no. 2, pp 74-83, July - December, 2015

[13]

[14]

R. J. Moreno, F. E. Valcárcel, and D. A. Hurtado, “Teleoperated systems: a perspective on telesurgery applications
(Sistemas teleoperados: una perspectiva desde las aplicaciones en telecirugía/ Sistemas de teleoperação: uma perspectiva sobre aplicações telecirurgia),” Revista Ingeniería
Biomédica, vol. 7, no. 14. 14-Jan-2014.
Emotiv Epoc & testbench™ specifications, Emotiv, 2014.
Emotiv Software Development Kit User Manual for Release, Ed . 1.0.0.5.

[15]
[16]

L. Ríos and M. Bueno, “Modelo matemático para un
robot móvil,” Sci. Tech., vol. 1, no. 38, pp. 13–18, Jun.
2008.
R. J. Moreno, O. A. Sánchez, and O. L. R. Sandoval,
“Análisis de la implementación de un controlador difuso
sobre diferentes arquitecturas de hardware.,” Ciencia e
Ingeniería Neogranadina, vol. 23, no. 1. pp. 77–87, 06Jun-2013.

83

