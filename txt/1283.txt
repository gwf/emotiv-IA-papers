XII SIMP√ìSIO DE ENGENHARIA BIOM√âDICA - IX SIMP√ìSIO DE INSTRUMENTA√á√ÉO E IMAGENS M√âDICAS

DOI: 10.5281/zenodo.3459428

Emotion Recognition: most recent works through
EEG signal investigation
Rha√≠ra H. C. Souza
Faculdade de Engenharia El√©trica
Universidade Federal de Uberl√¢ndia
Uberl√¢ndia, Brazil
ORCID: 0000-0003-0883-8150

Eduardo L. M. Naves
Faculdade de Engenharia El√©trica
Universidade Federal de Uberl√¢ndia
Uberl√¢ndia, Brazil
ORCID: 0000-0003-4175-723X

Abstract‚ÄîThe aim of this study is to select some relevant
studies that present human emotion recognition investigation
through EEG signals by means of novel approaches. Four
studies are highlighted, they were selected by means of most
citations and recognized journals. With accurate and objective
emotion analysis results from electroencephalogram (EEG) data
processing approaches, we can chose better methods to work
with. Hence, this paper summarizes the most recent works that
have converged and diverged in the methods in EEG signal
analysis for emotion recognition.
Keywords‚Äîaffective brain-computer interface,
processing, power spectrum, feature extraction.

signal

I. INTRODUCTION
Emotion is a psycho-physiological process, which
describes momentary aspects of our daily life. Conscious and
unconscious triggers activate personality traits, which can be
modeled by means of computing approaches. Affective braincomputer interface rises from the intention to make machines
interact with our emotion states.
Other types of investigation do not use brain signals to
understand emotion recognition (ER), and one type is called
‚Äúnon-physiological clue‚Äù [1], e.g., facial expression and
gesture, fused expression, speech, and different body aspects
together
to
translate
emotion
states.
Using
electroencephalogram (EEG) signals to recognize emotion
aspects, immediate responses to emotional stimuli with an
excellent temporal resolution can be obtained using direct and
comprehensive methods [2].
Emotion recognition can be applied in many fields, such
as mental health care, entertainment, society safety purposes,
but also in healthcare applications, improving quality of life
for many users (e.g., elderly people, chronically ill people and
people with severe motor disabilities) and improving quality
of experience when applied in research approaches, inside
serious games, for example.
Attentional engagement is modulated by emotion states, it
can be observed by detecting emotion changes of a subject in
an experiment, for example, that requires different levels of
engagement. In this sense, attentional engagement relates to
how effectively we gather information from a brain-computer
interface (BCI) application, for example, also it denotes
dominance. Even in situations where there is an absence of
competing stimuli, a consistent attentional engagement is a
challenge. Therefore, the modulation of neural responses by
attentional state has been widely explored, and this aspect is
important to relate to ER.

II. RELATED WORKS
A. Models and means of working with ER
Stimulus-evoked responses are investigated by several
approaches in neuroscience. Naturalistic stimuli studies how
the brain processes narratives and how it, conversely, affect
mental state [3]. It shows that films actually mimic the realworld environment, changing the perspective of conventional
laboratory stimuli.
Many multimodal approaches for ER are available in
neuroscience. Most commonly they use audio, visual and
audio-visual stimuli. Table 1 shows the most discussed actual
affective databases, modified from [4].
TABLE I.

USER-CENTERED AFFECTIVE DATABASES [4]

User-Centered Affective Databases
Name

Recorded signals

No.
subjects

No.
stimuli

HUMAINE

audio, visual, physiological

vara

vara

DEAP [5]

physiological

32

40

DECAF

face, physiological

30

76

MAHNOBHCI

face,
audio,
physiological

27

20

ASCERTAIN

face, physiological

58

36

eye

gaze,

a.

var denotes variable

Despite the fact that film-clips are used to mimic realistic
situations, they are intended to evoke target-specific emotion,
differing from the naturalistic stimuli approach, requiring user
free-viewing. Free-viewing definition is attributed to the
conditions under which eye movement behavior was not
influenced or restricted by the experimenter in some way other
than telling participants to perform a task.
Under the current definition, free-viewing could therefore
occur in different research interests, from reading to visual
search and scene perception [6]. A strategy proposed to work
with free-viewing and its extracted Event Related Potentials
(ERPs) - averaging EEG measurements - is to combine eyetracking (ET) signals.
Generally, two existing models of emotion guide
researchers to understand and construct an emotional space:
the discrete model and the dimension model. The discrete
model considers that the emotional space consists of a limited
number of basic discrete emotions [2].
Although some viewpoints are not consistent, most studies
tend to agree with at least six basic emotions: joy, sadness,
surprise, fear, anger, and disgust [7]. On the other hand, the
dimensional model divides the emotional space into two (i.e.,

XII SIMP√ìSIO DE ENGENHARIA BIOM√âDICA - IX SIMP√ìSIO DE INSTRUMENTA√á√ÉO E IMAGENS M√âDICAS

valence-arousal, VA), with standardized types and quantity of
stimuli, such as shown in Table 1 and Table 2.
Valence reflects the positive and negative characteristics.
Arousal reflects the mental vigilance level of emotion and the
intensity of physiological activation that an individual feels.
Dominance refers to an individual‚Äôs status: in control or being
controlled [2].

B. EEG data processing and toolboxes
Modern, off-the-shelf, wireless, portable and low-cost
EEG devices have proposed an increased investigation over
BCIs in neural application methods for daily-life requirements
and for healthcare applications. For example, an ER EEGbased system can be developed based on process as shown in
Fig. 1.

DOI: 10.5281/zenodo.3459428

For more naturalistic conditions of exploring ER
processing, co-registration of other signals, such as eye
tracking, provides new paradigms for studying attention,
memory encoding, visual search, reading and responses to
emotionally charged visual information [13].
In a most recent free-viewing data study [6], the EYE-EEG
toolbox was used. Independent Component Analysis (ICA)
processing was applied and data imported into MNE-Python
toolbox to be processed. A strategy to combine ET-EEG is to
read ERP as fixation related potentials (FRPs). It proposes
regression analysis to data, but this approach is limited when
applied to free-viewing circumstances.
A way of working with combined data is to consider its
nonlinearity. GAMM (generalized additive mixed modelling),
for example, combines a parametric part with a nonparametric part, which provides nonlinear smoothing
functions for modeling. The use of nonlinear regression
techniques in modeling ET and ERPs activity is currently in
the forefront of co-registration research [13].
Reference [13] highlights Morlet complex wavelets for
EEG processing, and evaluates phase-locking of EEG signals
to saccade and FRP across EEG epochs. Inter-trial coherence
(ITC) phenomena was first proposed by reference [14] and it
is given by
1

ùëõ

The lower complexity of some off-the-shelf devices often
makes it convenient to use and capture EEG, but it can also
mean fewer channels and less cortical information recording,
reducing data accuracy and system reliability [8].
A few existing studies have implemented real-time EEGbased emotion detection systems (see Table 2), using off-theshelf devices and standardized emotional stimuli [2].
TABLE II.

Reference

EXISTING REAL-TIME EEG-BASED EMOTION
RECOGNITION SYSTEMS [2]
All data recorded with EMOTIV¬Æ Device
Emotion

[9]

audio

[10]

audio, visual

[11]

visual

[12]

audio, visual

ùêπ (ùëì,ùë°)

ùêºùëáùê∂(ùëì, ùë°) = ‚àëùëõùëò‚àí1 |ùêπùëò (ùëì,ùë°)|,

Fig. 1. ER EEG-based system modules.

Stimulus (classes)

Classifier

2 valence x 3 arousal

SVMa

2 valence

SVM

2 valence x 2 arousal

SVM

valence

LDA
a

Support vector machine

Typically, standardized stimuli are selected based on a
large sample of participants‚Äô subjective feelings and
emotional experiences and have been proven to better elicit a
single and pure target emotion than those stimuli created
relying on a smaller sample size in a single experiment [2].
On the other hand, the majority of research application on
EEG-based emotion recognition is using supervised learning
algorithms (e.g., SVM, Na√Øve Bayes, K-Nearest Neighbours)
to predict emotional states. Researchers collect a user‚Äôs selfreported scores on the levels of arousal and valance after
presenting emotional stimuli [2]. Then, the user‚Äôs ratings are
separated into two (e.g. low and high) or more classes by
selecting the threshold of a 9-point self-assessment rating
scale [5]. Therefore, this categorization does not work for realtime recognition of emotion.

ùëò

where n indicates the number of trials, Fk(f, t) is the Fourier
component of trial k at frequency f and time t, estimated by
Morlet wavelets. ITC values vary between 0 and 1, where 0
indicates no phase-locking and 1 indicates perfect phaselocking.
Summing up, for feature extraction, in previous EEG-ER
systems, various features have been used, including common
spatial pattern, higher order crossings, time-domain statistical
features, EEG spectral power, wavelet entropy, and coherence
feature [15]. Among these features, EEG spectral power
appears to be the most frequently used feature, however, two
limitations should be noted:
ÔÇ∑ First, with the increases of the number of electrodes
and the number of chosen frequency bands, the
dimension of the feature vector consisting of the
spectral powers from different bands and different
electrodes would be very large which increases the
computational burden.
ÔÇ∑ Second, EEG requires high temporal resolution in
mapping, so that the EEG spectral power provides a
worse representation of the underlying oscillatory
brain activity during emotional processing.
Therefore, it is necessary to use a post-processing method
to further extract fewer features with higher discriminability
from a large number of spectral powers of different bands and
electrodes. This can be achieved by using subspace analysis
methods, such as principal component analysis (PCA) and
linear discriminant analysis (LDA) [15].
III. DISCUSSION
In the end, it should be mentioned that there are several
problems concerning the sum up of papers focusing on EEG
signals and their applications to ER. As the field is new,
standards of analysis and experimentation have not been

XII SIMP√ìSIO DE ENGENHARIA BIOM√âDICA - IX SIMP√ìSIO DE INSTRUMENTA√á√ÉO E IMAGENS M√âDICAS

established. This makes it difficult to draw clear conclusions
when comparing studies that might even be investigating
identical conditions.
Furthermore, these mathematically-focused contributions
do not always control for physiological variables when
obtaining data for classification, and they are often biased.
This issue is worsen by the relatively a small amount of data
that are typically used for these experiments, and a lack of
details when reporting on how the data were obtained and its
quality.

[4]

[5]

[6]

[7]
[8]

IV. CONCLUSION
In this paper, we highlighted some studies that worked
with ER in some types of EEG applications in order to reach
a higher accuracy of feature extraction and classification
processes.
Some studies issues were mentioned and discussed, as
well as the way we put studies information, revealed a lack of
standardization when it comes to neuroscience and its
application in ER and data processing.

[9]

[10]
[11]

ACKNOWLEDGMENT
This study was financed in part by the Coordena√ß√£o de
Aperfei√ßoamento de Pessoal de N√≠vel Superior - Brasil
(CAPES) - Proc. CAPES - 88887.091034/2014-01. Program:
PGPTA 3461/2014.

[12]

[13]

REFERENCES
[1]

[2]

[3]

J. Li, Z. Zhang, and H. He, ‚ÄúHierarchical Convolutional Neural
Networks for EEG-Based Emotion Recognition,‚Äù Cognit.
Comput., 2018.
Y. J. Liu, M. Yu, G. Zhao, J. Song, Y. Ge, and Y. Shi, ‚ÄúReal-time
movie-induced discrete emotion recognition from EEG signals,‚Äù
IEEE Trans. Affect. Comput., 2018.
J. J. Ki, S. P. Kelly, and L. C. Parra, ‚ÄúAttention strongly modulates
reliability of neural responses to naturalistic narrative stimuli,‚Äù J.
Neurosci., 2016.

[14]

[15]

DOI: 10.5281/zenodo.3459428

R. Subramanian, J. Wache, M. K. Abadi, R. L. Vieriu, S. Winkler,
and N. Sebe, ‚ÄúAscertain: Emotion and personality recognition
using commercial sensors,‚Äù IEEE Trans. Affect. Comput., 2018.
S. Koelstra et al., ‚ÄúDEAP: A database for emotion analysis; Using
physiological signals,‚Äù IEEE Trans. Affect. Comput., vol. 3, no. 1,
pp. 18‚Äì31, 2012.
T. Cornelissen, J. Sassenhagen, and M. L. H. V√µ, ‚ÄúImproving freeviewing fixation-related EEG potentials with continuous-time
regression,‚Äù J. Neurosci. Methods, 2019.
E. L. Van Den Broek, ‚ÄúUbiquitous emotion-aware computing,‚Äù
Pers. Ubiquitous Comput., 2013.
J. Minguillon, M. A. Lopez-Gordo, and F. Pelayo, ‚ÄúTrends in
EEG-BCI for daily-life: Requirements for artifact removal,‚Äù
Biomedical Signal Processing and Control, vol. 31. pp. 407‚Äì418,
2017.
Y. Liu, O. Sourina, and M. K. Nguyen, ‚ÄúReal-time EEG-based
emotion recognition and its applications,‚Äù in Lecture Notes in
Computer Science (including subseries Lecture Notes in Artificial
Intelligence and Lecture Notes in Bioinformatics), 2011.
N. Jatupaiboon, S. Pan-Ngum, and P. Israsena, ‚ÄúReal-time EEGbased happiness detection system,‚Äù Sci. World J., 2013.
V. H. Anh, M. N. Van, B. B. Ha, and T. H. Quyet, ‚ÄúA real-time
model based Support Vector Machine for emotion recognition
through EEG,‚Äù in 2012 International Conference on Control,
Automation and Information Sciences, ICCAIS 2012, 2012.
T. Castermans, M. Duvinage, and N. Riche, ‚ÄúOnline emotion
classification from electroencephalographic signals: A first study
conducted in a realistic movie theater,‚Äù in Lecture Notes in
Computer Science (including subseries Lecture Notes in Artificial
Intelligence and Lecture Notes in Bioinformatics), 2013.
A. R. Nikolaev, R. N. Meghanathan, and C. van Leeuwen,
‚ÄúCombining EEG and eye movement recording in free viewing:
Pitfalls and possibilities,‚Äù Brain Cogn., 2016.
A. Delorme and S. Makeig, ‚ÄúEEGLAB: An open source toolbox
for analysis of single-trial EEG dynamics including independent
component analysis,‚Äù J. Neurosci. Methods, 2004.
Y. H. Liu, C. Te Wu, W. T. Cheng, Y. T. Hsiao, P. M. Chen, and
J. T. Teng, ‚ÄúEmotion recognition from single-trial EEG based on
kernel Fisher‚Äôs emotion pattern and imbalanced quasiconformal
kernel support vector machine,‚Äù Sensors (Switzerland), 2014.

