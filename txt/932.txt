An Exploration of the Utilization of
Electroencephalography and Neural Nets to Control Robots
Dan Szafir1 and Robert Signorile2
Computer Science Department
Boston College
Chestnut Hill, MA USA
szafird@bc.edu1, signoril@bc.edu2

Abstract--It has long been known that as neurons fire within the brain they produce
measurable electrical activity. Electroencephalography (EEG) is the measurement and
recording of these electrical signals using sensors arrayed across the scalp. The idea of
Brain-Computer interfaces (BCIs), which allow the control of devices using brain
signals, naturally present themselves to many extremely useful applications including
prosthetic devices, restoring or aiding in communication and hearing, military
applications, video gaming and virtual reality, and robotic control, and have the
possibility of significantly improving the quality of life of many disabled individuals.
The purpose of this research is to examine an off the shelf EEG system, the Emotiv
EPOC© System, as a cost-effective gateway to non-invasive portable EEG
measurements and to build a BCI to control a robot, the Parallax Scribbler®. We built
middleware to interpret the outputs from the Emotiv and map them into commands for
the Scribbler robot.
Keywords: Human-Robot Interaction, Computer Human Interface, Control Systems,
Neural networks

1 Introduction
Simple Brain-Computer interfaces (BCIs) currently exist and research and public interest in
them only continues to grow. This research explores the process in creating a novel BCI that
utilizes the Emotiv EPOC System to measure EEG waves to control the Parallax Scribbler
robot. We wrote middleware to interpret the signals from the Emotive system and map those
signals into commands for the Scribbler robot. These include commands such as move
forward, move to an obstacle, etc. In latter sections of this paper, we describe the current
research in BCI, describe the Emotiv system, the Scribbler robot, our middleware and a novel
use of blinking (which can be detected by the Emotive systems) to enhance the command set
for the robot [29].

2 Electroencephalography
EEG waves are created by the firing of neurons in the brain and were intensely in the fields of
neuroscience and psychology [1] [2]. EEG waves are measured using electrodes attached to
the scalp, which are sensitive to changes in postsynaptic potentials of neurons in the cerebral
cortex. Postsynaptic potentials are created by the combination of inhibitory and excitatory
potentials located in the dendrites. These potentials are created in areas of local
depolarization or polarizations following the change in membrane conductance as
neurotransmitters are released. These average of the potentials are amplified and combined to
show rhythmic activity that is classified by frequency [3]. Electrodes are usually placed
along the scalp as in Figure 1 [4]. One of the historical downsides of EEG measurement has

been the corruption of EEG data by artifacts, which are electrical signals that are picked up by
the sensors that do not originate from cortical neurons. One of the most common causes of
artifacts is eye movement and blinking, however other causes exist [5]. Many EEG systems
attempt to reduce artifacts and general noise by utilizing reference electrodes placed in
locations where there is little cortical activity and attempting to filter out correlated patterns
[6].

Figure 1. Electrode Placement according to the International 10-20 System. Odd numbers on the right,

even on the left. Letters correspond to lobes – F(rontal), T(emporal), P(arietal), and O(ccipital). C
stands for Central (there is no central lobe).

3 Brain-Computer Interfaces
The term “Brain-Computer Interface” is the idea of linking the mind to computers [7]. The
ultimate goal of BCI research is to create a system that is not only an “open loop” system that
responds to users thoughts but a “closed loop” system that also gives feedback to the user.
Researchers initially focused on the motor-cortex of the brain, the area which controls muscle
movements, and testing on animals quickly showed that the natural learning behaviors of the
brain could easily adapt to new stimuli as well as control the firing of specific areas of the
brain [8] translate them into robotic activity [9][10] [11] [12]. Research is beginning to veer
away from invasive BCIs due to the costly and dangerous nature of the surgeries required for
such systems. Non-invasive alternatives for BCIs include EEG technology,
Magnetoencephalography (MEG), and Magnetic Resonance Imaging (MRI), as well as the
“partially invasive” Electrocorticography where sensors are placed within the skull but
outside the gray matter of the brain. These methods are limited in that they are often
susceptible to noise, have worse signal resolution due to distance from the brain, and have
difficulty recording the inner workings of the brain. However, non-invasive techniques have
the advantage of lower cost, greater portability, and the fact that they do not require any
special surgery [13].

4 Previous EEG BCI Research
Though the idea of using EEG waves as input to BCIs has existed since the initial conception
of BCIs, actual working BCIs based on EEG input have only recently appeared [14]. Most
EEG-BCI systems follow a similar paradigm of reading in and analyzing EEG data,
translating that data into device output, and giving some sort of feedback to the user (Figure
2), however implementing this model can be extremely challenging [15]. The primary
difficulty in creating an EEG-based BCI is the feature extraction and classification of EEG
data that must be done in real-time if it is to have any use.

Figure 2. Brain-Computer Interface Design Pattern

Feature extraction deals with separating useful EEG data from noise and simplifying that
data so that classification, the problem of trying to decide what the extracted data represents,
can occur. There is no best way of extracting features from EEG data and modern BCIs often
use several types of feature extraction including Hjorth, wavelet transforms and Fourier
transforms. The major features that EEG-BCI systems rely on are event-related potentials
(ERPs) and event-related changes in specific frequency bands [16][17]. BCI systems are
further complicated by the fact that there is no standard way of classifying the extracted data.
Various types of pattern recognizers are employed to try to match the input data to known
categories of EEG archetypes [18]. Researchers have also relied on unsupervised learning
algorithms to find natural clusters of EEG segments that are indicative of certain kinds of
mental activities with varying degrees of success [19][20]. Feedback is essential in BCI
systems as it allows users to understand what brainwaves they just produced and to learn
behavior that can be effectively classified and controlled [21].
EEG-BCIs can be classified as either synchronous or asynchronous. The computer drives
synchronous systems by giving the user a cue to perform a certain mental action and then
recording the user's EEG patterns in a fixed time-window. Asynchronous systems are driven
by the user and operate by passively and continuously monitoring the user's EEG data and
attempting to classify it on the fly. Synchronous protocols are far easier to construct and have
historically been the primary way of operating BCI systems [22] [23][24].

5 Our Research Project: Combining Machine learning, Neural Nets ,
Brain Waves And Our Middleware to Control Personal Robots
The goal of our project was to investigate and suggest the use of brainwaves to control
personal robots (and thus demonstrate the more general proposition that robots can be
controlled by brainwaves). Using training of the Emotiv System, we were able to extract the
EEG signals from the headset, categorize them into one of several groups, translate that group
to a robotic command, and finally control the robot. The two major hardware components of
our system are the Emotiv Headset and the Scribbler robot. The next subsections briefly
describe each system. Then we discuss our integration of the two systems sand finally we
describe some adjustments we made to extend the overall system.

5.1 The Emotiv© System
The Emotiv System is based around the EPOC headset for recording EEG measurements and
software suit which processes and analyzes the data. This research originally uses the
Research Edition of this off the shelf product. The Research Edition includes the Emotiv
Control Panel, EmoComposer (an emulator for simulating EEG signals), EmoKey (a tool for
mapping various events detected by the headset into keystrokes), TestBench, which enables
the capture of raw EEG data from each individual sensor [26].The Emotiv system can
measure engagement/boredom, frustration, meditation, instantaneous excitement, and longterm. The Cognitiv suite can measure 13 active thoughts as well as the passive neutral state.
This software works by running the input from the electrodes through a neural network and
attempting to classify the signals as one of the 13 built-in “prototype” action thoughts.The
core of the Emotiv SDK is the “EmoEngine,” which is a logical abstraction that
“communicates with the Emotiv headset, receives preprocessed EEG and gyroscope data,
manages user-specific or application-specific settings, performs post-processing, and
translates the Emotiv detection results into an easy-to-use structure called an EmoState.”
Every EmoState represents the current input from the headset including “facial, emotional,
and cognitive state” contains electrode measurements for each contact. Utilizing the Emotiv
API consists of connecting to the EmoEngine, detecting and decoding new EmoStates, and
calling code relevant to the new EmoState (Figure 3).

Figure 3. High-level View of the Utilization of Emotiv

5. 2 The Parallax Scibbler® Robot and IPRE Fluke
The Parallax Scribbler robot is a fully assembled reprogrammable robot built around the
BASIC Stamp® 2 microcontroller. It contains built in photovoltaic sensors, infrared sensors,
line sensors, two independent DC motors to drive the two wheels, three LED lights, a
speaker, and a serial port[28]. The Institute for Personal Robots in Education (IPRE) Fluke is
an add-on board created by Georgia Robotics that plugs into the Scribbler's serial port and
adds color vision, IR range sensing, internal voltage sensing, an extra LED, and bluetooth
functionality and has created the Myro APIs to control the Scribbler using Python [29].

5.3 Control Implementation
The code implementing this control scheme is divided into four basic parts: connecting to the
Emotiv headset via the Emotiv API, connecting to the Scribbler through the Myro Python
libraries, reading and decoding Emotiv events and sending the corresponding commands to
the Scribbler, and closing the connections when the user is done (Figure 4).

Figure 4. High-level View of the Control Scheme

5.4 Decoding and Handling EmoStates
There are four major steps in reading and decoding information from the EPOC headset:
creating the EmoEngine and EmoState handles, querying for the most recent EmoState,
deciding if this is a new EmoState, and decoding the EmoState. The EmoEngine handle
allows for queries to get direct input from the headset including contact quality, raw electrode
input, and the connection quality. New EmoStates are constantly created by the EmoEngine
which represent recognized actions such as facial expressions, changed emotional status, and
detected thoughts and can be queried through the EmoState handle.Next the program
determines the event type returned by the EmoEngine. There are three categories of event
types: hardware-related events, new EmoState events, and suite-related events. Once we have
decoded which thought sparked the EmoState, we send the appropriate call to the Scribbler
(Push → Move Forward, Turn Left → Turn Left, Turn Right → Turn Right). We initially

experimented with using the power of the thought as an input to the power of the robotic
action, however we found that this control scheme was too difficult to use and it ended up
being far more intuitive to use specific values for turning and moving forward no matter the
thought-power. This allowed the user to concentrate on the thoughts alone and not have to
additionally worry about how “hard” to think about the thoughts.
The internal sampling rate in the EPOC headset is 2048Hz which is filtered to remove
artifacts and alias frequencies own to about 128Hz. Any given motion input to the Scribbler
using Bluetooth takes approximately 2 seconds to execute, while picture taking take slightly
longer as it has to capture and send data back. Thus we needed to synchronize the sampling
rate with the actual Scribbler command execution (so that commands are not just queued up,
but executes in a orderly fashion). To solve this problem, we introduced a sampling variable
to only decode one in every ten input EmoStates to limit the EmoStates created. Using this
sampling variable we filter out those extra states that really only correspond to one event by
using a sample rate small enough that it will still capture events which send more than 10
input EmoStates while sending only one command to the Scribbler instead of queuing up 10.
This system worked much better, and even had the added bonus of filtering out “noise”
thoughts when the headset detected a push or turn thought for a fraction of a second.
To extend the number of command we can send to the Scribbler, we created an additional
mode, which remaps the same input thoughts to different outputs in the robot. This is hugely
beneficial as it does not increase the difficulty in recognizing new thoughts and also does not
require the user to train additional thoughts, thus giving double the usability with only one
additional input. This additional input is raising the eyebrows, which toggle between the
original and the new mode. We decided on utilizing the raising of eyebrows as a toggle as it
is very easily trained and accurately recognized by the headset. The addition of more modes
is certainly possible and is an excellent way of adding functionality without adding the cost of
recognizing and learning new thoughts. In the end, it was completely feasible to control the
Scribbler robot using the EPOC headset proving the viability of EEG based BCI technology.

5.5 Blink Detection and Data Reduction/Noise Reduction
We next decided to explore the Pre-Processing, Feature Extraction, and Classification of EEG
data by analyzing eye blinks. The analysis of eye blinks is useful in BCI development for two
reasons: eye blinks can be used as control inputs and if they are not they must be filtered out
lest they corrupt the useful EEG data. We decided on eye blinks since they are immediately
recognizable in one particular channel from the headset. This allowed us to immediately
reduce the amount of input data by a factor of 14 since we could discount the other 13 input
channels.
Reducing the size of the data set is the primary focus of pre-processing and feature
extraction whose goal is to get rid of extraneous and noisy data while preserving data that can
best differentiate between classes. We recorded twenty, ten second clips, ten of which we
blinked during and ten of which we didn't. We then exported the clips to MATLAB. These
recordings produced a lot of data because in addition to the 14 EEG channels capturing
electrode data at 128Hz the headset also records gyroscope data, battery data, packet
information, etc. and each 10 second clip ended up had roughly 36000 data points and
combined I recorded 720000 data points.
The first step of our feature extraction was to use just the channel where blinks are clearly
visible. The classification using MATLABS' nprtool to create a two-layer feedforward neural
network with backpropagation obtained only a 65% accuracy. Though there was a certain
pattern to the blinks, the neural net was thrown off because the blinks were not normalized
with respect to time. The neural net treated time as an attribute, and thus did not classify two

samples that both contain blinks but where the blinks occur at different times. Time was
correlated to blinks in respect to how long the blink takes and thus how wide the blink spike
will be, however the time that the blink occurs is not a usable attribute.
To solve this problem, we decided to further reduce the amount of data the neural net
worked with along with normalizing any blinks found. Recognizing that blinks correlate to
spikes in EEG data, we scanned each 10-second clip looking for the largest spikes. We found
that blinks typically were represented by a surge in the 4500 to 4800 µvolt range over
approximately .59 seconds and were followed by a characteristic dip of around 50 µvolts over
approximately .20 seconds. This pattern was very clear and easily distinguishable from a nonblink state; we first noticed it when applying unsupervised K-Means Clustering to detect
naturally occurring patterns in the data.We used this information to further filter each of the
20 inputs down to 1.6-second segments, each of which highlighted the maximum spike of the
original ten-second segment. This normalized the blinks by having each blink start at roughly
the same time and additionally filtered out noise that was unrelated to the blinks creating data
that was much easier for a neural net to distinguish. Using these inputs, neural net accuracy
improved to 100%, however we wanted to see if this system truly recognized blinks or was
over-trained on the input data. We then recorded five more segments, 3 with blinks and 2
without, and followed the same pre-processing/feature extraction steps and fed the data to the
neural net. The neural net accurately predicted all of these new inputs even though it had not
been trained upon them, showcasing that it was truly was extendable and actually recognizing
blink patterns. These are very promising results that prove the feasibility of utilizing a neural
net to classify blinks, however it would be best to obtain a larger sample size to accurately
test the classification performance of this scheme. Now blinks could be used to effectively
double our thoughts (think of the recognizable blink as a “shift” key on a keyboard).

6 Conclusions
Part of our research was to examine the state of EEG-based BCI construction and
implementation. In particular, we wanted to test the feasibility of BCI to control personal
items such as a personal robot. Our investigation demonstrates that, with our middleware, it is
a feasible system that will likely only improve and become more widespread in the future.
The system we constructed was largely a success as we were able to create a system whereby
we could control a robot with our thoughts and we further created accurate blink-recognizing
software to enhance the amount of thoughts we can recognize.Furthermore, our system
showcases the possibilities of BCI's in aiding the disabled. For instance, a person who could
only move their head could certainly use our system to control a motorized wheelchair
accurately using their thoughts. In addition, had they a computer built into the headset, they
could easily switch modes by raising their eyebrows and then use their thoughts as an input to
the computer, by using the same thoughts that had moved the wheelchair to control the mouse
and double-blinking to click. An alternative would be to keep the thoughts controlling the
wheelchair while utilizing the gyroscope in the headset to control the mouse, enabling the
user to have simultaneous control of the wheelchair and computer. Further research can
certainly lead to direct implementation of such systems and can explore the recognition of
thoughts beyond those included in the Emotiv API.

References
1

Swartz, B.E; Goldensohn, ES. "Timeline of the history of EEG and
Electroencephalography and Clinical Neurophysiology. Vol. 106,pp.173–176.1998

associated

fields."

2
3
4

5
6
7
8
9
10
11
12
13
14
15
16
17

18
19

20
21

22
23
24

25
26
27
28
29

Millett, David. "Hans Berger: from psychic energy to the EEG.” Perspectives in Biology and
Medicine, Johns Hopkins University Press, 2001. 44.4 pp. 522–542.
Nunez PL, Srinivasan R. Electric Fields of the Brain: The Neurophysics of EEG. Oxford
University Press. 1981.
Niedermeyer, Ernst and da Silva, Fernando Lopes. Electroencephalography: Basic Principles,
Clinical Applications,
and Related Fields, Fifth Edition. Lippincott Williams & Wilkins, 2005. pp 140
Rowan, A. James. Primer of EEG. Elsevier Science, Philadelphia, PA. 2003.
Ludwig, Kip A. et al. Employing a Common Average Reference to Improve Cortical Neuron
Recordings from Microelectrode Arrays. Journal of Neurophysiology, September 3rd, 2008.
J. Vidal, "Toward Direct Brain–Computer Communication." Annual Review of Biophysics and
Bioengineering. Vol. 2, 1973, pp. 157-180.
Fetz, E E. “Operant Conditioning of Cortical Unit Activity.” Science. Volume 163, February 28,
1969, pp. 955-958.
Kennedy, Philip R. et al. “Activity of single action potentials in monkey motor cortex during
long-term task learning.” Brain Research, Volume 760 Issue 1-2, June 1997, pp. 251-254.
Wessber, Johan et al. “Real-time prediction of hand trajectory by ensembles of cortical neurons
in primates.” Nature.Vol. 408, No. 6810, 2000. pp. 361-365.
Carey, Benedict. “Monkeys Think, Moving Artifiacl Arm as Own.” The New York Times. May
29, 2008.
Hochberg, Leigh R. et al. “Neuronal ensemble control of prosthetic devices by a human with
tetraplegia.” Nature. Vol. 442, July 13, 2006, pp. 164-171.
Fabiani, Georg E. et al. Conversion of EEG activity into cursor movement by a brain-computer
interface.
J. Vidal, "Toward Direct Brain–Computer Communication."
Omidvarnia, Amir H. et al. Kalman Filter Parameters as a New EEG Feature Vector for BCI
Applications.
Niedermeyer. Electroencephalography. pp. 1265-1266.
Sellers, Eric W. et al. “A P300 event-related potential brain–computer interface (BCI): The
effects of matrix size and inter stimulus interval on performance.” Biological Psychology.
Volume 73, Issue 3, October 2006. pp. 242-252.
Adlakha, Amit. Single Trial EEG Classification. Swiss Federal Institute of Technology. July 12,
2002.
Lu, Shijian et al. “Unsupervised Brain Computer Interface based on Inter-Subject Information.”
30th Annual International IEEE EMBS Conference. Vancouver, British Columbia, Canada.
August 20-24, 2008.
Niedermyer. Electroencephalography. pp. 1240.
Kauhanen L, Palomaki T, Jylanki P, Aloise F, Nuttin M, and Millan JR. “Haptic feedback
compared with visual feedback for BCI”. Proceeding of 3rd International BCI Workshop and
Training Course 2006. Graz Austria. 21-25 Sept 2006, Pp. 66-67.
Niedermeyer. Electroencephalography. pp. 1265.
Birbaumer, N. et al. “The Thought Translation Device (TTD) for Completely Paralyzed Patients.”
IEEE Transactions on Rehabilitation Engineering. Volume 8, No. 2, June 2000. pp. 190-193.
Galán, F. et al. “A Brain-Actuated Wheelchair: Asynchronous and Non-invasive BrainComputer Interfaces for Continuous Control of Robots.” Clinical Neurophysiology. Volume 119,
Issue 9, September, 2008. pp. 2159-2169.
Drummond, Katie. “Pentagon Preps Soldier Telepathy Push.” Wired Magazine. May 14, 2009.
Emotiv Website. <http://www.emotiv.com>.
“The Scribbler: A Reprogrammable Robot.” <http://www.parallax.com/tabid/455/Default.aspx>.
Copyright 2010 by Parallax Inc. Accessed 4/11/2010.
“Usage Guides.” <http://www.roboteducation.org/guides.html>. Copyright © 2007 Institute for
Personal Robots in Education. Accessed 4/11/2010.
Szafir, Dan, Non-Invasive BCI through EEG, unpublished Undergraduate Honors Thesis in
Computer Science, Boston College, 2010

