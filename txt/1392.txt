A. Georgaki and G. Kouroupetroglou (Eds.), Proceedings ICMC|SMC|2014, 14-20 September 2014, Athens, Greece

Creating a Place as a Medium for Musical Communication Using Multiple
Electroencephalography
Takayuki Hamano
JST, ERATO,
Okanoya Emotional Information Project
takayuki.hamano@mail.com
Ryu Nakagawa
JST, ERATO,
Okanoya Emotional Information Project
ingaz@me.com

Hidefumi Ohmura
JST, ERATO,
Okanoya Emotional Information Project
hidefumi.ohmura@gmail.com

Hiroko Terasawa
University of Tsukuba / JST, PRESTO
terasawa@slis.tsukuba.ac.jp

Kazuo Okanoya
The University of Tokyo
kazuookanoya@gmail.com

Reiko Hoshi-Shiba
BSI, RIKEN
reichin@brain.riken.jp

Kiyoshi Furukawa
Tokyo University of the Arts
kf@zkm.de

ABSTRACT
Music is an activity that expresses human thoughts and
emotions, for which human brain takes a central role. Meanwhile, music offers an emotionally compelling experience
when multiple persons lively participate. We hypothesize
that brain activities would exhibit specific responses and
patterns to music in a situation where multiple persons
gather and perform the music. Upon these premises, we
created an installation piece, which attempts to represent
the interconnection of people’s minds by capturing the characteristics of brain activities associated with music. The
system for the installation handles Electroencephalography
(EEG) data acquisition, data analysis, sonification, and visualization. The system analyzes EEG of multiple participants when they respond to given stimuli, such as acoustically played musical notes or simple visual elements. The
result of spectral analysis and the averaged responses of
brain activities of all the participants are represented with
musical notes and visual images. The system has been
devised to be compact and reproducible by making good
use of devices that are commercially available. With this
system, we created an installation piece focusing on the
human brain to constitutively form a space where musical
communication arises.
1. INTRODUCTION
We developed a system for an installation piece to produce
sonification and visualization of the analyzed brain activities of multiple participants responding to visual and auditory stimuli (Figure 1). Using this system, we created
an art installation piece focusing on the human brain with
Copyright:
an

open-access

c 2014

Takayuki

article

Hamano

distributed

under

Creative Commons Attribution 3.0 Unported License,

et

al.
the
which

This
terms

of

permits

is
the

Figure 1. Picture of our installation piece with 3 participants. at Tokyo University of the Arts.

an attempt to constitutively form a place where a primitive
form of musical communication arises 1 .
As described in Section 1.2, many art works using Electroencephalography (EEG) have been realized. Arguing
the novelty of our project might be difficult, yet our work
is distinct with the following aspects, delivering unique
experience to the audience: (1) the sonification and visualization of both individual and collective data, (2) the
concurrent sonification of both EEG spectral analysis and
ERP (Event-Related Potential) response, (3) the straightforward audiovisual mapping with minimal data processing, that allows participants to directly attend data, (4) the
electro-acoustic aspects of Clarinet and EEG composition.
In this paper, we describe the background, concept, and
development of our work.

unre-

stricted use, distribution, and reproduction in any medium, provided the original
1

author and source are credited.

- 637 -

This installation piece is submitted to Joint ICMC - SMC 2014

A. Georgaki and G. Kouroupetroglou (Eds.), Proceedings ICMC|SMC|2014, 14-20 September 2014, Athens, Greece

1.1 Basic Concept of Installation: Musical
Communication
In many cases of music, more than one person congregates
in a given place. The musicologist Charles Small proposed
a concept of musicking, meaning any activity involving or
related to music performance [1]. He also argued that the
act of musicking establishes a relationship of all individuals contributing to the nature of an event that is a musical
performance, in any place [2]. In such a situation, interactions between individuals are orchestrated within a single
brain, according to Benson [3].
Building from this idea, we are currently developing an
art piece in the form of installation with multiple participants. This is because we intend to capture the characteristics of brain activities associated with music that are
present not only in the brain activities of individuals, but
also in the relationship between the brain activities of multiple people. Besides that, we also assume that brain wave
patterns specific to music appear more strongly in a situation where multiple persons gather and perform the music.
Therefore, we decided to compose an expression of this
phenomenon by extracting the internal states of individuals and their interconnection using EEG.

On that idea, Brain dreams Music Project was founded in
2011 3 . The project aims to bridge art and neuroscience,
and explore a new form of musical instrument. The project
is both conducting research on how brain activities relate
to music, and developing artistic works such as live performances and installations. The project is organized by
members from many domains such as composers, visual
artists, neuroscientists, computational scientists, engineers,
and others.
1.3.1 Fundamental Research and Technology
Since the establishment of the project, we have developed
a technology for artistic expression by connecting the EEG
with sonification and visualization. In the early stages of
the project, we have focused on the EEG activity of individual people during their imagination of music. As an basic research study, Hoshi-Shiba has succeeded in finding
the neural correlates of expectation of termination, while
listening to a dominant chord in musical termination structure or cadence [9]. Currently, we are further investigating
the neural activity of music imagery by applying similar
experiments to both the listening of music and recalling
music in one’s mind. We are planning to publish the result
of this study this year.

1.2 Related artistic works using EEG
EEG is a technique used for over a century to measure electrical changes along the scalp in order to record brain activity. It is used not only in the medical and research fields,
but is also used as a tool for many artistic works. The most
attractive aspect is that the EEG may reflect thoughts and
emotional states. In recent years, some portable EEG systems have become available on the commercial market.
Many artists are attracted to the use of EEG for their
pieces. The composer Alvin Lucier is known as the first
person to produce music with an EEG [4]. David Rosenboom adopted an approach of biofeedback processes during musical performances where he made the brain state of
the performer audible [5].
These works still have an influence on art projects in recent decades. In a series called DECONcert, the EEGs
of 48 participants are used to produce biofeedback [6].
The MiND Ensemble, gives stage performances using a
portable EEG system 2 . There are also some notable projects
that employ multiple EEG systems associated with twodimensional representation of emotion, based on valence
and arousal model [7], or relaxation and attention framework [8].
1.3 Brain dreams Music Project
The brain takes a core role in human activities including
music, and music can be considered as an act inseparable
from human thinking and emotion. Around the year 2010,
we started a new project. We aimed to holistically capture
the various aspects of music by tracing back to the stage at
which music, emotion, and other thoughts are undifferentiated in human brain.
2

1.3.2 Development of “it’s almost a song..”
Based on the results of the above research studies, we developed a musical instrument using brain-computer interface (BCI) technology to generate an integrated musical
expression [10]. We developed a real-time musical performance system using a classification technique in BCI
technology[11] and sonification techniques to generate chords
with organically fluctuating timbre. The concert piece “it’s
almost a song...” is performed with clarinet, or with string
quartet.
In this paper, we present the installation version of “it’s
almost a song...” that inherits the core real-time technologies such as data acquisition and analysis, visualization,
and sonification, from “Brain dreams Music Project”. The
installation version was first presented at a workshop in
Fukushima, Japan in summer 2013. This manuscript describes the most current states of the installation version.

2. DESCRIPTION OF THE INSTALLATION
“it’s almost a song...” installation version is for three Electroencephalography (EEG) systems and Clarinet. The mixture of musical, auditory, and visual stimuli and the realtime visualization/sonification of EEGs by audience comprises a spatial and interactive representation of interconnected musical minds. Three participants from audience
listen to a clarinet composition, or observe visual stimuli
(flashing geometric figures), and provide their brain activities via EEG. The measured brain activities are sonified
and visualized, resulting in the following elements of the
installation:
3

The MiND Ensemble http://www.themindensemble.com/

- 638 -

Brain dreams Music http://brain-dreams-music.net/

A. Georgaki and G. Kouroupetroglou (Eds.), Proceedings ICMC|SMC|2014, 14-20 September 2014, Athens, Greece

Audio

stimuli are detected with Onset Detector and Photo Detector as described later.

• Continuous musical notes of harp whose pitch is mapped
from the averaged alpha-band power from each par3.1.2 Software Units for Individual Participants ([B])
ticipant. “Melodies” contributed from multiple parWhen the system is started, software units for EEG proticipants comprise an auditory stream, forming a colcessing and visualization for individual participants are launched
lective audio representation.
automatically. The number of these units is determined by
the number of the participants. EEG Receiver processes
• Musical notes of marimba as a time-scaled playback
the acquisition of EEG and two kinds of analysis. This proof ERP where the averaged voltage is mapped onto
gram is written purely in C for the sake of processing speed
the pitch. Collective representation of the neural reand time precision. The result of the analysis is sent to the
sponses.
Visualizer. Messaging Server assists interprocess commu• Clarinet composition, to artistically stimulate musicnication and the general control of timing.
related brain activities.
3.1.3 Software Units for Integrated Results ([C])
Visual
The analyzed data of each subject are sent to the other units
for integration. Visualizer for the center screen and MIDI
• Raw EEG wave forms from 14 electrodes for each
Synthesizer are the units with visualization and sonification
participant.
as their final output. Thereby, the audience listens to the
• Spectrum (frequency analysis) of EEG from 14 elecmusic and sees the images generated from the participants’
trodes for each participant.
states. Participants also perceive sonification as a form of
feedback.
• ERP wave forms for each participant.
All programs are built in open source programming environments, such as Processing 4 and Node.js 5 . MIDI Syn• Sparkling visual objects by alpha-band power for each
thesizer adopts FluidSynth 6 for real-time sound generaparticipant and for averaged result. (showing indition from SoundFont. For communication between softvidual and averaged result)
ware processes, OpenSound Control (OSC) is mainly used
• Animated overlapping rings by ERP. (showing indias a messaging protocol.
vidual and averaged result)
This installation system aims to display the brain activities of multiple people with visualization and sonification
and to build an environment to share it with an audience.
We aimed to build a compact and reproducible system with
the aid of devices that are commercially available.This system is not a BCI per se, but rather an interface for a constitutive experiment in order to develop a place that allows
musical communication. In the latest version of this work,
three participants wear EEG equipment. We have succeeded in running our developed system with five participants, and handling data from more participants is feasible,
in theory.
3. IMPLEMENTATION
3.1 Design of Architecture
We designed the architecture of the installation system as
shown in Figure 2. The system consists of input sources
including the EEG system and sensors, many software process units for individual participants and for the integration
of their results, and equipment for their output as well.
3.1.1 Input Sources ([A])
Stimuli are given to the participants while their brain activities are measured. There are two kinds of stimuli, audio and visual image. For the auditory stimuli, musical
notes are played by an acoustic instrument such as a piano
or clarinet. For the visual stimuli, a pre-composed movie,
like the flashing of simple shapes with a vivid color, is projected on a monitor and a screen. The timing of both of the

- 639 -

3.2 EEG System
We used a commercial gaming EEG system Emotiv EEG
for measuring brain activity 7 . The features of this EEG
system are that it is a wireless and wearable device with 14
electrodes and is relatively low-priced compared to other
devices for research use. The sampling rate of the system
is 128 Hz. This EEG system may prove a valid alternative to laboratory event-related potential (ERP) systems for
recording reliable late auditory ERPs over the frontal cortices [12].
3.3 Methods for EEG analysis
In this installation, we used two typical methods for EEG
analysis, frequency analysis and ERP. These methods are
reliable and have been widely used for a long time in the
history of EEG. We used them to clearly demonstrate the
relationship of EEGs arising from multiple participants by
keeping the analysis process simple.
3.3.1 Frequency Analysis
The frequency spectrum of EEG data was calculated by
frequency analysis. The powers of each frequency band of
the EEG, such as alpha and beta bands, are easily determined from the spectrum. Our system computes the spectrum for the latest time frame of EEG samples for a single second (=128 samples) at every sample for all channels
4

Processing.org http://processing.org
Node.js http://nodejs.org
6 FluidSynth http://sourceforge.net/apps/trac/fluidsynth/
7 Emotiv EEG System https://www.emotiv.com/
5

A. Georgaki and G. Kouroupetroglou (Eds.), Proceedings ICMC|SMC|2014, 14-20 September 2014, Athens, Greece

[A] Input Sources
Emotiv EEG

[C] Software Units for
Integrated Result

Units for Participant 1
C

Participant

♫

[B] Software Units for Individual Participants

Processing

EEG Receiver
Microphone

Auditory stimuli

Visualizer (Center)

+ Frequency Analysis
+ Event-related Potential

Visualizer (Sub)

Pure Data

Onset Detector

node.js

fluidsynth

MIDI Synthesizer

node.js

Messaging Server
Photodetector
(Raspberry Pi)

Projector

Processing

Speakers

Projector

Units for Participant 2

Visual stimuli

Units for Participant 3
Participant 2, 3…
Software unit
Device

Feedback

Figure 2. Diagram of the architecture of our installation system.
and participants. For visualization, the change of alphaband power was used. We used a C library FFTW 8 for
the computation of the Fast Fourier Transform.
3.3.2 Event-related Potential (ERP)
Event-related potentials (ERPs) are neural signals on EEG
that are elicited in response to specific events [13]. We
attempted to extract the ERPs for sound and visual stimuli
that were perceived and shared among the participants and
the audience.
When the stimuli are produced, a trigger signal is sent
to the EEG Receiver in as accurate a timing as is possible. Our system thereafter records EEG for 1 second to the
buffer after every trigger signal. The recorded samples are
averaged for each channel. ERP waves are also normalized, and then the waves of all participants are averaged as
an integrated result.
3.3.3 Trigger Unit for ERP
As mentioned in the section 3.3.2, the processing of ERPs
should be done carefully in order to prevent time jitter.
ERPs extract commonality of EEG patterns under certain
conditions by diminishing noise by averaging. The responses appearing in these EEG wave forms are highly
time-sensitive. Even a time jitter of a few milliseconds
may destroy a clear ERP wave form.
In order to overcome this problem, we took solutions
for the triggers as follows: For audio stimuli, an acoustic player makes a sound like a short pulse and the sound is
sampled from a microphone. Then, the onset of the sound
is detected with a program created on Pure Data. Meanwhile, in order to detect the visual stimuli at an accurate
time and transmit the signal to the main computer, we built

a trigger system based on a single board computer Raspberry Pi 9 . A photo transistor NJL7502L was utilized for
the light sensor 10 . We employed this photo transistor because of a sharp directivity and a spectral response similar
to the human eye. The trigger system is attached to a monitor and connected to the main computer with an ethernet
cable.

Figure 3. Prototype of trigger unit using Raspberry Pi and
a photodetector.
Trigger signals of both types of stimuli are transmitted
immediately to the EEG Receiver with an OSC protocol.
In this way, we minimize the error of trigger times by detecting target that the participants actually perceive.
3.4 Sonification and Visualization
The results of the EEG analyses are finally converted to
audio and visual images. In the current version, the parameter mapping for both the sonification and visualization is
arbitrarily defined by us. This is because the number of
9

Raspberry Pi http://www.raspberrypi.org/
NJL7502L (http://www.lanxinic.com/cn/product 2/uploadfiles/
20121111154322.pdf)
10

8

FFTW http://www.fftw.org

- 640 -

A. Georgaki and G. Kouroupetroglou (Eds.), Proceedings ICMC|SMC|2014, 14-20 September 2014, Athens, Greece

musical/visual parameters is considerable, and we believe
that an empirical selection may not work in this case. Thus,
the parameters were adjusted to sound and look like they
were expressing the most rich variety based on the data.
3.4.1 Sonification
Currently, our system allows us to generate music in two
ways as a sonification from each EEG analysis result. In
either manner, the resulting data is converted to musical
notes that are played by the MIDI synthesizer.
For the frequency analysis, the relative change of the power
of the alpha band averaged across all participants is mapped
onto the pitch of a continuously played arpeggio of the
harp. The stronger the power is, the higher the tone that
is played. The note set of the arpeggio is pre-defined and
the curve of the amplitude is manually configured with respect to the pitch of the tones.
For the preprocessing of ERP sonification, each data channel is normalized and the average of all participants is taken
for every channel. Since the ERP data is a second long, we
implemented sonification as a playback of that recorded
data. Each sample of ERP data represents the normalized
voltage, and it is mapped to the pitch of the tones with the
marimba. It is able to change the time scale of playback,
so that the result can be heard at a slower speed.
3.4.2 Visualization
The integrated results, such as the average of frequency
analysis or ERP, are visualized on the screen placed at the
center/top of the display. There are also other sub-screens
showing the status of each subject (Figure 4). On the subscreens, the positions of the electrodes are mapped and
preprocessed raw EEG singles and spectra are depicted in
real-time. Sparking objects around each electrode represents a rise of alpha-band power. ERPs are visualized like
overlapping rings as seen in Figure 1. Rings represent each
sample of ERP data, and their color shows time. Each electrode is mapped to the annular shape and the position of the
vertices extends according to the electric potential of the
ERP. This type of visualization is played as an animation
associated with the sonification.

4. INSTALLATION
We conducted a workshop with an earlier version of our
installation system. The workshop was held in the summer of 2013 in Affiliated Junior High School of Fukushima
University. About 15 students from the university and the
junior high school joined in the workshop. In the first half
of the workshop, we gave a introductory lecture about neuroscience and media art, and explained about interdisciplinary collaboration in these domains. In the second half,
we had time for hands-on learning session using our system. The students measured their EEG, and observed the
sonification and visualization generated from the EEGs of
their own. Next, we measured the ERP of five participants
simultaneously and created music and images of the averaged result.
During the hands-on session, all the participants needed
some time at first to familiarize themselves with the observation of their brain. However, while practicing many
trials by themselves, many of them actively tried to apply
various audio and visual stimuli and to see how they affect
on their EEGs. When finally experimenting with simultaneous ERP, all participants wearing EEG system concentrated on the stimulus cooperatively, and that resulted
in forming a very intense, focused atmosphere. After the
measurement, the place was in a relaxed mood in reversal.
The participants enjoyed the discussion comparing the results of everyone and their own by listening and watching
the result for many times.
Currently, we are planning to exhibit our installation at
various occasions to different kinds of audiences, as well
as making a performance piece based on this installation.
5. DISCUSSION
Our goal is to express musical communication by multiple
person in a place. Toward this goal, we developed a system enabling sonification and visualization based on EEGs
measured from multiple participants. The response from
the participants of the workshop was very positive in general. They lively enjoyed experimenting on their brain activities with musical or visual stimulations. The synchronization and segregation of audiovisual representations inspire the interactive exploration of the relationship between
brain and music.
As a consequence of the development, we achieved to
create a place which allows audience to observe a cyclical
process like musical communication that music is generated from participants EEG and that music returns to participants again as a biofeedback. By representing an integrated result of multiple participants as audio and images,
the audience is able to grasp the relationship among individual participants intuitively. In addition, the audience
can perceive a fine change of brain activity by music as
sonification which was exhaustively adjusted.
5.1 Expected Future Tasks

Figure 4. Screen shot of the visualization on sub-screen
for one subject.

- 641 -

We have implemented two types of sonification in this system. A possible improvement will be to realize a linear
mapping with real-time sound synthesis which will give

A. Georgaki and G. Kouroupetroglou (Eds.), Proceedings ICMC|SMC|2014, 14-20 September 2014, Athens, Greece

more precise temporal information to the output. A Further possibility is to allow the participants to map and scale
of parameters by controlling themselves. The mapping of
the current version is optimized with care by the composer
in order to optimize what is heard. Yet, because this is
an interesting part of making this installation, participants
would want to pay more attention to their brain activities
if they are allowed to manipulate the mapping of their own
EEG data.
In addition, we are planning to implement a real-time calculation of correlation for multiple EEGs in the next version. This feature will express the relationship between
participants much more clearly.
5.2 Towards Further Experiments for Musical
Communication

7. REFERENCES
[1] C. Small, Musicking: The Meanings of Performing and
Listening. Wesleyan University Press, 1998.
[2] ——, Music, Society, Education. Wesleyan University
Press, 1977.
[3] W. Benson, Beethoven’s Anvil: Music In Mind And
Culture. Basic Books, 2001.
[4] A. Lucier, “Music for solo performer,” cd, 1965, for
enormously amplified brain waves and percussion.

Different from the previous version of our work, which was
a BCI musical instrument, the participants in our current
work do not imagine the music directly. Rather, our installation is designed to form a place of music in a constitutive
way, and to immerse the participants in that place. The
acquisition of feedback such as listening to the sound and
watching the visual images will enhance that means of experience.
Furthermore, our latest work only deals with a neural
response to passive stimuli, while the previous work attempted to extract the proactive musical will from brain
activities. Considering a situation of singing with others,
it can be regarded that there is no singular subject, and occasionally the participants are identical to their group. In
other words, music is not only an expression by a subject,
but can be a media that connects more than one person. In
this sense, the main theme of our experimental work is the
human connection in music without the subject of expression, and this form of act might be the prototype of music.
We will continue this exploration in order to realize and
show a primitive form of music.
6. CONCLUSIONS
We developed a system for an installation piece through the
sonification and visualization of EEG with multiple participants 11 . One of the long-term goals of this project is to
realize a place that a primitive form of musical communication arises with the aid of neural technology, as described
in this paper. The system we have achieved has allowed us
to do a part of the experimental trial using products that are
commercially available for that objective. We hope that it
would be meaningful to share this process of development,
and that it will expand to similar experimental works.
Acknowledgments
This research was conducted as a joint research project
between the JST, ERATO, Okanoya Emotional Information Project (OEIP), Tokyo University of the Arts, and University of Tsukuba. The author would like to thank Tomasz
11

M. Rutkowski (University of Tsukuba) and all other members in the Brain dreams Music Project for advice related
to the experiments and analyses. This research is currently
supported by JST, PRESTO.

Recorded demonstration video of this installation is uploaded on the
project’s website.

[5] D. Rosenboom, “Method for producing sounds or light
flashes with alpha brain waves for artistic purposes,”
Leonardo, vol. Vol. 5, no. No. 2, pp. 141–145, 1972.
[6] S. Mann, J. Fung, and A. Garten, “Deconcert: Bathing
in the light, sound, and waters of the musical brainbaths,” in Proceedings of the 2007 International
Computer Music Conference, Copenhagen, Denmark,
2007, pp. vol.2, 204–211.
[7] S. L. Groux, J. Manzolli, and P. F. Verschure, “Disembodied and collaborative musical interaction in the
multimodal brain orchestra,” in Proceedings of the International Conference on New Interfaces for Musical
Expression, 2010.
[8] G. Leslie and T. Mullen, “Moodmixer : Eeg-based collaborative sonification,” in Proceedings of the International Conference on New Interfaces for Musical Expression, 2011, pp. 296–299.
[9] R. Hoshi-Shiba, K. Furukawa, and K. Okanoya, “Neural correlates of expectation of musical termination
structure or cadence,” NeuroReport, 2014, (in press).
[10] T. Hamano, T. M. Rutkowski, H. Terasawa,
K. Okanoya, and K. Furukawa, “Generating an
integrated musical expression with a brain–computer
interface,” in Proceedings of New Interfaces for
Musical Expression 2013, Korea, 2013, pp. 49–54.
[11] Q. Zhao, T. Rutkowski, L. Zhang, and A. Cichocki,
“Generalized optimal spatial filtering using a kernel
approach with application to eeg classification,”
Cognitive Neurodynamics, vol. 4, no. 4, pp. 355–358,
2010. [Online]. Available: http://dx.doi.org/10.1007/
s11571-010-9125-x
[12] N. Badcock, P. Mousikou, Y. Mahajan, P. de Lissa,
J. Thie, and G. McArthur, “Validation of the Emotiv
EPOC R EEG gaming system for measuring research
quality auditory ERPs,” PeerJ 1:e38, 2013.
[13] S. J. Luck, An Introduction to the Event-Related Potential Technique. A Bradford Book, 2005.

- 642 -

