1

Enhanced Motor Imagery Classification using
Riemannian Tangent Space Mapping
Shiu Kumar*, Kabir Mamun, and Alok Sharma

Abstract
Background:
Classification
of
electroencephalography (EEG) signals for motor imagery based
brain computer interface (MI-BCI) is an exigent task and
common spatial pattern (CSP) has been extensively explored for
this purpose. In this work, we focused on developing a new
framework for classification of EEG signals for MI-BCI.
New Method: We propose a single band CSP framework for
MI-BCI that utilizes the concept of tangent space mapping
(TSM) in the manifold of covariance matrices. The proposed
method is named CSP-TSM. Spatial filtering is performed on the
bandpass filtered MI EEG signal. Riemannian tangent space is
utilized for extracting features from the spatial filtered signal.
The TSM features are then fused with the CSP variance based
features and feature selection is performed using Lasso. Linear
discriminant analysis (LDA) is then applied to the selected
features and finally classification is done using support vector
machine (SVM) classifier.
Results: The proposed framework gives improved
performance for MI EEG signal classification in comparison with
several state-of-the-art-methods methods.
Comparison with existing methods: Experiments conducted
shows that the proposed framework reduces the overall
classification error rate for MI-BCI by 3.16% and 5.10% (for
BCI Competition III dataset IVa and BCI Competition IV
Dataset I, respectively) compared to the conventional CSP
method under the same experimental settings.
Conclusion: The proposed CSP-TSM method outperforms all
state-of-the-art methods and the computational complexity is less
compared to that of TSM method. Our proposed CSP-TSM
framework can be potentially used for developing improved MIBCI systems.
Index Terms‚ÄîBrain Computer Interface (BCI); Common
Spatial Pattern (CSP); Electroencephalography (EEG); Motor
Imagery (MI); Riemannian Distance, Tangent Space Mapping
(TSM).

I. INTRODUCTION

I

N a brain computer interface (BCI) system, direct
communication takes place between the brain and the
external devices without the involvement of peripheral nerves
and muscles in order to allow humans to interact with their
surroundings [1]. The electrical control signals generated by

This work was supported by the Faculty Research Committee of the
University of the South Pacific (grant no.: 6C482-1351-Acct-00) and the
College Research Committee of Fiji National University.
*S. Kumar is with the University of the South Pacific and Fiji National
University, Fiji. K. Mamun is with the University of the South Pacific, Fiji. A.
Sharma is with IIIS, Griffith University, Brisbane, Australia. (correspondence
e-mail: shiu.kumar@fnu.ac.fj).

the
brain
activity
are
measured
using
the
electroencephalogram (EEG) method. Motivated by the aim of
re-establishing independence and reducing social exclusion for
people with disabilities, BCI research has gained a vast range
of interest in this field. BCI has numerous emerging
applications such as applications for communication control
[2, 3], environment control [4], movement control [5, 6] and
neuro-rehabilitation [7-9]. Researchers have also concentrated
on developing BCI systems such as P300-based word typing
system [10], EEG controlled mouse [11], brain wave
controlled robots [12] and brain wave controlled wheelchair
for the disabled [13]. EEG signal has also been used for
biometric identification [14]. The major focus and emphasis of
BCI research is in the field of biomedical engineering [15-19].
Generally, in the realization of a BCI system the following
stages are involved: signal acquisition, preprocessing, feature
extraction, signal classification, and control interface. Several
methods are used for measuring and studying the brain waves
such as EEG, magnetoencephalogram (MEG), positron
emission tomography (PET) and single photon emission
computed tomography (SPECT). However, due to the facts
that EEG is non-invasive, has relatively low cost, supports real
time analysis and is portable makes it the most suitable
method for BCI systems [20, 21]. With technological
advancements, devices having low cost and reduced
complexity such as Neurosky Mindwave [22] and Emotiv
EPOC/EPOC+ headset [23] have been developed, which are
used in BCI research and applications.
Several techniques have been proposed with respect to
different aspects of the problem, the three major aspects being
filter band selection, spatial filter estimation and feature
extraction for optimal BCI performance. The conventional
CSP method utilized a single filter band. However, various
methods such as common spatio-spectral pattern (CSSP) [24],
common sparse spectral spatial pattern (CSSSP) [25], subband CSP (SBCSP) [26], filter band CSP (FBCSP) [27],
discriminative filter band CSP (DFBCSP) [28], sparse filter
band CSP (SFBCSP) [29] and filter band selection using
binary particle swarm optimization (BPSO) [30] have been
proposed. These methods have been proposed due to the fact
that the filter band that gives maximum discrimination
between different tasks for optimal classification varies from
subject to subject i.e. dependent on the users. CSP is applied
to the signals combined with its time delayed signals to obtain
the finite impulse response filter (FIR) coefficients in CSSP
(limited to single delay) and CSSSP. For each channel, a

2
different spectral pattern is found by CSSP whereas CSSSP
finds a spectral pattern that is common to all channels. In
SBCSP and FBCSP methods, the signal is decomposed into
sub-bands using multiple filter banks having different
frequency passband. CSP is then applied to each of the subbands separately. Recursive band elimination using support
vector machine (SVM) is performed for SBCSP method in
order to obtain the top ten sub-bands from the 24 sub-bands
(each having bandwidth of 4 Hz) with better discriminating
power. The selected sub-bands are then used for feature
extraction and classification (using SVM). On the other hand,
the FBCSP method utilizes all the sub-bands (having a
bandwidth of 4 Hz in the frequency range of 4-40 Hz).
However, feature selection using various techniques has been
employed to obtain the features that give optimal
discrimination resulting in better classification. DFBCSP
selects the best four sub-bands from 12 filter banks (each with
bandwidth of 4 Hz) using the fisher ratio calculated using
single channel C3, which provides a measure of the
discrimination between the two MI tasks. CSP features are
then extracted separately from these sub-bands and SVM
classifier is used for classification.
Recently, a SFBCSP [29] method that also uses multiple
filter bands is proposed, which optimizes the sparse patterns.
CSP on multiple overlapping frequency bands is performed,
and significant CSP features are then selected using
supervised technique. SVM classifier is then used for MI
classification using the selected features. Over the years,
Bayesian learning has also gained increased attention and it
has been used for feature selection in various applications
[31]. In [32], a sparse Bayesian learning of filter banks
(SBLFB) approach has been proposed for obtaining sparse
features that are used for classification using the SVM
classifier. The EEG signals were decomposed into multiple
sub-bands, CSP features were extracted and significant
features were selected using Bayesian learning. Furthermore,
in [30], a frequency band selection using BPSO is presented.
Unlike the DFBCSP method, the BPSO selects either one or
two best sub-bands producing optimal results. However, the
BPSO algorithm is computationally expensive and takes a
huge amount of time due to which the authors have only used
selected (25 and 14) channels of data for processing. These
methods recommend that feature extraction using sub-band
decomposition can improve the classification accuracy of MIBCI.
The measured EEG signals contain measurement noise and
spontaneous components related to other brain activities that
degrade the signal-to-noise ratio (SNR). Therefore, spatial
filtering is usually performed on the EEG signal in order to
discriminate between the overlapping activities and improve
the SNR. In spatial filtering, the multiple channel EEG signals
are linearly combined so that the unwanted sources are
obscured and those sources that are of interest are enhanced.
To this end, common spatial pattern (CSP) has been widely
explored [33] and used in BCI research. Several methods have
been proposed to optimize the temporal filter parameters for
better classification in order to prevent time consuming

manual tuning. In [34], an iterative spatio-spectral patterns
learning (ISSPL) method is proposed. In this method, the
classifier and spectral filters are parameterized simultaneously
to enhance the classification performance. A weighted
averaging method [35] has also been proposed for estimating
the covariance matrix for CSP. The number of training
samples available for MI tasks is usually small and can result
in the deterioration of the classification accuracy. To tackle
this problem, a regularized CSP (R-CSP) with aggregation has
been proposed by Lu et al. [36]. In this method, two
parameters (Œ≤, Œ≥) regularize the estimation of the covariance
matrix with the aim of reducing the estimation variance and
bias. In the regularization process, EEG samples from other
subjects (other than the subject of interest) are utilized. A
divergence based framework for CSP that also utilizes
information from other subjects is presented in [37].
In this study, we focus on the aspect of extracting features
from single frequency band that would further improve the
performance of BCI system. Barachant et al. [38] proposed
multiclass BCI classification by Riemannian geometry,
showing that it improves the MI classification accuracy.
However, they proposed to extract the spatial information
directly from the bandpass filtered EEG signal and as the
number of channels increases, it requires higher computational
complexity. To this end, we propose to utilize Riemannian
tangent space features extracted from the spatial filtered EEG
signal, which leads to an improved MI classification accuracy
and a reduction in the computational complexity of the
proposed method. Riemannian tangent space features are
combined with the CSP variance based features and feature
selection is performed. LDA [39] reduces the dimensionality
of the selected features and SVM classifier with linear kernel
is then used for classification. The proposed method is
validated on two publically available EEG dataset (BCI
Competition III dataset IVa and BCI Competition IV dataset
I), and compared with other related literature such as CSP,
FBCSP, DFBCSP, SFBCSP and SBLFB. Experimental results
show that the proposed method enhances the MI classification
accuracy.
The rest of the paper is organized as follows. Section II
presents the CSP method followed by the proposed CSP-TSM
framework for MI classification. The results and discussion
are presented in Section III and IV, respectively, while Section
V draws the conclusion and gives insight of some future
works.
II. CSP-TSM FOR MI CLASSIFICATION
Because existing competing methods such as FBCSP,
DFBCSP, SFBCSP and SBLFB uses multiple frequency
bands, the computational complexity of the system is higher in
comparison with that of if a single frequency band is utilized.
The proposed CSP-TSM method utilizes a single CSP based
filter such as the CSSP, CSSSP, and SPEC-CSP [40] methods.
This paper shows that a single frequency band relating to the
brain activities associated with MI-BCI tasks can be sufficient
to obtain optimal results.
In this section, the CSP-TSM algorithm for MI

3
classification is presented. The single bandpass filtered EEG
signal is transformed using the spatial filter, obtaining a lower
dimensional signal. Features are then extracted from the
spatial filtered signal using tangent space mapping of the
Riemannian distance. The features obtained after performing
TSM are then fused with the CSP variance based features.
Regression analysis using least absolute shrinkage and
selection operator (Lasso) is used for feature selection in order
to obtain the significant features. LDA is applied to the
selected features to reduce the dimensionality of the features.
SVM with linear kernel is then implemented for EEG signal
classification of MI tasks.
A. Feature Extraction using CSP
The CSP technique that was first used for detection of
abnormalities using EEG signal [41] has gained a wide
attention in the field of MI-BCI for feature extraction. CSP is
commonly used for transforming the signal to a new time
series that has maximum discrimination between different MI
tasks. Consider the two class problem having EEG samples
C xT
xn,1 and xn,2 ‚àà R , where n denotes the n-th trial, C is the
number of channels and T is the number of sample points. The
samples are bandpass filtered and it is assumed that the
samples have been centered. The normalized spatial
covariance matrix Œ£ of class l is given by (1), where Nl is the
number of trials in class l.

‚àël =

1
Nl

X n ,l X nT,l
‚àë
T
n =1 trace( X n ,l X n ,l )
Nl

(1)

Ô£´ var(Z ) Ô£∂
Ô£∑
i
Fi = logÔ£¨ 2 m
Ô£¨
Ô£∑
var(
)
Z
n Ô£∏
Ô£≠ ‚àën =1

B. Single Band CSP with TSM (CSP-TSM)
The CSP-TSM framework utilizes the theory of Riemannian
geometry in the manifold of covariance matrices [38] and uses
the tangent space vectors as features. Fig. 1 illustrates the
proposed CSP-TSM framework that utilizes a single frequency
2m x T x N

obtained after spatial
band. The projected data XÀÜ ‚àà R
filtering using (5) is utilized for further processing, where N is
the total number of trials. The normalized covariance matrix

Œ£i ‚àà R

2m x 2 m

wT ‚àë1 w
(2)
s.t. w 2 = 1
w
wT ‚àë 2 w
Solving the generalized eigenvalue problem in (3) will result
in the maximization of the Rayleigh quotient J(w).
max J ( w) =

‚àë1 w = Œª ‚àë 2 w

(3)

The spatial filter matrix W is then obtained using (4), where
P is the whitening transformation matrix and U is matrix
containing the eigenvectors. In this paper, it is assumed that
the eigenvalues and their corresponding eigenvectors are
arranged in descending order.

W =U P
T

(4)

The CSP spatial filter Wcsp is then formed by selecting the
first and last m columns of W. The transformation Z of a given
EEG sample X is thus obtained using (5).
T
Z = WCSP
X

for each projected sample XÃÇ i is computed using

(7), where Œ£i represents the sample covariance matrix (SCM)
of the spatial filtered data for the i-th sample.

‚àëi =

T
XÀÜ i XÀÜ i
T
trace( XÀÜ XÀÜ )
i

(7)

i

Œì (t ) : [0,1] ‚Üí Œ£( n ) ‚àà R

Consider

2m x 2m

to

be

any

differentiable path between Œì (0) = Œ£1 and Œì (1) = Œ£ 2 , where
Œ£ (n ) is symmetric positive-definite (SPD) matrices (the space

of which is a differentiable Riemannian manifold (M)).
Equation (8) gives the length of Œì (t ). The geodesic is the
curve with minimum length that connects the two points on
the manifold. The length of this curve gives the Riemannian
distance between the two points.

L(Œì(t ) ) = ‚à´ || Œì(t ) ||Œì (t ) dt

In CSP, the function in (2) is maximized in order to get
maximum separability between the variance of the two
classes, where w ‚àà R C is the spatial filter and || ‚ãÖ ||2 denotes the
l2 norm.

(6)

1

(8)

0

Classification algorithms such as SVM, LDA and Neural
Networks cannot be implemented directly in the Riemannian
manifold as they are based on projections into hyper-planes.
Thus each of the SCM is mapped into the tangent space
located at the Riemannian mean Œ£ of the whole set of SCM
matrices. The Riemannian mean is given by (9), where R(¬∑)
operator denotes computation of Riemannian mean and
i = 1,..., N . Due to the fact that there is no closed-form
expression for computing the Riemannian mean, an efficient
iterative algorithm given in [42] has been adopted.
N

Œ£ = R (Œ£ i ) = arg min ‚àë Œ¥ R2 (Œ£, Œ£ i )
Œ£ ‚ààŒ£(n)

(9)

i =1

The Riemannian distance Œ¥ R can be obtained using (10),
where upper(¬∑) means taking the upper triangular part of the
symmetric matrix, vectorizing it and applying 2 weight to the
out-of-diagonal elements [43], the logarithmic mapping

Log Œ£ (Œ£ i ) is given by (11) and

si is a vector of the normalized

tangent space.
(5)

The variance based CSP feature vector is then formed as FCSP
= [F1, F2, ‚Ä¶,F2m], where Fi is given by (6) with var(Zm)
denoting the variance of m-th row of Z.

Œ¥ R (Œ£, Œ£ i ) = || Log Œ£ (Œ£ i ) ||Œ£
= || upper (Œ£ ‚àí1 2 Log Œ£ (Œ£ i )Œ£ ‚àí1 2 ) ||2 = || s i ||2

(10)

4
Training Phase

Test Phase

Multi-Channel
EEG Signal
(Training Set)

Multi-Channel
EEG Signal
(Test Set)

Bandpass
Filter

Bandpass
Filter

CSP

Spatial filter (WCSP)

Transformed
Training Data
Compute
Covariance

Feature
Extraction

Spatial
filtering

Compute
Covariance

Feature
Extraction

Compute
Riemannian Mean
of Covariance
Riemannian Mean Covariance Matrix
TSM

TSM
upper(Riemannian
Distance)

upper(Riemannian
Distance)
Fusion

Fusion

Indices
Feature Selection

Select Features
using Indices

LDA

Dimensionality
Reduction

SVM
Training

Transformed

ùëáùëá
ùê∏ùê∏ÔøΩùëñùëñùëáùëáùëáùëáùëáùëá
=Data
ùëäùëäùê∂ùê∂ùê∂ùê∂ùê∂ùê∂
xùê∏ùê∏ùëñùëñùëáùëáùëáùëáùëáùëá
Test

Parameters
Œ± ,b

SVM
Classification
Class ID

Fig. 1. Illustration of the proposed single band CSP-TSM framework.

Log Œ£ (Œ£ i ) = Œ£1 2 log(Œ£ ‚àí1 2 Œ£ i Œ£ ‚àí1 2 ) Œ£1 2

(11)

Therefore, each of the SCM Œ£i is mapped into the tangent
space resulting in a set of 2 m( 2 m + 1) / 2 dimensional vectors

s i . These vectors si are used as the tangent space features in
our proposed framework.
C. Feature Selection and Classification
The variance based CSP features FCSP are concatenated with

as Lasso estimate [44] given by (12) in order to obtain
significant features, where u is the sparse vector that is to be
learned, Œª is the nonnegative regularization parameter that
controls the sparsity of u, and y ‚àà R is the vector consisting
of the target class labels.
N

1
u = arg min || Fu ‚àí y ||22 +Œª || u ||1
2
u

(12)

The expression in (12) is an optimization problem and for
solving
this the coordinate descent algorithm [45] has been
2
the tangent space features s iùê∏ùê∏to‚ààform
ùëÖùëÖùê∂ùê∂ x ùëáùëáax ùëÅùëÅ2 m + 3m dimensional
adopted. The optimized sparse vector u obtained is used for
feature vector F. However, the success of any MI-BCI selecting the features. Top d features in F corresponding to
ùê∂ùê∂ x 2m
ùëäùëäùê∂ùê∂ùê∂ùê∂ùê∂ùê∂
depends largely on the extracted features. A good selection
of ‚àà ùëÖùëÖ the largest d values in u are selected to form an optimized
2ùëöùëöx ùëáùëá
features will result in an improvement in ùê∏ùê∏ÔøΩthe
classification
feature set Fsel containing the significant features. LDA is
ùëñùëñ ‚àà ùëÖùëÖ
performance of MI tasks for BCI applications. Thus we
applied to further reduce the dimensionality of the optimized
employ feature selection using sparse regression model known
Œ£ùëñùëñ ‚àà ùëÖùëÖ2ùëöùëöx 2ùëöùëö

5

Ô£´ wT S w Ô£∂
wFDA = arg max Ô£¨Ô£¨ T B Ô£∑Ô£∑ = SW‚àí1 ( ¬µ1 ‚àí ¬µ 2 )
w Ô£≠ w SW w Ô£∏

(14)

The features FLDA obtained after applying LDA are used for
training the SVM classifier using a linear kernel. The trained
SVM classifier is then used to classify the test samples.
III. RESULTS
A. Description of Data
The BCI Competition III dataset IVa [46] and BCI
Competition IV dataset I [47], available publicly have been
used for evaluating the proposed method. The BCI
Competition III dataset IVa contains the EEG signals recorded
from five subjects labeled aa, al, av, aw, and ay performing
two different (right hand and left foot) MI tasks. 118 channels
at positions of the extended international 10/20 system [48]
were used for measuring the EEG signal, sampled at a rate of
1000 Hz. The dataset contains a total of 280 trials for each
subject with equal number of trials for each task. The data
provided was bandpass filtered with passband of 0.05-200 Hz.
The down-sampled data at 100 Hz is used. A detail description
of
the
dataset
can
be
found
at
http://www.bbci.de/competition/iii/.
The BCI Competition IV dataset I contains 59 channels of
real long-term EEG signals recorded for left hand, and right
hand MI tasks acquired from 7 healthy subjects (named a to
g). The down sampled signal at 100 Hz has been used, which
contains 200 trials for each subject with equal number of each
type of MI tasks. A detail description of the dataset can be
found online at [http://www.bbci.de/competition/iv/].

C. Analysis of the CSP-TSM framework with TSM and CSP
methods
Sparse regression has been exploited in this study and a
properly determined regularization parameter Œª leads to an
optimal learned sparse vector u from (12). The sparse vector u
Subject aa
0.4
0.3

Values of u

(13)

0.2
0.1
0
0

5

10

15

20

25

20

25

Feature Index

Subject al
0.4
0.3

Values of u

T
FLDA = wLDA
Fsel

butterworth bandpass filter having passband of 7-30 Hz. The
parameter m used was also chosen out of {1,...,10} in advance.
The value of m = 3 has been adopted as it gave the maximum
classification accuracy for all subjects.
The parameter Œª in (12) was chosen out of {0.01,...,0.99}
using a 10-fold cross validation. Fig. 2 presents an example of
the effect of varying Œª on the mean squared error for subject
aa. The value of Œª selected can be any value between the
points circled in blue and green. Similar result was obtained
for all other subjects and thus the value of Œª = 0.15 have been
used.

0.2
0.1
0
0

5

10

15

Feature Index
Subject av
0.4
0.3

Values of u

feature set using (13), where wLDA is the LDA transformation
matrix obtained using (14), in which ¬µl is the mean of class l,
and SB and SW are the between-class and within-class scatter
matrices, respectively.

0.2
0.1
0
0

5

10

15

20

25

20

25

Feature Index

Subject aw
0.4
0.3

Values of u

B. Experimental Setup
In this study, data between 0.5 seconds and 2.5 seconds (i.e.
200 sample points) after the visual cue has been extracted for
processing [49]. The data was further bandpass filtered using a

0.2
0.1
0

0.3

0

5

10

15

Feature Index
0.25

Subject ay
0.4
0.3

Values of u

MSE

0.2

0.15

0.1

0.2
0.1
0
0

0.05
10

-1

5

10

15

20

25

Feature Index

Lambda

Fig. 2. Cross-validated MSE of Lasso fit for one of the experimental runs for
subject aa.

Fig. 3. Example of sparse vectors learned by CSP-TSM method for each of
the five subjects in BCI Competition III dataset IVa.

6
variance based CSP features and TSM features obtained from
spatially filtered data.

Subject a

Values of u

0.3

0.2

0.1

0
0

5

10

15

20

25

20

25

20

25

20

25

20

25

20

25

Feature Index

Subject b

Values of u

0.3

0.2

0.1

0
0

5

10

15

Feature Index

Subject c

Values of u

0.3

0.2

0.1

0
0

5

10

15

Feature Index

Subject d

Values of u

0.3

0.2

0.1

0
0

5

10

15

Feature Index

Subject e

Values of u

0.3

0.2

0.1

0
0

5

10

15

Feature Index
Subject f
0.3

Values of u

0.2

An example of the sparse vectors learned by the proposed
CSP-TSM framework for each subject in the BCI Competition
III dataset IVa and BCI Competition IV dataset I are presented
in Fig. 3 and Fig. 4, respectively. The feature indices from 1 to
6 corresponds to the variance based CSP features while the
indices from 7 to 27 corresponds to the 21 TSM features
obtained from the spatially filtered data. The significant
features appeared at both the types of features used in this
study i.e. the CSP variance based features and TSM features.
It can be noted from Fig. 3 that the most significant feature for
subjects aa and ay were from the variance based CSP features.
On the other hand, for subjects al, av and aw the most
significant feature was from the TSM features. In Fig. 4, the
most significant feature for subjects d and g was from variance
based CSP features while for subjects a, b, c, e and f the most
significant feature was from TSM features. The significant
features selected were different for each of the subjects, which
is in agreement with the related literatures [28, 30, 32, 50]
(can be due to different skull size, skin thickness and due to
the fact that the way subjects think about the same task differs
from subject to subject). This indicates the reason for using
both types of features and explains the need for feature
selection in our proposed framework for enhanced MI
classification accuracy.
To compare the performance of the CSP-TSM framework
with the TSM and conventional CSP algorithm, we have
evaluated the classification performance of these methods
using selected 25 channels of data (from BCI Competition III
dataset IVa) as used in [30]. This is because the TSM
algorithm could not be run on the desktop personal computer
(Matlab ¬Æ on windows 7 with 6 GB Ram operating at 3.3
GHz) using all 118 channels of EEG signal as Matlab
becomes irresponsive and the computer freezes. The three
algorithms were run simultaneously so that all the classifiers
were built using the same set of training data and the results
evaluated exactly on the same set of test data for all the
methods. The results obtained are depicted in Fig. 5. For all
subjects except for subject aw, the CSP-TSM method
performs better while for subject aw, the best performance
was obtained using TSM method. It should be noted that on

0.1

100
0

5

10

15

Feature Index
Subject g
0.3

Values of u

0.2

Accuracy (%)

0

95
90
85

CSP

80

TSM

75

CSP-TSM

70
0.1

0
0

5

10

15

20

25

Subject

Feature Index

Fig. 4. Example of sparse vectors learned by CSP-TSM method for each of
the seven subjects in BCI Competition IV dataset I.

is utilized for selecting the significant features from the

Fig. 5. 10x10-fold cross validation accuracies for conventional CSP, TSM
and CSP-TSM methods using selected (25) channels for BCI Competition III
dataset IVa.

7
average the CSP-TSM method performs better than both the
conventional CSP and TSM methods by 1.73% and 1.17%,
respectively.
D. Analysis of the CSP-TSM framework with other competing
methods
In this section, the CSP-TSM framework is evaluated
against other competing methods. Table I and Table II shows
the 10x10-fold cross validation classification error rates of the
proposed CSP-TSM framework along with the conventional
CSP, FBCSP, DFBCSP, SFBCSP and SBLFB methods for the
two datasets. All the methods are evaluated under the same
experimental conditions using all channels of EEG data. For
the conventional CSP, a wide filter band of 7-30 Hz was
adopted while for FBCSP, DFBCSP and SFBCSP 17 filter
bands (sub-bands) with a bandwidth of 4 Hz overlapping each
other at a rate of 2 Hz was adopted from [28]. The
regularization parameter Œª for SFBCSP was determined using
the same procedure as mentioned earlier for CSP-TSM
framework. All methods employ SVM as the classifier. In
comparison with other competing methods; conventional CSP,
FBCSP, DFBCSP, SFBCSP and SBLFB, the proposed CSPTABLE I
10X10-FOLD CROSS VALIDATION CLASSIFICATION ERROR RATE (%) OF CSP,
FBCSP, DFBCSP, SFBCSP, SBLFB AND CSP-TSM METHODS,
RESPECTIVELY, USING BCI COMPETITION III DATASET IVA. FOR EACH
SUBJECT THE LOWEST ERROR IS MARKED IN BOLDFACE.
Subject
Method
Average
aa
al
av
aw
ay
21.00
3.86
28.29
10.36
3.86
13.47
CSP
¬± 5.31 ¬± 3.93 ¬± 7.46
¬± 5.10
¬± 4.11
¬± 5.18
FBCSP

17.14
¬± 8.19

1.29
¬± 1.88

30.36
¬± 8.23

6.50
¬± 4.55

5.07
¬± 4.68

12.07
¬± 5.51

DFBCSP

9.64
¬± 5.01

1.00
¬± 1.91

31.21
¬± 8.92

4.64
¬± 4.75

8.21
¬± 5.06

10.94
¬± 5.13

SFBCSP

18.43
¬± 8.26

1.64
¬± 1.36

29.93
¬± 6.44

9.29
¬± 8.58

12.79
¬± 5.96

14.41
¬± 5.57

SBLFB

18.71
¬± 7.45

1.36
¬± 2.03

29.64
¬± 9.98

6.57
¬± 4.47

12.36
¬± 7.22

13.73
¬± 6.23

CSP-TSM
(Proposed)

16.79
¬± 6.29

2.14
¬± 3.53

24.90
¬± 9.10

4.53
¬± 2.80

3.21
¬± 2.53

10.31
¬± 4.85

TABLE II
10X10-FOLD CROSS VALIDATION CLASSIFICATION ERROR RATE (%) OF CSP,
FBCSP, DFBCSP, SFBCSP, SBLFB AND CSP-TSM METHODS,
RESPECTIVELY, USING BCI COMPETITION IV DATASET I. FOR EACH
SUBJECT THE LOWEST ERROR IS MARKED IN BOLDFACE.
Subject
Method
a
b
c
d
e
f
g Average
13.2
42.8 43.7
22.4 18.0 22.5 7.10 24.2
CSP
¬± 8.1 ¬± 12.3 ¬± 11.3 ¬± 8.8 ¬± 9.7 ¬± 10.8 ¬± 5.1 ¬± 9.4
FBCSP

19.1
¬± 9.4

44.7 35.7
¬± 11.3 ¬± 9.6

22.2
¬± 9.0

14.0
¬± 9.1

19.6 6.9 23.2
¬± 8.6 ¬± 6.6 ¬± 9.1

DFBCSP

16.8
¬± 7.8

42.9
¬± 9.7

23.5
¬± 8.4

18.3
¬± 8.8

14.3 9.0 22.9
¬± 8.6 ¬± 5.1 ¬± 8.1

SFBCSP

17.4
¬± 5.9

45.3 43.0
¬± 6.6 ¬± 11.6

29.5 24.7 20.9 9.7 27.2
¬± 10.1 ¬± 10.3 ¬± 6.5 ¬± 5.0 ¬± 8.0

SBLFB

19.1
¬± 9.7

41.5 33.2
¬± 11.1 ¬± 12.5

11.5
¬± 7.9

11.6
¬± 6.9

21.2 5.9 20.6
¬± 9.0 ¬± 5.4 ¬± 9.4

CSP-TSM
(Proposed)

11.9
¬± 6.6

40.9 32.1
¬± 10.3 ¬± 8.7

15.7
¬± 7.9

9.8
¬± 5.8

14.1 7.8 19.1
¬± 7.1 ¬± 5.7 ¬± 7.5

35.2
¬± 8.5

TSM framework offers average error rate reductions of 3.16%,
1.76%, 0.63%, 4.10% and 3.42%, respectively for BCI
Competition III dataset IVa and 5.10%, 4.10%, 3.80%, 8.10%
and 1.50%, respectively for BCI Competition IV dataset I. Our
method outperforms all other state-of-the-art methods on
average while also obtaining the lowest classification error
rate for 3 out of 5 subjects (av, aw and ay) for BCI
Competition III dataset IVa and 5 out of 7 subjects (a, b, c, e
and f) for BCI Competition IV dataset I. Our proposed method
performed best for subject al of BCI Competition III dataset
IVa and subject g of BCI Competition IV dataset I, having
error rate of 2.14% and 7.8%, respectively. On the other hand,
as expected, the worst performance was noted for subject av
and subject b with error rate of 24.90% and 40.90%,
respectively (consistent with results of other methods as it
contains low quality signals).
IV. DISCUSSION
All the body activities including motor and muscle movement
are controlled by the brain, which is an essential part of the
human body. The message is firstly constructed in the brain
for every communication that is initiated. The human brain
contains over 100 billion neurons [51]. These neurons
communicate with each other producing different pattern of
electrical signals (generated due to electromagnetic activities
inside the brain) for different thoughts [52]. The function of a
BCI system is to capture the EEG signal and decode them for
different brain activities thus enabling a direct channel of
communication between the brain and the external devices
without the need for any muscular movement [53]. Neural
network have been widely used in various applications [54,
55] and has also been used for EEG signal classification [5658]. However, methods that use CSP [25-28, 50, 59-61] have
shown to be effective in MI EEG signal classification.
Although EEG signals of larger fragments are highly nonGaussian, up to 90 percent of short fragments of 4 seconds can
be considered as Gaussian [62, 63]. In this research, we have
used 2 second segments and therefore the EEG signals are
assumed to be Gaussian. This is shown by the fact that the
CSP method is able to perform well in MI EEG signal
classification. Thus, we have combined the power of CSP and
TSM to improve the performance of MI EEG signal
classification. We have employed Lasso estimate for feature
selection, however, other methods of feature selection [64]
could also be employed.
Research is also being carried out to improve the CSP
algorithm. In [65], a neural network-based optimal spatial
filter design method has been proposed. The spatial filter and
the classifier are trained simultaneously using a neural
network named spatial filter network (SFN). Methods have
also been proposed to optimize the classifier performance
[57]. The performance of CSP largely depends on the
frequency bands that are selected and as such research still
continues in finding the best frequency bands. In [32], a sparse
Bayesian learning approach for filter band selection (SBLFB)
is proposed to find significant features. Binary particle swarm
optimization has been proposed for selecting the filter bands
that contain the most significant features [30], while a subject
based feature extraction method has been proposed that uses

8
wavelet packet decomposition (WPD) together with CSP [66].
Therefore, implementing the proposed method with multiple

selected filter banks may further improve the classification
performance of the system at the cost of higher computational
time.

CSP

A. Comparison of feature distribution
To further compare the performance of the CSP-TSM
framework with the TSM and conventional CSP algorithm, we
have analyzed the distribution of the extracted features for
each of the methods. The distributions of the two most
significant features obtained by CSP, TSM and CSP-TSM
methods respectively from subject al is depicted in Fig. 6. If
we draw an imaginary non-linear line separating the two
clusters, the minimum number of misclassified samples
obtained for CSP, TSM, CSP-TSM and SBLFB methods from
Fig. 6 would be 16, 14, 12 and 16, respectively. Thus it can be
seen that CSP-TSM method achieved the maximum
discriminability of features. This explains the fact that the
CSP-TSM method outperforms the CSP and TSM methods.
The dataset used is from BCI Competition III and thus it may
or may not contain outliers. However, the overlap in the
feature points of CSP and TSM are in agreement with the
related literatures. It is shown in [38] that using Riemannian
distance to Riemannian mean as used by TSM is more
effective in providing relevant information about the class
membership than using Euclidean distance to its mean as used
by CSP. This explains the fact that the CSP-TSM approach is
able to attain a better separation as it uses the properties of
both CSP and TSM. It can be noted from Fig. 6 that some of
the feature points from one class appear to completely
resemble that of another class. This can be due to poor quality
of the signal recorded or possibility of an error made during
recording, for example the subject was actually performing
class 1 MI task during recording of class 2 MI task.
Supervised methods of training adopted in this research cannot

0

Value of best feature 2

-0.5
-1
-1.5
-2
-2.5
-3
-6

-5

-4

-3

-2

-1

0

Value of best feature 1
TSM
0.6

Value of best feature 2

0.4
0.2
0
-0.2
-0.4
-0.6
-5

-4

-3

-2

-1

0

Value of best feature 1

CSP-TSM
0.6

0.2
30

0

subject aa

-0.2

subject al

20

-0.4

Error (%)

Value of best feature 2

0.4

-0.6
-2

-1

0

1

subject av
subject aw
subject ay
average

10

2

Value of best feature 1
0

SBLFB

0

0

10

15

50

-1

subject a

40

subject b
subject c

-1.5

Error (%)

Value of best feature 2

-0.5

5

-2
-2.5

30

subject d
subject e

20

subject f

10

average

subject g

0

-3

0

-5

-4

-3

-2

-1

0

5

10

15

number of features selected

Value of best feature 1

Fig. 6. Distribution of two most significant features obtained by CSP, TSM,
and CSP-TSM, respectively, from subject al of BCI Competition III dataset
IVa.

Fig. 7. Misclassification error rates using different number of selected
features. Top: BCI Competition III dataset IVa. Bottom: BCI Competition IV
dataset I)

9
overcome this problem. Therefore, use of unsupervised
methods such as cluster methods [67-70] can be utilized to
overcome this problem and may further improve the
performance of the system.
B. Feature selection
The proposed CSP-TSM algorithm utilizes feature selection
of the fused CSP variance based features and TSM (from
spatially filtered data - CSP) features. We have employed
Lasso for selecting the significant features as it has performed
well in [29]. However, it requires the selection of the number
of features to be selected. We have conducted experiments to
select features in the range of 1 to 15 and the classification
accuracies obtained for BCI Competition III dataset IVa and
BCI Competition IV dataset I are shown in Fig. 7. From Fig.
7, it can be noted that using 10 selected features produced
optimal results and therefore, the top 10 significant features
have been used. LDA have been employed after feature
selection as in our previous work [71], we have shown that
using LDA improves the classification performance of the
system. Other approaches such as using only the TSM features
obtained from the spatially filtered data and applying principal
component analysis (PCA) or LDA have also been evaluated.
However, the proposed framework shown in Fig. 1 produced
optimal results and thus has been adopted. It is left as future
study to evaluate other feature selection methods such as
mutual information based feature selection [27] and sparse
Bayesian learning for feature selection [32], which have also
performed well in selecting the most significant features.
C. Comparison of computational complexity
The authors in [38] proposed to use TSM technique, which
directly depends on the covariance matrices of the EEG signal.
The TSM method is an unsupervised process and has the
ability to extract spatial information that is comparable to the
state-of-the-art CSP. Because the TSM method directly
depends on the covariance matrices, the computational
complexity of the system increases drastically when signal
from large number of EEG channels is used. In this case, a
channel selection algorithm will be required in order to select
the channels with most significant information. In this work,
we have proposed to use CSP to reduce the dimensionality of
the EEG signal and then apply TSM. In this way, the
computational complexity of the system is reduced drastically.
To evaluate the computational complexity of our proposed
method with that of TSM, the Big O Notation has been used.
Big O Notation has been widely used for evaluating the
computational complexity of an algorithm. The worst case
scenario is specifically defined by Big O. It can be used to
evaluate the execution time required by an algorithm. Table III
shows the computational complexity of CSP, TSM, and the
proposed CSP-TSM framework. It can be noted that the
computational complexity of the TSM method will increase as
a cubic function with respect to the number of channels of
EEG signal used. On the other hand, for the CSP and proposed
CSP-TSM method, the computational complexity would only
increase linearly. Thus, it is evident that the proposed CSPTSM method is computationally less expensive compared to
the TSM method. We did not take into account the training

TABLE III
COMPLEXITY OF TSM AND CSP-TSM METHODS (WHERE n IS THE NUMBER
OF CHANNELS).
Method

Complexity

CSP
TSM
CSP-TSM

O(n)
O(n3)
O(n)

phase for evaluating the computational complexity of the
methods as it can be performed offline.
Moreover, the state-of-the-art methods such as FBCSP,
DFBCSP, SFBCSP and SBLFB utilize multiple frequency
bands, whereas our method uses only a single frequency band
for achieving optimal results. The use of a single frequency
band compared to using multiple frequency bands makes our
system computationally less expensive.
V. CONCLUSION
This paper presents a new framework for MI classification
by utilizing two types of features; the variance based CSP
features and the TSM features of the spatially filtered data.
The proposed method selects the most significant features
from these two types of features. LDA is applied to the
selected features, which is then classified using the trained
SVM classifier. The proposed method has enhanced the
classification accuracy of BCI competition III dataset IVa and
BCI competition IV dataset I, and has outperformed all other
competing methods. We have also shown that the CSP-TSM
framework enhances the performance of TSM method while
also reducing the computational complexity of the TSM
method. Future research should aim to test the proposed
framework on a larger set of experimental data. Use of
multiple bands with appropriate sub-bands such as that of
FBCSP, DFBCSP, SFBCSP and SBLFB might further
improve the performance of the proposed CSP-TSM
framework. As future works, we will also investigate the use
of weighted voting scheme for MI EEG signal classification
using features from multiple filter banks.
CONFLICT OF INTEREST
The authors declare that there is no conflict of interest.
REFERENCES
[1]
[2]

[3]

[4]

[5]

L. F. Nicolas-Alonso and J. Gomez-Gil, "Brain Computer Interfaces, a
Review," Sensors, vol. 12, p. 1211, 2012.
A. K√ºbler, N. Neumann, J. Kaiser, B. Kotchoubey, T. Hinterberger, and
N. P. Birbaumer, "Brain-computer communication: Self-regulation of
slow cortical potentials for verbal communication," Archives of Physical
Medicine and Rehabilitation, vol. 82, pp. 1533-1539, November 2001.
S. C. Kleih, T. Kuafmann, C. Zickler, S. Halder, F. Leotta, F. Cincotti, et
al., "Out of the frying pan into the fire--the P300-based BCI faces realworld challenges.," Progress in Brain Research, vol. 194, pp. 27-46,
2011.
F. Cincotti, D. Mattia, F. Aloise, S. Bufalari, G. Schalk, G. Oriolo, et al.,
"Non-invasive brain‚Äìcomputer interface system: Towards its application
as assistive technology," Brain Research Bulletin, vol. 75, pp. 796-803,
April 2008.
D. J. McFarland, W. A. Sarnacki, and J. R. Wolpaw,
"Electroencephalographic (EEG) control of three-dimensional
movement," Journal of Neural Engineering, vol. 7, p. 036007, May
2010.

10
[6]

[7]

[8]

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]
[23]
[24]

[25]

[26]

J. R. Wolpaw and D. J. McFarland, "Control of a two-dimensional
movement signal by a noninvasive brain-computer interface in humans,"
Proceedings of the National Academy of Sciences of the United States of
America, vol. 101, pp. 17849-17854, 2004.
A. Ramos-Murguialday, D. Broetz, M. Rea, L. L√§er, √ñ. Yilmaz, F. L.
Brasil, et al., "Brain‚Äìmachine interface in chronic stroke rehabilitation:
A controlled study," Annals of Neurology, vol. 74, pp. 100-108, 2013.
M. D. Serruya, "Bottlenecks to clinical translation of direct braincomputer interfaces," Frontiers in Systems Neuroscience, vol. 8, p. 226,
2014.
S. Silvoni, A. Ramos-Murguialday, M. Cavinato, C. Volpato, G. Cisotto,
A. Turolla, et al., "Brain-Computer Interface in Stroke: A Review of
Progress," Clinical EEG and Neuroscience, vol. 42, pp. 245-252,
October 2011.
F. Akram, M. K. Metwally, H. Hee-Sok, J. Hyun-Jae, and K. Tae-Seong,
"A novel P300-based BCI system for words typing," in Brain-Computer
Interface (BCI), 2013 International Winter Workshop on, 2013, pp. 2425.
M. H. Alomari, A. AbuBaker, A. Turani, A. M. Baniyounes, and A.
Manasreh, "EEG Mouse:A Machine Learning-Based Brain Computer
Interface," International Journal of Advanced Computer Science and
Applications, vol. 5, pp. 193-198, 2014.
S. Ramesh, M. G. Krishna, and M. Nakirekanti, "Brain Computer
Interface System for Mind Controlled Robot using Bluetooth,"
International Journal of Computer Applications, vol. 104, pp. 20-23,
October 2014.
R. S. Naveen and A. Julian, "Brain computing interface for wheel chair
control," in Fourth International Conference on Computing,
Communications and Networking Technologies (ICCCNT), 2013, pp. 15.
D. La Rocca, P. Campisi, and J. Sole-Casals, "EEG based user
recognition using BUMP modelling," in International Conference of the
Biometrics Special Interest Group (BIOSIG), 2013, pp. 1-12.
S. Jirayucharoensak, S. Pan-Ngum, and P. Israsena, "EEG-Based
Emotion Recognition Using Deep Learning Network with Principal
Component Based Covariate Shift Adaptation," The Scientific World
Journal, vol. 2014, p. 10, 2014.
P. P. Acharjee, R. Phlypo, L. Wu, V. D. Calhoun, and T. Adali,
"Independent Vector Analysis for Gradient Artifact Removal in
Concurrent EEG-fMRI Data," IEEE Transactions on Biomedical
Engineering, vol. 62, pp. 1750-1758, 2015.
A. Sohrabpour, Y. Lu, P. Kankirawatana, J. Blount, H. Kim, and B. He,
"Effect of EEG electrode number on epileptic source localization in
pediatric patients," Clinical Neurophysiology, vol. 126, pp. 472-480,
2015.
H. Woehrle, M. M. Krell, S. Straube, S. K. Kim, E. A. Kirchner, and F.
Kirchner, "An Adaptive Spatial Filter for User-Independent Single Trial
Detection of Event-Related Potentials," IEEE Transactions on
Biomedical Engineering, vol. 62, pp. 1696-1705, 2015.
T. Yu, J. Xiao, F. Wang, R. Zhang, Z. Gu, A. Cichocki, et al.,
"Enhanced Motor Imagery Training Using a Hybrid BCI With
Feedback," IEEE Transactions on Biomedical Engineering, vol. 62, pp.
1706-1717, 2015.
Z. Cheng, Y. Kimura, H. Higashi, and T. Tanaka, "A simple platform of
brain-controlled mobile robot and its implementation by SSVEP," in
International Joint Conference on Neural Networks (IJCNN), 2012, pp.
1-7.
D. J. McFarland and J. R. Wolpaw, "Brain-Computer Interface
Operation of Robotic and Prosthetic Devices," Computer, vol. 41, pp.
52-56, 2008.
(27
January).
Neurosky:
EEG
Headsets.
Available:
http://store.neurosky.com/collections/eeg-headsets
(27 January). Emotiv eStore: EPOC Headset. Available:
https://emotiv.com/store/
S. Lemm, B. Blankertz, G. Curio, and K. Muller, "Spatio-spectral filters
for improving the classification of single trial EEG," IEEE Transactions
on Biomedical Engineering, vol. 52, pp. 1541-1548, 2005.
G. Dornhege, B. Blankertz, M. Krauledat, F. Losch, G. Curio, and K. R.
Muller, "Combined Optimization of Spatial and Temporal Filters for
Improving Brain-Computer Interfacing," IEEE Transactions on
Biomedical Engineering, vol. 53, pp. 2274-2281, 2006.
Q. Novi, G. Cuntai, T. H. Dat, and X. Ping, "Sub-band Common Spatial
Pattern (SBCSP) for Brain-Computer Interface," in 3rd International
IEEE/EMBS Conference on Neural Engineering, 2007, pp. 204-207.

[27] K. K. Ang, Z. Y. Chin, H. Zhang, and C. Guan, "Filter Bank Common
Spatial Pattern (FBCSP) in Brain-Computer Interface," in IEEE
International Joint Conference on Neural Networks (IEEE World
Congress on Computational Intelligence), Hong Kong, 2008, pp. 2390 2397.
[28] K. P. Thomas, G. Cuntai, C. T. Lau, A. P. Vinod, and A. Kai Keng, "A
New Discriminative Common Spatial Pattern Method for Motor
Imagery Brain Computer Interfaces," IEEE Transactions on Biomedical
Engineering, vol. 56, pp. 2730-2733, 2009.
[29] Y. Zhang, G. Zhou, J. Jin, X. Wang, and A. Cichocki, "Optimizing
spatial patterns with sparse filter bands for motor-imagery based brain‚Äì
computer interface," Journal of Neuroscience Methods, vol. 255, pp. 8591, November 2015.
[30] Q. Wei and Z. Wei, "Binary particle swarm optimization for frequency
band selection in motor imagery based brain-computer interfaces," BioMedical Materials and Engineering, vol. 26, pp. S1523-S1532, 2015.
[31] H. I. Suk and S. W. Lee, "A Novel Bayesian Framework for
Discriminative Feature Extraction in Brain-Computer Interfaces," IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 35, pp.
286-299, 2013.
[32] Y. Zhang, Y. Wang, J. Jin, and X. Wang, "Sparse Bayesian Learning for
Obtaining Sparsity of EEG Frequency Bands Based Feature Vectors in
Motor Imagery Classification," International Journal of Neural Systems,
vol. 27, p. 1650032, 2017.
[33] B. Blankertz, R. Tomioka, S. Lemm, M. Kawanabe, and K. R. Muller,
"Optimizing Spatial filters for Robust EEG Single-Trial Analysis,"
Signal Processing Magazine, IEEE, vol. 25, pp. 41-56, 2008.
[34] W. Wei, G. Xiaorong, H. Bo, and G. Shangkai, "Classifying Single-Trial
EEG During Motor Imagery by Iterative Spatio-Spectral Patterns
Learning (ISSPL)," IEEE Transactions on Biomedical Engineering, vol.
55, pp. 1733-1743, 2008.
[35] N. Tomida, T. Tanaka, S. Ono, M. Yamagishi, and H. Higashi, "Active
Data Selection for Motor Imagery EEG Classification," IEEE
Transactions on Biomedical Engineering, vol. 62, pp. 458-467, 2015.
[36] L. Haiping, E. How-Lung, G. Cuntai, K. N. Plataniotis, and A. N.
Venetsanopoulos, "Regularized Common Spatial Pattern With
Aggregation for EEG Classification in Small-Sample Setting," IEEE
Transactions on Biomedical Engineering, vol. 57, pp. 2936-2946, 2010.
[37] W. Samek, M. Kawanabe, and K. R. Muller, "Divergence-Based
Framework for Common Spatial Patterns Algorithms," IEEE Reviews in
Biomedical Engineering, vol. 7, pp. 50-72, 2014.
[38] A. Barachant, S. Bonnet, M. Congedo, and C. Jutten, "Multiclass Brain‚Äì
Computer Interface Classification by Riemannian Geometry," IEEE
Transactions on Biomedical Engineering vol. 59, pp. 920-928, April
2012.
[39] A. Sharma and K. K. Paliwal, "A deterministic approach to regularized
linear discriminant analysis," Neurocomputing, vol. 151, Part 1, pp. 207214, March 2015.
[40] A. Ashok, A. K. Bharathan, V. R. Soujya, and P. Nandakumar,
"Tikhonov regularized spectrally weighted common spatial patterns," in
International Conference on Control Communication and Computing
(ICCC), 2013, pp. 315-318.
[41] Z. J. Koles, "The quantitative extraction and topographic mapping of the
abnormal components in the clinical EEG," Electroencephalography
and Clinical Neurophysiology, vol. 79, pp. 440-447, December 1991.
[42] P. T. Fletcher and S. Joshi, "Principal Geodesic Analysis on Symmetric
Spaces: Statistics of Diffusion Tensors," in Computer Vision and
Mathematical Methods in Medical and Biomedical Image Analysis, ed
Berlin, Heidelberg: Springer Berlin Heidelberg, 2004, pp. 87-98.
[43] O. Tuzel, F. Porikli, and P. Meer, "Pedestrian Detection via
Classification on Riemannian Manifolds," IEEE Transactions on Pattern
Analysis and Machine Intelligence, vol. 30, pp. 1713-1727, 2008.
[44] R. Tibshirani, "Regression Shrinkage and Selection Via the Lasso,"
Journal of the Royal Statistical Society, Series B, vol. 58, pp. 267-288,
1996.
[45] J. Friedman, T. Hastie, and R. Tibshirani, "Regularization paths for
generalized linear models via coordinate descent," Journal of Statistical
Software, vol. 33, 2010.
[46] G. Dornhege, B. Blankertz, G. Curio, and K. Muller, "Boosting bit rates
in noninvasive EEG single-trial classifications by feature combination
and multiclass paradigms," IEEE Transactions on Biomedical
Engineering, vol. 51, pp. 993-1002, 2004.
[47] B. Blankertz, G. Dornhege, M. Krauledat, K.-R. M√ºller, and G. Curio,
"The non-invasive Berlin Brain‚ÄìComputer Interface: Fast acquisition of

11

[48]
[49]

[50]

[51]

[52]

[53]

[54]

[55]

[56]

[57]

[58]

[59]

[60]

[61]

[62]

[63]

[64]

[65]

[66]

[67]

[68]

effective performance in untrained subjects," NeuroImage, vol. 37, pp.
539-550, 8/15/ 2007.
T. C. T. Limited, "10/20 System Positioning," ed. Hong Kong, 2012.
L. Song and J. Epps, "Classifying EEG for brain-computer interfaces:
learning optimal filters for dynamical system features," presented at the
Proceedings of the 23rd international conference on Machine learning,
Pittsburgh, Pennsylvania, USA, 2006.
A. S. Aghaei, M. S. Mahanta, and K. N. Plataniotis, "Separable
Common Spatio-Spectral Patterns for Motor Imagery BCI Systems,"
IEEE Transactions on Biomedical Engineering, vol. 63, pp. 15-29, 2016.
S. Herculano-Houzel, "The Human Brain in Numbers: A Linearly
Scaled-up Primate Brain," Frontiers in Human Neuroscience, vol. 3, p.
31, September 2009.
M. A. Jatoi, N. Kamel, A. S. Malik, I. Faye, and T. Begum, "A survey of
methods used for source localization using EEG signals," Biomedical
Signal Processing and Control, vol. 11, pp. 42-52, May 2014.
J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and T.
M. Vaughan, "Brain‚Äìcomputer interfaces for communication and
control," Clinical Neurophysiology, vol. 113, pp. 767-791, 2002.
J. S. Chiu, Y. C. Li, F. C. Yu, and Y. F. Wang, "Applying an artificial
neural network to predict osteoporosis in the elderly," Studies in Health
Technologies and Informatics, vol. 124, pp. 609-14, 2006.
J. S. Chiu, C. F. Chong, Y. F. Lin, C. C. Wu, Y. F. Wang, and Y. C. Li,
"Applying an Artificial Neural Network to Predict Total Body Water in
Hemodialysis Patients," American Journal of Nephrology, vol. 25, pp.
507‚Äì513, 2005.
M. M. El Bahy, M. Hosny, W. A. Mohamed, and S. Ibrahim, "EEG
Signal Classification Using Neural Network and Support Vector
Machine in Brain Computer Interface," in Proceedings of the
International Conference on Advanced Intelligent Systems and
Informatics, A. E. Hassanien, K. Shaalan, T. Gaber, A. T. Azar, and M.
F. Tolba, Eds., ed Cham: Springer International Publishing, 2017, pp.
246-256.
Y. Ma, X. Ding, Q. She, Z. Luo, T. Potter, and Y. Zhang, "Classification
of Motor Imagery EEG Signals with Support Vector Machines and
Particle Swarm Optimization," Computational and Mathematical
Methods in Medicine, vol. 2016, p. 8, 2016.
S. Kumar, A. Sharma, K. Mamun, and T. Tsunoda, "A Deep Learning
Approach for Motor Imagery EEG Signal Classification," presented at
the 3rd Asia-Pacific World Congress on Computer Science and
Engineering, Denarau Island, Fiji, 2016.
W. Wu, Z. Chen, X. Gao, Y. Li, E. N. Brown, and S. Gao, "Probabilistic
Common Spatial Patterns for Multichannel EEG Analysis," Pattern
Analysis and Machine Intelligence, IEEE Transactions on, vol. 37, pp.
639-653, 2015.
D. Enzeng, L. Liting, and C. Chao, "Improved common spatial pattern
for brain-computer interfacing," in IEEE International Conference on
Mechatronics and Automation (ICMA), 2015, pp. 2112-2116.
H. Higashi and T. Tanaka, "Simultaneous Design of FIR Filter Banks
and Spatial Patterns for EEG Signal Classification," IEEE Transactions
on Biomedical Engineering, vol. 60, pp. 1100-1110, 2013.
F. F. Gonen and G. V. Tcheslavski, "Techniques to Assess Stationarity
and Gaussianity of EEG: An Overview," International Journal
Bioautomotion, vol. 16, pp. 135-142, 2012.
J. A. McEwen and G. B. Anderson, "Modeling the Stationarity and
Gaussianity of Spontaneous Electroencephalographic Activity," IEEE
Transactions on Biomedical Engineering, vol. BME-22, pp. 361-369,
1975.
A. Sharma, K. K. Paliwal, S. Imoto, and S. Miyano, "A feature selection
method using improved regularized linear discriminant analysis,"
Machine Vision and Applications, vol. 25, pp. 775-786, 2014.
A. Yuksel and T. Olmez, "A Neural Network-Based Optimal Spatial
Filter Design Method for Motor Imagery Classification," PLOS ONE,
vol. 10, p. e0125039, 2015.
B. Yang, H. Li, Q. Wang, and Y. Zhang, "Subject-based feature
extraction by using fisher WPD-CSP in brain‚Äìcomputer interfaces,"
Computer Methods and Programs in Biomedicine, vol. 129, pp. 21-28,
June 2016.
A. Sharma, D. Shigemizu, K. A. Boroevich, Y. L√≥pez, Y. Kamatani, M.
Kubo, et al., "Stepwise iterative maximum likelihood clustering
approach," BMC Bioinformatics, vol. 17, pp. 1-14, 2016.
D. Charalampidis, "A Modified K-Means Algorithm for Circular
Invariant Clustering," IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 27, pp. 1856-1865, 2005.

[69] T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. Piatko, R. Silverman,
and A. Y. Wu, "An efficient k-means clustering algorithm: analysis and
implementation," IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. 24, pp. 881-892, 2002.
[70] A. Sharma, K. Boroevich, D. Shigemizu, Y. Kamatani, M. Kubo, and T.
Tsunoda, "Hierarchical Maximum Likelihood Clustering Approach,"
IEEE Transactions on Biomedical Engineering, vol. 64, pp. 112-122,
2017.
[71] S. Kumar, R. Sharma, A. Sharma, and T. Tsunoda, "Decimation Filter
with Common Spatial Pattern and Fishers Discriminant Analysis for
Motor Imagery Classification " presented at the IEEE World Congress
on Computational Intelligence, Vancouver, Canada, 2016.

