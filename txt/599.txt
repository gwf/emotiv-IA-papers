Application of Cepstrum Analysis and Linear
Predictive Coding for Motor Imaginary Task
Classification
Shiu Kumar1,2, Alok Sharma2,3,4, Kabir Mamun2, Tatsuhiko Tsunoda4,5,6
1

Department of Electronics Engineering, Fiji National University, Suva, Fiji
School of Engineering & Physics, University of the South Pacific, Suva, Fiji
3
Institute for Integrated and Intelligent Systems (IIIS), Griffith University, Brisbane, Australia
4
RIKEN Center for Integrative Medical Sciences, Yokohama 230-0045, Japan
5
CREST, JST, Yokohama 230-0045, Japan
6
Medical Research Institute, Tokyo Medical and Dental University, Tokyo 113-8510, Japan
2

shiu.kumar@fnu.ac.fj
Abstract—In
this
paper,
classification
of
electroencephalography (EEG) signals of motor imaginary
tasks is studied using cepstrum analysis and linear predictive
coding (LPC). The Brain-Computer Interface (BCI)
competition III dataset IVa containing motor imaginary tasks
for right hand and foot of five subjects are used. The data was
preprocessed by applying whitening and then filtering the
signal followed by feature extraction. A random forest
classifier is then trained using the cepstrum and LPC features
to classify the motor imaginary tasks. The resulting
classification accuracy is found to be over 90%. This research
shows that concatenating appropriate different types of
features such as cepstrum and LPC features hold some
promise for the classification of motor imaginary tasks, which
can be helpful in the BCI context.
Keywords—BCI; cepstrum analysis; EEG; filetring; LPC;
random forest.

I. INTRODUCTION
With the increasing number of research in the BCI field,
understanding of the brain waves is gaining huge
importance. BCI or Brain-Machine Interface (BMI) and its
application has become one of the hot research topics with
the advances in technology aiming to make lives of people
easier. A BCI system allows to communicate with others or
to generate control signals for controlling devices such as
machines, electric wheelchair [1, 2], artificial limbs or
robots [3-6] by utilizing the brain's neural activity without
requiring any muscle control or direct physical movement
[7-10]. The major focus and emphasis of BCI research is in
the field of biomedical engineering [11-15].
BCI could be beneficial in restoring valuable functions
of severely disable people. The first BCI application was
developed in 1964 [16] by Grey Walter. The application
used EEG recordings for controlling a slide projector. With
technological advancements, devices having low cost and
reduced complexity such as Neurosky Mindwave [17]
device and Emotiv EPOC/EPOC+ headset [18] have been

developed, which are widely accepted and used in BCI
research and applications.
BCI systems based on EEG signal have gained
widespread interest due to their potential uses. The EEG
signal is recorded using non-invasive sensors making it
safer and easy to use. However, the EEG signal is
contaminated by other noises such as Electrocardiogram
(ECG), Electrooculogram (EOG) and Electromyogram
(EMG). Adaptive filters and blind source separation (BSS)
techniques [19, 20] can be utilized to effectively remove the
EOG and ECG artifacts. For the removal of muscular
artifacts, researchers have explored the use of ICA [21-23],
a BSS technique.
A BCI system usually involves these processes: data
acquisition, preprocessing, feature extraction and
classification (for the purpose of generating control signals).
Preprocessing is done on the acquired signal to remove the
noise/artifacts. For feature extraction, a number of feature
extraction techniques such as power spectral density (PSD),
R (ratio of α and β activities) [24], Common Spatial Pattern
(CSP) [25, 26], statistical features, Self-Organizing Maps
(SOM), Fractal Dimension (FD), correlation, Granger
causality, spectral coherence [27] and information entropy
[28, 29] have been studied. A number of classifiers such as
support vector machine (SVM) [24, 30-36], K-Nearest
Neighbors (KNN) [37-39], Random Forest (RF) [40], etc.
have been used. SVM and Linear classifiers [41-44] have
also been widely used for other applications.
All the above research works have contributed positively
to the field of BCI. However, to the authors knowledge no
research has been carried out to study the use of cepstrum
and LPC features for EEG signal classification of motor
imaginary tasks. In this research, the widely used speech
recognition feature extraction methods; cepstrum analysis
and LPC will be studied and applied for the classification of
EEG signals. A random forest classifier will be used for
classification. Various feature extraction methods have been

proposed and studied. However, feature extraction
techniques such as canonical correlation analysis, common
spatial spectral pattern (CSSP) and common sparse spectral
spatial pattern (CSSSP) [45] are computationally expensive.
Therefore, the computational time for feature extraction can
be reduced by the use of LPC features.
This paper is organized as follows. In section II, a brief
description of related literature works that have been carried
out is presented. Section III presents the description of the
dataset used and the proposed method respectively. In
section IV, the results are presented while section V
concludes the important findings of this paper.
II. RELATED WORKS
In the realization of an EEG-based BCI system,
generally three phases are involved: (i) recording the brain
activity by placing electrodes located on the scalp and preprocessing the recorded brain wave (EEG signal) for artifact
removal, which improves the signal-to-noise ratio (SNR);
(ii) feature extraction from the pre-processed EEG signal in
order to obtain meaningful information; (iii) classification of
the signals using the features in order to translate them into
control commands and drive external devices. Several EEGbased BCI applications such as wheelchair controllers [2,
46], and word speller programs [47] have been successfully
developed. A BCI system can be employed for various
reasons such as to understand our mental states and to
control devices via thought without any muscle activity.
Automatic emotion recognition [30, 48] is one such
application, which potentially bridges the gap between
human and machine interactions.
A number of researchers have proposed different noise
removal and feature extraction techniques. The common
artifact removal methods are adaptive filters and BSS
technique. A Cycle Spinning Wavelet Transform ICA
(CTICA) method for denoising the EEG signal is presented
in [49]. The authors argue that it is the most accurate
separation method. The method uses cyclic spinning and
merges Translational Invariant Wavelet Transform (TIWT),
Unscented Kalman Filter (UKF) and ICA. The method
outperformed Fast ICA and Efficient Fast ICA (EFICA).
Novi et. al. [26] proposed a sub-band common spatial
pattern (SBCSP) method for feature extraction aiming to
tackle the problem of varying rhythmic patterns between
different subjects. The EEG signal is decomposed into subbands using a filter bank. Then a discriminative analysis is
used for extracting the SBCSP features. A Linear
Discriminant Analyzer (LDA) with the SBCSP features as
the inputs is used to obtain scores. The classification
capability of each frequency band is reflected by these
scores. The scores are then fused, using Recursive Band
Elimination (RBE) and Meta-Classifier (MC), for making a
decision. The BCI competition III dataset IVa have been
used to assess the performance of the SBCSP method. Other
methods that have been proposed in the literature for
selecting the optimal frequency bands automatically are
common spatial pattern (CSP), CSSSP [45], discriminative
filter band CSP (DFBCSP) [50], and adaptive filters.

LPC features have been widely used in speech
recognition and its use and effectiveness for EEG signal
classification will be studied in this research. In [51], the
authors combined the Mel Frequency Cepstral Coefficients
(MFCC) with LPC features for the purpose of speaker
identification. Ten LPC and twelve MFCC features are
extracted from each sample. An artificial neural network
(ANN) has been used for recognition and identification of
the speech signal. In [52], a new hybrid method for
optimizing the extraction of accent in ethnically diverse
Malaysian English from speech utterances over facets using
LPC obtained from DWT is proposed. Using hybrid dyadicX DWT-LPC features attained an increase of 9.28%
classification accuracy compared to the conventional LPC
method. In [53] and [54], LPC features have been used for
emotion recognition (in Romanian Language) and speaker
recognition respectively.
III. METHODOLOGY
A. EEG Data Description
Dataset IVa from BCI competition III, which is provided
to the public by Fraunhofer FIRST (Intelligent Data
Analysis Group) have been used [55, 56]. The dataset IVa
consists of EEG signals for motor imaginary tasks, namely
right hand and left foot. It contains the EEG signals from
118 channels at positions of the extended international
10/20 system [57], which are recorded from five subject’s
referred to as aa, al, av, aw and ay. The signal was sampled
at 1000 Hz. However, the down sampled signal at 100 Hz is
used. Each subject performed 280 trials having equal
number of trials from each of the two motor imaginary
tasks. From the 118 channels of data, only the following 24
channels data is used (Fp1, Fp2, F3, F4, F7, F8, FC3, FC4,
FT7, FT8, T7, T8, P3, P4, P7, P8, C3, C4, CP3, CCP4, TP7,
TP8, O1, O2). This down sampled signal of 24 channels is
used for further processing and is referred to as data from
here onwards.
B. Pre-processing, Feature Extraction and Classification
The overall block diagram of the proposed method is
shown in Fig. 1. The data was firstly centered to make its
mean zero followed by the whitening process. The whitened
signal is then normalized and passed through five bandpass
filter banks namely theta (0-4 Hz), delta (4-8 Hz), alpha (814 Hz), beta (14-30 Hz) and gamma (30-50 Hz).
Windowing is then applied to the filtered data having a
window size of 0.80 seconds with an overlap of 75 percent.
The LPC and cepstrum features are then extracted from each
of the window data.
In LPC, the signal is approximated as a linear
combination of past p samples of the signal, where p
represents the order of prediction. The predicted signal
sˆ(n) of the present sample s(n) is obtained from the past
samples using (1).

sˆ(n)

k p

 ¦ ak s ( n  k )
k 1

(1)

Cepstrum coefficients are obtained by taking the inverse
Fourier transform of the logarithm of the magnitude
spectrum of the signal. All processing is carried out in
MATLAB except for the training and testing phase, which
is carried out using WEKA.

Fig. 1. Proposed cepstrum + LPC feature extraction method.

The MATLAB signal processing toolbox functions lpc
and rceps are used to perform the 3rd order LPC and real
cepstrum analysis, respectively. LPC coefficients C1, C2 and
C3 are used as features while C0 is ignored. When real
cepstrum is performed, the cepstrum coefficients and the
unique phase sequence is obtained. The maximum and
minimum of the unique phase sequence is used as features.
Therefore, each feature vector is 24 (channels) x 5 (bands) x
5 (features: 3 LPC features and 2 cepstrum features), which
gives a total of 600 features for each windowed data.

Fig. 2. Average 10-fold cross validation accuracies of all subjects.

Finally, the feature vectors are fed to a random forest
classifier to train and test the accuracy of the trained
classifier model.
IV. RESULTS AND DISCUSSIONS
A range of window sizes (0.50s, 0.80s, 1.00s, 1.50s and
2.00s) and overlap (25%, 50% and 75%) have been tested.
However, window size of 0.80s and overlap of 75%
produced the optimal results and are hence used in the preprocessing stage. Three separate experiments were carried
out in order to evaluate and show the significance of the
fusion of LPC and cepstrum features. The feature vectors
[(i) with three LPC features; (ii) with two cepstrum features;
(iii) with LPC and cepstrum features concatenated together]
are fed as the input to the random forest classifier (various
classifiers such as SVM, random committee, and rotation
forest have been tested however random forest gives the
best result and thus have been used in this paper). Different
number of LPC features have been tested however using
only three LPC coefficients gave similar results compared to
using 12 LPC coefficients as features. Hence only three
LPC coefficients have been used as LPC features in this
work. 10-fold cross validation (with 80% of data used as
training data and 20% as test data) is used for evaluating the
performance of each of the feature extraction methods. For
each subject, ten trial runs were carried out and the averages
of the results obtained were taken. The average accuracies
(across the five subjects) of the ten trial runs for the three
experiments is plotted in Fig. 2. It can be noted that for
subjects aa and al, the classification accuracies of the
method with the cepstrum and LPC features concatenated
are a little less than that of using only cepstrum features.
However, for the other three subject (av, aw and ay) it is
quite evident that the fusion of the cepstrum and LPC
features results in an increase in the classification accuracy
as the results are greater than that of classification
accuracies obtained when only cepstrum or LPC features are
used. The fusion of the cepstrum and LPC features shows
that the average of all five subjects’ classification accuracy
increases by 2% to 4% with respect to that of when only
cepstrum or LPC features are used.

TABLE I.

10x10-FOLD CROSS VALIDATION ERRORS OF DIFFERENT METHODS

No.

Method

Window
Size
(seconds)

Classifier

1

CSSSP [45]

2

2

RBE [26]

2

Percentage (%) Classification Error
Subject aa

Subject al

Subject av

Subject aw

Subject ay

Average

SVM

11.6 ± 6.3

2.1 ± 2.7

31.8 ± 7.7

6.5 ± 4.5

10.5 ± 5.7

12.50

SVM

9.2 ± 4.5

2.2 ± 3.4

31.0 ± 7.3

4.2 ± 3.3

5.0 ± 3.4

10.30

3

FBCSP [50]

2

SVM

6.93 ± 0.58

0.97 ± 0.24

31.0 ± 1.42

4.90 ± 0.89

6.18 ± 0.97

9.99

4

CSP+DS [45]

2

SVM

7.3 ± 5.1

0.9 ± 1.9

22.5 ± 7.8

2.8 ± 3.1

5.5 ± 4.3

7.80

5

Sparsity-aware [58]

2

SVM

19.64 ± 12.81

4.64 ± 4.48

28.93 ± 7.08

2.14 ± 1.96

6.43 ± 2.99

12.36

6

Cepstrum+LPC

0.8

RF

9.44 ± 0.96

7.87 ± 0.78

8.32 ± 0.61

14.76 ± 0.82

8.97 ± 0.53

9.87

In Table 1, the error rates of all five subjects together
with the average error of the proposed cepstrum+LPC
feature extraction method is shown along with other
methods that have used the same dataset for performance
evaluation. From the results obtained, it can be analyzed that
the use of only cepstrum or LPC features does not give very
promising results and the average individual error rates are
higher than other feature extraction methods depicted in
Table 1. All the other methods have used a window size of
2s with SVM as the classifier. However, 10-fold cross
validation is used by all methods to evaluate the
performance in terms of classification errors. It is noted that
compared to other methods the average classification error
of the proposed cepstrum+LPC feature extraction method
does not give the best results however, the results are
promising. The method outperforms the CSSSP, RBE, and
FBCSP feature extraction methods. Analyzing the results
for the individual subjects, the cepstrum+LPC method gives
optimal results for subject av. For subjects aa, al, aw and ay
the classification error rate of the proposed cepstrum+LPC
method is not the best. However, the individual subject
results are also promising. The proposed method performed
worst for subject aw having a classification error of 14.76%
while the best performance was noted for subject al having
an error rate of 7.87%. Cepstrum and LPC features are
computationally less expensive compared to other methods
such as CSP, CSSSP, and FBCSP. Usually the data transfer
rate in BCI applications is slow. Therefore, a smaller
window size would be also advantageous when real time
implementation is required.
The size of each feature vector used in this research as
mentioned is 600. To reduce the dimensionality of the
feature vectors, the widely used principle component
analysis (PCA) [59] and linear discriminant analysis (LDA)
[60-63] can be applied. Dimensionality reduction has not
been carried out in this research and will be considered later.
V. CONCLUSIONS
In this work, it is shown that speech processing features
such as cepstrum and LPC can be applied to the field of
biomedical signal processing. The results obtained are
promising and provides the basis for further research in the
use of speech processing features for biomedical signal
classification.

Some post-processing techniques such as cepstral
weighting, cepstral mean subtraction (CMS), pole-filtered
cepstral mean subtraction (PFCMS), adaptive component
weighted cepstrum (ACWC), and post-filter cepstrum have
not been used, and will be addressed and evaluated later by
expanding the proposed method. Also, the use of MFCC
features will be studied.

References
[1]

A. C. Lopes, G. Pires, and U. Nunes, "Assisted navigation for a brainactuated intelligent wheelchair," Robot. Auton. Syst., vol. 61, pp. 245258, 2013.
[2] R. S. Naveen and A. Julian, "Brain computing interface for wheel
chair control," in Computing, Communications and Networking
Technologies (ICCCNT),2013 Fourth International Conference on,
2013, pp. 1-5.
[3] A. Akce, M. Johnson, O. Dantsker, and T. Bretl, "A Brain Machine
Interface to Navigate a Mobile Robot in a Planar Workspace:
Enabling Humans to Fly Simulated Aircraft With EEG," Neural
Systems and Rehabilitation Engineering, IEEE Transactions on, vol.
21, pp. 306-318, 2013.
[4] S. Ramesh, M. G. Krishna, and M. Nakirekanti, "Brain Computer
Interface System for Mind Controlled Robot using Bluetooth,"
International Journal of Computer Applications, vol. 104, pp. 20-23,
October 2014.
[5] C. Yongwook, J. Sungho, and J. Jaeseung, "Brain-actuated humanoid
robot navigation control using asynchronous Brain-Computer
Interface," in Neural Engineering (NER), 2011 5th International
IEEE/EMBS Conference on, 2011, pp. 519-524.
[6] B. Choi and S. Jo, "A Low-Cost EEG System-Based Hybrid BrainComputer Interface for Humanoid Robot Navigation and
Recognition," PLOS one, vol. 8, p. e74583, 2013.
[7] S. P. Levine, J. E. Huggins, S. L. BeMent, R. K. Kushwaha, L. A.
Schuh, E. A. Passaro, et al., "Identification of electrocorticogram
patterns as the basis for a direct brain interface," Journal of Clinical
Neurophysiology, vol. 16, pp. 439-447, 1999.
[8] J. P. Donoghue, "Connecting cortex to machines: recent advances in
brain interfaces," Nat Neurosci, 10/28/online 2002.
[9] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and
T. M. Vaughan, "Brain–computer interfaces for communication and
control," Clinical Neurophysiology, vol. 113, pp. 767-791, 6// 2002.
[10] A. Vallabhaneni, T. Wang, and B. He, "Brain—Computer Interface,"
in Neural Engineering, B. He, Ed., ed: Springer US, 2005, pp. 85121.
[11] S. Jirayucharoensak, S. Pan-Ngum, and P. Israsena, "EEG-Based
Emotion Recognition Using Deep Learning Network with Principal
Component Based Covariate Shift Adaptation," The Scientific World
Journal, vol. 2014, p. 10, 2014.
[12] P. P. Acharjee, R. Phlypo, L. Wu, V. D. Calhoun, and T. Adali,
"Independent Vector Analysis for Gradient Artifact Removal in
Concurrent EEG-fMRI Data," Biomedical Engineering, IEEE
Transactions on, vol. 62, pp. 1750-1758, 2015.

[13] A. Sohrabpour, Y. Lu, P. Kankirawatana, J. Blount, H. Kim, and B.
He, "Effect of EEG electrode number on epileptic source localization
in pediatric patients," Clinical Neurophysiology, vol. 126, pp. 472480, 3// 2015.
[14] H. Woehrle, M. M. Krell, S. Straube, S. K. Kim, E. A. Kirchner, and
F. Kirchner, "An Adaptive Spatial Filter for User-Independent Single
Trial Detection of Event-Related Potentials," Biomedical
Engineering, IEEE Transactions on, vol. 62, pp. 1696-1705, 2015.
[15] T. Yu, J. Xiao, F. Wang, R. Zhang, Z. Gu, A. Cichocki, et al.,
"Enhanced Motor Imagery Training Using a Hybrid BCI With
Feedback," Biomedical Engineering, IEEE Transactions on, vol. 62,
pp. 1706-1717, 2015.
[16] B. Graimann, B. Allison, and G. Pfurtscheller, "Brain–Computer
Interfaces: A Gentle Introduction," in Brain-Computer Interfaces, B.
Graimann, G. Pfurtscheller, and B. Allison, Eds., ed: Springer Berlin
Heidelberg, 2010, pp. 1-27.
[17] (16
September).
Neurosky:
EEG
Headsets.
Available:
http://store.neurosky.com/collections/eeg-headsets
[18] (16 September). Emotiv eStore: EPOC Headset. Available:
https://emotiv.com/store/
[19] A. Sharma and K. K. Paliwal, "Subspace independent component
analysis using vector kurtosis," Pattern Recognition, vol. 39, pp.
2227-2232, November 2006.
[20] S. Shi-Yun, S. Kai-Quan, O. Chong Jin, E. Wilder-Smith, and L.
Xiao-Ping, "Automatic EEG Artifact Removal: A Weighted Support
Vector Machine Approach With Error Correction," Biomedical
Engineering, IEEE Transactions on, vol. 56, pp. 336-344, 2009.
[21] N. P. Castellanos and V. A. Makarov, "Recovering EEG brain
signals: Artifact suppression with wavelet enhanced independent
component analysis," Journal of Neuroscience Methods, vol. 158, pp.
300-312, December 2006.
[22] M. Crespo-Garcia, M. Atienza, and J. L. Cantero, "Muscle Artifact
Removal from Human Sleep EEG by Using Independent Component
Analysis," Annals of Biomedical Engineering, vol. 36, pp. 467-475,
March 2008.
[23] R. Vigario, J. Sarela, V. Jousmiki, Ha, x, ma, et al., "Independent
component approach to the analysis of EEG and MEG recordings,"
Biomedical Engineering, IEEE Transactions on, vol. 47, pp. 589-593,
2000.
[24] N.-H. Liu, C.-Y. Chiang, and H.-C. Chu, "Recognizing the Degree of
Human Attention Using EEG Signals from Mobile Sensors," Sensors,
vol. 13, pp. 10273-10286, August 2013.
[25] K. K. Ang, Z. Y. Chin, H. Zhang, and C. Guan, "Filter Bank
Common Spatial Pattern (FBCSP) in Brain-Computer Interface," in
IEEE International Joint Conference on Neural Networks (IEEE
World Congress on Computational Intelligence), Hong Kong, 2008,
pp. 2390 - 2397.
[26] Q. Novi, G. Cuntai, T. H. Dat, and X. Ping, "Sub-band Common
Spatial Pattern (SBCSP) for Brain-Computer Interface," in Neural
Engineering, 2007. CNE '07. 3rd International IEEE/EMBS
Conference on, 2007, pp. 204-207.
[27] D. L. Rocca, P. Campisi, B. Vegso, P. Cserti, G. Kozmann, F.
Babiloni, et al., "Human Brain Distinctiveness Based on EEG
Spectral Coherence Connectivity," IEEE Transactions on Biomedical
Engineering, vol. 61, pp. 2406-2412, September 2014.
[28] A. Zhang, B. Yang, and L. Huang, "Feature Extraction of EEG
Signals Using Power Spectral Entropy," in International Conference
on BioMedical Engineering and Informatics, Sanya, 2008, pp. 435 439.
[29] M. Sabeti, S. Katebi, and R. Boostani, "Entropy and complexity
measures for EEG signal classification of schizophrenic and control
participants," Artificial Intelligence in Medicine, vol. 47, pp. 263-274,
11// 2009.
[30] U. Wijeratne and U. Perera, "Intelligent emotion recognition system
using electroencephalography and active shape models," in
Biomedical Engineering and Sciences (IECBES), 2012 IEEE EMBS
Conference on, 2012, pp. 636-641.
[31] X. Li, X. Chen, Y. Yan, W. Wei, and Z. J. Wang, "Classification of
EEG Signals Using a Multiple Kernel Learning Support Vector
Machine," Sensors, vol. 14, pp. 12784-12802, July 2014.
[32] L. Yuan-Pin, W. Chi-Hong, W. Tien-Lin, J. Shyh-Kang, and C. JyhHorng, "Support vector machine for EEG signal classification during

[33]

[34]

[35]

[36]

[37]

[38]
[39]

[40]

[41]
[42]

[43]

[44]

[45]
[46]

[47]

[48]
[49]

[50]

listening to emotional music," in Multimedia Signal Processing, 2008
IEEE 10th Workshop on, 2008, pp. 127-130.
L. Mu and L. Bao-Liang, "Emotion classification based on gammaband EEG," in Engineering in Medicine and Biology Society, 2009.
EMBC 2009. Annual International Conference of the IEEE, 2009, pp.
1223-1226.
L. Yuan-Pin, W. Chi-Hong, J. Tzyy-Ping, W. Tien-Lin, J. ShyhKang, D. Jeng-Ren, et al., "EEG-Based Emotion Recognition in
Music Listening," Biomedical Engineering, IEEE Transactions on,
vol. 57, pp. 1798-1806, 2010.
D. Nie, X.-W. Wang, L.-C. Shi, and B.-L. Lu, "EEG-based emotion
recognition during watching movies," in 5th International
IEEE/EMBS Conference on Neural Engineering (NER), Cancun,
Mexico, 2011, pp. 667-670.
N. Jatupaiboon, S. Pan-ngum, and P. Israsena, "Emotion
classification using minimal EEG channels and frequency bands," in
Computer Science and Software Engineering (JCSSE), 2013 10th
International Joint Conference on, 2013, pp. 21-24.
L. Brown, B. Grundlehner, and J. Penders, "Towards wireless
emotional valence detection from EEG," in Engineering in Medicine
and Biology Society, EMBC, 2011 Annual International Conference
of the IEEE, 2011, pp. 2188-2191.
X. Haiyan and K. N. Plataniotis, "Affect recognition using EEG
signal," in Multimedia Signal Processing (MMSP), 2012 IEEE 14th
International Workshop on, 2012, pp. 299-304.
E. Parvinnia, M. Sabeti, M. Z. Jahromi, and R. Boostani,
"Classification of EEG Signals using adaptive weighted distance
nearest neighbor algorithm," Journal of King Saud University –
Computer and Information Sciences, vol. 26, pp. 1-6, 2014.
F. Akram, H.-S. Han, and T.-S. Kim, "A P300-Based Word Typing
Brain Computer Interface System Using a Smart Dictionary and
Random Forest Classifier," in The Eighth International MultiConference on Computing in the Global Information Technology,
2013, pp. 106-109.
A. Sharma, K. K. Paliwal, and G. C. Onwubolu, "Class-dependent
PCA, MDC and LDA: A combined classifier for pattern
classification," Pattern Recognition, vol. 39, pp. 1215-1229, 7// 2006.
A. Sharma and K. K. Paliwal, "Rotational Linear Discriminant
Analysis Technique for Dimensionality Reduction," Knowledge and
Data Engineering, IEEE Transactions on, vol. 20, pp. 1336-1347,
2008.
A. Sharma, S. Imoto, and S. Miyano, "A Top-r Feature Selection
Algorithm for Microarray Gene Expression Data," Computational
Biology and Bioinformatics, IEEE/ACM Transactions on, vol. 9, pp.
754-764, 2012.
A. Sharma and K. K. Paliwal, "A new perspective to null linear
discriminant analysis method and its fast implementation using
random matrix multiplication with scatter matrices," Pattern
Recognition, vol. 45, pp. 2205-2213, 6// 2012.
L. Song and J. Epps, "Classifying EEG for Brain-Computer Interface:
Learning Optimal Filters for Dynamical System Features,"
Computational Intelligence and Neuroscience, vol. 2007, p. 11, 2007.
L. Cao, J. Li, H. Ji, and C. Jiang, "A hybrid brain computer interface
system based on the neurophysiological protocol and brain-actuated
switch for wheelchair control," Journal of Neuroscience Methods,
vol. 229, pp. 33-43, 5/30/ 2014.
F. Akram, M. K. Metwally, H. Hee-Sok, J. Hyun-Jae, and K. TaeSeong, "A novel P300-based BCI system for words typing," in BrainComputer Interface (BCI), 2013 International Winter Workshop on,
2013, pp. 24-25.
N. Jatupaiboon, S. Pan-ngum, and P. Israsena, "Real-Time EEGBased Happiness Detection System," The Scientific World Journal,
vol. 2013, p. 618649, July 2013.
J. Walters-Williams and Y. Li, "A New Approach to Denoising EEG
Signals - Merger of Translation Invariant Wavelet and ICA,"
International Journal of Biometrics and Bioinformatics (IJBB), vol.
5, pp. 130-148, Juna 2011.
K. P. Thomas, G. Cuntai, C. T. Lau, A. P. Vinod, and A. Kai Keng,
"A New Discriminative Common Spatial Pattern Method for Motor
Imagery
Brain&#x2013;Computer
Interfaces,"
Biomedical
Engineering, IEEE Transactions on, vol. 56, pp. 2730-2733, 2009.

[51] R. B. Shinde and V. P. Pawar, "Fusion of MFCC & LPC Feature Sets
for Accurate Speaker Identification," International JOurnal of
Current Engineering and Technology, vol. 3, pp. 1763-1766, 2013.
[52] M. A. Yusnita, M. P. Paulraj, S. Yaacob, and A. B. Shahriman,
"Classification of speaker accent using hybrid DWT-LPC features
and K-nearest neighbors in ethnically diverse Malaysian English," in
IEEE Symposium on Computer Applications and Industrial
Electronics (ISCAIE), 2012, pp. 179-184.
[53] S. M. Feraru and M. D. Zbancioc, "Emotion recognition in Romanian
language using LPC features," in E-Health and Bioengineering
Conference (EHB), 2013, 2013, pp. 1-4.
[54] R. Visalakshi and P. Dhanalakshmi, "Acoustic Feature Extraction
Methods LPC, LPCC and RASTA-PLP in Speaker REcognition,"
Asian Journal of Information Technology, vol. 13, pp. 595-598, 2014.
[55] G. Dornhege, B. Blankertz, G. Curio, and K. Muller, "Boosting bit
rates in noninvasive EEG single-trial classifications by feature
combination and multiclass paradigms," IEEE Transactions on
Biomedical Engineering, vol. 51, pp. 993-1002, 2004.
[56] B. Blankertz, K. R. Müller, D. J. Krusienski, G. Schalk, J. R.
Wolpaw, A. Schlögl, et al., "The BCI competition III: validating
alternative approaches to actual BCI problems," IEEE Transactions
on Neural Systems and Rehabilitation Engineering, vol. 14, pp. 153159, June 2006.
[57] T. C. T. Limited, "10/20 System Positioning," ed. Hong Kong, 2012.
[58] N. Tomida, T. Tanaka, S. Ono, M. Yamagishi, and H. Higashi,
"Active Data Selection for Motor Imagery EEG Classification," IEEE
Transactions on Biomedical Engineering, vol. 62, pp. 458-467, 2015.
[59] A. Sharma and K. K. Paliwal, "Fast principal component analysis
using fixed-point algorithm," Pattern Recognition Letters, vol. 28, pp.
1151-1155, 7/15/ 2007.
[60] A. Sharma, K. K. Paliwal, S. Imoto, and S. Miyano, "A feature
selection method using improved regularized linear discriminant
analysis," Mach. Vision Appl., vol. 25, pp. 775-786, 2014.
[61] A. Sharma and K. K. Paliwal, "A two-stage linear discriminant
analysis for face-recognition," Pattern Recognition Letters, vol. 33,
pp. 1157-1162, 7/1/ 2012.
[62] A. Sharma, K. Paliwal, S. Imoto, and S. Miyano, "Principal
component analysis using QR decomposition," International Journal
of Machine Learning and Cybernetics, vol. 4, pp. 679-683,
2013/12/01 2013.
[63] A. Sharma and K. K. Paliwal, "A deterministic approach to
regularized linear discriminant analysis," Neurocomputing, vol. 151,
Part 1, pp. 207-214, 3/3/ 2015.

