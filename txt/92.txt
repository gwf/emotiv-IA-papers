World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:12, No:10, 2018

Optimized Brain Computer Interface System for
Unspoken Speech Recognition: Role of Wernicke
Area

International Science Index, Biomedical and Biological Engineering Vol:12, No:10, 2018 waset.org/Publication/10009609

Nassib Abdallah, Pierre Chauvet, Abd El Salam Hajjar, Bassam Daya

Abstract—In this paper, we propose an optimized brain computer
interface (BCI) system for unspoken speech recognition, based on
the fact that the constructions of unspoken words rely strongly on the
Wernicke area, situated in the temporal lobe. Our BCI system has four
modules: (i) the EEG Acquisition module based on a non-invasive
headset with 14 electrodes; (ii) the Preprocessing module to remove
noise and artifacts, using the Common Average Reference method;
(iii) the Features Extraction module, using Wavelet Packet Transform
(WPT); (iv) the Classiﬁcation module based on a one-hidden layer
artiﬁcial neural network. The present study consists of comparing
the recognition accuracy of 5 Arabic words, when using all the
headset electrodes or only the 4 electrodes situated near the Wernicke
area, as well as the selection effect of the subbands produced by
the WPT module. After applying the articial neural network on the
produced database, we obtain, on the test dataset, an accuracy of
83.4% with all the electrodes and all the subbands of 8 levels of the
WPT decomposition. However, by using only the 4 electrodes near
Wernicke Area and the 6 middle subbands of the WPT, we obtain
a high reduction of the dataset size, equal to approximately 19% of
the total dataset, with 67.5% of accuracy rate. This reduction appears
particularly important to improve the design of a low cost and simple
to use BCI, trained for several words.
Keywords—Brain-computer interface, speech recognition,
electroencephalography EEG, Wernicke area, artiﬁcial neural
network.

I. I NTRODUCTION

A

brain Computer Interface (BCI) is a direct connection
between the human brain and exterior devices. It relies on
systems that acquire signals directly from the brain, analyze
them, and translate them into commands. BCIs are studied
in numerous ﬁelds (medical, military, advertisements, gaming,
etc.) and are linked nowadays with the internet of things [1].
Yet, BCIs targeting a medical issue are the focus of
many researches, to improve the lives of persons affected by
number of different disease [2]. In this paper, we propose a
BCI system for people with speaking issues, focused on the
signals acquired from the brain using the Electroencephaloghy
technique (EEG). In fact, the EEG is widely used in this ﬁeld
of research, as it is noninvasive and provides high temporal
resolution of the acquired signal, for a low cost and portable
material [3]. More precisely, we investigate the importance
of the Wernicke-Broca zone for the recognition of 5 Arabic
N. Abdallah is a PhD student in Angers University,France and the Lebanese
University, Lebanon (e-mail: nassib.abdallah@etud.univ-angers.fr).
P. Chauvet is a professor at Université catholique de l’ouest,France and
attached to the Angers University-Laboratoire Angevin de Recherche en
Ingénierie des Systèmes, France.
A. Hajjar is an assistant professor in the Lebanese University,Lebanon
B. Daya is a professor in the Lebanese University, Lebanon.

International Scholarly and Scientific Research & Innovation 12(10) 2018

unspoken words, compared to results obtained during the
acquisition of all the channels around the scalp of a human
subject.
This article discusses the impact of EEG sensor selection
in the Wernicke area, by comparing the results obtained
when all the recording channels used in the acquisition
process are retained. Thus, we investigate the dataset reduction
using the selection of the Wernicke EEG sensors, and other
methodologies like dimension reduction, in order to increase
the speed of our system, by selecting the essential information
of the recorded signals.
The best result provided by our system for the recognition
of ﬁve unspoken speech words was 76.2% of accuracy
in the classiﬁcation process (Table IV) . This result was
according to the testing dataset injected into the system,
based on artiﬁcial neural network model, to validate its output
decision. Although, this work discussed the impact of selecting
subspaces from the decomposition result, applied after the
implementation of the Wavelet Packet Transform. Indeed, it
gives 67.5% of recognition, providing a high reduction in the
dataset dimension (Table VII).
In the ﬁrst section of this paper, we present a state of art of
the Brain computer Interface and the unspoken speech related
works. The second section presents the system architecture for
the recognition of 5 Arabic words {light, turn out, eat, drink
and sleep} as shows Table I.
In the third section, we present and discuss the results
of our system accuracy, through the comparison of different
methodologies and parameters like the selection of subspaces,
the set of features, etc. Finally, we conclude this paper with a
conclusion and perspectives.
TABLE I
5 A RABIC W ORDS WITH E NGLISH T RANSLATION AND P RONUNCIATION

II. S TATE OF A RT
The human brain consists of 6 different lobes (Frontal,
Parietal, Occipital, Temporal, Limbic and Insular cortex) [4].
The ﬁrst four lobes represents the main lobes positioned as
shown on Fig. 1.

456

scholar.waset.org/1307-6892/10009609

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:12, No:10, 2018

International Science Index, Biomedical and Biological Engineering Vol:12, No:10, 2018 waset.org/Publication/10009609

TABLE II
R ECOGNITION R ATE FOR 3 L EVELS OF D ECOMPOSITION U SING THE F IRST S ET OF F EATURES
F-measure F-measure F-measure F-measure F-measure
Channel
Accuracy
C1
C2
C3
C4
C5
selection
(%)
(%)
(%)
(%)
(%)
(%)
All Channels
58.6
62.58
54.36
53.42
55.61
60.49
Training
Wernickes
72.5
83.02
56.52
56.52
53.7
56.53
All Channels
57
61.14
49.65
49.65
54.25
59.29
Test
Wernickes
68.5
76.5
70.34
60.02
53.85
62.37
TABLE III
R ECOGNITION R ATE FOR 8 L EVELS OF D ECOMPOSITION U SING THE F IRST S ET OF F EATURES
F-measure F-measure F-measure F-measure F-measure
Channel
Accuracy
C1
C2
C3
C4
C5
selection
(%)
(%)
(%)
(%)
(%)
(%)
All Channels
64.6
65.95
66.22
71.58
35.63
58.94
Training
Wernickes
81.5
86.9
86.62
75.99
71.06
68.2
All Channels
62.6
63.55
63.75
73.01
29.72
54.59
Test
Wernickes
74.2
83.68
77.03
65.49
59.48
59.45
TABLE IV
R ECOGNITION R ATE FOR 8 L EVELS OF D ECOMPOSITION U SING THE S ECOND S ET OF F EATURES
F-measure F-measure F-measure F-measure F-measure
Channel
Accuracy
C5
C4
C3
C2
C1
selection
(%)
(%)
(%)
(%)
(%)
(%)
All Channels
85.2%
88.4%
87.97%
83.74%
82.33%
75.21%
Training
Wernickes
85.8%
91.08%
90.21%
75.88%
78.84%
77.84%
All Channels
83.4%
87.95%
85.57%
82.64%
80.13%
69.26%
Test
Wernickes
76.2%
85.4%
83.48%
60.55%
72.49%
52.47%
TABLE V
R ECOGNITION R ATE FOR 8 L EVELS OF D ECOMPOSITION U SING THE S ECOND S ET OF F EATURES AND THE S ELECTION OF THE F IRST F OUR D ETAILS
C OEFFICIENTS OF THE F IRST F OUR S UBSPACES CD1, CD2, CD3 AND CD4
F-measure F-measure F-measure F-measure F-measure
Channel
Accuracy
C1
C2
C3
C4
C5
selection
(%)
(%)
(%)
(%)
(%)
(%)
All Channels
58.6
62.58
54.36
53.42
55.61
60.49
Training
Wernickes
72.5
83.02
56.52
56.52
53.7
56.53
All Channels
57
61.14
49.65
49.65
54.25
59.29
Test
Wernickes
68.5
76.5
70.34
60.02
53.85
62.37
TABLE VI
R ECOGNITION R ATE FOR 8 L EVELS OF D ECOMPOSITION U SING THE S ECOND S ET OF F EATURES AND THE S ELECTION OF THE L AST F OUR D ETAILS
C OEFFICIENTS OF THE L AST F OUR SUBSPACES CD5, CD6, CD7 AND CD8
F-measure F-measure F-measure F-measure F-measure
Channel
Accuracy
C5
C4
C3
C2
C1
selection
(%)
(%)
(%)
(%)
(%)
(%)
All Channels
37.8
49.92
18.08
23.45
30.81
33.88
Training
Wernickes
42.2
52.1
40.88
10.42
31.07
48.6
All Channels
33.4
47.75
9.15
18.43
25.5
23.46
Test
Wernickes
28.4
42.73
19.15
3.73
7.77
16.63
TABLE VII
R ECOGNITION R ATE FOR 8 L EVELS OF D ECOMPOSITION U SING THE S ECOND S ET OF F EATURES AND THE S ELECTION OF THE D ETAILS C OEFFICIENTS
OF THE M IDDLE S UBSPACES CD2, CD3, CD4, CD5, CD6 AND CD7
F-measure F-measure F-measure F-measure F-measure
Channel
Accuracy
C1
C2
C3
C4
C5
selection
(%)
(%)
(%)
(%)
(%)
(%)
All Channels
74.4
77.9
76.77
72.5
73.47
63.76
Training
Wernickes
79
81.75
80.64
78.74
79.9
67.62
All Channels
69.7
73.56
71.61
70.13
66.69
54.31
Test
Wernickes
67.5
72.48
70.21
66.03
57.11
64.34

The frontal lobe constitutes two thirds of the human brain. It
is the main lobe were the personality of the human is formed.
Yet, the frontal lobe is used to make voluntary movements
such as walking, eating or drinking. In addition this lobe is
necessary to speak meaningfully [5].
The parietal lobe contains a map of neurons that have an

International Scholarly and Scientific Research & Innovation 12(10) 2018

important role to process the sensory information from various
parts of the body and speciﬁcally the bodys ﬁve senses such as
the sense of touch, smell, audition, taste and visual information
to guide the movement of the body [6].
The occipital lobe is located at the back of the brain as
shown in Fig. 1. It is the smallest of the four main lobes and is

457

scholar.waset.org/1307-6892/10009609

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:12, No:10, 2018

recording channels. Yet, the work done by (Porbadnigk et al.,
2008)[10] using the same material of recording as Calliess for
the same set of words using german subjects obtained 45.5%
of classiﬁcation of the ﬁve english words Echo,Charlie,Beta,
Delta, Alpha. However, the work done by (Salama et al., 2014)
[11] on a system for the recognition of two english words
using the Neurosky MindWave Headset containing only one
recording EEG electrode gave 56% of classiﬁcation for the
two english words YES, NO.

International Science Index, Biomedical and Biological Engineering Vol:12, No:10, 2018 waset.org/Publication/10009609

III. S YSTEM A RCHITECTURE

Fig. 1 Lateral surface of cerebrum

mainly responsible of visual perception and color recognition.
In fact, it processes the data acquired from the eyes and links
the information acquired with images in the memory of the
subject [7].
The temporal lobe is located in proximity of the ears: there
is one temporal lobe at each side of the brain. It plays an
important role in the processing of sensory inputs, as it is
involved in the storage of information in the memory of the
subject. Also, it contains the auditory and language processing,
with the speech production and comprehension localized in the
Wernickes area [8]. In fact, the process of the construction of
unspoken words in the brain is mainly relied to the Wernickes
and Broca area. The information is processed in the Wernickes
area and then send to the Broca area through the Arcuate
Fasciculus, a set of axons that connect different areas of
the brains for the language use. The Broca area receives the
information and send commands to the muscular cortex to
produce the articulation for the constructed word.
The BCI targeting people having speaking issue have to
consider the facts mentioned above. As this paper aims on
a system for automatic recognition of unspoken words, we
can improve it taking into account from where the problem is
located in the brain, using the good areas during the recordings
of the EEG.
The construction of a BCI consists of four main phases or
modules [3]: (i) The EEGs acquisition. (ii) The preprocessing
of the acquired signals to enhance their qualities and remove
the noise. (iii) The feature extraction to extract relevant
features from these signals (iv) And ﬁnally the classiﬁcation, in
order to associate the feature vector to different known classes.
Several BCI systems were constructed targeting unspoken
speech based on the Electroencephalographic technique for
the recognition of unspoken words. There were two BCIs
targetting the recognition of unspoken words were (Calliess
et al., 2006) [9] worked on a system for the recognition of the
ﬁve words spelling the NATO alphabet Alpha, Bravo, Charlie,
Delta, Echo using the system 10-20 for the acquisition of
the brain signals. They obtain 49% of classiﬁcation using 16

International Scholarly and Scientific Research & Innovation 12(10) 2018

Fig. 2 shows the architecture of the proposed BCI system
for unspoken speech recognition, based on the fact that the
constructions of unspoken words rely strongly on the Wernicke
area, situated in the temporal lobe. This system is composed
of four main components that are: Data Acquisition, Data
Preprocessing, Feature Extraction, and Data Classiﬁcation.
The Data Acquisition allows treating the EEG signals, reached
from the scalp of the subject, and extracting the pertinent EEG
according to the user choice. However, the user can choose to
extract only the Wernicke channels or extracting all the 14
channels. These extracted signals will be followed by a vector
Marker called M; it contains the index of the start and the
end of each window in the EEG Signal. This output will be
injected into the second component Data Preprocessing” that
allows applying the Common Average Reference algorithms,
and splitting the EEG signal, that represent a session of
1min 30seconds of recording, according to the marker vector
representing the parameter ’M’ in our system. The Feature
Extraction allows implementing the Wavelet PAcket Transform
Algorithm, this component has three parameters in addition
to the matrix of preprocessed signals; the ﬁrst parameter
’L’ specify the number of decomposition level, which was
applied on the original signal by the WPT Algorithm; the
second parameter ’Ftv’ specify the choice of the features set,
computed on the computed coefﬁcient vector resulting from
the WPT decomposition; and the third parameters specify
the band of ID for the selected subspaces resulting from the
WPT decomposition, in order to reduce the dimension of the
dataset. The Feature Extraction outputs are features vectors
that will be injected into an artiﬁcial neural network, based
on three layers in the Fourth and ﬁnal component called Data
Classiﬁcation”, this component aims to classify the input data
into ﬁve different classes through a conﬁgured neural network.
It takes one parameter ’NbH’ which specify the number of
hidden neuron in the hidden layer of the neural network.
A. Data Acquisition
This module is the ﬁrst phase of the construction of a
Brain Computer Interface. It consists of recording the brain
wave through speciﬁc materials of acquisition. Yet, there are
two different categories of acquisition of the brain signal.
The ﬁrst represents the invasive techniques which give high
resolution and efﬁcient signals. However, the disadvantage
of this category is its need to a surgery which can be very
harmful and dangerous for the subject [3]. The second category
concerns noninvasive techniques, that are the most used in

458

scholar.waset.org/1307-6892/10009609

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:12, No:10, 2018

Only F7, FC5, T7 and P7 electrodes, representing the
sensors nearby the Wernickes area for right handed subjects,
were selected to compare the recognition of the 5 words with
the classiﬁcation obtained by selecting all the 14 EEG sensors
of the Emotiv Headset. By selecting only 4 of the 14 channels,
the size of the database is reduced to 28.57% of the original
database according to the forumla:
reduction =

N umberof selectedchannels ∗ 100
T otalnumberof channels

.

International Science Index, Biomedical and Biological Engineering Vol:12, No:10, 2018 waset.org/Publication/10009609

B. Preprocessing

Fig. 2 General architecture of the Optimized BCI system

the BCI researches since they are simpler to implement and
harmless for the subject. The noninvasive techniques consist
of recording the brain signals, through harmless methods
like ﬁxing electrodes on the scalp of a subject to record
the electric ﬂow from the brain (Electroencephalography),
recording the magnetic ﬂow (Magnetoencephalograhy), using
the Blood Oxygenation Level Dependent (BOLD) or other
methods [3]. In this paper, the electric ﬂow was recorded and
analyzed by ﬁxing an Emotiv Epoc+ headset on the scalp of
a subject, using the EEG technique for the acquisition of the
data (Fig. 4). The Emotiv Epoc+ is a headset containing 14
bio potential sensors covering most of the scalp of a subject
(Fig. 5). It sends the recorded EEG through a USB transceiver.
The data are then saved and visualized through the Emotiv
APK called Testbench. The recording was realized on subjects
having between 19 and 25 years old. Each subject performs
between 3 and 5 sessions of recording for each of the 5 arabic
words. Each session consists of 1m30sec of recordings with
15 and 20 repetition of a same word. The session consists of a
video made speciﬁcally for each word as shows Fig. 3, where
Mi represents a marker injected manually during the
acquisition to separate each windows (begin and end of the
though word), Ri represents the repetition of a though word,
and n is the number of repetition in each session.
The records are saved in EDF format ﬁles where each ﬁle
represents a session for a speciﬁed subject and a speciﬁed
thought word. Each EDF ﬁle contains a row for each EEG
channel, i.e. the recorded values for each of the 14 electrodes
AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8
and AF4, and a row for the marker values injected during the
acquisition process.

International Scholarly and Scientific Research & Innovation 12(10) 2018

This phase consists of removing artifact and noise in order
to increase the rate of recognition. However, there are many
methods which can be implemented to enhance the quality
of the recorded signals, like Common Average Reference
(CAR) which remove the common components between
all the recording channels, Principle Component Analysis
(PCA) which can be either using for the preprocessing
and for the Feature extraction/dimension reduction, Adaptive
Filters which remove the noise through a set of ﬁlters
adapted to remove speciﬁc band of frequencies from the
signals and other techniques [3]. In this work we have
implemented the Common Average Reference which is
particularly performant in removing artifacts like potentials
induced by muscular/cardiac contractions. This method is
applied on each recording electrode to eliminate the common
components between all the channels: it consists of computing
a mean vector of the recorded channels and subtracting this
mean vector from each channel.
C. Feature Extraction
This phase consists of extracting relevant characteristics
form the EEG signals in order to construct a feature vector
representing the essential data of the recorded signal. For that,
the most used method applied is the Wavelet Packet Transform
since it is efﬁcient for non stationary signals which is the case
of EEG signals. However, Principle Component Analysis and
Independent Component Analysis can be applied to extract
principle components or independent components from the
signals [3]. The use of feature extraction methods is related
to the speciﬁcities of the processed signals. The process to
extract features from the signal in the proposed system follows
the steps below.
First, the preprocessed signals were imported and injected
into the feature extraction module, which consists of the
Wavelet Packet Transform with three or eight levels of
decomposition. The results for a three level decomposition
is 4 subspaces containing 3 vectors of details coefﬁcients
and a vector of approximation coefﬁcient. On each vector
of coefﬁcient for each subspace, 2 sets of features were
computed:
1) Variance, Standard deviation, Energy, Waveform length
2) Variance, Entropy, Energy, Waveform length
The results of this process is, for each EEG channel, a vector
of characteristics containing 16 values for three levels of

459

scholar.waset.org/1307-6892/10009609

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:12, No:10, 2018

International Science Index, Biomedical and Biological Engineering Vol:12, No:10, 2018 waset.org/Publication/10009609

Fig. 3 Video Procedure

(a) Headset on the scalp of
a subject

(b) Picture taken during
the acquisition process

Fig. 4 Acquisition process

for classiﬁcation and pattern recognition [12]. After the feature
extraction phase, a part of the data of interest was selected
from the dataset and was splitted into two subsets: 80%, 20%.
The ﬁrst subset was injected in a one hidden-layer neural
network as a 2D matrix and followed by a 1D target vector
representing the target classes identiﬁer of each observation
injected in the input. This process allows the neural network
to train and adapt his weights to give an output similar to
the target matrix through the minimization of a least-square
problem. The second 20% of the dataset was used for testing
the output of the trained neural network.
The results shown in Tables I-VI are measures of the
accuracy of the classiﬁcation and the F-measure, which is
related to the recall and precision formulas:
Recall =

P recision =

T rueP ositives
F alseN egatives

T rueP ositives
T rueP ositives + F alseP ositives

F measure = 2 ∗

Recall ∗ P recision
Recall + P recision

IV. R ESULTS AND D ISCUSSION
Fig. 5 Emotiv epoc+ EEG Sensors, 14 EEG sensors (AF3, F7, F3, FC5, T7,
P7, O1, O2, P8, T8, FC6, F4, F8 and AF4), 2 references (CMS and DRL)

decomposition and 36 values for eight decomposition. The
number of values is related to the number of subspace created
after the decomposition of the Wavelet Packet Transform,
following the formula below:
F eatureV ectorV alues = (Level+1)∗N umberOf F eatures.
D. Classiﬁcation
The Classiﬁcation is the fourth module of the BCI system.
Since the feature vectors are built in the third phase, these
vectors are injected in a machine learning based classiﬁer.
There are two main categories of classiﬁer. the ﬁrst consists of
linear classiﬁer like Linear Discriminant Analysis and Support
Vector Machine which classify the data using hyperplanes. The
second category consists of non linear classiﬁer like Random
forest based on tree decision, K nearest neighbor, Artiﬁcial
neural network and others [3]. In this work, we implement an
Artiﬁcial Neural network since it is robust and is efﬁcient tool

International Scholarly and Scientific Research & Innovation 12(10) 2018

The main result of this work is an optimized BCI system for
unspoken speech recognition. In this section, we will present
and discuss the performance results of the system according
to several parameters such as: level of decomposition, Feature
selection, and subband selection.

A. Levels of Decomposition
The ﬁrst comparison between results was done by
modifying the number of decomposition in the Wavelet Packet
Transform algorithm. As shows Table II, the results obtained
for 3 levels of decomposition by selecting the EEG sensors
in the Wernickes area shows a rate of recognition higher
than the recognition obtained by selecting all the 14 EEG
sensors. However, the use of eight levels of decomposition
gave even better results using only the 4 sensors near the
Werincke area (as shows Table III) with an average accuracy
of 81.5% on the training dataset and 74.2% on the test dataset,
for the classiﬁcation of the 5 Arabic words. In the rest of this
document accuracies are given in this order: training set - test
set.

460

scholar.waset.org/1307-6892/10009609

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:12, No:10, 2018

B. Features Selection
The second comparison criteria is the selection of the set of
features computed on the coefﬁcients vectors. The ﬁrst set of
features (Variance, Standard deviation, Energy and Waveform
length) gave the results obtained in Table III. The computation
of the Entropy instead of standard deviation provides (as shows
Table IV) an accuracy of 85.8%-76.2% , which validate that
the entropy is a better relevant feature to extract information
from the signal.

International Science Index, Biomedical and Biological Engineering Vol:12, No:10, 2018 waset.org/Publication/10009609

C. Subband Selection
In order to reduce the size of the dataset to analyze, we
selected some subspaces given by the WPT decomposition
process. Thus, the results given by Table IV were the
best results obtained. the sub-band selection component was
applied on the system with 8 levels of decomposition and
the second set of characteristics (Variance, Entropy, Waveform
Length and Energy).
1) CD1..CD4: As shows Table V, the selection of the ﬁrst
4 subspaces gives a reduction of
4 ∗ 100
= 55.55%
L
With L= Number of Levels+1 = 9.
Yet, this process gives (As shows Table V) an accuracy of
72.5%-68.5% by only selecting the Wernicke area.
2) CD5..CD8: However, the results were not good when
the subspaces CD5, CD6, CD7 and CD8 were selected, with
an accuracy of 42.2%-28.4% as shows Table VI.
3) CD2..CD7: Since the results shown in Table V are
better than the results using CD5 through CD8 subspaces,
the middle subspaces (CD2, CD3, CD4, CD5, CD6 and CD7)
were selected in order to detect where the essential information
is localized. This gives a reduction of 33.33% of the original
dataset according to the formula:
100 −

reduction = 100 −

N umberOf SelectedSubbands ∗ 100
T otalN umberOf Subbands

We obtain an accuracy of 79%-67.5% (As shows Table VII).
The results provided by this selection allow us to conclude that
a high amount of the essential information is in CD2 through
CD7 subspaces.
V. C ONCLUSION
This paper highlights the importance of the Wernicke area
for the recognition of unspoken speech through a BCI. The
proposed system, based on EEG analysis, consists of four
main components. The ﬁrst one is the headset allowing the
acquisition of the EEG signal, done here through an Emotiv
Epoc+ Headset. The second component is the preprocessing
module apply to the recorded signals. We have implemented
for that the Common Average Reference algorithm. The third
component is the feature extraction module, where the Wavelet
Packet Transform (WPT) is implemented to decompose the
preprocessed signal into subspaces and give coefﬁcient details
used for the computation of two set of features. Finally,
the fourth component is the classiﬁcation module done by

International Scholarly and Scientific Research & Innovation 12(10) 2018

conﬁguring an Artiﬁcial Neural Network with 3 layers to
classify the feature vector resulting from the third component.
The test was done using as parameters the number of levels of
decomposition of the signals and the set of features computed
on the subband resulting from the decomposition process. In
fact, the selection of only the EEG sensor on the Wernicke
area gives the results shown in Tables II-IV. This conﬁrms
that the Wernickes area contains the semantic of the unspoken
speech. Other tests were done on the dimensions reduction of
the dataset. However, the number of levels of decomposition
for the WPT method was taken into consideration as ﬁrst
criteria of amelioration of the quality of the BCI recognition.
The second criteria was the type of features computed on
the vectors resulting from the WPT decomposition. The third
criteria was the comparison between the results obtained by
selecting only the four Wernickes nearby sensor or all the
14 recording channels provided by the headset. The acquired
methodology for the construction of our system, shows better
results of classiﬁcation than the BCI done previously targeting
the recognition of 5 words, were it gives 79%-69.7% of
recognition (Table VII) with only 28.57% of the original
dataset, and add a reduction of 33.33% after selecting the
sub-bands. This gives us a total reduction of 81% of the
data set. Since we use only 19% of the original data set,
we will afford a small loss of classiﬁcation rate, although the
accuracy obtained is higher than the last BCI constructed for
the recognition of 5 words. Finally, The results conclude that
the 4 sensors F7, FC5, T7 and P7 of the Emotiv epoc+ are
indeed highly recommended for the construction of a Brain
Computer Interface system for the recognition of unspoken
speech, since they contains the highest quantity of the needed
information. As perspective, the 3D printing of a headset
containing only these 4 electrodes on the Wernickes area can
gives a high rate of recognition of unspoken speech with a
reduced price of the Headset and a greater ease of use.
R EFERENCES
[1] Hwaiyu Geng, Jim McKeeth the brain computer interface in the
internet of thingsWiley, Internet of Things and Data Analytics Handbook,
December 2016.
[2] Jerry J. Shih, Dean J. Krusienski, and Jonathan R. Wolpaw.
Brain-Computer Interfaces in Medicine Mayo Clin Proc. 2012 Mar; 87(3):
268279.
[3] M. Rajya Lakshmi, Dr. T. V. Prasad, Dr. V. Chandra Prakash, Survey
on EEG Signal Processing MethodsInternational Journal of Advanced
Research in Computer Science and Software Engineering, Volume 4, Issue
1, January 2014.
[4] Guilherme Carvalhal Ribas, The Cerebral Sulci and GyriNeurosurg Focus
56 (2): E2. PMID 20121437, 2010.
[5] Chayer C, Freedman M. Frontal lobe functionsCurr Neurol Neurosci Rep.
2001 Nov;1(6):547-52.
[6] G. H. Patel, B. J. He, M. Corbetta Attentional Networks in the Parietal
Cortex Encyclopedia of Neuroscience, 2009.
[7] Priyanka A. Abhang, Bharti W. Gawali, Suresh C. Mehrotra Introduction
to EEG and Speech-Based Emotion Recognition1st Edition, Elsevier,
2016.
[8] Bernard J. Baars, Nicole M. Gage The brain, Cognition, Brain, and
Consciousness (Second Edition), 2010.
[9] Jan-Peter Calliess, Further Investigations on Unspoken Speech Interactive
Systems Laboratorie,USA, Institut fur Theoretische Informatik, Germany,
2006.
[10] Anne Porbadnigk, EEG based Speech Recognition: Impact of
Experimental Design on Performance, Fakultat fur Informatik, Universitat
Karlsruhe, 2008.

461

scholar.waset.org/1307-6892/10009609

World Academy of Science, Engineering and Technology
International Journal of Biomedical and Biological Engineering
Vol:12, No:10, 2018

[11] May Salama, Loaay ElSherif, Haytham LAshin, Tarek
Gamal, Recognition of Unspoken Words Using Electrode
Electroencephalographic Signals, Cognitive, The sixth International
Conference on Advanced Cognitive Technologies and Applications,
2014.
[12] Nassib Abdallah, Shadi Khawandi, Bassam Daya, Pierre Chauvet, A
survey of methods for the construction of a Brain Computer Interface,
Sensors Networks Smart and Emerging Technologies (SENSET), 2017.

International Science Index, Biomedical and Biological Engineering Vol:12, No:10, 2018 waset.org/Publication/10009609

Nassib Abdallah Nassib Abdallah received a bachelor’s degree in computer
and communication networks engineering from the Lebanese university with
a scholarship of Excellence in 2013. He obtained his engineering degree in
France from ISEN-Brest in software engineering in 2015. He is currently
doing his PhD At the Lebanese University and Angers University on cerebral
signals processing for the recognition of unspoken speech, under the direction
of Pr. Bassam Daya in Lebanon and Pr. Pierre Chauvet in France.

Pierre Chauvet Pierre Chauvet is a full Professor at the Institute of Applied
Mathematics (Université Catholique de l’Ouest, Angers, France). He is a
member of the LARIS laboratory at Université d’Angers. He holds a Ph.D.
(1993) in Automatics from Université d’Angers (France) and an HdR (2001)
in Computer Science from Université Paris 8 (France). His current research
interests include artiﬁcial neural networks, simulation and biomedical.
applications.

Abd El Salam Hajjar Abd El Salam AL HAJJAR received the PHD
in Computer Science titled: ”Extraction and management of knowledge
from sites web multilingual: speciﬁcity of the Arabian language” in 2010
from Paris8 University, France. He was an assistant professor in Lebanese
University IUT-Saida from 2012, and he worked as consultant and senior
developer in Raﬁk Al Hariri Foundation DHSS, IT-department & Oger
System Company, Beirut-Branch, Specialized in the database development
(using SQl Queries, Views, Functions, and Stored Procedure), Data Migration
(using SQL Server Integration Services (SSIS)), and Business intelligence
(Microsoft SQL Server Analysis Services (SSAS), SQL Server Reporting
Services (SSRS), and Microsoft Performance Point). He was the chief of many
projects and in the programming ﬁeld using several programming languages
and technologies. His current research interests are in Arabic language
processing, in Web and data mining, artiﬁcial intelligent for biomedical
systems.

Bassam Daya Bassam Daya received the BE degree in electrical and computer
engineering in 1992 from the Lebanese University, Lebanon, the MS degree
in automatic control and applied computer in 1993 from the Ecole Centrale
of Nantes, France, and the PhD degree in automatic control and applied
computer in 1996 from the University of Angers, France. He was an assistant
professor from 1994 till 1998 in the University of Angers, France, and worked
as research engineer from 1996 till 1998 in UNIVALOIRE Society, Angers,
France. From 1998 till 2002 he was an assistant professor at the Lebanese
University, IUT of Saida, Lebanon and after it an associated professor from
2002 till 2007 in the same university and he became since 2007 a full professor
in the Lebanese University. He was awarded one of the top ten graduates
of the 1991-1992 academic year presented by the cultural center Hariri in
1992 at the American University of Lebanon, Lebanon. He obtained the ﬁrst
prize in the annual competition LIRA of the Lebanese industrial research
achievements of 2004 between all Lebanese universities on programming and
telecommunications section. He obtained as well the third prize in the same
section of the same competition LIRA for both years 2004 and 2005. He
was the chief of many projects organized by CEDAR and Ministry of culture
in Lebanon in 2006 and in 2009. He is a co-author of a best paper award
on the 30th international conference on information systems, architecture and
technology, Poland, 2009. He has more than 44 published papers. His current
research interests are in neural network architecture for robotics systems,
object detection and identiﬁcation (face, vehicle, and elderly fall detection),
iris recognition, learning Rules in the Purkinje cell system of the cerebellar
cortex and its application to a bipedal robot.

International Scholarly and Scientific Research & Innovation 12(10) 2018

462

scholar.waset.org/1307-6892/10009609

