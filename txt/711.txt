Classification of Basic Human Emotions
from Electroencephalography Data
Ximena Fernández1 , Rosana Garcı́a1 , Enrique Ferreira1(B) ,
and Juan Menéndez2
1

2

Universidad Católica del Uruguay,
Av. 8 de Octubre 2738, 11600 Montevideo, Uruguay
enferrei@ucu.edu.uy
Sentia Labs, 25 de Mayo 604, Of 102, 11100 Montevideo, Uruguay
juan.menendez@sentialabs.com

Abstract. This paper explores the combination of known signal processing techniques to analyze electroencephalography (EEG) data for
the classiﬁcation of a set of basic human emotions. An Emotiv EPOC
headset with 16 electrodes was used to measure EEG data from a population of 24 subjects who were presented an audiovisual stimuli designed
to evoke 4 emotions (rage, fear, fun and neutral). Raw data was preprocessed to eliminate noise, interference and physiologic artifacts. Discrete
Wavelet Transform (DWT) was used to extract its main characteristics
and deﬁne relevant features. Classiﬁcation was performed using diﬀerent
algorithms and results compared. The best results were obtained when
using meta-learning techniques with classiﬁcation errors at 5 %. Final
conclusions and future work are discussed.

Keywords: Electroencephalography
Human emotion classiﬁcation

1

·

Discrete Wavelet Transform

·

Introduction

Recently, scientiﬁc development has been enhanced by the application of the
interaction between diﬀerent research paradigms to help understand complex
phenomena in a ﬁeld of study. For example, the use of neuroscience techniques
to model human behavior in diﬀerent areas [1]. Usually, research on emotion analysis is based on facial expressions and voice analysis (discourse). [6]. However,
there are ways to alter those tests by masking real emotions or faking emotions
in an interview. To avoid this issue there has been growing interest in the use of
physiological data such us the EEG [2]. Ekman [5] and Winton [6] found the ﬁrst
evidences of physiological signal changes in relation to a small set of emotions.
Cacioppo [4] identiﬁed patterns within the physiological signals with statistical
signiﬁcance to emotional changes on humans. An EEG system records electrical
signals on the scalp generated by brain activity [9]. These signals are voltage
variations due to ionic currents caused by neuronal activity in the brain [8].
c Springer International Publishing Switzerland 2015

A. Pardo and J. Kittler (Eds.): CIARP 2015, LNCS 9423, pp. 108–115, 2015.
DOI: 10.1007/978-3-319-25751-8 14

Classiﬁcation of Basic Human Emotions from Electroencephalography Data

109

EEG signals are usually separated by its frequency content in 5 types. Delta
signals with frequencies up to 4 Hz and larger amplitude (250 to 325 μV ). Theta
signals in the range between 4 an 8 Hz. Alpha signals cover the range between 8
and 14 Hz and characterize relax and alert states. Beta waves, with a frequency
range between 14 and 32 Hz is related to motor activity. Gamma waves are the
fastest, with a frequency range in between 32 and 100 Hz [8]. With so many
interactions between neurons in the brain plus muscular activity and outside
interference, these signals have a relatively low signal to noise ratio. To gather
useful information from EEG data needs special equipment but also speciﬁc signal processing techniques [3,7,15,22]. On the other hand, it is a non invasive
technique with a simple setup, relatively low cost and temporal high resolution
potential that makes it ideal for engineering and clinical applications. There are
commercial products that use EEG data for diﬀerent applications such as games,
rehabilitation [11] but mostly there is not detailed information on how they do
it, making it diﬃcult to use on research. This work makes use of a medium
range commercial platform to gather EEG data from a designed experiment on
24 subjects and presents a signal processing strategy applying wavelet theory
and meta-learning techniques to classify four basic human emotions.
The paper is organized as follows: section 2 explains the methodology used,
equipment, population and experiment protocol. Section 3 describes the signal
processing techniques employed to classify the emotions present in the data.
Results are presented in section 4. Finally, conclusions and future work are presented in section 5.

2
2.1

Methodology
Population

EEG signals were recorded from 24 subjects between 22 and 39 years of age, 16
male and 8 women. None of them had any history of physical or mental illnesses
nor were taking any drugs or medication that could aﬀect EEG data. All subjects
were informed of the scope and objectives of the test and signed an informed
agreement with a detailed explanation of the test. Besides, any subject could
leave the experiment at any time if desired.
2.2

Experimental Setup

EEG data was measured and recorded using an Emotiv EPOC headset with
16 channels, although two of them were used as reference [10]. Ag/AgCl electrodes were placed on the subject’s scalp using the international 10-20 standard
convention [9]. Sampling time selected was 128 Hz. The headset is connected
to a PC which receives the time sequences corresponding to each channel. The
sequences are preprocessed in the device with 2 notch ﬁlters at 50 and 60 Hz to
eliminate power line interference and a passband ﬁlter of 0.16-45 Hz bandwidth.
The device also gives a measure of the contact quality on each channel. Data
was discarded if contact quality on a given channel was no good.

110

2.3

X. Fernández et al.

Test Protocol

The subjects were sat in front of a PC running the Psychopy [12] application with
the headset correctly placed. A sequence of 12 audiovisual clips was presented
to the subjects to elicit 4 emotions: rage, fear, fun and neutral (or absence
of emotion), with 3 clips per emotion. The clips were selected from FilmStim
[13], a free stimuli database. Each clip, taken from a commercial ﬁlm, has been
validated to elicit a speciﬁc emotion, even for spanish speakers [14,18]. The
order of clips in the sequence is such that consecutive clips can not evoke the
same emotion. In between clips a short survey with 3 SAM images [19] is given
for relaxation and in order to neutralize the eﬀects of one clip on the next.
Three 12-sequence audiovisual protocols were generated using the same 12 clips
in diﬀerent order, randomly selecting one for each subject. The experimental
process is summarized in Fig. 1. The whole test took between 30 to 45 minutes
to complete for all subjects.

Fig. 1. Test protocol presented to each subject: a sequence of 12 audiovisual clips to
elicit a speciﬁc emotion alternated with a survey of 3 SAM images.

3
3.1

Data Classification Process
Preprocessing

EEG raw signal is contaminated with noise and artifacts of external and physiologic origin. Emotiv EPOCH acquires and ﬁlters the raw data with notch ﬁlters
in 50 and 60 Hz to eliminate interference from the power line and a passband
ﬁlter with 0.16-45 Hz bandwidth [10]. There are still non desired artifacts in the
channel signal as shown in Fig. 2.
First, the EEG raw data obtained from Emotiv for each subject is segmented
in time in 12 pieces corresponding to each clip. To further eliminate artifacts such
as eye and eyebrow movements and neck muscle activity the clean rawdata()
wrapper function from the Artifacts Subspace Reconstruction (ASR) extension
to the EEGLAB Matlab Toolbox was applied [20]. Normalization of the ﬁltered
data was performed before extracting the main features to use for classiﬁcation.
3.2

Feature Extraction

Preprocessed data is still too big and complex to be able to discriminate emotions
from them directly. A set of relevant features needs to be extracted to minimize
classiﬁcation mistakes. Because EEG data is a strongly non-stationary signal

Classiﬁcation of Basic Human Emotions from Electroencephalography Data

111

Fig. 2. Raw data from all 14 active headset channels showing ocular artifacts (red
oval).

a multi-resolution analysis method using a Wavelet Transform is selected to
compress the data without losing too much information from it as proposed in
[17,21,22]. DWT uses a mother wave Ψ (t) to generate the basis for decomposition
of the time sequences recorded from EEG signals. Three mother waves were
selected, two from the Daubechies family (db4, db8) and one from the Symlet
(sym8) because they provided acceptable time-frequency resolution [23,24]. The
basis is generated using two integer parameters j and k, the scale and translation
indexes, giving the wavelets
Ψj,k (t) = Ψ (2j t − k),

j = 1, . . . , n

k = 1, . . . , N,

(1)

with N the number of samples and n the number of decomposition levels. Since
the sampling frequency is 128 Hz, n = 14 decomposition levels were used to have
suﬃcient discrimination for the 5 types of EEG waves. Each EEG preprocessed
sampled data per subject, channel and clip s(t) can be expressed in terms of the
wavelets as
N 
n

dj (k).Ψj,k (t).
(2)
s(t) =
k=1 j=1

The coeﬃcients dj (k) were computed using the Quadrature Mirror Filter Bank
[22]. Based on the coeﬃcients dj (k) the following features were computed:
1. Power. The power of the signal for each frequency decomposition level j.
Pj =

N
1 
|dj (k)|2 ,
N
k=1

j = 1, . . . , n.

(3)

112

X. Fernández et al.

2. Variance. A measure of the variation of the coeﬃcients of the signal for
each frequency decomposition level j.
Vj =

N
1 
(dj (k) − d¯j )2 ,
N

j = 1, . . . , n.

(4)

k=1

with d¯j the mean value of the coeﬃcients dj (k) of the signal for a level of
decomposition j over all k.
3. Entropy.
H=−

n


pj log(pj )

(5)

j=1

pj =

Ej
,
ET

j = 1, . . . , n,

(6)

with Ej the energy in the jth frequency band and ET the total energy.
In summary, for each EEG channel and clip, 2n + 1 features are generated.
3.3

Classification Process

Pattern classiﬁcation algorithms associate each element, i.e. each set of feature
values characterizing the current emotion of a subject, with one of the 4 emotions
analyzed. In this work a comparison of the best classiﬁers used for a similar problem in previous works was carried out [16,21]. Those were: K-nearest neighbors
(KNN), AdaBoost and Random Committee. KNN is a nonparametric classiﬁer
where a decision for an individual value is taken by looking at which classes its K
nearest neighbors are and voting. It is robust to outliers. K values between 2 and
8 were tried to ﬁnd the optimum (K=3). AdaBoost is a supervised learning algorithm that combines weak classiﬁers to generate a strong classiﬁer. It is robust
to overﬁtting but sensible to outliers [25,26]. The best results were reached when
using the kernel called J48 [28]. RandomCommittee is a technique within the
framework of metalearning algorithms. It takes existing classiﬁer systems and
generates an ensemble of instances of classiﬁers using random parameters that
are embedded in the base classiﬁers selected. The classiﬁcation is made by either
voting or averaging the results of the ensemble of classiﬁers generated.In this
work the best results were obtained when using RandomForest as the base classiﬁer and averaging their results [27]. Classiﬁcation was performed using the tool
WEKA [29], using 10-fold cross validation and pattern testing with 10 percent
fresh data.

4

Results

The tables below show the results as percentage of correct classiﬁcation and
ROC area for each class, and total percentage of correct classiﬁcation for the
three classiﬁers selected.

Classiﬁcation of Basic Human Emotions from Electroencephalography Data

113

Table 1. Classiﬁcation accuracy when using KNN method with k=3.

db4
% ROC
Correct Classiﬁcation (%) 79.9
Fear
70.0 0.900
80.0 0.819
Rage
77.4 0.924
Fun
98.1 0.992
Neutral
Weighted Average
81.0 0.909

db8
% ROC
73.4
63.8 0.820
74.1 0.846
64.7 0.845
96.2 0.991
74.3 0.874

sym8
% ROC
59.4
44.7 0.734
45.8 0.704
58.3 0.805
98.2 0.994
60.2 0.807

Table 2. Classiﬁcation accuracy using Random Committee with Random Forest kernel.

db4
% ROC
Correct Classiﬁcation (%) 94.3
Fear
87.5 0.989
96.5 0.993
Rage
94.8 0.990
Fun
100 1.00
Neutral
Weighted Average
94.5 0.975

db8
% ROC
91.8
83.1 0.978
91.5 0.992
88.3 0.983
98.3 1.00
92.1 0.960

sym8
% ROC
84.6
73.3 0.949
89.4 0.939
83.0 0.947
98.0 0.999
85.5 0.958

Table 3. Individual Classiﬁcation Accuracy when using AdaBoostM1 with kernel J48.

db4
% ROC
Correct Classiﬁcation (%) 87.3
Fear
89.5 0.956
83.3 0.986
Rage
81.8 0.974
Fun
96.4 0.985
Neutral
Weighted Average
87.8 0.975

db8
% ROC
82.4
76.6 0.932
83.6 0.980
76.6 0.944
94.5 0.987
82.6 0.960

sym8
% ROC
77.9
73.3 0.899
69.5 0.899
75.8 0.951
98.2 0.995
78.2 0.935

Table 4. Confusion matrix for Random Committee for db4 feature set.
Fear Rage Fun Neutral
Fear
64
0
2
0
6
53
0
0
Rage
5
0
55
0
Fun
2
0
57
Neutral 0

114

X. Fernández et al.

For the three types of wavelets selected the Random Committee classiﬁer
obtained the best results. Within each classiﬁer, the wavelet of type Daubechies
with 4 vanishing moments (db4) outperform the others, reaching 94.3 % of overall correct classiﬁcation percentage for the Random Committee classiﬁer. ROC
values are mostly acceptable at around 90 % in all cases and higher than 97 %
for the best results. Finally, the best classiﬁer reached 87.5 % classiﬁcation accuracy on the test set. Looking at the emotions themselves, the neutral emotion
was the easiest to discriminate for any classiﬁer throughout. On the other hand,
the Fear emotion seems to dominate over Rage and Fun according to Table 4.

5

Conclusions

This work presents a system to record, analyze EEG signals and classify basic
human emotions. An experiment was conducted using 24 subjects with a validated database of audiovisual clips to induce rage, fear, fun or neutral emotions. Even though the hardware only allowed to sense 16 channels compare to
research devices with 64 up to 256 electrodes, by an adequate signal processing
using DWT and relevant features, the overall percentage of errors achieved was
around 5 % when using meta-learning techniques. Some of the mistakes between
classes might be due to a smaller train set or the clips themselves that were
in some cases too long and with mixed feelings to clearly represent the emotion assigned even though the dataset has been validated internationally. The
study allowed to see the impact in classiﬁcation of the selection of features, algorithms for eliminating artifact in the signals and wavelets selected. The results
are promising to consider an EEG system like this one a relatively low cost new
complex sensor device for research into other bioengineering areas. From a practical point of view, the use of shorter clips should be better to have less dispersion
in the data. Also, to have more subjects will improve the statistics. Future work
includes the use of other techniques to improve the elimination of artifacts such
as independent component analysis, to reduce the dimensionality of the problem
in the feature space and the application of this sensor in neuromarketing and
rehabilitation engineering.

References
1. Lee, N., Broderick, A.J., Chanberlain, L.: What is neuromarketing? A discussion
and agenda for future research. Int. J. Psychophysiol. 63(2), 199–204 (2007)
2. Jatupaiboon, N., Pan-ngum, S., Israsena, P.: Real-Time EEG-Based Happiness
Detection System. The Scientiﬁc World Journal 2013, 12 (2013). ID 618649
3. Torres, A.A., Reyes, C.A., Villaseor, L., Ramrez, J.M.: Anlisis de Seales Electroencefalogrﬁcas para la Clasiﬁcacin de Habla Imaginada. Revista Mexicana de
Ingeniera Biomdica 34(1), 23–39 (2013)
4. Cacioppo, C.T., Tassinary, L.G.: Inferring Physiological Signiﬁcance from Physiological Signals. Am. Psychol. 45(1), 16–28 (1990)
5. Ekman, P., Levenson, R.W., Freison, W.V.: Autonomic Nervous System Activity
Distinguishes Among Emotions. J. Exp. Soc. Psychol. 19, 195–216 (1983)

Classiﬁcation of Basic Human Emotions from Electroencephalography Data

115

6. Winton, W.M., Putnam, L., Krauss, R.: Facial and Autonomic Manifestations of
the dimensional structure of Emotion. J. Exp. Soc. Psychol. 20, 195–216 (1984)
7. Murugappan, M., Murugappan, S., Balaganapathy, C.: Wireless EEG signals based
neuromarketing system using fast fourier transform (FFT). In: 10th Int. Col. on
Signal Processing & its Applications, pp. 25–30. IEEE (2014)
8. Lopes da Silva, F., Niedermeyer, E.: Electroencephalography: Basic Principles,
Clinical Applications, and Related Fields, 6th edn. Lippincot Williams & Wilkins
(2004). ISBN 0-7817-5126-8
9. Sanei, S., Sanei, S., Chambers, J.A.: EEG Signal Processing. Centre of Digital
Signal Processing Cardiﬀ University, UK (2007). ISBN 978-0-470-02581-9
10. (2015). http://www.emotiv.com/
11. (2015). http://neurogadget.com/category/headset-2
12. Pierce, J.W.: PsychoPy. Psychophysics software in Python (2007). http://www.
psychopy.org/
13. Schaefer, A., Nils, F., Snchez, X., Philippot, P.: FilmStim, Assessing the eﬀectiveness of a large database of emotion-eliciting ﬁlms: A new tool for emotion
researchers. Cognition and Emotion 24(7), 1153–1172 (2010)
14. Fernandez Megas, C., Prez Sola, V.: Inducción de emociones en condiciones
experimentales: un banco de estı́mulos audiovisuales. Programa de Doctorado en
Psiquiatra Departament de Psiquiatria i Medicin UAB (2012)
15. Murugappan, M., Nagarajan, R., Yaacob, S.: Combining Spatial Filtering and
Wavelet Transform for Classifying Human Emotions Using EEG Signals. IEEE
Symposium on Industrial Electronics & Applications 2, 836–841 (2009)
16. Murugappan, M.: Human emotion classiﬁcation using wavelet transform and KNN.
In: Int. Conf. on Pattern Analysis and Intelligent Robotics, vol. 11, pp. 48–153
(2011)
17. Murugappan, M., Nagarajan, R., Yaacob, S.: Comparison of diﬀerent wavelet features from EEG signals for classifying human emotions. IEEE Symposium on
Industrial Electronics & Applications 2, 836–841 (2009)
18. Fernandez, C., Pascual, J.C., Soler, J., Garca, E.: Validacin espaola de una batera
de pelculas para inducir emociones. Psicothema 23(4), 778–785 (2011)
19. Bradley, M., Lang, P.: Measuring Emotion: the Self-Assessment Semantic Diﬀerential. J. Behav. Ther. & Exp. Psvchrar. 25(1), 49–59 (1994)
20. EEGLAB Wiki. http://sccn.ucsd.edu/wiki/EEGLAB
21. Weber, P., Letelier, J.: Clasiﬁcacion de Espigas Extracelulares Basada en la Transformada de Wavelet Discreta. Universidad de Chile (2002). http://repositorio.
uchile.cl/tesis/uchile/2002/weber p/html/index-frames.html
22. Samar, V.J., Bopardikar, A.: Wavelet analysis of neuroelectric waveforms: a conceptual tutorial. Brain and Language 66(1), 7–60 (1999)
23. Mallat, S.: A wavelet tour of signal processing. Academic Press (1999)
24. Parameswariah, C., Cox, M.: Frequency characteristics of wavelets. IEEE Transactions on Power Delivery 17(3), 800–804 (2002). ISSN: 0885–8977
25. Witten, H., Frank, I., Hall, M.: DATA MINING Practical Machine Learning Tools
and Techniques, 3rd edn, pp. 356–372 (2011)
26. Aha, D., Kibler, D.: Instance-based learning algorithms. Machine Learning 6(1),
37–66 (1991)
27. Breiman, L.: Random Forests. Machine Learning 45(1), 5–32 (2001)
28. Quinlan, J.R.: C4.5: Programs for Machine Learning. Machine Learning 16(3),
235–240 (1994)
29. Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.H.: The
WEKA Data Mining Software: An Update. SIGKDD Explorations 11(1) (2009)

