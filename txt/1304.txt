International Journal of Computer Applications (0975 – 8887)
Volume 120 – No.2, June 2015

k-NN based Object Recognition System using Brain
Computer Interface
Anupama H S

Cauvery N K

Lingaraju G M

Assistant Professor
Dept of CSE, RVCE

Professor and Head
Dept of ISE, RVCE

Professor
Dept of ISE, MSRIT

ABSTRACT
Brain Computer Interface is a device which provides the
communication between the human brain and the computer. This
paper provides an idea of object recognition system using
Principal Component Analysis (PCA) and Singular Value
Decomposition (SVD). This is used to recognize the object by
analyzing EEG signals in real time. K-Nearest Neighbors
algorithm is implemented to classify the intended object.
Multiple training sets and users are taken into account during the
experiment and the efficiency of the algorithm is calculated.

Data
Acquisition and
Signal

1. INTRODUCTION
BCI started with Hans Berger in 1924. He found out that some
electrical activity is generated in human brain. He inserted
simple tubes inside the brain and connected that to Lippmann
capillary electrodes and observed for the signals. He could found
some oscillatory movement from human brain which we call it
as alpha wave (8–12 Hz), also known as Berger's wave.
Brain Computer Interface (BCI) is a non invasive
Electroencephalogram (EEG) based device, where research has
been immensely increased in this area over the past few years.
BCI is mainly used for disabled who cannot move their body,
basically who are paralyzed. To control BCI device user has to
produce different brain patterns which will be identified by the
system and then translates into intended commands.
Three main aspects of BCI are data acquisition, noise reduction
and classification. In data acquisition, features are extracted
from the human brain which is been generated when a person
thinks of some objects. The signals are then analyzed and given
to noise reduction technique as the obtained signals are not noise
free.[4,5] Because of some disturbances EEG signals are
distorted which has to be reduced. Proper noise reduction
algorithms are run on them to reduce the noise. At last
classification algorithms are used to differentiate the signals and
map the signals with the intended object whatever the user has
thought. Classification is the most difficult task in the brain
signals because every user doesn’t produce the same signals. It
varies from person to person which has to be classified based on
the proper and suitable classification algorithms. Therefore a
customized profile needs to be created for each person, where
he/she has to carry out independent training for each object.
Finally the decoded signals are sent to other control devices and
application which can use it as an input interface [1, 2]. The
aspect of BCI is shown in fig1.

Classification
Algorithm

Brain Signals
Control device
and application

Feedback

Index Terms
Brain Computer Interface, Invasive and Non-Invasive,
Electroencephalography (EEG), Emotive epoc, K-Nearest
Neighbors, Object recognition

Feature
Extraction

Fig 1. Representation of BCI
This paper presents a system which is mainly designed for object
recognition through real time EEG and reduces the noise using
some transformation algorithms and later on implements
classification algorithm to classify the object and identify the
object. The experiment is carried out using emotiv epoc device,
and has been carried out by multiple users and each of the users
has been tested with different sets of training data and efficiency
is calculated [1, 2].

2. EEG BASED BCI
A common method for designing a BCI is to use EEG signals
extracted during mental tasks . EEG is the most widely used
neuroimaging modality, owing to its high temporal resolution,
relative low cost, high portability, and few risks to the users.
EEG is the recording of brain’s electrical activity along the scalp
produced by the firing of neurons within the brain. However, the
signals are of low resolution as the signals have to cross the
scalp, skull, and many other layers [5]. So the signal strength in
the electrodes is weak, in the order of micro volts and very
sensitive to noise. Noise is the key factor in EEG signals, as it
reduces the signal to noise ratio and therefore the ability to
extract meaningful information from the recorded signals . The
noise may be either due to additional current fields inside the
brain or due to external noise sources.
The EEG recording system consists of electrodes, amplifiers,
A/D converter, and a recording device. The electrodes obtain the
signal from the scalp, the amplifiers magnify the amplitude of
the EEG signals and the A/D converter digitizes these signals.
Finally, the recording device stores and displays the data. The
EEG signal is measured as the potential difference over time
between the active electrode and reference electrode. The
multichannel EEG sets contain upto 128 or 256 active
electrodes. These electrodes are generally made of silver
chloride (AgCl). The EEG gel is an electrolyte which creates a
conductive path between the skin and the electrode for the
current flow. Electrodes that do not use gels, called ‘dry’
electrodes, are made with materials such as titanium and
stainless-steel.

35

International Journal of Computer Applications (0975 – 8887)
Volume 120 – No.2, June 2015
EEG comprises of a set of frequency bands. These frequency
bands are referred to as delta (δ), theta (θ), alpha (α), beta (β),
and gamma (γ) respectively. Relevant characteristics of these
bands are detailed below.
Table 1: Frequency bands in the brain signal
EEG
Bands

Frequency
(Hz)

Delta

upto 4

Theta

4–8

Alpha

8 – 13

Mu

10 -12

Beta

Gamma

13 – 30

> 30

Distribution
Central
cerebrum and
parietal lobes
Frontal,
parietal
and
temporal lobes
Most
prominent at
occipital and
parietal lobe
Central
electrodes,
over
motor
and
somatosensory
cortex
Localized

Very localized

State of Mind
Deep sleep,
REM sleep

non-

Drowsiness,
stage of sleep

first

Relaxed but alert

Shows
rest-state
motor neurons

2.

Noise Reduction

and

In this step, the idea is to reduce the noise in the EEG signals to
some extent. The concepts of Singular Value Decomposition
(SVD) and Principal Component Analysis (PCA) have been
used to reduce noise in these signals.

higher
mental
activity, including
perception
and
consciousness

PCA is used to convert a set of observations of possibly
correlated variables into a set of values of linearly uncorrelated
variables.

Highly alert
focused

3. METHODOLOGY
The proposed work composed of three separate modules. These
modules can be run separately or be run from a main script. The
modules are:

1.

Fig 2: Data extraction from the emotive epoc

Data Extraction

This is the first step or module of the proposed work which is
used to obtain the electroencephalography (EEG) signals from
the neuroheadset in the form of sensor readings and store it in a
file. The neuroheadset used in our experiment is emotive epoc
[5] which is of 14 electrodes device, high resolution, multichannel, wireless neuroheadset. Electrodes are placed on 14
different part of the brain scalp of the human brain and
connected to SDK of the emotive epoc. Once the device is ready
we will get the EEG signals [7, 8] of that user in the form of
waveforms. The waveforms obtained are not noise free. Noise
has been incurred because of the disturbances created while
capturing the EEG signals. Once the waveform is obtained, we
extract those signals into numerical and store it in a CSV file.
Research Edition SDK includes a proprietary software toolkit
that exposes the APIs to extract data in numerical form.Once the
interface is done with the device obtained sensor readings can be
processed subsequently.

Singular Value Decomposition (SVD) is used to remove noise
from the values obtained. The Eigen vectors and Eigen values of
the data are obtained by applying SVD. The Eigen values and
their corresponding Eigen vectors are sorted in decreasing order
of Eigen values. The sum of the Eigen values is found and the
Eigen values that contribute 99% of this sum are retained and
the ones that contribute to the last 1% are set to zero (0). This
removes the effect of the Eigen vectors corresponding to these
Eigen values. The rationale is that the small contributions from
these Eigen vectors must represent noise.

3.

Classification

Finally, the filtered data is classified to one of the categories or
classes established in the classification phase. The proposed
work employs the use of k-Nearest Neighbour Algorithm to
classify the data. The final task is to classify the records into one
of the labels defined using training. The model can be built as
the training is being performed (early learner approach) or when
classification needs to be performed (late learners approach).
The proposed work uses k Nearest Neighbors (kNN) algorithm.
This is a late learner’s technique. This takes longer to classify as
it involves a lot of computation at the time classification needs
to be performed. [15, 16, 17]

K-Nearest Neighbor
The k-NN classifies the feature vectors based on closest training
examples in the feature space.[15] The advantage of the k-NN
method over other supervised learning methods is its ability to
deal with multiple class problems. The feature vector is
classified by a majority vote of its neighbors, and is assigned to
the class which has lesser distance amongst its k nearest
neighbors, where k is a positive integer, typically small to make
boundaries between classes more distinct. Euclidean distance is
used as a distance metric for our work and the value of k is
chosen as 3 after repeated cross validation. The vector is simply
predicted and assigned to the class of its nearest neighbor.

36

International Journal of Computer Applications (0975 – 8887)
Volume 120 – No.2, June 2015
In the training phase of the system, the feature vectors and the
corresponding class labels of the training samples are stored.
The training samples are vectors in a multidimensional feature
space, each with an assigned class label. In the classification
phase, the unlabeled feature vector is classified by assigning the
label which is most frequent among the k training samples
nearest to that query point [17]. From fig 3 the test sample
(purple circle) should be classified either to the first class of
green squares or to the second class of red stars. If k = 3, it looks
for 3 nearest neighbors and it is assigned to the second class
because there are 2 stars and only 1 square inside the inner
circle. If k = 5, it looks for 5 nearest neighbors, it is assigned to
the first class of green squares as there are 3 squares and 2 stars
inside the outer circle.

An experiment was conducted on different individuals consists
of boys and girls with ages between 20 and 25 using emotive
epoc headset. [16, 17] The proposed work consists of two things.


Training
1.

{python.exe code/main.py <classLabel>}

The above command classifies the data recorded subsequently as
an object whose name is specified by classLabel.


Testing
2.

{python.exe code/main.py}

The above command tries to classify the obtain EEG signals into
one of the class labels recorded during training.
In data extraction, samples were collected for 10 seconds and
stores the resultant data in the output file specified as shown
below:
3.

{code/dataExtraction/dataExtraction.exe
<outputFileName>}

Later in noise reduction, it reduces the noise from the data
obtained by the neuroheadset. It uses Singular Value
Decomposition (SVD) and Principal Component Analysis
(PCA) which is as shown below:
4.

{code/svd/svd.exe
<outputFileName>}

<inputFileName>

It performs SVD on the contents of the input file specified and
removes some noise from the data. The output is stored in the
output file specified.
Fig 3. Example of k-NN classification for k=3 and k=5

4. EXPERIMENTAL SETUP
Fig 4 shows the block diagram of the entire process beginning
from data accusation via the EEG headset up till the results of
the classification algorithm

In Classification, data is classified data into one of the class
labels by applying the k-nearest neighbours algorithm as shown
below:
5.

{code/classification/nearestNeighbour.py<tra
iningDataSet> <testFile>}

It classifies the contents of test file using the training data set.

5. CONSLUSION AND FUTURE WORK
The main aim of this paper was to implement a system which
recognizes the object, analyze the signals by reducing the noise
and classify them based on the machine learning algorithm. The
experiment began with the users training the machine to
recognize different objects; this was accomplished by showing
the user a picture of the object while collecting the EEG signals
generated by him/her as a result of seeing the object. This
process of recording the signals was done for multiple users.
Once the machine was well trained, it was tested for its accuracy
by checking its correctness in classifying a reading for an object
that the machine had already learnt. Based on these test results,
it can be concluded that k-nearest neighbors has an efficiency of
75% in recognizing the objects.
Currently, real-time object recognition is implemented as a
standalone application. The next step of the project is to target
the medical industry and help paralyzed patients to communicate
with their environment and overcome their disabilities to express
their thoughts. The future enhancement includes noise reduction
using the algorithms like band-pass filters and newer algorithms
like fractal dimension, it also includes the usage of a more
powerful device that has a stronger and more focused signal
readings.

6. REFERENCES
Fig 4. Block Diagram of the system

[1] Anupama.H.S,

N.K.Cauvery,

Lingaraju.G.M,

“Brain

37

International Journal of Computer Applications (0975 – 8887)
Volume 120 – No.2, June 2015
computer interface and its types - a study”, International
Journal of Advances in Engineering & Technology, May
2012.
[2] Anupama.H.S, N.K.Cauvery, Lingaraju.G.M, “Real Time
EEG Based Object Recognition system using Barin
Computer Interface”, Nov 2014, pg no-1046-1051.
[3] G. Lorina Naci, Martin M. Monti, Damian Cruse, Andrea
Ku¨ bler, Bettina Sorger, Rainer Goebel, Boris Kotchoubey,
and Adrian M. Owen, “Brain–Computer Interfaces for
communication with nonresponsive patients”, unpublished.
[4] W. Lutzenberger, T. Elbert, N. Birbaumer, W. J. Ray, and
H. Schupp, “The scalp distribution of the fractal dimension
of the EEG and its variation with mental tasks,” Brain
Topography, vol. 5, 1992, pp. 27-34.
[5] About Emotive Epoc. http://emotiv.com/epoc/
[6] Nicolas-Alonso, Luis Fernando, and Jaime Gomez-Gil.
"Brain computer interfaces, a review." Sensors 12, no. 2
(2012): 1211-1279.
[7] Yisi Liu, Olga Sourina, and Minh Khoa Nguyen, “Realtime EEG-based Human Emotion Recognition and
Visualization,” unpublished.
[8] Emotiv Software Development Kit, User Manual for
Release 1.0.0.3.
[9] Mitchell, T. M., “Machine Learning”, McGraw-Hill, New
York, NY, 2nd Edition, 1997.
[10] Ravindra Changala, Annapurna Gummadi, G Yedukondalu,
UNPG Raju ,“Classification by Decision Tree Induction

Algorithm to Learn Decision Trees from the class-Labeled
Training Tuples “, International Journal of Advanced
Research in Computer Science and Software Engineering,
Volume 2, Issue 4, April 2012.
[11] Fayyad, U. M., Irani, K. B., “On the handling of
continuous-valued attributes in decision tree generation,”
Machine Learning, 1992.
[12] J. Goleberger, S. Roweis, G. Hinton, and R. Salahhutidnov,
“neighbourhood components analysis”, Advances in Neural
Information Processing Systems 17, Cambridge, MA, 2005.
[13] Lal, T.N, Schr¨oder, M.T, Hinterberger, J., Weston, M.,
Bogdan, N., Birbaumer, B and Sch¨olkopf, “Support Vector
Channel Selection in BCI”, in the proceedings of IEEE
Transactions on Biomedical Engineering, Special Issue on
Brain-Computer Interfaces, June 2004.
[14] Mason, Steven G., and Gary E. Birch. "A general
framework for brain-computer interface design." Neural
Systems
and
Rehabilitation
Engineering,
IEEE
Transactions on 11, no. 1 (2003): 70-85.
[15] Zhang, Hao, et al. "SVM-KNN: Discriminative nearest
neighbor classification for visual category recognition."
Computer Vision and Pattern Recognition, 2006 IEEE
Computer Society Conference on. Vol. 2. IEEE, 2006.
[16] Python. https://docs.python.org/2.7/library
[17] K-NearestNeighbour.
http://saravananthirumuruganathan.wordpress.com/2010/05
/17/a-detailed-introduction-to-k-nearest-neighbor-knnalgorithm/

IJCATM : www.ijcaonline.org
38

