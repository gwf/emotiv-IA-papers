This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

1

Steady State Visual Evoked Potential-based
Computer Gaming on a Consumer-grade EEG
Device
Nikolay Chumerin∗ , Nikolay V. Manyakov∗ , Marijn van Vliet, Arne Robben, Adrien Combaz,
and Marc M. Van Hulle, Senior Member, IEEE

Abstract—We introduce a game in which the player navigates
an avatar through a maze by using a brain-computer interface
(BCI) that analyzes the steady-state visual evoked potential
(SSVEP) responses recorded with electroencephalography (EEG)
on the player’s scalp. The four command control game, called
“The Maze” was specifically designed around a SSVEP BCI
and validated in several EEG set-ups when using a traditional
electrode cap with relocatable electrodes and a consumer-grade
headset with fixed electrodes (Emotiv EPOC). We experimentally
derive the parameter values that provide an acceptable trade-off
between accuracy of game control and interactivity, and evaluate
the control provided by the BCI during gameplay. As a final step
in the validation of the game, a population study on a broad
audience was conducted with the EPOC headset in a real-world
setting. The study revealed that the majority (85%) of the players
enjoyed the game despite of its intricate control (mean accuracy
80.37%, mean mission time ratio 0.90). We also discuss what to
take into account while designing BCI-based games.
Index Terms—brain-computer interface, games, humancomputer interaction, electroencephalography, steady-state visual
evoked potentials.

I. I NTRODUCTION

W

ITH a brain-computer interface (BCI), a subject’s
brain activity is recorded and used for enabling the
subject to interact with the external world without involving
any muscular activity or peripheral nerves. BCIs are now
widely regarded as one of the most successful engineering
applications of the neurosciences since they are in a position
to significantly improve the quality of life of patients suffering
from severe motor and/or communicative disabilities (e.g.,
amyotrophic lateral sclerosis, stroke, brain/spinal cord injury,
cerebral palsy, muscular dystrophy, etc.) [1], [2]. Apart from
clinical applications, researchers have also started to use BCIs
in computer games as an in-lab testbed for new decoding
algorithms and paradigms [3], [4], [5], [6], [7], [8], [9], [10].
In the same time, these BCIs mostly rely on conventional electroencephalography (EEG) equipment, which requires specific
skills (i.e., positioning the cap, application of conductive gel
to the electrodes, verifying the signal quality etc.), making it
all too cumbersome and time consuming experience for the
average user. Also, much EEG research is performed in a
∗ Equally contributed authors.
All authors are with the Laboratorium voor Neuro- en Psychofysiologie,
KU Leuven, Campus Gasthuisberg, O&N 2, Herestraat 49, 3000 Leuven,
Belgium e-mail: {Nikolay.Chumerin, NikolayV.Manyakov, Marijn.vanVliet,
Arne.Robben, Adrien.Combaz, Marc.VanHulle}@med.kuleuven.be

shielded room (Faraday Cage) for obtaining better and cleaner
(i.e., with less artifacts) signals. For these reasons, BCI games
based on EEG have rarely met the general public. In the
community this is actually regarded as a challenge for the
future [8], [11].
At the time of writing, several commercial BCI games are
available on the market. Systems that received a lot of media
attention are the ones based on the NeuroSky1 device, for
instance the “Force trainer”. It allows the player to raise and
lower a ball by controlling the rotational speed of a fan by
the player’s “concentration” level2 . Mind Flex3 , produced by
Mattel Inc., which is also based on the NeuroSky device, takes
this concept a step further and adds a turning knob with which
the player can control the position of the fan. The goal is
to guide the ball through an obstacle course. Both games do
not offer precise control and have caused consumer criticisms
regarding whether the player has any control at all4 . In addition
to this, the mentioned games are quite simple compared to
what is considered in BCI games research.
BCI games intended for a broad audience are required
to be easy to set up, the EEG recording device should be
comfortable to wear, and game to work properly even in
noisy, uncontrolled environments, so that they can be used
everywhere [8], [11]. While the potential of BCI games for
entertainment has been reported before [11], to the best of our
knowledge, there has been no attempt to create and validate a
BCI game satisfying the aforementioned requirements. Even
the standard BCI applications such as, for example, the brain
signal based spelling devices [12], have rarely been evaluated on a broad audience [13], [14], [15]. The majority of
the existing BCI games do not meet the above mentioned
requirements, and by consequence are not expected to fulfill
the user’s expectations. In this article, we present the design,
the evaluation, and the assessment of a BCI game based
on an inexpensive, consumer-grade EEG device, the Emotiv
EPOC. Our study also enabled us to collect feedback from
naı̈ve participants, recruited voluntarily from a broad audience,
playing a BCI game for the first time.
In attempt to make the BCI game even more attractive to the
general public, we wanted our game to satisfy some additional
requirements, such as user comfort and the set-up time of the
1 http://www.neurosky.com
2 http://company.neurosky.com/products/force-trainer
3 http://www.mindflexgames.com
4 http://youtu.be/HsmLA9PqTGM

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

BCI. By the first criterion, we mean the discomfort caused
by the preparation of the set-up and by the electrodes (e.g.,
dry electrodes potentially do not require any gel or liquid,
but cause a lot of discomfort). Therefore, we opted for the
consumer-grade EPOC headset. The second criterion refers
to the choice of the BCI paradigm. The set-up time can be
minimized by selecting a paradigm that does not require any
calibration/training (neither for the algorithm nor for the user).
We opted for the steady-state visual evoked potential (SSVEP),
which is recorded from the occipital pole of the skull. It is
the response to a repetitive presentation of a visual stimulus
(i.e., flickering stimulus). When repetition is at a sufficiently
high rate (starting from 6 Hz), the individual EEG responses
overlap, leading to a steady state signal resonating at the
stimulus rate and its multipliers (harmonics) [16]. With this
paradigm it is possible to detect whether a subject is looking
at a stimulus flickering at frequency f1 or not, by verifying the
saliency of the frequencies f1 , 2f1 , 3f1 , . . . in the spectrum of
the recorded EEG signal (see Fig. 1). Similarly, one can detect
which stimulus, out of several of them (each one flickering at
a different frequency f1 , f2 , . . . , fnf ), is attended to by the
subject. By linking each flickering stimulus to a particular
command, a multi-command frequency-coded SSVEP-based
BCI can be implemented,
Since in the spectral domain the EEG amplitude decreases
as 1/f [17], the higher harmonics become less prominent.
Furthermore, the SSVEP is embedded in other on-going brain
activity and (recording) noise. Thus, when considering a
recording interval that is too small, erroneous detections are
quite likely to occur. To overcome this problem, averaging
over several recording intervals [18], or recording over longer
time intervals [19] are often used for increasing the signal-tonoise ratio (SNR). An efficient frequency-coded SSVEP-based
BCI should be able to reliably detect several (nf ) frequencies
(see Fig. 1), which makes the SSVEP detection problem more
complex, calling for an efficient signal processing and decoding algorithm. Thus, the design of a BCI game is expected to
involve a good deal of signal processing and machine learning
to ensure a proper detection of the brain activity patterns. It is
also expected that (a minimal amount of) decoding mistakes
could be for the benefit of the game, turning a shortcoming
into a challenge [11]. In this paper, we try to accommodate
all these points in a BCI game designed for a broad audience
with an easy to use and low-cost EEG device operating in a
noisy, uncontrolled environment.
The goal of this study is not only to demonstrate a successful
application of a SSVEP-based BCI to computer gaming, but
also investigate the perception of the proposed BCI game
and its control through in-lab experiments as well as via a
population study. To evaluate the BCI game one has to assess
at least two of its major components: the game control and
the gameplay. The players’ post hoc subjective assessments
of the game’s free-play mode provide feedback on the overall
perception of the game including the gameplay and the quality
of the control. To evaluate the latter on its own, the game
should be adapted appropriately. To this end, we eliminated
the game elements (e.g., the maze randomness, the freedom
to navigate through the game environment, etc.) that affect the

Target 1

f1

Target 2

f2

Target 3

f3

2

(A)

(B)
PSD

EEG(t)

(C)
f1

2f1

3f1

frequency

t

Fig. 1: Schema of the SSVEP decoding approach: (A) subject
looks at Target 1, flickering at frequency f1 , (B) EEG is
recorded and preprocessed, (C) salient peaks at f1 , 2f1 and
3f1 in the EEG spectrum suggest Target 1 as the subject’s
choice.

gameplay but not the game control. This way, the contribution
of the gameplay can be decreased in the subjective assessments
of the game. Therefore, we split the evaluation of our BCIgame into two parts:
1) the assessment of the game control only (see Sec. III-B),
in which case the game environment is adapted to enable
an objective evaluation of the control parameters when
the participants are performing an experimental task, and
2) the overall assessment of the game through the players’
subjective evaluation of the unrestricted free-play game
mode (see Sec. III-C), in which case the participants are
not bound by any specific task.
Since the first part of the assessment could influence the overall perception of the game, we performed those assessments
on different groups of subjects.
II. M ETHODS
A. EEG Data Acquisition
We have considered two wireless EEG recording devices:
one with a setup that is commonly considered for BCI research, thus, for an in-lab environment, and an inexpensive,
consumer-grade device designed for entertainment purposes.
The first device is a prototype of a wireless EEG system
consisting of two parts: an amplifier coupled to a wireless
transmitter and a USB stick receiver (Fig. 2a, 2b). The wireless
EEG system was developed by IMEC5 and built around their
ultra-low power 8-channel EEG amplifier chip (for technical
specifications, see [20]). Each EEG channel is sampled at
a 12 bit resolution and at 1000 Hz, which we resampled to
250 Hz as it is not needed for our BCI application. We used
an EEG-cap with large filling holes and sockets for active
Ag/AgCl electrodes (ActiCap, Brain Products, Fig. 2c). The
5 http://www.imec.be

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

(a)

(b)

FP1
AF7

F7

F3

F1

Fz

F8

F6

F4

F2

B. Visual stimulation

AF8

AF4

AFz

FT9

FT10
FT7

T7

FC5

FC3

C1

CP1

CP3

CP5

TP7

FC1

C3

C5

FCz

FC2

Cz

C2

CPz

CP2

FT8

FC6

FC4

C4

T8

C6

CP4

CP6

TP8

TP9

TP10
P7

P5

PO7
PO9

P1

P3

PO3

O1

between the subjects), it actually increases the usability of the
EEG device as one is no longer required to precisely place the
electrodes on the scalp, which in turn dramatically reduces the
set-up time.
The raw EEG signals from both considered setups were
filtered above 3 Hz, with a fourth order zero-phase digital
Butterworth filter, so as to remove the DC component and the
low frequency drift. A notch filter was also applied to remove
the 50 Hz powerline interference.

FP2

AF3

F5

(c)

3

Pz

POz

Oz

P2

P4

PO4

O2

P6

P8

PO8
PO10

(d)

(e)

Fig. 2: (a) IMEC wireless eight channels EEG amplifier/transmitter, (b) IMEC receiver, (c) Brain Products ActiCap
active electrode, (d) locations of the electrodes on the scalp,
(e) Emotiv’s EPOC headset.

recordings were made with eight electrodes located primarily
on or near the occipital pole, namely at positions P3, Pz, P4,
PO9, O1, Oz, O2, PO10, according to the international 10–20
system (Fig. 2d). The reference and ground electrodes were
placed on the left and right mastoids, respectively.
The second device is the EPOC (Fig. 2e) headset, developed
by Emotiv6 . This headset has 14 saline electrodes and a
built-in gyroscope (which is not used in our application).
The data are sampled at (reportedly) 128 Hz and resolution
of 14 bit/channel/sample and then wirelessly transmitted to a
computer. Its low price7 and wide availability8 are important
features for making BCI games attractive to a broad audience.
It is worth to mention that the EPOC was also built as a
BCI gaming device, but since it is aimed at exploring inputs
from neurofeedback trained EEG patterns, head rotations, and
muscular activity (facial expression), it is not directly suited
for our purposes as we are aiming at gaming without requiring
any training and based only on brain activity. Also, since we
are accessing other brain regions than the ones the EPOC was
designed for, we had to place the EPOC in a 180◦ -rotated (in
the horizontal plane) position on the head of the player. This
way, the electrodes could reach the occipital region (where the
SSVEP is most strongly present), instead of the more anterior
region for which the device was initially designed. Since
the EPOC has a one-size-fits-all design, we cannot precisely
describe the electrode locations for a given subject, since they
strongly depend on the geometry of the subject’s skull. We can
only mention the brain area covered by the electrodes. While
this could be seen as a drawback from a scientific point of
view (not allowing to clearly describe and compare the results

We have used a laptop with a bright 15,4” LCD screen
with a 60 Hz refresh rate9 and, therefore, capable to produce
stimulation frequencies up to 30 Hz.
For the lower frequencies, there are at least two options. The
first one, which we call discrete or frame-based stimulation,
is commonly used for SSVEP BCIs and normally considers a
visual stimulation at frequencies that are dividers of the refresh
rate of the screen [21]. An intense (“on”) stimulus is shown for
k frames, and a less intense (“off”) one for the next l frames.
Hence, the flickering period of the stimulus is k +l frames and
the corresponding stimulus frequency is fscr /(k+l), where fscr
is the refresh rate of the computer screen. For fscr = 60 Hz
the stimulation frequencies, thus, could only be 30, 20, 15, 12,
10, 8.57, 7.5, 6.66 and 6 Hz.
In our experiments we used another strategy, which we call
continuous or time-based stimulation. The stimulus’ intensity
“continuously” changes using some periodic intensity profile
I(t) : R+ → [0, 1], (e.g., a sine wave: I(t) = (1 + sin t)/2).
Given the stimulus appearance time t in the next video
frame, the stimulus should be presented during this frame
with intensity If (t) = I(T f t), where T is the period of the
intensity profile I(t) and f is the stimulus frequency. With
this strategy one could, theoretically, present a visual stimulus
flickering at any desired frequency f ≤ 21 fscr . Using this
strategy, one can monitor brain responses even for gradually
changing stimulation frequencies (Fig. 3).
C. Spatial Filtering and Classification
To cancel out nuisance signals as much as possible we use
a spatial filter strategy called the minimum energy combination (MEC) method [22]: a linear combination of channels
(denoted by a matrix X where the rows represent channels
and samples are in columns) is sought that decreases the
noise level of the resulting weighted signals at the frequencies
we want to detect (namely, the frequencies corresponding to
the periodically flickering stimuli and their harmonics). This
can be done in two steps. In the first step, all information
related to the frequencies of interest must be eliminated from
the recorded signals by using a projection determined by the
matrix PA = A(AT A)−1 AT , where the columns of the
matrix A consist of discretized values of sine and cosine waves
at the all frequencies used in the stimulation and their Nh
harmonics. The resulting signals X̃ = X − PA X contain

6 http://www.emotiv.com
7 Starting
8 More

from $299
than 30000 devices have already been sold.

9 The real refresh rate of the laptop was 59.83 Hz, but for the sake of brevity
we refer to it as 60 Hz.

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.

Frequency (Hz)

IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

4

60

The “winner” frequency f ∗ is defined as the frequency with
the largest index Q( · ) among all frequencies of interest:

50

f ∗ = arg max Q(f ).
f1 ,...,fnf

40
30

D. Game Design and Implementation

20

We have developed an SSVEP-based BCI game called “The
Maze”, in which the player can control an avatar (the playing
character, depicted as Homer Simpson’s head) in a simple
maze-like environment. The task is to navigate the avatar
to the target (i.e., a donut) through the maze (see Fig. 4).
The maze consists of square cells (as visualized in Fig. 6)
surrounded by walls through which the avatar can not pass.
The game has two modes. The default mode is the free-play
mode (see Fig. 4a), where each maze is generated randomly
and the avatar’s movement is restricted only by the maze
walls. Advancing from level to level, the size of a maze cell
decreases allowing to fit more complicated mazes into the
same (fixed-size) screen region designated for the maze. For
testing purposes we use a special experimental game mode
with a predefined maze, where the avatar is allowed to move in
correct directions only (see Fig. 4b, and Sec. III-B for details).
The relative speed of the avatar, defined as the number of
cells the avatar can visit per second, is fixed in the beginning of
the game and does not depend on the level of the game. We
advise to keep the avatar’s relative speed quite low (around
0.2–0.5 cells/s) to “hide” the latency discussed further. The
player can control the avatar by looking at the flickering arrows
(showing the direction of the avatar’s next move) placed in the
periphery of the maze. Each arrow flickers with its own unique
frequency. The choice of those frequencies can be predefined
(default settings) or set according to the player’s preference.
The game is implemented in MATLAB as a client-server application by using the Psychophysics Toolbox extensions [23]
for obtaining a temporally-accurate visual stimulation. Each
intermediate decision is produced by the server after analyzing
the EEG data acquired over the last T seconds (data window).
In the game, T is one of the tuning parameters (which is
set before the game starts), which controls the game latency.
Decreasing T makes the game more responsive, but at the
same time renders the interaction less accurate, resulting in
wrong navigation decisions. By default, a new portion of
the EEG data is collected every 200 ms. The server analyzes
the new (updated) data window and detects the dominant
frequency using the MEC method described above. The command corresponding to the selected frequency is sent to the
client also every 200 ms, thus, the server’s update frequency
is 5 Hz.
For the final selection of the command to be executed we
weight the items in the queue over the last m commands sent
by the server. Each entry of the queue has a predefined weight
that linearly decreases from wmax (i.e., the most recent item)
to wmin (i.e., the oldest item in the queue). The “candidate”
for the “final winner” is selected as the command with the
largest cumulative weight. The “candidate” becomes the “final
winner” if its cumulative weight exceeds an empirically chosen
threshold θ = m
4 (wmax +wmin ), otherwise no decision is made.

10
10

20

30

40

50

60 70
Time (s)

80

90

100 110 120

Fig. 3: Spectrogram of an EEG recording for one of the
subjects for the continuous stimulation strategy with a gradually changing stimulation frequency (here, the stimulation
frequency was linearly changing from 6 to 28 Hz over 120 s).
Several oblique lines are visible, corresponding to the stimulation frequencies and their harmonics.

only information that is “uninteresting” in the context of
our application, and, therefore, could be considered as noise
components of the original signals. In the second step, we
look for a linear combination that minimizes the variance of
the weighted sum of the “noisy” signals obtained in the first
step. This is done through considering the K last (smallest)
T
eigenvalues (λ) of the P
covariance matrix
PΣN = E{X̃X̃ }, such
K
that K maximal for
k=1 λN +1−k /
j=1 λj < 0.1 to be
true. The corresponding K eigenvectors, arranged as rows of
a matrix VK , specify a linear transformation that efficiently
reduces the noise power in the signal X̃. The same noisereducing property of VK is expected to be valid for the original
signal X. Assuming that VK would reduce the variance of
the noise more than the variance of the signal of interest, the
signal that is spatially filtered in this way, S = VK X, would
have a greater (or, at least, not smaller) signal-to-noise ratio
(SNR) [22]. It is estimated for all stimulation frequencies as
Q(f ) =

1
K(Nh + 1)

K NX
h +1
X

Pk (hf )/σk (hf ),

k=1 h=1

where K is the dimensionality of the signal S. The signal
power function P (f ) here is defined as follows:
!2
!2
X
X
P (f ) =
s(t) sin(2πf t) +
s(t) cos(2πf t) ,
t

t

where s(t) is the signal after spatial filtering, and the noise is
estimated according to
πT
σ̃ 2
Pp
,
4 |1 − j=1 aj exp(−2πijf /Fs )|
√
where T is the length of the signal, i = −1, p is the order of
the regression model applied to the signals S̃ = VK X̃, aj are
the regression coefficients (estimated, for example, with the
use of the Yule-Walker equations), σ̃ is the residual regression
white noise variance, and Fs is the sampling frequency.
σ(f ) =

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

(a) Free-play mode.

5

(b) Experimental mode.

Fig. 4: Screenshots of “The Maze” game in the (a) free-play and (b) experimental modes. The decision queue (of size m = 8)
is shown in the upper-right corner. The “final” command is depicted just below the queue. Four big arrows on the periphery
are the SSVEP stimuli used to control the avatar (see text).

For the example in Fig. 5 (where the queue length m is 10,
the maximal weight wmax is 1, the minimal weight wmin is 0.1,
the decision threshold θ is 2.75 = 10
4 (1 + 0.1), the cumulative
weights are: “left”: 3.2 = 1+0.9+0.7+0.5+0.1, “right”: 0.3,
“up”: 1 = 0.8 + 0.2 and “down”: 1 = 0.6 + 0.4) the “final
winner” is the command “left”.
Since the game is BCI-controlled, in order to reach a
decision about the avatar’s next move, the BCI has to collect
and decode a few seconds of EEG data. Thus, the decision
is always based on the past few seconds, and this is the
source of the latency in the game control. As an attempt to
“hide” it, we let the avatar change its navigation direction
only in particular cells, which we refer to as the decision
points: as the avatar starts to move, it will not stop until it
reaches the next decision point on its way. This allows the
player to use this period of “uncontrolled” avatar movement
for anticipating the next navigation direction by looking at the
appropriate flickering arrow (see Fig. 6). By the time the avatar
reaches the next decision point, the EEG data window, which
is to be analyzed, would already contain the SSVEP response
corresponding to the new navigation direction. Optionally, any
cell can be marked as a decision point. However, to make
use of the anticipation strategy, the decision points must be
distributed sparsely in the maze. In our experiments only the
following types of cells were marked as decision points: Tjunctions, intersections, turnings, and dead-ends.

E. Evaluation of the game control
We prefer to call the free-play game mode dynamic, since
the player’s behavior depends on the dynamically changing
game environment (i.e., the position of the avatar). To assess
the efficiency of the dynamic game control we employed
two objective measures: first one based on mission time, and
second based on accuracy. The mission time, in our case, is
defined as the time from the beginning of the game level till
the moment when the avatar reaches the destination [24]. In
order to reduce the intrinsic dependency of the mission time
on the maze level complexity, we opted for the mission time
ratio (MTR), which is the ratio between the nominal time and
the estimated mission time [24]. By the nominal time we mean
the absolute minimal time required to complete the game level,
i.e., passing all the decision points without stopping in them
(without time penalties)10 .
An MTR that equals 1 indicates perfect control, thus MTR
below 1 corresponds to the mission time longer then the
nominal time to complete the level. On the other hand, the
MTR significantly higher than the one of a random walk
suggests that the player achieved control over the avatar.
The accuracy measure is defined as the number of correct
decisions divided by the number of all decisions taken during
a game session. Note, that here (for each decision point)
10 The time of completion of any game level would be nominal if the avatar
is controlled by a precise controller (i.e., keyboard) and without player’s
mistakes.

m
Decision queue:
Weights:
Arrival times:

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

– 0.2

– 0.4

– 0.6

– 0.8

–1

– 1.2

– 1.4

– 1.6

– 1.8

Fig. 5: Example of a decision queue of length m = 10 together
with the weights of the items in the queue and times of the
command arrival (in seconds with respect to the last command
arrival).

Fig. 6: The “anticipation” strategy. For the avatar moving from
left to right, in order to make the “blue-arrow” turn, the player
should start looking at the “down” arrow when the avatar is
in blue-shaded cells. The same applies for the “green-arrow”
turn and the green-shaded cells. But if the avatar reaches the
yellow zone, it would skip both upcoming turns.

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

we considered only one correct decision out of four possible
ones, unlike the accuracy definitions in some other population
studies [14], [25].
As it has been discussed in the Introduction, to achieve
a fair assessment of the game control, we had to adapt the
game by eliminating some game elements, which might affect
the perception of the achieved control. The adapted game we
implemented in the form of an experimental mode with a
special levels (e.g., as depicted in Fig. 4b). All the decision
points in this level were placed in “crossings”, allowing to
leave the decision point in any of four possible directions, only
one of which is correct. In order to make the MTR measure
more adequate for our purposes, we allowed the avatar to leave
a decision point only if a correct decision is made. Otherwise,
the decision queue is reset causing the avatar to stay put while
the system collects enough data to make a new decision. In
this way, the wrong decisions are penalized (by means of time)
not so severely as it would be if the avatar was allowed to
move in the wrong direction. To complete the experimental
level, the participant must pass 20 decision points, eventually
making five correct decision in each direction (up, down,
left and right). We intentionally designed the experimental
level to be as simple as possible, to exclude the necessity
of acquiring any advanced playing skills which, for example,
might be needed in situations similar to the one depicted in
Fig. 6. To simplify the experimental game mode even more,
we clearly indicated the correct decisions for each decision
point. These markings also allowed subjects to easily discover
and understand the decision point mechanism behind the game
control. Thus, by removing some challenging elements from
the game, we created a controlled game-like environment,
where the efficiency of the BCI-based game control can be
objectively assessed. In this experiment we also employed the
Visual Analogue Scale (VAS) [26] for continuous subjective
evaluation of the game control between “no control” and
“perfect control” extreme levels. The subjective data collected
this way were then compared with the objective assessments
of the BCI-control of the game.
F. Overall evaluation of the game
The population study was mostly done to probe the players’
feelings toward the SSVEP-based BCI game. Hence, we
primary wanted to determine whether this game raises any
sense of fun for the player. As was shown in [27], fun (namely,
hard fun, easy fun, people fun and serious fun) is a key to
unlock the players emotion during game play. Thus, for us was
interesting to check whether our game can potentially unleash
any emotions, not yet going deep into their classification.
While we expected that, as a result of the game design, hard
fun should be detected (playing to see how good I really am;
playing to beat the game, requiring a strategy rather than
relying on luck, . . . ) [27], we asked about fun in general
for justifying the game’s potential to evoke any emotions,
which we consider as one of the important aspect of the
game. Since such an assessment could be done only in a free
playing mode (where the player does not follow any particular
instructions), the assessment was done for subjects other than

6

those participating in the experiment described in Sec. III-B.
This fun assessment was done to check the attractiveness of
the free-play mode of the proposed game.
Additionally, we wanted to check some questions that
specially arise from the SSVEP paradigm used for game play.
Since SSVEP-BCI uses flicker (to display stimuli associated
with the BCI commands), it was reported that it produces
visual fatigue, which seems to be less the case with higher
frequencies [28], [29]. Since in our game we use low frequencies for controlling, it is quite important to check their usability
for BCI gaming. This led to the inclusion of the subject’ selfevaluation of visual fatigue. On other hand, it is known that
the subject’s ability to concentrate on the stimuli enhances
the SSVEP responses [30], [31]. Thus, for an SSVEP-based
BCI game it is particularly interesting to know how easily
the player can concentrate on the flickering stimulation during
game play. This led to the inclusion of easiness of concentration assessment. And, finally, we were interested in the
subjects’ self-assessment of the game control during game
play. Although we already performed a quantitative assessment
of control in the previous experiment (see Sec. III-B), which
provided us with a real evaluation of the accuracy of our
interface, the self-assessment allows us to see how good the
gaming elements enabled us to “hide” the not always perfect
BCI control during the game.
III. E XPERIMENTS AND R ESULTS
All the experiments were approved by the KU Leuven
ethical committee. Prior to the experiments, each participant
signed a consent form, among others stating that (s)he had no
history of epilepsy11 .
A. Selection of the game parameters
To run the game, one need to choose its parameters: four
stimulation frequencies f1 , . . . , f4 , the window size T and the
decision queue length m. In order to estimate these parameters,
and also to investigate the feasibility of using a consumer
grade EEG device for the proposed game, we conducted the
following experiments.
As for the choice of the stimulation frequencies, we opted
for those that are dividers of the screen refresh rate (60 Hz).
Such a scheme has already proven itself for SSVEP BCI [21].
We employed the continuous stimulation strategy, which
allowed us to reuse the recorded EEG data for further comparison12 of the continuous vs. discrete types of visual stimulation.
Following our experience and based on previous findings [32],
we selected frequencies 15, 12, 10, 8.57 Hz as the default ones
for our game. While other frequencies could also yield good
11 In photosensitive epilepsy, a seizure could be triggered by flashing or
flickering visual stimuli. Most people with photosensitive epilepsy are sensitive to 16–25 Hz (according to Epilepsy Action [http://www.epilepsy.org.uk/]).
Up to 5% of people having epilepsy suffer from photosensitive epilepsy (according to the UK Epilepsy Society [http://www.epilepsysociety.org.uk/]). One
of the prominent case of mass photosensitive epilepsy was in Japan, where at
least 618 children had suffered from convulsions, vomiting, irritated eyes, and
other symptoms after watching a particular episode of the “Pokemon” series
[http://edition.cnn.com/WORLD/9712/17/video.seizures.update/index.html].
12 This comparison is not presented here as it is out of the scope of this
study.

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.

B. Evaluation of the game control
Twenty healthy, naı̈ve to the game, subjects (15 males and 5
females; aged 15-41 with average age 27.9; 18 righthanded and
two lefthanded) participated in the experiment based on the
methodology described in Sec. II-E. The tests were performed
in an out-lab environment very similar to the one the participants would normally experience when playing a computer
game. MTR and accuracy estimated from the experimental

7

1

1

0.9

0.9
Subjective measure

results, or even better ones, for some subjects, it turned out
that the selected ones were satisfactory for all players of
the game (which was indirectly supported by our experience
both in the in-lab and out-lab experiments). It is also outside
the prominent range of frequencies causing photosensitive
epilepsy.
In order to estimate the m and T parameters, we conducted
an in-lab experiment on six healthy subjects (all male, aged
25–35 with average age 29.2, four righthanded, one lefthanded
and one bothhanded). Each subject was presented with a testlevel of the game, and was instructed to persistently look at
each one of the four flickering arrows for 20 s followed by
10 s of rest. The stimulus to attend to was marked by a small
crosshairs symbol. In this experiment the subject’s behavior
was predefined and did not depend on the game environment,
therefore we refer to this experiment as a static one. Each
recording session consisted of two rounds and, thus, lasted
2 × 4 × (20 + 10) = 240 s. The recorded EEG data was
processed off-line using exactly the same methods as during
the game. Due to the design of the experiment, the true winner
frequency was known at each moment of time. This enabled
us to estimate the accuracy of the SSVEP classification.
The game was originally designed and tested on a conventional EEG setup (i.e., IMEC), but for the planned validation
of the game, we also tested the game on the EPOC setup.
Thus, we had to make sure that the system pre-tuned for the
use with the IMEC device could also properly worked for the
EPOC headset, despite of the “SSVEP-unfriendly” placement
of its electrodes. Therefore, we conducted the experiment
twice: with the EPOC and the IMEC device. The results of
this experiment are presented in Tab. I. By the accuracy of
the frequency classification we mean the ratio of the correct
decisions with respect to all decisions. Note that the chance
level in this case is 25%.
We also conducted a Wilcoxon signed rank test for each
value of T and m in order to validate the difference in performance between the two devices. Based on the accuracy results
from Tab. I, and supported by our previous experience [33],
we choose the window size T = 3 and the queue length m = 5
(or more) as default values to achieve an acceptable control
level. This choice was also motivated by the fact that there
is no statistical difference in control accuracy between the
considered devices for those parameter values, which justifies
the use of a consumer grade EPOC for our game.
We also would like to emphasize that the results in Tab. I
should not be considered as any sort of technical comparison
of the EEG setups, as this is out of the scope of the present
study.

Subjective measure

IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

0.8
0.7
0.6

0.8
0.7
0.6

0.5

0.5
0.5

0.6

0.7
0.8
MTR

0.9

1

0.5

0.6

0.7
0.8
Accuracy

0.9

1

Fig. 7: Results of the game control assessment.

data were 0.90 ± 0.09 (mean±std) and 80.37% ± 11.85%
correspondingly.
We also considered the case of the random walk in the
experimental mode of the game, when the classifier was
generating random decisions (MTR: 0.49 ± 0.07, accuracy:
24.68% ± 4.61%).
The results of the comparison of objective measures vs.
subjective assessment of game control are shown in Fig. 7. It is
clear that the average efficiency of control does not correspond
to a perfect control (as it is expected for a BCI system), while
it is sufficiently high to consider BCI as a control interface for
the proposed game. The existing mistakes could be hidden in
a free-play mode (as it was described in Sec. II-D), causing
the player to “struggle” even more to “overcome” the hurdles
faced when navigating through the maze.
A correlation analysis between objective measures and the
subjective assessment of control reveals significant correlation
(MTR: r(18) = 0.86, p < 0.0001, accuracy: r(18) = 0.65,
p < 0.0025), showing us that the subject’s perception of
the control could also serve as an approximate measure of
the interface assessment. The latter is used in the population
study in an uncontrolled environment (as the game normally is
played) during the assessment of the quality of the gameplay.
C. Overall evaluation of the game
In order to assess the overall quality of the gameplay, we
participated in the I-Brain & Senses13 event. During two consecutive days, 53 persons (aged between 6 and 61 years)
played the maze game using several EPOC headsets.
They were mostly high school students during the first
day, and persons from all age groups during the second
day. The experimental conditions were quite far from those
of an in-lab environment: a noisy room crammed with all
sorts of wireless and other types of equipment (since we
shared a room with other demonstration booths). Moreover, the
participants were constantly distracted by their companions.
These conditions made our game evaluation close to that of a
real-world environment where people would typically use such
equipment for entertainment purposes (e.g., at their homes or
game arcades).
All participants were asked to fill out a questionnaire that
consisted of two parts: questions that were asked prior to the
13 Ghent,

Belgium, March 18–19, 2011 http://www.i-brain.be/

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

8

TABLE I: Averaged (among 6 subjects) classification accuracy (in percents) for both EEG devices considered as a function
of window size T and decision queue length m (see text) and p-value of the Wilcoxon signed rank test for the testing the
difference between the estimates of the accuracy.
T
m

1

2

3

4

5

1

5

9

1

5

9

1

5

9

1

5

9

1

5

9

EPOC
IMEC

59.01
69.60

59.52
70.38

60.12
71.21

82.71
85.80

83.71
86.86

84.84
87.57

91.86
92.24

92.39
93.03

92.49
93.31

96.63
95.90

96.77
96.43

96.84
96.75

98.71
97.05

98.78
97.68

98.90
98.04

p-value

0.156

0.156

0.156

0.687

0.687

0.687

1.000

1.000

1.000

0.812

0.625

0.812

0.437

0.625

0.625

experiment and a feedback evaluation after the experiment.
In the first part, the participants were asked to indicate
their gender (male/female), age, right/left/two-handedness, the
number of consumed drinks containing caffeine in the past
two hours, the number of cigarettes smoked per day, whether
they had any prior experience in EEG experiments, their hair
style (thin/thick and bald/long/normal hair). In the second part,
we asked each subject to evaluate the required concentration
during the game ((1) difficult, (2) neither difficult nor easy,
(3) easy to concentrate), visual fatigue ((1) game is tiring,
(2) not much, (3) not tiring at all), fun level ((1) the game is
fun, (2) not all that fun, (3) unpleasant) and control ((1) good,
(2) bad, (3) no control over the avatar).
We did not limit the duration of the gameplay: the participants were allowed to play the game until he/she wanted
to stop. Some of the participants succeeded in reaching really
complex levels of the game, which indicates their long evolvement in the experiment. Thus, one of the interesting parameters
is the subject’s perception of being in control of the game. As
a result, 36 participants (66%) indicated a good control over
the avatar, while 16 participants (30.2%) indicated bad control,
and two subjects (3.8%) no control at all (see Tab. II). The
latter two (no control) subjects were in a hurry, which was
also indicated by them in the questionnaire, thus, they did not
spend much time on the game learning to achieve a proper
game control. One can see that this subjective evaluation is
clearly biased towards being in control. This supports our
assumption that the game design special tricks (e.g., described
in Sec. II-D), can turn the imperfections of the BCI-based
game control into a challenge.
Based on the answers from the questionnaire, we have found
that mostly all subjects (45 persons – 85%) had fun with the
game, and no one disliked the game (see Tab. II).
In order to properly validate the game, we also asked
feedback about fatigue and concentration during gameplay.
In spite of the constantly flickering stimuli (which one could
TABLE II: Results of the overall game evaluation based
on the players’ self-assessment. Percentage and number of
players (between brackets) are shown for each level of the
questionnaire (see text for explanation).
1
Concentration
Fatigue
Fun
Control

13.2%
3.8%
85.0%
66.0%

2
(7)
(2)
(45)
(36)

41.5%
50.9%
15.0%
30.2%

3
(22)
(27)
(8)
(16)

45.3%
45.3%
0.0%
3.8%

(24)
(24)
(0)
(2)

regard as irritating), only two participants (3.8%) found them
tiring (see Tab. II). But, nevertheless, only 24 participants
(45.3%) found them easy to concentrate on (see Tab. II). This
means that the game requires some level of concentration on
the flickering stimuli, while it does not seem to lead to fatigue,
at least not during the time the subject spent on the game.
We have also analyzed the cross-dependency of different
factors. Our results suggests that neither the type of hair,
gender, caffeine nor other parameters that were asked prior
to the experiment influenced any of the feedback results. A
cross-analysis of the feedback reveals that only concentration
to the flickering stimuli and self-assessment of the goodness
of control depended on each other: easy concentration leads
to better control, while difficulties to concentrate causes bad
(or lack of) control. The correlation coefficient between those
two parameters is r(51) = 0.70, p < 0.0001, which indicates
a significant level of dependency. The results of the subjective
assessment are in line with the fact that a proper concentration
on the flickering stimuli increases the SSVEP responses [30],
which in turn leads to a better detectability of the commands
by interface and thus a better control of the game.
IV. D ISCUSSION AND C ONCLUSION
A. General remarks
In this paper, we reported on an SSVEP BCI game that we
developed and that was tested on a broad audience. By this
study, we tried to bridge the gap between SSVEP BCI games
for research purposes, and the testing of such games with
a consumer grade EEG device (such as the EPOC). While
our results suggest the applicability of a consumer-grade EEG
device for BCI gaming, we still see one of the main problem in
the one-size-fits-all design of the headset. In our experiments
we noticed that for some subjects (young persons) some of
the electrodes did not make good contact with the skin, and
even sometimes made no contact at all.
Our study could be regarded as an attempt to validate BCI
games and to probe their attractiveness on a broad audience,
thereby assessing some of the criteria suggested in [11]. The
assessment by the players revealed that the BCI game looks
attractive and allows for a satisfactory level of control, while
requiring some level of concentration. Moreover, the results
suggest that the players are able to turn all potential drawbacks
(not always perfect classification accuracy, requirement of
concentration, necessity to foresee the next command, . . . )
into a challenge, which contributed to the enjoyment of the
gameplay.

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

The results of the experiment described in Sec. III-B
show that for some particular subjects the most/least accurate
commands can clearly be seen. While the analysis over all
subjects shows no significant difference between the command
detection accuracies (repeated measures ANOVA p = 0.1477).
The erroneous command in the majority of the cases coincided
with the previously selected command, which can be explained
by the inertia of the game control.
MTR is a continuous measure reflecting the avatar’s average
speed, which, in turn, can be associated by players with
the game control level. Conversely, accuracy is a discrete
measure of performance, and arguably less “convenient” for
the subjects to estimate and keep track during the game
than mission time based MTR. This could explain why the
subjective measure better correlates with MTR than accuracy.
We included the accuracy analysis as it simplifies the possible
comparison of our (game) system with others.
For the chosen game parameters (T = 3, m = 5) the
accuracy in our static experiment reached 92.39% ± 6.96
(mean±std) (see Tab. I), which is comparable with other
SSVEP BCI systems tested on broad audience 89.16%–
95.78% [14], [25]. It is worth mentioning that apart from
the fact that we used consumer grade equipment (EPOC)
in this experiment, the definition of accuracy we employ is
unambiguous and more strict comparing to the ones used
in [14], [25].
The accuracy in the dynamic case experiment (see Sec. II-E)
reaches 80.37% ± 11.85%, which in addition to the above
mentioned reasons can be explained as follows: a) the subjects
had to repeatedly change their attention from the stimuli to
the avatar and back, while in the static case the subject could
attend exclusively to the stimulus; b) the “inertia” effect caused
by the latency of the control and queue-based decision making;
and, c) during the gameplay the naı̈ve subject still had to learn
the anticipation strategy, which for the static case was not
needed.
We believe, these reasons could explain the difference
between the static case accuracy reported in Tab. I and the
dynamic case accuracy discussed in Sec. II-E.
A few more issues concerning the visual stimulation and
the game design need to be discussed. As to the two visual
stimulation strategies (introduced in Sec. II-B) it is worth to
mention that, at least according to our six in-lab subjects,
the continuous style (with the sinusoidal intensity profile) is
perceptually “easier” on the subject than the discrete one. The
continuous style is more robust as it depends only on the
next video frame appearance time, which can be estimated
quite precisely given the actual video frame appearance time.
Even in the case of dropped frames, the continuous/timebased stimulation style is still capable of rendering stable
frequencies without phase drifts, which is not the case with
the discrete/frame-based strategy. Note also that the continuous
style is more general than the discrete one as the latter can be
emulated by the continuous style via an appropriate selection
of the intensity profile I(t). As a drawback of the continuous
style we should mention that, due to the aliasing effect (in
the time domain), for some frequencies, the stimuli might be
perceived with an undesired intensity amplitude modulation.

9

We defer an in-depth comparison of the two above mentioned
visual stimulation strategies to a follow up report.
During the course of our in-lab experiments, several subjects
mentioned that textured stimuli were easier to concentrate
on than uniform ones. Some of our subjects preferred the
yellow color of the stimuli over the white one, which partially
might be explained by a characteristic feature of yellow light
stimulation: it elicits an SSVEP response of a strength that
is less dependent on the stimulation frequency than other
colors [34]. These clues were considered for the default setting
of the game for our broad audience experiments.
While we evaluated through self-assessment some parameters related to the gameplay after one continuous play dependent on player wishes on different subjects (see Sec. III-C), we
could assume, that those parameters may change within one
subject during the course of gameplay. Thus, for example, long
evolvement into the game could lead within same subject to
more visual fatigue from stimulation, or concentration could be
reduced (leading to less control and, consequently, to the less
fun from the game). Thus, it is quite important to investigate
the changes of those parameters in time within same subject,
to properly assess the BCI gaming for longitudinal use. And
this can be seen as a future work.
In this study we only assessed the fun evoked by gameplay
in general, so whether it unlocked any emotions [27]. We did
not go into the classification of the source of fun, such as a
classification into hard fun (playing to see how good I really
am; playing to beat the game, requiring strategy rather than
luck,. . . ), easy fun (excitement and adventure, seeing what
happens in the story, exploring new world,. . . ), etc., leading to
emotions such as fiero (associated with the moment of personal
triumph over one’s adversary), curiosity, and so on [27]. Or
fun can even arise from the fact that one can use his/her
brain signals for playing. All this calls for a more in-depth
study of which genres of BCI gaming are best suited for
evoking emotions by using more rigorous game experience
questionnaires and several elaborate BCI games.
B. SSVEP-based BCI gaming
In this study we constructed a BCI game based on a particular paradigm, namely SSVEP. Since this paradigm requires
visual stimulation we, as usual, uses the same screen for the
stimulation and the game environment. This is desirable for
an SSVEP application to avoid switching between two devices
(one for stimulation and one for feedback). Although the
SSVEP paradigm is known to provide good accuracy [14] in
self-paced static BCI applications without preliminary training,
it has its own limitations. Assuming able subjects (not patients
with some issues controlling their gaze), we still have to cope
with the BCI control latency, the attentional effort, and fatigue
caused by the nature of the visual stimulation. As to the
possibility to concentrate on flickering stimuli, we found that
this could be not always easy and could therefore influence
game control. The problem with concentration could arise
from the following. The flickering stimulation is somewhat
“aggressive” which is why we had to “soften” it by using a
continuous stimulation profile (which could lead to a lower

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

accuracy) and/or stimulus color (reducing its luminance contrast), as mentioned in the previous subsection. Another source
of concentration problems could be due to the constant shift
from the stimuli at the border of the screen to the maze in the
center of the screen. As a way to overcome this, we can think
about locating the stimuli (arrows) close to the avatar, moving
with it during the game or, for example, making the stimuli
bigger so that the subject can sit further away from the screen
and the avatar is more closer to the fovea when attending the
arrows. While such recommendations seem reasonable, they
still need to be validated.
Concerning the latency of the SSVEP-based BCI control,
we were able to convert it into one of the game’s challenges,
as described in Sec. II-D. Together with the inaccuracy of
the interface, the player could think that some mistakes were
made by himself, but not by the BCI. Thus, this motivates the
subject to consider them as challenges that need to be met in
order to win the game. In this way, we are able to “turning
shortcomings into challenges” [11].
Research on BCI-based gaming is still in its infancy, and
many more issues need to be addressed before it would become accepted in the gaming community. The issues discussed
in this article already indicate the necessity of further research,
in general, and the development of suitable applications for
interactive entertainment, in particular.
ACKNOWLEDGMENT
NC is supported by the Tetra project Spellbinder (Flemish
Agency for Innovation by Science and Technology), NVM
is supported by the research grant GOA 10/019, MvV is
supported by IUAP P7/21 AR and AC are supported by
IWT doctoral grants, MMVH is supported by PFV/10/008,
CREA/07/027, G.0588.09, IUAP P7/21, GOA 10/019 and the
Tetra project Spellbinder.
The authors are grateful to Refet Firat Yazicioglu, Tom Torfs
and Cris Van Hoof from IMEC Leuven for providing us with
the wireless EEG system. The authors are also grateful to
Tan Le from Emotiv for supplying us some additional EPOC
devices for the I-Brain & Senses event.
R EFERENCES
[1] J. Mak and J. Wolpaw, “Clinical applications of brain-computer interfaces: current state and future prospects,” IEEE Reviews in Biomedical
Engineering, vol. 2, pp. 187–199, 2009.
[2] N. V. Manyakov, N. Chumerin, A. Combaz, and M. M. Van Hulle,
“Comparison of classification methods for P300 Brain-Computer Interface on disabled subjects,” Computational Intelligence and Neuroscience, vol. 2011, p. 519868, 2011.
[3] P. Martinez, H. Bakardjian, and A. Cichocki, “Fully online multicommand brain-computer interface with visual neurofeedback using SSVEP
paradigm,” Computational Intelligence and Neuroscience, vol. 2007, p.
94561, 2007.
[4] E. Lalor, S. Kelly, C. Finucane, R. Burke, R. Smith, R. Reilly, and
G. McDarby, “Steady-state VEP-based brain-computer interface control
in an immersive 3D gaming environment,” EURASIP Journal on Applied
Signal Processing, vol. 19, pp. 3156–3164, 2005.
[5] A. Finke, A. Lenhardt, and H. Ritter, “The mindgame: A P300-based
brain-computer interface game,” Neural Networks, vol. 22, no. 9, pp.
1329–1333, 2009.
[6] J. Bayliss, “Use of the evoked potential P3 component for control
in a virtual apartment,” IEEE Transactions on Neural Systems and
Rehabilitation Engineering, vol. 11, no. 2, pp. 113–116, June 2003.

10

[7] J. Pineda, D. Silverman, A. Vankov, and J. Hestenes, “Learning to
control brain rhythms: making a brain-computer interface possible,”
IEEE Transactions on Neural Systems and Rehabilitation Engineering,
vol. 11, no. 2, pp. 181–184, June 2003.
[8] A. Lécuyer, F. Lotte, R. Reilly, R. Leeb, M. Hirose, and M. Slater,
“Brain-computer interfaces, virtual reality, and videogames,” Computer,
vol. 41, no. 10, pp. 66–72, 2008.
[9] R. Scherer, L. Friedrich, B. Allison, M. Pröll, M. Chung, W. Cheung,
R. Rao, and C. Neuper, “Non-invasive Brain-computer interfaces: Enhanced gaming and robotic control,” in Proc. IWANN, Part I, LNCS
6691, 2011, pp. 362–369.
[10] D. Coyle, J. Garcia, A. Satti, and T. McGinnity, “EEG-based continuous
control of a game using a 3 channel motor imagery BCI: BCI game ,” in
IEEE Symposium on Computational Intelligence, Cognitive Algorithms,
Mind, and Brain (CCMB), 2011, pp. 1–7.
[11] A. Nijholt, D. Plass-Oude Bos, and B. Reuderink, “Turning shortcomings into challenges: Brain-computer interfaces for games,” Entertainment Computing, vol. 1, no. 2, pp. 85–94, 2009.
[12] L. Farwell and E. Donchin, “Talking off the top of your head: toward
a mental prosthesis utilizing event-related brain potentials,” Electroencephalography and Clinical Neurophysiology, vol. 70, no. 6, pp. 510–
523, 1988.
[13] C. Guger, S. Daban, E. Sellers, C. Holzner, G. Krausz, R. Carabalona,
F. Gramatica, and G. Edlinger, “How many people are able to control a
P300-based brain-computer interface (BCI)?” Neuroscience letters, vol.
462, no. 1, pp. 94–98, 2009.
[14] B. Allison, T. Lüth, D. Valbuena, A. Teymourian, I. Volosyak, and
A. Gräser, “BCI demographics: How many (and what kinds of) people
can use an SSVEP BCI?” IEEE Transactions on Neural Systems and
Rehabilitation Engineering, vol. 18, no. 2, pp. 107–116, April 2010.
[15] C. Guger, G. Edlinger, W. Harkam, I. Niedermayer, and G. Pfurtscheller,
“How many people are able to operate an EEG-based brain-computer
interface (BCI)?” IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 11, no. 2, pp. 145–147, June 2003.
[16] C. Herrmann, “Human EEG responses to 1–100 Hz flicker: resonance
phenomena in visual cortex and their potential correlation to cognitive
phenomena,” Experimental Brain Research, vol. 137, no. 3, pp. 346–353,
2001.
[17] P. Allegrini, D. Menicucci, R. Bedini, L. Fronzoni, A. Gemignani,
P. Grigolini, B. West, and P. Paradisi, “Spontaneous brain activity as a
source of ideal 1/f noise,” Physical Review E, vol. 80, no. 6, p. 061914,
2009.
[18] N. V. Manyakov, N. Chumerin, A. Combaz, A. Robben, and M. M.
Van Hulle, “Decoding SSVEP responses using time domain classification,” in International Conference on Fuzzy Computation and 2nd International Conference on Neural Computation, Valencia, Spain, October
2010, pp. 376–380.
[19] Y. Wang, R. Wang, X. Gao, B. Hong, and S. Gao, “A practical VEPbased brain-computer interface,” IEEE Transactions on Neural Systems
and Rehabilitation Engineering, vol. 14, no. 2, pp. 234–240, June 2006.
[20] R. Yazicioglu, T. Torfs, P. Merken, J. Penders, V. Leonov, R. Puers,
B. Gyselinckx, and C. Van Hoof, “Ultra-low-power biopotential interfaces and their applications in wearable and implantable systems,”
Microelectronics Journal, vol. 40, no. 9, pp. 1313–1321, 2009.
[21] I. Volosyak, H. Cecotti, and A. Gräser, “Impact of Frequency Selection
on LCD Screens for SSVEP Based Brain-Computer Interface,” in Proc.
IWANN, Part I, LNCS 5517, 2009, pp. 706–713.
[22] O. Friman, I. Volosyak, and A. Gräser, “Multiple channel detection
of steady-state visual evoked potentials for brain-computer interfaces,”
IEEE Transactions on Biomedical Engineering, vol. 54, no. 4, pp. 742–
750, April 2007.
[23] M. Kleiner, D. Brainard, D. Pelli, A. Ingling, R. Murray, and C. Broussard, “Whats new in psychtoolbox-3,” Perception, vol. 36, no. ECVP
Abstract Supplement, 2007.
[24] B. Rebsamen, C. Guan, H. Zhang, C. Wang, C. Teo, M. Ang, and
E. Burdet, “A brain controlled wheelchair to navigate in familiar
environments,” Neural Systems and Rehabilitation Engineering, IEEE
Transactions on, vol. 18, no. 6, pp. 590–598, 2010.
[25] I. Volosyak, D. Valbuena, T. Lüth, T. Malechka, and A. Gräser, “BCI
Demographics II: How many (and what kinds of) people can use an
SSVEP BCI,” IEEE Trans. Neural Syst. Rehabil. Eng, vol. 19, no. 3,
pp. 232–239, 2011.
[26] S. Grant, T. Aitchison, E. Henderson, J. Christie, S. Zare, J. McMurray,
and H. Dargie, “A comparison of the reproducibility and the sensitivity
to change of visual analogue scales, borg scales, and likert scales in
normal subjects during submaximal exercise,” Chest, vol. 116, no. 5,
pp. 1208–1217, 1999.

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication.
IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES, VOL. 0, NO. 0, MONTH 2012

[27] N. Lazzaro, “Why we play games: Four keys to more emotion without
story,” Design, vol. 18, pp. 1–8, 2005.
[28] P. Diez, V. Mut, E. Perona, and E. Leber, “Asynchronous BCI control
using high-frequency SSVEP,” Journal of NeuroEngineering and Rehabilitation, vol. 8, p. 39, 2011.
[29] Y. Wang, R. Wang, X. Gao, and S. Gao, “Brain-computer interface based
on the high-frequency steady-state visual evoked potential,” in Neural
Interface and Control, 2005. Proceedings. 2005 First International
Conference on. IEEE, 2005, pp. 37–39.
[30] F. Di Russo, W. Teder-Sälejärvi, and S. Hillyard, “Steady-state vep and
attentional visual processing,” The cognitive electrophysiology of mind
and brain. New York: Academic Press. p, pp. 259–274, 2002.
[31] Y. Kim, M. Grabowecky, K. Paller, K. Muthu, and S. Suzuki, “Attention induces synchronization-based response gain in steady-state visual
evoked potentials,” Nature Neuroscience, vol. 10, no. 1, pp. 117–125,
2006.
[32] I. Volosyak, H. Cecotti, and A. Gräser, “Optimal visual stimuli on
LCD screens for SSVEP based brain-computer interfaces,” in Proc. 4th
International IEEE EMBS Conference on Neural Engineering, 2009, pp.
447–450.
[33] N. Chumerin, N. V. Manyakov, A. Combaz, A. Robben, M. van Vliet,
and M. M. Van Hulle, “Steady State Visual Evoked Potential based
Computer Gaming - The Maze,” in Lecture Notes of the Institute
for Computer Sciences, Social Informatics and Telecommunications
Engineering (LNICST), vol. 78, Genoa, Italy, May 2011, pp. 28–37.
[34] D. Regan, “An effect of stimulus colour on average steady-state potentials evoked in man,” Nature, vol. 210, no. 5040, pp. 1056–1057, 1966.

Nikolay Chumerin received the M.Sc. degree in
Mathematics and Educational Science and Higher
Educational Certificate of teacher in Mathematics
and Computer Science from the BrSU (Brest State
University, Brest, Belarus) in 1999, and the Ph.D.
degree in biomedical sciences from KU Leuven
(University of Leuven, Belgium), in 2011. He is
currently a post-doctoral researcher at the Laboratorium voor Neuro- en Psychofysiologie, Medical School, KU Leuven. His research interests
include biologically-inspired computer vision, machine learning, signal processing and EEG-based brain-computer interfaces.

Nikolay Manyakov received the M.Sc. degree in
mathematics from the BSU (Belarusian State University, Minsk, Belarus) in 1998, the Ph.D. degree in
theoretical informatics from the BSUIR (Belarusian
State University of Informatics and Radioelectronics,
Minsk, Belarus) in 2005, and the Ph.D. degree in
biomedical sciences from KU Leuven (University
of Leuven, Belgium), in 2010. He is a Research
Fellow at the Computational Neuroscience Research
Group, Laboratorium voor Neuro- en Psychofysiologie, Medical School, KU Leuven, Belgium. His
current research interests include brain-computer interfaces, computational
neuroscience, neural networks, machine learning, data mining, and signal
processing.

11

Marijn va Vliet received the M.Sc. degree in
human-machine interaction, which he obtained at the
University of Twente, Netherlands, in 2010. During
his master, he became interested in brain-computer
interfaces (BCIs) and wrote his master thesis at the
BCI@HMI group. He is currently a PhD student at
the Computational Neuroscience Research Group at
the KU Leuven (University of Leuven, Belgium),
where his main work is focused on the neurological
responses during language processing. His passion
for BCIs however drives him to continue work on
BCI implementations from time to time.

Arne Robben received the B.Sc. degree in Mathematics from the UHasselt (University of Hasselt,
Belgium) in 2007. He completed the Mathematics
program by a Master at the KU Leuven (University
of Leuven, Belgium) in 2009. A year later, in 2010,
he graduated in the one-year program: Master of Artificial Intelligence at the KU Leuven. Directly upon
finishing his studies he joined the Computational
Neuroscience Research Group at the KU Leuven. In
January 2011 he obtained support from a specialization grant from IWT (Flemish Agency for Innovation
through Science and Technology) to start a PhD.

Adrien Combaz received the Engineer degree in
Modeling and Scientific Computation from the Institut des Sciences et Techniques de lIngnieur de Lyon,
Lyon, France in 2006. He then graduated from the
Master of Artificial Intelligence from the KU Leuven (University of Leuven, Belgium) in 2008. He
is currently a doctoral student at the Computational Neuroscience Research Group, Laboratorium
voor Neuro- en Psychofysiologie, Medical School,
KU Leuven. His research focuses on neuroscience,
machine learning, signal processing and EEG-based
brain-computer interfaces.

Marc M. Van Hulle received the M.Sc. degree in
electrotechnical engineering and the Ph.D. degree in
applied sciences from the KU Leuven (University of
Leuven, Belgium). He also received the B.Sc.Econ.
and M.B.A. degrees. He received the Doctor Technices degree from Queen Margrethe II of Denmark,
in 2003, and an Honorary Doctoral degree from
BrSU (Brest State University, Brest, Belarus), in
2009. He is currently a Full Professor at the Medical
School of the KU Leuven, where he heads the
Computational Neuroscience Research Group of the
Laboratorium voor Neuro- en Psychofysiologie.

Copyright (c) 2011 IEEE. Personal use is permitted. For any other purposes, permission must be obtained from the IEEE by emailing pubs-permissions@ieee.org.

