VOL. 11, NO. 5, MARCH 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com

EEG SIGNAL ANALYSIS RELATED TO SPEECH PROCESS THROUGH
BCI DEVICE EMOTIV, FFT AND STATISTICAL METHODS
Diego Alfonso Rojas, Leonardo Andrés Góngora and Olga Lucia Ramos
Department of Mechatronic Engineering, Nueva Granada Military University, Bogota, Cundinamarca, Colombia
E-Mail: u1801620@unimilitar.edu.co

ABSTRACT
The electroencephalography is a method used for measuring the electrical impulses that are generated on the
cerebral cortex by using electrodes located in different positions, but keeping a standard distribution. In this work, EEG
signals related to speech process were acquired by the Emotiv EPOC+®, this device is a low cost electroencephalogram
that have 16 electrodes but only six were used (F7, F8, FC5, FC6, T7, T8). The aim of this research is to analyze if there
are measurable and quantifiable differences among neutral EEG signals and vowels EEG signals from to imagine or to
think any vowel by using DSP techniques, like Filters or Fourier Transform, along with statistical method that allow verify
the truthfulness of previously mentioned difference. The aim of this research is to analyze if there are measurable and
quantifiable differences among neutral EEG signals and EEG signals from the imagination or the thinking of any Spanish
vowel by using DSP techniques, like Filters or Fourier Transform, along with statistical methods that allow verify the
truthfulness of the previously mentioned difference. The analysis performed in this work makes evident the differences
among the thinking of five Spanish vowels and the control signal, concluding that the recognizing of these is possible due
to measurable features that are different from each other.
Keywords: brain-computer interface (BCI), EMOTIV, electroencephalography, imagined speech, fast fourier transform, non-stationary
signal, analysis of variance.

INTRODUCTION
Communication is the process by which
information is transmitted from one place to another by
using different methods and elements. This process is one
of the most useful tools that humans have for interacting
with their peers and developing a variety of tasks in a
determined environment.
The most common forms of communication are
the visual and verbal interaction by using gestures and
speech respectively; nevertheless, some people with
disabilities have difficulties for performing these tasks,
such people with body or facial paralysis.
Nowadays are technological developments in the
design and implementation of devices that try to solve
communication problems in people with some disabilities
in motor or cognitive abilities have been. As one solution,
devices that work by using brain signal have been
proposed and developed.
Some researches use Brain-Computer interface
devices [1], based on the blood pressure changes that
occur in the cranial area, as is the case of [2], which can
identify with 80% accuracy the commands "yes" and
"not", others acquire the signals generated from the
thought of movements, as presented in [3], achieving a
rating of 65% for the movements of upper limbs, in the
same way, there are works about the imagined speech, as
it can be appreciated in [4] where try to identify two
monosyllables with a recognition rate equal to 61% and in
[4, 5] where Hidden Markov Models are used for making
the separation of classes of two imagined Korean vowels
with 86% of accuracy.

These works show the effort that has been made
to advance in the search for alternatives for the actual
communication systems of human being, whether natural
or artificial, in addition, besides of general interest in to
analyze all the data that our brain is capable to generate,
for example in [6, 7] where an identification of patterns in
alcoholic subjects was realized and in [7] with the
diagnosis of epilepsy patients, by measuring components
of high frequency in the brain waves.
Most recent developments include devices that
operates with EEG signals, this devices ranging from
purely educational purposes like in [8], emotion
recognizing as is presented in [9], basic robotic
manipulation through mental commands like in[10]and
some advances in the letters and signs recognition as is
exposed in [11].
One of these devices, that have been an
interesting innovation in the last years, is the Emotiv
EPOC+®, a low cost electroencephalogram [12], this
device was designed as a teaching and mental training
device capable to help people with problems in the
interaction with his environment using only body
movements. It is commonly used by simple commands
such as facial movements as shown [13], or detection of
moods, for example, stress or concentration as shown in
[14]. Also, its versatility has made of this an instrument
used in many scientific field, such as medicine, neurology,
psychology and sleep study [15].
The aim of this research is to analyze and identify
the differences in EEG signals between a neutral pattern of
thought and the signals obtained from the imagination of a
vowel, with de data of six sensors responsible for

3074

VOL. 11, NO. 5, MARCH 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
measuring the areas related to the speech. This
computation is performed by implementing the Fourier
transform for obtaining frequency data of all the samples,
then a statistical method called ANOVA was used for
proving that the samples have measurable differences
among each other.
In this paper the first part is about the topics
related to EEG signals and its applications, showing some
articles and researches that implement different methods
and devices to capture signals of this type. In the second
part the methods and materials that were used are
described, as well as its justification and individual and
combined importance to develop the work. Third section
shows the obtained results from the implementation of
ANOVA, which gives numerical support to the differences
among the acquired patterns. In the last part, the
conclusions obtained with the development of this work
are exposed, posing a future perspective which allows
giving a bigger margin of study for this topic.

their environment by using the activity generated in the
brain, without using external peripherals or signals that
belong to muscular movements [1].
For this work, the headset Emotiv EPOC+® was
used, this device has 16 electrodes (14 for the acquisition
task and the other 2 for reference) that are distributed
according the international 10-20 system which is used for
electroencephalography. These electrodes are specifically
located for acquiring the data of the brain activity without
capturing muscular signals, for example the motor cortex.
Figure-1 shows the distribution map of Emotiv electrodes.

MATERIALS AND METHODS
Materials
BCI Device Emotiv EPOC+®
Brain-computer interface devices are systems that
transform the signals generated by brain activity, which
generally are electrical or electromagnetic, in orders or
control commands that can be interpreted by machines or
computers.
The main idea of the development of these
devices is to allow the interaction between the user and

Figure-1. Distribution map of Emotiv electrodes.
The Table-1 shown the nomenclature of each
electrode according international standards, also has a
brief description of Brodmann areas associated to each
sensor and its main function.

Table-1. Nomenclature of the electrodes and its related Brodmann areas.
Sensor

Brodman’s area

Main functions

AF4

AF3

Granular Frontal

Emotions

F7

F8

Triangular

Semantic

F3

F4

Intermediate Frontal

Eye movements

FC5

FC6

Opercular

Syntax

T7

T8

Middle Temporal

Auditory process

P7

P8

Occipitotemporal

Visual Memory

O1

O2

Parastriate

Visual perception

According to the Table-1 the device is capable to
capture the signals individually, allowing the selection of
signals that we want to measured. Also the device has
another features like wireless connection with the
computer [16], acquisition of raw signals [17] and is
portable [18].

METHODS
Signals acquisition
Measures of the brain waves of three test subjects
were performed; all of them were in stress-free
environments. For the acquisition process the steps of the
algorithm shown in Figure-2 were followed.

3075

VOL. 11, NO. 5, MARCH 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com

Device inicialization and setup

API libraries load

Data acquisition during preset time

Data storage for its later visualization
Figure-2. Acquisition process diagram.
The Figure-3 shows an example of the signals
acquired through Emotiv® device, specifically the sensors
that are related to the processes in the brain regarding to
speech skill.

Table-2. Brain waves and its frequency bands. [19]
Frequency (Hz)
Wave
Brief description
Delta
0.5-3.5
Deep sleep
Theta
4-7
Sleepiness
Alpha
8-12
Relaxation
Beta
13-30
Active consciousness
Gamma
31-100
High attentional control
We can say that speech is a conscious process
[20], because its need certain grade of concentration and
stimuli because this need certain grade of concentration
and stimuli for processing the received and response data.
For this reason the beta wave was selected, and like this
signals are only present in a specific frequency band, is
necessary to perform a filter with a pass-band between 13
and 30 Hz as was mentioned in the Table-2.
The chosen filter was an IIR filter, specifically a
Butterworth filter, because it has a soft response in the
pass-band, this ensures that the amplitudes of the allowed
frequencies don't change. In the other hand, the filter has
two disadvantages, it is slow in the stop-band and has a
non-linear behaviour in the phase, but nevertheless these
features aren't critical because the reconstruction of the
signal is not required. The digital filter was realized in
MatLab® and its expression is shown in the equation 1.
|� � | =

Figure-3. Acquired EEG signals with the EMOTIV
Epoc ®.

+

(1)

� 2�
�0

Where,
� = Angular frequency
� = Cutoff frequency
� = Filter order
The Figure-4 shows an example of the acquired
signals as well as the filtering process. An amplitude
reduction for some time intervals can be seen, but the form
of the signal is the same.

Digital signal processing
Six sensors related to the speech and language
process were selected, these are: F7, F8, FC5, FC6, T7,
T8. In this manner, the study was adjusted for the more
suitable signals with the aim of find a difference between
neutral and vowel signals.
Processing was performed in two stages; the first
one is a filtering stage for extracting the data that is
relevant for our work and the other is a transformation
stage where the Fast Fourier Transform is applied.
Filtering
The brain has five types of waves with different
frequencies bands, these waves are Delta, Theta, Alpha,
Beta and Gamma and are distributed in an interval
between 1 and 100 Hz, as is depicted in the Table-2.
Figure-4. Neutral signal from F7 channel.

3076

VOL. 11, NO. 5, MARCH 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
Fast Fourier Transform (FFT)
Fast Fourier transform is a computation method
for the Discrete Fourier transform. The method used by
Matlab is known as Cooley-Tukey algorithm, exposed in
the equation 2. This method has one special condition, the
data length have to be equal to any power of 2; typically
are 512, 1024 and 2048.
�

−

2
= ∑�=

Where,

[ �]

�

�

+

� = Data series length
� = Sample index

�

�

−

2
∑�=

[ �+ ]

�

�

(2)

�

= Integer value between 0 and −

�=

Complex expression: �

− 2� �
�

This technique is one of the most important and
useful tools in fields like engineering, science and
mathematics, because is a domain transformation that
allow to process temporal signals in frequency domain,
which implies some advantages like dimension reduction,
feature extraction and normalized data lengths. The
principal advantage of this algorithm is its speed, because
de DFT needs at least N2 operations, like additions and
multiplications of complex expressions, while the FFT
only needs N(log(N)) operations because of its design.
The Figure-5 shown the specters of the same
signals, but the upper graphic are the original signal and
the other is the filtered signal. The second graphic shows
the amplitude values for the range of 12 to 31 Hz are the
only ones present.

Figure-5. FFT of neutral signal (blue) and the same signal
but filtered (red).

Analysis of variance
Analysis of variance or ANOVA, is a statistical
method based on the computation of variances for
determining if different samples have big differences, or
otherwise their average values don't change, which means
that samples are very similar each other. This model
analyzes groups of two or more data series, each series
represent an independent sample, conformed by various
observations of the same event. The normal linear model
of ANOVA, describes that the data groups have a normal
distribution with different averages, in this way the model
only require the computation of variances and averages of
each group. The most common model is depicted in the
equation (2).
,

=� +�,

(3)

Where,
= Experimental unit index
= Group’s index
, = Observations
� = The average of each group
� , = Normal distribution of random errors with zero
average.
If the model result is zero or near to this value,
the hypothesis is put into a doubt, which means that the
samples are different. In the practice, the achieving of a
value equal to zero is not possible, for this reason a
proximity value have to be defined, this value is known as
significance. If this value is less than 0.05, the hypothesis
is nullified, and with this, the difference among the data is
confirmed.
RESULTS
As a first results, were obtained a group of
datasets related to the thinking of Spanish vowels, as well
as a methodology for the acquisitions of bio potentials
associated with cognitive process like speech.
From the data acquired of three test subjects were
obtained the results consigned in the Tables 3, 4 and 5.
These data are the significance value generated by the
ANOVA test, making a comparison among neutral or
control signals and signals related to the thought of a
vowel.
When a significance value is less than 0.05 the
hypothesis is nullified, that means that the variation of the
amplitudes for the same frequency in a vowel signal is
different respect to a neutral signal. For interpreting tables,
the results highlighted are considered as non-success
cases. In the table 3 the results of the test subject 1 are
shown. It is evident that the best success cases, in terms of
the difference among the vowel and neutral patterns, are
presented in the F7, F8 and FC6 channels.

3077

VOL. 11, NO. 5, MARCH 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
Table-3. Significances table of test subject number 3.
Channel
F7
F8
FC5
FC6
T7
T8

A
1,82E-25
4,58E-12
0,7501
2,49E-10
0,8263
0,0241

E
1,17E-30
2,70E-09
0,6263
9,13E-09
0,3738
0,0503

The Figure-9 shows an example of box plot the
data of test subject 1.

Vowel signals
I
2,13E-40
1,17E-16
0,0796
2,10E-13
0,0262
0,0490

O
2,57E-16
7,14E-16
0,0254
3,00E-16
0,2682
0,0001

U
4,61E-07
1,15E-04
0,1833
1,14E-04
0,2271
0,1994

This box plot contains specifically the amplitudes
of F7 channel, and can be seen that the F7 data are
different for each vowel, this means that amplitude
distribution between a neutral signal and vowel signal is
different, and with this information is possible to find
accurate patterns for each signal. With the same idea were
calculated the values in the table 4.
This case is like the one shown in the above table, because
have three channels that showed significant differences but
located in different places (F8, FC6 and T8).

Figure-6. Box plot for F7 channels. Test subject 1.
Table-4. Significances table of test subject number 2.
Channel
F7
F8
FC5
FC6
T7
T8

A
0,56717
5,34E-16
0,92683
2,90E-07
1,36E-15
0,0071

E
0,57120
9,43E-19
0,15361
1,29E-14
3,30E-29
0,0018

Finally, the Table-5 includes data related to the
last test subject; this data has a different behavior in
comparison to the previous two. In first place, most
channels achieved values under the significance level, for
almost all the vowels and the amount of non-success cases

Vowel signals
I
4,55E-12
0,03037
0,00376
1,58E-17
1,71E-04
3,22E-05

O
1,24E-09
0,02936
0,05374
5,77E-06
0,4419
7,44E-07

U
3,33E-02
6,80E-11
9,08E-07
2,42E-55
1,11E-10
1,34E-09

are the same as the test subject number two, but
consistently distributed. For the test subject 3, the success
cases are located in the F7, F8, FC5, FC6 and T8 channels.
The only that is similar, taking into account the data
dispersion, is the channel T7.

Table-5. Significances table of test subject number 3.
Channel

Vowel signals
A

E

I

O

U

F7

5,29E-16

0,0170

8,41E-20

4,51E-09

5,53E-16

F8

1,83E-08

0,0366

6,25E-07

0,2823

0,0010

FC5

6,73E-10

0,8442

3,60E-10

7,96E-07

1,14E-05

FC6

5,99E-17

2,03E-06

9,91E-18

2,90E-11

1,72E-14

T7

9,96E-17

0,2275

1,02E-10

0,2691

0,0706

T8

2,68E-10

0,0882

5,25E-09

6,19E-04

1,43E-06

3078

VOL. 11, NO. 5, MARCH 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com

CONCLUSIONS AND FUTURE PERSPECTIVES
Fourier transform allows to analyze signals in the
frequency domain, which implies two main advantages,
the first one is the extraction of information present in the
signals frequencies and this information is relevant
because is not time-dependent, the second advantage is to
achieve a reduction in the amount of data to be analyzed.
F7 and F8 were the only channels that showed consistency
among the three test subjects, these channels are related to
the semantic process, in other words, with the
interpretation and identification of linguistic signs of
specific language.
Channels with the worst performance were FC5
and FC6, which are responsible for sensing the processes
attached to the syntax, according to this is possible that
this error of this channel may be because the development
of sentences is more complex than the sign recognizing.
It's difficult to find a common pattern for the
three different subjects with EEG signals related to the
communication process, specifically with the speech,
because the response of different subject for the same
thought of a vowel does not have a direct relation.
As a future work, a vowel detection system using
EEG signals and artificial intelligence algorithms, like
neural networks, could be implemented. These algorithms
will be trained with data extracted from measured signals.
ACKNOWLEDGEMENTS
Special thanks to the Research Vicechancellorship of the “Universidad Militar Nueva
Granada”, for financing the project ING/INV 1762 titled
“Dispositivo reproductor de voz del lenguaje español a
través de habla subvocal e interfaz cerebro-computador”
project, 2015 year.
REFERENCES
[1] T. Ebrahimi. 2007. Recent advances in braincomputer interfaces. In: IEEE 9th Workshop on
Multimedia Signal Processing, 2007. MMSP 2007.
pp. 17-17.
[2] Y. M. Masayoshi Naito. 2007. A Communication
Means for Totally Locked-in ALS Patients Based on
Changes in Cerebral Blood Volume Measured with
Near-Infrared Light. IEICE Trans. Inf. Syst. E90D
(7).
[3] P. J. G.-L. G. Rodríguez-Bermúdez. 2013.
Adquisición, procesamiento y clasificación de señales
EEG para diseño de sistemas BCI basados en
imaginación de movimiento. Rev. VI Jornadas Introd.
a la Investig. la UPCT. 6: 10-12.

[4] K. Brigham and B. V. K. V Kumar. 2010. Imagined
speech classification with EEG signals for silent
communication: A preliminary investigation into
synthetic telepathy. 2010 4th Int. Conf. Bioinforma.
Biomed. Eng. iCBBE 2010, pp. 1-4.
[5] J. Kim, S.-K. Lee and B. Lee. 2013. Classifying the
speech response of the brain using Gaussian hidden
markov model (HMM) with independent component
analysis (ICA). Conf. Proc. Annu. Int. Conf. IEEE
Eng. Med. Biol. Soc. IEEE Eng. Med. Biol. Soc.
Annu. Conf. 2013: 4291-4294.
[6] Classification of Electroencephlography (EEG)
Alcoholic and Control Subjects using Machine
Learning Ensemble Methods.
[7] J. R. Hughes. 2008. Gamma, fast, and ultrafast waves
of the brain: Their relationships with epilepsy and
behavior. Epilepsy Behav. 13(1): 25-31.
[8] M.-S. Yoh, J. Kwon and S. Kim. 2010. Neuro
Wander: A BCI Game in the Form of Interactive
Fairy Tale. In: Proceedings of the 12th ACM
International Conference Adjunct Papers on
Ubiquitous Computing - Adjunct. pp. 389-390.
[9] K. Crowley, A. Sliney, I. Pitt and D. Murphy. 2010.
Evaluating a brain-computer interface to categorise
human emotional response. In: Proceedings - 10th
IEEE International Conference on Advanced Learning
Technologies, ICALT 2010. pp. 276-278.
[10] W. A. Jang, S. M. Lee, and D. H. Lee. 2014.
Development BCI for individuals with severely
disability using EMOTIV EEG headset and robot. in
2014 International Winter Workshop on BrainComputer Interface (BCI). pp. 1-3.
[11] C. A. R.-G. A. A. Torres-García. 2012. Toward a
silent speech interface based on unspoken speech.
[12] Robert Lievesley, Martin Wozencroft, and David
Ewins. 2011. The Emotiv EPOC neuroheadset: an
inexpensive method of controlling assistive
technologies using facial expressions and thoughts? J.
Assist. Technol. 5(2): 67-82.
[13] M. Duvinage, T. Castermans, M. Petieau, T.
Hoellinger, G. Cheron and T. Dutoit. 2013.
Performance of the Emotiv Epoc headset for P300based applications. Biomed. Eng. Online. 12(1): 56.

3079

VOL. 11, NO. 5, MARCH 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
[14] T. D. Pham and D. Tran. 2012. Emotion recognition
using the emotiv EPOC device. Lect. Notes Comput.
Sci. (including Subser. Lect. Notes Artif. Intell. Lect.
Notes Bioinformatics). 7667 LNCS (PART 5): 394399.
[15] C.-S. Huang, C.-L. Lin, L.-W. Ko, S.-Y. Liu, T.-P. Su
and C.-T. Lin. 2014. Knowledge-based identification
of sleep stages based on two forehead
electroencephalogram channels. Front. Neurosci. 8:
263.
[16] E. Delic. 2009. Biosensor
WO2009087486 A2.

noise

reduction.

[17] B. Dubocanin and E. Delic. 2008. Analog
Conditioning of Bioelectric Signals. US20080159365
A1.
[18] E. Delic, N. Do and L. Washbon. 2007. Electrode
Headset. US20070238945 A1.
[19] A. K. Engel and P. Fries. 2010. Beta-band oscillations
- signalling the status quo? Curr. Opin. Neurobiol.
20(2): 156-165.
[20] N. Kazanina, C. Phillips and W. Idsardi. 2006. The
influence of meaning on the perception of speech
sounds. Proc. Natl. Acad. Sci. U. S. A. 103(30):
11381-11386.

3080

