Sakarya University Journal of Science
ISSN 1301-4048 | e-ISSN 2147-835X | Period Bimonthly | Founded: 1997 | Publisher Sakarya University |
http://www.saujs.sakarya.edu.tr/

Title: Feature Selection with Sequential Forward Selection Algorithm from Emotion
Estimation based on EEG Signals
Authors: Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Recieved: 2018-12-24 19:36:16
Accepted: 2019-06-27 17:04:21
Article Type: Research Article
Volume: 23
Issue: 6
Month: December
Year: 2019
Pages: 1096-1105
How to cite
Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu; (2019), Feature Selection with Sequential
Forward Selection Algorithm from Emotion Estimation based on EEG Signals.
Sakarya University Journal of Science, 23(6), 1096-1105, DOI:
10.16984/saufenbilder.501799
Access link
http://www.saujs.sakarya.edu.tr/issue/44246/501799

New submission to SAUJS
http://dergipark.gov.tr/journal/1115/submission/start

Sakarya University Journal of Science 23(6), 1096-1105, 2019

Feature Selection with Sequential Forward Selection Algorithm from Emotion
Estimation Based on EEG Signals

Talha Burak Alakus*1, Ibrahim Turkoglu2

Abstract
In this study, we conducted EEG-based emotion recognition on arousal-valence emotion model.
We collected our own EEG data with mobile EEG device Emotiv Epoc+ 14 channel by applying
the visual-aural stimulus. After collection we performed information measurement techniques,
statistical methods and time-frequency attribute to obtain key features and created feature space.
We wanted to observe the effect of features thus, we performed Sequential Forward Selection
algorithm to reduce the feature space and compared the performance of accuracies for both all
features and diminished features. In the last part, we applied QSVM (Quadratic Support Vector
Machines) to classify the features and contrasted the accuracies. We observed that diminishing
the feature space increased our average performance accuracy for arousal-valence dimension
from 55% to 65%.
Keywords: emotion estimation, feature selection, support vector machines, EEG

1. INTRODUCTION
Emotion can be described as voluntary or
involuntary reactions to external factors like an
environment or any stimuli. It plays a crucial role
in daily lives and effects all the decisions, moral
judgements, prejudices all the time. Basic
emotions like anger, fear, happiness reflect the
conditions of humans in society and determine
their statuses. It is observed that people who
reflect positive emotions always are more
successful in the community [1].

*

In order to comprehend the nature and behavior of
the emotions, many researchers conduct various
studies on emotion analysis with different
techniques including physical and non-physical
ways. Emotion is an abstract thing thus studies do
not reach the desired level. Besides, the
mentioned techniques require a high level of data
and analysis and as a result of that, data can be
very complex and examining the data requires
time. Consequently, developing a machine
learning and a computer-based system is
necessary [2]. Emotions can be collected via
various methods such as voice signals, facial
expressions, physical activities or body language.

burak.alakuss@gmail.com
Kirklareli University, Department of Software Engineering, Kirklareli, Turkey. ORCID: 0000-0003-3136-3341
2
Firat University, Department of Software Engineering, Elazig, Turkey. ORCID: 0000-0003-4938-4167
1

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

Although all of these methods are used clearly, it
can be manipulated by the subjects with
intentionally. This makes interpretation of a raw
data wrong and can cause misclassification of
emotion data. Hereby, more secure and reliable
system is needed thus, the importance of
physiological signals -Electrodermal Activity
(EDA), Galvanic Skin Response (GSR), Blood
Pressure (BP), Electrocardiogram (EKG) and
Electroencephalography (EEG) is enhanced [3].
1.1. Electroencephalography
Electroencephalography (EEG) is a way to collect
brain signals with electrodes which are placed in
the scalp of the brain. Because of advancing
technology, EEG signals are not only collected
from the hospital but also wearable and portable
EEG devices via Wi-Fi and Bluetooth. Figure 1
shows the most popular EEG devices.

Table 1. Brain rhythms
EEG Rhythms
Delta (Î´)
Theta (Î¸)
Alpha (Î±)
Beta (Î²)
Gamma (É£)

Frequency (Hz)
1 Hz â€“ 3 Hz
4 Hz â€“ 7 Hz
8 Hz â€“ 13 Hz
14 Hz â€“ 30 Hz
31 Hz â€“ 50 Hz

Amplitude (ÂµV)
20 ÂµV â€“ 400 ÂµV
5 ÂµV â€“ 100 ÂµV
2 ÂµV â€“ 10 ÂµV
1 ÂµV â€“ 5 ÂµV
<2 ÂµV

It is a well-known fact that best brain rhythms for
emotion analysis are beta (Î²) and gamma (É£) since
their frequency is high and amplitude is low [7].
Electrodes are placed on the scalp with the 10-20
system which is defined by the International
Electroencephalography
and
Clinical
Neurophysiology Federation Union standard.
Figure 2 represents the 10-20 electrode system.

Figure 2. Electrode replacement according to the 1020 electrode system. a) side of the scalp, b) upside of
the scalp [8,9]

Figure 1. Wearable and portable EEG devices. a)
Emotiv Epoc 14 Channel, b) Emotiv Insight 5
Channel, c) NeuroSky Brainwave 1 Channel [4-6]

Brain signals are monitored and conditions of the
brain are controlled with brain rhythms. As can be
seen in Table 1 there are five brain rhythms that
are named based on their frequency and
amplitude.

Sakarya University Journal of Science 23(6), 1096-1105, 2019

Electrodes are disposed on the scalp from nasion
to inion and the distances between the electrodes
are designated as 10%-20%-20%-20%-10%. The
left side of the brain is represented by odd
numbers while the right side is represented even
numbers. Fp shows the pre-frontal sides of the
scalp while F images the frontal parts of the brain.
Center side of the brain is specified with â€˜Câ€™ and
temporal sides are defined with â€˜Tâ€™. Parietal is the
back-side of the brain and specified with â€˜Pâ€™
whereas occipital part of the brain is defined â€˜Oâ€™.
1.2. Emotion Models
There are two types of emotion models exist;
discrete emotions and dimensional emotions.
Discrete feelings consist of positive and negative
emotions which include eight basics emotions
(anger, anticipation, joy, trust, fear, surprise,

1097

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

sadness and disgust) [10]. On the other hand, the
dimensional model includes both arousal-valence
and emotion wheel. In the arousal-valence
coordinate system, emotions are separated into
four different coordinates. The left side of the
coordinate plane represents the negative emotions
whereas the right side shows the positive ones.
Arousal is specified on the axis of the ordinate and
emotions are aligned from calm to excited. Yet,
valence is represented on the axis of abscissas and
emotions are aligned on this axis as positive and
negative. In Figure 3, arousal-valence emotion
plane is given.

1.3. Raw Data Acquisition and Stimulus
In emotion analysis studies, in order to collect raw
EEG data and to analyze them some stimuli are
used. Stimulus is categorized into three parts;
visual, aural and visual-aural.
The visual stimulus includes some images or
photographs. The pictures or photographs are
shown to the subjects for a certain period of time.
During these sessions, EEG signals are collected
from subjects. The most popular dataset for visual
stimulus is IAPS [13]. Researches can get this
dataset by completing the IAPS request form [14].
Aural stimulus consists of sounds or voices. IADS
is the well know dataset for aural stimuli [15]. It
includes various audio files which are used to
stimuli the subjects for a certain period of time.
Like IAPS, researchers can obtain this dataset by
filling the IADS request form [14].

Figure 3. Arousal-valence emotion space [11]

As can be seen in Figure 3 there are four different
zones. First two zones are high arousal zones. The
first zone includes High Arousal Positive Valence
(HAPV) emotions (happy, delighted, excited) and
the second zone consists of High Arousal
Negative Valence (HANV) emotions (frustrated,
angry, tense). Last two zones (3 and 4) are low
arousal zones which include Low Arousal
Negative Valence (LANV) emotions (depressed,
bored, tired) and Low Arousal Positive Valence
(LAPV) emotions (content, relaxed, calm). In that
model, emotions are not represented by their
name but with their arousal-valence coordinate.
For example, delighted is not called as delighted
but High Arousal Positive Valence (HAPV).
Discrete emotions are easier to develop since it
classifies and discriminates the specified
emotions. However, it is not universal because
some of the emotions do not have a definition in
some languages [12]. As a result of that, the
dimensional model is more common and
universal thus many studies applied this model.

Sakarya University Journal of Science 23(6), 1096-1105, 2019

Visual-aural stimulus contains music clips, short
movies, video games etc. which affect the ear and
eye at the same time. In the literature, it is
observed that DEAP dataset [16] is the most
preferred database in studies carried out using
both visual-aural stimuli [17]. Like any other
databases, researches need to complete the
request form and End-User License Agreement
[18].
1.4. Evaluation of Stimulus
To evaluate the accuracy of the stimuli, typically
SAM (Self-Assessment Manikin) form is used.
Generally, in this form, there are four different
parameters; valance, arousal, dominance and
liking. Subjects rate their feelings according to
the parameters after each stimulus session is
finished. Each parameter excluding liking has a
range of 1 to 9. Figure 4 images a typical SAM
form.

1098

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

parameter value is 5 specifies that the subject is
neutral to the given stimulus.

Figure 4. Self-Assessment Manikin [19]

Valence represents the attraction (positive
valence) or offensiveness (negative valence) of an
event, environment, stimuli or object [20]. In the
form, valence is defined from unhappy to happy.
If a parameter value is lower than 5 means the
subject is unhappy from a given stimulus and
represents the low valence. High valence means
that the parameter value is higher than 5 and also
shows the subject is happy about the stimulus.
Considering a parameter value is 5 means that the
subject is neutral to the given stimulus.
Arousal is the state of activity against a stimulus.
Arousal is identified from calm to excited in
SAM. If a parameter value is lower than 5 means
the subject is calm from a given stimulus and
specifies the low arousal. High arousal refers that
the parameter value is higher than 5 and also
shows the subject is excited about the stimulus.
Considering a parameter value is 5 intends that the
subject is neutral to the endowed stimulus.
Dominance shows the submissiveness or
prepotency to given stimuli. In the form,
dominance is described from obedience to
dominance. If a parameter value is lower than 5
means the subject is obedience to a given stimulus
and represents the low dominance. High
dominance refers that the parameter value is
higher than 5 and also shows the subject is
dominant to the stimulus. Considering a

Sakarya University Journal of Science 23(6), 1096-1105, 2019

The organization of this paper as follows. In
Section 2, some studies are explained about EEG
based emotion recognition. Their methods,
database and classification accuracy also has
given. In Section 3, we showed our database, its
collection process and technical information
about our wearable EEG device. Besides, in this
part, feature extraction techniques and feature
selection algorithm are mentioned. In the 4th
section, we showed the classification accuracy of
the EEG channels after the feature selection
process. Also, we compared the discrimination
accuracy from the original study. In the last
section, the study is concluded.
2. RELATED WORKS
In this section, related works about EEG based
emotion recognition studies are examined. We
observed each study and mentioned their feature
extraction methods, classification algorithms,
database, and classification performance.
According to the literature, the recognition
process includes three parts; a) EEG data
collection and pre-processing, b) feature
extraction and c) feature classification. In some
cases, feature selection is also applied to reduce
feature matrix into smaller space.
Authors proposed a method based on Kernel
Fischer Discrimination Analysis in the study of
[21]. They used the IADS database to stimulate
10 different subjects to collect aural stimuli-based
EEG data. They applied various feature extraction
methods and used the KNN (K Nearest Neighbor)
classifier algorithm to discriminate the emotions.
They applied dimensional emotion model and
classification accuracy is observed 78% from
valance plane and 82% from arousal plane.
In the study of [22], researchers used visual-aural
stimuli to collect raw EEG data from subjects.
They tried to observe and compare the
classification accuracy for both 3 electrodes and 8
electrodes system. They applied Higuchiâ€™s Fractal
Dimension to collect and determine the key
features. In order to classify dimensional model

1099

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

emotions, SVM (Support Vector Machines)
classification algorithm is used. At the end of the
study, they found the average classification
accuracy 51,94% and 77,38% for 3 electrodes and
8 electrodes system respectively. The study
showed that increasing the number of electrodes
makes classification performance high.
Authors
in
[23]
applied
Multivariate
Synchrosqueezing Transform (MST) to collect
key features from EEG signals. By using MST,
they removed vibrations from signals then they
applied Independent Component Analysis (ICA)
to reduce feature vector. In their study, DEAP
dataset is handled. For classification ANN
(Artificial Neural Networks) is used. At the end
of the study, classification performance is
observed from arousal 82,11% and from valence
82,03%.

3. MATERIAL AND METHODS
3.1. Technical Information About EEG Device
In this study, we used the Emotiv Epoc+ 14
channel EEG device. EEG channels are AF3, F7,
F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8 and
AF4. Figure 5 shows the electrode and sensor
locations of the device. It has a sequential
sampling method and sampling rate can be down
sampled both to 128 SPS and 256 SPS. The
bandwidth of the device changes from 0.16 Hz to
43 Hz and digital notch filters at 50 Hz and 60 Hz.
It has a build in filter which is 5th order Sinc
Filter.

In the study of [24], authors applied Relevance
Vector Machines (RVM) to discriminate the
positive-negative emotions. DEAP dataset is
utilized in that work and for classification. In the
feature extraction phase, they applied sample
entropy and multi-scale entropy. After this phase,
they used both RVM and SVM to classify the
emotions. In conclusion, they observed average
classification performance with SVM 78,67% and
93,33% with RVM. It showed that RVM is
superior from SVM according to the proposed
feature extraction methods.
In this study, we performed SVM classifier and
different feature extraction methods including
statistical analysis, time-frequency domain and
chaotic features. They are all generally used for
emotion estimation process in the literature yet
there are some differences in our study;
ï‚· We collected our own EEG data from a
portable EEG device by applying our own
stimuli. In the literature ordinarily, publicly
available datasets or stimuli applied.
ï‚· Second, generally datasets obtained from
traditional EEG devices. In our study, we
performed a wearable and portable EEG
device. With this way, we can compare the
performance of this device between
traditional devices.

Sakarya University Journal of Science 23(6), 1096-1105, 2019

Figure 5. Emotiv Epoc+ sensor and reference locations
[4]

In this work, we considered every EEG channel
and used the built-in filter to remove artefacts
from the device. Also, we configured the
sampling rate to 128 SPS.
3.2. EEG Data Collection Process
We collected EEG data from 28 various students
from Firat University, Faculty of Technology,
Department of Software Engineering. In order to
collect the data, we applied 4 different computer

1100

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

games varied from HAPV, HANV, LANV and
LAPV. Before data collection, we informed each
subject about the study and their usage since
participation was voluntary. Later each subject
played each computer game for 5 minutes. During
that time, we collected EEG signals for every
game. After each session, we applied SAM form
to analyze the EEG signals. Figure 6 images the
proposed data collection process. We collected 20
minutes long data for each subject thus we have
560 minutes long EEG data in our database.

be found in [18]. We collected 50 features for
each EEG channel. At the end of the feature
extraction phase, our feature vector was
50x14x28. The first one indicates the feature
number, the second one shows the EEG channels
and the last one means the subject numbers. That
implies we collected 700 features from one
subject and totally 19600 features are available in
our database.
3.4. Feature Selection
with
Forward Selection Algorithm

Sequential

Sequential Forward Selection (SFS) is a greedy
search algorithm and searches the set from bottom
to up. The algorithm starts from an empty set and
this set is filled by features selected by some
evaluation functions. Here is the pseudo code for
the algorithm.
At every rehearsal, the feature is added to the new

Figure 6. Data collection process

As shown in Figure 6, the first 20 seconds consist
of some eye practices. By doing that, we tried to
make the subjects focus the games.
3.3. Feature Extraction Methods
Information measurement methods, some
statistical techniques and time-frequency domain
attributes are used to collect key features. Firstly,
we applied Discrete Wavelet Decomposition
(DWD) for 4 levels. To do that, we applied the
Daubechies wavelet filter with order 2 and collect
sub-signals in different frequencies. Later, we
applied Detrended Fluctuation Analysis (DFA),
Hjorth parameters (H), the average energy of
wavelet coefficients (AvgEng), Shannon Entropy
(ShanEn), logarithmic energy entropy (LogEn),
sample entropy (SampEn), multi-scale entropy
(MSCEn), standard deviation (StdDev), variance
(V) and zero-crossings (ZC) for each sub-signal.
A more detailed description of these methods can

Sakarya University Journal of Science 23(6), 1096-1105, 2019

1. Starting with an empty set ð‘‹ = {âˆ…}
2. Algorithm selects the next best feature
ð‘¡ = ð‘Žð‘Ÿð‘” âˆ‰ max ð½(ð‘‹ + ð‘¡)
3. Update ð‘‹
= ð‘‹ + ð‘¡ ;ð‘˜ = ð‘˜ + 1
4. Go to part 2
dataset which is selected from the remaining
features from the feature set. It is selected based
on the minimum classification error [25]. It is
widely used since it is simple and rapid. Detailed
information about this algorithm can be found in
[26].
In our study, we used Bayesian Classification
(BS) as an evaluation function in SFS algorithm.
Besides, in order to validate our results, we
performed resubstitution method. After the
feature selection process, features are diminished
from 50 to 4-9 for each EEG channel. It means
that our new feature space was changed from
50x14x28 to [4-9]x14x28. Besides, the number of
total features were decreased from 19600 to 1218.

1101

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

4. CLASSIFICATION ACCURACIES AND
COMPARISON
During the study, we applied the QSVM
(Quadratic Support Vector Machines) to
determine the arousal-valence performance of the
EEG signals. We selected the penalty parameter
(C) as 1. Besides, we determined kernel scale
mode as a gamma. For classification validation,
we applied 10-fold cross-validation. After we
specified the necessary parameters, we classified
the arousal-valence emotion zones. Our
multiclass output includes four different classes
namely (HAPV, HANV, LANV, LAPV). Table 2
shows the average classification accuracies for
each EEG channel with 50 features (before
feature selection).
Table 2. Classification of arousal-valence
performance before feature selection [18]
EEG

Number of
Features

Accuracy

AF3
AF4
F3
F4
F7
F8
FC5
FC6
O1
O2
P7
P8
T7
T8
Average

50
50
50
50
50
50
50
50
50
50
50
50
50
50
50

54%
50%
40%
54%
70%
63%
34%
34%
55%
54%
66%
70%
47%
79%
55%

According to Table 2, the best classification
performance observed from EEG channel T8
(79%). This channel also gave the best
performance on HANV arousal-valence plane
with 96% classification accuracy. Here is the
plane classification performance;
ï‚· HAPV: Best result is observed from F5
(85%)
ï‚· HANV: Best result is collected from T8
(96%)

Sakarya University Journal of Science 23(6), 1096-1105, 2019

ï‚· LANV: Best result is obtained from T8
(72%)
ï‚· LAPV: Best result is achieved from O1
(72%)
After the discrimination process, we eliminated
some of the features based on SFS algorithm. We
observed that average classification accuracy is
increased. Besides all of the EEG channels
showed more successful average performance.
Table 3 specifies the classification accuracy after
feature selection.
Table 3. Classification performance after feature
selection
EEG

Number of
Features

Accuracy

AF3
AF4
F3
F4
F7
F8
FC5
FC6
O1
O2
P7
P8
T7
T8
Average

4
4
7
6
6
6
9
8
6
8
6
6
4
7
6

58%
56%
57%
65%
75%
72%
40%
61%
68%
55%
68%
73%
75%
80%
65%

Table 3 shows that average classification
accuracy 65% which is more successful than the
previous average classification accuracy (55%).
With the algorithm, we reduced the features for
each channel and all of the channels demonstrated
better results. Again, T8 EEG channel is the most
effective channel with 80% performance. Here is
the plane classification performance after feature
selection process;
ï‚· HAPV: Best result is observed from P7
(93%)
ï‚· HANV: Best result is collected from F7
(100%)
ï‚· LANV: Best result is obtained from O1
(79%)

1102

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

ï‚· LAPV: Best result is achieved from T7
(93%)
Best performance progress observed from both
T7 and FC6 EEG channels. Their accuracy
reached 75% and 61% from 47% and 34% with a
growth rate of 28 and 27 respectively. In Table 4,
the number of selected features for each EEG
channel and their names are provided.
Table 4. Selected features with SFS algorithm
EEG

Num. of
Features

AF3

4

AF4

4

F3

7

F4

6

F7

6

F8

6

FC5

9

FC6

8

O1

6

O2

8

P7

6

P8

6

T7

4

T8

7

Feature
Names
LogEn (2), ShanEn, and
StdDev.
MSCEn, SampEn, ShanEn, and
V.
DFA, AvgEng, MSCEn,
SampEn (2), and ShanEn (2).
LogEn (2), SampEn, ShanEn,
StdDev, and V.
LogEn, MSCEn, ShanEn (2),
and V (2).
H, LogEn, MSCEn, ShanEn (2),
and V.
DFA, H, AvgEng (2), LogEn,
MSCEn, ShanEn, StdDev, and
ZC.
H, AvgEng, LogEn (3),
MSCEn, SampEn, and ShanEn.
H (2), AvgEng, SampEn,
StdDev, and V.
DFA, H (2), AvgEng, MSCEn,
SampEn (2), and ZC
H, LogEn, MSCEn, StdDev,
and V (2).
DFA, MSCEn, ShanEn (2),
StdDev, and V.
LogEn (3), and MSCEn.
AvgEng, LogEn (2), MSCEn
(2), SampEn, and StdDev.

According to Table 4, some EEG channels have
multiple similar features. They are obtained from
different wavelet coefficients. For instance, T7
channel has 4 features after the feature selection
process, and 3 of them are logarithmic energy
entropies and the other one is multiscale entropy.

Sakarya University Journal of Science 23(6), 1096-1105, 2019

5. RESULTS
In this study, we performed EEG based emotion
recognition with dimensional emotion models.
Our study includes four parts; a) EEG data
collection, b) Feature extraction, c) Feature
selection, d) Feature classification. In EEG data
collection phase, we collected our data by
applying a visual-aural stimulus from 28 different
subjects. We used a wearable EEG device (14
channel Emotiv Epoc+) and 4 different computer
games. After collection of EEG signals, we
composed our database. It consists of 392
(14(channel)x28(subject)) EEG signals with 20
minutes long. In the feature extraction stage, we
performed DWT to transform EEG signals into
sub-signals. We utilized Daubechies 2nd order
wavelet filter and signals are decomposed into 4
levels. In that way, we collected 4 detailed
coefficients and 1 approximate coefficient. After
that, we applied some information measurement
and statistical methods to obtain key features from
each coefficient. 50x14x25 matrix size of features
are obtained after this phase. In the third part, we
applied the SFS algorithm to reduce the features
and disposed of unnecessary features. We
evaluated Bayes function to do that and our new
vector space reduces for each channel with a
different number of features. On average, our
vector reduced to 6x14x28 from 50x14x28. On
the classification part, we demonstrated QSVM
classifier for discrimination of emotions. Firstly,
QSVM is used for each EEG channel based on
their arousal-valence plane before feature
selection. After, we classified the EEG channels
based on selected features again and compared
their results. We observed that reducing the
feature space gives better results and our average
accuracy is increased from 55% to 65%.

1103

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

ACKNOWLEDGMENTS
This study is supported by the Firat University
Scientific Research Project Unit with Project
Number: TEKF.17.21. Authors also thank Asst.
Prof. Murat Gonen for valuable contribution for
collecting and analyzing EEG signals.
REFERENCES
[1]

T. B. Alakus, and I. Turkoglu, â€˜â€™EEG based
emotion analysis systems,â€™â€™ TÃ¼rkiye
BiliÅŸim VakfÄ± Bilgisayar Bilimleri ve
MÃ¼hendisliÄŸi Dergisi, vol. 11, no. 1, pp. 26
â€“ 39, 2018.

[2]

A. Turnip, A. I. Simbolon, M. F. Amri, P.
Sihombing, R. H. Setiadi, and E. Mulyana,
â€˜â€™Backpropagation neural networks training
for EEG-SSVEP classification of emotion
recognition,â€™â€™ Internetworking Indonesia
Journal, vol. 9, no. 1, pp. 53 â€“ 57, 2017.

[3]

W. Szwoch, â€˜â€™Using physiological signals
for emotionâ€™â€™, 2013 6th International
Conference on Human System Interaction
(HSI), pp. 556 â€“ 561, 2013.

[4]

Emotiv Epoc+ 14 Channel Mobile EEG
Device,
Online
Link:
https://www.emotiv.com/product/emotivepoc-14-channel-mobile-eeg/

[5]

Emotiv Insight 5 Channel Mobile EEG
Device,
Online
Link:
https://www.emotiv.com/product/emotivinsight-5-channel-mobile-eeg/

[6]

Brainwave NeuroSky One Channel EEG
Device,
Online
Link:
https://store.neurosky.com/pages/mindwav
e

[7]

[8]

J. A. Russel, â€˜â€™Core affect and physiological
construction of emotion,â€™â€™ Psychological
Review, vol. 110, no. 1, pp. 145 â€“ 150,
2003.
R. Cooper, J.W. Osselton, J.C. Shaw, â€œEEG
Technology,â€ 2nd Edition, 1974.

Sakarya University Journal of Science 23(6), 1096-1105, 2019

[9]

H. H. Jasper, â€˜â€™The ten-twenty electrode
system of the international federation,â€
Electroencephalography
and
Clinical
Neurophysiology, vol. 10, pp. 371 â€“ 375,
1958.

[10] P. Ekman, â€˜â€™An argument for basic
emotions,â€™â€™ Cognition and Emotion, vol. 6,
no. Â¾, pp. 169 â€“ 200, 1992.
[11] L. C. Yu, L. H. Lee, S. Hao, J. Wang, Y. He,
J. Hu, K. R. Lali, and X. Zhang, â€˜â€™Building
chinese affective resources in valencearousal dimensions,â€™â€™ Proceedings of the
15th Annual Conference of the Nort
American Chapter of the Association for
Computational
Linguistics:
Human
Language Techniques (NAACL-HLT), pp.
540 â€“ 545, 2016.
[12] J. A. Russel, â€œCulture and the
categorization of emotions,â€ Psychological
Bulletin, vol. 110, pp. 425 â€“ 450, 1991.
[13] P. J. Lang, M. M. Bradley, and B. N.
Cuthbert, â€˜â€™International affective picture
system (IAPS): Affective ratings of pictures
and instruction manual,â€™â€™ Technical Report
A-8, 2008.
[14] IAPS Request Form, Online Link:
https://csea.phhp.ufl.edu/media.html#topm
edia
[15] M. M. Bradley, and P. J. Lang,
â€œInternational affective digitized sounds
(IADS): Affective ratings of sounds and
instruction manual,â€ Technical Report B-3,
2007.
[16] S. Koelstra, C. MÃ¼hl, and M. Soleymani,
â€œDEAP: A database for emotion analysis
using physiological signals,â€ IEEE
Transactions of Affective Computing, vol.
3, no. 1, pp. 18 â€“ 31, 2012.
[17] T. B. Alakus, and I. Turkoglu, â€œEmotion
Detection Based on EEG Signals by
Applying
Signal
Processing
and
Classification Techniques,â€ Master Thesis,

1104

Talha Burak AlakuÅŸ, Ä°brahim TÃ¼rkoÄŸlu
Feature Selection with Sequential Forward Selection Algorithm from Emotion Estimation based on EEG Si...

Institute of Science, Department
Software Engineering, 2018.

of

Industrial Electronics Society, pp. 2845 â€“
2850, 2010.

[18] DEAP Dataset Access, Online Link:
http://www.eecs.qmul.ac.uk/mmv/datasets/
deap/download.html

[26] I. A. Basheer, and M. Hajmeer, â€œArtificial
neural networks: Fundamentals, computing,
design, and application,â€ Journal of
Microbiological Methods, vol. 43, no. 1, pp.
3 â€“ 31.

[19] S. Jirayucharoensak, S. Pan-Ngum, and P.
Israsena, â€œEEG-based emotion recognition
using deep learning network with principal
component
based
covariate
shift
adaptation,â€ The Scientific World Journal,
vol. 2014, 2014.
[20] N. H. Frijda, â€œThe emotions,â€ Cambridge
University Press, pp. 207, 1986.
[21] Y. H. Liu, W. T. Cheng, Y. T. Hsiao, C. T.
Wu., and M. D. Jeng, â€œEEG-based emotion
recognition based on kernel fishers
discriminant analysis and spectral Powers,â€
IEEE International Conference on Systems,
Man, and Cybernetics, pp. 5 â€“ 8, 2014.
[22] M. M. Javaid, M. A. Yousaf, Q. Z. Sheikh,
M. M. Awais, S. Saleem, and M. Khalid,
â€œReal-time EEG-based human emotion
recognition,â€
Neural
Information
Processing, pp. 182 â€“ 190, 2015.
[23] A. Mert, and A. Akan, â€œEmotion
recognition based on time frequency
distribution of EEG signals using
multivariate synchrosqueezing transform,â€
Digital Signal Processing, vol. 81, no. 2018,
pp. 152 â€“ 157, 2018.
[24] L. Xin, S. Xiao-Qi, Q. Xiao-Ying, and S.
Xiao-Feng, â€œRelevance vector machinebased EEG emotion recognition,â€ 2016
Sixth
International
Conference
on
Instrumentation
&
Measurement,
Computer, Communication and Control,
pp. 293-297, 2016.
[25] A. Marcano-Cedeno, J. QuintanillaDominguez, M. G. Cortina-Januchs, and D.
Andina,â€Feature selection using sequential
forward selection and classification
applying artificial metaplasticity neural
network,â€ 36th Annual Conference on IEEE

Sakarya University Journal of Science 23(6), 1096-1105, 2019

1105

