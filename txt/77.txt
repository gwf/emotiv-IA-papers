NESciences, 2019, 4(2): 92-106

-RESEARCH ARTICLEDetermination of the 25th Frame with the Eeg Signals Stored in the Videos
Gözde Özkan1*, Ahmet Gökçen2
1

The Graduate School of Engineering and Science, Iskenderun Technical University, Turkey
2
Department of Computer Engineering, Iskenderun Technical University, Turkey

Abstract
Nowadays, the videos that appear in every part of our lives are a set of images resulting from the
sequential addition of a series of image files. One second of the video is the result of the merging
of 24 picture frames. The visual subliminal perceives 24 frames per second. It is difficult to see
hidden pictures in the frames of videos which is called the 25th frame effect. In this study,
electroencephalogram (EEG) signals are analyzed and it is aimed to determine whether or not the
25th frame effect is perceived by the brain. For this purpose, 6 different videos were shown to 50
participants. The participants watched videos which are contain a raw and 25th frame effect. And
EEG signals were recorded by Emotive Epoc+. Statistical feature extraction algorithms were
applied to EEG signals. K-nearest neighbor (KNN) classifier and Naive Bayes(NB) classifier, were
used for classificstion. Training was performed by applying the k-fold cross validation. The KNN
classifier's performance are as follows; overall accuracy of 96.60%, recall of 98.00%, F1 score of
96.50%, precision of 95.29%. The NB classifier's performance are as follows; overall accuracy of
92.00%, recall of 92.00%, F1 score of 92.20%, precision of 92.00%.
Keywords:
Electroencephalography Signals, Brain Computer Interface, 25th frame, Subliminal Messages.
Article history:
Received 20 April 2019, Accepted 05 May 2019, Available online 16 May 2019
Introduction
A video is called a series of images resulting from the sequential addition of a series of images.
The number of images displayed in 1 second of a video is called frame per second (fps) (Davis et
al., 2015 ; Özcan et al., 2015). A one-second video has been composed by 24 frames. However, if
the video has the 25th frame, the viewer could create it at the level of consciousness and works in
*

Corresponding Author: Gözde Özkan, e-mail: gozdeozkan.mfbe16@iste.edu.tr

Natural and Engineering Sciences

93

his subconscious. In the literature, this situation, which is called the 25th frame effect, is usually
used by advertising companies to influence the viewer through subliminal message delivery
(Vokey, 2013; Karremans et al., 2006; Küçükbezirci, 2013).
The Radio and Television Supreme Council (RTÜK), which provides control of television
broadcasts in Turkey, stipulates that subliminal advertisements of this type should not be allowed.
Consciousness is the moment of awareness in people. At the level of consciousness, perception is
open and emotions are felt. The subconscious is another structure consisting of movements,
thoughts and behaviors in the state of consciousness. Movements in the state of consciousness
directly affect the subconscious (Florea, 2016).
The aim of this study is to determine if the brain perceives the hidden pictures in the videos
that are thought to affect people's subconscious. The signals were recorded using the Emotiv EPOC
+ device, which is mounted on a wireless hood and is connected to the computer via Wi-fi. Two of
the 16 channels of the Emotiv EPOC + device are used as reference points. The Emotiv EPOC +
device is non-invasively attached to the scalp, allowing electrode information from the brain.
Electroencephalogram (EEG) recordings can be used for observing the changes of human
emotions in brain signals (Altan et al., 2016). EEG signals are widely used in emotion estimation
applications In the mid-90s, people began to teach emotion estimation to machines. Hans Berger
was the first to associate EEG signals with sleep. The first EEG-based classification was made in
1937 by Loomis and his assistants (Williams et al., 1974 ).
There are many studies in the literature about the effect of EEG signals on emotions. In the
studies, emotion analysis and classification process were used for different types of stimuli using
EEG signals and facial expressions (Murugappan et all., 2008 ; Soroush et al., 2018; Daşdemir et
al., 2017 ; Atasoy et al., 2014). Emotions are reflected in body language, facial expressions, voice
tones. For this purpose, the participants evaluated the audio-visual stimuli. Accordingly, EEG
findings were classified according to their positive and negative conditions. (Soleymani et al., 2016
; Liu et al., 2010 ; Özerdem & Polat, 2016). Emotions are expressed by music, tone, voice, facial
expressions, gestures. Music videos are also used for observing the emotional effects. Participants
have rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and
familiarity by The bodily reactions of the user have been translated into EEG signals (Koelstra et
al., 2012). In another study, the participants were listened to unpleasant sounds and EEG recordings
were recorded. As a result, it was observed that spontaneous mimic movements increased during
the application of unpleasant sounds (Grunwald et al., 2014). In some studies, it has been examined
how brain performance is affected by music, picture and meditation by analsing EEG from the
patients wtih psychological trauma or chemotherapy treatment (Bhattacharya & Lee 2016 ; Tan et
al., 2014; Fidan & Özkan 2018). In a study, classification was performed by EEG signals for the
diagnosis of epileptic diseases (Acharya et al., 2011).
With the development of emotion recognition studies, the neuromarketing sector has been
emerged. With the transfer of the data obtained in neurological research to the marketing discipline,
the field of neuro-marketing has emerged. Studies are integrated into this field. The effect of
advertising, brand selection and product design on the brain was investigated. By analyzing at the
EEG signals of consumers, it was investigated how they gave the purchase decision and which
marketing tools were affected. Neuromarketing has focused on how advertising and marketing

Natural and Engineering Sciences

94

stimulates nerve centers in the brain (Wang et al., 2018 ; Yücel & Coşkun 2018). As a matter of
fact, EEG signals while watching the advertisements were recorded and emotional reactions were
examined (Elden, 2009). As a result of analysis on EEG, studies were conducted to detect the likes
of the brands that they have seen in television commercials (Custdio, 2011).
Material and Methods
The study was carried out in three stages as data acquisition, feature extraction and classification
respectively. Figure 1 shows the working flow chart.

Figure 1. Flow diagram of the study.
Data Acquisition
In this study, six different videos including animal, plant and nature themes were prepared. These
videos are divided into frames. Pictures are added to be randomly positioned between the frames.
Frames are reassembled to form a new video with hidden pictures. As a result of the videos
composed, the participants were shown two types of videos: original video and video with hidden
pictures. Figure 2 shows the frames of the video. Figure 3 shows the case of adding hidden pictures
to frames.

Natural and Engineering Sciences

Figure 2. Frames of the video

95

Figure 3. Adding hidden pictures to frames

Emotiv EPOC+ is a 16-channel EEG data device which has a sampling frequency of 128 Hz.
Constructed videos for the participants has 15 seconds duration. A total number of 600 EEG
recordings were collected on 50 participants following the viewing of 6 different videos with both
raw and 25th frame effects. The EEG signals were recorded in a silent and light isolated room. The
participants were selected from the students which are 19-26 years old and university staffs on the
basis of the ethics report and the necessary permissions on the basis of volunteerism. The sensors
of Emotiv EPOC+ do not receive high-quality signals from long-haired participants. Therefore,
male participants were used. The mean age of the participants was 23.20 and the standard deviation
was 2.338672. Figure 4 shows the EEG signals with 25 th frame effect video. Figure 5shows the
EEG signals with raw video in random channel.

Figure 4. EEG signals with 25th frame effect video of one person

Natural and Engineering Sciences

96

Figure 5. EEG signals with raw video of one person

The brain is divided into sub-regions that handle different roles. The EEG device provides
the possibility to receive signals from related areas of the brain in these areas. The occipital lobe,
which is the posterior part of the brain, is responsible for visual perception. The frontal lobe, which
is the front part of the brain, is responsible for creativity, problem solving, decision-making and
planning. The parietal lobe, which is the side part of the brain, is responsible for high perception
and language ability. The temporal lobe of the brain is responsible for hearing and memory
abilities. Figure 6 shows these sub-regions which have related to different abilities. Since the EEG
signals are collected with electrodes placed in the scalp, the region in which each sensor is placed
is of great importance for the analysis of signals and positioned by a system called 10-20 system
positioning. Figure 7 shows the sensor position of these EEG electrodes.

Figure 6. Left and right symmetrical hemispheres of longitudinally divided brain structure
(Duarte,2017)

Natural and Engineering Sciences

97

Figure 7. Sensor position of EEG electrodes for Emotiv EPOC + systems (Wang et al., 2014)
Feature Extraction
In the feature extraction stage, 10 different statistical features were calculated from raw signals
including difference between maximum and minimum values, mean, median, standard deviation,
power, variance, energy, kurtosis, skewness, interquartile range value. The features which are
calculated from raw and 25 frame effects videos are shown in Figure 8. Each value in the x-axis
represents features. The y axis in the graph is the amplitude values of the feature. Table 1 shows
the numbers and frequency values represented by the names of the feature.

Figure 8. The feature of EEG signals with raw video and 25th frame effect

Natural and Engineering Sciences

98

Table 1. Numbers and amplitude values represented by the names of the features.
Features

Amplitude of EEG
signals with raw
video

Amplitude of EEG
recordings with
25th effect frames

0,008537
0,163005
0,215715
0,005072
0,114452
0,000113
0,114453
0,022925
0,362387
0,043651

0,008608
0,761194
0,882353
0,008683
0,459141
0,000312
0,459141
0,025955
0,762613
0,020248

Difference between
maximum-minimum
Mean
Median
Standard deviation
Power
Variance
Energy
Kurtosis
Skewness
Interquartile Range

For KNN and NB classifiers, Median, Skewness and Mean value features were exprienced
as the most to be more successful features. Median is taken into account in cases where deviation
or endpoints are affected by the distribution of data. Since EEG signals are variable data endpoints
have an effect on signals (Türk & Özerdem, 2017). The median feature, which is more resistant to
noise and outliers, showed the highest success. At the same time, the median value was found to
be consistent. Skewness selects a central point in the signal and checks if the signals to the right
and left of this point are the same. If it is the same, it is concluded that the data is symmetrical
(Alpaslan et al., 2015). The symmetry is inversely proportional to the skewness. Since the EEG
signal are non-symmetrical, this feature gave high success. The average values of EEG signals of
videos containing the 25th frame effect were higher than the EEG signals of raw videos. Therefore,
the mean value was a distinctive value for the classifier. The formulas of the features are shown in
Table 2. Where, 𝑥𝑛 = 1, 2, 3 … n is a time series, N is the number of data points, AM is the mean of
the sample.
Table 2. Formulas of features
Names of
Features
Maximum
Minimum
Values
Difference
Mean(AM)
Median(MN)
Standard
deviation(SD)

Formula

MaxV = max[𝑥𝑛 ]
MinV = min[𝑥𝑛 ]
max[𝑥𝑛 ]min[𝑥𝑛 ]
1
AM=𝑁 ∑𝑁
𝑛=1 𝑥𝑛
𝑁+1 𝑡ℎ

MN=(

2

)

2
∑𝑁
𝑛=1 𝑥𝑛 −𝐴𝑀

SD=√

𝑁−1

Names of
Features
Variance
(V)

Skewness
(S)
Kurthosis
(K)
Power(P)

Formula

V=

S=

2
∑𝑁
𝑛=1 𝑥𝑛 −𝐴𝑀

𝑁−1

3
∑𝑁
𝑛=1 𝑥𝑛 −𝐴𝑀

K=

(𝑁−1)𝑆𝐷3
4
∑𝑁
𝑛=1 𝑥𝑛 −𝐴𝑀

P= 𝑙𝑖𝑚

𝑁→∞

(𝑁−1)𝑆𝐷4
1 𝑛=𝑁−1 2
∑
|𝑥𝑛 |
𝑁 𝑛=0

Natural and Engineering Sciences
Interquartile
Range(IQR)

IQR=𝑄3−𝑄1

99
∞

E= ∫−∞ |𝑥𝑛 |2

Energy(E)

𝑁 + 1 𝑡ℎ
)
4
3(𝑁 + 1) 𝑡ℎ
)
𝑄3 = (
4
𝑄1 = (

Classification
During the classification stage, the EEG signals from raw and 25th frame effect videos were
compared. There are lots of classification methods but in this study two of them are used. First, k
classification methods, the nearest neighbor (KNN) classifier and the other is Naive Bayes
classifier (NB), a linear classifier. A major disadvantage in calculating distance measurements from
the direct training set is that the variables have different measurement scales. Therefore, the fetaure
is standardized before classification stage. So all values have become values close to each other.
The formula of standardization process is shown in Eq.(1).
𝑋𝑠 =∑𝑁
𝑖=1 𝑋

𝑋𝑖 −𝑋𝑚𝑖𝑛

𝑚𝑎𝑥 −𝑋𝑚𝑖𝑛

(1)

K- Fold Cross Validation
K-fold cv divides the dataset into k folds. The first (training set) is used to determine the model
parameters of the classifier, while the other (test set) is used to measure the performance of the
trained classifier (Duda et al., 2012).
In a data set with a total number of n samples, the k-part verification method is divided into
separate discrete parts, each with n / k. Each time a different set of data sets is left for testing, the
remaining k-1 data set is used for training. By changing the test set of the classifier 'k' times training
is done. The average of the 'k' errors obtained in this way is estimated by the classifier performance.
In addition, diversification of data into training and testing sections is ensured (Altan et al. 2019;
İşçimen et al., 2014). In this study, 5- fold cross validation method was used. An equal number of
samples are available in each of the five allocated data sets to provide homogenity in distribution.
K- Nearest Neighborhood Classification
K- nearest neighbor (KNN) classifier is a distance based classifier used for the classification
process. It compares a particular unidentified test data with training data that are available in an
ndimensional space and the calculated distance measure is used for measuring the nearness of data
values(Vimala et al., 2019). The basis of the KNN method, which is a popular classification
algorithm, is to give new unclassified examples to the class of the majority. The advantage of the
KNN is that it can easily overcome the problems which high number of classes using simple
mathematical solutions. Its purpose is to classify existing learning data when a new sample is
available. When the algorithm arrives, a new instance looks at its closest 'k' neighbor to decide its
class, for example (Yıldız et al., 2008). KNN focuses on the closest training examples in the feature
space (Bahari & Janghorbani, 2013).
In the KNN algorithm, the value 'k' must be determined first. Once the value 'k' has been
determined, the distance from all learning samples must be calculated using ascending sortings.

Natural and Engineering Sciences

100

After sorting, it is found which class value it belongs to. Here, determining the value of 'k' means
how many values should be considered closest to us (Yağanoğlu et al., 2014 ). The nearest k
neighbor algorithm takes into account the distance between the test and the training data
(Piotrowski & Szypulska, 2017). In the study, 'k' value is taken as 3. In this case, it was decided
that the nearest 3 of the data in the learning set was taken and which class belonged. The method
uses Euclidean distance in calculating distances. The Euclidean method is the most commonly
used distance measure in classification and clustering algorithms. Euclidean method is shown in
Eq.(2) .
𝑑 = √∑𝑛𝑖=1(𝑥𝑖 − 𝑦𝑖 )2

(2)

'x' represents the data entry classified, 'y' represents the training set data, 'n' is the number of
the data set. Euclidean measure is calculated according to the equasition 'x' to measure the linear
distance C= (𝑥1 , 𝑥2 , 𝑥3 … 𝑥𝑛 ) and D= (𝑦1 , 𝑦2 , 𝑦3 … 𝑦𝑛 ) between two points in space (Kresse &
Danko, 2012; Eraldemir et al., 2017).
Naive Bayes Classification
Thomas Bayes, the pioneer of Bayes' theorem named Naive Bayes(NB) which predicts the
probability that the samples belong to classes. NB argues that features do not affect each other.
Each feature has the same importance in itself (Kutlu & Köse 2014). Bayesian classifiers are
statistical classifiers that predict class membership possibilities. Estimations of the probability of
the training data are calculated by Bayesian classifiers (Bhattacharyya et al., 2011). The NB
classifier requires less training data than the others for classification (Sharma,2017). The NB
classifier assumes that the existence of a particular property of a class is not related to the presence
of another property. Depending on the exact nature of the probability model, the NB classifier can
be trained very efficiently in a supervised learning environment (Wang & Zhang 2016).
The probability of generating the d instance of the cj class represented by n feature is shown
in Eq.(3) . The Bayes' theorem is given in Eq.(4) .
𝑝(𝑑|𝑐𝑗 )= 𝑝(𝑑1|𝑐𝑗 )* p( 𝑑2 |𝑐𝑗 )*…* 𝑝(𝑑𝑛 |𝑐𝑗 )
𝑝(𝑐𝑗 |𝑑) =

𝑝(𝑑|𝑐𝑗 )𝑝(𝑐𝑗)
𝑝(𝑑)

(3)

(4)

Results
The aim of this study is to determine if the brain perceives the hidden pictures in the videos that
are thought to affect people's subconscious. Signals were recorded using the Emotiv EPOC +
device. Within the scope of the study, 50 participants watched 6 different videos include raw and
25th frame effect. The EEG signals are recorded as a result of viewing videos containing the raw
and 25th frame effect. Statistical features from each EEg signals were calculated. Classification was
performed to compare the EEG signals of videos containing the raw and 25th frame effect using
KNN and NB. Training was provided by applying k-fold cross validation method. The learning
sample numbers (k) of the KNN classifier were tested as 1,3,5,7,9. The cross validation fold was
processed as 5 in both classifiers.

Natural and Engineering Sciences

101

In this study, the performance for each feature in the system were calculated. KNN classifier
has achieved overall accuracy rates of; 78.80% for the Maximum Minimum Values Difference,
95.00% for the Mean, 96.00% for the Median, 83.20% for the Standard Deviation, 95.20% for the
Power, 78.00% for the Variance, 94.40% for the Energy, 78.40% for the Kurtosis, 97.00% for the
Skewness, 86.40% for the Interquartile Range. Table 3 shows the success of the features using
the KNN classifier with different k values.
Table 3. The success of features using the KNN classifier
Distance
metrics
Maximum

k=1

k= 3

k=5

k=7

k=9

77.00%

83.00%

77.00%

79.00%

78.00%

Achievement
Averages
78.80%

Mean
Median
Standard
Deviation
Power
Variance

95.00%
95.00%
78.00%

95.00%
97.00%
85.00%

95.00%
95.00%
84.00%

95.00%
97.00%
86.00%

95.00%
96.00%
83.00%

95.00%
96.00%
83.20%

96.00%
76.00%

95.00%
78.00%

95.00%
81.00%

95.00%
79.00%

95.00%
76.00%

95.20%
78.00%

Energy
Kurtosis
Skewness
Interquartile

93.00%
80.00%
94.00%
77.00%

95.00%
80.00%
97.00%
87.00%

94.00%
82.00%
98.00%
89.00%

95.00%
78.00%
98.00%
88.00%

95.00%
72.00%
98.00%
91.00%

94.40%
78.40%
97.00%
86.40%

NB classifier has achieved overall accuracy rates of; 57.00% for the Maximum Minimum
Values Difference, 93.00% for the Mean, 95.00% for the Median, 60.00% for the Standard
Deviation, 92.00% for the Power, 48.00% for the Variance, 92.00% for the Energy, 57.00% for the
Kurtosis, 86.00% for the Skewness, 68.00% Interquartile Range. Table 4 shows the success of the
features using the NB classifier.
Table 4. The success of features using the Naive Bayes classifier
Values Difference
Mean
Median
Standard Deviation
Power
Variance
Energy
Kurtosis
Skewness
Interquartile Range

%
93
95
60
92
48
92
57
86
68

Median, Skew and Mean value features are the most successful for both classifiers. There is
a deviation in the distribution of EEG data. In addition, the effect of endpoints is large. In such
cases, the median value is taken into account. Skewness is the measurement of the non-symmetrical
probability distribution of the random variable. Therefore, the non-symmetrical values of the EEG

Natural and Engineering Sciences

102

signals gave high values for this feature. The average values of EEG signals of videos containing
the 25th frame effect were higher than the EEG signals of raw videos. Therefore, the mean is a
distinctive value for the classifier.
KNN classifier for all features has achieved overall accuracy rates of; 94.50% for the overall
accuracy, 97.20 %for the recall, 95.49% for the F1 score, 94.19% for the precision. Table 5 shows
the overall achievement for the KNN classifier.
Table 5. Performance achievement of the KNN classifier on all features
Distance
Metrics
Overall
accuracy
Recall
F1 Score
Precision

k=1

k= 3

k=5

k=7

k=9

92.00%

95.00%

96.00%

98.00%

96.00%

Achievement
Averages
94.50%

92.00%
91.87%
92.36%

98.00%
95.14%
92.54%

98.00%
96.18%
94.85%

100.00%
98.09%
96.36%

98.00%
96.17%
94.84%

97.20%
95.49%
94.19%

NB classifier for all features has achieved overall accuracy rates of; 83.00% for the overall
accuracy, 83.00% for the recall, 83.40% for the F1 score, 83.05% for the precision. Table 6 shows
the overall achievement for the NB classifier.
Table 6. Performance achievement of the Naive Bayes classifier on all features.
Overall
accuracy
Recall
F1 Score
Precision

83.00%
83.00%
83.40%
83.05%

The best 5 features have been selected to improve system performance. These features are;
Median, Skewness, Mean, Power, Energy Values. KNN and NB classification was applied to these
selected features. As a result, the performance of the system increased in both cases. KNN classifier
for high successful features has achieved overall accuracy rates of; 96.60% for the overall accuracy,
98.00% for the recall, 96.50% for the F1 score, 95.29% for the precision. Table 7 shows the
performance of the KNN classifier on high successful features.
Table 7. Performance achievement of the KNN classifier on high successful features.
Distance
Metrics
Overall
accuracy
Recall
F1 Score
Precision

k=1

k= 3

k=5

k=7

k=9

97.00% 96.00% 96.00% 97.00% 97.00%

Achievement
Averages
96.60%

98.00% 98.00% 98.00% 98.00% 98.00%
97.04% 96.17% 96.19% 97.04% 96.09%
96.18% 94.84% 94.54% 96.36% 94.55%

98.00%
96.50%
95.29%

Natural and Engineering Sciences

103

NB classifier for high successful features has achieved overall accuracy rates of; 92.00% for
the overall accuracy, 92.00% for the recall, 92.20% for the F1 score, 92.00% for the precision.
Table 8 shows the performance of the NB classifier on high successful features.
Table 8. Performance achievement of the Naive Bayes classifier on high successful features.
Overall
accuracy
Recall
F1 Score
Precision

92.00%
92.00%
92.20%
92.00%

Discussion
As a result, EEG signals of videos containing the 25 th frame effect were found to differ between
the EEG signals of raw videos. Some of the images in the videos we watch can pass at the speed
that our eyes cannot detect. In this case, the frames we see without awareness may affect our
subconscious. If this event is detected, it is possible to turn the situation in our favor. The 25 th frame
effect in the videos can be determined by looking at the EEG signals of the participants watching
the videos.
For both classifiers, Median, Skewness, Mean, Power, Energy Values features have shown
high success. The values were reclassified with the selection of the best features. As a result, the
success rate for both classifiers increased. There is a deviation in the distribution of EEG data and
that showed why the median feature is successful in EEG data. Skewness is the measurement of
the non-symmetrical probability distribution of the random variable. The fact that the EEG signals
do not have a symmetrical structure increased the success of the Skewness feature. The concept of
variance relates to how far each value of the distribution is from the average of the distribution.
Since EEG data did not have a normal distribution, high success was not obtained from the variance
feature.
KNN and NB classifiers were used in the study. KNN classifier has been found to improve
performance according to NB classifier. The learning example of the KNN classifier was tested
with different numbers. The number of best learning examples was determined as 3 and 7. In the
cross-validation method, it was observed that the performance of the classifier decreased as the
number of folds increased.
Detecting the 25th frame in the videos provides awareness of the circumstances affecting the
subconscious. With this study, it is possible to eliminate the conditions that negatively affect the
subconscious. İf it is considered the videos which are watched effect the subconcious, it is possible
to use this feature in a possitive way.
EEG signals are very sensitive to noise. Therefore, the signals need to be filtered and
processed in the first stage. The future work of the study will be developed by trying different
filtering processes and classification methods.

Natural and Engineering Sciences

104

References
Acharya, U. R., Sree, S. V., Chattopadhyay, S., Yu, W., & Ang, P. C. A. (2011). Application of
recurrence quantification analysis for the automated identification of epileptic EEG signals.
International journal of neural systems, 21(03), 199-211.
Alpaslan, N., Kara, A., Zencı̇ r, B., & Hanbay, D. (2015, May). Classification of breast masses in
mammogram images using KNN. In 2015 23nd Signal Processing and Communications
Applications Conference (SIU) (pp. 1469-1472). IEEE.
Altan, G., Kutlu, Y., & Allahverdi, N. (2016). Deep Belief Networks Based Brain Activity
Classification Using EEG from Slow Cortical Potentials in Stroke. International Journal of
Applied Mathematics, Electronics and Computers, 4(Special Issue-1), 205-210.
Altan, G., Kutlu, Y., & Yeniad, M. (2019). ECG based human identification using Second Order
Difference Plots. Computer methods and programs in biomedicine, 170, 81-93.
Atasoy, H., Kutlu, Y., Yıldırım, E., Yıldırım, S. 2014. Eeg Sinyallerinden Fraktal Boyut Ve
Dalgacık Dönüşümü Kullanılarak Duygu Tanıma. Bursa Bilgisayar ve Biyomedikal
Mühendisliği Sempozyumu.
Bahari, F. ve Janghorbani, A. (2013, Aralık). Eeg tabanlı duygu tanıma nüks komplo analizi ve en
yakın komşu sınıflandırıcıyı kullanarak. 2013 yılında 20. İran Biyomedikal Mühendisliği
Konferansı (ICBME) (s. 228-233). IEEE.
Bhattacharya, J., & Lee, E. J. (2016). Modulation of EEG theta band signal complexity by music
therapy. International Journal of Bifurcation and Chaos, 26(01), 1650001.
Bhattacharyya, S., Khasnobish, A., Konar, A., Tibarewala, D. N., & Nagar, A. K. (2011, April).
Performance analysis of left/right hand movement classification from EEG signal by
intelligent algorithms. In 2011 IEEE Symposium on Computational Intelligence, Cognitive
Algorithms, Mind, and Brain (CCMB) (pp. 1-8). IEEE.
Custdio, P. (2011). Use of EEG as a neuroscientific approach to advertising research (Doctoral
dissertation, Master thesis).
Daşdemir, Y., Yıldırım, E., & Yıldırım, S.(2017). Emotion Analysis using Different Stimuli with
EEG Signals in Emotional Space. Natural and Engineering Sciences, 2(2), 1-10.
Davis, J., Hsieh, Y. H., & Lee, H. C. (2015). Humans perceive flicker artifacts at 500 Hz. Scientific
reports, 5, 7861.
Duarte, R. M. 2017. Low cost brain computer interface system for ar. Drone control in Federal
University of Santa Catarina Department of Automation and System Graduate Program
inEngineering Engineering and Systems.
Duda, R. O., Hart, P. E., & Stork, D. G. (2012). Pattern classification. John Wiley & Sons.
Elden, M. (2009). Reklam ve Reklamcılık. Say Yayınları: İstanbul 503 -505 sayfa
Eraldemir, S. G., Arslan, M. T., & Yıldırım, E. (2017). Turkısh Text Readabılıty Degree
Classıfıcatıon From Eeg Sıgnals. Iı. Internatıonal Academıc Research Congress (579).
Fidan, U. & Özkan, N. (2018). Odaklanma–Meditasyon Sürecinin Aktif EMDR Yazılımı ile
Kontrol Edilmesi. Gazi Üniversitesi Mühendislik-Mimarlık Fakültesi Dergisi, 2018(2018).
Florea, M. (2016). History of the 25th Frame. the Subliminal Message. International Journal of
Communication Research, 6(3), 261.
Grunwald, M., Weiss, T., Mueller, S., & Rall, L. (2014). EEG changes caused by spontaneous
facial self-touch may represent emotion regulating processes and working memory
maintenance. brain research, 1557, 111-126.

Natural and Engineering Sciences

105

İşçimen, B., Kutlu, Y., Reyhaniye, A. N., & Turan, C. (2014, April). Image analysis methods on
fish recognition. In 2014 22nd Signal Processing and Communications Applications
Conference (SIU) (pp. 1411-1414). IEEE.
Karremans, J. C., Stroebe, W., & Claus, J. (2006). Beyond Vicary’s fantasies: The impact of
subliminal priming and brand choice. Journal of Experimental Social Psychology, 42(6),
792-798.
Koelstra, S., Muhl, C., Soleymani, M., Lee, J. S., Yazdani, A., Ebrahimi, T., & Patras, I. (2012).
Deap: A database for emotion analysis; using physiological signals. IEEE Transactions on
Affective Computing, 3(1), 18-31.
Kresse, W., & Danko, D. M. (Eds.). (2012). Springer handbook of geographic information.
Springer Science & Business Media.
Küçükbezirci, Y. 2013. Bilinçaltı Mesaj Gönderme Teknikleri Ve Bilinçaltı Mesajların Topluma
Etkileri. Electronic Turkish Studies, 8(9).
Kutlu, F., & Köse, C. (2014, April). Detection of epileptic seizure from EEG signals by using
recurrence quantification analysis. In 2014 22nd Signal Processing and Communications
Applications Conference (SIU) (pp. 1387-1390). IEEE.
Liu, Y., Sourina, O., & Nguyen, M. K. (2010, October). Real-time EEG-based human emotion
recognition and visualization. In 2010 international conference on cyberworlds (pp. 262269). IEEE.
Murugappan, M., Rizon, M., Nagarajan, R., Yaacob, S., Hazry, D., & Zunaidi, I. (2008). Timefrequency analysis of EEG signals for human emotion detection. In 4th Kuala Lumpur
international conference on biomedical engineering 2008 (pp. 262-265). Springer, Berlin,
Heidelberg.
Özcan, M. O., Taşkın, D., & Baysal, K. (2015). Video Görüntülerindeki Subliminal Çerçevelerin
Tespiti Üzerine Bir Yöntem Önerisi. EJOVOC: Electronic Journal of Vocational
Colleges,5(4), 94-103.
Özerdem, M. S., Polat, H. 2016. “Duygusal Uyarana Olan Aşinalığın Eeg İşaretleri Üzerine Etkisi”
Medical Technologies National Congress (TIPTEKNO) ,1-4.
Piotrowski, Z., & Szypulska, M. (2017). Classification of falling asleep states using HRV
analysis. Biocybernetics and biomedical engineering, 37(2), 290-301.
Sharma, R. K. (2017, May). DWT based epileptic seizure detection from EEG signal using k-NN
classifier. In 2017 International Conference on Trends in Electronics and Informatics
(ICEI) (pp. 762-765). IEEE.
Soleymani, M., Asghari-Esfeden, S., Fu, Y., & Pantic, M. (2016). Analysis of EEG signals and
facial expressions for continuous emotion detection. IEEE Transactions on Affective
Computing, 7(1), 17-28.
Soroush, M. Z., Maghooli, K., Setarehdan, S. K., & Nasrabadi, A. M. (2018). A novel method of
eeg-based emotion recognition using nonlinear features variability and Dempster–Shafer
theory. Biomedical Engineering: Applications, Basis and Communications, 30(04), 1850026.
Tan, L. F., Dienes, Z., Jansari, A., & Goh, S. Y. (2014). Effect of mindfulness meditation on brain–
computer interface performance. Consciousness and cognition, 23, 12-21.
Türk, Ö., & Özerdem, M. S. Epileptik EEG Sinyallerinin Sınıflandırılması için Bir Boyutlu
Medyan Yerel İkili Örüntü Temelli Öznitelik Çıkarımı. Gazi Üniversitesi Fen Bilimleri
Dergisi Part C: Tasarım ve Teknoloji, 5(3), 97-107.
Vimala, V., Ramar, K., & Ettappan, M. (2019). An Intelligent Sleep Apnea Classification System
Based on EEG Signals. Journal of medical systems, 43(2), 36.

Natural and Engineering Sciences

106

Vokey J. R. (2013). Subliminal messages, Chapter 21, Psychological Sketches (11th Edition),
Lethbridge, Alberta: Psyence Ink.
Wang, H., & Zhang, Y. (2016). Detection of motor imagery EEG signals employing Naïve Bayes
based learning process. Measurement, 86, 148-158.
Wang, R. W., Huarng, S. P., & Chuang, S. W. (2018). Right fronto-temporal EEG can differentiate
the affective responses to award-winning advertisements. International journal of neural
systems, 28(03), 1750030.
Wang, T., Guan, S. U., Man, K. L., & Ting, T. O. (2014). EEG eye state identification using
incremental feature learning with time-series classification. Mathematical Problems in
Engineering, 2014.
Williams, R.L., Karacan, I., Hursch, C.J. 1974. Electroencephalography (EEG) of Human Sleep.
Clinical Applications. John Willey & Sons Inc. New York.
Yağanoğlu, M., Bozkurt, F., & Günay, F. B. (2014). EEG tabanli beyin-bilgisayar arayüzü
sistemlerinde öznitelik çikarma yöntemleri. Mühendislik Bilimleri ve Tasarım Dergisi, 2(3),
313-318.
Yıldız, T., Yıldırım, S., Altılar, T., 2008. İstenmeyen İletilerin Paralelleştirilmiş KNN Algoritması
ile Tespiti. Akademik Bilişim, 2008, Çanakkale.
Yücel, A. & Coşkun, P. (2018). Nöropazarlama Literatür İncelemesi. Fırat Üniversitesi Sosyal
Bilimler Dergisi, 28(2), 157-177.

