GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

1

Technological Advancements in Affective
Gaming: A Historical Survey
Thomas Christy & Ludmila I. Kuncheva
School of Computer Science
Bangor University, LL57 1UT
thomas@thomaschristy.co.uk & l.i.kuncheva@bangor.ac.uk

Abstract—Affective gaming (AG) is a cross-disciplinary area
drawing upon psychology, physiology, electronic engineering
and computer science, among others. This paper presents
a historical overview of affective gaming, bringing together
psychophysiological system developments, a time-line of video
game graphical advancements and industry trends, thereby
offering an entry point into affective gaming research. It
is proposed that video games may soon reach a peak in
perceivable graphical improvements. This opens up the door
for innovative game enhancement strategies, such as emotiondriven interactions between the player and the gaming environment.
Index Terms—Affective gaming, emotion, psychophysiology,
physiology, input devices, computer graphics.

I. I NTRODUCTION
Video games have become the leading global entertainment industry, overtaking the movie industry on sales and
revenue statistics [21]. Provoking profound emotions is
deemed to be of vital importance in video game design [63].
Emotion is a crucial component of human interactions,
problem solving [62] and entertainment [67]. The role of
emotion in human interactions was discovered nearly two
millennia ago and has been documented scientifically for
well over a century [16], [36]. Affective Gaming (AG) is a
relatively new field of research that exploits human emotion
for the enhancement of player’s experience during video
game play.
Conventionally, the video game attempts to elicit emotion
by its story lines, characters and video effects. However,
there is no precise means to assess if the expected emotion
is being experienced. It is even more important to be able
to detect a change in the player’s emotional state as a result
of the game play. There is no provision for assessing such
changes within the mainstream gaming practices. AG seeks
to remedy this through the use of bespoke psychophysiological input sensors that read and interpret the changes in
the player’s emotion in real time.
Technically, an AG system acquires emotion-related signals from a set of sensory input modalities, analyses the
signals, and provides data to the game engine [35]. The
game is subsequently altered taking into account the type
and strength of the measured emotion. Figure 1 shows a
diagram of a real-time AG loop.
An AG system is expected to stream real-time affect data,
be robust, and most importantly be easy to use. The main
DOI: 10.5176/2251-3043_3.4.287

Fig. 1.

The real-time affective gaming (AG) loop.

criticism to experimental research in affective computing
thus far has been that it is done in a heavily controlled environment, which limits its chances for practical applications.
Affective gaming has to move away from the confides of a
laboratory and be deployed in a normal environment [13],
[22], [68].
A particular challenge when trying to design a single all
encompassing taxonomy of the field comes from the fact
that it is comprised of several broad disciplines: physiology,
psychology, electronic engineering and computer science.
It should also be mentioned that results of research into AG
conducted in commercial settings are rarely published.
In this study, we survey the historical technological developments and research efforts that are attempting to bring
practical AG to reality, including academic and commercial
contributions to the field as a whole. The rest of the paper
is organised as follows. Section II summarises the difficulties in measuring and classifying emotion. We argue that
affective gaming does not rely exclusively on the accuracy
of emotion recognition. Any change of the emotional state
of the player that is detected and reflected in the game can
contribute to the pleasurable experience. Behavioural and
physiological modalities for affective data acquisition are
presented in Section III. We put the emphasis on the wealth
of physiological modalities as the preferred input for AG.
Section IV reviews studies that use physiological modalities
in AG. Section V contains a historical perspective of the
development of two of AG-related technologies: console
platforms and video graphics. Finally, Section VI concludes
the paper by listing the tasks and challenges set before
modern AG.
32

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

2

II. E MOTION AND AFFECTIVE GAMING
Can we recognise and classify emotion? Emotion is
notoriously difficult to quantify, measure or put into clearcut categories [53]. The prevailing evidence from psychology and psychophysiology is that emotions do not
naturally form distinct clusters in data spaces extracted from
representational cues, but are rather facets of a continuum.
The relationship between the physiological measurements
and the emotional states they are supposed to identify is
complex and ambivalent [22]. The list of difficulties faced
by researchers in automatic emotion classification has been
widely discussed in the literature [10], [22], [41]. It includes
but is not limited to
• We don’t know what to measure.
• Emotions experienced by the subject may not correspond well to the stimuli.
• Different subjects may react with different emotions
to the same stimulus.
• The presentation of emotion will differ between subjects and also at different time moments for the same
subject.
• Emotion is not clear-cut and measurable, therefore
there cannot be “ground truth” data.
• There is no agreed protocol for stimulating and measuring emotion.
• There is no agreed protocol for testing emotion classification systems.
• The classes of emotions are intricately related to one
another.
A vast diversity of results have been reported as the outcome of emotion recognition experiments [11], [47], [65].
Owing to the difficulties listed above, classification accuracy in identifying categorical emotions was found to vary
considerably, spanning a range between 51% and 92% [61].
Along with the excitement, the literature contains cautious
or even sceptical views [55]. It may be that endeavours to
label emotion accurately across different subjects might be
an impossible quest using today’s technologies [13], [66],
[79]. Employing interdisciplinary research effort has been
strongly advocated [41], [68].
Video games are designed to entertain, and thus allow
a margin of error in recognising a specific emotion. The
ultimate aim of an affective game is to make the player
aware that the game recognises and interacts with their
emotional state throughout the course of the game. Occasional misclassifications will not have a crucial impact to
the player’s enjoyment or satisfaction.
III. A FFECT ACQUISITION MODALITIES
A variety of input modalities are used to gather affective
cues from the player. Figure 2 shows a diagram of the major
types of modalities in affective computing.

development [24]. When engaged in a dialogue with a
real person, it is normal to express facial emotions and
emotive body gestures, or body language, as a response
to the message being communicated. There are at least
100 documented facial expressions to concisely describe
the emotion or mood of a person [60]. One need only
consider research based on Autism and Asperger Syndrome
to recognise the need for visual emotion interaction in
social and professional environments. However, when faced
with a video game display, such outward expressions of
emotion are not expected from the active player. Spontaneous emotions may be displayed but the player will not
be compelled to react in the same way as in human to
human interaction. Emotion detection using cameras has
been criticised for being inefficient in that it requires a
lot of processing power to sift through video streams [23].
In addition behavioural affect detection presents cultural,
gender, and age differences, making behavioural analysis
difficult [73].
Voice modulation is perceived as one of the important behavioural modalities for detecting emotion in video
games. However, it has been observed that some players
feel uncomfortable talking to a video game [38].
B. Physiological modalities
The two types of physiological modalities in Fig. 2 come
from the central nervous system and peripheral nervous
system, respectively.
1) Central nervous system signals: It is unlikely that AG
will benefit from functional Magnetic Resonance Imaging
(fMRI) or functional Near Infra-red Spectroscopy (fNIRS)
in the near future. Electroencephalography (EEG), however, is an important technology in modern neuroscience.
Compared to fMRI, EEG has a worse spatial resolution
but a much better temporal resolution [27]. The electrical
potentials related to emotion can be projected widely in
an intricate pattern across the scalp, and can therefore
overlap with potentials evoked by other activities. EEG
has been applied for classification of emotions in various
contexts [8], [43], [82], [88] and is progressively becoming
a portable lightweight technology. Several commercially
available EEG sets can be considered for affective gaming: OCZ Nia1 , Neurosky Mindset2 , Neurosky Mindwave3 ,
Emotiv EPOC4 . It is often assumed that the projections of
positive and negative emotions in the left and right frontal
lobes of the brain make these two emotions distinguishable
by EEG. Practice has shown that the granularity of the
information collected from these regions through EEG may
be insufficient for detecting more complex emotions [8].
2) Peripheral nervous system signals: Psychophysiology
(PPG) is the combination of innate human physiological
responses in relation to emotional changes. The correlation
between emotion and physiology is well founded [67], [93],

A. Behavioural modalities

1 http://www.ocztechnology.com/nia-game-controller.html

Behavioural affect detection is an extremely instinctive
approach and is often used in video game research and

3 http://neurosky.com/Products/MindWave.aspx

2 http://store.neurosky.com/products/mindset
4 http://emotiv.com

33

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

3

Input Modalities for Affective Computing
Physiological

Behavioural
Facial Expression 11
Eye Tracking/Blink Rate 12

1 Electroencephalography (EEG)
2 functional MRI (fMRI)
3 functional Near-infra-red Spectroscopy (fNIRS)

Gesture 13
Posture 14

Voice Modulation 15

Central Nervous System
Peripheral Nervous System

4
5
6
7
8
9
10

Fig. 2.

Naturally Observed
Computer Interaction

Electrooculography (EOG)
Electromyography (EMG)
Electrodermal Activity (EDA)
Blood Volume
Blood Oxygenation
Respiration
Skin Temperature

HCI Patterns 16
Dialogue with Agent/Tutor 17
Pressure on Mouse 18

Main input modalities in affective computing.

[96], [98], and has been thoroughly explored throughout
psychological studies [85]. Some of the most commonly
used physiological inputs are listed below.
•

•

•

Electrodermal Activity (EDA) Fig. 2 (#6), also referred to as Galvanic Skin Response (GSR), Skin
Conductance Response (SCR) or Psycho Galvanic
Reflex (PGR), measures the variance in electrical
conductivity through the surface of the skin. EDA
readings are effected through the sympathetic nervous
system, making it a good indicator of stress and
anxiety. EDA suffers from latency, with a delay of
approximately one second for a response to be evoked,
followed by approximately three seconds for the effect
to dissipate. It is among the most basic and low cost
physiological modalities available, and is widely used
in physiological emotion recognition, including video
games [1], [17]. EDA is commonly read between two
fingers on either hand, although is not limited to this
area of the body [7]. EDA bodes well for adaptation
into video-game controllers.
Blood volume (Plethysmograph) Fig. 2 (#7-8) is the
variation in heart rate, and is a good indicator of stress
and anxiety. As a sign of its pervasive popularity,
heart rate input became the pivotal component of a
television game-show, called The Chair [83], [97]. In
this show, contestants answered general knowledge
questions and were expected to maintain a calm heart
rate to win money. The sensing devices suitable for
affective gaming come in the form of a clip, which
uses optical technology to measure simultaneously
heart rate and blood oxygenation [81].

•

•

Respiration Fig. 2 (#9) Emotion can influence breathing rates [6], [34]. The measuring device could be
a respiration belt or sensors embedded into clothing.
For example, a force feedback vest with embedded
breathing rate sensors already features in the avid progamers’ arsenal5 . However, mainstream applications
could be hindered by utilising garments to acquire
data.
Temperature Fig. 2 (#10) Body temperature is affected
by emotion, specifically joy, anger and sadness [57],
[58], and has been used for emotion recognition in
video games [7], [90]. Temperature sensors fall into
two general types: contact and non-contact. Both
types are sensitive to movement, which can introduce
inaccuracies in the data collected. Movement is an
important issue in the process of an active game play;
hence, the positions of the sensors have to be chosen
carefully.
Electromyography (EMG) Fig.2 (#5) measures the
electrical activity produced by muscle movement. Activity patterns in muscles such as orbicularis oculi
(eye) and zygomaticus major (smile) are often used
for affect detection. However across the populous
(including nationalities), people differ widely in terms
of how they visually display emotion [66], [79]. Besides, EMG sensors may need to be placed at various
body locations, which may compromise the player’s
comfort.

5 http://en.wikipedia.org/wiki/3rd

34

Space Vest

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

4

3) Sensors and devices: Table I shows the early patents,
designed to detect PPG signals. These systems formed the
bedrock of modern PPG technologies.
Sensors and devices for AG can be roughly grouped into
thee types.
• Standard sensors. Hardware used in AG research
has been borrowed from psychological research or
commercial relaxation systems, such as the BioPac6 ,
IOM7 , etc. Commercial hardware for physiological
acquisition is considered expensive and awkward to
use [42]. For example, standard sensors give better
results when they are held still. However, the devices
can regraded as a nuisance, being attached to the
player’s fingers, ear, etc. This makes them unsuitable
for active video game play.
• Wearable sensors. Wearable sensors implies “body
worn”, making long term physical contact with the
body [66]. In 1997, Picard and Healey [66] introduced
an affective wearable system that stored physiological
data from Respiration, EDA, Blood Volume Pulse
(BVP) and Electromyography (EMG), for later analysis. Picard’s work would later become a beacon for
affective computing research [7], [32], [45]. Sensors
can be embedded into clothing, glasses, gloves, shoes,
hats, helmets, jewellery, etc., making this an attractive
avenue for AG.
• Seamless contact sensors and devices. The sensors
in this group come into contact with the body for a
limited time, for example through traditional interfaces
such as mouse and keyboard. To be considered seamless, the user should not be aware of any interaction
with the sensor. For example, EDA could be measured
from electrodes embedded into the hand-grip of a console controller or on a mouse. A comprehensive study
on devices of this type is provided by Reynolds [76],
examples of which are
– Sentograph – measures and visualises user’s touch
along a two-dimensional space
– Touch Phone, touch mouse – measures grip
strength
– Sentic Mouse – senses directional input
– Sqeekee – click pressure
– IBM Emotion Mouse – gathers temperature, EDA
and somatic movement
Even though the core technology for physiological signal
capture is mature and well proven, hardware for affective
gaming is still not widely available.
Affective video game input must be comfortable and
intuitive to use. If a sensor impedes the enjoyment and competitive edge that video game players expect, it is less likely
to be adopted. AG would benefit best from seamless contact
sensors. It needs to move from expensive laboratory equipment to reliable and affordable consumer devices [13], [22],
[68]. Affective sensors can be incorporated into already

adopted video game controllers [2], [7], [13], [50]. Valve8
and Sony 9 have both implied that EDA and HR could
soon be incorporated into standard controllers. Producing
bespoke low cost hardware for AG is feasible [7], [13],
for example, by using recently released rapid prototyping
platforms10 and 3D printing. It is proposed that this type of
rapid prototyping is expected to shape the newly forming
landscape of AG.
IV. U SING PHYSIOLOGICAL MODALITIES IN AG
By 2001, academic research into AG took off [5], [69],
[76]. Table II lists the research contributions made within
the field of AG, including the physiological sensors and
video games used. Many sensors and sensor permutations
have been tested, along with several game genres.
Tables III and IV detail game variations in response
to changes in physiological data, published by Dekker &
Champion [17].
TABLE III
D EKKER & C HAMPION VISUAL EFFECTS AND PHYSIOLOGICAL
THRESHOLD CONDITIONS ; USED IN THE MODIFIED VIDEO GAME
Half Life 2.
Emotion

Game Change

Criteria*

Comatose

Sound (heart beat),
new enemy or boss

HR + EDA < 0.8
or < 0.4 below avg

Bored

Black & White

HR < 0.8− avg

Calm

Shader (White filter)

HR > ×2+ avg

Worried

Shader (Red filter)

HR > avg ×2

Panic

Shader (Bright red filter)
+ FOV = 130

HR > ×3 above avg

Berserk

Shader (Red screen)

HR > ×3.5 above avg

*Abbreviated terms: Heart Rate (HR), Electrodermal Activity (EDA). Shaders refer
to graphical overlay alterations

TABLE IV
D EKKER & C HAMPION CONDITIONS APPLIED TO
PSYCHOPHYSIOLOGICAL THRESHOLD CRITERIA IN THE VIDEO GAME

Half Life 2.
Condition

Criteria*

Stealth

EDA 0.5 ≫ 0.7

Invisible

HR < 0.5 and EDA < 0.5

Weapon damage

HR & EDA ×40

Speed

HR

Sound volume

EDA2 × 0.8

Bullet time (Slow motion)

EDA > cal ×3

Shake

HR > 3.8 above avg

*Abbreviated terms: Heart Rate (HR), Electrodermal Activity (EDA).

In this example, visual and audible effects are introduced
to the game when particular electrodermal activity (EDA)

6 http://www.biopac.com/psychophysiology

8 http://www.valvesoftware.com/

7 http://www.wilddivine.com/iom-feedback-hardware/iom-active-

9 http://www.sonyentertainmentnetwork.com/
10 https://www.ghielectronics.com/,

feedback-hardware/

35

http://www.netmf.com/

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

5

TABLE I
E ARLY DAY DEVICES PRE - DATING AFFECTIVE GAMING TECHNOLOGIES .
[h] Year
1928
1928
1943
1944
1953
1953
1954
1955
1956
1958
1964
1965
1967
1969
1972

Author
Schrawzkopf & Wodtke [80]
Hathaway [30]
Raesler et al. [72]
Milne et al. [56]
Koller [44]
Holzer & Marko [33]
Mathison [51]
Golseth & LeGrand [29]
Mathison [52]
Douglas [18]
Ryan [77]
Takagi [87]
Weidinger et al. [95]
Tygart [91]
Burlyl R. Payne [64]

Acquired a patent for:
An electrocardiograph.
A circuit design of an EDA device Apparatus for measuring psychogalvanic responses.
Psychogalvanometer; a fluid-aided EDA device.
Psychometer; an easy to use device.
Cardio-Pneumo-Electrodermograph; an advance upon earlier machines.
Arrangement for recording variations in the electrical resistance in the human body.
Electropsychometer or Bioelectronic instrument (v1); a sponge-aided EDA device.
Electronic Diagnostic Instruments; a portable EDA device.
Second instalment of the Electropsychometer or Bioelectronic instrument (v2); a low cost EDA device.
Psychogalvanometer; EDA plus phonographic recorder.
An improved Novelty (Toy) lie detector.
An EDA device.
A portable heart monitoring device.
System for FM transmission of cardiological data over telephone lines.
Audible Psychogalvonometer (AP); smaller and low-cost EDA device.

and heart rate (HR) signal threshold combinations are met.
Tijs et al. [89] use 7 physiological parameters to guide the
speed of Pacman (Table V).

8
7

Tijs et al. [89]: EFFECTS OF GAME SPEED OF Pacman,

Number of AG papers

TABLE V
BASED ON

PSYCHOPHYSIOLOGICAL DATA INPUT

Physiological features*

condition identified (action)

Mean SCL

slow (speed up)

Number of SCR

slow (speed up)

Mean HR

slow (speed up)

Mean respitory

slow (speed up)

CORR

fast (slow down)

ZYG

fast (slow down)

Key pressure

slow (speed up) & fast (slow down)
& normal (nothing)

*Abbreviated terms: Heart Rate (HR), Skin Conductance Level (SCL),
Skin Conductance Response (SCR), corrugator supercilii muscle,
(CORR), zygomaticus major muscle (ZYG).

To illustrate the developmental potential of the physiological input modalities, we collated the accessible publications explicitly devoted to affective gaming, and noted
which ones address the engineering of bespoke psychophysiological hardware. Figure 3 gives a bar chart of the
distribution of the publications over the years. The papers
whose main focus are psychophysiological sensors and
devices are marked in a lighter colour.
Even though the publication numbers are not high, an
emerging trend could be identified. Affective input devices
are beginning to make their way to the centre stage of
affective gaming.
Judging by the achievements and the potential of using
physiological modalities in AG, the future is likely to
see smarter and more sophisticated implementations on
progressively smaller, more robust, reliable and noise-free
devices.
V. T ECHNOLOGIES FOR AG
A. Generations of console platforms
Historically, the introduction of the electronic computer
heralded the beginning of a new era [14]. No sooner

6
5
4
3
2
1
0
2002

2004

2006

2008

2010

2012

Fig. 3.
Time-line view of AG research publications. Publications
addressing bespoke psychophysiological hardware are shown in a lighter
colour.

had the computer become affordable to the masses; video
games became an arising staple of popular entertainment
[70]. Interactivity plays a pivotal role of video games.
Typically, video games allow the player to interact with the
virtual environment using joysticks, joy-pads, keyboards,
mice, trackballs, cameras, touch-screens, etc. Video game
consoles became a dominant symbol of the mainstream
video game market. Several attempts have been made
to introduce AG to commercial environments [3], [15],
[25], [26], [94]. The companies involved manufactured
the necessary hardware and software to foster the use of
affect in video games. However, none of the systems were
successful in the long term. Below we take a closer look
at the developmental context and the possible reasons for
the delayed progress.
Figure 4 shows a time-line representing the introduction
and commercial duration of 8 video console generations.
The thick black lines show the time span of each generation
and the vertical dashed indicate the year of key commercial
contributions.
The first video game console, called the Magnavox
36

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

6

TABLE II
A FFECTIVE GAMING MODALITIES AND THE CURRENT CONTRIBUTORS , LISTED IN ORDER OF YEAR . M ODALITIES INDICATE WHICH COMBINATION
OF PSYCHOPHYSIOLOGICAL OR BEHAVIOURAL AFFECT DETECTION SENSORS CONSIDERED AND G AME DETAILS WHICH GAMES AND
GAME - GENRES USED .
Modalities & year published*

Game

EDA [5], 2001.

Racing Dragon

HR, EDA, EMG, video [79], 2002.

Puzzle

HR [28], 2003.

Action based

Game pad pressure [86], 2003.

Space Invaders

EMG [31], 2006.

Juiced (THQ)

EDA,EMG [4], 2005.

Cards (Skip Bo)

ECG, ICG, HR, HS, EDA, EMG
temperature, questionnaire [73], 2005.

Pong

User control knobs [78], 2005.

Generic

HR, EDA [54], 2006.

Treasure Hunt (Source)

HR, EDA, facial EMG [74], 2006.

Monkey Ball 2

EDA, HR [17], 2007.

Half Life 2

EDA, ECG, HR [49], 2007.

NHL 2003

HR, EOG, EDA, EEG,
respiration, temperature [12], 2008.

Tetris

Time, eye movement [37], 2008.

Half Life

Audio (vocal cues) [39], 2008.

Half Life Mod

EEG [71], 2008.

Break-Out (Arkanoid)

HR, EDA, facial EMG [75], 2008.

Monkey Ball 2 & James Bond 007

HR, EDA, respiration [89], 2008.

Pacman

EDA, HR [19], 2009.

Prey, Doom3 & Bioshock

EDA, HR, EMG, temperature [48], 2009.

Pong & anagrams

EDA, EMG [59], 2009.

Half Life 2 Mod

Control tilt, pressure [92], 2009.

Need 4 Speed

EDA, respiration [46], 2010.

Emoshooter (FPS)

EDA [90], 2010.

Racing

(Use) EDA, (tried) HR, eye movement, EEG,
pupil dilation, EOG, posture, gesture, voice,
face expression, respiration [2], 2011.

Left 4 Dead 2, Portal 2 & Alien Swarm

EDA, HR, pressure [7], 2011.
temperature, gyroscope

Racing Car

EDA, HR, temperature [13], 2013.

Custom game

*Abbreviated terms: Heart Rate (HR), Heart Sound (HS), Electrodermal Activity (EDA), Electrooculography (EOG),
Electroencephalography (EEG), Electromyography (EMG), First Person Shooter (FPS), Impedance Cardiogram (ICG).

Odyssey, was released in 1971, as shown in Fig. 4. In
1982 Atari planned to release an input device called
the Mindlink, but the company collapsed prior to its release [94]. The Atari Mindlink was a head-mounted device
that used Electromyography (EMG) to detect electrical
changes in the player’s forehead. The Mindlink was to
be used as an input device in lieu of a standard joystick
controller. The device was abandoned when Atari was
redistributed in 1983 [94].
In 1984 CalmPrix was introduced with a psychophysiological system called CalmPute. CalmPrix was a car racing
video game that used EDA signals to alter the speed of
the racing car. It used a commercial EDA sensor called the
Mantra Mouse or GSR2 [25] as an input device. The CalmPrix video game was meant to teach a relaxation technique,

using an extremely primitive racing car game (even for the
time). CalmPrix would have been pitted against games such
as the highly successful Mario Brothers (1983)11 , Return of
the Jedi and Elite (1984)12 . Commercially, it didn’t stand
a chance.
Tokimeki memorial oshiete your heart was a provocative,
alluring arcade game that was released in 1997. Unfortunately, the game was available only in Japan which limited
its global success. Tokimeki memorial oshiete my heart was
a curious cartoon dating game, far flung from the popular
games of the day, such as Herc’s Adventure, Backyard
Baseball and Claw13 . It encouraged players to express
11 www.IMDb.com

- Highest Rated Video Games Released In 1983
- Highest Rated Video Games Released In 1984
13 www.IMDb.com - Highest Rated Video Games Released In 1997
12 www.IMDb.com

37

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

7

9
8

Generations

7
6
1998, Tetris 64 (Nintendo)

5
4
3
1982, Mindlink (Atari)

2
1971, Magnavox Odyssey

1

1984, CalmPrix (CalmPute)
0
1970

1975

1980

1985

1990

1997, Tokimeki memorial (Konami)
1995

2000

2005

2010

2015

Fig. 4. Video game console time-line representing the introduction and commercial duration of each console generation, shown in thick black
segments. Key commercial contributions are indicated with vertical dashed lines pinpointing the year of release. Given in brackets are the names of
the relevant companies. CalmPrix and Tokmeki Memorial are plotted at the bottom of the figure because they were not console based.

affect towards cartoon characters (Manga art), which was
measured by EDA and Heart Rate (HR).
Tetris 64 was released on the Nintento 64 in 1998. It used
HR taken from a clip attached to the player’s ear to control
the speed of the falling shapes. The game allowed up to four
players to compete on the same screen, making it possible
to alter the outcome of the competition using emotional
feedback. Unfortunately, the game concept was rather old.
Although Tetris remains a popular relic, it was competing
against games such as Half Life, Crash Bandicoot, Sonic
Adventures, etc.14 . In addition, it was reported that Nintendo
was experiencing issues with its latest console. Among
these were expensive cartridges, poor graphical rendering
and a complex programming interface [20].
Other physiological devices have since been considered,
such as the Wii Vitality. However, this device was not
released due to speculation that it would not prove commercially successful [40].

dering technology arena, through competitive video card
releases. An advanced programming interface (API) called
OpenGL15 (Open Graphics Library) was introduced in
1992. It offered a single graphical programming interface
across all popular technologies and platforms, thereby
speeding up game development. Notably, nVidia released
the Graphical Processing Unit (GPU) in 1999. Mega
(10002 ) Texels (MT) are defined as the number of texture
elements graphic hardware processors can manipulate per
iteration. Figure 5 demonstrates the exponential growth of
MT graphics hardware performance since 1997. In 1997,
the maximum MT expected from a 3D rendering graphic
processor was log10 (100), which grew exponentially to
log10 (1875000) by mid-201316 .
6.5
6
5.5

Immersion is important for emotional experiences within
video game environments [9], [37]. The illusion of immersion and interaction with surroundings, materials and
substances in modern video games cannot be achieved
without the giant steps in video graphic hardware and
software. Graphic technology and video games evolved
synchronously, from primitive monocohrome pixelatedblocks being controlled on a cathode ray tube (CRT) to
advanced visually realistic, fully immersive, simulated environments, presented on ultra high definition (4K) organic
light emitting diode (OLED) liquid crystal displays (LCD).
Detailing advanced graphical techniques, such as particle
systems, billboards, shadow-maps, etc., is beyond the scope
of this paper. Here we are interested in the exponential
technological growth in video graphics performance and
its relationship with AG.
Companies such as Intel, Array Technologies Industry
(ATI) and nVidia made vast efforts in the graphic ren-

Megatexels log10

B. Graphical advancements

5
4.5
4
3.5
3
2.5

nVidia released GPU

2
1996 1998 2000 2002 2004 2006 2008 2010 2012

Fig. 5. Graphic card technology advancement since 1997 beginning in
1997 at 100 mega-texels (MT) and growing exponentially to 1,875,000 MT
by mid-2013. The vertical axis is log10 (y), where y represents maximum
MT per year.

It is suggested that graphical advancements could soon
reach a plateau. High-end video game systems are now
15 http://www.opengl.org/about/

14 www.IMDb.com

16 http://www.techspot.com/article/650-history-of-the-gpu/

- Highest Rated Video Games Released In 1998

38

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

8

capable of animating real-time graphic renderings that are
becoming visually close to that of real life video footage.
In addition, video graphic displays have pixels that are so
minute, they cannot be discriminated individually by the
human eye, with pixel density greater than 300 pixels per
inch. As the visual component of video games reaches a
peak, more emphasis on player’s interaction and immersion is expected. Games are now appealing to a more
sophisticated audience, with the average age of the frequent
game purchaser being 35 [21]. This calls for exploring new
avenues in simulated intelligence and affect manipulation.
Commercial video game publishers are rumoured to be
considering psychophysiological hardware, as part of their
next generation of video game consoles [84]. This may
herald the birth of real commercial investment into AG.
VI. C ONCLUSION
The general consensus is that using the player’s affective
state to manipulate the video game adds to the enjoyment
and immersion experienced. AG will form an important
role in the future of human computer interaction. The tasks
remaining for modern AG can be summarised as follows
1) Bring together expertise from the various fields that
AG draws upon: psychology, physiology, computer
science and engineering.
2) Create unobtrusive, robust and accurate devices for
inputting physiological signals such as electrodermal
activity (EDA) and heart rate (HR) among many.
3) Develop state-of-the-art pattern recognition and machine learning methodologies for reliable emotion
recognition as well as algorithms for detecting
changes in the player’s emotional state.
4) Move AG out of laboratories and into the developer’s
hands. A step in this direction would be the creation of an open affect application protocol interface
(OAAPI) for affect acquisition. When no affect acquisition hardware device is present the interface would
emulate the required emotive techniques necessary
using software. This would enable the developer to
code the game for affective video games with or
without hardware specific knowledge.
We speculated that video graphic advancements are heading towards a plateau, which will likely shift the focus
towards intelligent interactivity and affective gaming. Such
a shift is expected to open up commercial perspectives for
AG.
Taking a look into the not so distant future. Equipped
with inventive affective input devices, using fast and powerful pattern recognition algorithms and realistic graphical
rendering technology, the game developer is facing the most
exciting challenge of all: creating the affective gaming loop
to maximise the gamer’s entertainment pleasure.
R EFERENCES
[1] M. Ambinder. Valve’s approach to playtesting: The application of
empiricism. Valve Software, 2009.
[2] M. Ambinder. Biofeedback in gameplay: How valve measures
physiology to enhance gaming experience. Valve Software, 2011.

[3] Amtex. Tetris 64. Seta Corporation, November 1998.
[4] C. Becker, A. Nakasone, H. Prendinger, M. Ishizuka, and
I. Wachsmuth. Physiologically interactive gaming with the 3D agent
Max. In International Workshop on Conversational Informatics at
JSAI, volume 5. Citeseer, 2005.
[5] D. Bersak, G McDarby, N. Augenblick, P. McDarby, D. McDonnell,
B. McDonald, and R. Karkun. Intelligent biofeedback using an immersive competitive environment. Designing Ubiquitous Computing
Games Workshop, 2001.
[6] F.A. Boiten. The effects of emotional behaviour on components of
the respiratory cycle. Biological Psychology, 49(1-2):29–51, 1998.
[7] A. Bonarini, F. Costa, M. Garbarino, M. Matteucci, M. Romero, and
S. Tognetti. Affective videogames: The problem of wearability and
comfort. SpringerLink: Human-Computer Interaction. Users and
Applications, 6764:649–658, 2011.
[8] D. O. Bos.
EEG-based emotion recognition.
[Online]
url: http://emi.uwi.utwente.nl/verslagen/capita-selecta/CS-oude BosDanny, 2006.
[9] E Brown and P Cairns. A grounded investigation of immersion in
games. Extended abstracts of the 2004 conference on Human factors
and computing systems CHI 04, computings:1297, 2004.
[10] R.A. Calvo and S. DMello. Affect detection: An interdisciplinary review of models, methods, and their applications. IEEE Transactions
on Affecitve Computing, 1(1):18–37, 2010.
[11] G. Chanel, J. Kronegg, D. Grandjean, and T. Pun. Emotion assessment: Arousal evaluation using EEGs and peripheral physiological
signals. Multimedia Content Representation, Classification and
Security, pages 530–537, 2006.
[12] G. Chanel, C. Rebetez, M. Bétrancourt, and T. Pun. Boredom,
engagement and anxiety as indicators for adaptation to difficulty
in games. In Proceedings of the 12th international conference on
Entertainment and media in the ubiquitous era, pages 13–17. ACM,
2008.
[13] T. Chisty and L.I. Kuncheva. A.M.B.E.R. Shark-Fin: An Unobtrusive
Affective Mouse. In ACHI 2013: The Sixth International Conference
on Advances in Computer-Human Interactions, pages 488–495,
2013.
[14] Jack Copeland. Colossus: The First Electronic Computer (Popular
Science). Oxford University Press, USA, 1 edition, May 2006.
[15] Konami Corporation. Tokimeki memorial oshiete your heart. Arcade,
1997.
[16] C. Darwin. The Expression of the Emotions in Man and Animals.
John Murray, 1872.
[17] A. Dekker and E. Champion. Please biofeed the zombies: enhancing
the gameplay and display of a horror game using biofeedback. Proc.
of DiGRA, pages 550–558, 2007.
[18] D.W. Douglas. Psychogalvanometer, April 1958.
[19] A. Drachen and A. L. Pedersen. Correlation between heart rate,
electrodermal activity and player experience in first-person shooter
games. Heart, pages 49–54, 2009.
[20] The Economist. Nintendo wakes up, 1996. Last accesed 23
September 2013.
[21] (ESA). Essential facts about the computer and video game industry.
ESA E3 2013, 2013. Last accessed 11 September 2013.
[22] S.H. Fairclough. Fundamentals of physiological computing. Interacting with Computers, 21(1-2):133–145, 2008.
[23] C. Fisher and P. Sanderson. Exploratory sequential data analysis:
exploring continuous observational data. Interactions, pages 25–34,
1996.
[24] B. Fulton. Beyond Psychological Theory: Getting Data that Improves
Games. In Gamasutra, 2002.
[25] A. Gaggioli. Mantra mouse. gaggio.blogspirit.com/archive/2006/03/
27/mantra-mouse.html, March 2006. last accesed 9 April 2013.
[26] N. Genes. We‘re Not Lying About Galvanic Skin Response. www.
medgadget.com/2006/03/were\ not\ lying.html, March 2006. Last
accessed 9 April 2013.
[27] M. Gerven, J. Farquhar, R. Schaefer, R. Vlek, J. Geuze, A. Nijholt,
N. Ramsey, P. Haselager, L. Vuurpijl, S. Gielen, and P. Desain.
The brain–computer interface cycle. Journal of Neural Engineering,
6:041001, 2009.
[28] K.M. Gilleade and J. Allanson. A Toolkit for Exploring Affective Interface Adaptation in Videogames Developing an Affective
Videogame. Proceedings of HCI International, 2:370—-374, 2003.
[29] J. Golseth and C.C. LeGrand. Electronic diagnostic instruments, July
1955.
[30] Starke R. Hathaway. Apparatus for measuring psychogalvanic
responses, Jan 1930.

39

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

9

[31] R.L. Hazlett. Measuring emotional valence during interactive experiences boys at video game play. In SIGCHI conference on Human
Factors, pages 1023–1026, 2006.
[32] J.A. Healey. Wearable and Automotive Systems for Affect Recognition from Phychiology, 2000.
[33] W. Holzer and A. Marko. Arrangement for recording variations in
the electrical resistance if the human body, January 1953.
[34] Y. Homma, I. Masaoka. Breathing rhythms and emotions. Experimental physiology, 93:1011–1021, 2008.
[35] E. Hudlicka. Affective game engines: motivation and requirements.
In Proceedings of the 4th International Conference on Foundations
of Digital Games, pages 299–306. ACM, 2009.
[36] W. James. Mind association what is an emotion ? Oxford University
Presson behalf of the Mind Association, 9:188–205, 1884.
[37] C. Jennett, A.L. Cox, P. Cairns, S. Dhoparee, A. Epps, and A. Tijs,
T. Waltson. Measuring and defining the experience of immersion in
games. International Journal of Human-Computer Studies, 66:641–
661, 2008.
[38] C. Jones and A. Deeming. Affective human-robotic interaction.
Affect and Emotion in Human-Computer Interaction, pages 175–185,
2008.
[39] C. Jones and J. Sutherland. Acoustic emotion recognition for
affective computer gaming. Affect and emotion in human-computer
interaction: from theory to applications, 4868:209, 2008.
[40] Z Kaplan. Wii vitality sensor never released because it was
’insufficient as a commercial product’. Nintendo World Report, July
2013. Last accessed 11 July 2013.
[41] A. Kappas. Smile when you read this, whether you like it or
not: conceptual challenges to affect detection. Affective Computing,
IEEE, 1(1):38–41, 2010.
[42] J.M. Kivikangas, I. Ekman, and G. Chanel. Review on psychophysiological methods in game research. Proc. of 1st Nordic DiGRA,
2010.
[43] K-E. Ko, H-C. Yang, and K-B. Sim. Emotion recognition using
EEG signals with relative power values and Bayesian network.
International Journal of Control, Automation and Systems, 7(5):865–
870, October 2009.
[44] R. Koller. Cardio-pneumo-electrodermograph, March 1953.
[45] E.I. Konstantinidis, C.A. Frantzidis, C. Papadelis, C. Pappas, and
P.D. Bamidis. Wadeda: A wearable affective device with on-chip
signal processing capabilities for measuring electrodermal activity.
XII Mediterranean Conference on Medical and Biological Engineering and Computing, pages 276–279, 2010.
[46] K. Kuikkaniemi, I. Kosunen, M. Turpeinen, T. Saari, T. Laitinen,
and P. Lieevonen. Designing Biofeedback for Games and Playful
Applications. In CHI 2010, 2010.
[47] W. Liao, W. Zhang, Z. Zhu, Q. Ji, and W. D. Gray. Towards a
decision-theoretic framework for affect recognition and user assistance. International Journal of Man-Machine Studies, 64(9):847–
873, 2006.
[48] C. Liu, P. Agrawal, N. Sarkar, and S. Chen. Dynamic difficulty adjustment in computer games through real-time anxietybased affective feedback. International Journal of Human-Computer
Interaction, 25:506–529, 2009.
[49] R.L. Mandryk and M.S. Atkins. A fuzzy physiological approach
for continuously modeling emotion during interaction with play
technologies. International Journal of Human-Computer Studies,
65:329–347, 2007.
[50] R.L. Mandryk and K.M. Inkpen. Physiological indicators for the
evaluation of co-located collaborative play. In Proceedings of the
2004 ACM conference on Computer supported cooperative work CSCW ’04, pages 102—112, 2004.
[51] V.G. Mathison. Electropsychometer or bioelectronic instrument [v1],
July 1954.
[52] V.G. Mathison. Electropsychometer or bioelectronic instrument [v2],
February 1956.
[53] I.B. Mauss and M.D. Robinson. Measures of emotion: A review.
Cognition & Emotion, 23(2):209–237, 2009.
[54] S. McQuiggan, S. Lee, and J. Lester. Predicting user physiological
response for interactive environments: An inductive approach. 2nd
Artificial Intelligence for Interactive, 2006.
[55] M.D. van der Zwaag, E.L. van den Broek, and J.H. Janssen.
Guidelines for biosignal-driven HCI. CHI 2010, April 2010.
[56] D.D. Milne, J.P. Fagarty, and J.B. Duxlevie. Psychometer, January
1944.

[57] B. Mittelmann and H.G. Wolff. Effective states and skin temperature:
experimental study of subjects with ”cold hands” and raynaud’s
syndrome. Psychosomatic Medicine, 1:271–292, 1939.
[58] B. Mittelmann and H.G. Wolff. Emotions and skin temperature;
observations of patients during psychotherapeutic (psychoanalytic)
interviews. Psychosomatic Medicine, 5(3):211?231, 1943.
[59] L.E. Nacke. Affective ludology: Scientific measurement of user
experience in interactive entertainment. Thesis, 2009.
[60] M. Nichol. 100 words for facial expressions. Daily Writing Tips,
2012.
[61] M.A. Nicolaou, H. Gunes, and M. Pantic. Continuous prediction
of spontaneous affect from multiple cues and modalities in valencearousal space. IEEE Transactions on Affective Computing, 2(2):92
– 105, 2011.
[62] A.D. Norman. Emotional Design: Why We Love (or Hate) Everyday
Things. Basic Books, 2003.
[63] R.J. Pagulayan, K. Keeker, D. Wixon, R.L. Romero, and T. Fuller.
User-centered design in games. The human-computer interaction
handbook: fundamentals, evolving technologies and emerging applications, pages 883–906, 2003.
[64] Burlyl R. Payne. Audible psychogalvonometer, March 1972.
[65] P Petrantonakis and L. Hadjileontiadis. Emotion recognition from
EEG using higher-order crossings. IEEE Transactions on Information Technology in Biomedicine, 14(2):186–197, 2010.
[66] R. Picard and J. Healey. Affective wearables. Personal Technologies,
1:231–240, 1997. 10.1007/BF01682026.
[67] R.W. Picard. Affective computing. The MIT press, 2000.
[68] R.W. Picard. Emotion research by the people, for the people.
Emotion Review, 2(3):250, June 2010.
[69] R.W. Picard, E. Vyzas, and J. Healey. Toward machine emotional
intelligence: analysis of affective physiological state. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(10):1175–
1191, 2001.
[70] S. Poole. Trigger happy: Videogames and the entertainment revolution. Web Download Edition, 2007. Last accessed 11 September
2013.
[71] P.A. Pour, T. Gulrez, O. AlZoubi, G. Gargiulo, and R.A. Calvo.
Brain-computer interface: Next generation thought controlled distributed video game development platform. IEEE Symposium On
Computational Intelligence and Games, pages 251–257, 2008.
[72] J.L. Raesler, C.J. Bills, and C.D. Osborne. Psychogalvanometer,
January 1943.
[73] P. Rani, N. Sarker, and C. Liu. Maintaining Optimal Challenge
in Computer Games through Real-Time Physiological Feedback
Mechanical Engineering. Pulse, 2005.
[74] N. Ravaja, T. Saari, M. Salminen, J. Laarni, and K. Kallinen. Phasic
Emotional Reactions to Video Game Events: A Psychophysiological
Investigation. Media Psychology, 8(4):343–367, 2006.
[75] N. Ravaja, M. Turpeinen, T. Saari, S. Puttonen, and L. KeltikangasJärvinen. The psychophysiology of James Bond: phasic emotional
responses to violent video game events. Emotion, 8(1):114–120,
2008.
[76] C.J. Reynolds. The sensing and measurement of frustration with
computers. PhD thesis, Massachusetts Institute of Technology, 2001.
[77] J.W. Ryan. Toy lie detector, March 1964.
[78] T. Saari, N. Ravaja, J. Laarni, and M. Turpeinen. Towards Emotionally Adapted Games based on User Controlled Emotion Knobs.
Human Factors, 2005.
[79] J. Scheirer, R. Fernandez, J. Klein, and R.W. Picard. Frustrating
the user on purpose: a step toward building an affective computer.
Interacting with Computers, 14(2):93–118, 2002.
[80] E Schrawzkopf and G. Wodtke. Electrocardiograph, August 1928.
[81] K. Shelley and S. Shelley. Pulse oximeter waveform: photoelectric
plethysmography. W.B. Saunders, 2001.
[82] J. Sherwood and R. Derakhshani. On classifiability of wavelet features for EEG-based brain-computer interfaces. 2009 International
Joint Conference on Neural Networks, pages 2895–2902, June 2009.
[83] Uk Game Shows.com. The chair. Internet, August 2002.
[84] T.C. Sottek. How valve’s steam box will reinvent the game console
as you know it. TheVerge.com, February 2013. last accessed 7th
February 2013.
[85] R.M. Stern, W.J. Ray, and K.S. Quigley. Psychophysiological
Recording. Oxford university press, second edition, 2001.
[86] J. Sykes and S. Brown. Affective gaming. CHI 03 extended abstracts
on Human factors in computing systems CHI 03, page 732, 2003.
[87] M. Takagi. Instument for locating particular cutaneous points caused
by viscero-vascular reflex, September 1965.

40

© 2014 GSTF

GSTF Journal on Computing (JoC) Vol.3 No.4, April 2014

10

Thomas Christy was born in Caernarfon, Wales,
UK. He obtained his BSc in Computer Science,
Bangor University, in 2009. He won a Eurographics award for Best use of graphics, through
an advanced video game, utilising a haptic input
device. He is working towards his PhD at Bangor
University, specialising in the field of Affective
Video Games. His work continues towards advancing video game immersion through intuitive
technological methods of human computer interaction.

[88] K. Takahashi. Remarks on emotion recognition from bio-potential
signals. In The Second International Conference on Autonomous
Robots and Agents, pages 186–191. Citeseer, 2004.
[89] T.J.W. Tijs, D. Brokken, and W.A. Ijsselsteijn. Dynamic game balancing by recognizing affect. In Proceedings of the 2nd International
Conference on Fun and Games., pages 88–93, 2008.
[90] S. Tognetti, M. Garbarino, A. Bonarini, and M. Matteucci. Modeling
enjoyment preference from physiological responses in a car racing
game. Computational Intelligence and Games (CIG), pages 321–
328, 2010.
[91] H.W. Tygart. System for fm transmission of cardiological data
over telephone lines, February 1969. transmit physiological data
for remote analysis.
[92] W.M. Van Den Hoogen, W.A. IJsselsteijn, and Y.A.W. De Kort.
Effects of Sensory Immersion on Behavioural Indicators of Player
Experience: Movement Synchrony and Controller Pressure. digraorg, 2009.
[93] P.H. Venables and M.J. Christie. Electrodermal Activity in Psychological Research, chapter Chapter 1: Mechanisms, Intrumentation,
Recording Techniques, and Quantification of responses, pages 1–
124. ACADEMIC PRESS New York and London, 1973.
[94] C Vendel. The atari mindlink. www.atarimuseum.com, 2013. Last
accessed 27 August 2013.
[95] H. Weidinger, G. Volbehr, W. Limpart, and H. Steusloff. Heart
monitoring device with filter for suppressing the frequency of an
ambient A.C. power source, May 1967.
[96] M.A.A.G. Wiethoff and E.M. Houwing. The value of psychophysiological measures in human-computer interaction. In Proceedings
of the Fourth International Conference on Human-Computer Interaction, volume 18, pages 661–665, 1991.
[97] Wikipedia. The chair (game show). Internet, december 2011.
[98] G.F. Wilson, J.D. Lambert, and C.A. Russell. Performance enhancement with real-time physiologically controlled adaptive aiding. Proceedings of the Human Factors and Ergonomics Society, 1(13):61–
64, 2000.

41

© 2014 GSTF

