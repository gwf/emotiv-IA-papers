Proceedings

Memory Retrieval in Ageing Adults through
Traditional Music Genres—An Experiment Based on
Electroencephalography Signals †
Almudena Bartolomé-Tomás 1,2 , Roberto Sánchez-Reolid 1,3 , Beatriz García-Martinez 1,3 ,
Alicia Fernández-Sotos 4 and Antonio Fernández-Caballero 1,3, *
1

2
3
4

*
†

Instituto de Investigación en Informática de Albacete, Universidad de Castilla-La Mancha,
02071-Albacete, Spain; almuxbt@gmail.com (A.B.-T.); roberto.sanchez@uclm.es (R.S.-R.);
beatriz.gmartinez@uclm.es (B.G.-M.)
Conservatorio de Música de Cieza “Maestro Gómez Villa”, Calle Cadenas, 6, 30530-Cieza, Murcia, Spain
Departamento de Sistemas Informáticos, Universidad de Castilla-La Mancha, 02071-Albacete, Spain
Conservatorio de Música de Murcia, Calle Cartagena, 74, 30002-Murcia, Spain;
alicia.fernandez5@murciaeduca.es
Correspondence: antonio.fdez@uclm.es
Presented at the 13th International Conference on Ubiquitous Computing and Ambient Intelligence
UCAmI 2019, Toledo, Spain, 2–5 December 2019.



Published: 20 November 2019

Abstract: This paper studies the relationship between exposure to traditional musical styles and
memories retrieved by Spanish ageing adults living close to the region of Murcia. The objective is to
discover alterations in brain activity when memories are generated from listening to rhythms that
the participants heard during their youth. Brain region activation is observed after the acquisition,
processing and analysis of electroencephalography (EEG) signals. For this, an experiment is designed,
where first each participant responds to the positive and negative affect scales (PANAS) questionnaire
to determine his/her affective state. Then, he/she listens to eight ad-hoc composed music pieces
of varied styles (twist, swing, fandango, petenera, bolero, habanera, pasodoble and jota murciana). After
listening to each composition, the participant is asked if memories have been recalled during the
performance, which enables the interaction person–music style into classes “MEMORY-EVOKED”
and “NO-MEMORY-EVOKED”. Lastly, after the eight music pieces, the PANAS questionnaire
is given again to determine the new emotional state after being exposed to the musical styles.
From this experiment, three different studies are introduced. A first within-subject study looks
for significant differences in the activation of brain regions between “MEMORY-EVOKED” and
“NO-MEMORY-EVOKED” classes by analyzing the EEG recordings corresponding to each complete
musical piece lasting 60 s. The second within-subject study decomposes the EEG records of each
musical piece into four 15 s segments, and repeats the approach. Finally, a between-subjects
study determines if there are significant differences between all “MEMORY-EVOKED” and
“NO-MEMORY-EVOKED” segments. The promising results, although preliminary, show that there
are significant differences in terms of “MEMORY-EVOKED”/“NO-MEMORY-EVOKED” classes
in the prefrontal cortex for alpha, beta, theta and gamma frequency bands by using the spectral
power method.
Keywords: ageing adults; memory retrieval; electroencephalography; spectral power

Proceedings 2019, 31, 33; doi:10.3390/proceedings2019031033

www.mdpi.com/journal/proceedings

Proceedings 2019, 31, 33

2 of 11

1. Introduction
The term emotion refers to a mental state that arises spontaneously due to numerous stimuli. These
stimuli trigger alterations in the person’s behavior, which is usually accompanied by changes in facial
and vocal expressions, as well as physiological and neurophysiological alterations [1,2]. In this sense,
different dimensions of emotions have been described so far. According to the circumplex model,
emotions are differentiated by associating their intensity with distinct levels of valence and arousal [3].
Valence represents the pleasantness or unpleasantness of an emotional experience, while arousal is
related to the excitement or calmness that a stimulus produces.
Presently, the ageing population is growing, and old age entails many troubles related to physical
and psychological changes. Many studies indicate that ageing adults have a greater tendency towards
depression and anxiety [4,5]. Being able to identify the different emotional dimensions enables
the possibility to invert or modify an emotional state by evocation or elicitation through different
stimuli [6–8]. Modifying the emotions felt can be achieved from recalling memories. Indeed, a very
recent paper affirms that experiences that arise from youth benefit in adulthood or old age [9].
In this paper, music is the vehicle used to evoke different feelings. Music allows humans to
express, communicate and to reinforce individual and collective identity in a natural manner [10,11].
Previous works have demonstrated that some musical parameters contribute to the activation of
some brain regions, causing changes in the emotional state [12]. Hence, this paper aims to study how
listening to certain music produces memories, thus helping to improve mood [4,13].
More concretely, a musical experiment and a series of studies carried out with people over
60 years old in the region of Murcia, Spain, is described in this paper. Different musical pieces have
been composed exclusively for this experiment to evoke emotions and memories. All the musical
pieces are based on music genres listened by the participants when they were young, so to determine
which rhythm and its variations generate memories in the participant. This approach will check
whether the exposure to these fragments produces any kind of neuroelectrophysiological response
as in other similar works [4,14]. To quantify the ageing adults’ reactions, the focus is not only put
on responses provided through questionnaires, but also electroencephalography (EEG) patterns are
analyzed as a method to validate the outcomes as in similar works [7,15,16].
The remainder of the paper is structured as follows. In Section 2, the different materials used for
the experiment are described. In Section 3, the design of the experiment and the technologies used
are shown. Section 5 offers the results obtained. Finally, Section 6 presents a discussion of the most
relevant aspects derived from our studies and the conclusions reached.
2. Materials
2.1. E-Prime and Music Tracks
E-prime [17] is a software package widely used in the field of Psychology. This tool allows
the design and execution of psychological experiments. It permits the addition of audio clips and
images to the flow of the experiment. In addition, this software allows the insertion of personalized
questionnaires and collection of the data that is produced for each participant, including EEG signals
and answers to the questionnaires, for later analyses.
Here, musical pieces are composed exclusively for the experiment to study their capability to
evoke emotions and memories. Eight variations of a same melody were composed. In fact, all music
pieces have the same melody played by a piano during 60 s, but the accompaniment instrument plays
a given music style. The eight variations correspond to music genres rock/jazz (twist and swing),
flamenco (fandango and petenera), Cuban music (bolero and habanera), and traditional Spanish folklore
(pasodoble and jota murciana) as shown in Table 1. These music pieces correspond to music styles that
the participants listened during their youth.

Proceedings 2019, 31, 33

3 of 11

Table 1. Musical genres and styles used in the experiment.
Musical Genre

Style

Rock/Jazz
Flamenco
Cuban Genre
Spanish folklore

Twist and swing
Fandango and petenera
Bolero and habanera
Pasodoble and jota murciana

2.2. Emotiv EPOC+ Headset and EmoSys Software Suite
The EEG signals are captured using an Emotiv EPOC+ headset (see Figure 1a), transforming brain
activity into electrical signals which are amplified and digitized for further processing. The Emotiv
EPOC+ device is a low-cost brain–computer interface (BCI) headset whose main advantage is its easy
set up and use. It has 14 channels (AF4, F8, F4, FC6, T8, P8, O2, O1, P7, T7, FC5, F3, F7 and AF3) for
acquiring EEG signals and two references placed according to the international standard 10–20 system
for electrodes location (see Figure 1b). The device has copper-zinc electrodes covered by pads. These
must be moistened with a saline solution. The sampling frequency for each channel is 128 Hz and the
battery life is approximately 12 hours [18,19]. The device implements a control system to monitor the
quality of the contacts with the skin. This monitoring makes it possible to detect if any electrode has
gone dry during its use [19]. The data transmission from headset to computer is performed wireless.

Figure 1. (a) Emotiv EPOC+ headset. (b) Position of the electrodes.

Moreover, the EmoSys software suite (see Figure 2), developed by some of the authors of
this paper, is used for data acquisition and storage. The application enables the integration and
synchronization of several devices that acquire different physiological signals in an efficient manner.
This software has been used in other studies with outstanding results [15]. In the present work, the
single device connected to EmoSys is an Emotiv EPOC+ headset. Thus, first, the Emotiv EPOC+ device
communicates with the installed local server. Then, the neurophysiological signals pass through the
two libraries EmoKey and EmoEngine to obtain emotional metrics and raw signals, respectively. These
signals are then stored in a .csv file.
2.3. PANAS Questionnaire
The positive and negative affect scales (PANAS) is a psychological instrument used to measure
the subjective affective state of a person. This questionnaire makes it possible to obtain emotional
information from people before and after performing an experiment to analyze its emotional
impact [20]. The questionnaire is composed of 20 items, where 10 items refer to positive and 10
to negative affection. A participant must be discarded in case a great emotional alteration is detected
from before (PANAS-PRE) to after (PANAS-POST) the experiment. This is fundamental when the

Proceedings 2019, 31, 33

4 of 11

differences are more significant toward the items that show negative affection. This means that the
participant has suffered some kind of negative stress or anxiety during or after the experiment [20,21].

Figure 2. EmoSys software suite.

3. Methods
3.1. Participants
Twelve volunteers (50% women and 50% men) are selected to perform the experiment. They are
all in good mental and physical health and do not receive any financial compensation. The participants
must sign an agreement form and are informed about all the potential risks involved in carrying out
the experiment. The experiment is designed following the Helsinki Declaration and is approved by
the Ethical Committee in Clinical and Health Studies from Universidad de Castilla-La Mancha in
accordance with European legislations.
3.2. Experiment Design
As shown in Figure 3, each participant must fill in the PANAS-PRE questionnaire to establish the
basis for evaluating the state of affect before carrying out the experiment. Then, the eight music pieces
are presented randomly. At the end of the eight musical pieces, the volunteer indicates memories from
his/her youth have been generated. Then, the PANAS-POST questionnaire is responded. During the
time the experiment is being performed, the EEG signals are acquired and stored.

Figure 3. Experiment workflow.

4. Feature Extraction and Metrics
4.1. Preprocessing of EEG signals
Apart from neural information, raw EEG signals contain data from other physiological systems.
The appearance of artefacts, resulting from muscular and facial movements or simply blinking, can
make signals unrecognizable. Therefore, EEG recordings need to be preprocessed prior to any kind
of analysis. In this sense, the baseline of each EEG channel is first removed by using a forward

Proceedings 2019, 31, 33

5 of 11

or reverse filter. Specifically, a linear phase finite impulse response filter is applied. After that, a
band-pass filter with 3 Hz and 45 Hz cut-off frequencies is used to maintain the frequency bands of
interest in EEG spectrum. It is important to note that the interference of power line is at 50 Hz, so this
filter completely eliminates its components. On the other hand, artefacts derived from physiological
(e.g., eye blinks, heart bumping, etc.) and technical aspects (such as electrode-pops) are eliminated
through an independent component analysis technique [22,23]. Thus, unwanted components are
rejected after visualization of their energy spectrum and their distribution on the scalp. For example,
eye movements are easily recognizable due to their high power at low frequencies and the decreasing
trend in the EEG spectrum when the frequency increases.
4.2. Feature Extraction
The process of feature extraction consists of transforming the electrical signals into parameters
that characterize the brain activity for each participant. Thus, it allows the obtaining of some specific
features from the acquired signals that are useful to discriminate among different mental states. As is
known, the EEG spectrum is commonly separated into the following five frequency bands:
•

•

•

•
•

Delta waves (δ) (0–4 Hz) are present in children under 1 year of age and in adults in deep sleep.
A large amount of delta activity in awake adults is abnormal and related to neurological diseases.
Because of its low frequency, it is easy to confuse delta waves with artefacts caused by large
muscles in the neck or jaw. It is important to remark that in the emotional field the delta band in
not relevant [24,25].
Theta waves (θ) (4–7 Hz) are in the temporal-parietal region of the cortex. They are produced by
emotional stress, especially frustration or disappointment. They have also been associated with
access to unconscious material, creative inspiration and deep meditation.
Alpha waves (α) (8–15 Hz) are present during states of wakefulness, on rear regions of the head,
generally of great amplitude on the occipital zones. The amplitude of alpha waves increases
when the eyes are closed or in states of relaxation and little mental activity, and they attenuate or
decrease when the eyes are opened, during attention, especially visual, and mental effort.
Beta waves (β) (15–30 Hz) are small, fast waves associated with concentration and intense mental
activities and are well defined in the central and frontal cortex.
Gamma waves (γ) (30–45 Hz) are the fastest waves in the brain. They are associated with
increased mental activity (e.g., during problem solving) and may include flashes of brilliance,
sudden bursts of perception/intuition and moments of extreme attention and concentration.

This work calculates the spectral power of the EEG signals for each channel and each frequency
band (except for delta band) to carry out the comparative analysis of the music pieces that recall
memories [26]. For that purpose, the signal is transformed from the time domain to the frequency
domain by means of the Fast Fourier Transform (FFT) [27–30]. After that, the obtained spectrum is
divided into the aforementioned frequency bands. Finally, the spectral power (SP) associated with
each band is calculated as:
N

SP =

∑ [ X ]2

(1)

n −1

where X corresponds to the signal in frequency domain.
4.3. Statistical Analysis
To assess this experiment, it is necessary to verify if there are differences between the
person–music style interaction when memories have been generated (“MEMORY-EVOKED”) and not
(“NO-MEMORY-EVOKED”) in the different EEG channels. The non-parametric Mann-Whitney test is
used due to the limited amount of available data [31]. Our hypotheses are as follows:

Proceedings 2019, 31, 33

•
•

6 of 11

H0: There are no statistically significant differences in brain activation, i.e.: “MEMORY-EVOKED”
= “NO-MEMORY-EVOKED”
H1: There are statistically significant differences in brain activation, i.e.:“MEMORY-EVOKED” 6=
“NO-MEMORY-EVOKED”

for p-value < 0.05.
5. Results
The results derived from the experiment are analyzed both in intra- and inter-subject studies.
However, prior to that analysis, the participants undergo a series of filters. Three of the 12 participants
are discarded due to the scores obtained from questionnaire PANAS-PRE to PANAS-POST [20].
Other three subjects are discarded as their EEG signals present too many artefacts so that data after
preprocessing and segmentation is considered unreliable [24,26]. Therefore, the studies can only be
performed for the remaining six participants.
5.1. Intra-Subject Studies
The proposed intra-subject studies aim at comparing each individual with himself/herself
to discover if there are notable differences in terms of the level of brain region activation in the
several frequency bands (theta, alpha, beta, gamma) [32,33] for classes “MEMORY-EVOKED” and
“NO-MEMORY-EVOKED”. In this analysis, two participants (labelled P1 and P2) are selected to process
their data in two different manners. Both had more retrieved memories during the experiment than
the other participants.
5.1.1. Analysis Using Complete Pieces of Music Each Lasting 60 s
Using the Mann-Whitney test, no significant differences are found. Therefore, we must accept
hypothesis H0. This result can be explained by the fact that memory is not sustained through time.
This type of elicitation is usually punctual during the exposure to the stimulus. Figure 4 shows the
spectral power map calculated for the whole duration (60 s) of all musical pieces for subject P1. In fact,
the figure shows that there are hardly any differences between the two groups (“MEMORY-EVOKED”
versus “NO-MEMORY-EVOKED”).

Figure 4. Spectral power map for participant P1. For each frequency band: left, “NO-MEMORYEVOKED”; right, “MEMORY-EVOKED”.

Proceedings 2019, 31, 33

7 of 11

5.1.2. Analysis Using Segmented Pieces of Music Lasting 15 s
Some recent studies maintain that the time frames for this remembrance are not longer than 10 or
15 s [33,34]. Hence, this second study is ought to determine whether the two classes show significant
differences when segmenting the music pieces into segments of 15 s. To verify this issue and apply it
to the rest of the participants, a simple analysis is carried out on participant P2. This participant is
selected as he/she has manifested the highest number of memories retrieved. In this case, each piece
of music has been divided into 4 segments of 15 s each.
As shown in Figure 5, the two central segments are compared one-by-one by means of the
associated spectral powers for each band. This simple idea is based on the belief that both the initial
and the final segments distort the results. Indeed, the participant takes some time to internalize the
stimulus and to check if it produces any kind of reaction. Therefore, we must verify if there are any
differences between the segments where some kind of memory may have been generated.

Figure 5. Partitioning of each of the EEG recordings into 15-s segments.

First, a comparison is performed between two segments that belong to a same class (“MEMORYEVOKED” or “NO-MEMORY-EVOKED”). When comparing segment S2-NO-MEMORY-EVOKED
with segment S3-NO-MEMORY-EVOKED, after calculating the Mann-Whitney test, it is verified
that there are no significant differences. In the comparison of S2-MEMORY-EVOKED with
S3-MEMORY-EVOKED segment, we also get that there are no significant differences between them.
These are good news, because this shows that brain activation behaves equally among segments of the
same type for both classes.
Now, another analysis demonstrates that there are significant differences between two segments
of different classes in several channels (see Figure 6).
Moreover, Table 2 shows the statistical results of this study. As can be observed, significant
differences appear highlighted in bold for AF4, F8, FC6, F4, O2, and T7 channels in the theta band
(4–8 Hz). In alpha band (8–15 Hz) significant differences appear in channels FC5, FC6, AF3 and O2.
For the beta band (15–30 Hz), no significant differences appear for any EEG channel. Finally, for the
gamma band there are no significant differences between the two groups of signals.
Table 2. p-value from Mann-Whitney test in a single participant (P2) for segments of 15 s.

Channel

AF3
0.480

AF4
0.035

F3
0.157

F4
0.029

F7
0.157

F8
0.045

Theta
FC5
0.157

FC6
0.040

O1
0.480

O2
0.480

P7
0.157

P8
0.157

T7
0.040

T8
0.157

Channel

AF3
0.480

AF4
0.157

F3
0.157

F4
0.157

F7
0.157

F8
0.157

Alpha
FC5
0.045

FC6
0.042

O1
0.480

O2
0.048

P7
0.157

P8
0.157

T7
0.157

T8
0.157

Channel

AF3
0.480

AF4
0.157

F3
0.157

F4
0.157

F7
0.157

F8
0.157

Beta
FC5
0.157

FC6
0.480

O1
0.480

O2
0.480

P7
0.367

P8
0.657

T7
0.450

T8
0.255

Channel

AF3
0.480

AF4
0.157

F3
0.157

F4
0.157

F7
0.157

Gamma
F8
FC5
0.157 0.157

FC6
0.480

O1
0.480

O2
0.480

P7
0.157

P8
0.157

T7
0.157

T8
0.157

Proceedings 2019, 31, 33

8 of 11

Figure 6. Spectral power map for participant P2. For each frequency band: left, “NO-MEMORYEVOKED”; right, “MEMORY-EVOKED”.

5.2. Inter-Subjects Study
After carrying out the previous intra-subject studies, it is decided to analyze the data of all
valid participants [35,36]. As before, only the two central 15-s segments are again classified as
“MEMORY-EVOKED” and “NO-MEMORY-EVOKED”. The spectral power in each of the frequency
bands is analyzed (see Figure 7).

Figure 7. Spectral power map for the different frequency bands using six valid participants.

Proceedings 2019, 31, 33

9 of 11

The Mann-Whitney test demonstrates that many channels present significant differences in the
several frequency bands. According to Table 3, channels AF3, AF4, F4, F8, FC5, FC6, O2 and T7 show
significant differences between the two classes in theta band. In the alpha band, there are significant
differences for all channels. On the other hand, the channels that present differences for the beta band are
AF3, AF4, F4, FC5, FC6, P7 and P8. In contrast, in the gamma band significant variations are only present
in the AF3, AF4, F3 and F4 prefrontal cortex areas. The significant values are highlighted in bold.
Table 3. p-value from Mann-Whitney test in all participants for segments of 15 s.

Channel

AF3
0.036

AF4
0.025

F3
0.157

F4
0.034

F7
0.157

F8
0.046

Theta
FC5
0.057

FC6
0.030

O1
0.760

O2
0.045

P7
0.185

P8
0.169

T7
0.048

T8
0.497

Channel

AF3
0.028

AF4
0.067

F3
0.017

F4
0.042

F7
0.042

F8
0.019

Alpha
FC5
0.035

FC6
0.048

O1
0.036

O2
0.046

P7
0.017

P8
0.063

T7
0.023

T8
0.019

Channel

AF3
0.018

AF4
0.017

F3
0.013

F4
0.042

F7
0.542

F8
0.032

Beta
FC5
0.023

FC6
0.041

O1
0.369

O2
4̇62

P7
0.012

P8
0.023

T7
0.423

T8
0.216

Channel

AF3
0.048

AF4
0.052

F3
0.015

F4
0.015

F7
0.117

Gamma
F8
FC5
0.132 0.143

FC6
0.450

O1
0.420

O2
0.560

P7
0.657

P8
0.427

T7
0.132

T8
0.127

6. Discussion and Conclusions
This paper has introduced an experiment and three studies that were intended to obtain
information from brain activity while listening to several musical genres and styles and recalling
memories. For this purpose, the neural activity was observed from the acquisition, processing and
classification of EEG signals. The results offer a perspective of changes that take place in the emotional
state of a listener during the experiment [6,10,12].
Moreover, the brain activation responses to the memories retrieved when listening to the musical
fragments have also been demonstrated. According to other studies [16,33,37], the zones that are
activated during the generation of memories are very similar to those obtained in our experiment.
It should be highlighted that our experiment has been performed with a low-cost brain–computer
interface. Although other similar experiments use 32 or 64 channels, with the 14 channels available
on the Emotiv EPOC+ headset, the cortex regions that have shown significant differences are also the
prefrontal and frontal-temporal ones.
As for frequency bands, other studies [5,16,33,37] mention a change in the alpha and theta bands
when memory is recalled. For beta and gamma bands, there is no consensus as to whether any major
alteration occurs. Our inter-subject experiment has detected differences, but the results cannot be
generalized at this point [23,38]. Without entering into the typology of memory, specific or non-specific,
it can be concluded that the proved capacity for discrimination between the different regions allows
us to locate and recognize the zones that are activated at the moment of the production of retrieved
memories as described by other authors [32,39].
Nonetheless, the results obtained during this experiment should be taken as preliminary. The
number of subjects involved in the experiment is too small to generalize the gotten results. Therefore,
currently, our research team is recruiting more volunteers to validate our proposal.
Author Contributions: A.B.-T., R.S.-R., A.F.-S. and A.F.-C. conceived and designed the experiments; A.B.-T. and
R.S.-R. performed the experiments; B.G.-M. and R.S.-R. analyzed the data; A.B.-T., R.S.-R., B.G.-M. and A.F.-C.
wrote the paper.
Acknowledgments: This work was partially supported by Spanish Ministerio de Ciencia, Innovación y
Universidades, Agencia Estatal de Investigación (AEI)/European Regional Development Fund (FEDER, UE)
under DPI2016-80894-R grant, and by Castilla-La Mancha Regional Government/FEDER, UE under
SBPLY/17/180501/000192 grant. R.S.-R. holds BES-2017-081958 scholarship from Spanish Ministerio de Educación
y Formación Profesional. B.G.-M. holds FPU16/03740 scholarship from Spanish Ministerio de Educación y
Formación Profesional.

Proceedings 2019, 31, 33

10 of 11

Conflicts of Interest: The authors declare no conflict of interest. The funding sponsors had no role in the design
of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, and in the
decision to publish the results.

Abbreviations
The following abbreviations are used in this manuscript:
BCI
EEG
PANAS
SAM

brain-computer interface
electroencephalogram
positive and negative affect scales
self-assessment manikin

References
1.

2.

3.
4.
5.
6.
7.

8.
9.

10.

11.

12.
13.
14.
15.

16.

17.

Fernández-Sotos, A.; Fernández-Caballero, A.; Latorre, J.M. Elicitation of emotions through music:
The influence of note value. In Artificial Computation in Biology and Medicine; Springer: Cham, Switzerland,
2015; pp. 488–497.
Fernández-Caballero, A.; Martínez-Rodrigo, A.; Pastor, J.M.; Castillo, J.C.; Lozano-Monasor, E.; López, M.T.;
Zangróniz, R.; Latorre, J.M.; Fernández-Sotos, A. Smart environment architecture for emotion recognition
and regulation. J. Biomed. Inform. 2016, 64, 55–73.
Russell, J.A. A circumplex model of affect. J. Personal. Soc. Psychol. 1980, 39, 1161.
Brewer, W.F. What Is Autobiographical Memory?; Cambridge University Press: Cambridge, UK, 1986.
Conway, M.A. Sensory–perceptual episodic memory and its context: Autobiographical memory. Philos. Trans.
R. Soc. Lond. Ser. Biol. Sci. 2001, 356, 1375–1384.
Bradley, M.M. Emotional memory: A dimensional analysis. In Emotions; Psychology Press: London, UK,
2014; pp. 111–148.
Martínez-Rodrigo, A.; Zangróniz, R.; Pastor, J.M.; Fernández-Caballero, A. Arousal level classification in
the ageing adult by measuring electrodermal skin conductivity. In Ambient Intelligence for Health; Springer:
Cham, Switzerland, 2015; pp. 213–223.
Sokolova, M.V.; Fernández-Caballero, A. A review on the role of color and light in affective computing.
Appl. Sci. 2015, 5, 275–293.
Terrett, G.; Horner, K.; White, R.; Henry, J.D.; Kliegel, M.; Labuschagne, I.; Rendell, P.G. The relationship
between episodic future thinking and prospective memory in middle childhood: Mechanisms depend on
task type. J. Exp. Child Psychol. 2019, 178, 198–213.
Fernández-Sotos, A.; Martínez-Rodrigo, A.; Moncho-Bogani, J.; Latorre, J.M.; Fernández-Caballero, A. Neural
correlates of phrase quadrature perception in harmonic rhythm: an EEG study using a brain–computer
interface. Int. J. Neural Syst. 2017, 28, 1750054.
Martínez-Rodrigo, A.; Fernández-Sotos, A.; Latorre, J.M.; Moncho-Bogani, J.; Fernández-Caballero, A.
Neural correlates of phrase rhythm: An EEG study of bipartite vs. rondo sonata form. Front. Neuroinform.
2017, 11, 29.
Fernández-Sotos, A.; Fernández-Caballero, A.; Latorre, J.M. Influence of tempo and rhythmic unit in musical
emotion regulation. Front. Comput. Neurosci. 2016, 10, 80.
Williams, J.M.G.; Barnhofer, T.; Crane, C.; Herman, D.; Raes, F.; Watkins, E.; Dalgleish, T. Autobiographical
memory specificity and emotional disorder. Psychol. Bull. 2007, 133, 122.
Cohen, G. The effects of aging on autobiographical memory. In Autobiographical Memory; Psychology Press:
London, UK, 2014; pp. 105–124.
Sánchez-Reolid, R.; García, A.S.; Vicente-Querol, M.A.; Fernández-Aguilar, L.; López, M.T.;
Fernández-Caballero, A.; González, P. Artificial neural networks to assess emotional states from
brain-computer interface. Electronics 2018, 7, 384.
Conway, M.A.; Pleydell-Pearce, C.W.; Whitecross, S.; Sharpe, H. Brain imaging autobiographical memory.
In Psychology of Learning and Motivation; Elsevier: Amsterdam, The Netherlands, 2002; Volume 41,
pp. 229–263.
Schneider, W.; Eschman, A.; Zuccolotto, A. E-Prime: User’s Guide; Psychology Software Incorporated:
Sharpsburg, PA, USA, 2002.

Proceedings 2019, 31, 33

18.

19.
20.
21.

22.
23.
24.
25.
26.
27.
28.

29.

30.

31.

32.
33.

34.
35.
36.
37.
38.

39.

11 of 11

Lievesley, R.; Wozencroft, M.; Ewins, D. The Emotiv EPOC neuroheadset: An inexpensive method of
controlling assistive technologies using facial expressions and thoughts? J. Assist. Technol. 2011, 5, 67–82.
doi:10.1108/17549451111149278.
Emotiv. Emotiv SDK User Manual. Available online: https://www.emotiv.com/epoc/ (accessed on
20 November 2019)
Watson, D.; Clark, L.A.; Tellegen, A. Development and validation of brief measures of positive and negative
affect: The PANAS scales. J. Personal. Soc. Psychol. 1988, 54, 1063.
Gaudreau, P.; Sanchez, X.; Blondin, J.P. Positive and negative affective states in a performance-related setting:
Testing the factorial structure of the PANAS across two samples of French-Canadian participants. Eur. J.
Psychol. Assess. 2006, 22, 240–249.
Sanei, S. Adaptive Processing of Brain Signals; John Wiley & Sons: Hoboken, NJ, USA, 2013.
Koelstra, S.; Muhl, C.; Soleymani, M.; Lee, J.S.; Yazdani, A.; Ebrahimi, T.; Pun, T.; Nijholt, A.; Patras, I. DEAP:
A database for emotion analysis using physiological signals. IEEE Trans. Affect. Comput. 2012, 3, 18–31.
Tatum, W.O., IV. Handbook of EEG Interpretation; Demos Medical Publishing: New York, NY, USA, 2014.
Klimesch, W. EEG alpha and theta oscillations reflect cognitive and memory performance: A review and
analysis. Brain Res. Rev. 1999, 29, 169–195.
Teplan, M. Fundamentals of EEG measurement. Meas. Sci. Rev. 2002, 2, 1–11.
Martínez-Rodrigo, A.; García-Martínez, B.; Zunino, L.; Alcaraz, R.; Fernández-Caballero, A. Multi-lag
analysis of symbolic entropies on EEG recordings for distress recognition. Front. Neuroinform. 2019, 13, 40.
Martínez-Rodrigo, A.; García-Martínez, B.; Alcaraz, R.; González, P.; Fernández-Caballero, A. Multiscale
entropy analysis for recognition of visually elicited negative stress from EEG recordings. Int. J. Neural Syst.
2019, 29, 1850038.
García-Martínez, B.; Martinez-Rodrigo, A.; Alcaraz, R.; Fernández-Caballero, A. A review on nonlinear
methods using electroencephalographic recordings for emotion recognition. IEEE Trans. Affect. Comput.
2019, doi:10.1109/TAFFC.2018.2890636.
García-Martínez, B.; Martínez-Rodrigo, A.; Fernández-Caballero, A.; Moncho-Bogani, J.; Alcaraz, R.
Nonlinear predictability analysis of brain dynamics for automatic recognition of negative stress. Neural
Comput. Appl. 2018. doi:10.1007/s00521-018-3620-0.
Bares, M.; Brunovsky, M.; Novak, T.; Kopecek, M.; Stopkova, P.; Sos, P.; Höschl, C. QEEG theta cordance in
the prediction of treatment outcome to prefrontal repetitive transcranial magnetic stimulation or venlafaxine
ER in patients with major depressive disorder. Clin. Eeg Neurosci. 2015, 46, 73–80.
Delorme, A.; Makeig, S. EEGLAB: An open source toolbox for analysis of single-trial EEG dynamics
including independent component analysis. J. Neurosci. Methods 2004, 134, 9–21.
Ros, L.; Latorre, J.M.; Aguilar, M.J.; Ricarte, J.J.; Castillo, A.; Catena, A.; Fuentes, L.J. Differences in
brain activation between the retrieval of specific and categoric autobiographical memories: An EEG study.
Psicol. Int. J. Methodol. Exp. Psychol. 2017, 38, 347–363.
Yousefzadeh, F.; Pirzad Jahromi, G.; Mokari Manshadi, E.; Hatef, B. The effect of prostration (Sajdah) on the
prefrontal brain activity: A pilot study. Basic Clin. Neurosci. 2019, 10, 257–268.
Gevins, A.; Zeitlin, G.; Doyle, J.; Yingling, C.; Schaffer, R.; Callaway, E.; Yeager, C. Electroencephalogram
correlates of higher cortical functions. Science 1979, 203, 665–668.
Polich, J. On the relationship between EEG and P300: Individual differences, aging, and ultradian rhythms.
Int. J. Psychophysiol. 1997, 26, 299–317.
Conway, M.A.; Pleydell-Pearce, C.W.; Whitecross, S.E.; Sharpe, H. Neurophysiological correlates of memory
for experienced and imagined events. Neuropsychologia 2003, 41, 334–340.
Subramaniam, K.; Hinkley, L.B.; Mizuiri, D.; Kothare, H.; Cai, C.; Garrett, C.; Findlay, A.; Houde, J.F.;
Nagarajan, S.S. Beta-band activity in medial prefrontal cortex predicts source memory encoding and
retrieval accuracy. Sci. Rep. 2019, 9, 6814.
Steinvorth, S.; Wang, C.; Ulbert, I.; Schomer, D.; Halgren, E. Human entorhinal gamma and theta oscillations
selective for remote autobiographical memory. Hippocampus 2010, 20, 166–173.
c 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).

