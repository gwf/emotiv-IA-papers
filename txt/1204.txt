VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com

ROBOTIC ARM CONTROLLED BY A HYBRYD BRAIN
COMPUTER INTERFACE
J. Salgado Patrón and C. Barrera
Department of Electronic Engineering, Universidad Surcolombiana, Neiva, Colombia
E-Mail: josesalgadop@usco.edu.co

ABSTRACT
The Hybrid Brain Computer Interface (Hybrid BCI) systems provide an integrated system with different signal
sources, as multiple interpretations of brain waves through an electroencephalogram (EEG), as well as muscular signals
from electromyography (EMG) and gyroscopic positioning. Many hybrid BCI systems perform not only with high quality
devices, longer preparation times but with lower possibility of lightweight portability not just for the acquisition device but
for the processing device as well. A hybrid BCI is implemented using a commercial device for the signal measurement
known as Emotiv EPOC, focusing on relaxation (alpha wave related) and concentration (Beta and Gamma wave related) as
brain waves, winking as muscular application and head movement on the horizontal axis. It was implemented the features
extraction methods, Power Spectral Density (PSD), Hjorth Complexity and Mobility (Hjorth Parameters), Petrosian Fractal
Dimension (PFD) and the Frobenius Norm. A Support Vector Machine (SVM) classifier was used as the classification
method.
Keywords: hybrid BCI, electroencephalography, electromyography, EPOC, power spectral density, petrosian fractal dimension, support
vector machine.

INTRODUCTION
A method that interlaces different type of signals
such as electroencephalography, electromyography and
body movement is known as a hybrid Brain Computer
Interface (BCI) [1] which is included in the Human
Machine Interfaces (HMI), giving a wider range of
possibilities for the user to manipulate the end of the
application.
As diverse bio-signals exists, the same is
understood for methods to process them, falling into two
main categories, synchronous and asynchronous, where
the user has the liberty to activate them or with an external
stimulus. It is a must for the system to be adaptable and
easily accessible, needing just a couple of sessions to
completely control the system.
Using a bulky system is always certain to work,
but limits the portability, therefore a small standalone
system offers a solution, not only as a lower cost like
Emotiv EPOC [2] for acquiring the signals and the
Raspberry Pi 2 [3] for the processing segment, it offers a
faster setup time with only a main drawback on being light
on the hardware’s capability.
For an appropriate interaction between the user
and the end application, a graphical interface is needed,
not just for the acquisition segment but for the real time
work, which under a standalone system it is necessary to
maintain the design to a minimum approach. The main
concern on the system limitations applies as well for the
processing segment, where the number of stages must be
kept short, with interest in features based on the time and
frequency variability, linear and nonlinear signals
generated mostly from the brain, features extraction
methods such as Power Spectral Density [4] and Hjorth
Parameters [5] were implemented with the Support Vector
Machine (SVM) [6] as the classifier, without the use of
other methods like artefact rejection [7], keeping a lower
consume on processing and memory power.

The main purpose of a hybrid BCI application is
for the end-user to have diverse control on it, which in this
case is the manipulation of a robotic arm by moving
square and rectangular shaped pieces from a stand point to
boxes with their respective shaped grooves.
METHODOLOGY
Hybrid BCI
A typical BCI is conformed of a cycle involving
the user, processing segments and an application, as seen
in the Figure-1 (M. Ahn M. Lee, J. Choi et al. 2014),
where the main aspects are mentioned. A user with an
active or passive control mostly, an acquiring segment
with invasive or non-invasive method, processing which
includes pre-processing and selection of the features to be
extracted, prediction has the activation of from the user
and it is recognized for a prediction or classification
method and lastly an application that shows the final stage
of a BCI involving medical rehabilitation, video games or
virtual reality.

7313

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
This device offers 14 EEG channels that follow
the 10-20 standards, wireless communication with a USB
dongle and a suitable design for different head sizes as
seen in the Figure-3; some of the specifications can be
found in the Table-1 (Emotiv, Inc, 2014), where the
system uses 128 Hz of sampling rate with a resolution of
14 bit, enough to perform the basic EEG and EMG signal
processing [10].

Figure-1. A typical BCI.
There are multiple methods to measure the brain
activities which focused on different approaches, such as
Magnetoencephalography (MEG), functional Magnetic
Resonance Imaging (fMRI), Electrocorticography (ECoG)
or Electroencephalography (EEG). Some of these methods
requires a high quality standard equipment to perform,
meaning higher costs and complex settings up, however,
produces precise information on specific locations of the
brain such as the fMRI [8] and with invasive procedures
like ECoG, where a grid of electrodes implant are
surgically implanted on the surface of the brain [9]. From
a user standpoint, a hardware should be easy to wear with
no complexity on the operation and drawbacks that could
affect the performance, EEG offers the possibility to work
over the surface of the scalp, with multiple electrodes
offering possibilities on acquiring brain signals from
different points of the head and no main concerns on the
way of wearing it.
EEG is a reasonable tool to develop BCIs, even
though there are some which are categorized as high
standard medical equipment with a wide frequency range
and multiple EEG channels. Commercial EEGs are not
just affordable to anyone but they offer a portable and
light solution to the user. In the Figure-2a, shows the
popularity of EEG among other types of hardware within
the research community; In the Figure-2b, the different
types of commercial EEGs, where Emotiv EPOC is the
most popular among them.

Figure-2. Some popular aspects of measurement methods
and EEG devices.

Figure-3. The EPOC Emotiv.
Table-1. EPOC Emotiv specifications.
Specification key
Number of
channels
Sampling method
Connectivity
Channels Names
Sampling Rate
Resolution
Dynamic Range
Bandwidth
Battery Life

Specifications
14 channels with CMS/DRL
references
Sequential sampling, single ADC
Proprietary Wireless, 2.4 GHz
band
AF3, AF4, F3, F4, F7, F8, FC5,
FC6, P7, P8, T7, T8, O1, O2
128 Hz (2048 Hz Internally)
16 bits (14 bits effective)
1 LSB = 0.51uV
8400uVpp
0.2 – 45 Hz, 5th order Sinc Filter
Digital notch filters at 50 Hz and
60 Hz
12 Hours

BCI is focused mainly on improving the
interaction of some patients with the environment due to
some physical factors or impediments that deter them from
having a typical daily life. Other applications aim to
provide a type of entertainment for anyone who wants to
explore the different aspects of a BCI such as with virtual
reality, video games [11] or robotic manipulation [12].
A hybrid BCI system could be structured of
different brain signals, nevertheless, using alternative
aspects of others physiological signals used in Human
Machine Interfaces (HMI), such as Electrooculography
(EOG), Electromyography (EMG), head or hands
movement, could be categorized as a hybrid BCI [13]. In

7314

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
this case, three aspects are used, EEG, EMG and
Gyroscopic movement.
Types of signals
The EPOC Emotiv offers a frequency range of
0.2 to 45 Hz, which works mainly for the EEG signals
such as alpha (8 to 13 Hz), beta (14 to 30 Hz) and gamma
(31 to 50 Hz) that are involved with relaxation and
concentration [14]. For the case of the magnitude of the
signals, the EPOC offers a resolution of 14 bits with
0.51uV as the least significant bit (LSB) with a most
significant bit (MSB) of approximately 8.1mV, more than
enough for the EEG and EMG signals to be correctly
measured. Mostly of the EEG waves have a magnitude of
microvolt such as alpha (30 to 50 uV), beta (5 to 20 uV)
and gamma (5 to 10 uV) [14]. For the case of the EMG, is
an accumulation of motor unit action potentials (MUAPs)
that can be found in microvolt as well as in the millivolt
region, with a typical magnitude of 0 to 10 mV [15].
From EEG there are many types of signals that
can be acquired and depending of the point of view of the
user, three main types are found, active, reactive and
passive. An active type is when the control is totally from
the user; Reactive when an external stimulus is used and
passive when the user has no control over it. The most
common for each type are motor imagery and mental
sates, SSVEP and P300, and feelings respectively [16].
Active control offers freedom to the user without
the need of an external stimulus, but due to some difficulty
of motor imagery on training and application [17], mental
sates are chosen as the EEG method.
The two chosen mental states are relaxation and
concentration, which can be activated any moment by the
user. Those states can be found at the occipital and frontal
lobe respectively [18]. In the Figure-4 (Q. Wang, O.
Sourina. 2013), a comparison between the relaxation state
and the concentration state can be appreciated, where the
relaxation focused mainly on the occipital lobe, indicated
by the red portion, with a contrast on the frontal lobe, with
a blue portion. The concentration state is showing in the
frontal lobe, but in a minuscule portion, with some
influence on the occipital lobe, nonetheless, concentration
can be found mainly in the frontal channels, and relaxation
on the occipital channels.

Figure-4. Aspects of mental processing of relaxation
and concentration
As seen in the Figure-5 (N. Puzi, R. Jailani, H.
Norhazman et al. 2013), indicated by the red circles, the
EEG channels used by the EPOC, some are situated on the

occipital lobe, like O1 and O2. For the frontal lobe there
are some channels like AF3, AF4, or F7 and F8. The main
purpose is to maintain to a minimum the quantity of
channels, therefore, one channel is used for each function.
For the relaxation state the O2 channel is selected and for
the concentration state, the AF3 channel. AF3 is a channel
influenced by the concentration and in a position on the
head with no hair.

Figure-5. 10-20 EEG system used for the EPOC.
The EPOC Emotiv has an acceptable frequency
range and frontal channels for facial expressions to be
recorded; many projects use facial expressions like smiling
or clenching [20]; In this case, the action of left and right
winking is used as the EMG signal.
The channels closer for the winking action are
F7, F8 and AF3, AF4, but knowing that AF3 is already
used for the concentration state, it can be used as well for
the winking action, leaving the right winking to the F8
channel.
For the gyroscope aspect, the EPOC system
offers two deflecting sensors in the horizontal and vertical
axis, which is ideal for the nod and shake head movements
[21]; In this case is used only he shake movement.
Pre-processing
The first step is to remove the DC offset from the
signals in spite of using a filter to do so, indicated by [22]
and [23]. It is recommended to use a simple adjustment of
the offset by removing the average value and multiplying
it by the LSB to give the signal in microvolt.
The EPOC has a Band Pass Filter already applied
to the signals; therefore a High Pass Filter is used at 2 Hz
5th order Digital Butterworth, to avoid any possible
remaining noise. There is no artefact rejection system
used, as applied by [24] to avoid any extra memory
consumption.
The size of the window must be relatively small
to avoid any heavy processing of multiple values. In some
cases different window values from 2 to 16 seconds have
been examined, with better results on balancing the speed
and value extraction with 2 and 4 seconds [25]. A window

7315

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
of less than 2 seconds wide is used when a quick reaction
characteristic such as SSVEP can be applied, similarly to
P300 which values of reaction time are needed to be
instant on less than a second; In this case a window of 2
seconds is used in the online process and 4 seconds in the
data collection for the relaxation and concentration, and 2
seconds for the winking action.
Another aspect of preparation is the
normalization of the signal, where it is a must as a preprocessing step [26]; it basically centres it to the mean and
component wise scales it to the unit variance. This aspect
is only applied for the EEG signals; it helps to separate
any aspect that can be found in an EMG signal, in which
normalization is not applied to avoid any removing of
features of the winking action.
Features extraction
To classify and differentiate the actions of the
user, the understanding of signal’s characteristic is a most.
Having multiple options of feature extracting functions,
the quantity per action depends on the complexity and
difficulty of detecting the signals. Others use a technique
of converting them to a subspace delimiting the dimension
of the characteristics related to the spatial patterns, but it
imply to increase the consumption of processing memory,
therefore the features are kept to a minimum, with 2
characteristics or dimension for simpler action like
winking and relaxation and 3 dimensions for
concentration.
There are many types of function for extracting
characteristics from the biological signals with certain
aspects which helps the classifier. Some functions are
linear such as Power Spectral Density (PSD) that are used
[27], and the Frobenius Norm, but are not enough for more
complex brain signals like concentration, where
nonlinearity features are needed to distinguish the action
from others like Hjorth Parameters and Petrosian Fractal
Dimension (PFD) [28].
The chosen functions can be seen in the Table-2
with their respective actions, where for relaxation and
winking, linear and quasilinear functions are used but for
concentration a nonlinear aspect is applied in order to
extract another aspect of the action that may not be easily
observable with the linear or quasilinear functions [29].
Table-2. Description of the features extraction functions.
Relaxation
Power Spectral Density ratio
Hjorth Mobility
Concentration
Power Spectral Density ratio
Hjorth Mobility
Petrosian Fractal Dimension
Winking
Frobenius Norm Hjorth Complexity

Linear
Quasilinear

The samples were taken in one session of 1 hour
approximately; for relaxation, the user with the closed
eyes entered a relaxing state for 128 seconds with 8
seconds active interval, 5 times. For the concentration, a
26 minutes session is used with 100 seconds active
interval. For the winking action a 300 seconds session is
used with 2 seconds active interval.
In the Table-3, it can be appreciated the three
actions with their offline and online window’s sizes, the
total of the trial in seconds and the quantity of the samples
used to train the classifiers. Concentration needed more
samples than the others due to the difficulty of detecting it.
Table-3. Some aspects of action’s data.
Action
Relaxation
Concentration
Winking

Offline
window
size (s)
4
4
2

Online
window
size (s)
2
2
2

Trial
(s)

Samples
quantity

640
1600
300

75
192
75

To understand better the actions of relaxation and
concentration, a spectrogram plotting function was used,
where in first sight, in the Figure-6, the relaxation action
shows a reddish bold line at 10 Hz followed by the resting
segment, each line represent a moment of activation from
the user when is relaxing with the eyes closed.

Figure-6. Spectrogram of relaxation (Channel O2).
The Figure-7 shows the result of concentration, in
this case it was used the successive subtraction of a
random number higher than 200, by subtracting 3 from it
each time for the whole active segment [30], different
from the online process where concentrating to a specific
point for a time can generate similar results. It can be
appreciated that the active segments have small reddish
dots from a frequency range of 10 to 40 Hz, in some cases
at the non-active segments some are visible due to the user
concentrating when it was time for resting or be distracted,
nevertheless, the concentration can be easily observable
when is applied at longer times of trials.

Linear
Quasilinear
Nonlinear
Figure-7. Spectrogram of concentration (Channel AF3).
Linear
Quasilinear

For a different view of analysing concentration, a
convolution and coherence (Normalized Cross Spectral
Density) is applied to observe the active frequency range,

7316

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
where in Figure-8(a), the similitude on the channels AF3
and AF4 remarks frequency ranges of 10 to 18 Hz and 22
to 30 Hz, which in Figure-8(b), with the coherence
between the signals have higher relationship between 22 to
30 Hz approximately, indicating that concentration is
found in that range mostly.

(a)

Figure-10. Relaxation’s features box plot

(b)
Figure-8. Concentration convolution and coherence
analysis plot.
The winking action can be seen in the Figure-9,
where the left winking (channel AF3) is stronger in
magnitude than the right winking (channel F8) despite
both electrodes being positioned closer to the eyes, it
shows that the user has stronger winking with the left eye
than the right.

The non-active samples have a standard action
which involves the user to fix the mind into a blank state
with the eyes open; and an offline action, that basically is
leaving the EPOC system on a flat surface and sending the
raw data; It is useful to understand what kind of noise
could influence the real active samples and save them for
future classification of non-active samples.
The Figure-11 shows the three features extraction
functions for the concentration, which beta ratio is the
PSDr for beta frequency range, PFD and Hjorth Mobility.
The non-active classes for concentration are standard,
offline, EOG and Winking; standard and offline are the
same type as for relaxation; EOG are samples taken when
the user moves the eyes from left to right within the
respective time window; lastly, the EMG-Wink is related
to the winking action, in this case is taken as an artefact,
so that the classifier can detect and differentiate correctly
the concentration action.

Figure-9. Spectrogram of left and right winking
(Channels AF3 and F8).
To visualize the extracted features, the box plot is
used for each action with their respective extracting
function. This method helps to analyse a vast of quantity
of samples with different classes or action and compare
their tendency, majority and median values.
The Figure-10, shows the case for the relaxation,
where the action or the active samples are easily
differentiable from the non-active ones in the Alpha Ratio,
that it’s the Power Spectral Density ratio for alpha
frequency range, with scalar values given by the
algorithm; contrary to the Hjorth Mobility where it can be
distinguish from offline but not so much with the standard
action.

Figure-11. Concentration’s features box plot.
For the case of Beta ratio, the active class is not
easily distinguishable from standard and offline; for PFD
active is similar to standard, EOG and winking, but for
Hjorth Mobility, active class is more observable from all
the others non-active classes.

7317

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
For the winking action, Figure-12 and Figure-13,
shows the winking for the right and left eyes, where they
look similar to each other, with the difference that for the
right winking in the Hjorth Complexity, the active class is
similar to the EOG, due to the user having less control
over the right winking, opposite to the left winking which
has better results.

The variation of γ and C can be seen in the
Figure-14, for the relaxation action, where the best fit must
contain an acceptable degree of samples from the active
and non-active; the red dots represent the non-active
samples and blue the active samples, therefore their
respective coloured shadows indicates the curvature of the
classifier, where γ = 10^-1 (γ = 0.1) gives a circular
frontier and C = 10^2 (C = 100) fits it to be in an adequate
distance between the closest samples of active and nonactive class; the RBF parameters are the same for all
classes.

Figure-12. Right winking’s features box plot.
Figure-14. Relaxation’s RBF parameters plot
The classifier operates as a binary type,
classifying between an active class and a non-active class,
where the active class has all the correct actions done by
the user and the non-active has the chosen artefacts with a
specific number of samples all conforming one single
class, instead of using multiple classes, facilitating the use
of simple classifiers, one for each action.
The concentration is different as it has tree
dimension or classes. The Figure-15 shows the 3D plot,
where the blue dots represent the active class and the red
the non-active. The use of three dimensions helps to
separate the samples correctly, increasing the accuracy of
the classifier.
Figure-13. Left winking’s features box plot.
Classification
The first step is to mix the samples randomly and
separate them into two parts, the data to train the classifier
and a test; the distribution for the samples is
approximately 65% data and 35% test. The standardization
of samples is a must before the application of the
classifier, where it removes the mean and scales them to a
unit variance.
The chosen classifier is the Support Vector
Machine (SVM) which is widely used on bioinformatics
due to the exactitude on handling high dimension data
[31]. The kernel function used is the Radial Basis Function
(RBF), one of the most applicable with the SVM; RBF
parameters are γ (gamma) and C, which adjust the quantity
of samples to be taken into account and the curvature of
the frontiers respectively.

Figure-15. Concentration’s RBF parameters plot.
RESULTS
The setup of the experiment has a 5 DoF Robotic
arm where the gyroscopic action was given to the waist

7318

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
movement, the relaxation and concentration to the opening
and closing of the tool respectively, and the rotation of the
tool for the winking action. All the action are assigns to be
as ON/OFF control which when an action is detected the
execution is done once, except for the gyroscopic where
gradually moves depending of the head position.
The programming language used is Python with
the multithreading and multiprocessing functions and Qt
for the GUI interface. The hardware for the standalone
system is a Raspberry Pi 2, with 900 MHz processor and
1GB of memory and Raspbian as the operating system,
sufficient for handling the real time processes.
The Table-4 shows the method applied to 5 users,
where relaxation action has more accuracy than
concentration despite having an extra class or dimension,
nevertheless the process is assertive for most of the users.
The cross validation was at 10 fold and the winking and
gyroscopic action was used only for a final user whom
would manipulate the robotic arm.
Table-4. Results of the classifier for the users.
User
1(%)
Relaxation
Concentration

98.6
82.7

User
2
(%)
86.6
80.3

User
3
(%)
98.4
81.2

User
4
(%)
99.6
86.8

User
5
(%)
79.6
76.0

The explanation of the test was done only once as
the test itself, in order to maintain a simplicity for the user
to perform. Some users have stronger alpha wave than
others, the same was found for concentration where the
user sometimes couldn’t enter a relaxing state after a
concentrating one fast enough, even though the results
were acceptable for being a one session test.
The design of experiment is for the user to move
two pieces of different shapes, square and rectangular, to a
different position where a box with the same opening
shape as the piece is located as quick as possible without
making any mistakes; the Figure-16 shows the layout of
the experiment.

Figure-16. Experiment’s layout.
The cycle of the process starts with the user
adjusting to a correct rotation of the tool with the winking
action; followed by the opening it in order to grab the
piece with the relaxation action, then closing it with
concentration action. The head movement or gyroscopic

action rotates the waist of the robotic arm in order to
position it over the respective box; rotation may be needed
to fit the piece into the opening and finally relaxation
action in order to drop the piece into the box. Table-5
shows two sessions of the experiment with some trials and
the average time for each session and the accuracy of the
sessions, where the user demonstrates an acceptable result
for the whole experiment.
Table-5. Results of the experiment for one user.
Session

Trials

1st
2nd

11
13

Average
time (s)
34
26

Accuracy
(%)
73
87

CONCLUSIONS
 The project was possible to be adapted into a
Raspberry Pi 2 and Python, to manipulate the robotic
arm with multiprocessing feature extraction functions,
a SVM as a classifier and a graphical interface in real
time without any delay and less than 40% of
processing consumption.
 Only three channels were used from the EPOC
Emotiv to extraction relaxation, concentration, left
and right winking actions, making it less heavy and
fast for the processing without depending on any
artefact rejection.
 Due to the similitude of alpha, beta and gamma waves
for relaxation and concentration, and the winking
action between users, any person could use the
system, without the need of taking sample data and
only one training session.
 The concentration can be analyzed easily by
performing it on longer periods of time from 10 to 60
seconds where using successive subtractions can
increase it, opposite to needing a quick result where
by just staring at a fixed point for a couple of seconds.

For the relaxation on the alpha wave, some users
have strong waves compared to others that have it to a
minimum, ranging from 9 to 12 Hz, most focusing on
10 Hz, but using the features extraction method of
ratio, it was possible to detect for all the users.
 The RBF SVM classifier increases accuracy when an
extra dimension or feature is added, nevertheless the
processing consumption as well, therefore it must be
kept to a minimum for a correct balance between
speed and accuracy.
 The best RBF parameters were C = 100 and γ = 0.1,
which fit for the relaxation, concentration and as well
as for the winking action, without the need of
different values for different types of signals.
 The most reliable feature extraction methods were the
Hjorth Parameters and the Power Spectral Density
ratio, which they offer a wide range of lineal and nonlineal brain detections and muscular signals.

7319

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
REFERENCES
[1] B Choi, S Jo. 2013. A Low-Cost EEG System-Based
Hybrid Brain-Computer Interface for Humanoid
Robot Navigation and Recognition. PLoS ONE. 8(9):
e74583.
[2] Y. Liu, X. Jiang, T. Cao et al. 2012. Implementation
of SSVEP Based BCI with Emotiv EPOC. 2012 IEEE
International Conference on Virtual Environments
Human-Computer Interfaces and Measurement
Systems (VECIMS) Proceedings. pp. 34-47.
[3] Upton, Liz. Benchmarking Raspberry Pi 2 Raspberry Pi. Raspberry Pi. N. p., 2015. Web. 29
November 2015.
[4] W. Kaysa, Wi A. Dyotriatmo. 2013. Design of Braincomputer interface platform for semi real-time
commanding
electrical
wheelchair
simulator
movement. 2013 3rd International Conference on
Instrumentation Control and Automation (ICA). 3944.
[5] S. Oh, Y. Lee, H. Kim. 2014. A novel EEG Feature
Extraction Method Using Hjorth Parameter.
International Journal of Electronics and Electrical
Engineering. 2(2): 106-110
[6] A. Risangtuni, A. Widyotriatmo. 2012. Towards
online application of wireless EEG-based open
platform Brain Computer Interface. 2012 IEEE
Conference on Control, Systems and Industrial
Informatics. pp. 141-144.
[7] Daly, R. Scherer, M. Billinger, et al. 2014. FORCe:
Fully Online and automated artifact Removal for
brain-Computer interfacing. IEEE transactions on
neural systems and rehabilitation engineering: a
publication of the IEEE Engineering in Medicine and
Biology Society. 4320(c): 1-13.
[8] O. Cohen, S. Druon, S. Lengagne, A. Mendelsohn et
al. 2012. fMRI robotic embodiment: A pilot study.
Biomedical Robotics and Biomechatronics (BioRob).
pp. 314-319.
[9] A. Garcia, I. Schjolberg, S. Gale. 2013. EEG control
of an industrial robot manipulator. IEEE 4th
International
Conference
on
Cognitive
Infocommunications. pp. 39-44.
[10] P. Chowdhury, S. Kibria Shakim, M. Karim et al.
2014. Cognitive efficiency in robot control by Emotiv

EPOC. 2014 International Conference on Informatics,
Electronics and Vision. pp. 1-6.
[11] Rouillard, A. Dupres, F. Cabestaing et al. 2015.
ScienceDirect Hybrid BCI coupling EEG and EMG
for severe motor disabilities. Procedia Manufacturing.
00(Ahfe): 1301-1308.
[12] S. Grude, M. Freeland, C. Yang. 2013. Controlling
mobile Spykee robot using Emotiv Neuro Headset.
Control Conference (CCC), 32nd Chinese. 5927-5932.
[13] R. Leeb, H. Sagha, R. Chavarriaga et al. 2010.
Multimodal Fusion of Muscle and Brain Signals for a
Hybrid-BCI. Annual International Conference of the
IEEE Engineering in Medicine and Biology. pp.
4343-4346
[14] N. Liu, C. Chiang, H. Chu. 2013. Recognizing the
degree of human attention using EEG signals from
mobile sensors. Sensors. 13(8): 10273-10286.
[15] M. Reaz, M. Hussain, F. Mohd-Yasin. 2006.
Techniques of EMG signal analysis: detection,
processing, classification and applications. Biological
Procedures Online. 8(1): 11-35
[16] M. Ahn M. Lee, J. Choi et al. 2014. A Review of
Brain-Computer Interface Games and an Opinion
Survey from Researchers, Developers and Users.
Sensors. 14(8). 14601-14633.
[17] S. Ge, R. Wang, D. Yu. 2014. Classification of FourClass Motor Imagery Employing Single-Channel
Electroencephalography. PLoS ONE. 9(6): e98019.
[18] Q. Wang, O. Sourina. 2013. Real-time mental
arithmetic task recognition from EEG signals. IEEE
Transactions on Neural Systems and Rehabilitation
Engineering. 21(2): 225-232.
[19] N. Puzi, R. Jailani, H. Norhazman et al. 2013. Alpha
and Beta brainwave characteristics to binaural beat
treatment. Proceedings - 2013 IEEE 9th International
Colloquium on Signal Processing and its
Applications. 14: 344-348.
[20] D. Sinyukov, R. Li, N. Otero et al. 2014. Augmenting
a Voice and Facial Expression Control of a Robotic
Wheelchair with Assistive Navigation. IEEE
international Conference on Systems, Man, and
Cybernetics. 1088-1094.
[21] Gomez-Gil, I. San-Jose-Gonzalez, L. Nicolas-Alonso
et al. 2011. Steering a Tractor by Means of an EMG-

7320

VOL. 11, NO. 11, JUNE 2016

ISSN 1819-6608

ARPN Journal of Engineering and Applied Sciences
©2006-2016 Asian Research Publishing Network (ARPN). All rights reserved.

www.arpnjournals.com
Based Human-Machine Interface. Sensors. 11(12):
7110-7126.
[22] C. Reyes, J. Rugayan, C. Jason et al. 2012. A Study
on Ocular and Facial Muscle Artifacts in EEG Signals
for BCI Applications. TENCON 2012 - 2012 IEEE
Region 10 Conference. pp. 1-6.
[23] A. Ulltveit-moe. 2014. A Comparison of Visual
Evoked Potential (VEP) -Based Methods for the LowCost Emotiv EPOC Neuroheadset Fredrik Tron
Hvaring.
Institutt
for
datateknikk
og
informasjonsvitenskap.
[24] Y. Wang, T. Jung. 2013. Improving Brain-Computer
Interfaces Using Independent Component Analysis.
Springer-Verlag. pp. 1-17.
[25] B. Hamadicharef, H. Zhang, C. Guan et al. 2009.
Learning EEG-based spectral-spatial patterns for
attention level measurement. Proceedings - IEEE
International Symposium on Circuits and Systems. pp.
1465-1468.
[26] P. Mishra, S. Singla. 2013. Artifact Removal from
Biosignal using Fixed Point ICA Algorithm for Preprocessing in Biometric Recognition. Measurement
Science Review. 13(1): 7-11.
[27] S. Dharmasena, K. Lalitharathne. K. Dissanayake et
al. 2013. Online classification of imagined hand
movement using a consumer grade EEG device. IEEE
8th International Conference on Industrial and
Information Systems. pp. 537-541.
[28] H. Siamaknejad, C. Loo, W. Liew. 2014. Fractal
Dimension Methods to Determine Optimum EEG
Electrode Placement for Concentration Estimation.
SCIS & ISIS. pp. 952 – 955.
[29] D. Garrett, D. Peterson, C. Anderson et al. 2003.
Comparison of linear, nonlinear, and feature selection
methods for EEG signal classification. IEEE
Transactions on Neural and Rehabilitation Systems
Engineering. 11(2): 141-144.
[30] T. Hwang, M. King, M. Hwangbo et al. 2014.
Comparative analysis of cognitive tasks for modeling
mental workload with electroencephalogram. IEEE
Engineering in Medicine and Biology Society. pp.
2661-2665.

7321

