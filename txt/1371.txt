sensors
Review

Deep Learning in Physiological Signal Data: A Survey
Beanbonyka Rim 1 , Nak-Jun Sung 1 , Sedong Min 2 and Min Hong 3, *
1
2
3

*

Department of Computer Science, Soonchunhyang University, Asan 31538, Korea;
rim.beanbonyka@gmail.com (B.R.); njsung@sch.ac.kr (N.-J.S.)
Department of Medical IT Engineering, Soonchunhyang University, Asan 31538, Korea;
sedongmin@sch.ac.kr
Department of Computer Software Engineering, Soonchunhyang University, Asan 31538, Korea
Correspondence: mhong@sch.ac.kr

Received: 7 January 2020; Accepted: 9 February 2020; Published: 11 February 2020




Abstract: Deep Learning (DL), a successful promising approach for discriminative and generative
tasks, has recently proved its high potential in 2D medical imaging analysis; however, physiological
data in the form of 1D signals have yet to be beneficially exploited from this novel approach to
fulfil the desired medical tasks. Therefore, in this paper we survey the latest scientific research on
deep learning in physiological signal data such as electromyogram (EMG), electrocardiogram (ECG),
electroencephalogram (EEG), and electrooculogram (EOG). We found 147 papers published between
January 2018 and October 2019 inclusive from various journals and publishers. The objective of this
paper is to conduct a detailed study to comprehend, categorize, and compare the key parameters
of the deep-learning approaches that have been used in physiological signal analysis for various
medical applications. The key parameters of deep-learning approach that we review are the input
data type, deep-learning task, deep-learning model, training architecture, and dataset sources. Those
are the main key parameters that affect system performance. We taxonomize the research works
using deep-learning method in physiological signal analysis based on: (1) physiological signal data
perspective, such as data modality and medical application; and (2) deep-learning concept perspective
such as training architecture and dataset sources.
Keywords: deep-learning; machine learning; physiological signals; 1D signal data analysis

1. Introduction
Deep Learning has succeeded over traditional machine learning in the field of medical imaging
analysis, due to its unique ability to learn features from raw data [1]. Objects of interest in medical
imaging such as lesions, organs, and tumors are very complex, and much time and effort is required
to extract features using traditional machine learning, which is accomplished manually. Thus, deep
learning in medical imaging replaces hand-crafted feature extraction by learning from raw input data,
feeding into several hidden layers, and finally outputting the result from a huge number of parameters
in an end-to-end learning manner [2]. Therefore, many research works have benefited from this novel
approach to apply physiological data to fulfil medical tasks.
Physiological signal data in the form of 1D signals are time-domain data, in which sample data
points are recorded over a period of time [3]. These signals change continuously and indicate the health
of a human body. Physiological signal data categories fall into characteristics such as electromyogram
(EMG), which is data regarding changes to skeleton muscles, electrocardiogram (ECG), which is data
regarding changes to heart beat or rhythm, electroencephalogram (EEG), which is data regarding
changes to the brain measured from the scalp, and electrooculogram (EOG), which is data regarding
changes to corneo-retinal potential between the front and the back of the human eye.

Sensors 2020, 20, 969; doi:10.3390/s20040969

www.mdpi.com/journal/sensors

Sensors 2020, 20, 969

2 of 39

Sensors 2020, 20, 969

2 of 35

Convolutional neural
neural network
network (CNN)
(CNN) is
is the
the most
most successful
successful type
type of
of deep-learning
deep-learning model
model for
for 2D
2D
Convolutional
image
analysis
such
as
recognition,
classification,
and
prediction.
CNN
receives
2D
data
as
an
input
image analysis such as recognition, classification, and prediction. CNN receives 2D data as an input
and extracts
extracts high-level
high-level features
features though
though many
many hidden
hidden convolution
convolution layers.
layers. Thus,
Thus, to
to feed
feed physiological
physiological
and
signals
into
a
CNN
model,
some
research
works
have
converted
1D
signals
into
2D
data
[4].
signals into a CNN model, some research works have converted 1D signals into 2D Therefore,
data [4].
in
this
paper
we
survey
147
contributions
which
have
found
highly
accurate
and
significant
results
of
Therefore, in this paper we survey 147 contributions which have found highly accurate and
physiological
signal
using asignal
deep-learning
approach.
We overview
and explain
solutions
significant
results
ofanalysis
physiological
analysis using
a deep-learning
approach.
Wethese
overview
and
and
contributions
in
more
detail
in
Section
3,
Section
4,
and
Section
5.
explain these solutions and contributions in more detail in Sections 3, 4, and 5.
We collected
collectedpapers
papersvia
viasearch
search
engine
PubMed
with
keywords
combining
“deep
learning”
We
engine
PubMed
with
keywords
combining
“deep
learning”
and
and
a
type
of
physiological
signal
such
as
“deep
learning
electromyogram
emg”,
“deep
learning
a type of physiological signal such as “deep learning electromyogram emg”, “deep learning
electrocardiogram ecg”,
ecg”, “deep
“deep learning
learning electroencephalogram
electroencephalogram eeg”,
eeg”, and
and “deep
“deep learning
learning
electrocardiogram
electrooculogram eog”
eog”[5].
[5].We
We
found
papers
published
between
January
and October
electrooculogram
found
147147
papers
published
between
January
2018 2018
and October
2019
2019
inclusive
from
various
journals
and
publishers.
As
illustrated
in
Figure
1a,
the
works
on EMG,
inclusive from various journals and publishers. As illustrated in Figure 1a, the works on EMG,
ECG,
ECG,EEG
andusing
EEG using
a deep-learning
approach
have rapidly
increased
2018
andwhile
2019, EOG
whileand
EOG
and
a deep-learning
approach
have rapidly
increased
in 2018inand
2019,
a
and a combination
of those
signals
are limited.
Within
the works
on EEG,
has been
an increase
by
combination
of those
signals
are limited.
Within
the works
on EEG,
therethere
has been
an increase
by 13,
13, from
33 works
in 2018
works
2019.
shown
Figure1b,
1b,among
amongthe
thefour
fourdata
datamodalities
modalities of
of
from
33 works
in 2018
to to
46 46
works
in in
2019.
AsAs
shown
inin
Figure
physiological signals,
in in
79 79
works
on aon
variety
of applications.
For ECG,
there
physiological
signals,EEG
EEGhas
hasbeen
beenconducted
conducted
works
a variety
of applications.
For ECG,
have
47
works
conducted.
Fifteen
works
apply
to
EMG,
1
work
to
EOG,
and
5
works
to
a
combination
there have 47 works conducted. Fifteen works apply to EMG, 1 work to EOG, and 5 works to a
of those signals.
combination
of those signals.

(a)

(b)

Figure
for papers
papers using
usingaadeep-learning
deep-learningapproach
approachinin
physiological
signal
data
grouped
Figure 1.
1. Statistics
Statistics for
physiological
signal
data
grouped
by:
by:
(a)
year
of
publication;
and
(b)
data
modality.
(a) year of publication; and (b) data modality.

There are many papers that prove that the deep-learning
deep-learning approach
approach is more successful than
There
traditional machine
machine learning
learning for
for both implementation
implementation and performance.
performance. However,
However, this
this paper
paper does
traditional
not aim to study the comparison between them. In
In this
this paper,
paper, we
we review
review some
some recent
recent methods
methods of
not
deep learning
learning in
in the
the last
last two years that analyze
analyze the physiological
physiological signals.
signals. We
We only
only compare
compare the
the key
key
deep
data type,
type, deep-learning
deep-learning task,
task, deep-learning
deep-learning
parameters within deep-learning methods such as input data
model, training
training architecture,
architecture, and
and dataset
dataset sources
sources which
which are
are involved
involved in
in predicting
predicting the
the state
state of
of hand
model,
motion, heart disease, brain disease, emotion, sleep stages, age, and gender.
2. Related
Related Works
Works
2.
There are
are two
two types
types of
There
of scientific
scientific survey
survey in
in deep-learning
deep-learning approaches
approaches regarding
regarding physiological
physiological
signal data
data for
for healthcare
healthcare application
application between
between January
January 2018
signal
2018 and
and October
October 2019
2019 inclusive.
inclusive.
The first
first is
is oriented
oriented to
to medical
medical fields
fields such
such as
as aa taxonomy
based on
on medical
medical tasks
tasks (i.e.,
(i.e., disease
disease
The
taxonomy based
detection,
computer-aided
diagnosis,
etc.),
or
a
taxonomy
based
on
anatomy
application
areas
(i.e.,
detection, computer-aided diagnosis, etc.), or a taxonomy based on anatomy application areasbrain,
(i.e.,
eyes, chest,
lung,lung,
liver,liver,
kidney,
heart,
etc.).etc.).
Faust
et et
al al
[6][6]collected
regarding
brain,
eyes, chest,
kidney,
heart,
Faust
collected53
53research
research papers
papers regarding
physiological signal
signal analysis
analysis using
using deep-learning
deep-learning methods
methods published
published from
from 2008
2008 to
to 2017
2017 inclusive.
inclusive.
physiological
This work
work initially
initially introduced
introduced deep-learning
deep-learning models
models such
such as
as auto-encoder,
auto-encoder, deep
deep belief
belief network,
network,
This
restricted
Boltzmann
machine,
generative
adversarial
network,
and
recurrent
neural
network.
it
restricted Boltzmann machine, generative adversarial network, and recurrent neural network.Then,
Then,

it categorized the papers based on types of physiological signal data modalities. Each category points
out the medical application, the deep-learning algorithm, the dataset, and the results.

Sensors 2020, 20, 969

3 of 39

categorized the papers based on types of physiological signal data modalities. Each category points
out the medical application, the deep-learning algorithm, the dataset, and the results.
The second is oriented to deep-learning techniques such as a taxonomy based on deep-learning
architectures (i.e., AE, CNN, RNN, DBN, GAN, U-Net, etc.), or the workflow of deep-learning
implementation for medical application. Ganapathy et al [3] conducted a taxonomy-based survey on
deep learning of 1D biosignal data. This work collected 71 papers from 2010 to 2017 inclusive. Most of
the collected papers were published on ECG signals. The goal of the survey was initially to review
several techniques for biosignal analysis using deep learning. Then, it classified deep-learning models
based on origin, dimension, type of biosignal as an input data, the goal of application, dataset size,
type of ground-truth data, and learning schedule of the network. Tobore et al [7], pointed out some
biomedical domain considerations in deep-learning intervention for healthcare challenges. It presented
the implementation of deep learning in healthcare by categorizing it into biological system, e-health
record, medical image, and physiological signals. It ended by introducing research directions for
improving health management on a physiological signal application.
3. Physiological Signal Analysis and Modality
Physiological signal analysis is a study estimating the human health condition from a physical
phenomenon. There are three types of measurement to record physiological signals: (1) reports;
(2) reading; and (3) behavior [8]. The “report” is a response evaluation of questionnaire from subjects
who participants in rating their own physiological states. The “reading” is recorded information
that is captured by a device to read the human body state such as muscle strength, heartbeat, brain
functionality, etc. The “behavior” measurement records a variety of actions such as movement of the
eyes. In this paper, we did not review the “report” measurement because the response of “report”
is a more biased, less precise question and has broader diversity of question scale. We focus on the
technique of “reading” and “behavior” measurement in which the response results are in a signal
modality of EMG, ECG, EEG, EOG, or a combination of these signals.
Table 1 describes the physiological signal modality which was used to implement medical
application. The muscle tension pattern of the EMG signal provides hand motion and muscle activity
recognition. The variant of heartbeat or heart rhythm provides heart disease, sleep stage, emotion,
age, and gender classification. The diversity of brain response of EEG signal provides brain disease,
emotion, sleep-stage, motion, gender, words, and age classification. The changes of eye corneo-retinal
potential of EOG signal provides sleep-stage classification.
Table 1. Medical application in physiological signal analysis.
Signal Modality

Medical Application

EMG

Hand motion recognition [9–17], Muscle activity recognition [18–23]

ECG

Heartbeat signal classification [24–48], Heart disease classification
[49–63],
Sleep-stage classification [64–68], Emotion classification [69],
age and gender prediction [70]

EEG

Brain functionality classification [71–91], Brain disease classification
[92–121], Emotion classification [122–129], Sleep-stage classification
[130–141],
Motion classification [142–145], Gender classification [146],
Words classification [147], Age classification [148]

EOG

Sleep-stage classification [149]

Combination of signals

Sleep-stage classification [150–154]

This section presents a categorization of physiological signal data modality regarding the various
deep-learning models. We demonstrate key contributions in medical application and performance

Sensors 2020, 20, 969

4 of 39

of systems. We taxonomize contributions such as deep learning on electromyogram (EMG), deep
learning on electrocardiogram (ECG), deep learning on electroencephalogram (EEG), deep learning on
electrooculogram (EOG), and deep learning on a combination of signals, as shown in Table 2.
Table 2. Table structure based on signal modality and dataset source.
Signal Modality

Public Dataset

Private Dataset

Hybrid Dataset

EMG

Table 3

Table 4

ECG

Table 5

Table 6

Table 7

EEG

Table 8

Table 9

Table 10

EOG

Table 11

Combination of signals

Table 12

Table 3. Medical application in EMG analysis using a public dataset source.
Medical
Application

Medical Task

Gesture
recognition [10]

Hand motion
recognition

Gesture
recognition [11]

DL Model

CNN+RNN

CNN

Dataset Source

No. of
Subjects

Performance

NinaProDB1

27

Accuracy = 87.0%

NinaProDB2

40

Accuracy = 82.2%

BioPatRec
sub-database

17

Accuracy = 94.1%

CapgMyo
sub-database

18

Accuracy = 99.7%

csl-hdemg databases

5

Accuracy = 94.5%

NinaPro

128

Accuracy = 85.78%

BioPatRec

53

Accuracy = 94.0%

MYO

17

Accuracy = 98.31%

NinaPro

10

Accuracy = 68.98%

GFM

NinaPro database

10

Accuracy = 63.86 ± 5.12%

CNN+RNN

Ninapro project
dataset

78

Accuracy = 87.3 ± 4.9%

Gesture signal
classification [12]

CNN

Hand gesture
classification [13]
Hand movement
classification [16]

We do both a quantitative and qualitive comparison of the deep-learning model. For quantitative
comparison, the number of deep-learning models that have been used in medical application is
illustrated. For qualitative comparison, since the performance criterion is not provided uniformly,
we assume an accuracy value as a base criterion for an overall performance comparison.

Sensors 2020, 20, 969

5 of 39

Table 4. Medical application in EMG analysis using Private dataset source.
Medical
Application

Hand motion
recognition

Muscle activity
recognition

Medical Task

DL Model

Dataset Source

No. of
Subjects

Performance

Chinese sign language
recognition [9]

DBN

6-D inertial sensor (3D-ACC and
3D-GYRO)

8

Accuracy = 95.1%
(user-dependent test), Acc =
88.2% (user-independent test)

Hand-grasping classification [14]

SAE

MYO

15

Accuracy = 95%,
SD = 3.58~1.25%

Hand motion classification [15]

CNN

MYO

7

mean CE ± SD = 9.79 ± 4.57

Limb movement estimation [17]

CNN+RNN

EMG system (NCC Medical Co.,
LTD, Shanghai, China)

8

mean R2 = 90.3 ± 4.5%

Multi-labeled movement
information extraction [18]

CNN

ELSCH064NM3 from OT
Bioelettronica, Turin, Italy

14

mean exact match rate = 78.7%
and a mean Hamming
loss = 2.9%

Muscle activity detection [19]

RNN

Vastus Lateralis and the Lateral
Hamstring of a runner

N/A

Signal-to-noise ration < 5

Musculoskeletal force prediction
[20]

CNN

Trigno Wireless EMG system,
Delsys, USA

156

RMSE = 0.25,
Std. = 0.13

Grapevine NIP system (Ripple,
Salt Lake City, UT, USA)

2

Prosthetic limb control,
Movement Intent decoder [21]

CNN
LSTM

NMSE = 0.033 ± 0.017
NMSE = 0.096 ± 0.013

Real-time, simultaneous
myoelectric control system [22]

CNN

Eight pairs of
bipolar surface electrodes
(g.HiAmp, g-tec Inc.)

17

Accuracy = 91.61%,
Standard error = 0.39

Wave form identification [23]

CNN

Tokushima University Hospital

83

Accuracy = 86% (test set),
Accuracy = 100% (train set)

Sensors 2020, 20, 969

6 of 39

Table 5. Medical application in ECG analysis using a public dataset source.
Medical Application

Heartbeat signal
classification

Medical Task

DL Model

Anomaly class
identification [26]

LSTM+SVM,
LSTM+MLR, LSTM+MLP

Dataset Source
MIT-BIH Arrhythmia

No. of Subject/Data

Performance

43 input features

LSTM+SVM = 42.86% LSTM+MLR
= 51.43% LSTM+MLP = 50.0%

Atrial fibrillation
detection [27]

STFT+CNN, SWT+CNN

MIT-BIH Atrial fibrillation

23 annotated ECG
recordings

STFT+CNN:
Sensitivity = 98.34%,
Specificity = 98.24%,
Accuracy = 98.29%.
SWT+CNN:
Sensitivity = 98.79%,
Specificity = 97.87%, Accuracy =
98.63%

CAD ECG signals
detection [28]

LSTM+CNN

PhysioNet

47

Accuracy = 99.85%

Congestive heart failure
detection [30]

BIDMC-CHF

15

Accuracy = 99.22%

LSTM

MIT-BIH NSR

18

Accuracy = 98.85%

Fantasia

40

Accuracy = 98.92%

PhysioNet

42

Correlation (r = 0.85)

23 records (test set)

P-on = 0.4 ± 14.4
P-peak = −0.4 ± 10.1
P-off = −2.0 ± 12.7
QRS-on = −0.7 ± 10.9
QRS-off = −4.8 ± 13.1
T-peak = −0.3 ± 10.5
T-off = −0.3 ± 18.5

Dofetilide plasma
concentrations prediction
[31]

CNN

ECG Characteristic
detection [32]

CNN+RA

QT database (MIT-BIH
Arrhythmia+ ST-T
Database+ several other
ECG databases)

ECG signal compression
[33]

AE

MIT-BIH arrhythmia

48 records

Compression ratio = 106.45,
Root mean square difference =
8.00%

Electrocardiogram
diagnosis [34]

CNN+BRNN

Chinese Cardiovascular
Disease Database

19K

Accuracy = 87.69%

Sensors 2020, 20, 969

7 of 39

Table 5. Cont.
Medical Application

Heartbeat signal
classification

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

Heartbeat classification
for continuous monitoring
[35]

LSTM

MIT-BIH arrhythmia

N/A

VEB:
Accuracy = 99.2%,
Sensitivity = 93.0%,
Specificity = 99.8%
F1 = 95.5%
SVEB:
Accuracy = 98.3%,
Sensitivity = 66.9%,
Specificity = 99.8%
F1 = 78.8%

Heartbeat classification
[36]

CNN

MIT-BIH Arrhythmia

48 records

Accuracy = 96%,
F1-score = 90%

Heartbeat types
classification [37]

CNN+RBM

MIT-BIH arrhythmia

47

AUC = 0.999

Heartbeats classification
[38]

DBLSTM-WS

MIT-BIH arrhythmia

48 records

Accuracy = 99.39%

Heartbeats classification
[39]

CNN

MIT-BIH arrhythmia

48 records

Accuracy = 98.6%

Multi-lead ECG
classification [42]

DL-CCANet, TL-CCANet

MIT-BIH database

48 records

DL-CCANet: Accuracy = 95.2%

INCART database

78 records

TL-CCANet:
Accuracy = 95.52%

MIT-BIH arrhythmia

119 records

Precision = 100%,
Recall = 100%,
Accuracy = 100%

44 records

Ventricular ectopic beats
(Acc = 93.63%),
Supraventricular ectopic beats
(Acc = 95.57%)

Premature ventricular
contraction classification
[45]
Ventricular and
supraventricular heart
beats detection [47]

EBR

RBM+DBM

MIT-BIH database

Sensors 2020, 20, 969

8 of 39

Table 5. Cont.
Medical Application

Heart disease
classification

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

Arrhythmia classification
[49]

AE+LSTM

MIT-BIH arrhythmia

47

Accuracy = 99.0%,
Root mean square
difference = 0.70%

Arrhythmia diagnosis [50]

CNN+LSTM

MIT-BIT arrhythmia

47

Accuracy = 98.10%,
Sensitivity = 97.50%,
Specificity = 98.70%

Arrhythmias detection
[51]

CNN

MIT-BIH arrhythmia

48

DB1:
Accuracy = 97.87%
DB2:
Accuracy = 99.30%

Atrial fibrillation (AF)
automatically prediction
[52]

CNN

MIT-BIH

139 records

Accuracy = 98.7%,
Sensitivity = 98.6%,
Specificity = 98.7%.

Beat-wise arrhythmia
diagnosis [53]

AE+U-net

MIT-BIH AFDB + PAFDB
+ MIT-BIH NSRDB

74 (evaluate), 65 (test)

Accuracy = 98.7%
Sensitivity = 98.7%
Specificity = 98.6%

Cardiac Arrhythmia
classification [54]

MLP, CNN

Cardiac arrhythmias
classification [55]

1D-CNN

MIT-BIH Arrhythmia

45

Accuracy = 91.33%

Cardiologist-Level
Arrhythmia detection and
classification [56]

CNN

Ziomonitor (iRhythm
Technologies Inc, San
Francisco, CA)

53,877 patients

AUC = 0.97,
Fi-score = 0.837,
Sensitivity = 0.780

Early detection of
myocardial ischemia [58]

CNN

PhysioNet

N/A

AUC = 89.6%
Sensitivity = 84.4%
Specificity = 84.9%,
F1-score = 89.2%

Heart Disease
classification [59]

Faster RCNN

MIT-BIH

47

Accuracy = 99.21%

Heart Diseases
classification [60]

LSTM

PhysioNet

CNN

Creighton University
Ventricular
Tachyarrhythmia +
MIT-BIH Malignant
Ventricular Arrhythmia

Sudden cardiac arrests
(SCA) detection [63]

PhysioBank

208 ECG recordings

Kaggle

Accuracy = 88.7%
Accuracy = 83.5%

Accuracy = 98.4%

35 records +
22 records

Accuracy = 99.26%
Sensitivity = 97.07%
Specificity = 99.44%

Sensors 2020, 20, 969

9 of 39

Table 5. Cont.
Medical Application

Medical Task
Apnea detection [64]

Sleep-stage classification

DL Model
CNN

Dataset Source
PhysioNet

No. of Subject/Data

Performance

35

Accuracy = 94.4%
Sensitivity = 93.0%
Specificity = 94.9%

Signal quality and sleep
position classification [66]

CNN

MIT-BIH arrhythmia

12

C1 class:
Precision = 0.99,
Recall = 0.99
Sleep position:
Precision = 0.99,
Recall = 0.99

Sleep Apnea detection
[68]

CNN

PhysioNet Apnea +
University College Dublin

70 records + 25 records

Accuracy = 87.6%
Sensitivity = 83.1%
Specificity = 90.3%
AUC = 0.950

Sensors 2020, 20, 969

10 of 39

Table 6. Medical application in ECG analysis using Private dataset source.
Medical Application

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

6 types of ECG
abnormalities
classification [24]

CNN

Telehealth Network of Minas
Gerais, Brazil

1,558,415 patients

F1-score > 80%
Specificity > 99%

Cardiologs and veritas
detection [29]

CNN

ECGs recorded in the ED of
HCMC

1500 records

Cardiologs:
Accuracy = 92.2%
Sensitivity = 88.7%
Specificity = 94.0%
Veritas:
Accuracy = 87.2%
Sensitivity = 92.0%
Specificity = 84.7%

Left ventricular systolic
dysfunction detection [41]

CNN

Mayo Clinic ECG

16 056 adult patients

Accuracy = 86.5%
Sensitivity = 82.5%
Specificity = 86.8%
Positive prediction = 0.74,
Negative prediction = 0.96,
Sensitivity = 0.88,
Specificity = 0.89,
F1-score = 0.80,
AUC = 0.93
Accuracy = 0.73

Heartbeat signal
classification

Noise detection and
screening model [43]

CNN

trauma intensive-care unit

165,142,920 ECG II
(10-second lead II
electrocardiogram)

Scalogram of ECG
classification [46]

ResNet

Physikalisch-Technische
Bundesanstalt (PTB)-ECG

290

Chosun University (CU)-ECG

100

Accuracy = 0.94

Kasturba Medical Hospital
(KMH), Manipal, India

30

Accuracy = 97.62%,
Sensitivity = 100%

Heart failure
database (HFDB)

128 ECG pairs

AUC = 84%

Ischemia database (IDB)

482 ECG
pairs

AUC = 83%

CNN+LSTM

Zephyr BioHarness 3.0

18

Accuracy = 83.9%,
F1-score = 0.81,
AUC = 0.92

Sleep apnea detection [67]

DNN, 1D-CNN, 2D-CNN,
RNN, LSTM, GRU

SA dataset

86

Accuracy = 99.0%,
Recall = 99.0% (1D-CNN and GRU)

Stressful state
classification [69]

RNN+CNN

Kwangwoon University
in Korea

13

Accuracy = 87.39%

KU Leuven University in
Belgium

9

Accuracy = 73.96%

Mayo Clinic digital data vault

275,056

Accuracy = 90.4%,
ACU = 0.97 (independent test data)

Diabetic subject detection
[57]

1D-CNN

Heart failure detection on
patients in ischemia and
post-infarction [61]

CNN

Mental stress recognition
[62]
Sleep-stage classification

Emotion classification

Heart disease
classification

Age and gender
prediction

Age and gender
prediction [70]

CNN

Sensors 2020, 20, 969

11 of 39

Table 7. Medical application in ECG analysis using Hybrid dataset source.
Medical Application

Heartbeat signal
classification

Medical Task

Ventricular fibrillation
detection [48]

DL Model

1D-CNN+ LSTM

Dataset Source

No. of
Subject/Data

Performance

PhysioNet MIT-BIH Malignant Ventricular
Arrhythmia + Creighton University
Ventricular Tachyarrhythmia +
American Heart Association ECG Database

N/A

BAC = 99.3%,
Sensitivity = 99.7%,
Specificity = 98.9%

OHCA patients

N/A

BAC = 98.0%,
Sensitivity = 99.2%,
Specificity = 96.7%

Sensors 2020, 20, 969

12 of 39

Table 8. Medical application in EEG analysis using Public dataset source.
Medical Application

Medical Task

1D-CNN+RNN

Event-related potential (ERP) detection
and analysis [76]

CNN

Brain activity detection [81]

CNN

Dataset Source

No. of Subject/Data

Performance

TUH Abnormal EEG Corpus

1488 abnormal + 1529 normal
EEG sessions

Accuracy = 76.9%

BCI competition II and III

2

AUC = 0.825 ± 0.064

BCIC IV 2a. BCI competition IV
data set 2a

9

Accuracy = 69%

BCIC IV 2b. BCI competition IV 2b

9

Accuracy = 83%

Upper limb movement

15

Accuracy = 31%

Motor Imagery classification [83]

RNN+3D-CNN

BCI competition IV-2a 4-class
Motor Imagery (MI) dataset

9

Accuracy = 74.46%

Motor Imagery EEG classification [85]

CNN

BCI Competition IV

9

Accuracy = 87.94%

BCI competition IV 2a

9

Accuracy = 74.6%
Precision = 73.9%
Recall = 74.7%
F1-score = 0.743

HGD dataset

14

Accuracy = 93.7%
Precision = 73.7%
Recall = 93.7%
F1-score = 0.937

BCI Competition Dataset 2a

9

Mean kappa = 0.61
St. Dev = 0.101

Motor Imagery EEG Decoding [86]

Brain functionality
classification

DL Model

EEG session normal or abnormal
detection [74]

Multiclass Motor Imagery classification
[87]

CP-MixedNet

CNN

Online decoding of Motor Imagery
movement [88]

LSTM, CNN, RCNN

BCI Competition IV

20

LSTM:
Accuracy = 66.97 ± 6.45%
CNN:
Accuracy = 66.2 ± 7.21%
RCNN:
Accuracy = 77.72 ± 6.5%

Prediction of bispectral index during
target-controlled infusion of propofol
and remifentanil [89]

LSTM

vitaldb

180 data points

concordance correlation
coefficient (95% CI) = 0.561
(0.560 to 0.562)

8

EEGNet:
SNRs = 20.43
DeepCNN:
SNRs = 20.50
ShallowCNN:
SNRs = 20.53

26

EEGNet:
SNRs = 20.26
DeepCNN:
SNRs = 20.39
ShallowCNN:
SNRs = 20.31

9

EEGNet:
SNRs = 25.50
DeepCNN:
SNRs = 25.57
ShallowCNN:
SNRs = 25.60

P300 Evoked Potentials (P300)

EEG-based BCIs classification [91]

CNN

Feedback Error-Related Negativity
(ERN)

MI

Sensors 2020, 20, 969

13 of 39

Table 8. Cont.
Medical Application

Medical Task

DL Model

No. of Subject/Data

Performance

University of Bonn

28

AUC = 0.9703
Accuracy = 90%

HMM+SDAE

TUH EEG Corpus

13,500 patients

Sensitivity > 90%
Specificity < 5%

Depression screening [97]

CNN

Bonn University

15 normal + 15 depressed
patients

Left hemisphere:
Accuracy = 93.5%
Right hemisphere:
Accuracy = 96.0%

EEG-based epileptic seizure detection
[102]

CNN

CHB-MIT dataset

23

Accuracy = 98.3%
Sensitivity = 96.7%
Specificity = 99.1%

Bonn University

A: healthy 100 segment
B: healthy 100 segment
C: patient 100 segment
D: patient 100 segment
E: patient 100 segment

A-E:
Accuracy = 99.5%
A-D:
Accuracy = 100%
D-E:
Accuracy = 98.5%
A-D-E:
Accuracy = 99.0%
A-B-C-D-E:
Accuracy = 93.6%

Bern-Barcelona EEG

5

Accuracy = 98.9 ± 0.08%

Epileptic Seizure Recognition
datasets

500

Accuracy = 99.8 ± 0.13%

Aberrant epileptic seizure identification
[92]

CNN+LSTM

Brain disorders diagnosis [95]

Epilepsy detection by using scalogram
[104]

CNN

Epileptic EEG recording classification
[106]

CNN

Dataset Source

Brain disease
classification

Epileptic Seizure prediction [107]

CNN

Seizure Prediction Challenge

5

AUC = 0.79

Epileptic Seizure prediction [108]

CNN+LSTM

CHB-MIT EEG dataset

22

Accuracy = 99.6%
Accuracy = 100%
Sensitivity = 100%
Specificity = 100%

Epileptic seizures detection using EEG
[110]

LSTM

Bonn University

A: healthy 100 segment
B: healthy 100 segment
C: patient 100 segment
D: patient 100 segment
E: patient 100 segment

Epileptic seizures prediction [111]

LSTM

Open CHB-MIT Scalp

23

Sensitivity = 100%
Specificity = 99.28%

Seizure detection in multimodal
EEG-fNIRs [114]

LSTM

BCI competition IV 2b dataset

40

Sensitivity = 89.7%
Specificity = 95.5%

Seizure Detection [118]

CNN+AE

CHB-MIT dataset

23

Accuracy = 94.37%
F1-score = 85.34%

University of Bonn

A: healthy 100 segment
B: healthy 100 segment
C: patient 100 segment
D: patient 100 segment
E: patient 100 segment

Accuracy = 95.54%
AUC = 0.9582

Seizure detection [119]

LSTM

Sensors 2020, 20, 969

14 of 39

Table 8. Cont.
Medical Application

Emotion classification

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

Emotion recognition [122]

2D-CNN

DEAP dataset

32

Accuracy = 73.4%

Emotion Recognition [124]

RNN

SJTU emotion EEG dataset

15

Accuracy = 89.5%

CK+ facial expression

327 images

Accuracy = 95.4%

Fear level classification based on
emotional dimensions [125]

DNN

DEAP database

32

Accuracy = 59.84%
F1-score = 58.78%

Human emotion recognition [126]

RBM

SEED-IV dataset

15

Accuracy = 85.11%

Recognition of emotion [127]

DBN-GC+RBM

DEAP dataset

32

Arousal:
Accuracy = 75.92%
Valence:
Accuracy = 76.83%

Relaxation classification [128]

CNN

OpenBCI

7

1s temporal window:
Accuracy = 55.46%
2s temporal window:
Accuracy = 98.96%

Valence and arousal classification [129]

LSTM

DEAP dataset

32

Arousal:
Accuracy = 74.65%
Valence:
Accuracy = 78%

Montreal Archives of Sleep Studies
dataset

19

Precision = 0.3
Recall = 0.95

Stanford Sleep Cohort dataset

26

Precision = 0.58
Recall = 0.43

Wisconsin Sleep Cohort dataset

30

Precision = 0.79
Recall = 0.1

MESA dataset

1000

N/A

Montreal archive of sleep studies

19

Sensitivity = 90.07 ± 2.16%
Specificity = 96.19 ± 0.71%
FDR = 30.36 ± 5.88%
F1-score = 0.75 ± 0.05
AUROC = 98.97 ± 0.13%

DREAMS database

8

Sensitivity = 77.85 ± 4.28%
Specificity = 94.2 ± 1.26%
FDR = 61.96 ± 7.39%
F1-score = 0.48 ± 0.07
AUROC = 95.97 ± 0.96%

Detect multiple sleep micro-events in
EEG [130]

Sleep-stage classification

Real-time detection of sleep spindles
[133]

CNN

CNN+RNN

Sleep-stage classification [135]

CNN

PhysioNet
(SleepEDF dataset)

20

Setting 1:
Accuracy = 79.8%
Setting 2:
Accuracy = 82.6%

Sleep-stage classification [136]

RNN+SVM

PhysioNet
(Sleep-EDF dataset)

20

Setting 1:
Accuracy = 79.1%
Setting 2:
Accuracy = 82.5%

Sleep-stage classification [137]

CU-CNN

UCD dataset

25

Accuracy = 87%
Kappa = 0.8

Sensors 2020, 20, 969

15 of 39

Table 8. Cont.
Medical Application

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

MIT-BIH datasets

16 records

Accuracy = 99.9%
Kappa = 0.904

Sleep-stage scoring/detection [138]

CNN+RNN

PhysioNet (Sleep-EDF datasets)

258

Accuracy = 84.26%
F1-score = 79.66%
Kappa = 0.79

Sleep stages classification from
single-channel EEG [139]

CNN

PhysioNet

8

Accuracy = 98.10%, 96.86%,
93.11%, 92.95%, 93.55%,
Kappa = 0.98%, 0.94%, 0.90%,
0.86%,0.89%,

Motion classification

Movement intention recognition of
disable person [143]

LSTM

MI-based eegmmidb dataset

12

Accuracy = 68.20%

Gender classification

Gender prediction from brain rhythms
[146]

CNN

Brain Resource International
Database

1308

Accuracy > 80%
(p < 10−5 )

P300 EEG dataset

9

Accuracy = 97.5%

EEG recording of individuals with
alcoholism and control
individuals

64

Accuracy = 95%

Sleep-stage classification

Words classification

Words recognition of speech-impaired
people from brain-generated signals
[147]

DN-AE-NTM

EEGMMIDB

109

Accuracy = 98%

MNIST

60K samples

Accuracy = 99.4%

ORL

10 images

Accuracy = 99.1%

Sensors 2020, 20, 969

16 of 39

Table 9. Medical application in EEG analysis using Private dataset source.
Medical Application

Medical Task

DL Model

Dataset Source

No. of
Subject/Data

Performance

Cerebral Dominance detection [71]

CNN+SVM

Firat University Hospital
(Nicolet EEG v32 device)

67

AUC = 0.83 ± 0.05

“Hamrah
Clinic” of Tabriz, Iran

20

Accuracy = 83%
Sensitivity = 84%
Specificity = 86%
F1-score = 84%

SAE, DCNN

National Institute of Technology
Raipur (ctiCAP Xpress V-amp EEG
recorder)

10

Accuracy = 88.22%

Walking Imagery Evaluation [75]

MMDPN

Biosemi ActiveTwo
system

9

Text-MMDPN:
AUC = 0.7984
VE-MMDPN:
AUC = 0.9424

EEG event-related classification on
children with ADHD from healthy
controls [77]

CNN+RNN

Technical University of Dresden

144

Accuracy = 83%

Focal epileptiform discharges
detection [78]

CNN+RNN

Department of Clin.
Neurophysiology and Neurology,
Medisch Spectrum Twente,
Enschede, The Netherlands

50

AUC = 0.94
Sensitivity = 47.4%
Specificity = 98.0%

Human Mental workload
Recognition [79]

EL-SDAE

Simulated Human Machine
systems

8

Accuracy = 92.02%

Identify patterns of brain activity of
children at idle time and playing
videogame time [80]

CNN

University of Houston

233

Accuracy = 67%

Cross-task mental workload
assessment [82]

RNN+3D-CNN

Tsinghua University

20

Accuracy = 88.9%,

Spectral and temporal feature
learning for mental workload
assessment [90]

CNN+TCN

Tsinghua University

17

Accuracy = 91.9%,

Complexity of peri-perceptual
processes of familiarity detection
[72]
Devanagari script input-based P300
speller detection [73]

Brain functionality
classification

SNN

Sensors 2020, 20, 969

17 of 39

Table 9. Cont.
Medical Application

Medical Task

Automatic diagnosis of unipolar
depression [93]

Brain disease
classification

DL Model

1D-CNN,
1D-CNN+LSTM

Dataset Source

hospital
Universiti Sains Malaysia (HUSM)

No. of
Subject/Data

Performance

63

1D-CNN:
Accuracy = 98.32%
Precision = 99.78%
Recall = 98.34%
F-score = 97.65%
1D-CNN+LSTM:
Accuracy = 95.97%
Precision = 99.23%
Recall = 93.67%
F-score = 95.14%

Brain disease detection [94]

CNN, RNN, DNN

EEG data of the University of
California Irvine

122

CNN:
F1-score = 0.94
RNN:
F1-score = 0.73
DNN:
F1-score = 0.70

Confusion state induction and
detection [96]

CNN

Emotiv Epoc+

16

Accuracy = 71.36%

Early Alzheimer’s disease
diagnosis [98]

DCssCDBM

Beijing Easy monitor Technology

14

Accuracy = 95.04%

Early prediction of epileptic seizure
[99]

CNN+LSTM

Department of Neurology at the
First Affiliated Hospital of
Xinjiang Medical University

15

Accuracy = 93.40%
Sensitivity = 91.88%
Specificity = 86.13%

Early stage Alzheimer disease
detection [100]

CNN

Chosun University Hospital
(CUH, Gwangju, S. Korea)
and Gwangju Optimal Dementia
Center located in Gwangju
Senior Technology Center
(Gwangju, S. Korea)

10

Accuracy = 59.4%
Std. = 22.7

Epileptic discharge detection [105]

CNN

EEG/fMRI study

30

Sensitivity = 84.2%

Epileptic seizure prediction [109]

CNN

Intracranial electrodes (magenta
circles)

10

Sensitivity = 69%

Identifying Schizophrenia from
EEG connectivity Patterns [112]

CNN

Lomonosov Moscow State
University

84

Accuracy = 91.69%

Sensors 2020, 20, 969

18 of 39

Table 9. Cont.
Medical Application

Brain disease
classification

Emotion classification

Sleep-stage classification

Medical Task

DL Model

Dataset Source

No. of
Subject/Data

Performance

Seizure classification [113]

CNN

Diagnosis of medication refractory
TLE based on International League
Against Epilepsy (ILAE) criteria

50

Positive Predictio n = 88 ± 7%,
Negative Prediction = 79 ± 8%,
Accuracy < 50%

Seizure detection [117]

3D-CNN

Hospital of
Xinjiang Medical University

13

Accuracy = 90.00%
Sensitivity = 88.90%
Specificity = 93.78%

Seizure detection [120]

CNN

Department of Physiology, College
of Medicine, The Catholic
University of Korea

249

Sensitivity = 100%
Positive Prediction = 98%

Tracking both the level of
consciousness and delirium [121]

CNN+LSTM

Partners Institutional Review
Board (IRB)

Human Intention Recognition [4]

CNN+LSTM

BCI2000 instrumentation

108 subjects,
3,145,160 EEG
records

Accuracy = 98.3%

Driving Fatigue detection from
EEG [131]

PCANet+SVM

Guangdong Provincial Work Injury
Rehabilitation Center

6

Accuracy = 95%

174

Accuracy = 70%
Sensitivity = 69%
Specificity = 3%
AUC = 0.80

CNN

Department of Neurology in
Massachusetts General Hospital

8522 EEGs

EEGs:
AUC = 0.917
EEGs+Age:
AUC = 0.924
EEGs+Age+Sleep:
AUC = 0.925

Sleep stages classification [141]

CNN+LSTM

Chronobiology and Sleep Research,
Institute of Pharmacology and
Toxicology, University of Zurich,
Zurich, Switzerland

75 records

Kappa = 0.8

Problem-solving behavioral pattern
characterization [144]

CNN

Fakultät Management und Vertrieb,
Hochschule Heilbronn Campus
Schwäbisch Hall,
74523 Schwäbisch Hall, Germany

26

Accuracy = 99%

CNN

Center
for Advanced Research in Sleep
Medicine of the
Hôpital du SacrèCoeur de Montréal

212

Accuracy = 80 ± 1%
AUC = 87 ± 1%

Identifying abnormal EEGs, age
and sleep-stage classification [132]

Motion classification
Rapid eye movement behavior
disorder [145]

Sensors 2020, 20, 969

19 of 39

Table 10. Medical application in EEG analysis using Hybrid dataset source.
Medical Application

Brain disease
classification

Sleep-stage classification

Age classification

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

BCI Competition IV
dataset 2b

9

Kappa = 0.564

Ag-AgCl electrodes

5

3-electrode EEG:
Kappa = 0.568
5-electrode EEG:
Kappa = 0.603

SIESTA database

19

Kappa = 0.760 ± 0.022

Data Science,
Philips Research,
Eindhoven, Netherlands

29

Kappa = 0.727 ± 0.005

BCI Competition IV

9

University of Toronto,
Toronto, Canada

92

CNN + VAE

EEG classification of Motor Imagery [101]

Real-time sleep-stage classification [134]

CNN+LSTM

Age of children classification on performing
a verb-generation task, a monosyllable
speech-elicitation task [148]

CNN

Accuracy = 95%

Table 11. Medical application in EOG analysis using Public dataset source.
Medical Application

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

Sleep stages classification

Sleep-stage labeling [149]

GRU

PhysioNet

6 sleep stages and 6 sleep
disorders

Accuracy = 69.25%

Sensors 2020, 20, 969

20 of 39

Table 12. Medical application in Combine of signals analysis using Public dataset source.
Medical Application

Medical Task

DL Model

Dataset Source

No. of Subject/Data

Performance

Sleep stages classification
[150]

CNN

PhysioNet

20

Accuracy = 81%
F1-score = 72%

Sleep-stage classification
[151]

CNN

MASS dataset - session 3

62 records

Sensitivity = 85%
Specificity = 100%

PhysioNet Sleep-EDF
Database (SLPEDF-DB)

19

Kappa = 0.67 ± 0.05

Montreal Archive of Sleep
Studies (MASS-DB)

200

Kappa = 0.74 ± 0.01

CAP Sleep Database
(CAPSLP-DB)

112

Kappa = 0.61 ± 0.01

RBD Database (RBD-DB)

21

Kappa = 0.48 ± 0.07

9

6 sleep classes:
Accuracy = 98.06%,
94.64%, 92.36%, 91.22%,
91.00%

61

6 sleep classes:
Accuracy = 97.62%,
94.34%, 92.33%, 90.98%,
89.54%

2048 samples

EEG:
Accuracy = 92.4%
MEG:
Accuracy = 95.4%
EEG+MEG:
Accuracy = 95.6%

Sleep-stage classification
[152]

CNN

Sleep stages classification

Sleep-stage classification
[153]

1D-CNN

Sleep-EDF

Sleep-EDFX

Classification of brain and
artifactual independent
component (IC) [154]

CNN

Electrical Geodesic Inc,
EEG System Net 300

EOG
Combination of signals

Table 11
Table 12

We do both a quantitative and qualitive comparison of the deep-learning model. For quantitative
comparison, the number of deep-learning models that have been used in medical application is
illustrated.
For
Sensors 2020, 20,
969qualitative comparison, since the performance criterion is not provided uniformly,
21 of 39
we assume an accuracy value as a base criterion for an overall performance comparison.
3.1. Deep
Deep Learning
Learning with
with Electromyogram
Electromyogram (EMG)
(EMG)
3.1.
Electromyogram (EMG)
is data
data regarding
regarding changes
changes of
of skeleton
skeleton muscles,
muscles, which
which is
is recorded
recorded
Electromyogram
(EMG) signal
signal is
by
putting
non-invasive
EMG
electrodes
on
the
skin
such
as
the
commercial
MYO
Armband
(MYB).
by putting non-invasive EMG electrodes on the skin such as the commercial MYO Armband (MYB).
Since different
different muscle
information is
is defined
defined by
by different
different activity,
activity, it
of
Since
muscle information
it can
can discriminate
discriminate aa pattern
pattern of
motion
such
as
an
open
or
closed
hand.
To
classify
those
motion
patterns
based
on
the
EMG
signal
motion such as an open or closed hand. To classify those motion patterns based on the EMG signal
information, 15
15 research
information,
research works
works were
were conducted
conducted using
using deep-learning
deep-learning methods,
methods, as
as shown
shown in
inTables
Table 33
and Table
4. Within
these research
works,works,
there are
two
of keyof
contribution.
One isOne
focused
on hand
and
4. Within
these research
there
aretypes
two types
key contribution.
is focused
on
motion
recognition
and
another
one
is
focused
on
general
muscle
activity
recognition.
hand motion recognition and another one is focused on general muscle activity recognition.
Figure 22shows
number
of deep-learning
models
used to
analyze
the EMGthe
signal:
(a)signal:
illustrates
Figure
showsthethe
number
of deep-learning
models
used
to analyze
EMG
(a)
hand
motion
recognition
and
(b)
illustrates
muscle
activity
recognition.
In
hand
motion
recognition,
illustrates hand motion recognition and (b) illustrates muscle activity recognition. In hand motion
CNN and CNN+RNN
are the most
commonly
muscle activity
CNN
recognition,
CNN andmodels
CNN+RNN
models
are the used.
mostIncommonly
used.recognition,
In musclethe
activity
model is the the
most
commonly
used.
recognition,
CNN
model is
the most commonly used.

(a)

(b)

Figure
2. Number
models used
used in
in EMG
EMG signals
signals for:
for: (a)
hand motion
motion recognition;
recognition; (b)
(b) muscle
muscle
Figure 2.
Number of
of DL
DL models
(a) hand
activity
activity recognition.
recognition.

Table
describes medical
medicalapplication
applicationusing
usingdeep-learning
deep-learningmethods
methodsininEMG
EMGsignal
signalanalysis
analysisfrom
froma
Table 33 describes
a
public
dataset
source.
The
publicly
available
datasets
are
deployed
in
the
CNN
model,
which
public dataset source. The publicly available datasets are deployed in the CNN model, which provides
provides
overall accuracy
>68%. However,
the CNN+RNN
provides
accuracy
than
the
overall accuracy
>68%. However,
the CNN+RNN
model model
provides
higherhigher
accuracy
than the
CNN
CNN
with accuracy
model,model,
with accuracy
>82%.>82%.
Table
describes medical
medicalapplication
applicationusing
usingdeep-learning
deep-learningmethods
methodsininEMG
EMGsignal
signalanalysis
analysisfrom
froma
Table 44 describes
a private(in-house)
(in-house)dataset
datasetsource.
source.The
Theworks
worksuse
usetheir
theirown
own in-house
in-house (private)
(private) dataset
dataset to recognize
private
hand motion. The
DBN
model
performs
with
overall
accuracy
>88%.
Therefore,
The DBN
overall accuracy >88%. Therefore, The
The DBN model
performs better than CNN and CNN+RNN models. For
muscle
activity
recognition,
For muscle activity recognition, the CNN model
performs NMSE
NMSE of
of 0.033
0.033±0.017,
performs
± 0.017,while
whileRNN/long
RNN/longshort-term
short-termmemory
memory(LSTM)
(LSTM) model
model performs
performs NMSE
NMSE
of
0.096±0.013.
Therefore,
the
CNN
model
performs
better
than
the
RNN/LSTM
model.
of 0.096 ± 0.013. Therefore, the CNN model performs better than the RNN/LSTM model.
3.2. Deep
Deep Learning
Learning with
with Electrocardiogram (ECG)
Electrocardiogram (ECG)
data
regarding
changes
of heartbeat
or rhythm.
There are
47 research
Electrocardiogram
(ECG)is is
data
regarding
changes
of heartbeat
or rhythm.
There
are 47
works
using
deep-learning
methods tomethods
analyze the
ECG signals,
as shown
in Table
5, Table
6, and5,Table
7.
research
works
using deep-learning
to analyze
the ECG
signals,
as shown
in Table
Table
Their key contributions are categorized as heartbeat signal classification, heart disease classification,
sleep-stage classification, emotion detection, and age and gender prediction.
Figure 3 shows the number of deep-learning models used to analyze ECG signal: (a) illustrates
heartbeat signal classification in which the CNN model is the most commonly used; (b) illustrates heart
disease classification in which CNN is the most commonly used; (c) illustrates sleep-stage detection in
which CNN is the most commonly used; (d) illustrates emotion detection in which RNN/LSTM and
CNN+RNN are used; and (e) illustrates age and gender classification in which only CNN is used.

Figure 3 shows the number of deep-learning models used to analyze ECG signal: (a) illustrates
heartbeat signal classification in which the CNN model is the most commonly used; (b) illustrates
heart disease classification in which CNN is the most commonly used; (c) illustrates sleep-stage
detection in which CNN is the most commonly used; (d) illustrates emotion detection in which
RNN/LSTM
Sensors
2020, 20,and
969 CNN+RNN are used; and (e) illustrates age and gender classification in which
22only
of 39
CNN is used.

(a)

(b)

(c)

(d)

(e)
Figure 3.
of of
DLDL
models
usedused
in ECG
signals
for: (a)for:
heart(a)beat
signal
classification;
(b) heart
Figure
3. Number
Number
models
in ECG
signals
heart
beat
signal classification;
disease
classification;
(c) sleep stage(c)
detection;
(d) emotion
detection;
and (e) age
and gender
(b)
heart
disease classification;
sleep stage
detection;
(d) emotion
detection;
and classification.
(e) age and
gender classification.

Table 5 describes medical application using deep-learning methods in ECG signal analysis from
a public
source.
In heartbeat
signal
classification,
themethods
CNN model
performs
with overall
Tabledataset
5 describes
medical
application
using
deep-learning
in ECG
signal analysis
from
>95%. RNN/LSTM
model performs
overall accuracy
>98%.
CNN+RNN/LSTM
model
aaccuracy
public dataset
source. In heartbeat
signal with
classification,
the CNN
model
performs with overall
performs >95%.
with overall
accuracy
>87%.
Therefore,
model>98%.
performs
better than CNN
and
accuracy
RNN/LSTM
model
performs
withRNN/LSTM
overall accuracy
CNN+RNN/LSTM
model
CNN+RNN/LSTM
models.
In
heart
disease
classification,
CNN
model
performs
with
overall
performs with overall accuracy >87%. Therefore, RNN/LSTM model performs better than CNN and
accuracy >83%. RNN/LSTM
performs
with overallCNN
accuracy
CNN+RNN/LSTM
model
CNN+RNN/LSTM
models. Inmodel
heart disease
classification,
model>90%.
performs
with overall accuracy
performs
with
overall
accuracy
>98%.
Therefore,
CNN+RNN/LSTM
model
performs
the
best.
In
>83%. RNN/LSTM model performs with overall accuracy >90%. CNN+RNN/LSTM model performs
sleep-stage
onlyTherefore,
CNN model
is used and it performs
with overall
>87%.
with
overallclassification,
accuracy >98%.
CNN+RNN/LSTM
model performs
theaccuracy
best. In sleep-stage
classification, only CNN model is used and it performs with overall accuracy >87%.
Table 6 describes medical application using deep-learning methods in ECG signal analysis from
a private dataset source. In heartbeat signal classification, only CNN model is used and the CNN
model performs with overall accuracy >78%. In heart disease classification, CNN model performs
with overall accuracy >97%, while CNN+LSTM model performs with accuracy >83%. Therefore, CNN
model performs better than CNN+LSTM model. In sleep-stage classification, CNN and GRU model

Table 6 describes medical application using deep-learning methods in ECG signal analysis from
a private dataset source. In heartbeat signal classification, only CNN model is used and the CNN
model performs with overall accuracy >78%. In heart disease classification, CNN model performs
with overall accuracy >97%, while CNN+LSTM model performs with accuracy >83%. Therefore, CNN
Sensors 2020, 20, 969
23 of 39
model performs better than CNN+LSTM model. In sleep-stage classification, CNN and GRU model
perform with accuracy of 99%. In emotion classification, CNN+RNN model performs with accuracy
>73%. In with
age and
gender
CNN model
performs
with accuracy
>90%.
perform
accuracy
ofprediction,
99%. In emotion
classification,
CNN+RNN
model
performs with accuracy
Table
7 describes
medical
application
ECG signal analysis from
>73%.
In age
and gender
prediction,
CNN using
modeldeep-learning
performs withmethods
accuracyin>90%.
a hybrid
source.medical
In heartbeat
signal classification,
CNN+LSTM
model in
performs
with accuracy
Tabledataset
7 describes
application
using deep-learning
methods
ECG signal
analysis
>99%.
from a hybrid dataset source. In heartbeat signal classification, CNN+LSTM model performs with
accuracy >99%.
3.3. Deep Learning with Electroencephalogram (EEG)
3.3. Deep Learning with Electroencephalogram (EEG)
Electroencephalogram (EEG) is data regarding changes of the brain measured from the scalp.
data regarding
changes
the brain
measured
from
the scalp.
ThereElectroencephalogram
are 79 research works(EEG)
using is
deep-learning
methods
to of
analyze
the EEG
signals,
as shown
in
There
79 research
deep-learning
methods are
to analyze
the EEG
signals,
as shown
Table are
8, Table
9, andworks
Table using
10. Their
key contributions
categorized
as brain
functionality
in Table 8, Table
9, disease
and Table
10. Their key
contributions
are categorized
brain functionality
classification,
brain
classification,
emotion
classification,
sleep-stage as
classification,
motion
classification, gender
brain disease
classification,
emotion classification,
sleep-stage classification, motion
classification,
classification,
word classification,
and age classification.
classification,
genderthe
classification,
classification,
andused
age classification.
Figure 4 shows
number of word
deep-learning
models
to analyze EEG signal: (a) illustrates
4 showsclassification
the number in
of which
deep-learning
analyze
EEG signal:
brainFigure
functionality
the CNNmodels
model used
is theto
most
commonly
used; (a)
(b) illustrates
classification
in which
the CNN
model
the most commonly
(b) illustrates
brain functionality
disease classification
in which
the CNN
is the
mostiscommonly
used; (c) used;
illustrates
emotion
brain diseasein
classification
in which
CNN
is the most
used;
(c) illustrates
emotion
classification
which the CNN
is thethe
most
commonly
used;commonly
(d) illustrates
sleep-stage
classification
classification
in is
which
the CNN
is the most
used;
(d) illustrates
sleep-stage
classification
in
in
which CNN
the most
commonly
used;commonly
(e) illustrates
motion
classification
in which
CNN is the
which
CNN is theused;
most(f)
commonly
used;
(e) illustrates
motion
classification
in which
CNN
the most
most commonly
illustrates
gender
classification
in which
only CNN
is used;
(g)isillustrates
commonly
used; (f)
classification
which only
is used;in
(g)which
illustrates
word
recognition
in illustrates
which onlygender
AE is used;
and (h) in
illustrates
age CNN
classification
only word
CNN
recognition
in which only AE is used; and (h) illustrates age classification in which only CNN is used.
is
used.

(a)

(b)

(c)

(d)
Figure 4. Cont.

Sensors 2020, 20, 969

24 of 39

Sensors 2020, 20, 969

7 of 35

(e)

(f)

(g)

(h)

Figure
Figure 4.
4. Number
Number of
of DL
DL models
models used
used in
in EEG
EEG signals
signals for:
for: (a)
(a)brain
brainfunctionality
functionality classification;
classification; (b)
(b) brain
brain
disease
classification;
(c)
emotion
classification;
(d)
sleep-stage
classification;
(e)
motion
classification;
disease classification; (c) emotion classification; (d) sleep-stage classification; (e) motion classification;
(f) gender
gender classification;
classification; (g)
(g) words
words recognition;
recognition; and
and (h)
(h) age
age classification.
classification.
(f)

Table
describes medical
medicalapplication
applicationusing
usingdeep-learning
deep-learningmethods
methodsininEEG
EEGsignal
signalanalysis
analysisfrom
froma
Table 88 describes
a publicdataset
datasetsource.
source.InInbrain
brainfunctionality
functionalitysignal
signalclassification,
classification,CNN
CNN model
model performs
performs with overall
public
accuracy >66%. RNN/LSTM
overall accuracy
accuracy >77%.
>77%. CNN+RNN/LSTM model
RNN/LSTM model performs with overall
RNN/LSTM
model
performs
better
thanthan
CNNCNN
and
performs with
with overall
overallaccuracy
accuracy>74%.
>74%.Therefore,
Therefore,
RNN/LSTM
model
performs
better
CNN+RNN/LSTM
models.
In
brain
disease
classification,
CNN
model
performs
with
overall
and CNN+RNN/LSTM models. In brain disease classification, CNN model performs with
accuracy >93%. RNN/LSTM
overall accuracy
accuracy >95%.
>95%. CNN+RNN/LSTM model
RNN/LSTM model performs with overall
performs with overall accuracy >90%. Therefore,
Therefore, RNN/LSTM
RNN/LSTM model performs better than CNN and
CNN+RNN/LSTM
CNN+RNN/LSTM models.
models. In
In emotion
emotion classification,
classification, CNN
CNN model
model performs
performs with
with overall accuracy
>55%. RNN/LSTM
>55%.
RNN/LSTM model
model performs with overall accuracy >74%. RBM
RBM model
model performs with overall
accuracy >75%.
>75%. Therefore,
Therefore, RBM
RBM model
model performs
performs best. In
In sleep-stage
sleep-stage classification,
classification, CNN model
performs with overall
overall accuracy
accuracy >79%.
>79%. RNN/LSTM
model
performs
with
>79%.
RNN/LSTM model performs with overall accuracy >79%.
CNN+RNN/LSTM model performs with overall
overall accuracy
accuracy >84%.
>84%. Therefore,
Therefore, CNN+RNN/LSTM model
performs better than CNN and
and RNN/LSTM
RNN/LSTM models.
models. In motion classification, only RNN/LSTM is
used, with accuracy >68%.
>68%. In
with accuracy
accuracy >80%.
>80%. In word
In gender
gender classification, only CNN is used, with
classification, only CNN+AE
CNN+AE is
is used,
used, with overall accuracy >95%.
>95%.
Table
describes medical
medicalapplication
applicationusing
usingdeep-learning
deep-learningmethods
methodsininEEG
EEGsignal
signalanalysis
analysisfrom
froma
Table 99 describes
a private
dataset
source.
In brain
functionality
classification,
CNN model
performs
with
private
dataset
source.
In brain
functionality
signalsignal
classification,
CNN model
performs
with overall
overall
accuracy
>63%. CNN+RNN/LSTM
model performs
with accuracy
overall accuracy
>83%. Stacked
autoaccuracy
>63%. CNN+RNN/LSTM
model performs
with overall
>83%. Stacked
auto-encoder
encoder (SAE)+CNN
modelwith
performs
overall
accuracy
>88%.
Therefore,
SAE+CNN
(SAE)+CNN
model performs
overallwith
accuracy
>88%.
Therefore,
SAE+CNN
model
performsmodel
better
performs
than CNN and CNN+RNN/LSTM
brain diseaseCNN
classification,
CNN model
than CNNbetter
and CNN+RNN/LSTM
models. In brainmodels.
diseaseInclassification,
model performs
with
performs
with
overall
accuracy
>59%.
RNN/LSTM
model
performs
with
overall
accuracy
>73%.
overall accuracy >59%. RNN/LSTM model performs with overall accuracy >73%. CNN+RNN/LSTM
CNN+RNN/LSTM
model
performs
with
overall
accuracy
>70%. Therefore,
RNN/LSTM
model performs with
overall
accuracy
>70%.
Therefore,
RNN/LSTM
model performs
bettermodel
than
performs
better than CNN models.
and CNN+RNN/LSTM
models. only
In emotion
classification,
only
CNN and CNN+RNN/LSTM
In emotion classification,
CNN+LSTM
model is used,
CNN+LSTM
model
is
used,
with
accuracy
>98%.
In
sleep-stage
classification,
CNN
model
performs
with accuracy >98%. In sleep-stage classification, CNN model performs with overall accuracy >95%.
with
overall accuracy
>95%.
CNN+RNN/LSTM
model
performs
with kappaonly
> 0.8.
Inmodel
motion
CNN+RNN/LSTM
model
performs
with kappa > 0.8.
In motion
classification,
CNN
is
classification,
only CNN
model is used, with accuracy >80%.
used, with accuracy
>80%.
Table 10 describes medical application using deep-learning methods in EEG signal analysis from
a hybrid dataset source. In brain disease classification, only the CNN+AE model is used, with kappa

Sensors 2020, 20, 969

25 of 39

Table
medical application using deep-learning methods in EEG signal analysis from
Sensors
2020,10
20,describes
969
8 of 35
a Sensors
hybrid2020,
dataset
source.
In
brain
disease
classification,
only
the
CNN+AE
model
is
used,
with
kappa
20, 969
8 of 35
0.564. In
Insleep-stage
sleep-stageclassification,
classification,only
onlyCNN+LSTM
CNN+LSTM model
modelisisused,
used,with
withkappa
kappa> >0.72.
0.72.InInage
age
>>0.564.
classification,
onlythe
theCNN
CNN
modelisisused,
used,
with
accuracy>95%.
>95%. is used, with kappa > 0.72. In age
classification,
only
model
accuracy
> 0.564. In sleep-stage
classification,
onlywith
CNN+LSTM
model
3.4.
Deep
Learning
with
Electrooculogram
(EOG)
classification, only the CNN model is used, with accuracy >95%.
3.4.
3.4.Deep
DeepLearning
Learningwith
withElectrooculogram
Electrooculogram(EOG)
(EOG)
Electrooculogram (EOG) is data regarding changes of the corneo-retinal potential between the
Electrooculogram
(EOG)
isisdata
regarding
ofofthe
potential
the
front
and the back of
the human
Therechanges
are
1 research
work
using deep-learning
methods
Electrooculogram
(EOG)
dataeye.
regarding
changes
thecorneo-retinal
corneo-retinal
potentialbetween
between
theto
front
and
the
back
of the
eye. eye.
There
are 1 research
work using
methods
to analyze
analyze
the
EOG
signals,
as shown
in There
Table
11.
contribution
of
deploying
deep learning
in EOG
front
and
the
back
of human
the human
are The
1 research
workdeep-learning
using
deep-learning
methods
to
the
EOG signals,
inshown
Table
11.
The
contribution
of deploying
deep
in
signal
signal
analysis
isshown
only for
sleep-stage
classification.
Figure
5 of
shows
the learning
number
of EOG
deep-learning
analyze
the
EOGassignals,
as
in Table
11. The contribution
deploying
deep learning
in
EOG
analysis
is which
only for
sleep-stage
classification.
Figure
5 Figure
shows 5classification.
the
number
deep-learning
models
models
usedfor
to sleep-stage
analyze
EOGclassification.
signal
for sleep-stage
The
workofused
GRU
model.
signal
analysis
isare
only
shows
the of
number
deep-learning
which
arewhich
used to
signal
for
sleep-stage
classification.
The work
models
areanalyze
used toEOG
analyze
EOG
signal
for sleep-stage
classification.
Theused
workGRU
used model.
GRU model.

Figure 5. Number of DL models used in EOG signals for sleep-stage classification.
Figure5.5.Number
NumberofofDL
DLmodels
modelsused
usedininEOG
EOGsignals
signalsfor
forsleep-stage
sleep-stageclassification.
classification.
Figure

Table 11 describes medical application using deep-learning methods in EOG signal analysis
from
a public
dataset medical
source.
In sleep-stage
classification,
themethods
GRUmethods
model
performs
with accuracy
Table
describes
medical
application
using
deep-learning
in signal
EOG signal
analysis
Table
1111
describes
application
using
deep-learning
in EOG
analysis
from
of
69.25%.
from
a
public
dataset
source.
In
sleep-stage
classification,
the
GRU
model
performs
with
accuracy
a public dataset source. In sleep-stage classification, the GRU model performs with accuracy of 69.25%.
of 69.25%.
3.5.Deep
DeepLearning
Learningwith
withaaCombination
CombinationofofSignals
Signals
3.5.
3.5.There
Deep Learning
with a Combination
of Signals
methods to
toanalyze
analyzeaacombination
combinationofofsignals,
signals,
Thereare
are55research
researchworks
works using
using deep-learning
deep-learning methods
as
asshown
shown
in
Table
12.
Sokolovsky
et
al
[150]
combined
EEG
and
EOG
signal.
Chambon
et
al
[151]
and
in Table
Sokolovsky
al [150]
combined EEG
and to
EOG
signal.
Chambon etof
al signals,
[151] and
There
are 512.
research
workset
using
deep-learning
methods
analyze
a combination
as
Andreotti
etetalal[152]
combined
(PSG)
signals such
asasEEG,
EMG,
EOG. The
Andreotti
[152]
combinedpolysomnography
polysomnography
(PSG)
such
EEG,
EMG,and
and
shown in Table
12. Sokolovsky
et al [150] combined
EEGsignals
and EOG
signal.
Chambon
et alEOG.
[151] The
and
work
ofofYildirim
etetalal[153]
the
signals
ofofEEG
EOG.
Croce
et al’s
work
Yildirim
[153]exploited
exploited
thecombination
combination
signals
EEGand
and
EOG.
Croce
al’s[154]
[154]
Andreotti
et al [152]
combined
polysomnography
(PSG)
signals
such
as
EEG,
EMG,
andetEOG.
The
contribution
was
from
EEG
and
magnetoencephalographic
(MEG)
signals.
CNN
is
used
for
both
contribution
was et
from
EEG exploited
and magnetoencephalographic
(MEG)
signals.
CNNCroce
is used
for [154]
both
work of Yildirim
al [153]
the combination signals
of EEG
and EOG.
et al’s
sleep-stage
classification and
the
independent
components.
sleep-stage
andand
theclassification
classificationofofbrain
brainand
andartifactual
artifactual
independent
components.
contributionclassification
was from EEG
magnetoencephalographic
(MEG)
signals.
CNN is used
for both
Figure
66shows
the
number
ofofdeep-learning
models
used
totoanalyze
aacombination
ofofsignals
for
Figure
shows
the
number
deep-learning
models
used
analyze
combination
signals
for
sleep-stage classification and the classification of brain and artifactual independent components.
sleep-stage
classification.
sleep-stage
classification.
Figure 6 shows
the number of deep-learning models used to analyze a combination of signals for
sleep-stage classification.

Figure 6. Number of DL models used in a combination of signals for sleep-stage classification.
Figure 6. Number of DL models used in a combination of signals for sleep-stage classification.
Figure 6. Number of DL models used in a combination of signals for sleep-stage classification.

Table 12 describes medical application using deep-learning methods in a combination of signals
analysis
from
a public dataset
source.
In sleep-stage
classification,methods
only theinCNN
model is used,
with
Table
12 describes
medical
application
using deep-learning
a combination
of signals
an
overall
accuracy
>81%.
analysis from a public dataset source. In sleep-stage classification, only the CNN model is used, with
an overall accuracy >81%.
4. Training Architecture
4. Training Architecture

Sensors 2020, 20, 969

26 of 39

Table 12 describes medical application using deep-learning methods in a combination of signals
analysis from a public dataset source. In sleep-stage classification, only the CNN model is used, with an
overall accuracy >81%.
Sensors
2020, 20,Architecture
969
4. Training

9 of 35

To strive for high accuracy,
accuracy, deep-learning
To
deep-learningtechniques
techniquesrequire
requirenot
notonly
onlyaagood
goodalgorithm,
algorithm,but
butalso
alsoa
dataset
[155].
Therefore,
the the
input
datadata
is used
in twoinways:
the (1)
input
are data
first extracted
agood
good
dataset
[155].
Therefore,
input
is used
two (1)
ways:
thedata
input
are first
as
features,
then
the
feature
data
are
fed
into
the
network.
Based
on
our
review,
some
contributions
extracted as features, then the feature data are fed into the network. Based on our review, some
use traditionaluse
machine-learning
methods as feature
extractors
described
in detail
in Section
while
contributions
traditional machine-learning
methods
as feature
extractors
described
in 4.1,
detail
in
other contributions
use deep-learning
methods
as featuremethods
extractorsasdescribed
in detail in
Section 4.2;
Section
4.1, while other
contributions use
deep-learning
feature extractors
described
in
and (2)inthe
raw input
data (2)
are the
fed into
network
directly
for end-to-end
learning
described
in detail
detail
Section
4.2; and
raw the
input
data are
fed into
the network
directly
for end-to-end
in Section
4.3.
learning
described
in detail in Section 4.3.
4.1. Traditional
Traditional Machine
Machine Learning
Learning as
as Feature
Feature Extractor
Extractor and
and Deep
Deep Learning
Learning as
as Classifier
Classifier
4.1.
To distinguish
distinguish the
the label
label of
of signals,
signals, raw
raw signal
signal data
data is
is divided
divided into
into N
N levels.
levels. This
This step
step is
is called
called
To
feature extraction.
extraction. Feature
Featureextraction
extractionisisconducted
conductedto
tostrengthen
strengthenthe
the accuracy
accuracy of
of prediction
prediction in
in the
the
feature
classification
step.
Figure
7
illustrates
the
training
architecture
using
traditional
machine
learning
as
classification step. Figure 7 illustrates the training architecture using traditional machine learning as
feature
extractor
and
deep
learning
as
classifier.
For
example,
the
raw
EMG
signal
is
divided
into
N
feature extractor and deep learning as classifier. For example, the raw EMG signal is divided into N
levels using
using mean
meanabsolute
absolutevalue
value(MAV).
(MAV). The
The featured
featured data
data is
is fed
fedinto
intoaaCNN
CNNto
toclassify
classifyhand
handmotion.
motion.
levels
Input

Feature Extractor

Classifier

Output

Data

Machine Learning
method

Deep Learning
method

Result

MAV

CNN

States of
hand motion

Ex: EMG

Figure
machine
learning
as as
feature
extractor
andand
deep
learning
as classifier.
Figure7.7.Training
Trainingarchitecture
architectureofof
machine
learning
feature
extractor
deep
learning
as classifier.

Yu
Yu et
et al
al [9]
[9] designed
designed aa feature-level
feature-level fusion
fusion to
to recognize
recognize Chinese
Chinese sign
sign language.
language. The
The features
features are
are
extracted
extracted using
using hand-crafted
hand-craftedfeatures
featuresand
and learned
learnedfeatures
featuresfrom
from DBN.
DBN. These
These two
two feature
feature levels
levels are
are
concatenated
concatenated before
before being
being fed
fed into
intothe
thedeep
deepbelief
beliefnetwork
networkand
andfully
fullyconnected
connectednetwork
networkfor
forlearning.
learning.
For
the hand-grasping
hand-graspingclassification
classificationdescribed
described
Lialet[14],
al [14],
principal
component
analysis
For the
byby
Li et
principal
component
analysis
(PCA)
(PCA)
method
used
for dimension
reduction
and with
DNNawith
stack
of 2-layered
auto-encoders,
method
is usedisfor
dimension
reduction
and DNN
stacka of
2-layered
auto-encoders,
and a
and
a
SoftMax
classifier
is
applied
for
classifying
levels
of
force.
SoftMax classifier is applied for classifying levels of force.
Saadatnejad
heartbeat classification
classification for
for continuous
continuous monitoring.
monitoring. The
Saadatnejad et
et al
al [35]
[35] proposed
proposed ECG
ECG heartbeat
The
work
extracted
raw
ECG
samples
into
heartbeat
RR
interval
features
and
wavelet
features.
Next,
the
work extracted raw ECG samples into heartbeat RR interval features and wavelet features. Next,
extracted
features
were
fed
into
two
RNN-based
models
for
classification.
the extracted features were fed into two RNN-based models for classification.
To
Jeon
et al
extracted
the features
in theinQRS
To classify
classifypremature
prematureventricular
ventricularcontraction,
contraction,
Jeon
et [45]
al [45]
extracted
the features
the
pattern
from
the
ECG
signal
and
classified
by
modified
weight
and
bias
based
on
the
errorQRS pattern from the ECG signal and classified by modified weight and bias based on the
backpropagation
algorithm.
error-backpropagation
algorithm.
Liu
Liu et
et al
al [60]
[60] presented
presented heart
heart disease
disease classification
classification based
based on
on ECG
ECG signals
signals by
by deploying
deploying symbolic
symbolic
aggregate
approximation
(SAX)
as
a
feature
extraction
and
LSTM
for
classification.
aggregate approximation (SAX) as a feature extraction and LSTM for classification.
Majidov
Majidov et
et al
al [85]
[85] proposed
proposed motor
motor imagery
imagery EEG
EEG classification
classification by
by deploying
deploying Riemannian
Riemannian
geometry-based
feature
extraction
and
a
comparison
between
convolutional
layers
and
geometry-based feature extraction and a comparison between convolutional layers and SoftMax
SoftMax
layers
layers and
and convolutional
convolutional layers,
layers, and
and fully
fully connected
connected layers
layers which
which outputs
outputs 100
100 units.
units.
Abbas
et al
al[87]
[87]designed
designed
a model
multiclass
motor
imagery
classification,
in fast
which
fast
Abbas et
a model
for for
multiclass
motor
imagery
classification,
in which
Fourier
Fourier
transform
energy
map
(FFTEM)
is
used
for
feature
extraction
and
CNN
is
used
transform energy map (FFTEM) is used for feature extraction and CNN is used for classification. for
classification.
In diagnosing brain disorders, Golmohammadi et al [95] used linear frequency cepstral coefficients
In for
diagnosing
brain disorders,
Golmohammadi
al [95]
linear
frequency
cepstral
(LFCC)
feature extraction
and hybrid
hidden Markovet
models
andused
stacked
denoising
auto-encoder
coefficients
(LFCC)
for
feature
extraction
and
hybrid
hidden
Markov
models
and
stacked
denoising
(SDA) model for classifying.
auto-encoder (SDA) model for classifying.
4.2. Deep Learning as Feature Extractor and Traditional Machine Learning as Classifier
Figure 8 illustrates the training architecture of using deep learning as a feature extractor and
traditional machine learning as classifier. For example, the raw EEG signal is divided into N levels

Sensors 2020, 20, 969

27 of 39

4.2. Deep Learning as Feature Extractor and Traditional Machine Learning as Classifier
Sensors 2020, 20, 969

10 of 35

Figure 8 illustrates the training architecture of using deep learning as a feature extractor and
Sensors 2020, 20, 969
10 of 35
traditional machine learning as classifier. For example, the raw EEG signal is divided into N levels
using SAE. The featured data is fed into support vector machine (SVM) to classify the state of emotion.
Input

Feature Extractor

Classifier

Output

Input
Data

Feature Extractor
Deep Learning
method
Deep
Learning

Classifier
Machine Learning
method
Machine
Learning

Output

method
SAE

method
SVM

Data
Ex: EEG

Result
Result
States of
emotion
States of

Ex: EEG
SAE
SVM
emotion
Figure 8. Training architecture of deep learning as feature extractor and machine learning as classifier.
Figure
Training architecture
architectureof
ofdeep
deeplearning
learningasasfeature
feature
extractor
and
machine
learning
as classifier.
Figure 8. Training
extractor
and
machine
learning
as classifier.

Chauhan et al [26] proposed an ECG anomaly class identification algorithm, in which the LSTM
Chauhan
et
[26]
an
class
algorithm,
in
the
and error
profile
modeling
are used
as a anomaly
feature
extractor.
Then, the multiple
choices
of traditional
Chauhan
et al
al
[26] proposed
proposed
an ECG
ECG
anomaly
class identification
identification
algorithm,
in which
which
the LSTM
LSTM
and
as
Then,
the
choices
of
machine-learning
classifier are
models
conducted,
such as
multilayer
perception,
vector
and error
error profile
profile modeling
modeling
are used
usedwere
as aafeature
featureextractor.
extractor.
Then,
the multiple
multiple
choicessupport
of traditional
traditional
machine-learning
classifier
models
machine,
and logistic
regression.
machine-learning
classifier
models were
were conducted,
conducted, such
such as
as multilayer
multilayer perception,
perception, support
support vector
vector
machine,
and
logistic
regression.
To diagnose
arrhythmia,
Yang et al [42] used DL-CCANet and TL-CCANet as feature extractor
machine,
and logistic
regression.
To
arrhythmia,
DL-CCANet
TL-CCANet
as as
feature
extractor
to
to discriminate
features
fromYang
dual-lead
and
three-lead
ECGs.and
Then,
the extracted
features
were
fed
Todiagnose
diagnose
arrhythmia,
Yangetetalal[42]
[42]used
used
DL-CCANet
and
TL-CCANet
feature
extractor
discriminate
features
from
dual-lead
and
three-lead
ECGs.
Then,
the
extracted
features
were
fed
into
into
the
linear
support
vector
machine
for
classification.
to discriminate features from dual-lead and three-lead ECGs. Then, the extracted features were fed
the
support
machine
for
Nguyen
etsupport
alvector
[63]vector
proposed
an classification.
algorithm
for detecting sudden cardiac arrest in automated
intolinear
the
linear
machine
for classification.
Nguyen
etetalal[63]
proposed
an CNN
algorithm
for detecting
sudden
cardiac
arrest in
automated
external
external
defibrillators,
in
which
is used
as
extractor
(CNNE)
and
a boosting
(BS)
Nguyen
[63]
proposed
an algorithm
forfeature
detecting
sudden
cardiac
arrest
in automated
defibrillators,
in
which
CNN
is
used
as
feature
extractor
(CNNE)
and
a
boosting
(BS)
classifier.
classifier.
external defibrillators, in which CNN is used as feature extractor (CNNE) and a boosting (BS)
Ma
Ma et
et al
al [131]
[131] designed
designed aa model
model to
todetect
detectdriving
drivingfatigue.
fatigue. The
The network
network model
model integrated
integrated the
the
classifier.
PCA
andetdeep-learning
deep-learning
method
called
PCANet
for
feature
extraction.
Then,
SVM/KNN
is
used
PCA Ma
method
called
PCANet
for
feature
extraction.
Then,
SVM/KNN
is
used
for
al [131] designed a model to detect driving fatigue. The network model integrated the
for
classification.
classification.
PCA and deep-learning method called PCANet for feature extraction. Then, SVM/KNN is used for
classification.
4.3.
4.3. End-to-End
End-to-End Learning
Learning
4.3. End-to-End
Learning
Rather
extracting
Rather than
than
extracting the
the feature
feature from
from raw
raw data,
data, the
the raw
raw data
data is
is fed
fed into
into the
the network
network for
for
classification.
This
architecture
reduces
the
feature-extraction
step.
Figure
9
illustrates
the
training
classification.
This
architecture
reduces
the
feature-extraction
step.
Figure
9
illustrates
the
training
Rather than extracting the feature from raw data, the raw data is fed into the network for
architecture
ofofThis
using
only
deep-learning
to get
raw
data,
do a classification,
andtraining
output
architecture
using
only
deep-learning
methods
to input
get input
rawFigure
data,
a classification,
and
classification.
architecture
reducesmethods
the
feature-extraction
step.
9do
illustrates
the
the
result.
For
example,
the
ECG
data
is
fed
into
the
LSTM
network
to
classify
the
states
of
sudden
output
the result.
For only
example,
the ECG data
is fed to
into
LSTM
network
to classify
the statesand
of
architecture
of using
deep-learning
methods
getthe
input
raw
data, do
a classification,
cardiac
arrests.
sudden
cardiac
arrests.
output the result. For example, the ECG data is fed into the LSTM network to classify the states of
sudden cardiac arrests.

Ex:

Input

Classifier

Output

Input
Data

Output

Data

Classifier
Deep Learning
method
Deep
Learning

ECG

method
LSTM

Result
Result
States of
SuddenStates
cardia
ofarrests

Ex: ECG
LSTM
Sudden cardia arrests
Figure 9. Training architecture
architecture of
of end-to-end
end-to-end learning
learning using
using deep
deep learning.
learning.
Figure 9. Training architecture of end-to-end learning using deep learning.

All
3–12 which
which are
are not
not mentioned
mentioned in
in Sections
Sections 4.1
4.1 and
and 4.2
4.2 use
All works
works in
in Tables
Table 3–12
use aa raw
raw dataset
dataset for
for
end-to-end
learning.
end-to-end
learning.
All works
in Table 3–12 which are not mentioned in Sections 4.1 and 4.2 use a raw dataset for

end-to-end learning.
5. Dataset Sources
5. Dataset Sources
We deduce
that there are three types of dataset sources used. (1) The public dataset as shown
5. Dataset
Sources
We deduce
that there are three types of dataset sources used. (1) The public dataset as shown in
in Table 3, Table 5, Table 8, Table 11, and Table 12 is available online and freely accessible. It has
TableWe
3, Table
5,
Table
8, Table
11, and
Table
12 is available
and
freely
accessible.
It shown
has large
deduce that
there
are three
types
of dataset
sources online
used. (1)
The
public
dataset as
in
large numbers of samples. Figure 10 illustrates the number of papers using a public dataset based
numbers
of samples.
1011,
illustrates
the
of papers
a public
datasetIt based
on
Table 3, Table
5, TableFigure
8, Table
and Table
12number
is available
online using
and freely
accessible.
has large
on physiological data modality. For EMG signal analysis, NinaPro DB is the most commonly used.
physiological
data modality.
EMG signal
analysis,
DBusing
is the amost
commonly
numbers of samples.
Figure For
10 illustrates
the
numberNinaPro
of papers
public
dataset used.
basedFor
on
ECG
signal analysis,
MIT-BIH
the signal
most commonly
used, then
is the second
physiological
data modality.
ForisEMG
analysis, NinaPro
DB isPhysioNet
the most commonly
used.most
For
commonly
For EEG
signal is
analysis,
BCIcommonly
competition
II is the
most
commonly
used,
then CHBECG signalused.
analysis,
MIT-BIH
the most
used,
then
PhysioNet
is the
second
most
MIT
and DEAP
commonly
used. ForIIEOG
analysis, only
PhysioNet
is
commonly
used.are
Forthe
EEGsecond
signal most
analysis,
BCI competition
is thesignal
most commonly
used,
then CHBused.
For DEAP
the combination
of signal
MASS
andFor
PhysioNet
is the
most commonly
used. (2)
MIT and
are the second
mostanalysis,
commonly
used.
EOG signal
analysis,
only PhysioNet
is
Private
datasets
are shown of
in signal
Table 4,
Table 6,MASS
and Table
9: it is collected
an commonly
author in their
own
used. For
the combination
analysis,
and PhysioNet
is the by
most
used.
(2)

Sensors 2020, 20, 969

28 of 39

For ECG signal analysis, MIT-BIH is the most commonly used, then PhysioNet is the second most
commonly used. For EEG signal analysis, BCI competition II is the most commonly used, then
CHB-MIT and DEAP are the second most commonly used. For EOG signal analysis, only PhysioNet
is used. For the combination of signal analysis, MASS and PhysioNet is the most commonly used.
(2)
Private
Sensors
2020,datasets
20, 969 are shown in Table 4, Table 6, and Table 9: it is collected by an author in their11own
of 35
laboratory, hospital, or institution. This dataset requires a specific device for recording or capturing
laboratory,
hospital, or institution.
This
dataset
requires
a specific
deviceThus,
for recording
or capturing
and
requires participants
or subjects to
evolve
in the
experimental
process.
it has a small
number
and
requires
participants
or
subjects
to
evolve
in
the
experimental
process.
Thus,
it
has
a small
of samples. (3) Hybrid datasets are shown in Tables 7 and 10: the public and private datasets
are
number of
(3)experiment.
Hybrid datasets are shown in Table 7 and Table 10: the public and private
combined
forsamples.
use in the
datasets are combined for use in the experiment.

Figure10.
10.Number
Number
paperused
usedPublic
Public dataset
dataset in
signal
analysis.
Figure
ofof
paper
inphysiological
physiological
signal
analysis.

6. Discussion
6. Discussion
We studied contributions based on types of physiological signal data modality and training
We studied contributions based on types of physiological signal data modality and training
architecture. The medical application, deep-learning model, and performance of those contributions
architecture. The medical application, deep-learning model, and performance of those contributions
have been reviewed and illustrated.
have been reviewed and illustrated.
6.1. Discussion of the Deep-Learning Task
6.1. Discussion of the Deep-Learning Task
In medical application, we deduced that most of the contributions were conducted using a
In medical
we deduced
most
of the contributions
were conducted
usingisa
classification
task, application,
feature-extraction
task, andthat
data
compression
task. The classification
task, which
classification
feature-extraction
task,task,
and data
compression
Theon
classification
task,
which
also
known as task,
recognition
task, detection
or prediction
task,task.
focuses
whether the
instance
is
also
known
as
recognition
task,
detection
task,
or
prediction
task,
focuses
on
whether
the
instance
exists or does not exist. For example, arrhythmia detection [51] analyzes whether the heartbeat signal is
exists or
not exist.
For
example, arrhythmia
detection
[51] analyzes
whether
heartbeat
signal
normal
or does
arrhythmic.
The
classification
task also focuses
on grouping
or leveling
thethe
types
of instances.
is normal
oremotion
arrhythmic.
The classification
task also
focuses
grouping
or happy,
levelingneutral,
the types
For
example,
classification
[126] analyzes
emotion
intoongroups
of sad,
andof
instances.
For
example,
emotion
classification
[126]
analyzes
emotion
into
groups
of
sad,
happy,
fear. The feature-extraction task [43] focuses on input data enhancement, in which the unsupervised
neutral,technique
and fear. isThe
feature-extraction
task
focuses
onburden
input data
in which
the
learning
used
to label the dataset
to [43]
avoid
a heavy
fromenhancement,
manual labeling.
The data
unsupervised
learning
technique
is
used
to
label
the
dataset
to
avoid
a
heavy
burden
from
manual
compression task [33] focuses on decreasing the data size while still retaining the high quality of data
labeling.
compression task [33] focuses on decreasing the data size while still retaining the
for
storageThe
anddata
transmission.
high quality of data for storage and transmission.

6.2. Discussion of the Deep-Learning Model
Even though there are various deep-learning models, we deduced that only CNN, RNN/LSTM,
and CNN+RNN/LSTM models are the most commonly used. As theorized in the literature, the
RNN/LSTM model predicts continuously sequential data well. However, many contributions convert
physiological signals into 2D data and feed those 2D data into a CNN network, in which the
performance is good.

Sensors 2020, 20, 969

29 of 39

6.2. Discussion of the Deep-Learning Model
Even though there are various deep-learning models, we deduced that only CNN, RNN/LSTM, and
CNN+RNN/LSTM models are the most commonly used. As theorized in the literature, the RNN/LSTM
model predicts continuously sequential data well. However, many contributions convert physiological
signals into 2D data and feed those 2D data into a CNN network, in which the performance is good.
6.3. Discussion of the Training Architecture
Due to different characteristics of data modality, investigation into the diversity of training
architectures has been conducted. The first type of architecture exploits the traditional machine-learning
model as a feature extractor and deep-learning model as a classifier. This architecture’s goal is to boost
accuracy of classification by converting raw data into feature data. The feature data consists of higher
potentially discriminated characteristics than the raw data. The DL classifier trains this feature data in
a supervised learning manner.
In contrast, the second type of architecture employs the deep-learning model as a feature extractor
and traditional machine-learning model as a classifier. This architecture’s goal is to reduce the
heavy burden of the hand-crafted labeling of the dataset. The DL extractor trains the raw data in an
unsupervised learning manner.
The third architecture type uses only a deep-learning model to train raw data and receive the final
output. This architecture’s goal is to not rely on the input dataset, but to strengthen the algorithm
of the deep-learning model, in which they believe that the more robust the DL algorithm, the higher
the accuracy will be received. This architecture trains raw data in a supervised learning manner.
Additionally, this architecture eases the implementation stage.
In our survey, we could not point out which type of architecture was best. This is because there are
no contributions that apply these three types of architecture using the same input dataset for training,
testing, and receiving the same desired task.
6.4. Discussion of the Dataset Source
We overviewed the sources of the dataset which were conducted for the deep-learning application
of physiological signal analysis. The available public datasets which are widely used are MIT-BIH,
PhysioNet, BCI competition II, CHB-MIT, DEAP, Bonn University, and NinaPro. The private dataset
was collected by authors in their own laboratory, hospital, or institution. The private dataset was
collected if the data was not available as a public source. Due to lack of datasets, contributions
such as Nodera et al [23] employed a technique of data augmentation, in which a fake dataset is
generated by duplicating original data and doing a transformation such as translation and rotation.
Contributions [12,16,23,46,58] employed a transfer learning technique. Rather than undertaking a
training from a scratch with a huge required dataset, they adapted the pre-weight from a state-of-the-art
model such as AlexNet, VGG, ResNet, Inception, or DenseNet.
7. Conclusions
In this paper, we conducted an overview of deep-learning approaches and their applications
in medical 1D signal analysis over the past two years. We found 147 papers using deep-learning
methods in EMG signal analysis, ECG signals analysis, EEG signals analysis, EOG signals analysis,
and combinations of signal analysis.
By reviewing those works, we contribute to the identification of the key parameters used to
estimate the state of hand motion, heart disease, brain disease, emotion, sleep stages, age, and gender.
Additionally, we reveal that the CNN model predicts the physiological signals at the state-of-the-art
level. We have also learned that there is no precise standardized experimental setting. These
non-uniform parameters and settings makes it difficult to compare exact performance. However,
we compared the overall performance. This comparison should enlighten other researchers to make a

Sensors 2020, 20, 969

30 of 39

decision on which input data type, deep-learning task, deep-learning model, and dataset is suitable for
achieving their desired medical application and reaching state-of-the-art level. As a lesson learned
from this review, our discussion can also help fellow researchers to make a decision on a deep-learning
task, deep-learning model, training architecture, and dataset. Those are the main parameters that
effects the system performance.
In conclusion, a deep-learning approach has proved promising for bringing those current
contributions to the state-of-the-art level in physiological signal analysis for medical applications.
Author Contributions: Conceptualization, Project administration, and Writing-review and editing was made by
M.H. Methodology, Writing-original draft was made by B.R. Writing-review and editing and Validation was made
by S.M. Data curation and Writing-original draft was made by N.-J.S. All authors have read and agreed to the
published version of the manuscript.
Acknowledgments: This research was supported by the Bio and Medical Technology Development Program of the
National Research Foundation (NRF) funded by the Korean government (MSIT) (No. NRF-2019M3E5D1A02069073)
and was supported by the Soonchunhyang University Research Fund.
Conflicts of Interest: The authors declare no conflict of interest.

Abbreviations
ADHD
AE
ANN
AUC
AUPRC
AUROC
BB
BCI
BRNN
CAM-ICU
CapsNet
CNNE
CP-MixedNet
CssC DBM
DBLSTM-WS
DBM
DBN
DBN-GC
DCNN
DCssC DBM
DL-CCANet
DN-AE-NTM
DNN
EBR
ED
EEG-fNIRs
EL-SDAE
ERP
ESR
ETLE
FPR
GAN
GFM
GRU
HGD

Attention Deficit Hyperactivity Disorder
Auto-encoder
Artificial neural network
Area under the curve
Area under the precision–recall curve
Area under the receiver operating characteristic curve
Bern-Barcelona EEG database
Brain-computer interface
Bi-directional recurrent neural network
Confusion assessment method for the ICU
Capsule network
Convolutional neural network as a feature extractor
Channel-projection mixed-scale convolutional neural network
Contractive Slab and Spike Convolutional Deep Boltzmann Machine
Bi-directional LSTM network-based wavelet sequences
Deep Boltzmann Machine
Deep belief network
Deep belief networks with glia chains
Deep convolution neural network
Discriminative version of CssCDBM
Dual-lead ECGs - canonical correlation analysis and cascaded convolutional network
Deep network - auto-encoder - neural Turing machine
Deep neural network
Error Backpropagation
Emergency department
EEG-Functional near-infrared spectroscopy
Ensemble SDAE classifier with local information preservation
Event-related potential
Epileptic Seizure Recognition dataset
Extra-temporal lobe epilepsy
False prediction rates
Generative adversarial network
Generative flow model
Gated-recurrent unit
High gamma dataset

Sensors 2020, 20, 969

HMM
IC
KFs
LSTM
MEG
MLP
MLR
MMDPN
MPCNN
MTLE
NIP
NMSE
OCNN
PCANet
R3DCNN
RA
RASS
RBM
RCNN
RNN
RR
SAE
SDAE
SEED
SNN
STFT
SVEB
SVM
SWT
TCN
TL-CCANet
TLE
VAE
VEB

31 of 39

Hidden Markov models
Independent component
Polynomial Kalman filters
Long short-term memory
Magnetoencephalographic
Multilayer perceptron
Multilayer logistic regression
Multi-view multi-level deep polynomial network
Multi-perspective convolutional neural network
Mesial temporal lobe epilepsy
Neural interface processor
Normalised mean square error
Orthogonal convolutional neural network
Integrating the principal component analysis (PCA) and a deep-learning model
3D convolutional neural networks
Region aggregation
Richmond agitation-sedation scale
Restricted Boltzmann machine
Recurrent convolutional neural network
Recurrent neural network
Respiratory rate
Stacked auto-encoder
Stacked denoising auto-encoder
SJTU emotion EEG dataset
Spiking neural network
Short-term Fourier transform
Supraventricular ectopic beat
Support vector machine
Stationary wavelet transforms
Temporal convolutional network
Three-lead ECGs - canonical correlation analysis and cascaded convolutional network
Temporal lobe epilepsy
Variational auto-encoder
Ventricular ectopic beat

References
1.
2.
3.
4.

5.
6.
7.

8.

Mu, R.; Zeng, X. A Review of Deep Learning Research. TIISs 2019, 13, 1738–1764. [CrossRef]
Zhang, L.; Jia, J.; Li, Y.; Gao, W.; Wang, M. Deep Learning based Rapid Diagnosis System for Identifying
Tomato Nutrition Disorders. KSII Trans. Internet Inf. Syst. 2019, 13, 2012–2027. [CrossRef]
Ganapathy, N.; Swaminathan, R.; Deserno, T.M. Deep learning on 1-D biosignals: A taxonomy-based survey.
Yearbook Med. Inf. 2018, 27, 98–109. [CrossRef] [PubMed]
Zhang, D.; Yao, L.; Chen, K.; Wang, S.; Chang, X.; Liu, Y. Making Sense of Spatio-Temporal Preserving
Representations for EEG-Based Human Intention Recognition. IEEE Trans. Cybern. 2019, 1–12. [CrossRef]
[PubMed]
PubMed. Available online: https://www.ncbi.nlm.nih.gov/pubmed/ (accessed on 31 October 2019).
Faust, O.; Hagiwara, Y.; Hong, T.J.; Lih, O.S.; Acharya, U.R. Deep learning for healthcare applications based
on physiological signals: A review. Comput. Methods Programs Biomed. 2018, 161, 1–13. [CrossRef] [PubMed]
Tobore, I.; Li, J.; Yuhang, L.; Al-Handarish, Y.; Abhishek, K.; Zedong, N.; Lei, W. Deep Learning Intervention
for Health Care Challenges: Some Biomedical Domain Considerations. JMIR mHealth uHealth 2019, 7, e11966.
[CrossRef]
Baig, M.Z.; Kavkli, M. A Survey on Psycho-Physiological Analysis & Measurement Methods in Multimodal
Systems. Multimodal Technol. Interact 2019, 3, 37. [CrossRef]

Sensors 2020, 20, 969

9.
10.
11.
12.

13.
14.
15.

16.
17.
18.

19.
20.
21.

22.
23.
24.

25.

26.
27.
28.

29.

30.

32 of 39

Yu, Y.; Chen, X.; Cao, S.; Zhang, X.; Chen, X. Exploration of Chinese Sign Language Recognition Using
Wearable Sensors Based on Deep Belief Net. IEEE J. Biomed. Health Inf. 2019. [CrossRef]
Hu, Y.; Wong, Y.; Wei, W.; Du, Y.; Kankanhalli, M.; Geng, W. A novel attention-based hybrid CNN-RNN
architecture for sEMG-based gesture recognition. PLoS ONE 2018, 13, e0206049. [CrossRef]
Wei, W.; Dai, Q.; Wong, Y.; Hu, Y.; Kankanhalli, M.; Geng, W. Surface Electromyography-based Gesture
Recognition by Multi-view Deep Learning. IEEE Trans. Biomed. Eng. 2019, 66, 2964–2973. [CrossRef]
Cote-Allard, U.; Fall, C.L.; Drouin, A.; Campeau-Lecours, A.; Gosselin, C.; Glette, K.; Laviolette, F.; Gosselin, B.
Deep learning for electromyographic hand gesture signal classification using transfer learning. IEEE Trans.
Neural Syst. Rehabil. Eng. 2019, 27, 760–771. [CrossRef] [PubMed]
Sun, W.; Liu, H.; Tang, R.; Lang, Y.; He, J.; Huang, Q. sEMG-Based Hand-Gesture Classification Using a
Generative Flow Model. Sensors 2019, 19, 1952. [CrossRef] [PubMed]
Li, C.; Ren, J.; Huang, H.; Wang, B.; Zhu, Y.; Hu, H. PCA and deep learning based myoelectric grasping
control of a prosthetic hand. Biomed. Eng. Online 2018, 17, 107. [CrossRef] [PubMed]
Rehman, M.Z.; Waris, A.; Gilani, S.O.; Jochumsen, M.; Niazi, I.K.; Jamil, M.; Farina, D.; Kamavuako, E.N.
Multiday EMG-based classification of hand motions with deep learning techniques. Sensors 2018, 18, 2497.
[CrossRef]
Wang, W.; Chen, B.; Xia, P.; Hu, J.; Peng, Y. Sensor Fusion for Myoelectric Control Based on Deep Learning
with Recurrent Convolutional Neural Networks. Artif. Organs 2018, 42, E272–E282. [CrossRef]
Xia, P.; Hu, J.; Peng, Y. EMG-based estimation of limb movement using deep learning with recurrent
convolutional neural networks. Artif. Organs 2018, 42, E67–E77. [CrossRef]
Olsson, A.E.; Sager, P.; Andersson, E.; Bjorkman, A.; Malesevic, N.; Antfolk, C. Extraction of Multi-Labelled
Movement Information from the Raw HD-sEMG Image with Time-Domain Depth. Sci. Rep. 2019, 9, 7244.
[CrossRef]
Khowailed, I.A.; Abotabl, A. Neural muscle activation detection: A deep learning approach using surface
electromyography. J. Biomech. 2019, 95, 109322. [CrossRef]
Rance, L.; Ding, Z.; McGregor, A.H.; Bull, A.M.J. Deep learning for musculoskeletal force prediction.
Ann. Biomed. Eng. 2019, 47, 778–789. [CrossRef]
Dantas, H.; Warren, D.J.; Wendelken, S.M.; Davis, T.S.; Clark, G.A.; Mathews, V.J. Deep Learning Movement
Intent Decoders Trained with Dataset Aggregation for Prosthetic Limb Control. IEEE Trans. Biomed. Eng.
2019, 66, 3192–3203. [CrossRef]
Ameri, A.; Akhaee, M.A.; Scheme, E.; Englehart, K. Real-time, simultaneous myoelectric control using a
convolutional neural network. PLoS ONE 2018, 13, e0203835. [CrossRef]
Nodera, H.; Osaki, Y.; Yamazaki, H.; Mori, A.; Izumi, Y.; Kaji, R. Deep learning for waveform identification
of resting needle electromyography signals. Clin. Neurophysiol. 2019, 130, 617–623. [CrossRef]
Ribeiro, A.L.P.; Paixao, G.M.M.; Gomes, P.R.; Ribeiro, M.H.; Ribeiro, A.H.; Canazart, J.A.; Oliveira, D.M.;
Ferreira, M.P.; Lima, E.M.; Moraes, J.L.; et al. Tele-electrocardiography and bigdata: The CODE
(Clinical Outcomes in Digital Electrocardiography) study. J. Electrocardiol. 2019, 57, S75–S78. [CrossRef]
Cano-Espinosa, C.; Gonzalez, G.; Washko, G.R.; Cazorla, M.; Estepar, R.S.J. Automated Agatston score
computation in non-ECG gated CT scans using deep learning. In Proceedings of the Medical Imaging 2018:
Image Processing, Houston, TX, USA, 2 March 2018. [CrossRef]
Chauhan, S.; Vig, L.; Ahmad, S. ECG anomaly class identification using LSTM and error profile modeling.
Comput. Biol. Med. 2019, 109, 14–21. [CrossRef]
Xia, Y.; Wulan, N.; Wang, K.; Zhang, H. Detecting atrial fibrillation by deep convolutional neural networks.
Comput. Biol. Med. 2018, 93, 84–92. [CrossRef]
Tan, J.H.; Hagiwara, Y.; Pang, W.; Lim, I.; Oh, S.L.; Adam, M.; Tan, R.S.; Chen, M.; Acharya, U.R. Application
of stacked convolutional and long short-term memory network for accurate identification of CAD ECG
signals. Comput. Biol. Med. 2018, 94, 19–26. [CrossRef]
Smith, S.W.; Walsh, B.; Grauer, K.; Wang, K.; Rapin, J.; Li, J.; Fennell, W.; Taboulet, P. A deep neural network
learning algorithm outperforms a conventional algorithm for emergency department electrocardiogram
interpretation. J. Electrocardiol. 2019, 52, 88–95. [CrossRef]
Wang, L.; Zhou, X. Detection of congestive heart failure based on LSTM-based deep network via short-term
RR intervals. Sensors 2019, 19, 1502. [CrossRef]

Sensors 2020, 20, 969

31.

32.

33.
34.

35.
36.
37.
38.
39.

40.
41.

42.
43.
44.

45.
46.
47.
48.

49.

50.

33 of 39

Attia, Z.I.; Sugrue, A.; Asirvatham, S.J.; Acherman, M.J.; Kapa, S.; Freidman, P.A.; Noseworthy, P.A.
Noninvasive assessment of dofetilide plasma concentration using a deep learning (neural network) analysis
of the surface electrocardiogram: A proof of concept study. PLoS ONE 2018, 13, e0201059. [CrossRef]
Chen, M.; Wang, G.; Xie, P.; Sang, Z.; Lv, T.; Zhang, P.; Yang, H. Region Aggregation Network: Improving
Convolutional Neural Network for ECG Characteristic Detection. In Proceedings of the 2018 40th Annual
International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI,
USA, 18–21 July 2018.
Wang, F.; Ma, Q.; Liu, W.; Chang, S.; Wang, H.; He, J.; Huang, Q. A novel ECG signal compression method
using spindle convolutional auto-encoder. Comput. Methods Programs Biomed. 2019, 175, 139–150. [CrossRef]
Wang, E.K.; Xi, I.; Sun, R.; Wang, F.; Pan, L.; Cheng, C.; Dimitrakopoulou-Srauss, A.; Zhe, N.; Li, Y. A new
deep learning model for assisted diagnosis on electrocardiogram. Math. Biosci. Eng. MBE 2019, 16, 2481–2491.
[CrossRef] [PubMed]
Saadatnejad, S.; Oveisi, M.; Hashemi, M. LSTM-Based ECG Classification for Continuous Monitoring on
Personal Wearable Devices. IEEE J. Biomed. Health Inf. 2019, 24, 515–523. [CrossRef] [PubMed]
Brito, C.; Machado, A.; Sousa, A. Electrocardiogram Beat-Classification Based on a ResNet Network.
Stud. Health technol. Inf. 2019, 264, 55–59. [CrossRef]
Xu, S.S.; Mak, M.W.; Cheung, C.C. Towards end-to-end ECG classification with raw signal extraction and
deep neural networks. IEEE J. Biomed. Health Inf. 2018, 23, 1574–1584. [CrossRef]
Yildirim, Ö. A novel wavelet sequence based on deep bidirectional LSTM network model for ECG signal
classification. Comput. Biol. Med. 2018, 96, 189–202. [CrossRef]
Zhao, W.; Hu, J.; Jia, D.; Wang, H.; Li, Z.; Yan, C.; You, T. Deep Learning Based Patient-Specific Classification
of Arrhythmia on ECG signal. In Proceedings of the 2019 41st Annual International Conference of the IEEE
Engineering in Medicine and Biology Society (EMBC); IEEE: Berlin, Germany, 2019. [CrossRef]
Niu, J.; Tang, Y.; Sun, Z.; Zhang, W. Inter-Patient ECG Classification with Symbolic Representations and
Multi-Perspective Convolutional Neural Networks. IEEE J. Biomed. Health Inf. 2019. [CrossRef]
Attia, Z.I.; Kapa, S.; Yao, X.; Lopez-Jimenez, F.; Mohan, T.L.; Pellikka, P.A.; Carter, R.E.; Shah, N.D.;
Friedman, P.A.; Noseworthy, P.A. Prospective validation of a deep learning electrocardiogram algorithm
for the detection of left ventricular systolic dysfunction. J. Cardiovascu Electrophysiol. 2019, 30, 668–674.
[CrossRef]
Yang, W.; Si, Y.; Wang, D.; Zhang, G. A Novel Approach for Multi-Lead ECG Classification Using DL-CCANet
and TL-CCANet. Sensors 2019, 19, 3214. [CrossRef]
Yoon, D.; Lim, H.; Jung, K.; Kim, T.; Lee, S. Deep Learning-Based Electrocardiogram Signal Noise Detection
and Screening Model. Healthcare Inf. Res. 2019, 25, 201–211. [CrossRef]
Ansari, S.; Gryak, J.; Najarian, K. Noise Detection in Electrocardiography Signal for Robust Heart Rate
Variability Analysis: A Deep Learning Approach. In Proceedings of the 2018 40th Annual International
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI, USA, 18–21
July 2018.
Jeon, E.; Jung, B.; Nam, Y.; Lee, H. Classification of Premature Ventricular Contraction using Error
Back-Propagation. KSII Trans. Internet Inf. Syst. 2018, 12, 988–1001. [CrossRef]
Byeon, Y.; Pan, S.; Kwak, K. Intelligent deep models based on scalograms of electrocardiogram signals for
biometrics. Sensors 2019, 19, 935. [CrossRef] [PubMed]
Mathews, S.M.; Kambhamettu, C.; Barner, K.E. A novel application of deep learning for single-lead ECG
classification. Comput. Biol. Med. 2018, 99, 53–62. [CrossRef] [PubMed]
Picon, A.; Irusta, U.; Alvarez-Gila, A.; Aramendi, E.; Alonso-Atienza, F.; Figuera, C.; Ayala, U.; Garrote, E.;
Wik, L.; Kramer-Johansen, J.; et al. Mixed convolutional and long short-term memory network for the
detection of lethal ventricular arrhythmia. PLoS ONE 2019, 14, e0216756. [CrossRef] [PubMed]
Yildirim, O.; Baloglu, U.B.; Tan, R.; Ciaccio, E.J.; Acharya, U.R. A new approach for arrhythmia classification
using deep coded features and LSTM networks. Comput. Methods Programs Biomed. 2019, 176, 121–133.
[CrossRef] [PubMed]
Oh, S.L.; Ng, E.Y.K.; Tan, R.S.; Acharya, U.R. Automated diagnosis of arrhythmia using combination of CNN
and LSTM techniques with variable length heart beats. Comput. Biol. Med. 2018, 102, 278–287. [CrossRef]
[PubMed]

Sensors 2020, 20, 969

51.
52.

53.

54.
55.
56.

57.

58.
59.
60.

61.

62.
63.
64.
65.
66.

67.

68.

69.

70.

71.

34 of 39

He, Z.; Zhang, X.; Cao, Y.; Liu, Z.; Zhang, B.; Wang, X. LiteNet: Lightweight neural network for detecting
arrhythmias at resource-constrained mobile devices. Sensors 2018, 18, 1229. [CrossRef]
Erdenebayar, U.; Kim, H.; Park, J.; Kang, D.; Lee, K. Automatic Prediction of Atrial Fibrillation Based on
Convolutional Neural Network Using a Short-term Normal Electrocardiogram Signal. J. Korean Med. Sci.
2019, 34. [CrossRef]
Oh, S.L.; Ng, E.Y.K.; Tan, R.S.; Acharya, U.R. Automated beat-wise arrhythmia diagnosis using modified
U-net on extended electrocardiographic recordings with heterogeneous arrhythmia types. Comput. Biol. Med.
2019, 105, 92–101. [CrossRef]
Savalia, S.; Emamian, V. Cardiac arrhythmia classification by multi-layer perceptron and convolution neural
networks. Bioengineering 2018, 5, 35. [CrossRef]
Yıldırım, Ö.; Plawiak, P.; Tan, R.S.; Acharya, U.R. Arrhythmia detection using deep convolutional neural
network with long duration ECG signals. Comput. Biol. Med. 2018, 102, 411–420. [CrossRef]
Hannun, A.Y.; Rajpurkar, P.; Haghpanahi, M.; Tison, G.H.; Bourn, C.; Turakhia, M.P.; Ng, A.Y.
Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep
neural network. Nat. Med. 2019, 25, 65–69. [CrossRef] [PubMed]
Yildirim, O.; Talo, M.; Ay, B.; Baloglu, U.B.; Aydin, G.; Acharya, U.R. Automated detection of diabetic
subject using pre-trained 2D-CNN models with frequency spectrum images extracted from heart rate signals.
Comput. Biol. Med. 2019, 113, 103387. [CrossRef] [PubMed]
Xiao, R.; Xu, Y.; Pelter, M.M.; Mortara, D.W.; Hu, X. A deep learning approach to examine ischemic ST
changes in ambulatory ECG recordings. AMIA Summits Transl. Sci. Proc. 2018, 2018, 256.
Ji, Y.; Zhang, S.; Xiao, W. Electrocardiogram Classification Based on Faster Regions with Convolutional
Neural Network. Sensors 2019, 19, 2558. [CrossRef] [PubMed]
Liu, M.; Kim, Y. Classification of Heart Diseases Based On ECG Signals Using Long Short-Term Memory.
In Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), Honolulu, HI, USA, 18–21 July 2018.
Sbrollini, A.; Jongh, M.C.; Haar, C.C.T.; Treskes, R.W.; Man, S.; Burattini, L.; Swenne, C.A. Serial
electrocardiography to detect newly emerging or aggravating cardiac pathology: A deep-learning approach.
Biomed. Eng. Online 2019, 18, 15. [CrossRef]
Seo, W.; Kim, N.; Lee, C.; Park, S. Deep ECG-Respiration Network (DeepER Net) for Recognizing Mental
Stress. Sensors 2019, 19, 3021. [CrossRef]
Nguyen, M.T.; Nguyen, B.V.; Kim, K. Deep Feature Learning for Sudden Cardiac Arrest Detection in
Automated External Defibrillators. Sci. Rep. 2018, 8, 17196. [CrossRef]
Wang, L.; Lin, Y.; Wang, J. A RR interval based automated apnea detection approach using residual network.
Comput. Methods Programs Biomed. 2019, 176, 93–104. [CrossRef]
Dey, D.; Chaudhuri, S.; Munshi, S. Obstructive sleep apnoea detection using convolutional neural network
based deep learning framework. Biomed. Eng. lett. 2018, 8, 95–100. [CrossRef]
Kido, K.; Tamura, T.; Ono, N.; Altaf-Ul-Amin, M.; Sekine, M.; Kanaya, S.; Huang, M. A Novel CNN-Based
Framework for Classification of Signal Quality and Sleep Position from a Capacitive ECG Measurement.
Sensors 2019, 19, 1731. [CrossRef]
Erdenebayar, U.; Kim, Y.J.; Park, J.; Joo, E.; Lee, K. Deep learning approaches for automatic detection of sleep
apnea events from an electrocardiogram. Comput. Methods Programs Biomed. 2019, 180, 105001. [CrossRef]
[PubMed]
Wang, T.; Lu, C.; Shen, G.; Hong, F. Sleep apnea detection from a single-lead ECG signal with automatic
feature-extraction through a modified LeNet-5 convolutional neural network. PeerJ 2019, 7. [CrossRef]
[PubMed]
Hwang, B.; You, J.; Vaessen, T.; Myin-Germeys, I.; Park, C.; Zhang, B.T. Deep ECGNet: An optimal deep
learning framework for monitoring mental stress using ultra short-term ECG signals. TELEMEDICINE
e-HEALTH 2018, 24, 753–772. [CrossRef] [PubMed]
Attia, Z.I.; Friedman, P.A.; Noseworthy, P.A.; Ladewig, D.J.; Satam, G.; Pellikka, P.A.; Munger, T.M.;
Asirvatham, S.J.; Scott, C.G.; Carter, R.E.; et al. Age and sex estimation using artificial intelligence from
standard 12-lead ECGs. Circ. Arrhythmia Electrophysiol. 2019, 12. [CrossRef]
Toraman, S.; Tuncer, S.A.; Balgetir, F. Is it possible to detect cerebral dominance via EEG signals by using
deep learning? Med. Hypotheses 2019, 131. [CrossRef]

Sensors 2020, 20, 969

72.
73.
74.

75.

76.
77.
78.

79.

80.

81.
82.

83.
84.
85.
86.

87.

88.

89.
90.

91.
92.

35 of 39

Doborjeh, Z.G.; Kasabov, N.; Doborjeh, M.G.; Sumich, A. Modelling peri-perceptual brain processes in a
deep learning spiking neural network architecture. Sci. Rep. 2018, 8. [CrossRef]
Kshirsagar, G.B.; Londhe, N.D. Improving Performance of Devanagari Script Input-Based P300 Speller Using
Deep Learning. IEEE Trans. Biomed. Eng. 2018, 66, 2992–3005. [CrossRef]
Roy, S.; Kiral-Kornek, I.; Harrer, S. Deep learning enabled automatic abnormal EEG identification.
In Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), Honolulu, HI, USA, 18–21 July 2018.
Lei, B.; Liu, X.; Liang, S.; Hang, W.; Wang, Q.; Choi, K.; Qin, J. Walking imagery evaluation in brain computer
interfaces via a multi-view multi-level deep polynomial network. IEEE Trans. Neural Syst. Rehabil. Eng. 2019,
27, 497–506. [CrossRef]
Li, J.; Yu, Z.L.; Gu, Z.; Wu, W.; Li, Y.; Jin, L. A hybrid network for ERP detection and analysis based on
restricted Boltzmann machine. IEEE Trans. Neural Syst. Rehabil. Eng. 2018, 26, 563–572. [CrossRef]
Vahid, A.; Bluschke, A.; Roessner, V.; Stober, S.; Beste, C. Deep Learning Based on Event-Related EEG
Differentiates Children with ADHD from Healthy Controls. J. Clin. Med. 2019, 8, 1055. [CrossRef]
Tjepkema-Cloostermans, M.C.; Carvalho, R.C.V.; Putten, M.J.A.M. Deep learning for detection of focal
epileptiform discharges from scalp EEG recordings. Clin. Neurophysiol. 2018, 129, 2191–2196. [CrossRef]
[PubMed]
Yang, S.; Yin, Z.; Wang, Y.; Zhang, W.; Wang, Y.; Zhang, J. Assessing cognitive mental workload via EEG
signals and an ensemble deep learning classifier based on denoising autoencoders. Comput. Biol. Med. 2019,
109, 159–170. [CrossRef] [PubMed]
Ravindran, A.S.; Mobiny, A.; Cruz-Garza, J.G.; Paek, A.; Kopteva, A.; Vidal, J.L.C. Assaying neural activity of
children during video game play in public spaces: A deep learning approach. J. Neural Eng. 2019, 16, 12.
[CrossRef]
Zhao, D.; Tang, F.; Si, B.; Feng, X. Learning joint space–time–frequency features for EEG decoding on small
labeled data. Neural Networks 2019, 114, 67–77. [CrossRef]
Zhang, P.; Wang, X.; Zhang, W.; Chen, J. Learning Spatial–Spectral–Temporal EEG Features With Recurrent
3D Convolutional Neural Networks for Cross-Task Mental Workload Assessment. IEEE Trans. Neural Syst.
Rehabil. Eng. 2018, 27, 31–42. [CrossRef]
Sakhavi, S.; Guan, C.; Yan, S. Learning temporal information for brain-computer interface using convolutional
neural networks. IEEE Trans. Neural Networks Learn. Syst. 2018, 29, 5619–5629. [CrossRef]
Ha, K.W.; Jeong, J.W. Motor Imagery EEG Classification Using Capsule Networks. Sensors 2019, 19, 2854.
[CrossRef]
Majidov, I.; Whangbo, T. Efficient Classification of Motor Imagery Electroencephalography Signals Using
Deep Learning Methods. Sensors 2019, 19, 1736. [CrossRef]
Li, Y.; Zhang, X.R.; Zhang, B.; Lei, M.Y.; Cui, W.G.; Guo, Y.Z. A Channel-Projection Mixed-Scale Convolutional
Neural Network for Motor Imagery EEG Decoding. IEEE Trans. Neural Syst. Rehabil. Eng. 2019, 27, 1170–1180.
[CrossRef]
Abbas, W.; Khan, N.A. DeepMI: Deep Learning for Multiclass Motor Imagery Classification. In Proceedings
of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society
(EMBC), Honolulu, HI, USA, 18–21 July 2018.
Tayeb, Z.; Fedjaev, J.; Ghaboosi, N.; Richter, C.; Everding, L.; Qu, X.; Wu, Y.; Cheng, G.; Conradt, J. Validating
deep neural networks for online decoding of motor imagery movements from EEG signals. Sensors 2019, 19,
210. [CrossRef]
Lee, H.C.; Ryu, H.G.; Chung, E.J.; Jung, C.W. Prediction of bispectral index during target-controlled infusion
of propofol and remifentanil. Anesthesiology 2018, 128, 492–501. [CrossRef] [PubMed]
Zhang, P.; Wang, X.; Chen, J.; You, W.; Zhang, W. Spectral and Temporal Feature Learning With Two-Stream
Neural Networks for Mental Workload Assessment. IEEE Trans. Neural Syst. Rehabil. Eng. 2019, 27,
1149–1159. [CrossRef] [PubMed]
Zhang, X.; Wu, D. On the Vulnerability of CNN Classifiers in EEG-Based BCIs. IEEE Trans. Neural Syst.
Rehabil. Eng. 2019, 17, 814–825. [CrossRef] [PubMed]
Ahmedt-Aristizabal, D.; Fooke, C.; Denman, S.; Nguyen, K.; Sridharan, S.; Dionisio, S. Aberrant epileptic
seizure identification: A computer vision perspective. Seizure 2019, 65, 65–71. [CrossRef]

Sensors 2020, 20, 969

93.
94.
95.
96.

97.

98.
99.
100.

101.
102.

103.

104.
105.
106.

107.
108.
109.

110.
111.

112.

113.

36 of 39

Mumtaz, W.; Qayyum, A. A deep learning framework for automatic diagnosis of unipolar depression. Int. J.
Med. Inform. 2019, 132. [CrossRef]
Kim, S.; Kim, J.; Chun, H.W. Wave2Vec: Vectorizing Electroencephalography Bio-Signal for Prediction of
Brain Disease. Int. J. Environ. Res. Publ. Health 2018, 15, 1750. [CrossRef]
Golmohammadi, M.; Torbati, A.H.H.N.; Diego, S.L.; Obeid, I.; Picone, J. Automatic analysis of EEGs using
big data and hybrid deep learning architectures. Front. Hum. Neurosci. 2019, 13, 76. [CrossRef]
Zhou, Y.; Xu, T.; Li, S.; Li, S. Confusion State Induction and EEG-based Detection in Learning. In Proceedings
of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society
(EMBC), Honolulu, HI, USA, 18–21 July 2018.
Acharya, U.R.; Oh, S.L.; Hagiwara, Y.; Tan, J.H.; Adeli, H.; Subha, D.P. Automated EEG-based screening of
depression using deep convolutional neural network. Comput. Methods Programs Biomed. 2018, 161, 103–113.
[CrossRef]
Bi, X.; Wang, H. Early Alzheimer’s disease diagnosis based on EEG spectral images using deep learning.
Neural Networks 2019, 114, 119–135. [CrossRef]
Wei, X.; Zhou, L.; Zhang, Z.; Chen, Z.; Zhou, Y. Early prediction of epileptic seizures using a long-term
recurrent convolutional network. J. Neurosci. Methods 2019, 327, 108395. [CrossRef]
Kim, D.; Kim, K. Detection of Early Stage Alzheimer’s Disease using EEG Relative Power with Deep Neural
Network. In Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in
Medicine and Biology Society (EMBC), Honolulu, HI, USA, 18–21 July 2018.
Dai, M.; Zheng, D.; Na, R.; Wang, S.; Zhang, S. EEG Classification of Motor Imagery Using a Novel Deep
Learning Framework. Sensors 2019, 19, 551. [CrossRef] [PubMed]
Tian, X.; Deng, Z.; Ying, W.; Choi, K.S.; Wu, D.; Qin, B.; Wan, J.; Shen, H.; Wang, S. Deep multi-view feature
learning for EEG-based epileptic seizure detection. IEEE Trans. Neural Syst. Rehabil. Eng. 2019, 27, 1962–1972.
[CrossRef] [PubMed]
Jonas, S.; Rossetti, A.O.; Oddo, M.; Jenni, S.; Favaro, P.; Zubler, F. EEG-based outcome prediction after
cardiac arrest with convolutional neural networks: Performance and visualization of discriminative features.
Hum. Brain Mapp. 2019, 40, 4606–4617. [CrossRef] [PubMed]
Türk, Ö.; Özerdem, M.S. Epilepsy Detection by Using Scalogram Based Convolutional Neural Network from
EEG Signals. Brain Sci. 2019, 9, 115. [CrossRef]
Hao, Y.; Khoo, H.M.; Ellenrieder, N.; Zazubovits, N.; Gotman, J. DeepIED: An epileptic discharge detector
for EEG-fMRI based on deep learning. NeuroImage Clin. 2018, 17, 962–975. [CrossRef]
San-Segundo, R.; Gil-Martin, M.; D’Haro-Enriquez, L.F.; Pardo, J.M. Classification of epileptic EEG recordings
using signal transforms and convolutional neural networks. Comput. Biol. Med. 2019, 109, 148–158.
[CrossRef]
Korshunova, I.; Kindermans, P.J.; Degrave, J.; Verhoeven, T.; Brinkmann, B.H.; Dambre, J. Towards improved
design and evaluation of epileptic seizure predictors. IEEE Trans. Biomed. Eng. 2018, 65, 502–510. [CrossRef]
Daoud, H.; Bayoumi, M. Efficient Epileptic Seizure Prediction based on Deep Learning. IEEE Trans. Biomed.
Circ. Syst. 2019, 13, 804–813. [CrossRef]
Kiral-Kornek, I.; Roy, S.; Nurse, E.; Mashford, B.; Karoly, P.; Carroll, T.; Payne, D.; Saha, S.; Baldassano, S.;
O’Brien, T.; et al. Epileptic seizure prediction using big data and deep learning: Toward a mobile system.
EBioMedicine 2018, 27, 103–111. [CrossRef]
Hussein, R.; Palangi, H.; Ward, R.K.; Wang, Z.J. Optimized deep neural network architecture for robust
detection of epileptic seizures using EEG signals. Clin. Neurophysiol. 2019, 130, 25–37. [CrossRef]
Tsiouris, K.M.; Pezoulas, V.C.; Zervaski, M.; Konitsiotis, S.; Doutsouris, D.D.; Fotiadis, D.I. A Long Short-Term
Memory deep learning network for the prediction of epileptic seizures using EEG signals. Comput. Biol. Med.
2018, 99, 24–37. [CrossRef]
Phang, C.R.; Norman, F.; Hussain, H.; Ting, C.M.; Ombao, H. A Multi-Domain Connectome Convolutional
Neural Network for Identifying Schizophrenia from EEG Connectivity Patterns. IEEE J. Biomed. Health Inf.
2019. [CrossRef]
Gleichgerrcht, E.; Munsell, B.; Bhatia, S.; Vandergrift III, W.A.; Rorden, C.; McDonald, C.; Edwards, J.;
Kuzniecky, R.; Bonilha, L. Deep learning applied to whole-brain connectome to determine seizure control
after epilepsy surgery. Epilepsia 2018, 59, 1643–1654. [CrossRef]

Sensors 2020, 20, 969

37 of 39

114. Sirpal, P.; Kassab, A.; Pouliot, P.; Nguyen, D.K.; Lesage, F. fNIRS improves seizure detection in multimodal
EEG-fNIRS recordings. J. Biomed. Opt. 2019, 24, 051408. [CrossRef]
115. Emami, A.; Kunii, N.; Matsuo, T.; Shinozaki, T.; Kawai, K.; Takahashi, H. Seizure detection by convolutional
neural network-based analysis of scalp electroencephalography plot images. NeuroImage Clin. 2019, 22,
101684. [CrossRef]
116. Acharya, U.R.; Oh, S.L.; Hagiwara, Y.; Tan, J.H.; Adeli, H. Deep convolutional neural network for the
automated detection and diagnosis of seizure using EEG signals. Comput. Biol. Med. 2018, 100, 270–278.
[CrossRef]
117. Wei, X.; Zhou, L.; Chen, Z.; Zhang, L.; Zhou, Y. Automatic seizure detection using three-dimensional CNN
based on multi-channel EEG. BMC Med. Inf. Decis. Making 2018, 18, 111. [CrossRef]
118. Yuan, Y.; Xun, G.; Jia, K.; Zhang, A. A Multi-View Deep Learning Framework for EEG Seizure Detection.
IEEE J. Biomed. Health Inf. 2018, 23, 83–94. [CrossRef]
119. Ahmedt-Aristizabal, D.; Fookes, C.; Nguyen, K.; Sridharan, S. Deep classification of epileptic signals.
In Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), Honolulu, HI, USA, 18–21 July 2018.
120. Jang, H.J.; Cho, K.O. Dual deep neural network-based classifiers to detect experimental seizures. The Korean
Can. J. Physiol. Pharmacol. 2019, 23, 131–139. [CrossRef]
121. Sun, H.; Kimchi, E.; Akeju, O.; Nagaraj, S.B.; McClain, L.M.; Zhou, D.W.; Boyle, E.; Zheng, W.L.; Ge, W.;
Westover, M.B. Automated tracking of level of consciousness and delirium in critical illness using deep
learning. NPJ Digital Med. 2019, 2, 1–8. [CrossRef]
122. Kwon, Y.H.; Shin, S.B.; Kim, S.D. Electroencephalography based fusion two-dimensional (2D)-convolution
neural networks (CNN) model for emotion recognition system. Sensors 2018, 18, 1383. [CrossRef] [PubMed]
123. Chao, H.; Dong, L.; Liu, Y.; Lu, B. Emotion Recognition from Multiband EEG Signals Using CapsNet. Sensors
2019, 19, 2212. [CrossRef] [PubMed]
124. Zhang, T.; Zheng, W.; Cui, Z.; Zong, Y.; Li, Y. Spatial–temporal recurrent neural network for emotion
recognition. IEEE Trans. Cybern. 2018, 49, 839–847. [CrossRef] [PubMed]
125. Bălan, O.; Moise, G.; Moldoveanu, A.; Leordeanu, M.; Moldoveanu, F. Fear Level Classification Based on
Emotional Dimensions and Machine Learning Techniques. Sensors 2019, 19, 1738. [CrossRef]
126. Zheng, W.L.; Liu, W.; Lu, Y.; Lu, B.L.; Cichocki, A. Emotionmeter: A multimodal framework for recognizing
human emotions. IEEE Trans. Cybern. 2018, 49, 1110–1122. [CrossRef]
127. Chao, H.; Zhi, H.; Dong, L.; Liu, Y. Recognition of emotions using multichannel EEG data and DBN-GC-based
ensemble deep learning framework. Comput. Intell. Neurosci. 2018, 2018, 9750904. [CrossRef]
128. Yohanandan, S.A.C.; Kiral-Kornek, I.; Tang, J.; Mashford, B.S.; Asif, U.; Harrer, S. A Robust Low-Cost EEG
Motor Imagery-Based Brain-Computer Interface. In Proceedings of the 2018 40th Annual International
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI, USA, 18–21
July 2018.
129. Choi, E.J.; Kim, D.K. Arousal and Valence Classification Model Based on Long Short-Term Memory and
DEAP Data for Mental Healthcare Management. Healthcare Inf. res. 2018, 24, 309–316. [CrossRef]
130. Chambon, S.; Thorey, V.; Arnal, P.J.; Mignot, E.; Gramfort, A. DOSED: A deep learning approach to detect
multiple sleep micro-events in EEG signal. J. Neurosci. Methods 2019, 321, 64–78. [CrossRef]
131. Ma, Y.; Chen, B.; Li, R.; Wang, C.; Wang, J.; She, Q.; Luo, Z.; Zhang, Y. Driving fatigue detection from EEG
using a modified PCANet method. Comput. Intell. Neurosci. 2019, 2019, 9. [CrossRef]
132. Van Leeuwen, K.G.; Sun, H.; Tabaeizadeh, M.; Struck, A.F.; Putten, M.J.A.M.; Westover, M.B. Detecting
abnormal electroencephalograms using deep convolutional networks. Clin. Neurophysiology 2019, 130, 77–84.
[CrossRef]
133. Kulkarni, P.M.; Xiao, Z.; Robinson, E.J.; Jami, A.S.; Zhang, J.; Zhou, H.; Henin, S.E.; Liu, A.A.; Osorio, R.S.;
Wang, J.; et al. A deep learning approach for real-time detection of sleep spindles. J. Neural Eng. 2019, 16,
036004. [CrossRef] [PubMed]
134. Bresch, E.; Grossekathofer, U.; Garcia-Molina, G. Recurrent deep neural networks for real-time sleep stage
classification from single channel EEG. Front. Comput. Neurosci. 2018, 12, 85. [CrossRef] [PubMed]

Sensors 2020, 20, 969

38 of 39

135. Phan, H.; Andreotti, F.; Cooray, N.; Chen, O.Y.; Vos, M.D. DNN filter bank improves 1-max pooling CNN for
single-channel EEG automatic sleep stage classification. In Proceedings of the 2018 40th Annual International
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI, USA, 18–21
July 2018.
136. Phan, H.; Andreotti, F.; Cooray, N.; Chen, O.Y.; Vos, M.D. Automatic sleep stage classification
using single-channel eeg: Learning sequential features with attention-based recurrent neural networks.
In Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), Honolulu, HI, USA, 18–21 July 2018.
137. Zhang, J.; Wu, Y. Complex-valued unsupervised convolutional neural networks for sleep stage classification.
Comput. Methods Programs Biomed. 2018, 164, 181–191. [CrossRef] [PubMed]
138. Mousavi, S.; Afghah, F.; Acharya, U.R. SleepEEGNet: Automated sleep stage scoring with sequence to
sequence deep learning approach. PLoS ONE 2019, 14, e0216456. [CrossRef] [PubMed]
139. Mousavi, Z.; Rezaii, T.Y.; Sheykhivand, S.; Farzamnia, A.; Razavi, S.N. Deep convolutional neural network
for classification of sleep stages from single-channel EEG signals. J. Neurosci. Methods 2019, 324, 108312.
[CrossRef]
140. Zhang, J.; Yao, R.; Ge, W.; Gao, J. Orthogonal convolutional neural networks for automatic sleep stage
classification based on single-channel EEG. Comput. Methods Programs Biomed 2019, 183, 105089. [CrossRef]
141. Malafeev, A.; Laptev, D.; Bauer, S.; Omlin, X.; Wierzbicka, A.; Wichniak, A.; Jernajczyk, W.; Riener, R.;
Buhmann, J.; Achermann, P. Automatic human sleep stage scoring using deep neural networks. Front.
Neurosci. 2018, 12, 781. [CrossRef]
142. Goh, S.K.; Abbass, H.A.; Tan, K.C.; Al-Mamun, A.; Thakor, N.; Bezerianos, A.; Li, J. Spatio–Spectral
Representation Learning for Electroencephalographic Gait-Pattern Classification. IEEE Trans. Neural Syst.
Rehabil. Eng. 2018, 26, 1858–1867. [CrossRef]
143. Ma, X.; Qiu, S.; Du, C.; Xing, J.; He, H. Improving EEG-Based Motor Imagery Classification via Spatial and
Temporal Recurrent Neural Networks. In Proceedings of the 2018 40th Annual International Conference of
the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI, USA, 18–21 July 2018.
144. Villalba-Diez, J.; Zheng, X.; Schmidt, D.; Molina, M. Characterization of Industry 4.0 Lean Management
Problem-Solving Behavioral Patterns Using EEG Sensors and Deep Learning. Sensors 2019, 19, 2841.
[CrossRef]
145. Ruffini, G.; Ibanez, D.; Castellano, M.; Dubreuil-Vall, L.; Soria-Frisch, A.; Postuma, R.; Gagnon, J.F.;
Montplaisir, J. Deep learning with EEG spectrograms in rapid eye movement behavior disorder. Front.
Neurol. 2019, 10, 1–9. [CrossRef]
146. Van Putten, M.J.A.M.; Olbrich, S.; Arns, M. Predicting sex from brain rhythms with deep learning. Sci. Rep.
2018, 8, 3069. [CrossRef] [PubMed]
147. Boloukian, B.; Safi-Esfahani, F. Recognition of words from brain-generated signals of speech-impaired people:
Application of autoencoders as a neural Turing machine controller in deep neural networks. Neural Networks
2019, 121, 186–207. [CrossRef] [PubMed]
148. Kostas, D.; Pang, E.W.; Rudzicz, F. Machine learning for MEG during speech tasks. Sci. Rep. 2019, 9, 1609.
[CrossRef] [PubMed]
149. Lee, W.; Kim, Y. Interactive sleep stage labelling tool for diagnosing sleep disorder using deep learning. In
Proceedings of the 2018 40th Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), Honolulu, HI, USA, 18–21 July 2018.
150. Sokolovsky, M.; Guerrero, F.; Paisarnsrisomsuk, S.; Ruiz, C.; Alvarez, S.A. Deep learning for automated
feature discovery and classification of sleep stages. IEEE/ACM Trans. Comput. Biol. Bioinf. 2019. [CrossRef]
151. Chambon, S.; Galtier, M.N.; Arnal, P.J.; Wainrib, G.; Gramfort, A. A deep learning architecture for temporal
sleep stage classification using multivariate and multimodal time series. IEEE Trans. Neural Syst. Rehabil.
Eng. 2018, 26, 758–769. [CrossRef]
152. Andreotti, F.; Phan, H.; Cooray, N.; Lo, C.; Hu, M.T.M.; Vos, M.D. Multichannel sleep stage classification and
transfer learning using convolutional neural networks. In Proceedings of the 2018 40th Annual International
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Honolulu, HI, USA, 18–21
July 2018.
153. Yildirim, O.; Baloglu, U.B.; Acharya, U.R. A deep learning model for automated sleep stages classification
using psg signals. Int. J. Environ. Res. Publ. Health 2019, 16, 599. [CrossRef]

Sensors 2020, 20, 969

39 of 39

154. Croce, P.; Zappasodi, F.; Marzetti, L.; Merla, A.; Pizzella, V.; Chiarelli, A.M. Deep Convolutional
Neural Networks for feature-less automatic classification of Independent Components in multi-channel
electrophysiological brain recordings. IEEE Trans. Biomed. Eng. 2018, 66, 2372–2380. [CrossRef]
155. Goodfellow, I.; Bengio, Y.; Courville, A. Practical Methodology. In Deep Learning; MIT Press: Cambridge,
MA, USA, 2016; pp. 416–437.
© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).

