Jurnal
Teknologi

Full Paper

TOWARDS THE DEVELOPMENT OF A ELECTROENCEPHALOGRAPHY
BASED
NEUROPROSTHETIC
TERMINAL DEVICE

Article history
Received
16 February 2015
Received in revised form
30 April 2015
Accepted
30 June 2015

Khairunnisa Johara, Cheng Yee Lowa*, Fazah Akhtar Hanapiahb,
Ahmed Jaffara, Farhana Idrisa, Mohamad Amlie Abu Kasima
aFaculty

of Mechanical Engineering, Universiti Teknologi MARA,
Malaysia
bFaculty of Medicine, Universiti Teknologi MARA, Malaysia
Graphical abstract

Neural
Signal

*Corresponging author
chengyee.low@salam.uitm.
edu.my

Abstract
Brain-Computer Interface (BCI) using Electroencephalography (EEG) enables noninvasive direct control between human brain and machine and opens up new
possibilities in providing healthcare solutions for people with severe motor impairment.
This paper reviews the recent trends in neuroprostheses and presents a conceptual
design for the development of a cost-effective neuroprosthetic hand deploying EEG
signals. Towards the development of a brain-computer interface for neuroprostheses,
EEG signals are recorded from healthy subjects using the Emotiv Suite Software. The
recognition phase and signal analysis are performed using the EEGLab Software.
Signal processing is required until clear rhythmic waves are obtained as a command
to control a prosthetic hand. A Graphical User Interface (GUI) will be developed using
Matlab Software and aided with 3D Animation as a medium of interaction for basic
training for the patient before using the prosthetic hand.
Keywords: Brain computer interface, neuroprostheses, electroencephalography
© 2015 Penerbit UTM Press. All rights reserved

1.0 INTRODUCTION
BCI is a technology where the device records a
certain area of brain activities and gives a command
to an external device such as robot and prosthesis.
There are four methods that record microvolt-level
extracellular potentials generated by neurons in the
cortical
layers;
Electroencephalography
(EEG),
Electrocorticography (ECoG), Local Field Potentials
(LFPs), and single-neuron action potential recordings
(single units) [1]. Generally, electroencephalography
are historically dominated by BCI researchers as
providing non-invasive, cheap equipment, excellent
resolution, painless, ease of use, portable and no
implantation approaches. The input was obtained
from EEG mental tasks that include movement of a
limb, respiratory, speech, heart and more.

In this paper, our focus of research is to help upper
limb amputees to control prosthetic hand developed
by our team using non-invasive technique EEG based
BCI.

2.0 STATE-OF-THE-ART
Guger et al. [2] controlled the prosthetic hand, also
known as the terminal device to grasp and release
using EEG amplifier, which focused on electrode
position C3 and C4 from one healthy subject. The
experiment was done with imagery of hand grasp and
release by the subject to move the prosthetic terminal
device.

76:4 (2015) 77–82 | www.jurnalteknologi.utm.my | eISSN 2180–3722 |

78

Khairunnisa Johar et al. / Jurnal Teknologi (Sciences & Engineering) 76:4 (2015) 77–82
Table 1 Comparison of prosthesis hand control using EEG based Brain Computer Interface

Control of an Electrical
Prosthesis With an
SSVEP-Based BCI

Design on the System
of Brain-Computer
Interface Driving
Neural Prosthesis
Hand

Brain EEG Signal
Processing For
Controlling a Robotic
Arm

Towards BrainComputer Interface
Control of a 6-Degreeof-Freedom Robotic
Arm Using Dry EEG
Electrodes

Christoph Guger,
Werner Harkam,
Carin Hertnaes,
Gert Pfurtscheller

Gernot R. Müller-Putz,
Gert Pfurtscheller,

Xiao-Dong Zhang,
Yun-Xia Wang

Howida A.Shedeed,
Mohamed F.Issa, Salah
M.El-sayed

Alexander Astaras,
Nikolaos Moustakas,
Alkinoos Athanasiou,
Aristides Gogoussis

Years

1999

2008

2009

2013

2013

EEG Data

One healthy
subject.

Four healthy volunteers
(aged 18–29 years old,
two males, and two
females

One healthy subject.

A healthy subject, 26
year old, male

34 healthy subjects (25
males, 9 females)

If the person
imagined a left
movement, then
the prosthesis was
closed and vice
versa.

Four written instructions
appeared with a short
beep tone in a row on
the top of the screen:
left, right, open, and
close. One of the
commands had a
different color
indicating to the
subjects which flickering
light need to be
focused on.

Data recorded
during the hand
movement. Subject
needs to move four
task (arm’s free state,
arm movement,
hand crawl, hand
open)

Data recorded during
the hand movement.
Subject needs to move
three task (close, open
arm and close hand)

-

Device

EEG amplifier

Ag/AgCl electrodes

-

Emotiv

Emotiv

Channel
Selected

C3 and C4

O1 and O2

-

AF3,F7,F3 and FC5

-

Prosthesis
Movement

Open and close
hand

Grasp function (open
and closing of the
fingers), a wrist rotation
(to the left and right).

Arm waiting state,
arm movement,
hand crawl and
hand open

Three movements
(close, open arm and
close hand)

Pitch, yaw, and roll at
the shoulder joint, pitch
and roll at the elbow,
pitch and yaw at the
wrist.

Feature
Extraction
Method

Adaptive
Autoregressive
(AAR)

Discrete Fourier
transform (DFT)

Power Spectral
Density (PSD)

Wavelet Transform (WT),
Fast Fourier
Transformation (FFT)
and Principal
Component Analysis
(PCA)

-

Classification
Method

Linear Discriminant
Analysis LDA

-

Support Vector
Machine (SVM) and
Back Propagation
(BP) Neural Network

Back Propagation (BP)
Neural Network

-

Classification
Accuracy

82.5, 88.75 and
90%.

Between 44% and 88%

-

91.1%, 86.7%and 85.6%

-

Title

Prosthetic Control
by an EEG-based
Brain Computer
Interface (BCI)

Authors

Experiment
Sessions

Model of
Prosthetic

79

Khairunnisa Johar et al. / Jurnal Teknologi (Sciences & Engineering) 76:4 (2015) 77–82

For the signal processing concept, this paper used
adaptive autoregressive model as the feature
extraction method and Linear Discriminant Analysis
(LDA) as the classification method. In this project,
classification accuracies 82.5, 88.75 and 90% were
achieved. Even though the paper is applying imagery
to the prosthetic hand, but the imagery data
recorded is not accordance with the application.
In 2008, Pfurtscheller and Müller-Putz were study to
control two axes electrical hand prosthesis by Steady
State Visual Evoked Potential (SSVEP) based BCI
concept [3]. Using an SSVEP based BCI, the subject is
not required to undergo brain training because the
subject does not have to concentrate on the
simulation of actions (motor imagery). During
experiment, the subject is required to focus on which
flickering light need to be focused on and the
prosthesis hand will move based on LED positions at
prosthesis hand. The signal data was collected from
four healthy subjects by using four sintered Ag/AgCl
electrode placed at 2.5cm anterior and posterior to
electrode positions at O1 and O2. Signal processing
was done by using Discrete Fourier Transform (DFT) and
online classification was achieved between 44% and
88% accuracies. Although they are successful to
control the prosthetic hand but the concept idea of
this paper is not practical to apply for the amputee.
Due the EEG signal recorded from visual areas of the
brain, the subject needs to focus which LED is
flickering.
Zhang and Wang presented the BCI by using EEG to
control a prosthesis hand with three degree of
freedom [4,5]. In this paper, they did not specify their
EEG device and electrode channels recorded but the
signal data was recorded during the hand movement
from one subject. The subject need to perform four
tasks (arm’s free state, arm movement, hand crawl,
hand open) and the prosthesis hand will move based
on subject task. Power Spectral Density (PSD) was used
as feature extraction method and tested with two
types of classification; Support Vector Machine (SVM)
and Back Propagation (BP) Neural Network. The results
showed that SVM classification had better recognition
rate and good classification ability compared to BP
Neural Network. This paper used real hand movement
signal data to control the prosthesis. Therefore, it is also
not practical for the amputee because of the EEG
recognition from hand action.
In 2013, a team researcher fom Egypt [6] presented
a Brain Machine Interface (BMI) system based on EEG
to control robotic arm with three movements
(close/open arm and close hand). During the
experiment, the signals data was recorded from one
healthy subject during the right hand movement. The
EEG device was used is Emotiv Epoc and channels
selected is AF3 F7, F3 and FC. It shows that AF3 position
at the prefrontal cortex and F7, F3 and FC at the
supplementary motor cortex of the brain. Data was
processed by using three different types of feature
extraction method; Wavelet Transform (WT), Fast
Fourier Transformation (FFT) and Principal Component
Analysis (PCA) to examine the classification accuracy

by using BP Neural Network. From the result, Wavelet
Transform (WT) has achieved 91.1% which highest than
Fast Fourier Transformation (FFT) and Principal
Component Analysis (PCA). However the researcher
only used data from real hand movements to control
the robotic arm. In this case, the upper limb amputee
will find difficulties to control the prosthesis due to the
different signal in EEG recognition [7].
Astaras et al. from Greece also presented their
project of BCI [8, 9] to control a robotic arm by using
exoskeletel position sensing harness with a dry EEG
electrode. 34 subjects was involved for the pilot study
which all subjects need to wear BMI harness and the
robotic arm was placed at front lower right area from
the subject. The purpose of this experimental setup is
for qualitative assesment of the BMI. This project is still
under development and the BCI headset was planned
to integrate into the MERCURY prototype system. The
researcher also planned to introduce feedback loop
for tactile sensing in future studies. However further
studies has not been reported since 2013.
Brain Computer Interface (BCI) is a field of research
that is developed to read and control the human
brain. This technology allows the disabled to move
devices without additional support tools. Paralysed
individuals with limited communication capacity can
use brainwaves BCI to move prosthetic devices.
Although this technology was known, but innovation is
still growing rapidly with the modern touch technology
as a tactile sensor, adaptive control, haptic which
enables the hand to mimic the natural movement.
However, until now the system used in the
demonstration is still not showing the actual
effectiveness and still in early stages. From the review
(Table 1), there is no complete study to develop a
prosthesis hand by using EEG device in motor imagery.
Historically, invasive methods have shown more
success in prosthetic control by motor imagery as
compared to non-invasive methods [10]. Moreover,
the device invented can only be used for specific
people, requires training, limited by the range of
function and devices [11].

3.0
CONCEPTUAL DESIGN OF A NEUROPROSTHETIC HAND
We are developing a new neuroprosthetic hand
compatible to use with EEG device by improving our
past robotic hand designs [12], [13]. The design of the
hand will be printed by a 3D printer. Neuroprosthetic
terminal device is completed with five fingers full with
seven degrees of freedom. It is individually driven by
an actuator motor mimicking the human hand
movements. This terminal device comes with tactile
sensors placed at the fingertip [14], [15]. Basic activities
as design requirements for the neuroprosthetic
terminal device include touch, grasp and release.
This project aims to develop a neuroprosthetic hand
with simple mechanism but effective to perform daily
activities for amputee. Figure 1 shows the main system
elements of a neuroprosthetic hand with an EEG

80

Khairunnisa Johar et al. / Jurnal Teknologi (Sciences & Engineering) 76:4 (2015) 77–82

based BCI. The development of the neuroprosthetic
hand focuses on three main criteria: non-invasive

technique, high portability and ease of use.

Figure 1 Block diagram of the processes of the system

The system functions by the acquisition of neural
signals form the amputee. The data will be processed
and stored. The subject will be selected based on the
healthy condition with no problems related to brain
with a different level of age. Each selected subject will
move his or her hands and the result data will be
recorded using the Emotiv Testbench Software. They
will be given consent of ethic before experiment
started. Experiment result will serve as signal sample
that will be studied and used for training the amputee
later. Subject will sit in front of the display screen in a
comfortable position, while monitored by supervisors to
help reduce any unnecessary movement, which can
interfere with the data collection. However for this
experiment, only channels that are related to motor
cortex which involves the movement of muscle will be
used. EEG Emotiv EPOC 14 Channel with two
reference channels used will send a signal to the
receiver signal via Bluetooth. Then, the receiver will
send a signal in the Workstation for processing the
data using a GUI.
The GUI is developed for data acquisition, signal
processing and training. If the pattern is detected
together with the recorded pattern, GUI system will
send a signal to act in EEGBox to move the actuators
in neuroprosthetic hand as required. The efficiency of
a neuroprosthetic hand system depends on the
software developed, hardware that acts as a real time
and the neuroprosthetic hand developed. The longer
signal recorded from user and many number channels
used can affect to the time required for processing the
data. Because of these problems, GUI developed must
be more stable and efficient for controlling the signal
obtained from the brain user.

Raw data obtained from data acquisition cannot be
used as a command because there are a lot of
artifact signal. Therefore, every signal data obtained
will go through a process to eliminate the noise. Before
processing the signal, the data must be clean without
any artifacts. Several disorders usually occur during
EEG recording such as Noise Environment and
Physiological Noise. Examples of Environmental Noise
as an AC power lines, lighting, wireless device, and a
large array of electronic equipment such as
computers and laptop displays. The physiological
noise can interfere with recording data like Muscle
movement (EMG), Cardiac Signal (ECG) and eye
blinks (ECOG). A few noises simply eliminated using
Automatic Artifact Removal (AAR) through EEGLab.
For the muscle movement can be reduced by
minimize the body movement of the subject. In
addition, special rooms are also required to facilitate
the EEG recording. It is also one of the methods to
control noise effectively during EEG recording [1].
Every precaution should be taken to reduce the
source of noise and easily to filter the noise.
The clean signal data will be converted into a matrix
form and saved as a pattern approval in EEGbox
database system. This EEGBox data controlled by using
the Graphical User Interface (GUI) generated from
Matlab Software. In the GUI interface EEGBox, have a
training data to be used by the amputee as a
supporting training before using the actual prosthetic
hand. EEGBox GUI acts as a decision maker to make
every movement neuroprosthetic hand depending on
the pattern that has been in the program approval
inside the database. EEGBox also acts as a real time
interface between the GUI software developed by the

81

Khairunnisa Johar et al. / Jurnal Teknologi (Sciences & Engineering) 76:4 (2015) 77–82

hardware output as the actuator motor and tactile
sensors are used.

4.0 EXPERIMENTAL SET-UP

Freedom. Individually driven by the actuator motor
makes more mimic the human hands movement.
Figure 2 shows an overview of this project consists of
workstation, DAC, EEG Epoc and prosthetic hands.

This project was started in early 2014. This hand is
completed with five fingers full with 7 Degree of

Workstation

Prosthetic Hand

DAC

EEG Emotiv
Epoc

Figure 2 UiTM Neuroprosthetic hand project

5.0 CONCLUSION
Research has shown the advantages of deploying
EEG technology to offer new solutions in prosthetic
devices. However, until today, EEG based prosthetic
devices cannot be found in the market. This shows
that this technology is still undergoing a maturing
process. In this work, the state-of-the-art is reviewed
and a conceptual design for a non-invasive
approach for controlling a neuroprosthesis hand
using an Emotiv EEG device integrated with a GUI is
presented.

[3]
[4]
[5]
[6]

[7]

Acknowledgement
The Research Team wishes to thank the Ministry of
Education
Malaysia
under
grant
number
(ERGS/1/2013/TK01/UITM/01/01) for funded on this
project.

[8]

[9]

References
[1]
[2]

Schwartz, A. B., Cui, X. T., Weber, D. J. and Moran D. W.
2006. Brain-Controlled Interfaces: Movement Restoration
with Neural Prosthetics. Neuron. 52: 205-220.
Guger, C., Harkam, W., Hertnaes, C., and Pfurtscheller, G.
1999. Prosthetic Control by an EEG-based Brain- Computer

[10]
[11]

Interface
(BCI).
European
Conference
for
the
Advancement of Assistive Technology. 1-6.
Müller-Putz, G. R. and Pfurtscheller, G. 2008. Control of an
Electrical Prosthesis with an SSVEP-based BCI. IEEE Trans.
Biomeical Engineering. 55(1): 361-364.
Dai, W. H. and Zhang, X. D. 2009. Design on the System of
Brain-Computer Interface Driving Neural Prosthesis Hand.
Key Engineering Materials. 392-394: 1012-1018.
Zhang, X., Wang, Y. and Li, Y. 2010. An Approach for
Pattern Recognition of EEG Applied in Prosthetic Hand
Drive. International Conference. 9: 51-57.
Shedeed, H. A., Issa, M. F. and El-Sayed, S. M. 2013. Brain
EEG Signal Processing for Controlling a Robotic Arm.
Proceedings 2013 8th International Conference on
Computer Engineering and Systems. 152-157.
Höller, Y., Bergmann, J., Kronbichler, M., Crone, J. S.,
Schmid, E. V., Thomschewski, A., Butz, K., Schütze, V.,
Höller, P. and Trinka, E. 2013. Real Movement vs. Motor
Imagery in Healthy Subjects. International Journal of
Psychophysiology. 87(1): 35-41.
Astaras, A., Moustakas, N., Athanasiou, A., and Gogoussis,
A. 2013. Towards Brain-Computer Interface Control of a 6Degree-of-Freedom Robotic Arm Using Dry EEG
Electrodes.
Moustakas, N., Athanasiou, A., Kartsidis, P., Bamidis, P. D.,
and Astaras, A. 2014. Development and User Assessment
of a Body-Machine Interface for a Hybrid-Controlled 6Degree of Freedom Robotic Arm (MERCURY). XIII
Mediterranean Conference on Medical and Biological
Engineering and Computing 2013 SE-16. 41: 65-68.
Arafat, I., 2013. Brain Computer Interface: Past, Present &
Future. 1-6
Schalk, G., McFarland, D. J., Hinterberger, T., Birbaumer,
N., and Wolpaw, J. R. BCI2000: A General-Purpose Brain-

82

[12]
[13]

[14]

Khairunnisa Johar et al. / Jurnal Teknologi (Sciences & Engineering) 76:4 (2015) 77–82
Computer Interface (BCI) System. 2004. IEEE Transactions
on Biomedical Engineering. 51(6): 1034-1043.
Kasim, A. M., Aqilah, A., Jaffar, A., Low, C. Y., Jaafar, R.,
and Bahari, M. S. 2013. Development of UiTM Robotic
Prosthetic Hand. 7(1): 1054-1059.
Jaffar, A., Bahari, M. S., Low, C. Y. and Jaafar, R. 2011.
Design and Control of a Multifingered Anthropomorphic
Robotic Hand. International Journal of Mechanical and
Mechatronics Engineering. 1(4): 26-33.
Low, C. Y. Kasim, M. A., Koch, T., Dumitrescu, R., Yussof, H.,
Jaafar, R., Jaffar, A., Aqilah, A. and Ng, K. M. 2013. Hybrid-

[15]

Actuated Finger Prosthesis With Tactile Sensing.
International Journal of Advanced Robotic Systems. 10: 110.
Aqilah, A., Jaffar, A., Bahari, S., Low, C. Y. and Koch, T.
2012. Resistivity Characteristics of Single Miniature Tactile
Sensing Element Based on Pressure Sensitive Conductive
Rubber Sheet. Signal Processing and its Applications
(CSPA), 2012 IEEE 8th International Colloquium. 223-227.

