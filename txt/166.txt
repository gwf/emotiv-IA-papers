VOG-ENHANCED ICA FOR SSVEP RESPONSE DETECTION FROM CONSUMER-GRADE
EEG
Mohammad Reza Haji Samadi, Neil Cooke
Interactive Systems Engineering Research Group, University of Birmingham, U.K.
ABSTRACT
The steady-state visual evoked potential (SSVEP) braincomputer interface (BCI) paradigm detects when users look
at flashing static and dynamic visual stimuli. Electroculogram
(EOG) artefacts in the electroencephalography (EEG) signal
limit the application for dynamic stimuli because they elicit
smooth pursuit eye movement. We propose ‘VOG-ICA’ - an
EOG artefact rejection technique based on Independent Component Analysis (ICA) that uses video-oculography (VOG)
information from an eye tracker. It demonstrates good performance compared to Plöchl when evaluated on matched
and EEG data collected with consumer grade eye tracking
and wireless cap EEG apparatus. SSVEP response detection
from frequential features extracted from ICA components
demonstrates higher SSVEP response detection accuracy and
lower between-person variation compared with extracted features from raw and post-ICA reconstructed ‘clean’ EEG. The
work highlights the requirement for robust EEG artefact and
SSVEP response detection techniques for consumer-grade
multimodal apparatus.
Index Terms— ICA, SSVEP, EEG, Artefact Rejection,
VOG
1. INTRODUCTION
Electroencephalography (EEG) measures the brain’s electrical activity from scalp-based electrodes [1]. The Steady-State
Visual Evoked Potential (SSVEP) is the brain’s electrical response to retinal stimulation by a flickering visual stimuli at
a frequency greater than 6Hz [2]. It is characterised by an
EEG signal oscillation at the same frequency. SSVEP is a
popular technique for Brain-Computer Interface (BCI) due to
the minimal between-person differences.
Non-biological (e.g. electrical mains) and biological artefacts (e.g. muscle movement) contaminate EEG signals, leading to lower BCI performance [3]. The prevalent biological
artefact is Electroculogram (EOG) - eye movements produced
by the corneo-retinal dipole, and eyelid movements such as
blinks. The Blind Source Separation technique Independent
Component Analysis (ICA) has been successfully applied on
EEG channel data to remove EOG sources [4] so that a ‘clean’

EEG signal can be reconstructed. However, ICA does not label sources automatically - a current research topic [5] [6].
In addition to EOG artefacts, SSVEP response detection
difficulty arises from people’s exposure to prolonged flashing
stimuli resulting in a gradual decrease in SSVEP response the habituation effect [7]. Use of static flashing visual stimuli
potentially reduces EOG artefacts because slow moving ‘pursuit’ eye movement is absent. This could improve SSVEP
response detection accuracy. However, the SSVEP response
is reduced by the habituation effect lowering SSVEP response
detection accuracy [8]. Contrastingly, dynamic flashing stimuli may reduce the habituation effect but introduce more EOG
artefacts. It is desirable therefore that SSVEP response detection methods should have consistence performance for static
and dynamic visual stimuli.
In this work we consider robust field BCI - consistent
SSVEP response detection to static and dynamic stimuli from
consumer grade, non-clinical wireless cap EEG apparatus and
VOG from a portable wearable eye tracker. The EEG device
(Emotiv EPOC) has fewer channels and lower sampling rates
than clinical versions. The eye tracker (Tobii Eye glasses) is
monocular and samples at a low rate compared to laboratory
counterparts.
In section 2 we review previous EOG artefact rejection
studies. Section 3 outlines our EOG artefact rejection VOGICA technique and SSVEP response detection. In section 4
we describe the evaluation method and a VOG/EEG dataset
captured. Experiment results are presented in section 5 followed with a discussion in section 6.

2. RELATED WORK
Several studies propose algorithms to identify artefactual
sources including EOG from EEG spatial and temporal features [9, 10]. Notably, ADJUST [5] automatically detects
different EOG types by considering temporal and spatial
features. Recently Plöchl et al. [6] used matched Videooculography (VOG) and EEG data to discard EOG artefacts
when saccades (rapid and large eye movement) occurred.

2.1. Novelty
In this work we use information from VOG to label ICA separated sources as eye movement artefacts arise from pursuit
eye movement as well as rapid and large eye movement. In
addition, previous studies in EEG for BCI chiefly apply ICA
exclusively for artefact rejection rather than feature extraction. We demonstrate that ICA components can be beneficial as features for SSVEP response detection. We evaluate
SSVEP response detection on a specifically designed smooth
pursuit eye movement VOG/EEG dataset. which itself reduces habituation - a key requirement for the real-world BCI
SSVEP paradigm use. We use consumer grade EEG equipment with lower spatial and temporal resolution compared to
clinical EEG to demonstrate field potential.
3. APPROACH
3.1. VOG-ICA EOG artefact labelling
To identify eye movement / EOG sources and reject them
from EEG, the Extended-Infomax [11] ICA algorithm is applied. A VOG signal is used as an extra information source
for artefact detection. It gives the time-variant signals x(t)
and y(t) representing the horizontal and vertical gaze coordinates at time t, respectively. The cross-correlation [12] of the
ith Independent Component (IC), Si , with x(t) and y(t), is
calculated. ICs are scored according to the maximum absolute cross-correlation values with x(t):
γx,i = max(|(Si ∗ x)(t)|)
t

(1)

where γx,i refers to the maximum absolute cross-correlation
values between the ith IC, Si (t), and signal x(t). The ICs
Z-Scores in γx,i is calculated;
Zγx,i =

γx,i − E[γx,i ]
σ(γx,i )

(2)

where E[...] and σ(...) refer to the expected value and standard deviation for γx,i , respectively. High scoring IC’s are
identified as eye movement artefacts.The threshold (Zγx,i or
Zγy,i = 2.0) for high score is determined empirically. The
same procedure is applied to obtain ICs which are correlated
with vertical eye movement sequence, y(t).
3.2. SSVEP response detection
To detect SSVEP, the EEG signal channels or ICA components are split into 2000ms windows with 80% overlaps. The
stimulation frequencies (7Hz, 10Hz and 12Hz) amplitude
and their second harmonics (i.e. 14Hz, 20Hz and 24Hz) features are extracted from the power spectral density (PSD) for
each window. The PSD is estimated by Welch’s method [13].
A k-Nearest Neighbour (kN N ) classifier with Euclidean distance metric is trained on a subset of data to distinguish different SSVEP frequencies. k’s value is set to 1 (i.e. 1-N N ).

Fig. 1. An illustration of the experimental paradigms: (a)
possible trajectories followed by stimuli. (b) Static SSVEP:
Flickering stimuli are fixed at the screen centre (c) Dynamic
SSVEP: Stimuli move from the display centre towards locations shown in (a). Subjects follow the stimuli.
4. EVALUATION
4.1. Method
Participants are instructed to perform the tasks illustrated in
the Fig. 1: The screen is a black square which is divided into
nine possible locations for stimulus presentation (Fig. 1.a).
The trials start when a white fixation cross appears in the
screen’s centre for 5 seconds. Next, a 10x10 checkerboard
(the stimulus) covers the fixation cross and flickers at three
frequencies (7Hz, 10Hz or 12Hz [14]) for 14 seconds. In
Static SSVEP the checkerboard is remains fixed in the screen’s
centre (Fig. 1.b); however, in Dynamic SSVEP the stimulus
moves from centre towards one remaining location on the
screen (Fig. 1.c). Each Static SSVEP run consists 8 trials for
every flickering frequency. There are also 8 trials for flickering stimulus, moving to different directions, in Dynamic
SSVEP.
4.2. Participants
Five healthy people participate. All have normal or correctedto-normal vision and informed consent is obtained. They are
positioned in a comfortable chair at approximately 100cm
distance from a 19 inch liquid crystal display (LCD) with
60Hz vertical refresh rate. All participants are instructed to
relax and remain as still as possible to avoid the EEG signal
contamination with muscle artefacts.
4.3. EEG and eye tracking apparatus
EEG and VOG are captured with two non-intrusive consumergrade recording apparatus designed for mobile situations. A
14 electrodes wireless EEG headset (Emotiv EPOC) is used

for EEG signal acquisition. There are also two reference electrodes located above the subjects’ ears. The EEG device has
a 128Hz sample rate. VOG is captured from a head-mounted
monocular eyetracker (Tobii Glasses) at 30Hz sample rate .
The eye tracker’s recording visual angle is 56◦ × 40◦ which
is sufficient to capture all movement in relation to the LCD.
EEG and VOG recordings are synchronised by timestamps
displayed on the LCD and captured by the eyetracker’s scene
camera.
4.4. EEG signal preprocessing and feature extraction
EEG signals are Band-pass filtered to remove the slow drifts
and high-frequency noises from the recorded data (1–40Hz).
To provide synchronization between VOG and EEG recorded
signals, the scene camera recordings are visually inspected to
label the stimulation start and end. The VOG is up-sampled
to match the EEG sample rate with linear interpolation.
Four feature sets are compared for SSVEP response detection: pre-ICA ‘raw’ EEG channel features (Orig); postICA ‘clean’ EEG channel features from EEG reconstructed
from non-EOG IC (ClnEEG); ICA components (ICs); nonEOG ICs identified with VOG-ICA (ClnICs). For each feature set, a 10-fold cross validation method is used to evaluate
the kN N SSVEP response detection classifier performance.

Fig. 2. shows the Z-Score distribution obtained by each single IC cross-correlated with x(t) and y(t). ICs belong to all
subjects in the Dynamic SSVEP. Z-Score value distribution
for each γx,i and γy,i sequences are superposed on the relative axis. Red lines indicate the selected threshold (Zγx,i or
Zγy,i = 2.0).

4.5. SSVEP response detection tests
To evaluate the VOG-ICA signal processing for EOG artefact
rejection, we compare the SSVEP response detection accuracy before and after applying ICA. Results are compared
with the state-of-art artefact rejection method proposed by
Plöchl et al [6].

5.2. SSVEP response detection from ICA components
SSVEP response detection for all subjects is significantly
higher when features are extracted from ICs rather than
EEG channels (Table 2 bold figures). This suggests that

5. RESULTS
5.1. VOG-ICA for EOG rejection
Figure 2 illustrates the ICs’ Z-Score distribution for all subjects in Dynamic SSVEP. The ICs with Z-Scores higher than
2.0 are highly correlated with VOG, contains eye movementrelated activities. Thus, ICs with Z-scores higher than 2.0 are
labelled as EOG artefacts.
There is a linear relation between the ICs’ Z-scores crosscorrelated with eye movement signals x(t) and y(t). The
outlying ICs exceed both thresholds, suggesting that the eyerelated potentials for vertical and horizontal eye movements
are separate ICs (figure 2).
If extracting features from VOG-ICA components for
SSVEP response detection, the averaged SSVEP classification accuracy increases by 4% in Static SSVEP, and by 3% in
Dynamic SSVEP (Table 1). All eye-related artefacts are detected.However, when Plöchl is applied, the averaged SSVEP
classification accuracy decreases by 6% in both experiments
and the EOG artefacts for some subjects are not detected.

Table 1. The percentage (%) SSVEP classification accuracy
for each subject in Static SSVEP and Dynamic SSVEP; when
there is no EOG artefact rejection (Orig) compared to when
Plöchl and VOG-ICA are applied for EOG artefact rejection.
The best obtained result is highlighted in bold.
Static SSVEP

Subj

Dynamic SSVEP

Orig Plöchl VOG-ICA

Orig Plöchl VOG-ICA

S01
S02
S03
S04
S05

82.98
88.99
80.38
85.27
81.76

68.36
89.24
76.10
72.99
—

81.60
94.02
90.65
82.00
90.55

89.14 —
88.65 64.55
89.80 83.79
83.85 83.29
81.54 —

93.47
91.24
85.86
95.01
80.12

Ave
std

83.88 77.69∗
3.37 8.08

87.76
5.62

86.60 80.46∗
3.68 9.33

89.14
6.11

∗

In the cases where there is no IC detected as artefact (“—”),
the original accuracy is considered in the averaged accuracy
calculation.

Table 2. SSVEP classification performance when SSVEP frequential features are extracted from: the original EEG data (Orig);
cleaned reconstructed EEG data (ClnEEG); all estimated ICs (ICs), and ICs detected as non-artefact (ClnICs).
Static SSVEP

Subjects

Dynamic SSVEP

Orig (%)

ClnEEG (%)

ICs (%)

ClnICs (%)

Orig (%)

ClnEEG (%)

ICs (%)

ClnICs (%)

S01
S02
S03
S04
S05

82.98
88.99
80.38
85.27
81.76

81.60
94.02
90.65
82.00
90.55

96.69
96.84
96.08
96.57
95.72

95.67
95.91
93.80
94.88
94.76

89.14
88.65
89.80
83.85
81.54

93.47
91.24
85.86
95.01
80.12

96.87
95.25
95.03
96.91
96.21

96.49
95.00
92.56
96.59
95.54

Ave
std

83.87
3.37

87.76
5.62

96.38
0.46

95.00
0.83

86.60
3.68

89.14
6.11

96.05
0.88

95.23
1.63

extracting features from ICs significantly reduces betweenperson variation (figure 3).

6. DISCUSSION
In this work we demonstrate that static and dynamic SSVEP
detection performance is significantly improved by extracting
frequential features from source components estimated from
ICA rather than EEG signal channels. VOG can assist in the
automatic labelling of EOG sources via cross correlation of
the eye tracker signal with the independent components.

Fig. 3. SSVEP classification performance for Static SSVEP
and Dynamic SSVEP, averaged over 5 subjects. The error
bars represent standard errors.

Five people participated in the evaluation. While this is a
small sample set, it is justified because the SSVEP response
detection performance from frequential components demonstrates minor between person variation; the reason why the
SSVEP BCI paradigm is popular. The good performance
of the kNN classifier also suggests a sufficient training data
quantity. However, whether or not retaining EOG labelled
components for SSVEP response detection is worthwhile
given the insignificant performance difference requires further study with more people.

ICA performs well in source separation. Comparing ICs
and ClnICs shows detection performance insignificantly decreases 1% in both scenarios, suggesting that EOG ICs may
have some SSVEP information due to imperfect source separation. When features are extracted from the original EEG
data (Orig), the SSVEP response detection accuracy for Dynamic SSVEP is 3% higher than for Static SSVEP. This
suggests that a gradual decrement in static SSVEP amplitude
responses due to the habituation effect which is reduced with
the dynamic SSVEP. SSVEP response detection performance
improves slightly for reconstructed ‘clean’ EEG over original
‘raw’ EEG. In addition to improving detection performance,

Compared to other techniques, VOG-ICA outperforms
Plöchl et al. [6]. The ADJUST [5] method does not detect
any EOG artefacts in our data and is omitted. Thus, we cannot
claim that VOG-ICA is superior to other methods due to the
different dataset characteristics; e.g. non corneo-retinal EOG
artefacts such as blinks are accounted for by bandpass prefiltering in this study rather than explicitly by the algorithm.
This highlights that current approaches to artefact rejection
and SSVEP response detection evaluated on data captured by
clinical grade EEG may under-perform on data captured with
consumer grade wireless cap EEG apparatus, which has more
utility in field BCI. Future studies considering spatial resolution and temporal precision effects on algorithm performance
may therefore be valuable.

7. REFERENCES
[1] Saeid Sanei and Jonathon A Chambers, EEG signal processing, Wiley. com, 2008.
[2] Matthew Middendorf, Grant McMillan, Gloria Calhoun,
and Keith S Jones, “Brain-computer interfaces based on
the steady-state visual-evoked response,” Rehabilitation
Engineering, IEEE Transactions on, vol. 8, no. 2, pp.
211–214, 2000.
[3] John N Demos, Getting started with neurofeedback,
WW Norton & Company, 2005.
[4] Ricardo Nuno Vigário, “Extraction of ocular artefacts
from eeg using independent component analysis,” Electroencephalography and clinical neurophysiology, vol.
103, no. 3, pp. 395–404, 1997.
[5] Andrea Mognon, Jorge Jovicich, Lorenzo Bruzzone,
and Marco Buiatti, “Adjust: An automatic eeg artifact
detector based on the joint use of spatial and temporal
features,” Psychophysiology, vol. 48, no. 2, pp. 229–
240, 2011.
[6] Michael Plöchl, José P Ossandón, and Peter König,
“Combining eeg and eye tracking: identification, characterization, and correction of eye movement artifacts in
electroencephalographic data,” Frontiers in human neuroscience, vol. 6, 2012.
[7] Seth Sharpless and Herbert Jasper, “Habituation of the
arousal reaction,” Brain, vol. 79, no. 4, pp. 655–680,
1956.
[8] Heng-Yuan Kuo, George C Chiu, John K Zao, Kuan-Lin
Lai, Allen Gruber, Yu-Yi Chien, Ching-Chi Chou, ChihKai Lu, Wen-Hao Liu, Yu-Shan Huang, et al., “Habituation of steady-state visual evoked potentials in response
to high-frequency polychromatic foveal visual stimulation,” in Engineering in Medicine and Biology Society
(EMBC), 2013 35th Annual International Conference of
the IEEE. IEEE, 2013, pp. 803–806.
[9] Julie Onton, Marissa Westerfield, Jeanne Townsend, and
Scott Makeig, “Imaging human eeg dynamics using independent component analysis,” Neuroscience & Biobehavioral Reviews, vol. 30, no. 6, pp. 808–822, 2006.
[10] Yuan Zou, John Hart, and Roozbeh Jafari, “Automatic eeg artifact removal based on ica and hierarchical
clustering,” in Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on.
IEEE, 2012, pp. 649–652.
[11] Anthony J Bell and Terrence J Sejnowski,
“An
information-maximization approach to blind separation
and blind deconvolution,” Neural computation, vol. 7,
no. 6, pp. 1129–1159, 1995.

[12] Sophocles J Orfanidis, “Optimum signal processing: an
introduction,” 1985.
[13] Peter Welch, “The use of fast fourier transform for the
estimation of power spectra: a method based on time averaging over short, modified periodograms,” Audio and
Electroacoustics, IEEE Transactions on, vol. 15, no. 2,
pp. 70–73, 1967.
[14] Danhua Zhu, Jordi Bieger, Gary Garcia Molina, and
Ronald M Aarts, “A survey of stimulation methods used
in ssvep-based bcis,” Computational intelligence and
neuroscience, vol. 2010, pp. 1, 2010.

