sensors
Letter

EEG Fingerprints under Naturalistic Viewing Using a
Portable Device
Matteo Fraschini 1, * , Miro Meli 1 , Matteo Demuru 2 , Luca Didaci 1 and Luigi Barberini 3
1
2
3

*

Department of Electrical and Electronic Engineering, University of Cagliari, 09123 Cagliari, Italy;
m.meli4@studenti.unica.it (M.M.); ldidaci@unica.it (L.D.)
Stichting Epilepsie Instellingen Nederland (SEIN), 2103SW Heemstede, The Netherlands;
matteo.demuru@univ-amu.fr
Department of Medical Sciences and Public Health, University of Cagliari, 09123 Cagliari, Italy;
barberini@unica.it
Correspondence: fraschin@unica.it; Tel.: +39-070-675-5894

Received: 3 November 2020; Accepted: 16 November 2020; Published: 17 November 2020




Abstract: The electroencephalogram (EEG) has been proven to be a promising technique for personal
identification and verification. Recently, the aperiodic component of the power spectrum was shown
to outperform other commonly used EEG features. Beyond that, EEG characteristics may capture
relevant features related to emotional states. In this work, we aim to understand if the aperiodic
component of the power spectrum, as shown for resting-state experimental paradigms, is able to
capture EEG-based subject-specific features in a naturalistic stimuli scenario. In order to answer this
question, we performed an analysis using two freely available datasets containing EEG recordings
from participants during viewing of film clips that aim to trigger different emotional states. Our study
confirms that the aperiodic components of the power spectrum, as evaluated in terms of offset
and exponent parameters, are able to detect subject-specific features extracted from the scalp EEG.
In particular, our results show that the performance of the system was significantly higher for the
film clip scenario if compared with resting-state, thus suggesting that under naturalistic stimuli it is
even easier to identify a subject. As a consequence, we suggest a paradigm shift, from task-based or
resting-state to naturalistic stimuli, when assessing the performance of EEG-based biometric systems.
Keywords: EEG; fingerprints; emotion; spectral analysis; naturalistic stimuli

1. Introduction
During the last several years, the electroencephalogram (EEG) has been proven to be a
promising technique for personal identification and/or verification [1]. Despite its noisy characteristics,
several scalp EEG features still contain relevant subject-specific traits that have been tested under any
conceivable scenario. In particular, EEG fingerprints have been successfully observed and reported in
resting-state [2–4], motor, visual, auditory, imagined speech or even multi-functional systems [5–7].
More recently, the aperiodic component of the power spectrum [8], as defined by the offset and the
exponent, which reflect its 1/f-like characteristic, was shown to outperform other commonly used EEG
features [9].
Beyond that, EEG characteristics may be sensitive to or may capture relevant features related
to emotional states [10–13], which may also play an important role in the development of the
brain-computer interfaces (BCI) [14]. Although there is ample literature about this last topic, the possible
effects of emotional states in EEG-based identification systems have not been widely investigated.
Nevertheless, some recent findings suggest that the influence of emotional states on EEG biometric
systems should be properly taken into account [15,16].
Sensors 2020, 20, 6565; doi:10.3390/s20226565

www.mdpi.com/journal/sensors

Sensors 2020, 20, 6565

2 of 9

In this work, we aim to understand if the aperiodic component of the power spectrum, used in
the resting-state experimental paradigm [9], is able to capture EEG-based subject-specific features in
naturalistic stimuli scenarios. In order to answer this question, we performed an analysis using a
freely available EEG dataset [17] containing EEG recordings from 23 participants during the viewing
of film clips that aim to trigger different emotional states. Moreover, we have replicated our results
using another EEG dataset from 32 participants also recorded during naturalistic viewing (i.e., movie
watching) [18]. Such naturalistic paradigms, which represent a better approximation of real-life
scenarios, using stimuli such as films, spoken narratives, or music emerged in response to the common
concerns about the use of simple tasks or no-tasks resting-state paradigms [19]. The analysis was
performed using the FOOOF tool [8] that works on the frequency representations (power spectra),
fits the model, shows original power spectrum with the associated model fit, and provides the
parameters of the model fit, namely the aperiodic components (offset and exponent). Moreover,
the study was also replicated using the classical analysis performed in terms of the more common
periodic components, namely theta (4–8 Hz), alpha (8–13 Hz), beta (13–30 Hz), and gamma (30–45 Hz)
frequency bands. For both approaches, the performance evaluation procedure was performed using a
standard approach to evaluate biometric systems [20].
We would like to highlight that the aim of this study is twofold. It represents a verification
of the stability and robustness of the aperiodic component of the power spectrum in picking up
relevant subject-specific features over several and different naturalistic stimuli, which, to the best of
our knowledge, was never evaluated before and, moreover, we argue that this is also important to
realize how individual variability may be relevant when automated emotion recognition represents
the ultimate goal.
2. Materials and Methods
2.1. Datasets
In this work, we used DREAMER [17], a freely available dataset for emotion recognition from
wireless low-cost devices, which includes EEG signals from 23 participants recorded during affect
elicitation by means of audio-visual stimuli. The EEG signals were recorded using a sampling rate
of 128 Hz with an Emotiv EPOC fourteen-channel system. Emotions were elicited by using 18 film
clips that have been shown to evoke a wide range of emotions such as amusement, excitement,
happiness, calmness, anger, disgust, fear, sadness, and surprise. Together with the EEG signals,
the participants’ self-assessment of their affective state after each stimulus (in terms of valence, arousal,
and dominance) was also acquired. Our analysis was performed on two different segments, each one
lasting 1 min. The first segment (video_start) includes the first 60 s of the stimulus and the second
segment (video_end), which represents a replication of the study, includes the last 60 s of the same
stimulus. The reason for reproducing the analysis using two different segments was to understand
how the film clip length may play a significant role in defining the final results [19]. Moreover, as for
the video stimuli, the analysis was further replicated using a baseline condition, which represents a
60 s eyes-open resting-state condition, where a neutral clip was shown in order to help the subject
return to a neutral emotional state. The whole analysis was later replicated using another EEG dataset,
the DEAP dataset, a dataset for emotion analysis using EEG, physiological, and video signals [18],
where the EEG and peripheral physiological signals of 32 participants were recorded as each watched 40
one-minute-long music videos. The data also contain, for each single participant, a baseline recording
(eyes-open resting-state) that we used to compare the differences between the two conditions (i.e.,
resting-state and naturalistic viewing). For both analyses, each segment was successively organized
into non-overlapping epochs of 15 s [21].

Sensors 2020, 20, 6565

3 of 9

2.2. Features Extraction
For each subject, film clip, segment, and epoch, we computed the aperiodic components of the
power spectrum, reflecting 1/f-like characteristics, namely the offset and the exponent, using the
FOOOF tool [8]. In particular, the FOOOF algorithm works on frequency representations (power
spectra in linear space), fits the model, shows the original power spectrum with the associated model
fit, and provides the parameters of the model fit, the aperiodic components (offset and exponent).
The FOOOF tool is freely available both for MATLAB and Python [8]. Before computing the aperiodic
components, the raw EEG signals were filtered using a band-pass filter between 1 and 50 Hz using the
‘eegfilt’ function in EEGLAB [22] and subsequently the power spectral density was estimated using the
‘pwelch’ method in MATLAB (The MathWorks, Inc., Natick, MA, USA, version 9.8.0.1323502, R2020a).
Finally, for each film clip and each subject, we obtained a feature vector, consisting of fourteen values
(one value for each EEG channel), separately for the two aperiodic components. The relevance of these
parameters in the context of this study and the implementation of the aperiodic components as EEG
fingerprints in a different experimental scenario (resting-state paradigm) were previously investigated
and reported in [9]. Finally, we compared our results with the classical analysis performed using the
common periodic components, namely theta (4–8 Hz), alpha (8–13 Hz), beta (13–30 Hz) and gamma
(30–45 Hz) frequency bands.
2.3. Performance Evaluation and Statistical Analysis
The performance of the two aperiodic components was obtained using a standard approach used
to evaluate biometric systems [20]. The approach requires the definition of genuine and impostor
scores (equal to 1/(1 + d), where d is the Euclidean distance), computed between pairs of feature
vectors. In more detail, for each feature vector, consisting of fourteen values (one value for each
EEG channel), we computed the similarity score against every other feature vector, thus obtaining
the genuine scores (within-subject) and impostor score (between-subjects) distributions. The overall
performance was successively evaluated from the false acceptance rate (FAR, the error occurring
when an impostor is accepted) and the false rejection rate (FRR, the error occurring when a genuine
is rejected) using different thresholds. The equal error rate (EER), the point where FAR equals
FRR, was reported to outline the final results, so that low EER values represent high performance.
The Wilcoxon rank test was used in order to test possible statistical differences among the different
experimental scenarios. The statistical results are reported in terms of p-value, confidence interval,
and effect size. All the analysis was performed using MATLAB (The MathWorks, Inc., Natick, MA,
USA, version 9.8.0.1323502, R2020a) and all the figures were realized using Jamovi (version 1.0.8.0)
available from https://www.jamovi.org. All the scripts used to perform the analysis are freely available
at the following link: https://github.com/matteogithub/EEG-fingerprints-for-Sensors.
3. Results
3.1. 1/f Offset Parameter
A visual representation of the extracted feature vectors for a single video-clip are represented in
Figure 1. The best absolute performance, in terms of EER, was observed during naturalistic stimuli as
shown in Figure 2. In particular, for the video_start condition, we obtained an EER equal to 0.08 for an
excitement target video, which represents overall the best performance found during this analysis.
The results from corresponding statistical analysis, including p-values, confidence intervals, and effect
sizes, performed using a Wilcoxon rank test, are summarized in Table 1. As reported, we observed
significant differences between baseline and task conditions, irrespective of the time window (first or
last part of the experiment) used for the analysis.

Sensors 2020,
2020, 20,
20, 6565
x FOR PEER REVIEW
Sensors
Sensors 2020, 20, x FOR PEER REVIEW

of 99
44 of
4 of 9

Figure 1. Features vector for offset (upper panel) and exponent (lower panel) computed for a single
Figure 1. Features vector for offset (upper panel) and exponent (lower panel) computed for a single
Figureclip
1. Features
vector
(upper dataset.
panel) and
exponent
(lower
panel)and
computed
a single
video
extracted
fromfor
theoffset
DREAMER
Rows
represent
subjects
columnsfor
represent
video
clip extracted
from
the
DREAMER
dataset. Rows
represent
subjects
and columns
represent
video
clip
extracted
from
the
DREAMER
dataset.
Rows
represent
subjects
and
columns
represent
electroencephalogram (EEG)
(EEG) channels.
channels.
electroencephalogram
electroencephalogram (EEG) channels.

Figure 2. Scatter-plots represent the equal error rates (EERs) for each experimental condition for the
Figure 2. Scatter-plots represent the equal error rates (EERs) for each experimental condition for the
offset parameter.
Figureparameter.
2. Scatter-plots represent the equal error rates (EERs) for each experimental condition for the
offset
offset parameter.
Table 1. Statistical analysis for the 1/f offset parameter.
Table 1. Statistical analysis for the 1/f offset parameter.
1/fStatistical
Offset Parameter—Wilcoxon
Rank Test
Table 1.
analysis for the 1/f offset
parameter.
1/f Offset Parameter—Wilcoxon Rank
Test
95% Confidence Interval
1/f Offset Parameter—Wilcoxon Rank
Test
95%
Confidence Interval
Statistic
p
Lower
Upper
Cohen’s d
95%
ConfidenceUpper
Interval Cohen’s d
Statistic
Lower
p
Baseline
Videos_start
Wilcoxon
W W 171
0.0345
0.05941
2.022
Statistic
Lower
Upper
Cohen’s
p
Baseline
Videos_start
Wilcoxon
171 <0.00001
<0.00001
0.0345
0.05941
2.022 d
Baseline
Videos_end Wilcoxon W
165
0.00011
0.0267
0.06013
1.349
Videos_start
171
<0.00001
0.0345
0.05941
2.022
Baseline
Videos_end Wilcoxon W
165
0.00011
0.0267
0.06013
1.349
Videos_start Videos_end Wilcoxon W
76
0.70188
−0.0222
0.00955
−0.192
Baseline
165
0.00011
0.0267
0.06013
1.349
Videos_start
Videos_end Wilcoxon W
76
0.70188
−0.0222
0.00955
−0.192
Videos_start Videos_end Wilcoxon W
76
0.70188
−0.0222
0.00955
−0.192

3.2.
1/f Exponent
3.2. 1/f
Exponent Parameter
Parameter
3.2. 1/f
Exponent
Parameter performance, in terms of EER, was observed during naturalistic stimuli
Again,
Again, the
the best
best absolute
absolute performance, in terms of EER, was observed during naturalistic stimuli
as
shown
in
Figure
3.
As
the
the
video_start
we
an
Again,
the
best
absolute
in terms offor
EER,
was
observedcondition,
during naturalistic
stimuli
as shown in Figure 3.
As for
for performance,
the 1/f
1/f offset
offset parameter,
parameter,
for
the
video_start
condition,
we obtained
obtained
an
EER
equal
to
0.12
for
an
amusement
target
video,
which,
however,
represents
a
lower
performance
if
as shown
Asamusement
for the 1/f offset
for the
video_start
condition,
weperformance
obtained an
EER
equalin
toFigure
0.12 for3.an
targetparameter,
video, which,
however,
represents
a lower
EER
equal to with
0.12 for
amusement
target video,
represents a statistical
lower performance
if
compared
thean1/f
offset parameter.
The which,
results however,
from corresponding
analyses,
if compared with the 1/f offset parameter. The results from corresponding statistical analyses,

Sensors 2020, 20, 6565
Sensors 2020, 20, x FOR PEER REVIEW

5 of 9
5 of 9

including p-values,
confidence
intervals,The
and
effectfrom
sizes,corresponding
performed using
a Wilcoxon
rank
test, are
compared
with the 1/f
offset parameter.
results
statistical
analyses,
including
summarized
in Tableintervals,
2. As reported,
wesizes,
observed
significant
and task
p-values,
confidence
and effect
performed
usingdifferences
a Wilcoxonbetween
rank test,baseline
are summarized
conditions,
irrespective
theobserved
time window
(first or
last part ofbetween
the experiment)
for the
analysis.
in
Table 2. As
reported,ofwe
significant
differences
baseline used
and task
conditions,
Furthermore,
significant
difference
was
between the
first
the last
part of the
irrespective
of athe
time window
(first or
lastalso
partobserved
of the experiment)
used
forpart
the and
analysis.
Furthermore,
abaseline.
significant difference was also observed between the first part and the last part of the baseline.

Figure 3. Scatter-plots represent the EERs for each experimental condition for the exponent parameter.
Figure 3. Scatter-plots represent the EERs for each experimental condition for the exponent
parameter.
Table 2. Statistical analysis for the 1/f exponent parameter.
Exponentanalysis
Parameter—Wilcoxon
Rank Test
Table 2.1/fStatistical
for the 1/f exponent
parameter.
95% Confidence Interval

1/f Exponent Parameter—Wilcoxon Rank Test
Statistic
p
Lower
Upper
Cohen’s d
95% Confidence Interval
Baseline
Videos_start Wilcoxon W
171
0.0375
0.0636
2.174 d
Statistic<0.00001
Lower
Upper
Cohen’s
p
Videos_end Wilcoxon W
166
0.00008
0.027
0.0602
1.371
Baseline
Baseline
Videos_start Wilcoxon W
171
<0.00001
0.0375
0.0636
2.174
Videos_start Videos_end Wilcoxon W
70
0.51354
−0.0240
0.0101
−0.250
Baseline
Videos_end Wilcoxon W
166
0.00008
0.027
0.0602
1.371
Videos_start Videos_end Wilcoxon W
70
0.51354
−0.0240
0.0101
−0.250

3.3. Correlation with Participants’ Self-Assessment

3.3. Correlation
Self-Assessment
Finally, wewith
alsoParticipants’
observed moderate
correlations between the dominance (computed as the mean
over Finally,
all the subjects)
and the EER
for thecorrelations
offset parameter,
both
the first (rho
= −0.477,
= 0.045)
we also observed
moderate
between
thefor
dominance
(computed
as pthe
mean
and
(rho =and
0.412,
block,
using
the parameter,
non-parametric
overthe
all second
the subjects)
thens)
EER
for the
offset
both Spearman
for the firstmethod.
(rho = −0.477, p = 0.045)

and the second (rho = 0.412, ns) block, using the non-parametric Spearman method.
3.4. Periodic Components
3.4. Periodic
Components
As for the
periodic components, we observed the following performance in terms of EER for the
first 60
of film
clip viewing:
0.24 ± 0.03
the thetathe
band,
0.24 ± 0.04
for the alpha
band, of
0.15
± 0.02
for
Ass for
the periodic
components,
wefor
observed
following
performance
in terms
EER
for the
the
beta
band,
and
0.19
±
0.03
for
the
gamma
band.
Moreover,
we
observed
the
following
performance
first 60 s of film clip viewing: 0.24 ± 0.03 for the theta band, 0.24 ± 0.04 for the alpha band, 0.15 ± 0.02
in
of EER
for the
60 ±s of
filmfor
clip
viewing:
± 0.04
for the theta
band, 0.23the
± 0.04
for the
forterms
the beta
band,
andlast
0.19
0.03
the
gamma0.25
band.
Moreover,
we observed
following
alpha
band,
0.14
±
0.03
for
the
beta
band,
and
0.17
±
0.03
for
the
gamma
band.
Finally,
we
observed
performance in terms of EER for the last 60 s of film clip viewing: 0.25 ± 0.04 for the theta band, 0.23
the
following
performance
in terms
EER
theband,
baseline
± 0.02
for the
theta
band,
± 0.04
for the alpha
band, 0.14
± 0.03of
for
thefor
beta
and condition:
0.17 ± 0.03 0.28
for the
gamma
band.
Finally,
0.28
± 0.02 for
the
alpha band,
0.20 ± 0.03
for the
0.24 ±
0.03 for the
band.
we observed
the
following
performance
in terms
ofbeta
EER band,
for theand
baseline
condition:
0.28gamma
± 0.02 for
the
The
differences
among
the
three
conditions,
namely
baseline,
video_start
and
video_end,
for
the
beta
theta band, 0.28 ± 0.02 for the alpha band, 0.20 ± 0.03 for the beta band, and 0.24 ± 0.03 for the gamma
band,
was the periodic
component
with the higher
are represented
in Figurefor
4.
band. which
The differences
among the
three conditions,
namelyperformance,
baseline, video_start
and video_end,
The
corresponding
statistics
areperiodic
reported
in Table 3. with the higher performance, are represented in
the beta
band, which
was the
component

Figure 4. The corresponding statistics are reported in Table 3.

Sensors 2020, 20, 6565
Sensors 2020, 20, x FOR PEER REVIEW

6 of 9
6 of 9

Figure 4. Scatter-plots represent the EERs for each experimental condition for the beta frequency band.
Figure 4. Scatter-plots represent the EERs for each experimental condition for the beta frequency
band.
Table 3. Statistical analysis for the beta band.
Beta
Band—Wilcoxon
Rank
Table 3.
Statistical
analysis for
theTest
beta band.
95% Confidence Interval

Beta Band—Wilcoxon Rank Test
Statistic
p
Lower
95%
ConfidenceUpper
Interval
Baseline
Video_start Wilcoxon W
168
0.03658
0.0617
Statistic 0.00004
Lower
Upper
p
Baseline
W W 169168
0.00002
0.04634
0.0839
Baseline Video_end
Video_startWilcoxon
Wilcoxon
0.00004
0.03658
0.0617
Video_start Video_end Wilcoxon W
129
0.05994
−0.00142
0.0357
Baseline
Video_end Wilcoxon W
169
0.00002
0.04634
0.0839
Video_start Video_end Wilcoxon W
129
0.05994
−0.00142
0.0357

Cohen’s d
1.73 d
Cohen’s
1.85
1.73
0.479
1.85
0.479

3.5. Replication on the DEAP Dataset
3.5. Replication
on the DEAP
In the replication
part ofDataset
the study, we observed the best absolute performance, in terms of EER,
during
stimuli
offset
with
a minimum
EER value equal
to 0.099
and
In naturalistic
the replication
partusing
of thethe
study,
weparameter,
observed the
best
absolute performance,
in terms
of EER,
aduring
mean naturalistic
of 0.166 ± 0.031.
exponent
parameter
performed
worse, with
a minimum
value
stimuliThe
using
the offset
parameter,
with a minimum
EER value
equal toEER
0.099
and
equal
toof
0.201
and
a mean
ofexponent
0.285 ± 0.030.
Therefore,
as for the
original
the use
of value
videoequal
clips
a mean
0.166
± 0.031.
The
parameter
performed
worse,
withresults,
a minimum
EER
outperformed
use of resting-state
paradigms,
latter approach
theuse
EERofwas
equal
to
to 0.201 and athe
mean
0.285 ± 0.030.
Therefore,where,
as forfor
thethis
original
results, the
video
clips
0.350
for
the
offset
and
equal
to
0.362
for
the
exponent.
It
is
important
to
highlight
that,
for
this
second
outperformed the use of resting-state paradigms, where, for this latter approach the EER was equal
dataset
only and
one resting-state
recording
for each subject
since that,
thesefor
traces
to 0.350we
forhave
the offset
equal to 0.362(i.e.,
for baseline)
the exponent.
It is important
to highlight
this
were
recorded
theonly
video
clips
were presented.
As for the
periodic
of since
the power
second
datasetbefore
we have
one
resting-state
(i.e., baseline)
recording
forcomponent
each subject
these
spectra,
again,
the naturalistic
stimuli
outperform
thepresented.
baseline condition
forperiodic
3 out of 4component
frequency bands,
traces were
recorded
before the
video
clips were
As for the
of the
namely
theta (minimum
EER
value equal
to 0.147
and a mean
0.184 ± condition
0.026 for the
power spectra,
again, the
naturalistic
stimuli
outperform
the ofbaseline
for naturalistic
3 out of 4
stimuli
andbands,
EER value
equal
to 0.194
for theEER
baseline),
EER
valueof
equal
frequency
namely
theta
(minimum
value alpha
equal (minimum
to 0.147 and
a mean
0.184to±0.159
0.026and
for
athe
mean
of 0.204stimuli
± 0.023and
for EER
the naturalistic
and
value equal
to 0.233
for theEER
baseline),
naturalistic
value equalstimuli
to 0.194
forEER
the baseline),
alpha
(minimum
value
and
beta
(minimum
EER value
equal
to 0.146
andnaturalistic
a mean of 0.194
± and
0.029EER
for value
the naturalistic
stimuli
equal
to 0.159
and a mean
of 0.204
± 0.023
for the
stimuli
equal to 0.233
for
and
EER
value
equal
to
0.147
for
the
baseline),
where
the
opposite
was
observed
for
the
gamma
band
the baseline), and beta (minimum EER value equal to 0.146 and a mean of 0.194 ± 0.029 for the
(minimum
value
equal
0.249equal
and atomean
± 0.022 forwhere
the naturalistic
stimuli
and EER
naturalisticEER
stimuli
and
EERto
value
0.147of
for0.285
the baseline),
the opposite
was observed
value
equal
to 0.173
for(minimum
the baseline).
for the
gamma
band
EER value equal to 0.249 and a mean of 0.285 ± 0.022 for the
naturalistic stimuli and EER value equal to 0.173 for the baseline).
4. Discussion

4. Discussion
In summary, this study confirms that the aperiodic components of the power spectrum [8,9],
as evaluated
in terms
offset
and exponent
are able to detect
subject-specific
In summary,
this of
study
confirms
that theparameters,
aperiodic components
of the power
spectrumfeatures
[8,9], as
extracted
from
the
scalp
EEG.
evaluated in terms of offset and exponent parameters, are able to detect subject-specific features
In particular,
results
extracted
from theour
scalp
EEG.show that the performance of the system was significantly higher (lower
EER value)
for
the
film
clip
scenario,
thusthe
suggesting
that under
naturalistic
stimulus it ishigher
even
In particular, our results
show that
performance
of the asystem
was significantly
easier
identify
subject.
This
is of
specialthus
relevance
since that
naturalistic
represent
a better
(lowertoEER
value)a for
the film
clip
scenario,
suggesting
under astimuli
naturalistic
stimulus
it is
even easier to identify a subject. This is of special relevance since naturalistic stimuli represent a better
approximation of real-life scenarios [19] if compared with the more classical approaches based on

Sensors 2020, 20, 6565

7 of 9

approximation of real-life scenarios [19] if compared with the more classical approaches based on
arbitrary tasks or resting-state paradigms. Furthermore, our results also show a moderate correlation
between the system performance and the participants’ self-assessment, especially for the dominance
scale where the magnitude of the association was particularly high and significant, at least for the
offset parameter.
Moreover, we reproduced the study using the more common approach based on the classical
decomposition of the EEG signals in frequency contents, namely theta, alpha, beta, and gamma bands.
In this case, it is of relevance to highlight that, as expected [3,9], the high frequency contents, beta and
gamma bands, represent the periodic components that gave the best performance, in all the investigated
scenarios. Furthermore, we argue that this approach represents an important replication of the results
obtained using the aperiodic components, since, even in this case, we successfully demonstrated that
the naturalistic stimuli, as provided using film clips, outperform the use of no-task conditions. Finally,
it is also interesting to note that, as previously shown [9], the aperiodic component of the power
spectrum outperforms the use of the more classical approach based on periodic components (frequency
bands decomposition).
In order to understand to what extent the reported results are dependent on the specific set of data
used in this study, we decided to replicate the whole analysis using another fresh dataset. Specifically,
we used the DEAP dataset [18], a dataset for emotion analysis using EEG, physiological, and video
signals, which have several similarities with the original one. Interestingly, we may conclude that we
successfully replicated the original findings and thus we are more confident that the reported results
can be considered robust, and at least in part generalizable.
We also want to emphasize that a recent work [23], even though performed using the functional
magnetic resonance technique, shows that compared to the resting-state, naturalistic viewing allows
a more accurate prediction of trait-like phenotypes in both cognitive and emotional domains,
also suggesting that naturalistic stimuli amplify individual differences. In line with this result,
our study, even using a different recording technique and a different set of features, confirms that
naturalistic viewing allows the increase of the performance in a subject identification scenario such as
the one explored in this work. In this context, our study suggests that even with a much lower spatial
resolution, as represented by the use of low-density scalp-EEG, the naturalistic stimuli, as observed in
functional magnetic resonance, amplify individual differences.
Nevertheless, we recognize two important limitations of the present study. The first limitation
concerns the number of subjects involved in the study since we used a freely available dataset, which on
the other hand represents a strong point in terms of reproducibility, and it is not straightforward to
collect such complex data; this limitation is not easy to overcome. However, we think that future
studies should aim to replicate these results on a bigger dataset in order to generalize these findings.
The second limitation concerns the use of scalp EEG recordings, moreover from a low-cost device,
which is very well known to be affected by diverse sources of noise. We argue that, even if not relevant
for biometric systems, it would be important to investigate whether these findings still hold when
using source-reconstructed analysis with high-density EEG, since individual variability still represents
a very important issue or limit when comparing groups or conditions [24].
The stronger point, which to the best of our knowledge was never discussed before, is that the
use of naturalistic stimuli, representing experiences from everyday life and recently proposed as
potential alternative to resting-state [19], outperforms the same EEG features when used in a baseline
(no-stimulus) condition. We think that this result may represent valuable information for the EEG
community working on individual variability and that in the near future it may drive a paradigm shift
to test the performance of EEG-based biometric systems.
5. Conclusions
In conclusion, our study confirms, performing two completely separate analyses, that the aperiodic
components of the power spectrum are able to grab subject-specific features extracted from the scalp

Sensors 2020, 20, 6565

8 of 9

EEG and that the performance of this approach based on naturalistic stimuli outperforms the same
EEG features when used in a baseline (no-stimulus) condition. As a consequence, our results suggest
focusing on naturalistic stimuli when assessing the performance of EEG-based biometric systems
as this approach seems more prone to unveiling subject-specific features compared to task-based or
resting-state paradigms.
Author Contributions: Conceptualization, M.F., M.D., L.D., and L.B.; formal analysis, M.M.; methodology, M.F.
and M.D.; software, M.M.; supervision, M.F., L.D., and L.B.; writing—original draft, M.F., M.M., M.D., L.D.,
and L.B.; writing—review and editing, M.F., L.D., and L.B. All authors have read and agreed to the published
version of the manuscript.
Funding: Regione Autonoma della Sardegna: Algorithms and Models for Imaging Science [AMIS], Fondazione
Banco di Sardegna: F72F20000350007.
Acknowledgments: M.F. was in part supported by Regione Autonoma della Sardegna research project “Algorithms
and Models for Imaging Science [AMIS]”, FSC 2014–2020—Patto per lo Sviluppo della Regione Sardegna and in
part by the Fondazione Banco di Sardegna with the grant “Formal Methods and Technologies for the Future of
Energy Systems”, n◦ F72F20000350007.
Conflicts of Interest: The authors declare no conflict of interest.

References
1.
2.
3.
4.

5.

6.
7.
8.
9.
10.
11.
12.
13.
14.

15.

Chan, H.-L.; Kuo, P.-C.; Cheng, C.-Y.; Chen, Y.-S. Challenges and Future Perspectives on
Electroencephalogram-Based Biometrics in Person Recognition. Front. Neuroinform. 2018, 12, 66. [CrossRef]
Crobe, A.; Demuru, M.; Didaci, L.; Marcialis, G.L.; Fraschini, M. Minimum spanning tree and k-core
decomposition as measure of subject-specific EEG traits. Biomed. Phys. Eng. Express 2016, 2, 017001. [CrossRef]
Fraschini, M.; Hillebrand, A.; Demuru, M.; Didaci, L.; Marcialis, G.L. An EEG-Based Biometric System Using
Eigenvector Centrality in Resting State Brain Networks. IEEE Signal Process. Lett. 2015, 22, 666–670. [CrossRef]
La Rocca, D.; Campisi, P.; Vegso, B.; Cserti, P.; Kozmann, G.; Babiloni, F.; Fallani, F.D.V. Human Brain
Distinctiveness Based on EEG Spectral Coherence Connectivity. IEEE Trans. Biomed. Eng. 2014, 61,
2406–2412. [CrossRef] [PubMed]
Pani, S.M.; Ciuffi, M.; Demuru, M.; La Cava, S.M.; Bazzano, G.; D’Aloja, E.; Fraschini, M. Subject, session
and task effects on power, connectivity and network centrality: A source-based EEG study. Biomed. Signal
Process. Control 2020, 59, 101891. [CrossRef]
Ruiz-Blondet, M.V.; Jin, Z.; Laszlo, S. CEREBRE: A Novel Method for Very High Accuracy Event-Related
Potential Biometric Identification. IEEE Trans. Inf. Forensics Secur. 2016, 11, 1618–1629. [CrossRef]
Yang, S.; Deravi, F.; Hoque, S. Task sensitivity in EEG biometric recognition. Pattern Anal. Appl. 2018, 21,
105–117. [CrossRef]
Haller, M.; Donoghue, T.; Peterson, E.; Varma, P.; Sebastian, P.; Gao, R.; Noto, T.; Knight, R.T.; Shestyuk, A.Y.;
Voytek, B. Parameterizing neural power spectra. bioRxiv 2018, 299859. [CrossRef]
Demuru, M.; Fraschini, M. EEG fingerprinting: Subject-specific signature based on the aperiodic component
of power spectrum. Comput. Biol. Med. 2020, 120, 103748. [CrossRef]
Betti, V.; Della Penna, S.; De Pasquale, F.; Corbetta, M. Spontaneous Beta Band Rhythms in the Predictive
Coding of Natural Stimuli. Neuroscientist 2020. [CrossRef]
Jenke, R.; Peer, A.; Buss, M. Feature Extraction and Selection for Emotion Recognition from EEG. IEEE Trans.
Affect. Comput. 2014, 5, 327–339. [CrossRef]
Lin, Y.-P.; Wang, C.-H.; Jung, T.-P.; Wu, T.-L.; Jeng, S.-K.; Duann, J.-R.; Chen, J.-H. EEG-Based Emotion
Recognition in Music Listening. IEEE Trans. Biomed. Eng. 2010, 57, 1798–1806. [CrossRef]
Petrantonakis, P.C.; Hadjileontiadis, L.J. Emotion Recognition from EEG Using Higher Order Crossings.
IEEE Trans. Inf. Technol. Biomed. 2010, 14, 186–197. [CrossRef] [PubMed]
Al-Nafjan, A.N.; Hosny, M.; Alohali, Y.A.; Al-Wabil, A. Review and Classification of Emotion Recognition
Based on EEG Brain-Computer Interface System Research: A Systematic Review. Appl. Sci. 2017, 7,
1239. [CrossRef]
Arnau-Gonzalez, P.; Arevalillo-Herraez, M.; Katsigiannis, S.; Ramzan, N. On the influence of affect in
EEG-based subject identification. IEEE Trans. Affect. Comput. 2018. [CrossRef]

Sensors 2020, 20, 6565

16.

17.
18.

19.
20.
21.

22.
23.
24.

9 of 9

Vahid, A.; Arbabi, E. Human identification with EEG signals in different emotional states. In Proceedings of
the 2016 23rd Iranian Conference on Biomedical Engineering and 2016 1st International Iranian Conference
on Biomedical Engineering (ICBME), Tehran, Iran, 24–25 November 2016; pp. 242–246. [CrossRef]
Katsigiannis, S.; Ramzan, N. DREAMER: A Database for Emotion Recognition Through EEG and ECG Signals
From Wireless Low-cost Off-the-Shelf Devices. IEEE J. Biomed. Health Inform. 2018, 22, 98–107. [CrossRef]
Koelstra, S.; Muhl, C.; Soleymani, M.; Lee, J.-S.; Yazdani, A.; Ebrahimi, T.; Pun, T.; Nijholt, A.; Patras, I.
DEAP: A Database for Emotion Analysis; Using Physiological Signals. IEEE Trans. Affect. Comput. 2012, 3,
18–31. [CrossRef]
Sonkusare, S.; Breakspear, M.; Guo, C. Naturalistic Stimuli in Neuroscience: Critically Acclaimed. Trends
Cogn. Sci. 2019, 23, 699–714. [CrossRef]
Ross, A.A.; Nandakumar, K.; Jain, A.K. Handbook of Multibiometrics; Springer: New York, NY,
USA, 2006. [CrossRef]
Fraschini, M.; Demuru, M.; Crobe, A.; Marrosu, F.; Stam, C.J.; Hillebrand, A. The effect of epoch length
on estimated EEG functional connectivity and brain network organisation. J. Neural Eng. 2016, 13,
036015. [CrossRef]
Delorme, A.; Makeig, S. EEGLAB: An open source toolbox for analysis of single-trial EEG dynamics including
independent component analysis. J. Neurosci. Methods 2004, 134, 9–21. [CrossRef] [PubMed]
Finn, E.S.; Bandettini, P.A. Movie-watching outperforms rest for functional connectivity-based prediction of
behavior. Neuroscience 2020. [CrossRef]
Lai, M.; Demuru, M.; Hillebrand, A.; Fraschini, M. A comparison between scalp- and source-reconstructed
EEG networks. Sci. Rep. 2018, 8, 12269. [CrossRef] [PubMed]

Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional
affiliations.
© 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).

