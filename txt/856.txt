Kent Academic Repository
Full text document (pdf)
Citation for published version
Yuvaraj, Rajamanickam and Murugappan, Murugappan and Ibrahim, Norlinah Mohamed and
Sundaraj, Kenneth and Omar, Mohd Iqbal and Mohamad, Khairiyah and Palaniappan, Ramaswamy
(2014) Optimal set of EEG features for emotional state classification and trajectory visualization
in Parkinson's disease. International Journal of Psychophysiology, 94 (3). pp. 482-495. ISSN

DOI
https://doi.org/10.1016/j.ijpsycho.2014.07.014

Link to record in KAR
http://kar.kent.ac.uk/48277/

Document Version
Pre-print

Copyright & reuse
Content in the Kent Academic Repository is made available for research purposes. Unless otherwise stated all
content is protected by copyright and in the absence of an open licence (eg Creative Commons), permissions
for further reuse of content should be sought from the publisher, author or other copyright holder.

Versions of research
The version in the Kent Academic Repository may differ from the final published version.
Users are advised to check http://kar.kent.ac.uk for the status of the paper. Users should always cite the
published version of record.

Enquiries
For any further enquiries regarding the licence status of this document, please contact:
researchsupport@kent.ac.uk
If you believe this document infringes copyright then please contact the KAR admin team with the take-down
information provided at http://kar.kent.ac.uk/contact.html

*Manuscript
Click here to view linked References

Running head: Emotional state classification in PD

Optimal set of EEG features for emotional state classification and trajectory
visualization in Parkinson’s disease

R. Yuvaraja,*, M. Murugappana, Norlinah Mohamed Ibrahimb, Kenneth Sundaraja, Mohd Iqbal Omara,
Khairiyah Mohamadb, R. Palaniappanc

a

School of Mechatronic Engineering, University Malaysia Perlis (UniMAP), Arau, Malaysia

b

Neurology Unit, Department of Medicine, UKM Medical Center, Kuala Lumpur, Malaysia

c

Faculty of Science and Engineering, University of Wolverhampton, Telford, UK

*Correspondence author at: R. Yuvaraj, School of Mechatronic Engineering, University Malaysia Perlis
(UniMAP), Campus UluPauh, Arau, Perlis, 02600, Malaysia. E-mail: yuva2257@gmail.com; Tel: +6014-6011990; Fax: 04-988-5167

1

Emotional state classification in PD

2
Abstract

In addition to classic motor signs and symptoms, individuals with Parkinson’s disease
(PD) are characterized by emotional deficits. Ongoing brain activity can be recorded as
electroencephalograph (EEG) to discover the links between emotional states and brain activity.
This study utilized machine-learning algorithms to categorize emotional states in PD patients
compared with healthy controls (HC) using EEG. Twenty non-demented PD patients and 20
healthy age-, gender-, and education level-matched controls viewed happiness, sadness, fear,
anger, surprise, and disgust emotional stimuli while fourteen-channel EEG was being recorded.
Multi-modal stimulus (combination of audio and visual) was used to evoke the emotions. To
classify the EEG-based emotional states and visualize the changes of emotional states over time,
this paper compares four kinds of EEG features for emotional state classification and proposes an
approach to track the trajectory of emotion changes with manifold learning. From the
experimental results using our EEG data set, we found that (a) bispectrum feature is superior to
other three kinds of features, namely power spectrum, wavelet packet and nonlinear dynamical
analysis; (b) higher frequency bands (alpha, beta and gamma) play a more important role in
emotion activities than lower frequency bands (delta and theta) in both the groups and; (c) the
trajectory of emotion changes can be visualized by reducing subject-independent features with
manifold learning. This provides a promising way of implementing visualization of patient’s
emotional state in real time and leads to a practical system for noninvasive assessment of the
emotional impairments associated with neurological disorders.
Keywords: electroencephalogram; emotion classification; feature reduction, manifold learning;
Parkinson’s disease.

Emotional state classification in PD

3

1. Introduction
Parkinson’s disease (PD) is a neurodegenerative disorder associated with the loss of
dopamine-producing neurons in the basal ganglia. The cardinal symptoms of the disease are
tremor, muscular rigidity, bradykinesia (i.e., slowness of movement), and postural instability.
These motor impairments are often accompanied by a wide range of non-motor symptoms (e.g.,
depression, executive dysfunctions, sleep disturbances, autonomic impairments), both symptom
categories having a great impact on the quality of PD patient’s life (Martinez-Martin et al.,
2011).
Over the last decade, there has been an increasing attention to the role played by
emotional processes in PD (Gray and Tickle-Degnen, 2010; Péron et al., 2012). Evidence
indicates the individuals with PD have deficits in recognizing emotions from prosody (Dara et
al., 2008; Pell and Leonard, 2003; Yip et al., 2003) and facial expressions (Ariatti et al., 2008;
Clark et al., 2008; Dujardin et al., 2004), although not all findings have been consistent. Several
studies have failed to find impaired performance in the recognition of facial expressions related
to emotion in their PD samples (Adolphs et al., 1998; Pell and Leonard, 2005), whereas others
have failed to find deficits in recognition from prosody (Clark et al., 2008; Kan et al., 2002). In a
recent meta-analysis of the literature comparing emotional recognition abilities of individuals
with PD and healthy controls (HC), Grey and Tickle-Degnen concluded that there is a robust link
between PD and deficits in emotion recognition using both voice and faces, with impairments
particularly marked with respect to negative emotions (Gray and Tickle-Degnen, 2010). A
commonly drawn inference is that the emotion recognition deficit experienced by individuals
with PD is likely to be cross-modal (Peron et al., 2010), yet only a small number of studies have
examined emotion recognition performance in both facial and prosodic modalities with same

Emotional state classification in PD

4

participants. A number of these report found deficits in both modalities (Ariatti et al., 2008; Yip
et al., 2003), whereas others found problems in only one modality (facial, Pell and Leonard,
2003); prosody, Pell and Leonard, 2005), and at least one failed to find deficits in recognition in
either modality (Caekebeke et al., 1991).
Furthermore, there is sparse event related potential (ERP) evidence that early processing
of emotional prosody (mismatch negativity, Schröder et al., 2006) and faces (early posterior
negativity, Wieser et al., 2012) may be affected in PD. Altogether, experimental evidence does
support the view of deficits in emotion processing in PD patients. However, much of the research
in this area focused on the patient’s behavioral responses (i.e. participants were asked to match,
identify or rate the emotional stimuli) and few studies have measured physiological response to
emotions (e.g., ERPs). The existing literature mentioned above used traditional statistical
analysis tools for the investigation of emotion processing in PD. There is little quantitative
objective measurement that correlates with the emotional impairment in neurological disorder
patients compared to healthy controls participants. This underlines the need for an objective
quantitative measure of emotional processing that can identify and compute subtle changes in
emotional states and hence help in a group based comparative analysis between PD patients and
HC, thereby enabling the assessment of emotional impairment treatment efficacy and
progression of the disease.
Numerous studies on engineering approaches to automatic emotion recognition have been
performed with healthy participants in the past few decades. They can be categorized into three
main approaches. The first kind of approach focuses on the analysis of facial expressions,
speech, or gesture (Anderson and McOwan, 2006; Gunes and Piccardi, 2007; Kessous et al.,
2010). These audio-visual based techniques allow noncontact detection of emotions, so they do

Emotional state classification in PD

5

not give any discomfort to the subject. However, these techniques might be more prone to
deception, and the parameters vary in different situations. The second kind of approach focuses
on peripheral physiological signals. Various studies show that peripheral physiological signals
varying for different emotional states can be observed through changes of autonomic nervous
system (ANS) in the periphery, such as electrocardiogram (ECG), skin conductance (SC),
electromyogram (EMG), respiration rate (RR), and pulse (Valenza et al., 2012). In comparison
with audio-visual based methods, the responses of peripheral physiological signals tend to
provide more detailed information as indicator for estimating emotional states. The third kind of
approach focuses on brain signals captured from central nervous system (CNS) such as
electroencephalogram (EEG), Magnetoencephalogram (MEG), Positron Emission Tomography
(PET), and functional Magnetic Resonance Imaging (fMRI). Among these, EEG appears to be
less invasive and the one with best time resolution as compared to the other methods (MEG,
PET, and fMRI). In addition, EEG signals have been proved to provide informative
characteristics in responses to the emotional states (Petrantonakis and Hadjileontiadis, 2011).
Recently, emotion classification using EEG data has attracted much attention with the
rapid development of dry electrodes, digital signal processing methods, machine learning
techniques, and various real- world applications of brain computer interface (BCI) for healthy
controls. However, there still exist some limitations on traditional EEG-based emotion
recognition framework. One of the major limitations is that almost all existing methods do not
consider the characteristics of EEG and emotion. In general, EEG is unsteady rapidly changing
voltage signal and the features extracted from EEG usually changes dramatically, whereas
emotions only change gradually. This leads to wider differences among EEG features, even with
the same emotional state in adjacent time periods. Moreover, existing studies with HC are only

Emotional state classification in PD

6

able to predict the labels of emotion samples, but could not reveal the trend of changes in the
emotion. To overcome these limitations, in this paper, we introduce an approach to track the
trajectory of emotion changes in PD patients compared to HC. In order to validate the
effectiveness of the proposed method we compare four kinds of EEG emotion-specific features,
and evaluate the classification performance of six emotional states (happiness, sadness, fear,
anger, surprise and disgust) of PD patients in comparision with age-, education level- and
gender-matched HC.
The rest of the paper is organized as follows: Section 2 provides an overview of related
work on various methods for EEG based emotion classification in HC. Section 3 presents the
participants’ characteristics and experiment setting for emotion induction. A description of
feature extraction, feature dimensionality reduction, classification, and trajectory of emotion
changes is given in Section 4. Finally in Section 5, we present experimental results that we
obtained. Conclusions and future work are presented at the end.

2. Related work
Since EEG not only indicates emotional states, but also reflects other cognitive activity of
the brain. The selection of independent variables to discriminate emotions from the EEG across
various electrode locations is not very self-evident, thus recently researchers explored complex
methods to find the correlation between the emotional changes and EEG signals. Zhang and Lee
reported an average accuracy of 73.00% ± 0.33% by using EEG features to categorize subject’s
status into two emotional states (Zhang and Lee, 2009). Chanel et al. obtained an average
accuracy of 63% by using EEG time-frequency information as features for three emotional
classes (Chanel et al., 2009). Lin et al. (2010) used EEG signals to recognize emotions in
response to emotional music. Their study achieved a recognition rate of 82.29% ± 3.06% for four

Emotional state classification in PD

7

emotional states (Lin et al., 2010). Murugappan et al. (2010) attained a maximum average
accuracy of 83.26% for distinguishing five emotional states using different set of EEG channels
(Murugappan et al., 2010). Petrantonakis et al. (2010) proposed a user-independent emotionestimation system for recognizing six emotional states; with the average accuracy of 83.33%
achieved (Petrantonakis and Hadjileontiadis, 2010). Moreover, evidence of brain activity relating to
affective responses is reported in the majority of EEG frequency bands, i.e., theta (4 – 8 Hz), alpha (8 –

13 Hz), beta (13 – 30 Hz), and gamma (30 – 49 Hz) (Aftanas et al., 2004; Davidson, 2004). Frontal
midline (Fm) theta power modulation is suggested to reflect affective processing during
emotional stimuli (Sammler et al., 2007). The alpha-power asymmetry on the prefrontal cortex
has been proposed as an index for the discrimination between positively and negatively valenced
emotions (Davidson, 2004; Schmidt and Trainor, 2001). Beta activity has been associated with
emotional arousal modulation (Aftanas et al., 2006) and also, asymmetric activity in this band is
linked to the emotional dimensions of approach or withdrawal (Schutter et al., 2001). Finally,
gamma band has been mainly suggested as related to arousal effects (Balconi and Lucchiari,
2008).

3. Materials
3.1 Recruitment of eligible participants
Twenty non-demented PD patients (10 men and 10 women) and 20 healthy controls (9 men
and 11 women) matched for age (range from 40 – 65 years), education level, and gender
participated in the study. The PD patients were recruited through the Neurology Unit outpatient
service at the Department of Medicine of the Hospital University Kebangsaan Malaysia
(HUKM) medical center in Kuala Lumpur, Malaysia. All of them had been diagnosed with
Idiopathic PD by a neurologist. Patients who had coexisting neurological disturbances (e.g.,

Emotional state classification in PD

8

epilepsy, stroke) or who had undergone deep brain stimulation were not included in the study.
The HC participants were recruited through the hospital community and/or from relatives of PD
patients.
Exclusion criteria for controls included any current psychiatric or neurological disorder.
Exclusion criteria for both groups were dementia or depression as indicated by a score of 24 or
lower on the Mini-Mental State Examination (MMSE) (Folstein et al., 1975; Wieser et al., 2012)
or 18 or higher on the Beck Depression Inventory (BDI) (Beck et al., 1961; Schröder et al.,
2006). All participants were right-handed as determined by self-report and confirmed by
Edinburgh Handedness Inventory (EHI) (Oldfield, 1971). This test consisted of 10 questions
asking for the preferred hand for a series of activities (e.g. writing, throwing, using scissors, etc.).
All participants reported normal or corrected-to-normal vision and intact hearing was formally
established in all participants by administering a pure tone audiometric screening of both ears to
ensure acceptable normal hearing threshold (minimum 30 dB HL at 0.5, 1, 2, and 4 kHz, for the
better ear).
3.2 Participant’s characteristics
Demographic and clinical characteristics of patients with PD and healthy controls are
presented in Table 1. Patients and controls were comparable in demographic variables such as
age (PD: mean age =59.05 ± 5.64 years; HC: mean age = 58.10 ± 2.95 years), t (38) = 0.667, p =
0.509, gender distribution (PD: 10 men, HC: 09 men), x2(1, N = 40) = 0.100, p = 0.752, and
education level (PD: 10.45 ± 4.86 years; HC: 11.05 ± 3.34 years), t (38) = -0.455, p = 0.652.
Furthermore, PD patients and HC did not differ in mean MMSE scores, mean BDI scores as well
as mean EHI scores.

Emotional state classification in PD

9

The severity of motor symptoms corresponded to the Stages I – III (Stage I = unilateral
disease with mild symptoms, Stage II = bilateral involvement, Stage III = bilateral symptoms
with postural and gait disturbances) of the Hoehn and Yahr scale (Hoehn and Yahr, 1967) and to
an average score of 17.05 ± 3.15 in the motor scale of the Unified Parkinson’s Disease Rating
Scale (UPDRS) (Fahn et al., 1987). Motor symptoms were characterized as left dominant (n =
11) and right dominant (n = 9). Duration of the disease varied between 1 – 12 years, with a mean
of 5.75 ± 3.52 years. All of the patients were undergoing dopamine replacement therapy and
were tested while being administered their anti-Parkinsonian medication (i.e. during their “ON”
state), distributed as follows: d2-agonist (n = 18); carbidopa/L-dopa (n = 13), monoamine
oxidase B (MAO-B) inhibitor (n = 7), catechol-O-methyltransferase (COMT) inhibitor (n = 5),
amantadine (n = 5), or anticholinergics (n = 3).
3.3 Ethics statement
This study was approved by the ethics committee of the HUKM and written informed
consent was obtained according to the Declaration of Helsinki. Participants were financially
compensated (50 Malaysian Ringgits) for their time.
3.4 Stimulus material
Gathering good and meaningful data are essential in any signal processing application. In
works related to emotion recognition using physiological signal, acquiring emotional data that
corresponds to specific emotional state is challenging, because of the subjective nature of the
emotions and cognitive dependence of physiological signals which requires the emotional states
to be elicited internally in the participant. Until now, most studies on emotion recognition in PD
have used only facial stimuli, prosodic stimuli, or music stimuli (Gray and Tickle-Degnen, 2010;
Lima et al., 2013; Péron et al., 2012). In addition, a number of emotion induction techniques

Emotional state classification in PD

10

using pictures, sounds, music, or multimodal approach (combination of audio and visual) have
been used to elicit the target emotions in healthy controls (Baumgartner et al., 2006; Lin et al.,
2010; Murugappan et al., 2010; Petrantonakis and Hadjileontiadis, 2011; Wang et al., 2013).
Among all of these stimuli modalities researchers have identified that multimodal stimuli induce
emotions in the participants more naturally and more effectively compared to other modalities
(Murugappan et al., 2010; Wang and Guan, 2008). In this work, we have utilised a multimodal
approach to evoke specific targeted emotional state.
The emotional stimuli we used were taken from different sources such as the
International Affective Picture System (IAPS) database (Lang et al., 2008), International
Affective Digitized Sounds (IADS) (Bradley and Lang, 2007) database and video clips (e.g.,
funny animals, wonder activities by humans etc.) collected from various resources on the internet
(e.g., YouTube, Facebook, and others) (Murugappan et al., 2010). The elicitation of emotions
such as sad, fear, and disgust was attained by using affective pictures from IAPS and sounds
from IADS databases. Various psychological and psychophysiological experiments have
revealed that these stimuli sets have great potential in the investigation of sad, fear, and disgust
emotion [43, 50]. Additionally, Mikels et al. (Mikels et al., 2005) and Redondo et al. (Redondo
et al., 2008) provided a more complete characterisation of the categorical structure of the IAPS
and IADS stimuli set, with the objective of identifying images and sounds that elicit one discrete
emotion more than other emotions. The IAPS pictures1 [disgust: valence- mean ± SD = 2.43 ±
1.51, arousal mean ± SD = 5.90 ± 2.25; fear: valence mean ± SD = 3.80 ± 1.89, arousal mean ±
SD = 5.85 ± 2.12; sadness: valence- mean ± SD = 2.74 ± 1.57, arousal mean ± SD = 5.00 ± 2.08]
and IADS sound2 [disgust: valence mean ± SD = 4.00 ± 1.72, arousal mean ± SD = 5.82 ± 1.93;
fear: valence mean ± SD = 4.00 ± 1.72, arousal mean ± SD = 5.82 ± 1.93; sadness: valence

Emotional state classification in PD

11

mean ± SD = 3.28 ± 1.65, arousal mean ± SD = 6.61 ± 1.89] were selected and combined
together according to their arousal and valence values provided in the databases. For example, a
negative/high aroused sound was matched with a negative/high aroused image. On the other
hand, the emotions happiness, surprise, and anger were elicited using video clips. A pilot study
was conducted to identify the video clip that was better able to elicit the target emotion in the
participants. 90 video clips corresponding to happiness, surprise and anger were displayed to 30
volunteers with a mean age of 26.4 years (ranging from 24 to 45 years). All of them were
psychology teachers or students of the UKM medical center, Kuala Lumpur. Of these, 30 clips
with the highest ratings were chosen for data collection.
3.5 Emotion elicitation protocol
An illustrated representation of the emotion elicitation protocol is shown in Figure 1(a). As
shown in the figure, the protocol had two sessions of three trials each. There was a break of 10–
15 minutes between the sessions. The participants were allowed to relax during the break since
the continuous assessment would have been too exhausting. The multimodal stimuli relating to
all the six emotional states (happiness, sadness, fear, anger, surprise and disgust) were displayed
in each trial in a random order. Each combination of picture and sound was presented for 6seconds (Yuvaraj et al., 2014). To maximise the participants’ emotional response, each clip block
consisted of six combinations of the same emotional category and lasted for 36-seconds. In
addition, each of the video clips varied from 36–45 seconds in duration, depending on the length
of the clip. Neutral images, which can calm down the participants, were displayed for 10 seconds
at the start of each trial. This would help the participants return to the normal or neutral state
away from emotional excitation. Besides, a 15 second rating interval (Hamdi et al., 2012) was

Emotional state classification in PD

12

provided between the clips in which participants answered a five point self-assessment
questionnaire. Each session took approximately 30 minutes.
3.6 Procedure
The purpose of the study was clearly explained to the participants before initiating the
experiment. The participants were further requested to relax, minimise their bodily movements
(as much as possible, to reduce the appearance of undesired artifacts in the EEG recordings), and
concentrate on the emotional stimuli. The self-guided emotion elicitation protocol was then
displayed on the screen. The complete experimental set up is shown in Figure 1(b). At the end of
each clip, participants filled a self-assessment questionnaire to state the status of the emotions
they felt during the experiment; they were also asked to report the strength of the emotions using
a five-point scale according to the degree (1 = very low, 2 = low, 3 = medium, 4 = high, and 5 =
very high). These ratings were then used to understand the intensity of the emotional state they
experienced. However, despite the intensity levels, all emotional data were taken into
considerations. The participants were also allowed to indicate multiple emotions during the
experiment. An example of the self-assessment questionnaire is shown in Figure 1(c).
3.7 EEG recordings
EEG recordings were conducted using the Emotive EPOC 14 channel EEG wireless
recording headset (Emotive Systems, Inc., San Francisco, CA) (Hadjidimitriou and Hadjileontiadis,
2012). The electrode scheme was arranged according to the international 10–20 system and
included active electrodes at AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, and AF4
positions, referenced to the common mode sense (CMS-left mastoid)/driven right leg (DRL-right
mastoid) ground as shown in Figure 1(d). The acquired data were digitised using the embedded
16-bit ADC with 128 Hz sampling frequency per channel and sent to the computer via wireless

Emotional state classification in PD

13

communication, which utilises a proprietary USB dongle to communicate using the 2.4 GHz
band.
4. Methods
4.1 Signal preprocessing
First, the time waves of EEG data were pre-processed using thresholding method to remove
movement artifacts (such as eye movement/blinking), in which data that are found to have
amplitudes of more than 80 µV are discarded from the study (Gotlib et al., 1998). Second, a 6th
order bandpass Butterworth filter (with forward reverse filtering algorithm) was used to extract
the frequency range of 1–49 Hz. Third, each channel of the artifact-free emotional EEG data was
divided into same-length of epochs without overlapping using time-windows. Finally, all
features discussed below were computed on each epoch of the emotional EEG data of PD
patients and HC.
4.2 Feature Extraction
The main task of feature extraction is to derive the significant features which can map the
EEG data into consequent emotional states. For a comparative study, we investigated four kinds
of features, namely bispectrum, power spectrum, wavelet packet and nonlinear dynamical
analysis.
4.2.1 Bispectrum feature
Higher order spectra are the spectral representations of higher order moments or cumulants
of a signal (Nikias and Petropulu, 1993). The third order statistics is called bispectrum which is
used in this study. The bispectrum B( f1 , f 2 ) is the Fourier transform of the third order correlation
of the signal and is given by
B( f1 , f 2 ) = E[ X ( f1 ) X ( f 2 ) X * ( f1 + f 2 )]

(1)

Emotional state classification in PD

14

where X ( f ) represent the Fourier transform of the signal x (nT ) , n is an integer index, * denotes
complex conjugate and E[] denotes the statistical expectation operation over an ensemble of
possible realizations of the signal. For deterministic sampled signals, X ( f ) is the discrete-time
Fourier transform and is computed using Fast Fourier Transform (FFT) algorithm. The frequency
f may be normalized by the Nyquist frequency (half of the sampling frequency) that lies

between 0 and 1. The bispectrum, given by Eq. (1), is a complex valued function of two
frequencies. The bispectrum exhibits symmetry, and needs to be computed in non- redundant
regions or in its principal domain. Assuming there is no bispectral aliasing, the bispectrum of a
real valued signal is uniquely defined with the triangle 0 ≤ f 2 ≤ f1 ≤ f1 + f 2 ≤ 1 . This nonredundant region is denoted by Ω , is also termed as principal domain and is shown in Figure 2
(Nikias and Petropulu, 1993).
In order to calculate bispectrum feature, we used epochs of 768 samples with hanning
window of 50% overlap corresponding to six seconds at the used sampling rate of 128 Hz. These
epochs were taken from each record of 1024 NFFT points. The mean magnitude of the
bispectrum were log transformed after being extracted in standard EEG frequency bands such as
delta (1– 4 Hz), theta (4 – 8 Hz), alpha (8 – 13 Hz), beta (13– 30 Hz) and gamma (30–49 Hz).
Besides bispectrum feature of all electrodes (BNoAs), the bispectrum of differential asymmetry
was also chosen as features. Throughout the whole brain, there were seven asymmetry indices
derived from seven symmetric electrode pair combinations, namely AF3-AF4, F7-F8, F3-F4,
FC5-FC6, T7-T8, P7-P8, and O1-O2. The asymmetry indexes were calculated either by
bispectrum subtraction (e.g. bispectrum of F3 minus bispectrum of F4) or division (bispectrum
of F3 divide bispectrum of F4) (Lin et al., 2010; Wang et al., 2013) and named as bispectrum

Emotional state classification in PD

15

differential asymmetry of seven electrode pairs (BDAs) and rational asymmetry of seven
electrode pairs (BRAs), respectively.

4.2.2 Power spectrum feature
Power spectrum (second order measures of HOS) can be analyzed to characterize the
perturbations in the oscillatory dynamics of ongoing EEG (Lin et al., 2010). First, each of the
EEG data was processed with Hanning window in order to reduce ‘spectral leakage effects’.
Second, windowed epochs were subjected to Fast Fourier Transform (FFT) with length of 1024
point (spectral resolution of 0.125 Hz). Finally, EEG power spectrums were log transformed
after being extracted in delta, theta, alpha, beta, and gamma bands with ranges as mentioned
previously. Similar to bispectrum asymmetry, we also adopted the spectral power of the
hemispheric asymmetry and labeled as power spectrum differential asymmetry (PDAs) and
rational asymmetry (PRAs) of seven electrode pairs (Lin et al., 2010; Wang et al., 2013).
4.2.3 Wavelet packet (WP) feature
Wavelet packet feature is the time-frequency domain feature that has been used for EEG
signal analysis (Murugappan et al., 2010). Usually, tests are performed with different types of
wavelets and the one which gives maximum efficiency is selected for the particular application.
In this study, Daubechies wavelet of order four (db4) was used to analyze the emotional EEG
data. In order to investigate the effect of other wavelets on classification accuracy, tests were
carried out using other wavelets. Apart from db4, Symmlet of order 10 (sym10), Coiflet of order
4 (coif4), and Daubechies of order 2 (db2) were also tested. It was noticed that daubechies
wavelet gives best accuracy (due to its near optimal time-frequency location properties) than the
others, and db4 is slightly better than db2.

Emotional state classification in PD

16

Furthermore, the choice of number of decomposition level is very important in analysis
of signals using WP transform (WPT). The decomposition level is chosen based on the dominant
frequency components of the signal. The level(s) are chosen such that those parts of the signal
that correlate well with the frequency necessary for classification of the signal are retained in the
wavelet packet coefficients. In the present study, EEG signals were decomposed into four levels.
The lowest frequency resolution can be estimated as
∆f =

1 fs
= 4 Hz
24 2

( 2)

where f s is the sampling rate of 128 Hz. There are 2 4 = 16 sub-bands of wavelet packets at the
fourth level whose corresponding frequency ranges are f1 : [0,4] , f 2 : [4,8] , f 3 : [8,12] , f 4 : [12,16]
,..., f16 : [60,64] .These frequency bands have similar range with the traditional frequency bands
derived from clinical EEG signal analysis. Specifically, delta band is f1 : 1– 4 Hz, theta band is

f 2 : 4 – 8 Hz, alpha band is f3 : 8 – 12 Hz, beta band is f 4 − f8 : 12– 32 Hz and gamma band is

f9 − f16 : >32 Hz. Thus specific bands of emotional EEG signals can be extracted by WPT from
PD patients and HC.
Since the coefficients from each resolution level j correspond to different frequency
bands, the energy E j for each frequency range in each time window can be computed as the
corresponding squared coefficients. Total energy Etotal of the signal in each time window was
calculated as the sum of energies of all resolution levels. Thereafter, the relative wavelet energy
(RWE) (Eq.3) was computed as the ratio between the energy of each band.
Pj = E j Etotal

(3)

Emotional state classification in PD

17

Then, the wavelet packet entropy (WPE) can be defined as
WPE j = −

Pj log 2 Pj

( 4)

j

The relative wavelet coefficient energy Pj , and wavelet packet entropy WPE j were chosen as the
time frequency domain features in this study.
4.2.4 Nonlinear feature
Non-linear analysis is useful for biological time-series (such as EEG) analysis as such
signals typically exhibit complex dynamics (Aftanasa et al., 1997). Several non-linear features
approaches have been proposed to detect the underlying important dynamical properties of the
physiological phenomenon. In this paper, we studied the emotional EEG signals using three
different types of nonlinear dynamical features, namely approximate entropy, Hurst exponent,
and detrended fluctuation analysis.
Approximate entropy ( Ae ) is part of a family of statistics that can be seen as non-linear
quantification of the regularity of a signal (Pincus, 1995). Approximate entropy takes into
account the temporal order of points in a time sequence and is therefore appropriate measure of
randomness or regularity. The first step in computing approximate entropy of a time series xi ,
i = 1,2,....., n , is to construct the state vectors in the embedding space:
yi = {xi , xi +1 , xi + 2 ,....., x(i + m −1)}, 1 ≤ i ≤ n − m + 1

(5)

where m is the embedding dimension. Second, we compute

Cim (r ) =

n − m +1
1
θ (r − d ( yi , y j ))
n − m + 1 j =1

(6)

Emotional state classification in PD

18

where θ ( y ) (θ ( y ) = 1) for y > 0 , θ ( y ) = 0 , otherwise) is the standard Heavyside function, r is
the vector comparison distance, and d ( yi , y j ) is a distance measure defined by

d ( yi , y j ) = max

k =1, 2 ,...., m

(y

i + k −1)

− y j + k −1)

)

Third, we compute φ m (r ) as, φ m (r ) =

(7 )

n − m +1
1
ln Cim ( r )
n − m + 1 i =1

(8)

Finally, for fixed m , r , and n , approximate entropy Ae can be expressed as
Ae ( m, r , n) = φ m ( r ) − φ m +1 ( r )

(9)

For this study, m is set to 2 and r is set to 0.2 times of the standard deviation of the data.
These values are selected on the basis of previous studies indicating good statistical validity for
Ae using these values (Pincus and Goldberger, 1994).
Hurst exponent (H) is the measure of the smoothness of a fractal time series based on the
asymptotic behavior of the rescaled range of the process. In time series analysis, Hurst exponent
is used by many researchers for characterizing the non-stationary behavior of the EEG episodes
(Wang et al., 2013). First, the accumulated deviation of mean of the time series over time is
computed. The rescaled range R S follows a power law relationship with time T as,
R S ~TH

(10)

where R is the difference between the maximum and minimum deviation from the mean and S
represents the standard deviation. The Hurst exponent, H can be derived as,

H = log(R S ) log(T )

(11)

Emotional state classification in PD

19

where T is the length of sample data and R/S represents the corresponding value of rescaled
range.
In addition, in this work we also used Detrended Fluctuation Analysis (DFA), which is a
method for determining the statistical self-affinity of a signal. It is related to measures based
upon spectral techniques such as autocorrelation and Fourier transform. Briefly, the time series
to be analyzed (with N samples) is first integrated. Next, the integrated time series is divided into
boxes of equal length, n . In each box of length n , a least square line is fit to the data
(representing the trend in that box). The y coordinate of the straight line segments is denoted by

yn (k ) . Next, we detrended the integrated time series, y ( k ) , by subtracting the local trend, yn (k ) ,
in each box. The root mean-square fluctuation of this integrated and detrended time series was
calculated by

F ( n) =

1
N

N

[ y(k ) − yn (k )]2

(12)

k =1

4.3 Feature dimensionality reduction
Feature dimensionality reduction can not only improve learning efficiency, but also
improve prediction performance. In this study, feature dimensionality reduction was carried out
with three well known dimension reduction methods, namely principal component analysis
(PCA), independent component analysis (ICA), and correlation-based feature selector (CFS).
Principal component analysis is a useful statistical technique that represents the raw data
in a lower dimensional feature space to convey maximum useful information, by seeking to find
the highest variability in the original feature space. It uses eigenvalues to determine the
significance of principal components so that dimensionality reduction is accomplished by
selecting principal components in accordance with magnitude of their associated eigenvalues.

Emotional state classification in PD

20

Independent component analysis is a nonlinear dimensionality reduction method (Hyvarinen and
Oja, 2000). It assumes that the observed signal is a result of mixing of several sources or
independent signals. The ICA method involves computation of a mixing matrix. The weights in
this mixing matrix are used as features for subsequent emotion pattern classification.
Correlation-based feature selector is a kind of supervised dimensionality reduction
method. Each feature gets a score presenting its correlation with emotion by this method. The
most emotion-relevant features can be found by ranking these scores. Let EEG feature set be
denoted by m x n matrix X , where m is the dimension of features and n is the number of samples,
then X = {X 1 , X 2 ,....... X n } . Let riT denote the random variable corresponding to the i th component
of X , i = 1,2,3,....m and y denote the label set of samples. The emotion-relevant score of each
feature can be computed as follows:
Rri y =

Cri y
Cri C y

(13)

where C represents covariance and R denotes the correlation coefficient. The absolute value of
correlation can be regarded as the emotion-relevant score. Ranking these scores in a descending
order, the top-ranked features are considered as the most emotion-relevant features.
4.4 Emotional state classification
To assess the association between EEG and emotional states of PD patients in comparision with HC,
the classification into the predefined emotional classes was achieved by using support vector machine
(SVM) classifiers and Fuzzy K-Nearest Neighbor (FKNN).
In SVM, a separating hyperplane that maximizes the margin between the input data classes which
are viewed in an n-dimensional space (n is the number of features used as inputs) is determined. SVM can
be easily adapted to nonlinearly separable data by the use of kernel functions to map the data to a much

Emotional state classification in PD

21

higher dimensional space where the data becomes more separable. FKNN assigns a class based on the
predominant class among the k nearest neighbors. Euclidean distance was used as the metric in FKNN
allocating fuzzy class memberships before making decisions. The fuzzy strength parameter m is used to
determine how heavily the distance is weighted when calculating each neighbor’s contribution to the
membership value. Here, the m value is varied between 1 and 2 with steps of 0.01, and the classification
performance is obtained using k -values between 1 and 10.
In order to use entire dataset for training and testing the classifiers, a ten-fold cross-validation
method was adopted, where the feature vectors were divided randomly into ten sets and training is
repeated for ten times. Classification performance was evaluated through the classification accuracy (CA)
and is computed between six emotional states of PD patients and HC as,
!
(

)

!

"#$%&$'

* +,,

(14)

"#$%&$'

where -./01/2 refers to the six emotional states namely happiness, sadness, fear, anger, surprise and
disgust of PD patients and HC (i.e., 34 5 67896:;<=>>
and HI;<=>>

?@@ A@ @=B ?@@ A@ C?=D A@ = E?D A@ @FD>D @? A@ B @EF@ G ,

?@@ A@ @=B ?@@ A@ C?=D A@ = E?D A@ @FD>D @? A@ B @EF@ G G,

across delta, theta, alpha, beta, gamma

EEG frequency bands and ALL (combination of five frequency bands). The overall performance of the
classifier is evaluated by taking the average and standard deviation (SD) of the accuracies of the ten-fold
classification. Here, the SD of the classification clearly reveals the consistency of the classifier results and
the number of classes used for classification here is six for each group.

4.5 Trajectory of emotion changes

In the analysis, we focused on the emotion classification, but then emotion usually changes.
Thus we also used manifold learning to find the trajectory of emotion changes in PD patients and
HC.

Emotional state classification in PD

22

In this work, the Isometric feature mapping method (hereafter referred as Isomap) is chosen
for its global characteristics (Tenenbaum et al., 2000). Isomap has been successfully applied to
the analysis of high-dimensional biomedical data (Park, 2012). Isomap seeks to preserve the
intrinsic geometry of the nonlinear data by utilizing the geodesic manifold distances (i.e. shortest
path along the manifold connecting two points) between all pairs of data points
(Balasubramanian and Schwartz, 2002). The algorithm can be summarized in three steps: Step 1:
Construction of global neighborhood graph. For each point, find its k nearest neighbors using the
predefined conditions. Construct a neighborhood graph by connecting each point to its k
neighbors, with the distance of the points in the original spaces as the edge weights. Step 2:
Computation of shortest paths. Estimate the shortest paths di , j between each pair of points i, j as
geodesic distance. The shortest paths were computed by Dijkstra method with the global
neighborhood graph. Step 3: Construction of embedding. After calculation of the shortest paths,

{ }

the data can be represented with the matrix D = di2, j , expressing the geodesic distance of each
pair of points on the manifold. Applying classical multidimensional scaling (MDS) to this matrix
constructs an embedding of the data that best preserves the manifolds estimated intrinsic
geometry.
1
Assume that K = − ( I − zz T ) D ( I − zz T ),
2

(15)

with z = 1 n(1,1,....1)T . The largest k eigenvalues of K are λ1 , λ2 ,.., λk and the respective
eigenvectors are u1 , u2 ,....uk . Assume U = (u1 , u2 ,...., uk ) , then the embedding result is
Y = diag ( λ1 , λ2 ,...., λk )U T

(16)

The selected features we obtained from dimensionality reduction were input to the Isomap
model and the one dimension output curve is the trajectory of the emotional changes.

Emotional state classification in PD

23

5. Experimental results and discussions
5.1 Statistical analysis

The statistical significance of all the computed emotion-specific features (namely
bispectrum [BNoAs, BDAs, and BRAs], power spectrum [PNoAs, PDAs, and PRAs], wavelet
packet [WPE, and RWE] and nonlinear dynamical analysis [Ae, H, and DFA]) was studied using
analysis of variance (ANOVA) test. The significant threshold was set to (p < 0.05). The ANOVA
results indicated that all the emotion features were showed statistically significant (p < 0.05)
changes among the six emotional states of PD patients and HC across delta, theta, alpha beta,
gamma and ALL frequency bands. This also ensures the probability of achieving better
classification accuracy. In particular, emotional features of HC show very low p-value (p <
0.0001) compared to PD (p < 0.05) among the six emotional states. This may ensure the EEG is
not reflecting the emotion accurately in PD, which could be interpreted as impairment in the
brain’s processing ability of emotions.
5.2 Time windows

To find the most suitable time window length, we compared the classification
performance using bispectrum feature obtained from PD patients and HC across ALL EEG
frequency bands with ten different length time windows between 1-second and 10-second in step
of 1-second. The radial basis function (RBF) kernel SVM classifier was applied to these ten
different lengths. The average classification results are presented in Table 2. It can be seen that
the average classification of accuracy of 6-second EEG epochs is better than those of others.
Hence 6-second was chosen as the time window length in the remaining analysis. Figure 3 shows
the average classification accuracies of bispectrum across delta, theta, alpha, beta, gamma and
ALL frequency bands with different length time windows for PD patients and HC. In this case,

Emotional state classification in PD

24

twenty participants from each group with six emotions, six trials per emotion, and six epochs per
channel for each band resulted in a total of 4320 x 70 (14 channels x 5 bands) feature vectors,
which were processed.
5.3 Choosing of SVM kernels

One of our motivations is to obtain the best classification performance of emotional states of
PD patients and HC. For the SVM classifier, to find the best kernel, the performance of three
different types of kernels, namely linear kernel (hereafter denoted SVMlinear), polynomial
kernel (SVMpoly), and RBF kernel (SVMRBF), was compared in our experiments. The
parameters of SVM were determined by ten-fold cross-validation technique. For SVMlinear, we
estimated the classification accuracy using different cost parameters C : C ∈ {2−5 ,2−4 ,....,214 ,215 }.
For SVMpoly, we studied the validation accuracy using different combinations of the cost
parameter C and polynomial degree of d : C ∈ {2−5 ,2−4 ,.....,214 ,215 } and d ∈ {1,2,3,......,14,15}. For
SVMRBF, we used the different combinations of the cost parameter C and kernel parameter γ :

γ ∈ {2−15 ,2−14 ,....,23 ,24 }. The code to implement SVMs was obtained from LibSVM (Chang and
Lin, 2001).
Figure 4 shows the relationship between the FKNN classification accuracy of bispectrum
across ALL frequency bands and fuzzy strength parameter m which varies in the range of 1 and
2 in the steps of 0.01 using different values of k . It can be observed that the classification
accuracy fluctuates between 60% and 75% with different values of m . It reveals that the fuzzy
strength parameter has a big impact to the performance of FKNN classifier. The better
classification accuracy was achieved with the parameter pair of (3, 1.17), (5, 1.06), and (7, 1.02)
as shown in Figure 4(a) – (c) when k is equal to 3, 5, and 7 respectively. These optimal different

Emotional state classification in PD

25

parameter pairs, namely (3, 1.17), (5, 1.06), and (7, 1.02) are used in the subsequent experiments,
and for convenience they are named FKNN1, FKNN2, and FKNN3 respectively.
Table 3 and Table 4 shows the average classification performance of bispectrum feature
extracted from PD patients and healthy controls emotional states across delta, theta, alpha, beta,
gamma, and ALL frequency bands using SVM (linear, poly, and RBF kernels) and FKNN
classifier (FKNN1, FKNN2, and FKNN3). From the tables, several important observations can
be drawn. First, it can be observed that the classification performance of bispectrum across ALL
frequency bands is better than those based on individual frequency bands under the same
conditions. Second, it is found that the classification performance of alpha, beta, and gamma
bands is better than those of delta and theta bands in both the groups. This partly reflects that
higher frequency bands play a more important role in emotion activities than lower frequency
bands (Oathes and Ray, 2008; Wang et al., 2013) in PD patients and HC respectively. On the
contrary, previous findings of EEG-emotion correlation in theta band has been reported (Aftanas
and Golocheikine, 2001; Sammler et al., 2007). This may be influenced by the contribution of
different approaches to data analysis. Third, PD patients achieved less averaged classification
performance compared with HC among the six emotional states. This suggests that the PD
patients give lower accuracy as the EEG is not representing the emotion accurately, which could
be interpreted as impairment in the brain’s processing ability of emotions. This is an agreement
with other studies that there is decrease in brain’s complexity during emotion processing due to
the dysfunction in the neural circuits (Adolphs et al., 1996; Lawrence et al., 2007). Recent
evidence points to neuropathological changes in PD in many brain areas which are assumed to
play key roles in emotion processing (Kober et al., 2008). These include limbic structures such as
the amygdala, and the ventral striatum, which is centrally located within the basal ganglia’s

Emotional state classification in PD

26

limbic loop. Furthermore, our results are compatible with the more general hypothesis that a loss
of complexity appears when the biological systems become functionality impaired (Jeong et al.,
1998). Finally, the average classification performance of SVM with RBF kernel outperforms
SVMlinear, SVMpoly and FKNN classifier. The best average classification accuracy of
bispectrum across ALL frequency bands using SVMRBF is 77.43% ± 1.59% and 83.04% ±
1.87% for PD patients and HC, respectively. This definitely proves the robustness of the
SVMRBF over the SVMlinear, SVMpoly and FKNN for these data sets. Therefore SVM with
RBF kernel was chosen as the classifier for the following stages.
5.4 Comparison of bispectrum with other features

To find the best emotion-specific features of PD patients and HC, the other types of
features were also analyzed in this study. Table 5 shows the average classification performance
of the bispectrum differential and rational asymmetry features. It can be seen that the
classification performance of the combination of ALL bispectrum of differential asymmetry is
better than BRAs features. The average accuracy with the combination of ALL BDAs features is
72.96% ± 1.56% and 74.31% ± 2.19% for PD patients and HC, respectively using SVMRBF
kernel function. Table 6 shows the average classification performance of power spectrum feature
types PNoAs, PDAs, and PRAs across different EEG frequency bands. The classification
performance of using PNoAs is evidently better than those based on other types under the same
conditions. A maximum average classification accuracy of 65.62% ± 2.56% and 68.19% ±
2.34% is obtained using ALL frequency bands for PD patients and HC, respectively.
Table 7 shows the classification performance of the WP features. The average
classification performance of wavelet packet entropy across ALL frequency bands is better than

Emotional state classification in PD

27

other wavelet packet feature. A maximum classification accuracy of 55.97% ± 1.77% and
63.96% ± 2.61% for PD patients and HC respectively is obtained using the WP entropy across
ALL frequency bands. Table 8 shows the classification performance using nonlinear dynamical
features. From Table 8, it can be seen that the approximate entropy feature gives a maximum
average classification accuracy of 67.61% ± 1.36% and 73.17% ± 1.57% for PD patients and
HC, respectively over other nonlinear dynamical features.
From the above analysis, the average classification performance confirms that bispectrum
across ALL frequency bands is the most robust feature among all of the four types of features
studied.
5.5 Comparision of feature dimensionality reduction methods

Our goal here was to find the relationship between EEG data and emotional states of PD
patients in comparision with HC. Moreover, we wished to obtain the general subject-independent
features related to emotion. Thus, feature dimensionality reduction was implemented in our
study. Since the best performance was obtained using the bispectrum across ALL frequencies,
three kinds of dimensionality reduction methods, namely PCA, ICA and CFS were applied for
further data analysis.
The classification performance of the PCA method is shown in Figure 5(a). The
horizontal axis denotes the number of principle components used for classification, and the
vertical axis denotes the average classification accuracy. It can be noted that when the feature
dimension reaches a certain number (30 principle components), the average classification
accuracy becomes almost stable. This number is much smaller than the dimension of the original
features. However, there exist differences in classification performance between PD patients and
HC. Figure 5(b) illustrates the average classification accuracy of using the ICA approach. Again,

Emotional state classification in PD

28

when the feature dimension reaches a certain number, the average classification accuracy
becomes almost stable. Obviously this number is smaller than the dimension of the original
features. The classification performance of the CFS approach is shown in Figure 5(c). When the
dimension of feature reaches about 40, the average classification accuracy becomes almost
stable, and the average accuracy is about 72.60% ± 2.48% and 78.89% ± 2.79% for PD patients
and HC, respectively. Obviously this number is smaller than the dimension of the original
features.
From the Figure 5(a) – 5(c), it can be noted that the best average classification accuracy
of 76.90% ± 1.48 and 86.78% ± 1.34% is obtained for PD patients and HC, respectively using
ICA method when the number of feature dimensions is reduced to 30, whereas the average
performance of using PCA is slightly better (76.78% ± 1.08 and 83.30 ± 2.08 for PD patients and
HC, respectively) and appears to be more stable. The merit of PCA is that the extracted
components have minimum correlation along the principal axes, but PCA cannot be uses to find
the emotion-specific features since the data is transformed to the PCA domain. In contrast, the
features selected by CFS were directly computed from features. Therefore, the discriminative
emotion-related brain areas and frequency bands could be found by CFS.
The distribution of top 40 subject-independent features in PD patients and healthy
controls (since the classification accuracies of CFS method become almost stable after the
dimension reaches about 40) is shown in Figure 6. As can be seen, none of the top 40 features
are in the delta band and very few are in the theta band. This may suggests that delta and theta
bands have little relationship with emotion. This result contrast with previous findings of EEGemotion correlation in these bands (Aftanas and Golocheikine, 2001; Sammler et al., 2007)
since the approaches to data analysis varied from study to study. In PD patients, the selected

Emotional state classification in PD

29

subject-independent features were mainly in the left frontal lobe and temporal lobe for the alpha
band, the temporal lobe beta band, and right occipital lobe and anterior frontal lobe for gamma
band. Whereas, in HC, the selected subject-independent features were in the left parietal lobe for
alpha band, the right temporal and parietal lobe for beta band, and the left occipital and frontal
lobe for gamma band. The emotion-related brain areas finding in HC is nearly consistent with the
emotion studies of other researchers (Davidson et al., 1985; Guntekin and Basar, 2007; Schutter
et al., 2001), however, none of the studies investigated PD patients.

5.6 Trajectory of emotion changes

In order to find the trajectory of emotion changes in PD patients and HC during the
experiment, we place the selected top 40 subject-independent features into the manifold model
and reduced the features into one dimension using the Isomap method. The trajectory of emotion
changes is as shown in Figure 7. The horizontal axis denotes the time, and the vertical axis
denotes the emotional value estimated by Isomap. The dashed red line represents the emotional
state labels (i.e. reference) where positive emotions (happiness, surprise) are labeled as +1 and
negative emotions (sadness, fear, disgust, anger) are labeled as -1. The solid blue line indicates
the values Isomap estimation. During the experiment, emotional stimuli were presented at
random order. It can be seen that the changes of the trajectory obtained by Isomap are consistent
with the change of emotional states. We can also observe that the estimated emotional values
decrease from HC participant to PD patients during the evoking of the emotions. This is due to
the dynamic processes underlying the EEG recording that are less complex for PD patients than
HC during emotion processing.
6. Conclusion

Emotional state classification in PD

30

Non-motor symptoms, including disruptions in emotion information processing have
been found in over 50% of newly diagnosed PD patients. In this study, we investigated the
characteristics of EEG features of PD patients in comparision with HC for emotion classification
and a technique for tracking the trajectory of emotion changes. Multi-modal stimulus was
designed to arouse six emotional states (happiness, sadness, fear, anger, surprise, and disgust) of
participants and EEG data from 20 PD patients and 20 HC was recorded. Four kinds of features,
namely bispectrum, power spectrum, wavelet packet, and nonlinear dynamical analysis were
extracted to assess the association between the EEG data and emotional states. Experimental
results demonstrate that bispectrum across ALL frequency bands was the most robust feature
among all four kinds features discussed above, and higher frequency bands play more important
role in emotion activities than lower frequency bands in both the groups. However, the use of
small number of PD samples which affect the reliability of the system. In order to generalize the
proposed algorithm, further studies should use larger number of samples to examine the
relationship between brain activity and emotions in PD.
Furthermore, three feature dimensionality reduction methods, namely PCA, ICA, and
CFS were implemented on the feature set. The best average classification accuracy of 76.90% ±
1.08% and 86.78% ± 2.08% for PD patients and HC was achieved by using ICA method when
the number of feature dimension was reduced to 30. The top 40 subject-independent features
most relevant to emotion were selected by the CFS method. Through, these subject-independent
features, we found the emotion related brain areas in PD patients and HC. The trajectory of
emotion changes was obtained by a manifold learning model. This provided a promising way of
implementing visualization of patient’s emotional state in real time and could lead to a practical
system for noninvasive assessment of the emotional impairments associated with neurological

Emotional state classification in PD
disorders. The future development of this research will be focused on analyzing each of the six
emotional state differences of PD patients compared with HC.

31

Emotional state classification in PD

32

Appendix
1

The following pictures in the database were used for emotion induction: Disgust: 1945, 2352.2,

3000, 3010, 3015, 3030, 3051, 3060, 3061, 3071, 3080, 3110, 3120, 3130, 3140, 3150,3160,
3250, 3400, 7360, 7361, 7380, 8230, 9040, 9042, 9181, 9290, 9300, 9320, 9330, 9373, 9390,
9405, 9490, 9570, 9830; Fear: 1019, 1022, 1030, 1040, 1050, 1051, 1052, 1070, 1080, 1090,
1110, 1111, 1113, 1120, 1200, 1201, 1220, 1230, 1240, 1280, 1274, 1300, 1301, 1302, 1321,
1390, 1930, 1931, 3280, 5970, 5971, 5972, 6370, 9584, 9594, 9592; Sadness: 2205, 2271, 2276,
2490, 2520, 2590, 2700, 2800, 2900, 3220, 3230, 3300, 3301, 3350, 6570, 6838, 8010, 9000,
9041, 9050, 9120, 9190, 9210, 9220, 9331, 9410, 9415, 9470, 9520, 9530, 9561,9611, 9910,
9911, 9920, 9921.
2

The following sounds in the database were used for emotion induction: Disgust: 134, 115, 251,

262, 284, 698, 702, 711, 712, 713, 714, 720, 728, 729, 730, 732, 812, 813; Fear: 106, 133, 170,
171, 275, 276, 277, 279, 291, 312, 378, 380, 424, 425, 500, 626, 627, 699, 817; Sadness: 115,
150, 260, 261, 278, 280, 285, 286,290, 293, 295, 310, 311, 368, 403, 420, 422, 501, 600, 625.

Emotional state classification in PD

33

Acknowledgements

The research was financially supported by Ministry of Science and Technology (MOSTI),
Malaysia. Grant Number: 9005-00053. The authors would like to thank Dr. Mohamad Fadli, Dr.
Siva Rao Subramanian and Dr. Shahrul Azmin for their assistance with recruitment of PD
participants. Also we would like to thank all of the individuals who participated in this study.

Emotional state classification in PD

34

References

Adolphs, R., Damasio, H., Tranel, D., Damasio, A.R., 1996. Corticle systems for the recognition
of emotion in facial expressions. J. Neurosci 16, 7678-7687.
Adolphs, R., Schul, R., Tranel, D., 1998. Intact recognition of facial emotion in Parkinson's
disease. Neuropsychology 12, 253-258.
Aftanas, L.I., Golocheikine, S.A., 2001. Human anterior and frontal midline theta and lower
alpha reflect emotionally positive state and internalized attention: high resolution EEG
inestigation of meditaion. Neurosci. Lett 310, 57-60.
Aftanas, L.I., Reva, N.V., Savotina, L.N., Makhnev, V.P., 2006. Neurophysiological correlates
of induced discrete emotions in humans: An individually oriented analysis. Neurosci.
Behav. Physiol 36, 119-130.
Aftanas, L.I., Reva, N.V., Varlamov, A.A., Pavlov, S.V., Makhnev, V.P., 2004. Analysis of
evoked EEG synchronization and desynchronization in emotional activation in humans:
temporal and topographic characteristics. Neurosci. Behav. Physiol 34, 859-867.
Aftanasa, L.I., Lotovaa, N.V., Koshkarova, V.I., Pokrovskajaa, V.L., Popova, S.A., Makhneva,
V.P., 1997. Non-linear analysis of emotion EEG: calculation of Kolmogorov entropy and
the principal Lyapunov exponent. Neurosci. Lett 226, 13-16.
Anderson, K., McOwan, P.W., 2006. A real-time automated system for the recognition of human
facial expressions. IEEE Trans. Syst. Man and Cybern.-Part B Cybern 36, 96-105.
Ariatti, A., Benuzzi, F., Nichelli, P., 2008. Recognition of emotions from visual and prosodic
cues in Parkinson’s disease. Neurol. Sci 29, 219-227.
Balasubramanian, M., Schwartz, E., 2002. The isomap algorithm and topological stability.
Sccience 295, 7.

Emotional state classification in PD

35

Balconi, M., Lucchiari, C., 2008. Consciousness and arousal effects on emotional face
processing as revealed by brain oscillations. A gamma band analysis. Int. J. Psychophysiol
67, 41-46.
Baumgartner, T., Esslen, M., Jancke, L., 2006. From emotion perception to emotion experience:
Emotions evoked by pictures and classical music. Int. J. Psychophysiol 60, 34-43.
Beck, A.T., Ward, C.H., Mendelson, M., Mock, J., Erbaugh, J., 1961. An inventory for
measuring depression. Arch. Gen. Psychiatry 4, 561-571.
Bradley, M.M., Lang, P.J., 2007. International affective digitized sounds (2nd Edition; IADS-2):
Affective ratings of sounds and instruction manual. Technical Report B-3 University of
Florida, Gainesville, FL.
Caekebeke, J.F., Jennekens-Schinkel, A., VanderLinden, M.E., Buruma, O.J., Roos, R.A., 1991.
The interpretation of dysprosody in patients with Parkinson's disease. J. Neurol. Neurosurg.
Psychiatry 54, 145-148.
Chanel, G., Kierkels, J.J.M., Soleymani, M., Pun, T., 2009. Short-term emotion assessment in a
recall paradigm. Int. J. Hum. Comput. Stud 67, 607-627.
Chang, C., Lin, C., 2001. A Library for Support Vector Machines. Available at
http://www.csie.ntu.edu.tw/~cjlin/libsvm/.
Clark, U.S., Neargarder, S., Cronin-Golomb, A., 2008. Specific Impairments in the Recognition
of Emotional Facial Expressions in Parkinson’s disease. Neuropsychologia 46, 2300-2309.
Dara, C., Monetta, L., Pell, M.D., 2008. Vocal emotion processing in Parkinson's disease:
Reduced sensitivity to negative emotions. Brain Res 1188, 100-111.
Davidson, R.J., 2004. What does the prefrontal cortex “do” in affect: perspectives on frontal
EEG asymmetry research. Biol. Psychol 67, 219-233.

Emotional state classification in PD

36

Davidson, R.J., Schaffer, C.E., Saron, C., 1985. Effects of lateralized presentations of faces on
self-reports of emotion and EEG asymmetry in depressed and non-depressed subjects.
Psychophysiology 22, 353-364.
Dujardin, K., Blairy, S., Defebvre, L., Duhem, S., Noël, Y., Hess, U., Destée, A., 2004. Deficits
in decoding emotional facial expressions in Parkinson’s disease. Neuropsychologia 42,
239-250.
Fahn, S., Elton, R.L., Committee, M., 1987. Unified Parkinson's Disease Rating Scale. In:
Fahn's, Marsden CD, Calne DB, Goldstein M, Clane DB. Recent Developments in
Parkinson's Disease.Macmillan Health Care Information; Florham Park: 2, 153-163.
Folstein, M.F., Folstein, S.E., Mchugh, P.R., 1975. Mini-Mental State Examination: a practical
method for grading the cognitive state of patients. Psychol. Res 12, 189-198.
Gotlib, I.H., Raganathan, C., Rosenfeld, J.P., 1998. Frontal EEG alpha asymmetry, depression,
and cognitive functioning. Cogn. Emo 12, 449-478.
Gray, H.M., Tickle-Degnen, L., 2010. A meta-analysis of performance on emotion recognition
tasks in Parkinson’s disease. Neuropsychology 24, 176-191.
Gunes, H., Piccardi, M., 2007. Bi-modal emotion recognition from expressive face and body
gestures. J. Netw. Comput. Appl. 30, 1334-1345.
Guntekin, B., Basar, E., 2007. Emotional face expressions are differentiated with brain
oscillations. Int. J. Psychophysiol 64, 91-100.
Hadjidimitriou, S.K., Hadjileontiadis, L.J., 2012. Toward an EEG-based recognition of music
liking using time-frequency analysis. IEEE Trans. Biomed. Eng 59, 3498-3510.

Emotional state classification in PD

37

Hamdi, H., Richard, P., Suteau, A., Allain, P., 2012. Emotion assesment for affective computing
based on physiological responses. IEEE proc. World Congress on Computational
Intelligence (WCCI), 10-15.
Hoehn, M.M., Yahr, M.D., 1967. Parkinsonism: Onset, Progression and mortality. Neurology 17,
427-442.
Hyvarinen, A., Oja, E., 2000. Independent Component Analysis: Algorithms and Applications.
Neural Netw 13, 411-430.
Jeong, J., Kim, S.Y., Han, S.H., 1998. Non-linear dynamical analysis of the EEG in Alzheimer’s
disease with optimal embedding dimension. Electroencephalogr. Clin. Neurophysiol 106,
220-228.
Kan, Y., Kawamura, M., Hasegawa, Y., Mochizuki, S., Nakamura, K., 2002. Recognition of
emotion from facial, prosodic and written verbal stimuli in Parkinson's disease. Cortex 38,
623-630.
Kessous, L., Castellano, G., Caridakis, G., 2010. Multimodal emotion recognition in speechbased interaction using facial expression, body gesture and acoustic analysis. J. Multimodal
User Interfaces 3, 33-48.
Kober, H., Barrett, L.F., Joseph, J., Bliss-Moreau, E., Lindquist, K., Wagera, T.D., 2008.
Functional grouping and cortical–subcortical interactions in emotion: A meta-analysis of
neuroimaging studies. Neuroimage 42, 998-1031.
Lang, P.J., Bradley, M.M., Cuthbert, B.N., 2008. International affective picture system (IAPS):
Affective ratings of pictures and instruction manual. Technical Report A-8. University of
Florida, Gainesville, FL.

Emotional state classification in PD

38

Lawrence, A.D., Goerendt, I.K., Brooks, D.J., 2007. Impaired recogition of facial expression of
anger in Parkinson’s disease patients acutely withdrawn from dopamine replacement
theraphy. Neuropsychologia 45, 65-74.
Lima, C.F., Garrett, C., Castro, S.L., 2013. Not all the sounds sound the same: Parkinson's
disease affects differently emotion processing in music and in specch prosody. J. Clin. Exp.
Neuropsychol 35, 373-392.
Lin, Y.P., Wang, C.H., Wu, T.L., Jeng, S.K., Duann, J.R., Chen, J.H., 2010. EEG-based emotion
recognition in Music Listening. IEEE Trans. Biomed. Eng 57, 1798-1806.
Martinez-Martin, P., Blazquez, C.R.-., Kurtis, M.M., Chaudhuri, K.R., 2011. The impact of nonmotor symptoms on health-related quality of life of patients with Parkinson's disease. Mov.
Disord 26, 399-406.
Mikels, J., Fredrickson, B., Larkin, G., Lindberg, C., Maglio, S., Reuter-Lorenz, P., 2005.
Emotional Category data on images from the international affective picture system. Behav.
Res. Methods 37, 630-636.
Murugappan, M., Nagarajan, R., Yaacob, S., 2010. Combining Spatial Filtering and Wavelet
Transform for classifying human emotions using EEG signals. J. Med. Biol. Eng 31, 45-51.
Nikias, C.L., Petropulu, A., 1993. Higher-order spectral Analysis: A Nonlinear signal Processing
Framework. Prentice Hall, Englewood Cliffs, NJ.
Oathes, D.J., Ray, W.J., 2008. Worry, generalized anxiety disorder, and emotion: evidence from
the EEG gamma band. Biol. Psychol 79, 165-170.
Oldfield, R.C., 1971. The assessment and analysis of handedness: the Edinburgh Inventory.
Neuropsychologia 9, 97-113.

Emotional state classification in PD

39

Park, H., 2012. ISOMAP induced manifold embedding and its application to Alzheimer’s disease
and mild cognitive impairment. Neurosci. Lett 513, 141-145.
Pell, M.D., Leonard, C.L., 2003. Processing emotional tone from speech in Parkinson's disease:A
role for the basal ganglia. Cogn. Affect. Behav. Neurosci 3, 275-288.
Pell, M.D., Leonard, C.L., 2005. Facial expression decoding in early Parkinson’s disease. Cogn.
Brain Res 23, 327-340.
Peron, J., Biseul, I., Leray, E., 2010. Subthalamic Nucleus Stimulation Affects Fear and Sadness
Recognition in Parkinson’s disease. Neuropsychology 24, 1-8.
Péron, J., Dondaine, T., Jeune, F.L., Grandjean, D., Vérin, M., 2012. Emotional processing in
Parkinson's disease: a systematic review. Mov. Disord. 27, 186-199.
Petrantonakis, P.C., Hadjileontiadis, L.J., 2010. Emotion recogntion from brain signals using
hybrid adaptive filtering and higher order crossings analysis. IEEE Trans. Affect. Comput
1, 81-96.
Petrantonakis, P.C., Hadjileontiadis, L.J., 2011. A novel emotion elicitation index using frontal
brain asymmetry for enhanced EEG-based emotion. IEEE Trans. Inf. Technol. Biomed. 15,
737-746.
Pincus, S., 1995. Approximate entropy (apen) as complexity measure. Choas 5, 110-117.
Pincus, S.M., Goldberger, A.L., 1994. Physiological time-series analysis: what does regularity
quantify? Am. J. Physiol 266(4 Pt 2), H1643-1656.
Redondo, J., Fraga, I., Padron, I., Pineiro, A., 2008. Affective ratings of sound stimuli. Behav.
Res. Methods 40, 784-790.

Emotional state classification in PD

40

Sammler, D., Grigutsch, M., Fritz, T., Koelsch, S., 2007. Music and emotion:
electrophysiological correlates of the processing of pleasant and unpleasant music.
Psychophysiology 44, 293-304.
Schmidt, L.A., Trainor, L.J., 2001. Frontal brain electrical activity (EEG) distinguishes valence
and intensity of musical emotions. Cogn. Emo 15, 487-500.
Schröder, C., Möbes, J., Schütze, M., Szymanowski, F., Nager, W., Bangert, M., Münte, T.F.,
Dengler, R., 2006. Perception of emotional speech in Parkinson's disease. Mov. Disord 21,
1774-1778.
Schutter, D.J.L., Putman, P., Hermans, E., vanHonk, J., 2001. Parietal electroencephalogram beta
asymmetry and selective attention to angry facial expressions in healthy human subjects.
Neurosci. Lett 314, 13-16.
Tenenbaum, J.B., deSilva, V., Langford, J.C., 2000. A Global Geometric Framework for
Nonlinear Dimensionality Reduction. Science 290, 2319-2323.
Valenza, G., Lanata, A., Scilingo, E.P., 2012. The role of nonlinear dynamics in affective
valence and arousal recognition. IEEE Trans. Affect. Comput. 3, 237-249.
Wang, X.W., Nie, D., Lu, B.L., 2013. Emotional state classification from EEG data uisng
machine learning approach. Neurocomput 129, 94-106.
Wang, Y., Guan, L., 2008. Recognizing human emotional state from audiovisual signals. IEEE
Trans. Multimed. 10, 659-668.
Wieser, M.J., Klupp, E., Weyers, P., Pauli, P., Weise, D., Zeller, D., Classen, J., Muhlberger, A.,
2012. Reduced early visual emotion discrimination as an index of diminished emotion
processing in Parkinson’s disease? - Evidence from event-related brain potentials. Cortex
48, 1207-1217.

Emotional state classification in PD

41

Yip, J.T., Lee, T.M., Ho, S.L., Tsang, K.L., Li, L.S., 2003. Emotion recognition in patients with
idiopathic Parkinson's disease. Mov. Disord 18, 1115-1122.
Yuvaraj, R., Murugappan, M., Norlinah, M.I., Iqbal, M., Sundaraj, K., Mohamad, K.,
Palaniappan, R., Satiyan, M., 2014. Emotion classification in Parkinson's disease by
higher-order spectra and power spectrum features using EEG signals: A comparative study.
J. Integr. Neurosci 13, 1-32.
Zhang, Q., Lee, M., 2009. Analyis of positive and negative emotions in natural scene using brain
activity and GIST. Neurocomput 72, 1302-1306.

Table(s)

Emotional state classification from EEG in PD
Table 1 Demographic and clinical characteristics of patients with PD and healthy controls.

Age (years)

PD (N = 20)

HC (N = 20)

Test's Value

Statistical
result*

59.05 ± 5.64

58.10 ± 2.95

t = 0.667

p = 0.509

2

Sex

10F/10M

11F/9M

x = 0.100

p = 0.752

Education (years)

10.45 ± 4.86

11.05 ±3.34

t = -0.455

p = 0.652

MMSE score (0–30)

26.90 ± 1.51

27.15 ± 1.63

t = -0.502

p = 0.619

Hoehn and Yahr scale (I/II/III)

2.25 ± 0.63

-

-

-

Motor UPDRS score

17.05 ± 3.15

-

-

-

Disease duration (years)

5.75 ± 3.52

-

-

-

BDI score (0–21)

5.80 ± 2.87

5.45 ± 2.18

t =0.433

p = 0.667

EHS (1–10)

9.55 ± 0.76

9.84 ± 0.72

t = -0.818

p = 0.403

Note: N = number of participants, M = male, F = female, MMSE = mini mental state examination,
UPDRS = Unified Parkinson's Disease Rating Scale, BDI = Beck Depression Inventory, EHS = Edinburg
Handedness Inventory. Data presented as mean ± SD. *Difference is significant at the p < 0.05 level

Table 2 Average classification accuracies (± standard deviation) of bispectrum feature across different EEG
frequency bands with different length time windows.
Time
windows
length

Emotional EEG frequency band

Group
Delta (%)

Theta (%)

Alpha (%)

Beta (%)

Gamma (%)

ALL (%)

PD

49.89 ± 2.27

46.53 ± 2.49

56.02 ± 3.54

74.86 ± 1.10

72.12 ± 1.78

77.20 ± 2.81

HC

51.93 ± 2.16

52.78 ± 2.54

61.34 ± 2.30

78.24 ± 2.17

74.50 ± 2.67

80.39 ± 2.13

PD

47.36 ± 2.05

44.91 ± 2.01

51.32 ± 1.84

75.30 ± 2.67

74.00 ± 1.78

74.93 ± 1.55

HC

50.76 ± 2.58

51.62 ± 2.27

60.42 ± 2.23

78.52 ± 1.83

76.55 ± 2.16

78.37 ± 1.34

PD

52.66 ± 2.53

48.96 ± 1.80

59.47 ± 1.99

75.42 ± 1.91

74.09 ± 2.64

76.58 ± 2.21

HC

54.24 ± 2.01

56.17 ± 2.19

67.45 ± 2.21

79.07 ± 1.79

78.31 ± 1.82

81.48 ± 1.84

PD

53.29 ± 2.23

50.76 ± 2.50

64.88 ± 2.37

76.97 ± 1.91

74.72 ± 2.24

77.43 ± 1.59

HC

55.05 ± 2.45

57.25 ± 3.11

72.50 ± 1.85

80.30 ± 1.95

78.84 ± 2.05

83.04 ± 1.87

PD

51.60 ± 2.10

47.45 ± 3.10

54.49 ± 2.42

74.88 ± 1.01

73.45 ± 3.02

74.01 ± 1.82

HC

52.70 ± 1.63

57.01 ± 1.69

57.92 ± 2.04

75.57 ± 1.76

75.00 ± 2.01

80.76 ± 2.12

2s

3s

5s

6s

8s

Note: Here, ‘ALL’ means the combination of five EEG frequency band bispectrum features. Due to space reasons
we have reported only top five classification accuracies of different length time windows.

Table 3 Average classification accuracies (± standard deviation) of bispectrum feature (BNoAs) across different
frequency bands using SVM with different kernels.
Kernal
function
Linear

Poly

RBF

Emotional EEG frequency band

Group
Delta (%)

Theta (%)

Alpha (%)

Beta (%)

Gamma (%)

ALL (%)

PD

46.50 ± 1.91

38.75 ± 1.48

43.68 ± 2.19

48.13 ± 1.21

50.16 ± 2.35

56.76 ± 1.25

HC

50.51 ± 1.92

46.55 ± 1.89

53.75 ± 2.06

56.18 ± 2.27

59.38 ± 1.93

61.30 ± 2.16

PD

48.66 ± 2.46

39.03 ± 1.12

55.12 ± 2.18

60.53 ± 1.83

61.83 ± 3.00

68.13 ± 2.08

HC

52.89 ± 1.63

47.66 ± 2.28

59.12 ± 1.62

67.92 ± 2.28

71.62 ± 1.26

72.52 ± 1.55

PD

53.29 ± 2.23

50.76 ± 2.50

64.88 ± 72.50

76.97 ± 1.91

74.72 ± 2.24

77.43 ± 1.59

HC

55.05 ± 2.45

57.25 ± 3.11

64.88 ± 2.37

80.30 ± 1.95

78.84 ± 2.05

83.04 ± 1.87

Note: Here, ‘ALL’ means the combination of five EEG frequency band bispectrum features

Table 4 Average classification accuracies (± standard deviation) of bispectrum feature (BNoAs) across different
frequency bands using FKNN with different optimal parameters.

FKNN
FKNN1
k=3
m = 1.17
FKNN2
k=5
m = 1.06
FKNN3
k=7
m = 1.02

Emotional EEG frequency band

Group
Delta (%)

Theta (%)

Alpha (%)

Beta (%)

Gamma (%)

ALL (%)

PD

49.17 ± 2.59

41.00 ± 2.37

47.55 ± 2.77

62.59 ± 1.79

62.66 ± 1.94

69.42 ± 1.56

HC

54.56 ± 1.99

51.06 ± 2.71

57.20 ± 1.86

70.79 ± 1.41

72.22 ± 2.86

74.46 ± 1.75

PD

46.94 ± 2.09

38.89 ± 1.57

46.18 ± 2.52

58.36 ± 1.49

60.37 ± 2.74

67.69 ± 2.62

HC

51.76 ± 2.01

49.38 ± 1.70

53.75 ± 2.06

69.63 ± 1.92

71.88 ± 2.01

73.50 ± 1.27

PD

47.45 ± 1.50

40.81 ± 2.35

36.44 ± 1.89

60.83 ± 2.00

60.56 ± 1.45

68.98 ± 2.24

HC

53.96 ± 2.33

49.49 ± 3.39

45.00 ± 0.87

69.55 ± 1.68

72.06 ± 2.12

73.38 ± 1.59

Note: Here, ‘ALL’ means the combination of five EEG frequency band bispectrum features

Table 5 Average classification accuracies (± standard deviation) of bispectrum asymmetry feature across different
frequency bands using SVM with RBF kernel.
Feature
type
BDAs

BRAs

Emotional EEG frequency band

Group
Delta (%)

Theta (%)

Alpha (%)

Beta (%)

Gamma (%)

ALL (%)

PD

46.85 ± 2.02

48.24 ± 1.82

52.15 ± 1.31

68.63 ± 1.99

65.00 ± 1.49

72.96 ± 1.56

HC

50.97 ± 2.46

52.50 ± 2.33

52.87 ± 2.63

67.62 ± 1.74

67.20 ± 3.02

74.31 ± 2.19

PD

47.11 ± 1.83

49.21 ± 2.86

52.38 ± 2.26

68.50 ± 1.89

64.95 ± 1.53

73.82 ± 1.70

HC

50.32 ± 2.32

53.15 ± 2.71

53.15 ± 2.28

67.94 ± 1.40

66.27 ± 2.02

73.84 ± 1.70

Note: Here, ‘ALL’ means the combination of five EEG frequency band bispectrum features

Table 6 Average classification accuracies (± standard deviation) of power spectrum feature across different
frequency bands using SVM with RBF kernel.
Feature
type

Emotional EEG frequency band
Group
Delta (%)

Theta (%)

Alpha (%)

Beta (%)

Gamma (%)

ALL (%)

PD

47.08 ± 1.36

40.44 ± 2.47

46.76 ± 2.57

61.81 ± 2.30

58.86 ± 1.81

65.62 ± 2.56

HC

53.36 ± 1.82

50.37 ± 2.83

55.00 ± 1.57

69.86 ± 1.78

66.83 ± 1.40

68.19 ± 2.34

PD

41.83 ± 1.96

34.84 ± 1.53

43.73 ± 2.02

48.89 ± 1.65

42.36 ± 1.80

52.82 ± 2.55

HC

47.27 ± 2.13

43.87 ± 1.59

48.73 ± 1.98

53.08 ± 2.78

47.85 ± 1.68

56.83 ± 2.05

PD

38.13 ± 2.62

33.52 ± 1.48

36.37 ± 2.21

48.19 ± 2.19

40.12 ± 2.95

49.56 ± 2.67

HC

42.96 ± 3.14

37.20 ± 1.54

40.65 ± 2.40

49.95 ± 2.46

42.34 ± 1.54

54.93 ± 3.32

PNoAs

PDAs

PRAs

Note: Here, ‘ALL’ means the combination of five EEG frequency band power spectrum features

Table 7 Average classification accuracies (± standard deviation) of wavelet packet feature across different frequency
bands using SVM with RBF kernel.
Wavelet
feature

RWE

WPE

Emotional EEG frequency band

Group
Delta (%)

Theta (%)

Alpha (%)

Beta (%)

Gamma (%)

ALL (%)

PD

19.44 ± 1.56

18.87 ± 1.06

39.81 ± 2.27

40.76 ± 2.44

42.48 ± 1.98

49.47 ± 1.67

HC

28.06 ± 2.24

27.85 ± 2.02

47.87 ± 0.97

50.12 ± 1.72

49.10 ± 1.66

59.07 ± 2.18

PD

41.50 ± 2.68

30.67 ± 1.34

41.97 ± 2.59

46.30 ± 2.91

45.93 ± 1.96

55.97 ± 1.77

HC

45.44 ± 3.14

34.81 ± 2.34

48.47 ± 2.12

49.84 ± 1.31

64.14 ± 2.41

63.96 ± 2.61

Note: Here, ‘ALL’ means the combination of five EEG frequency band wavelet packet features

Table 8 Average classification accuracies (± standard deviation) of nonlinear dynamic feature across different
frequency bands using SVM with RBF kernel.
Nonlinear
dynamic
feature
ApEn

Emotional EEG frequency band
Group
Delta (%)

Theta (%)

Alpha (%)

Beta (%)

Gamma (%)

ALL (%)

PD

40.58 ± 2.06

41.99 ± 2.20

47.75 ± 2.40

65.60 ± 1.91

64.68 ± 1.62

67.61 ± 1.36

HC

42.04 ± 2.16

45.39 ± 1.89

48.36 ± 1.62

72.01 ± 1.56

67.94 ± 1.54

73.17 ± 1.57

PD

40.72 ± 1.79

40.19 ± 2.13

52.84 ± 2.02

61.50 ± 1.32

60.76 ± 2.00

65.05 ± 1.99

HC

44.68 ± 2.06

45.55 ± 1.30

58.50 ± 1.64

67.63 ± 2.06

67.05 ± 1.90

69.34 ± 2.01

PD

38.73 ± 2.29

38.89 ± 3.20

43.75 ± 2.57

62.59 ± 2.52

61.53 ± 1.45

66.93 ± 1.95

HC

41.34 ± 1.53

38.66 ± 2.41

48.10 ± 1.86

68.17 ± 1.93

67.61 ± 1.74

73.12 ± 1.73

HE

DFA

Note: Here, ‘ALL’ means the combination of five EEG frequency band nonlinear features

Figure(s)

Emotional state classification from EEG in PD

Fig. 1 (a) Schematic representation of the experiment protocol

Fig. 1 (b) Experimental setup for emotion assessment using multimodal stimuli

Fig. 1 (c) Self-assessment questionnaire

Fig. 1 (d) Electrode positions, according to the 10-20 system, of the Emotiv EPOC device used for EEG
acquisition.

Fig. 2. Non-redundant region (W) of computation of the bispectrum for real signals

(a) PD patients

(b) Healthy controls

Fig. 3. Average classification accuracies of bispectrum feature across EEG bands with different
length time windows. (a) PD patients (b) healthy controls

(a)

(b)

(c)
Fig. 4. The relationship between average classification accuracy of bispectrum feature across
ALL EEG frequency bands and fuzzy strength m with different numbers of k

2
3
4
5
6
7
8
(a)

(b)

10
11
(c)

Fig. 5. Comparison of feature dimensionality reduction methods of across ALL frequency bands
(a) the process of PCA (b) the process of ICA (c) the process of CFS

(a)

(b)

Fig. 6. Distribution of top 40 subject-independent features (a) PD patients (b) healthy controls.
For interpretation of the references to color in this figure caption, the reader is referred to the
web version of this paper.

(a)

(b)

Fig. 7 The trajectory of emotion changes of (a) 20 PD patients and (b) 20 healthy controls during
the experiment. For interpretation of the references to color in this figure caption, the reader is
referred to the web version of this paper.

