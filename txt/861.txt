IoT-enabled Multimodal Sensing Headwear System
Aung Aung Phyo Wai

He Dajiang, Ng Soon Huat

Computational Intelligence Lab,
School of Computer Science and Engineering,
Nanyang Technological University
Singapore
apwaung@ntu.edu.sg

Neural and Biomedical Technology Department
Institute for Infocomm Research, A*STAR
Singapore
{hedj, shng}@i2r.a-star.edu.sg

Abstract—with the proliferation of Internet of Things (IoT)
paradigm, wearable devices and solutions aim to resolve unmet
needs from military, automotive to healthcare domains.
Particularly, there are growing interests in wearable Brain
Computer Interface (BCI) from both commercial and research
applications. Still uphill challenges lie ahead to bring such BCI
technologies to mass market due to lack of technical, usability and
application aspects. To fill these gaps, this paper presents design,
development and evaluation of an IoT-enabled multimodal
headwear system, iMESH. Our solution senses user’s neural,
physiological and physical states through direct measurements and
derives health parameters. We then developed driving fatigue
assessment application as exemplar to illustrate applicability and
feasibility of the proposed solution. Initial results are promising
and with ongoing development on methodologies, we are hoping to
further develop and validate iMESH functionalities in different
applications.

and neural states of subject under observation. From our
experiments with two EEG headsets for controlling drones,
various data quality and usability issues were identified [10].
This motivates us to design and develop an IoT-enabled
multimodal headwear system, iMESH. Based on the limitations
and issues identified [10], we have evaluated different electrode
materials, headwear design concepts and signal quality of
iMESH.
The system design, architecture and implementation of the
proposed multimodal headwear will be explained in section 2.
Section 3 describes experiment design, criteria and evaluation of
proposed headwear in design, signal quality and sensed health
parameters. Section 4 presents driving simulator scenario with
results achieved for real-time mental fatigue assessment
application. Finally, limitations and future works relevant to
proposed multimodal headwear system can be found in section 5.

Keywords—Internet of Things (IoT), Brain Computer Interface
(BCI), Multimodal Sensing Headwear.

I. INTRODUCTION
With pervasiveness of smart phone in our daily life and
proliferation of IoT technologies, paradigm in health and
wellness shifts from centralized to mobile care [1, 2]. In recent
years, BCI technology garnered huge interests to bring into mass
consumer market beyond clinical and lab settings [3]. There is a
potential to integrate BCI technology with existing IoT
technologies to create integrated body-mind wellness care [4].
There are some initial works on providing robust communication
for such wearable BCI devices interfacing with IoT [5, 6]. Even
wearable BCI is applicable in intelligent transport domains for
preserving safety and wellness [3, 7].
This paper presents design and implementation of wearable
multimodal sensing system connecting to IoT ecosystem [8]. In
recent years, there are a few successful crowd funding projects
for wearable BCI such as Muse$, Emotiv Insight&, OpenBCI%,.
Such EEG devices target application areas ranging from sleep,
entertainment, sport, etc. to safety and neuro-marketing [9]. Still
there are challenges and limitations in providing as a general
purpose BCI wearable device available for application
developers. Nevertheless, existing wearable devices do not
provide diverse sensing needs to measure motion, physiological
$

II. SYSTEM DESIGN AND ARCHITECTURE
Existing consumer BCI headsets and research prototypes [3,
9] only provide from one to five EEG channels and motion
sensor. But physiological parameters such as HR, HRV, etc. are
crucial to quantify various user wellness states. In addition to
EEG and motion sensing, iMESH supports 2 PPG sensors as
shown in Table 1; thus able to detect different neural,
physiological and motion parameters.
TABLE I.

COMPARISON OF DIFFERENT WEARABLE EEG SOLUTIONS

Mod
ality
EEG

Muse

Emotiv
Insight

iMESH

OpenBCI
Ganglion

[3]

Mindwave
mobile*

4

5

4

4

5

1

PPG

0

0

2

Add-on*

0

0

IMU

Yes

Yes

Yes

Yes

-

No

A. Hardware Design and Architecture
The following Fig 1(a) describes six hardware sub-modules
involved in iMESH’s PCB module. EEG Analog Front End
(AFE) consists of instrumentation amplifier, bias feedbacks with
Programmable Gain Amplifier (PGA) and Delta-Sigma Analog
to Digital Controller (ADC) to acquire unipolar brain wave
signals. PPG AFE includes Light Emitting Diode (LED) driver,

https://www.indiegogo.com/projects/muse-the-brain-sensing-headband#/
https://www.kickstarter.com/projects/tanttle/emotiv-insight-optimize-your-brain-fitness-and-per
%
https://www.kickstarter.com/projects/openbci/openbci-biosensing-for-everybody
*
https://store.neurosky.com/pages/mindwave
#
https://www.rigado.com/products/modules/bmd-350/
&

Trans-Impedance Amplifier and ADC connected to both infrared
and red LED and photo detectors. IMU DAQ senses physical
motion using integrated 3-axis accelerometer and 3-axis
gyroscope (six degrees of freedom). MCU and BLE wireless submodules are designed with SoC module, BMD350 from Rigado
Inc#. Power management supports different regulated voltages
required by EEG, PPG and IMU sensors and battery charging.
iMESH board size is 24 x 39 x 4 mm3 fabricated with 4-layered
PCB as shown in Fig 1(b).

streaming without geographical range limits. Topmost layer
relies on cloud-based Software-as-a-service (SaaS) platform
provided by third party IoT platform, Initial State Technologies
(https://www.initialstate.com) [14]. The modular integration with
existing data platform enables iMESH to be easily accessible
anywhere and at any level (local or remote applications at
heterogeneous devices) without delving into software
architecture implementation details [16]. So this tiered
architecture allows iMESH to be easily integrated into any IoT
system with multimodal sensing needs.

Fig. 1. iMESH Hardware and Prototype module (a) Hardware functional subcomponents (b) Actual PCB module with dimensions and sensor connectors

B. Health & Wellness Parameters Measurements
As discussed in previous section, iMESH differentiates itself
from other solutions by being able to support three sensing
modalities. The following Table II outlines several health and
wellness parameters directly measured and derived from acquired
EEG, PPG and IMU readings. Below table only lists some basic
features and some derived parameters to illustrate capabilities of
iMESH (Not exhausted listing). The additional features and
advanced parameters can further computed depending on
application requirements. Furthermore, multiple features can be
extracted with algorithms developed on module, PC or Cloud
according to the specific application needs [11, 12, 13].
TABLE II.

MEASURED AND DERIVED PARAMETERS OF THREE SENSORS

Sensor

EEG
PPG
IMU

Health and Wellness Parameters
Direct
Measures
Brain waves
Pulse
Signals
Acceleration
& Angular
raw readings

Features
5 band
powers
Peaks, IBI

Derived Parameters
General
Specific
Attention,
Fatigue,
Calmness
Emotion
PR#, PRV#
SpO2, RR#

#

ms-2 &
rad/sec

Quaternion,
Euler angles

Application
specific physical
activities

IBI – Inter Beat Interval, PR – Pulse Rate, PRV – Pulse Rate Variability, RR –
Respiratory Rate

C. Software Design and Platform
As shown in Fig 2, iMESH software is designed in three
layers: module (headwear), gateway (PC/mobile) and cloud. First
layer, firmware, at headwear is responsible for sensing, MCUbased processing and wireless transfer using BLE (Bluetooth
version 4.2). Middle layer, application and library, is
implemented at either PC or mobile platform to wirelessly
interface with headwear, perform full-fledged multimodal signal
processing, store synchronized data and support further data

Fig. 2. iMESH Software Design and Components (Right to Left ): (a)
Headband unit acquiring signals and wireless data transfer (b) Intermediate
device (PC or mobile) acquisition and data streaming by direct communication
with headband unit (c) Cloud or server remote unit analyzing, visualizing and
storing recorded data

III. HARDWARE DESIGN, TESTING AND EVALUATION
As iMESH supports three different sensors, careful hardware
design, software interfacing and signal quality evaluation were
involved in headwear development [17]. This section explains
detailed design, testing results and evaluation of signal quality of
iMESH in workbench as well as human subject testing scenarios.
A. Headwear design with Dry Electrodes
In order to ensure convenient and easy usage, dry electrode is
commonly used in consumer EEG headsets [18]. Similarly,
iMESH uses soft conductive fabric material as dry electrode [19].
EEG electrodes and PPG sensors can easily be fitted into
different wearable design, cap (Fig 3-a) or band (Fig 3-c),
through flexible PCB substrate (Fig 3-b), connected to the PCB
(Fig 1-b). EEG and PPG at forehead are positioned according to
EEG 10-20 standard as shown in Fig 3-d. Current dry electrodes
can achieve average contact impedance of 200-400 kΩ that is a
decent range for data recording with dry electrode.

Fig. 3. iMESH Wearable Design and Form Factor (a) Attached sensing strip to
cap as accessory (b) Internal of sensor strip in (a) where showing positions of
EEG fabric electrodes and PPG sensors (c) Wearable elastic band connected to
sensing strip as standalone headband strap (d) Positions of six EEG electrodes
and 2 PPG sensors at forehead area

B. Hardware Performance Evaluation
The amplitudes of EEG signals range from 10 to 100 µV [9,
17]. Self-noise or noise floor of EEG AFE is important to ensure
such tiny EEG signals can be captured and amplified correctly.
Noise floor can be measured by connecting all EEG electrodes
except bias to analog ground of the module. iMESH module
exhibits average RMS amplitude of 2.5 µV that is lower than
nominal EEG amplitude range. This basically explains why
iMESH can detect signals and signal changes across EEG signal
range.

Fig. 5. iMESH EEG amplifier outputs in response to simulated sine wave
inputs: Showing eight waveform output plots with input sine wave of 5Hz
frequency with eight amplitudes ranging from 10 µV to 2.5 mV (Top-Left graph:
10 µV, Bottom-Righ grapht: 2.5 mV, In-between graphs: outputs with input
amplitudes of 20, 50, 100, 200, 500, 1000 µV sequentially)

Subsequent tests involve wireless performance and battery
life time evaluation. The operating distance is more than 5 m
range from testing inside the lab while subject is wearing the
module under blocking and non-blocking conditions. iMESH
module lasts more than 7.5 hours with non-optimized firmware
for continuous data streaming with 250 Hz sampling using 150
mAh rechargeable LiPo battery. This illustrates that reliable
wireless data streaming with long-term usage can be achieved
with iMESH for different wearable application needs [2].
After passing basic work-bench testing successfully, the
acquired EEG and PPG signals are evaluated using basic signal
fidelity testing procedure using eye blinks, eye closed and eye
open events. As show in Fig 6-a, blinks (EOG) can easily be
detected using electrodes positioned at Fp1 and Fp2 with Fpz
reference montage. The strong EEG alpha power can be seen in
Figure 6-b while closing eyes compared with eye open
conditions as highlighted in green color box.

Fig. 4. Noise floor test results with iMESH hardware module (Top) EEG
waveforms (Middle) Amplitude Histogram, 2.53µV in time-domain (Bottom)
Noise Power Spectral Density (<-10dB) in frequency-domain

Another bench test includes injecting sine waves with varying
amplitude and frequency through EEG simulator to test EEG
AFE response. The results show no distortion in waveform with
amplified signals according to PGA’s gain settings set in
iMESH’s firmware as shown in Fig 5.

Fig. 6. iMESH EEG Amplifier’s Basic EEG signal fidelity testing outcomes
with time-domain waveforms (Top) and frequency-domain spectrum plots
(Bottom) [Only showing single EEG signal for clarity] (a) Eye blinks for plots at
left side (b) eye open and eye close for plots at right side.

The derived physiological parameters such as PR (HR) and
PRV (HRV) can be detected from PPG signals applying
appropriate signal processing approaches [12, 13]. Fig 7 shows
steps involved in derivation of PR and PRV from raw PPG
signals. HR and HRV parameters can be detected by processing
raw PPG signals through filtering, peak detections and finally,
extracting IBI features and applying first order derivatives.

(a)

(c)

(b)

(d)

Fig. 7. PPG outputs from iMEHS module (a) Raw PPG signals (b) peaks
detection after performing filtered and normalized PPG signals (c) normalized
Pulse Rate (PR) (d) normalized Pulse Rate Variability (PRV)

C. Real-time data streaming and visualization
Besides visualizing sensors’ readings at local device (PC or
mobile), iMESH extends availability of its data to anywhere
anytime real-time streaming and analytics using cloud SaaS. The
picture in Fig 8 shows a snapshot of visualizing EEG and PPG
signals at web browser by streaming from headwear through
cloud leveraging library provided by Initial State Technologies.
This paves way for BCI data availability beyond local (PC or
mobile) processing; and group based analysis of user’s neural
and physiological states through cloud-based data analytics. This
showcases how iMESH can leverage and integrate with existing
IoT software and hardware technologies for sensing neural,
physical and physiological parameters.

2 PPG Signals

4 EEG Signals

Fig. 8. Real-time streaming and visualization of EEG + PPG signals from
iMESH headwer over cloud using library from Initial State Technologies

IV. EXPERIMENTAL EVALUATION: FATIGUE ASSESSMENT
Several solutions applying different sensing and intelligent
approaches to mitigate accidents due to fatigue were proposed to
improve safety on the road [7, 16]. These research works
highlight the necessity of assessing in and off vehicle as well as
subject’s parameters to reliably determine fatigue states [17]. As
many parameters influence driver’s fatigue states especially in
real-world usage, research and development works are ongoing
to prevent road accidents due to driver’s fatigue regardless of
recent advances in autonomous driving [7].
To evaluate how iMESH works well on detecting fatigue
states, we conducted pilot in-house trials using EEG and PPG
sensors with simulated driving scenarios. The experiment design
and protocols are explained details in [21]. A total of ten healthy
subjects who have no sleep disorders or deprivation participated
in 1.5 hours long driving experiment as shown in Fig 5. Besides
EEG and PPG recording from iMESH, camera and eye tracker
data are recorded for data labeling and validation. Subject has to
complete driving game that emulates monotonous driving
scenarios. In this driving test, deviations of car are programmed
at random [2-10s] interval from center lane to either left or right
lane for evaluating user’s sleepiness through reaction time.
During the experiment, subject was instructed to look at the game
screen and turn steering wheel at correct direction immediately
whenever simulator deviates car from center lane to left or right
lane in random intervals. Reaction time (RT) for each lanedeparture event was calculated as the time latency between
deviation (at the start of lane deviation event in driving game)
and response onset (when user turning steering wheel). Current
fatigue assessment uses RT as surrogate measures to classify
between fatigue and non-fatigue events during driving scenarios.

Fig. 9. Fatigue Driving Experiment Setup (a) Driving Simulator with headwear
and additional sensors such as desktop eye trackers and kinect camera for
ground-truth evaluation (b) eye tracker plots (c) EEG spectrogram (d) PPG
signals [snapshots taken from one session of driving experiment]

With the labeled fatigue and non-fatigue datasets according to
RT ranges, mean classification has accuracy of 86.4% using
features extracted from EEG modality alone. Eye tracker
modality using gaze positions and gaze velocity has only 77.6%
accuracy. By combining EEG with PPG modalities, fatigue

detection accuracy improves 4 to 5 % compared with EEG
modality alone. This initial outcome is encouraging to include
multimodal sensors in detecting fatigue. Though motion data is
not used currently, its inclusion will be useful for head movement
based fatigue states detection as well as for reducing or removing
motion artifacts from EEG and PPG readings [22, 23].

[6]

[7]

[8]

V. DISCUSSION AND CONCLUSION
There will be unprecedented benefits by integrating wearable
BCI with existing IoT paradigm in various applications [1, 3, 20].
With integrated motion sensors, motion artifacts to EEG and PPG
signals caused due to body and head movements can be
alleviated [22, 23]. In our fatigue states recognition, data labeling
is solely based on time responds to lane deviation events. There
might be potentially biased datasets, imprecise labeling and over
fitting of data considered in fatigue states classification [3]. Also,
comparison of iMESH with clinical grade EEG amplifier for
signal fidelity and performance is yet to be carried out.
Though feasible, there are several challenges in deriving
reliable health parameters from sensors used in iMESH [12, 13,
20]. iMESH is the first step in realizing a wearable BCI that goes
beyond conventional wearable by exploiting Low-power wireless
and IoT technologies [1, 20]. Driving fatigue assessment is
complex due to several intrinsic influences and extrinsic factors
in both technical and usability aspects. The next step involves
validation in real-world scenarios with development of efficient
counter-measures to reduce fatigue states for safe driving [24].
This paper presents the design and evaluation of a wireless
low-power headwear system. iMESH leverages on low-power
SoC, IoT and SaaS platform for multimodal sensing, real-time
streaming, cloud storage and data analytics. We presented
hardware, software and design with evaluation of iMESH
functionalities and performance. Further evaluation with fatigue
assessment using driving simulator is developed and validated.
With integrated neural, physiological and physical sensing,
iMESH can be used in diverse applications by taking advantages
of integrated modular hardware and software eco system.
REFERENCES
[1]

[2]

[3]

[4]

[5]

S. M. R. Islam, D. Kwak, M. H. Kabir, M. Hossain and K. S. Kwak, "The
Internet of Things for Health Care: A Comprehensive Survey," in IEEE
Access, vol. 3, no. , pp. 678-708, 2015.
Piwek L, Ellis DA, Andrews S, Joinson A (2016) The Rise of Consumer
Health Wearables: Promises and Barriers. PLOS Medicine 13(2):
e1001953.
C. T. Lin et al., "Forehead EEG in Support of Future Feasible Personal
Healthcare Solutions: Sleep Management, Headache Prevention, and
Depression Treatment," in IEEE Access, vol. 5, , pp. 10612-10621, 2017.
McKeeth Jim, ‘THE BRAIN–COMPUTER INTERFACE IN THE
INTERNET OF THINGS, Internet of Things and Data Analytics
Handbook, John Wiley & Sons, Inc., 2017.
M. Muztoba, U. Gupta, T. Mustofa and U. Y. Ogras, "Robust
communication with IoT devices using wearable brain machine interfaces,"

[9]

[10]

[11]

[12]

[13]

[14]

[15]

[16]

[17]

[18]
[19]
[20]

[21]

[22]

[23]

[24]

2015 IEEE/ACM Int. Conf. on Computer-Aided Design (ICCAD), Austin,
TX, 2015, pp. 200-207.
P. K. Yong and E. T. W. Ho, "Streaming brain and physiological signal
acquisition system for IoT neuroscience application," IEEE EMBS Conf.
on Biomedical Engineering and Sciences (IECBES), pp. 752-757, 2016.
L. Li, D. Wen, N. N. Zheng and L. C. Shen, "Cognitive Cars: A New
Frontier for ADAS Research," in IEEE Transactions on Intelligent
Transportation Systems, vol. 13, no. 1, pp. 395-407, March 2012.
Mathe, E. and E. Spyrou, Connecting a Consumer Brain-Computer
Interface to an Internet-of-Things Ecosystem. Proc.9th ACM Int. Conf. on
PErvasive Technologies Related to Assistive Environments, ACM: 1-2
S. Lee, Y. Shin, S. Woo, K. Kim and H.-No Lee Review of Wireless BrainComputer Interface Systems, Brain-Computer Interface Systems - Recent
Progress and Future Prospects, Dr. Reza Fazel-Rezai (Ed.), InTech, 2013,
DOI: 10.5772/56436
P. Peining, A.A. Phyo Wai and G. Tan, “Evaluation of Consumer-Grade
EEG Headsets for BCI Drone Control”, Int. Researcher Club Conf on
Science, Engineering and Technology, 10-11 Aug 2017, Singapore.
W.A.W Azlan and Y. F. Low, "Feature extraction of electroencephalogram
(EEG) signal - A review," 2014 IEEE Conf.on Biomedical Engineering
and Sciences (IECBES), Kuala Lumpur, 2014, pp. 801-806
N. Pinheiro et al., "Can PPG be used for HRV analysis?," 2016 38th
Annual International Conference of the IEEE Engineering in Medicine and
Biology Society (EMBC), Orlando, FL, 2016, pp. 2945-2949.
Meredith DJ, Clifton D, Charlton P, Brooks J, Pugh CW, Tarassenko L.
“Photoplethysmographic derivation of respiratory rate: a review of relevant
physiology” J Medical Engineering & Technology. 2012 Jan;36(1):1-7.
W.T. Tsai, X. Bai and Y. Huang, “Software-as-a-service (SaaS):
perspectives and challenges”, Journal Science China Information Sciences,
Vol 57(5), pp 1-15, May 2014.
H. V. P. Singh, S. R. Rizvi and Q. H. Mahmoud, "Two architectures for
real-time sensor data streaming for cloud applications," 2015 IEEE Int.
Symposium on Signal Processing and Information Technology, Abu
Dhabi, 2015, pp. 133-138.
Y. Dong, Z. Hu, K. Uchimura and N. Murayama, "Driver inattention
monitoring system for intelligent vehicles: A review," IEEE Intelligent
Vehicles Symposium, Xi'an, 2009, pp. 875-880
Ali Bulent Usakli, “Improvement of EEG Signal Acquisition: An Electrical
Aspect for State of the Art of Front End,” Computational Intelligence and
Neuroscience, vol. 2010, Article ID 630649, 7 pages, 2010.
Lopez-Gordo, A. M, Sanchez-Morillo, D., Valle, P. F. “Dry EEG
Electrodes, Sensors 2014, 14(7), pp. 12847-12870.
Löfhede, J., Seoane, F., & Thordstein, M. (2012). “Textile Electrodes for
EEG Recording — A Pilot Study”. Sensors, 12(12), 16907–16919.
J. Andreu-Perez, D. R. Leff, H. M. D. Ip and G. Z. Yang, "From Wearable
Sensors to Smart Implants-–Toward Pervasive and Personalized
Healthcare," in IEEE TBME, vol. 62 (12), pp. 2750-2762, Dec. 2015.
W. Heiqao and A.A. Phyo Wai, “Empirical Evaluation of Multi-modal
mental Fatigue Assessment using Lowcost Commercial Sensors”, Int.
Researcher Club Conf on Science, Engineering and Technology, 10-11
Aug 2017, Singapore.
P. Gibbs and H. H. Asada, "Reducing motion artifact in wearable biosensors using MEMS accelerometers for active noise cancellation,"
Proceedings of the 2005, American Control Conference, 2005., 2005, pp.
1581-1586 vol. 3
Reis, Pedro M. R. et al. “Methodological Aspects of EEG and Body
Dynamics Measurements during Motion.” Frontiers in Human
Neuroscience 8 (2014): 156. PMC. Web. 7 Aug. 2017.
Gaspar JG et al,"Evaluating driver drowsiness counter measures," Traffic
Injury Prevention”, May 2017, Vol. 18(sup1), pp. S58-63.

