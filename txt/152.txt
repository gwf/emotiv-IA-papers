TELKOMNIKA Telecommunication, Computing, Electronics and Control
Vol. 18, No. 4, October 2020, pp. 2748~2756
ISSN: 1693-6930, accredited First Grade by Kemenristekdikti, Decree No: 21/E/KPT/2018
DOI: 10.12928/TELKOMNIKA.v18i5.14899

ï²

2748

Brain-computer interface of focus and motor imagery
using wavelet and recurrent neural networks
Esmeralda C. Djamal, Rifqi D. Putra
Department of Informatics, Universitas Jenderal Achmad Yani, Indonesia

Article Info

ABSTRACT

Article history:

Brain-computer interface is a technology that allows operating a device
without involving muscles and sound, but directly from the brain through
the processed electrical signals. The technology works by capturing electrical
or magnetic signals from the brain, which are then processed to obtain
information contained therein. Usually, BCI uses information from
electroencephalogram (EEG) signals based on various variables reviewed.
This study proposed BCI to move external devices such as a drone simulator
based on EEG signal information. From the EEG signal was extracted to get
motor imagery (MI) and focus variable using wavelet. Then, they were
classified by recurrent neural networks (RNN). In overcoming the problem of
vanishing memory from RNN, was used long short-term memory (LSTM).
The results showed that BCI used wavelet, and RNN can drive external devices
of non-training data with an accuracy of 79.6%. The experiment gave
AdaDelta model is better than the Adam model in terms of accuracy and value
losses. Whereas in computational learning time, Adam's model is faster than
AdaDelta's model.

Received Jun 19, 2019
Revised Apr 8, 2020
Accepted May 1, 2020
Keywords:
Brain-computer interface
EEG signal
Focus
Motor imagery
Recurrent neural networks
Wavelet

This is an open access article under the CC BY-SA license.

Corresponding Author:
Esmeralda C. Djamal,
Department of Informatics,
Universitas Jenderal Achmad Yani,
Terusan Jenderal Sudirman Cimahi St., Indonesia.
Email: esmeralda.contessa@lecture.unjani.ac.id

1.

INTRODUCTION
Humans in every day always carry out activities that involve the movement of limbs. The brain
instructs the resulting action through motor nerves. Every human activity requires a focus on carrying out
activities for particular purposes. Nevertheless, the focus can be influenced by several factors such as
stimulation of sound or vision that can affect the activities being carried out. In meanwhile, the command to
move a limb occurs over a state of mind called motor imagery (MI). However, moving the object can be carried
out without involve gestures, muscles, sounds, and other motor functions. These commands are obtained from
the brain through intermediate devices to translate brain commands, known as the brain-computer interface
(BCI). This system can help people with physical disabilities in moving external devices. Currently, BCI has
been widely used to drive games [1, 2], robots [3], to help post-stroke patients [4] and neuromuscular
disabilities [5].
BCI consists of three parts, particularly command input, intermediate device, and command control.
BCI usually uses standard tools such as electroencephalogram (EEG) signals to translate brain commands [6].
The EEG signal is bioelectric in the brain that is captured on the surface of the scalp. EEG signal has a low
amplitude, non-stationary, and complicated patterns. The signal consists of frequency components such as
Journal homepage: http://journal.uad.ac.id/index.php/TELKOMNIKA

ï²

TELKOMNIKA Telecommun Comput El Control

2749

Alpha waves (8-13 Hz), Beta waves (14-30 Hz), Theta waves (4-7 Hz), Delta waves (0.5-3 Hz), and Gamma
waves (> 30 Hz). EEG signal identified mental task variables as appropriate actions on a computer [7].
Therefore, the representation of EEG signals into the frequency domain is very considerate for
getting conditions particular thoughts. Some previous studies in extracting EEG signals using wavelet
transform [8-11] in BCI. Wavelets can filter signals from precise frequency components. So that method is
proper for non-stationary signals such as EEG. However, with a short time segmentation, it is possible to use
other methods such as fast Fourier transform (FFT) for extracting non-stationary signals [12]. FFT has
advantages in terms of computational speed, although wavelet is usually more accurate. Wavelet extraction
can increase accuracy by 3.6% and accelerate detection time by 0.003 seconds. The last study obtained 93.6%
accuracy of training data, and 90% of non-training data [13].
Some variables that affected EEG signals are determinants of classification in previous studies,
such as emotions [14], disorder [15] and focus [16]. Meanwhile, usually, the EEG signal variable translated
in BCI is focus [16], attention level [17], relax [1], emotion [18, 19], hand grasping imagination [20] and hybrid
of motor imagery and speech imagery [21]. Usually, the studies used one characteristic variable in
the classification process. Previous studies used BCI to move characters in arcade games based on focus
feedback [22], controls for computer applications, or action on imagined conditions of the mind [6] and
wheelchair robotic [23].
In pattern recognition, after extraction features, then into the classification system. In BCI application,
the previous research used some methods such as learning vector quantization (LVQ) [1], recurrent neural
networks (RNN) [24], and convolutional neural networks (CNN) [25]. There was using CNN to BCI game
control [26]. Meanwhile, time series cases often use RNN, which facilitates the connection of sequential data
with past time [19]. In previous studies using RNN to recognize emotions from EEG signals with an accuracy
rate of 87% [14]. This research proposed the BCI model to drive the drone simulator from the focus state and
motor imagery. Models developed using wavelet and recurrent neural networks (RNNs). The drone simulator
is designed to be driven by an imagery motor into four, particularly "forward", "right", "left", and "silent".
Besides, the simulator action added focus factor (two classes: focus or not focus), which is described as
the rotation speed. So that eight classes are obtained.
2.

RESEARCH METHOD
This research proposed BCI to drive the drone simulator through EEG signals using wavelet and RNN,
as shown in Figure 1. The system used variable MI and Focus that were processed by simultaneous. So that
are eight classes of both variables. The model used data set with emotiv epoch EEG recording as shown in
Figure 2.
256 data points
each segment
every channel

Input
Training Data 6400 set

EEG Signals
Praprocessing
Segmentation

Recurrent Neural
Networks Training
LSTM Layer
1 (Relu)

Data Training
Wavelet Extraction

Dropout Layer

LSTM Layer
2 (Sigmoid)
Weight

Dense Layer
(Sigmoid)

Output
Recurrent Neural
Networks Identification

Concentration Thingking Forward
Concentration Thingking Idle

EEG Signal

EEG Signal
Praprocessing
Segmentation

Wavelet Extraction

256 data points
each segment
every channel

1st LSTM Layer
(Relu)
Dropout
Layer
2nd LSTM Layer
(Sigmoid)
Dense Layer
(Sigmoid)

Concentration Thingking Turn Right
Concentration Thingking Turn Left
Not Concentration Thingking Forward
Not Concentration Thingking Turn Right
Not Concentration Thingking Turn Left
Not ConcentratIon Thinking Idle

Figure 1. BCI based on focus and MI variable of EEG signal
Brain-computer interface of focus and motor imagery using wavelet andâ€¦ (Esmeralda C. Djamal)

2750

ï²

Instruction
Visua
l
Seconds

ISSN: 1693-6930
Imagine Moving Go Forward

Imagine Moving Turn Right

10

30

Imagine Motionless

Instruction

Instruction

Instruction

0

Imagine Moving Turn Left

70

60

40

Instruction

90

120

100

One Category (30 Seconds)
Segmen 1

Instruction

Seconds

0

10

Segmen 2

12

Segmen 3

14

Segmen 4

16

18

Segmen 5

Segmen 6

20

Segmen 7

22

Segmen 8

24

Segmen 9

26

Segmen 10

28

30

Figure 2. Recording scenario
2.2. Wavelet extraction
The wavelet transform can extract the needed signal components, hence reducing the number of data
without losing important information. Besides, this method is suitable for non-stationary signals. The output
of the wavelet transform into a time-domain allows its application as a pre-model [6]. Wavelet transformation
has two main processes, specifically decomposition, that extract a signal into a specific frequency and
reconstruction that recombine extracted signals into their original form [27]. Wavelet works in a convolution
signal with mother wavelet. Various forms of wavelets used for EEG signal extraction from previous studies,
such as Daubechies Haar and Symmlet. The researchers did not specifically mention the basic shape of
the wavelet that gives good accuracy. But in general, the asymmetric Daubechies [7], combine of Daubechies
and Symlet [28] and Symmlet [29]. Both forms are compatible with EEG signal characteristics. One type of
wavelet transform is wavelet packet decomposition (WPD). Wavelet packets are linear combinations of
wavelet functions [9]. A wavelet function has three indices, j: index scale (integer), k: translation coefficient,
n: oscillation parameter and t is time as (1).
ğ‘›
ğ‘Šğ‘—,ğ‘˜
= 2ğ‘—/2 ğ‘Š ğ‘› (2ğ‘— ğ‘¡ âˆ’ ğ‘˜)

(1)

The wavelet packet functions are a scaling function ïª (t ) and the mother wavelet function ï¹ (t ) .
Wavelet packet functions with higher filter are:
2ğ‘›
2ğ‘›
(2ğ‘¡ âˆ’ ğ‘˜)
ğ‘Š0,0
= âˆš2 âˆ‘ğ‘˜ â„(ğ‘˜)ğ‘Š1,ğ‘˜

(2)

2ğ‘›
2ğ‘›+1
(2ğ‘¡ âˆ’ ğ‘˜)
ğ‘Š0,0
= âˆš2 âˆ‘ğ‘˜ ğ‘”(ğ‘˜)ğ‘Š1,ğ‘˜

(3)

The factor h(k) and g(k) indicate quadrature mirror extraction [30]. The value (h(k) and g(k) related
to the scaling function and the mother wavelet function. The inner product signal f(t) with wavelet packet
functions in a range of t show (4):
ğ‘›
ğ‘›
ğ‘›
(2ğ‘¡ âˆ’ ğ‘˜)
ğ‘Šğ‘—,ğ‘˜
= ğ‘“(ğ‘¡)*ğ‘Šğ‘—,ğ‘˜
= âˆ‘ğ‘¡ ğ‘“(ğ‘¡)ğ‘Šğ‘—,ğ‘˜

(4)

For original signal S, the left-side is obtained in low pass filter h(k) as an approximation coefficient
and the right side as high pass filter g(k) or detail. In (6) showed the scale, translation, and oscillation values.
In (4), the signal can be decomposed into a scale factor j in a particular frequency, either high or low. In this
study, using the standard form Daubechies 4, which consists of four low-pass filter coefficients [29]. Wavelets
decompose signals into specific frequency ranges, such as delta, alpha, beta, theta, and gamma waves, such as
Figure 3.
2.3. Recurrent neural networks
RNN is one method used in Deep Learning for sequential data [31], by looping to store information
from the past [32]. This configuration is shown in Figure 4. RNN is activated with a function such as sigmoid
as Figure 5. RNN has the problems of short memory, so it needs control to forget some parts throughout
the gate. Some of the methods are gated recurrent unit (GRU), backpropagation through time (BPTT), and long
short-term memory (LSTM). This research used the LSTM gate to overcome short-term memory problems or
often called vanishing gradient [14], which has a increase in capability from a single layer [33].

TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 5, October 2020: 2748 - 2756

ï²

TELKOMNIKA Telecommun Comput El Control

2751

Beta
1-64 Hz
Alfa / Mu

A

Teta

Gamma

AA

AAA

AAAA

1-4 Hz

33-64 Hz

1-16 Hz

5-8 Hz

9-12 Hz

17-24 Hz

9-16 Hz

AADD

13-16 Hz

AAADA

25-32 Hz

ADA

25-28 Hz

ADD

29-32 Hz

DA

33-48 Hz

49-64 Hz

DAA

33-40 Hz

41-48 Hz

DD

DAD

ADDD

ADDA

AADA
5-6 Hz

D

AD

17-32 Hz

AAD

1-8 Hz

AAAD

1-32 Hz

7-8 Hz

13-14 Hz

15-16 Hz

AAADD

AADDA

AADDD

29-30 Hz

31-32 Hz

ADDDA

ADDDD

Figure 3. Wavelet multilevel

Figure 4. Recurrent neural network architecture

Figure 5. LSTM cell architecture

The LSTM network consists of modules with repetitive processing, as in Figure 4. Memory in LSTM
is called cells that take input from the previous state (ht-1) and current input (xt). The collection of cells decides
what will be stored in memory and what will be removed from memory. LSTM combines the previous state,
current memory, and input. LSTM has three gates, particularly the forget gate, to determine which eliminating
information from the cell using the sigmoid layer [34]. In (5) with the activation function used is the release
shown in (8).
ğ‘“ğ‘¡ = ğœ(ğ‘Šğ‘“ . [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡ ] + ğ‘ğ‘“ )

(5)

ğ‘…ğ‘’ğ¿ğ‘ˆ(ğ‘¥) = max(0, ğ‘¥)

(6)

The second gate is the input gate (i), which of the sigmoid layer (Ïƒ) will be updated, and tanh of
the layer will be formulated as a vector of the updated value. It can be seen at (7) and (8) where x t is input for
each current step time. At this layer, a vector of updated values will be produced [35].
ğ‘–ğ‘¡ = ğœ(ğ‘Šğ‘“ . [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡ ] + ğ‘ğ‘– )

(7)

ğ¶Ìƒğ‘¡ = tanh(ğ‘Šğ‘ . [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡ ] + ğ‘ğ‘ )

(8)

Then the cells of (7), (8) will be updated using (9).
ğ¶ğ‘¡ = ğ‘“ğ‘¡ âˆ— ğ¶ğ‘¡âˆ’1 + ğ‘–ğ‘¡ âˆ— ğ¶Ìƒğ‘¡

(9)

Brain-computer interface of focus and motor imagery using wavelet andâ€¦ (Esmeralda C. Djamal)

2752

ï²

ISSN: 1693-6930

Finally, the output gate will be calculated based on cell updates, and the sigmoid layer looks like (10) and (11).
ğ‘œğ‘¡ = ğœ(ğ‘Šğ‘œ . [â„ğ‘¡âˆ’1 , ğ‘¥ğ‘¡ ] + ğ‘ğ‘œ )

(10)

â„ğ‘¡ = ğ‘œğ‘¡ âˆ— tanh(ğ¶ğ‘¡ )

(11)

where ğœ is the sigmoid activation function, and tanh as the tanh activation function used for the results of
multiplying the weight of each gate, namely Wf, Wt, Wc, Wo with input values and added bias including bf, bi,
bc, bo. Gate used is gate input it , forget ft, , and output ot . Each passing gate will be searched for hidden state
candidates ğ¶Ìƒğ‘¡ obtained from the gate calculation with the current hidden state ğ¶ğ‘¡ furthermore, the previously
hidden state Ct-1 to produce the latest hidden state, which is used as the output of the hidden layer.
In the identification layer, there is an effort to minimize the difference between the target output and
the output of computational results. Objective functions are often referred to as cost functions or loss functions
so-called "loss". One of the loss functions that can be used is cross-entropy, as in (12). Where loss is a distance,
S is the result of the activation function, and L is the target of each class label. A loss function is used to
measure convergence in the learning process.
Loss (S , L ) = âˆ’ ïƒ¥ Li log (Si )

(12)

i

In machine learning such RNN, it is essential to set input features. This research used MI and focus
variable, so alpha, mu, beta, and gamma (32-40Hz) waves relate that. Based on Figure 3, we got the waves of
four channels, as shown in Table 1. The BCI works every two seconds. While the RNN configuration is as
shown in Table 2. In the first model, the number of neurons of the model is faced with the same amount as
the input vector with a two-dimensional shape that applies the return sequence to the second LSTM model.
The LSTM model has a one-dimensional vector, which results in the dense layer, which has eight neurons,
according to the number of classes produced.
Table 1. RNN features of BCI
No
1
2

Component
Alpha, Beta, Gamma (9-40 Hz)
Mu (9-14Hz)
Total

Number of points
128
24

Description
Four-channel
FC5 and FC6 only

All channel
512
48
560

Table 2. Architecture model recurrent neural networks
Model
LSTM
Dropout
Dense

Neuron
560
0.2
8

Output shape
1,560
1,560
8

3.

RESULTS AND ANALYSIS
The experiment was carried out by comparing the effect of using wavelet as the extraction of alpha,
mu, beta, and gamma waves. Experiments were also carried out on the model in terms of providing the highest
accuracy and considering the computational time of learning. Identification involves eight classes, namely
"Forward", "Right", "Left", and "Silent" each in focus and not. In using BCI, performance depends on
translating variables from the EEG signal being reviewed. Identification performance is very dependent on
the use of extraction methods. Therefore, testing begins with wavelet performance.
3.1. Wavelet extraction
Wavelet extraction uses Daubechies 4 at 9-40Hz, which has been normalized as in Figure 6. Wavelet
extraction is shown in blue compared to the original signal using orange. The EEG signal after going through
wavelet extraction is more stable because it is adjusted to the waves which are in the frequency range. Then
eliminate unused waves and signal noise. The results of each channel are stored sequentially into input vectors.
3.2. Compared between optimization model
This study used three-weight correction models that are adaptive moment estimation (Adam), adaptive
learning estimation (AdaDelta), and stochastic gradient descent (SGD). We experience optimizer models and
optimal learning parameters that higher accuracy and shortest time computing. Adam has a fast convergence
property, but it is only unstable due to very rapid error reduction. Besides the optimizer model, we compared
using wavelet and without wavelet, as in Figure 7 of Accuracy and Figure 8 of losses value. There are three
TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 5, October 2020: 2748 - 2756

ï²

TELKOMNIKA Telecommun Comput El Control

2753

models. Adam and AdaDelta are convergent of 100 epoch learning, except for the SGD model. So that
100 epochs are optimal enough, except with SGD with 500 epoch addition. Each color in Figure 7 and
Figure 8 indicates the testing of training data with wavelet (blue), training data without wavelet (green),
non-training/validation data with wavelet (orange), and validation data without wavelet (red). From the three
models shown in Figure 7 that using wavelet can increase accuracy and reduce computing time. The exact
values of the three models are shown in Table 3. Likewise, the value of Losses from using wavelets for
the three models generally decreases. This result told that wavelet could improve accuracy by reducing
the non-stationary properties of EEG signals.

Figure 6. Wavelet extraction

(b)

(a)

(c)
Figure 7. Accuracy of the optimizer model; (a) Adam, (b) AdaDelta (c) SGD
The accuracy of the three models is relatively the same, mainly between 76-80% for validation data
while 100% for training data. Even so, the highest AdaDelta model is 79.81%. The exciting thing is that
the Adam model quickly corrects weights, which causes accuracy to increase rapidly and losses to decrease
at the beginning of the iteration. However, conditions of small fluctuations continue at the end of the epoch.
While the AdaDelta model tends to be stable at the end of the epoch, it achieves longer than the Adam model.
But it is understood that the weight correction method of the Adam model tends to jump like a ball that rolls
easily. Besides, the SGD model had almost no ripples of instability during the training. But the disadvantages
require longer iterations. Even in the 500th epoch, the accuracy is still increasing.
Brain-computer interface of focus and motor imagery using wavelet andâ€¦ (Esmeralda C. Djamal)

2754

ï²

ISSN: 1693-6930

(b)

(a)

(c)
Figure 8. Losses of the optimizer model: (a) Adam, (b) AdaDelta (c) SGD
Table 3. Comparison of loss and accuracy using Adam, AdaDelta, and SGD model
Model

epochs

Adam
AdaDelta
SGD
SGD

100
100
100
500

Wavelet
Train Data
Validation Data
Accuracy
Loss
Accuracy
Loss
98,5
0,0422
78,84
1,0767
100,0
0,0005
79,81
1,3561
17.7
2.0512
17.31
2.0158
100,0
0.0349
77,82
0.9281

Without Wavelet
Train Data
Validation Data
Accuracy
Loss
Accuracy
Loss
100,0
0,0003
76.92
1,4218
100,0
0,0002
74,04
1,3240
32.05
1.9622
22.12
2.0304
100,0
0.0052
77.88
1.1612

From various experiments, showed that RNN and wavelet could be used to support BCI using MI and
Focus variables with an accuracy of almost 80% non-training data. The future experiment needs to look out
the configuration of the input features and channel usage of the EEG signal. So that can improve accuracy.
This research gave the duration of computational learning using Adam, AdaDelta, and SGD optimization with
several configurations. A comparison of the length of time from the three optimizations can be seen in Table 4
with several configurations in 100 epochs.
Table 4. Computing time of 100 epochs
Model
Adam
AdaDelta
SGD

Methods
With Wavelet
Without Wavelet
With Wavelet
Without Wavelet
With Wavelet
Without Wavelet

Learning time (second)
516
540
606
642
370
380

4.

CONCLUSION
This research showed that brain-computer interface could use motor imagery and focus variable of
EEG signal to move drone simulator. Nevertheless, the emphasis is real-time action with other computing time
applications that can be used. Proposed methods using RNN and wavelet could support BCI with MI and focus
variables with an accuracy of almost 80% non-training data. The research gave that the use of wavelet as
a pre-process can improve accuracy, lead to stability, and reduce the training data computation time. This result
is consistent with the hypothesis referring to previous research that wavelet is suitable for non-stationary signals
TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 5, October 2020: 2748 - 2756

TELKOMNIKA Telecommun Comput El Control

ï²

2755

such as EEG signals. In using RNN, it is necessary to pay attention to the optimization model for the correction
of weights and the number of epochs used. Adam's model reaches asymptotically faster, but still fluctuates
at the end of the epoch, so it requires the right number of iterations. The SGD model is quieter in performance
but requires far more epochs. While the AdaDelta model adopts both models, it provides stable and high
accuracy. The next thing to look out for is the configuration of the input features and channel usage of
the EEG signal.
ACKNOWLEDGEMENTS
The research was funded by "PTUPTâ€“Penelitian Terapan Unggulan Perguruan Tinggi" from
the Ministry of Research Technology and Higher Education, Republik Indonesia.
REFERENCES
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]
[22]

E. C. Djamal, M. Y. Abdullah, and F. Renaldi, â€œBrain Computer Interface Game Controlling Using Fast Fourier
Transform and Learning Vector Quantization,â€ Journal of Telecommunication, Electronic and Computer
Engineering (JTEC), vol. 9, no. 2-5, pp. 71-74, 2017.
M. Van Vliet, A. Robben, N. Chumerin, et al., â€œDesigning a brain-computer interface controlled video-game using
consumer grade EEG hardware,â€ 2012 ISSNIP Biosignals and Biorobotics Conference: Biosignals and Robotics
for Better and Safer Living, BRC 2012, 2012.
S. Ramesh, M. G. Krishna, and M. Nakirekanti, â€œBrain Computer Interface System for Mind Controlled Robot using
Bluetooth,â€ International Journal of Computer Application, vol. 104, no. 15, pp. 20-23, 2014.
B. VÃ¡rkuti, et al., â€œResting State Changes in Functional Connectivity Correlate With Movement Recovery for BCI
and Robot-Assisted Upper-Extremity Training After Stroke,â€ Neurorehabilitation and Neural Repair, vol. 27, no. 1,
pp. 53-62, 2013.
D. J. McFarland and J. R. Wolpaw, â€œEEG-Based Brain-Computer Interfaces,â€ Current Opinion in Biomedical
Engineering, vol. 4, no. Dec, pp. 194-200, 2017.
E. C. Djamal and Suprijanto, â€œRecognition of Electroencephalogram Signal Pattern against Sound Stimulation using
Spectral of Wavelet,â€ Tencon 2011, pp. 767-771, 2011.
M. H. Alomari, A. Abubaker, A. Turani, et al., â€œEEG Mouse: A Machine Learning-Based Brain Computer Interface,â€
(IJACSA) International Journal of Advanced Computer Science and Applications, vol. 5, no. 4, pp. 193-198, 2014.
S. Chaudhary, S. Taran, V. Bajaj, and S. Siuly, â€œA flexible analytic wavelet transform based approach for
motor-imagery tasks classification in BCI applications,â€ Computer Methods and Programs in Biomedicine, vol. 15,
no. 45, 2020.
H. GÃ¶ksu, â€œBCI oriented EEG analysis using log energy entropy of wavelet packets,â€ Biomedical Signal Processing
and Control, vol. 44, pp. 101-109, 2018.
T. Nguyen, A. Khosravi, D. Creighton, and S. Nahavandi, â€œEEG signal classification for BCI applications by wavelets
and interval type-2 fuzzy logic systems,â€ Expert System With Applications, vol. 42, no. 9, pp. 4370-4380, 2015.
A. Khalaf, E. Sejdic, and M. Akcakaya, â€œCommon spatial pattern and wavelet decomposition for motor imagery
EEG- fTCD brain-computer interface,â€ Journal of Neuroscience Methods, vol. 320, no. April, pp. 98-106, 2019.
F. Ansari, D. R. Edla, S. Dodia, and V. Kuppili, â€œBrain-Computer Interface for Wheelchair Control Operations:
An Approach based on Fast Fourier Transform and On-Line Sequential Extreme Learning Machine,â€ Clinical
Epidemiology and Global Health, vol. 7, no. 3, pp. 274-278, 2018.
S. H. Fairclough, â€œBCI and physiological computing for computer games: Differences, similarities & intuitive
control,â€ Proceedings of CHIâ€™08, no. 1, pp. 1-6, 2008.
S. Alhagry, A. A. Fahmy, and R. A. El-Khoribi, â€œEmotion Recognition based on EEG using LSTM Recurrent Neural
Network,â€ International Journal of Advanced Computer Science and Applications, vol. 8, no. 10, pp. 356-358, 2017.
J. R. Wolpaw, N. Birbaumer, D. J. McFarland, et al., â€œBrain Computer Interfaces for communication and control,â€
Frontiers in Neuroscience, vol. 4, no. 113, pp. 767-791, 2002.
T. J. Choi, J. O. Kim, S. M. Jin, and G. Yoon, â€œDetermination of the Concentrated State Using Multiple EEG
Channels,â€ International Journal of Computer, Electrical, Automation, Control and Information Engineering, vol. 8,
no. 8, pp. 1359-1362, 2014.
K. G. Smitha, S. Shenjie, K. P. Thomas, and A. P. Vinod, â€œTwo player EEG-based neurofeedback ball game for
attention enhancement,â€ in International Conference on Systems, Man and Cybernetics, 2014, pp. 3150-3155.
D. Iacoviello, A. Petracca, M. Spezialetti, and G. Placidi, â€œA real-time classification algorithm for EEG-based BCI driven
by self-induced emotions,â€ Computer Methods and Programs in Biomedicine, vol. 122, no. 3, pp. 293-303, 2015.
E. C. Djamal, H. Fadhilah, A. Najmurrokhman, A. Wulandari, and F. Renaldi, â€œEmotion brain-computer interface
using wavelet and recurrent neural networks,â€ International Journal of Advances in Intelligent Informatics, vol. 6,
no. 1, pp. 1-12, 2020.
E. C. Djamal, Suprijanto, and S. J. Setiadi, â€œClassification of EEG-Based Hand Grasping Imagination Using
Autoregressive and Neural Networks,â€ Jurnal Teknologi, vol. 78, no. 6-6, pp. 105-110, 2016.
L. Wang, X. Liu, Z. Liang, Z. Yang, and X. Hu, â€œAnalysis and classification of hybrid BCI based on motor imagery
and speech imagery,â€ Measurement, vol. 147, p. 106842, 2019.
A. Finke, A. Lenhardt, and H. Ritter, â€œThe MindGame: A P300-based brain-computer interface game,â€ Neural
Networks, vol. 22, no. 9, pp. 1329-1333, 2009.

Brain-computer interface of focus and motor imagery using wavelet andâ€¦ (Esmeralda C. Djamal)

2756

ï²

ISSN: 1693-6930

[23] T. I. Voznenko, E. V Chepin, I. Voznenko, et al,, â€œThe Control System Based Based on Extended BCI for a Robotic
Wheelchair,â€ in Procedia Computer Science, 2018, vol. 123, pp. 522-527.
[24] T. Hosman, et al., â€œBCI decoder performance comparison of an LSTM recurrent neural network and a Kalman filter
in retrospective simulation,â€ 2019 9th International IEEE/EMBS Conference on Neural Engineering (NER),
pp. 1066-1071, 2019.
[25] J. Liu, Y. Cheng, and W. Zhang, â€œDeep learning EEG response representation for brain computer interface,â€ Chinese
Control Conference, pp. 3518-3523, 2015.
[26] S. Umar, M. Alsulaiman, and G. Muhammad, â€œDeep Learning for EEG motor imagery classification based on multilayer CNNs feature fusion,â€ Future Generation Computer Systems, vol. 101, pp. 542-554, 2019.
[27] E. A. Mohamed, M. Z. B. Yusoff, N. K. Selman, and A. S. Malik, â€œEnhancing EEG Signals in Brain Computer
Interface Using Wavelet Transform,â€ in International Journal of Information and Electronics Engineering, vol. 4,
no. 3, pp. 234-238, 2014.
[28] C. Rodrigues, P. P. RebouÃ§as, E. Peixoto, A. K. N, V. Hugo, and C. De Albuquerque, â€œClassification of EEG signals
to detect alcoholism using machine learning techniques,â€ Pattern Recognition Letters, vol. 125, pp. 140-149, 2019.
[29] E. C. Djamal and P. Lodaya, â€œEEG Based Emotion Monitoring Using Wavelet and Learning Vector Quantization,â€
2017 4th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI 2017),
pp. 19-21, 2017.
[30] A. N. Akansu and R. A. Haddad, â€œMultiresolution signal decomposition,â€ Academic Press, Second., no. 1, T. R.
Hsing, Ed. Academic Press, pp. 22-25, 2001.
[31] Y. Shen, H. Lu, and J. Jia, â€œClassification of Motor Imagery EEG Signals with Deep Learning Models,â€ Lecture
Notes in Computer Science book series, vol. 10559, pp. 181-190, 2017.
[32] J.-S. Wang, Y.-T. Yang, C.-Y. Hsu, and Y. Hsu, â€œA Recurrent Neural Sleep-Stage Classifier Using Energy Features
of EEG Signals,â€ Neurocomputing, vol. 104, pp. 105-114, 2013.
[33] A. Mazumder, A. Rakshit, and D. N. Tibarewala, â€œA Back-Propagation Through Time Based Recurrent Neural
Network Approach for Classification of Cognitive EEG States,â€ 2015 IEEE International Conference on Engineering
and Technology, no. March, pp. 1-5, 2015.
[34] J. Zhou, M. Meng, Y. Gao, Y. Ma, and Q. Zhang, â€œClassification of Motor Imagery EEG Using Wavelet Envelope
Analysis and LSTM Networks,â€ 2018 Chinese Control And Decision Conference (CCDC), pp. 5600-5605, 2018.
[35] Y. Li, J. Huang, H. Zhou, and N. Zhong, â€œHuman Emotion Recognition with Electroencephalographic
Multidimensional Features by Hybrid Deep Neural Networks,â€ Applied Sciences, vol. 7, no. 10, p. 1060, 2017.

BIOGRAPHIES OF AUTHORS
Esmeralda Contessa Djamal received a Bachelor's degree in Engineering Physics from
Institut Teknologi Bandung in 1994, a Master's degree in Instrument and Control from
Institut Teknologi Bandung in 1998. Since Ph.D. dissertation until now, research on EEG
classification and finished doctoral program from Institut Teknologi Bandung in 2005.
She is a lecturer of Informatics Department, Universitas Jenderal Achmad Yani.

Rifqi Dania Putra received his bachelor's degree in Informatics department from
Universitas Jenderal Achmad Yani in 2019. E-mail: daniaputra24@gmail.com

TELKOMNIKA Telecommun Comput El Control, Vol. 18, No. 5, October 2020: 2748 - 2756

