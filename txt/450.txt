Journal of Autonomous Intelligence (2019) Volume 2 Issue 4.
doi:10.32629/jai.v2i4.60

Original Article
Research on the Key Technologies of Motor Imagery EEG Signal
Based on Deep Learning
Zhuozheng Wang1*, Zhuo Ma1, Xiuwen Du1, Yingjie Dong1, Wei Liu1
Beijing University of Technology

ABSTRACT
Brain-computer interface (BCI) is an emerging area of research that establishes a connection between the brain and
external devices in a completely new way. It provides a new idea about the rehabilitation of brain diseases,
human-computer interaction and augmented reality. One of the main problems of implementing BCI is to recognize and
classify the motor imagery Electroencephalography(EEG) signals effectively. This paper takes the characteristic data of
motor imagery of EEG as the research object to conduct the research of multi-classification method. In this study, we
use the Emotiv helmet with 16 biomedical sensors to obtain EEG signal, adopt the fast independent component analysis
and the fast Fourier transform to realize signal preprocessing and select the common spatial pattern algorithm to extract
the features of the motor imagery EEG signal. In order to improve the accuracy of recognition of EEG signal, a new
deep learning network is designed for multi-channel self-acquired EEG data set which is named as min-VGG-LSTMnet
in this paper. This network combines Long Short-Term Memory Network with convolutional neural network VGG and
achieves the four-classification task of the left-hand, right-hand, left-foot and right-foot lifting movements based on
motor imagery. The results show that the accuracy of the proposed classification method is at least 8.18% higher than
other mainstream deep-learning methods.
Keywords: Electroencephalography; Motor Imagery; Convolutional Neural Network; Long Short-term Memory
Network
ARTICLE INFO
Received: Oct 29, 2019
Accepted: Feb 23, 2020
Available online: Feb 24, 2020
*CORRESPONDING AUTHOR
Dr. Zhuozheng Wang, Beijing
University of Technology, China;
wangzhuozheng@bjut.edu.cn;
CITATION
Zhuozheng Wang, Zhuo Ma, Xiuwen
Du, Yingjie Dong, Wei Liu. Research
on the Key Technologies of Motor
Imagery EEG Signal Based on Deep
Learning. Journal of Autonomous
Intelligence 2019; 2(4): 1-14. doi:
10.32629/jai.v2i4.60
COPYRIGHT
Copyright © 2019 by author(s) and
Frontier Scientific Publishing. This
work is licensed under the Creative
Commons Attribution-NonCommercial
4.0 International License (CC BY-NC
4.0).
https://creativecommons.org/licenses/b
y-nc/4.0

1. Introduction
BCI is an intelligent system that enables users to communicate with external
devices such as computers or neural prostheses without the involvement of
peripheral nerves and muscles[1]. It has been widely studied recently. The research
of BCI has been applied to various aspects of a wide range of fields. In the first
place, BCI can assist people better understand, protect and exploit the brain in the
field of brain cognition; Additionally, it is able to

convert the information sent by

the brain into a command of external device to help stroke patients to communicate
with the outside world in the field of medical rehabilitation; Further, BCI
technology provides the possibility of intelligent weaponry which can remotely
control "machine soldiers" in the military field.
A BCI-based system generally records the signals generated by the user’
s brain and controls a machine by detecting the user ’s intent through
pre-processing, feature extraction, and classification of brain signals [2]. Among the
various methods to capture the brain activities, electroencephalography (EEG) is
commonly used to collect and feed input signals to BCI systems owing to its
non-invasiveness and low cost[3]. EEG is an electrical phenomenon exhibited by the
electrophysiological activity of the brain’s nerve cells on the surface of the cerebral
cortex or scal p. It is most widel y and commonly us ed in motor

1

Zhuozheng Wang, Zhuo Ma, Xiuwen Du, et al.
imagery-based BCI applications[4].

points of the electrode channel over a period of time,

The classification of motor imagery EEG signal has

which not directly applicable to the traditional deep

obtained many great breakthroughs with the effort of
researchers at home and abroad. Professor

learning

method.

In

this

paper,

we

design

a

Pfurtscheller[5]

min-VGG-LSTMnet hybrid deep learning network to

designed a BCI system based on Graz I and Graz II

solve the problem of low recognition accuracy of

theory, which enables motor imagery EEG devices to

multi-class task. It combines Long Short-Term Memory

perform different actions based on classification signals,

Network with VGGnet, a classic model of Convolutional

such as cursor control or character selection operation.

Neural Network. The min-VGG-LSTMnet achieved

Based on the results of Graz's research, Bernhard

high-precision of four-class task based on motor imagery.

Obermaier[6]

studied 5 different motor imagery tasks of

Compared the performance of the proposed method is

the left hand, right hand, left foot, right foot and brain

with the mainstream deep learning method, the result

computing on the lifting movement, and divided the

demonstrates that the accuracy of the proposed network

research into different brain task combinations of 2 ,3, 4,

is improved at least 8.18%, and the loss value is

and 5 classes. The experimental result shows that the

reduced by at least 0.0288. The analysis conclusively

fusion of three classes of different motor imagery tasks

proves that the proposed min-VGG-LSTMnet is superior

obtained the largest information transmission rate. Wan

to other approaches.

Baikun[7] of Tianjin University adopted two-dimensional

The rest of this paper is arranged as follows: Section

time-frequency analysis combined with Fisher analysis

2 introduces related works including signal acquisition,

to extract features of four different limb parts, and

signal preprocessing and feature extraction. Section 3

support vector machine was used to recognize. The

introduces the design method of deep neural network.

accuracy rate of that is 85.7%. Xu Xin[8] of Nanjing

Section 4 the experimental results are discussed.

University of Posts and Telecommunications used
common spatial patterns combined with support vector

2. Materials and Methods

machine to extract and classify the EEG signals in four

2.1 Signal acquisition

kinds of motor imagery and the highest accuracy rate is

According to the endogenous and exogenous stimuli

86.3%.
EEG

signal

is

transient,

of event-related potential, EEG is divided into two types,

non-stationary, low

spontaneous EEG and induced EEG. The rhythmic

signal-to-noise ratio and easy to interfere. Therefore, the

changes of EEG signal generally belong to endogenous

difficulty of BCI based on motor imagery is how to

stimuli, and the frequency is in the range of 0~30Hz,

extract the most important information and select the

which is divided into five basic bands,

optimal model to achieve high-precision recognition and

θ band (4~8 Hz),

classification. The signal-to-noise of EEG signal is

and

relatively low and susceptible to interference. At present,

waves are

increase of the working memory load in the motor

a method of simple filtering, but some important features

imagery is often accompanied with the increase of the

will lose. Therefore, we need to find a method of data

power of θ wave, while the

preprocessing that can both reduce noise and retain

considered

important information. The existing feature extraction

in

the

Synchronization (ERS)

methods have low versatility. For the recognition of two

BCI
[9]

wave is often not
study.

Event-Related

refers to the increase of cortical

activity in specific frequency bands (such as

types of tasks, the average accuracy of the algorithm can

and

bands), and Event-Related Desynchronization (ERD)[10]

reach 85%, but the recognition of multi-class tasks is far
Deep learning

band (14~30 Hz)
and

directly related to the motor imagery BCI study. The

the noise reduction of EEG signal is mainly achieved by

from satisfactory.

band (8~14 Hz),

band (>30 Hz). Especially,

band (<4 Hz),

refers to the reduction of cortical activity in specific

is a method based on

frequency bands (such as

learning the characteristics of sample data. It can be

and

bands). They mainly

reflect the changes of EEG amplitude caused by motor

understood as "feature learning" or "representation

imagery.

learning". However, EEG data records the sampling

The quantization method for different band power is

2

Research on the key technologies of motor imagery EEG signal based on deep learning
given by the following formula (1):
ul
uh

=

−u
u

× 100%,

randomly displays arrows indicating the left and right
directions, and the subject should complete the

(1)

imaginary motion of left hand, right hand, left foot and
right foot according to the direction of the arrow. When

where A is the energy value of the brain band signal, R is

the arrow disappears, the subject ends the experiment.

the average power of the band, ERD/ERS is the power

The single experiment lasts for about 9 seconds. There

reduction or increase of the band signal. The negative

will be 128 sample points per second. In order to avoid

percentage value represents ERD, and the positive

errors caused by the subjects not entering the test state

percentage value represents ERS.

during the experiment and ensure the accuracy of

In order to analyze the motor imagery EEG signals

analysis and processing of EEG signal, we cut off the

of different movements and obtain the intrinsic

data for the first 3 seconds and the last 1second, and

relationship between EEG signal and motor imagery

retain the samples for the middle 5 seconds. The

tasks, two different data sets are used in this paper. The

experiment of each subjects lasts 4 minutes and about

first is the official standard competition data set (BCI

3.72 million sample points are obtained.

Competition III data set[11]), which use 118 electrodes at

14-channel EEG collector Emotiv of Emotiv

the location of extended international 10-20 system to

company is used as the signal acquisition instrument in

record EEG signals data of five subjects ("aa", "al", "av",

this paper. The most important part of the Emotiv helmet

"aw" and "ay") and divided them into training set and

is 16 biomedical sensors. On the one hand, it touches the

test set. The subjects perform one of three imaginary
movements, (L)raise left hand, (R)raise right hand,

scalp to sense the nerve signal. On the other hand, it

(F)

transmits the signal to the computer. The order of the

raise right foot. Before t=2s, subjects gaze the computer

channels of electrode from left to right is AF3, F7, F3,

monitor, keeping arms and feet relaxed and avoiding

FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4, and

movement of eyes. When t=2s, the “+” cursor appears on

there are two reference electrodes CMS and DRL. The

the screen, prompting the subjects to start preparing.

material of sensor is felt pad soaked in saltwater.

After 1s, the “+” cursor on the screen will randomly

Sampling method is sequential. The position of electrode

change to the arrow of left, right and up, and the subjects

is shown in Figure 1:

will perform the same imaginary action of left hand,
right hand or right foot. When t=7s, the arrow disappears
and the single experiment ends. Each subject contains
140 sample sets per imaginary task and each sample set
includes 1520 sample points. The second data set is the
EEG data of 20 real students collected in the laboratory.
We let 20 subjects carry out the motor imagery tasks, and
collect the data

of EEG signal. All subjects gave their

informed consent for inclusion before they participated
in the study. Each subject was divided into four

Figure 1. Electrode position map.

experimental groups as required, including four types of

2.2 Motor imagery EEG signal preprocessing

motor imagery tasks, raise the left hand, raise the right

Independent Component Analysis (ICA)[12] as a

hand, raise the left foot, and raise the right foot. First,

spatial

from the start of the time to 2nd second before, the

filtering

technique,

its

coefficients

are

determined by the statistical correlation of existing data.

subject stares at the computer monitor and keeps the

ICA is a statistical analysis method of blind source

arms and feet relaxed, avoiding eyes movement. At 2nd

separation. “ Blind ” means unclear source signal or

second, a "+" cursor appears in the center of the display

hybrid system. ICA can efficiently extract independent

screen lasting for about 1 second, the subject is prompted

original signals from a mixture of multiple sensors. The

to concentrate on preparation. At 3rd second, the screen

FastICA[13] algorithm based on fixed-point iteration is

3

Zhuozheng Wang, Zhuo Ma, Xiuwen Du, et al.
used to find the non-Gaussian

maximum. FastICA

Assuming A(r, θ, Φ) is a point in the 3-D space,

is implemented by the EEGlab, which is an EEG analysis

which is projected by the AEP and falls in the point M on

toolbox

the plane of the 2-D image. The equidistant projection

.

[14]

It

can

remove

the

trials

containing

artifacts based on statistical features (i.e. variance,

model is:

kurtosis and maximum). Then the fast Fourier transform

0
0
0 0 1

method is introduced to make the frequency accurate to 1
Hz and intercepting the time window of the EEG signal
from 14 channels.

=

(2)

,

In this paper, the shape of the Emotiv collector

can be approximated by a sphere. So, we can use the
same method to calculate the projection of the position of
electrode on 2-D surface. As shown in Figure 4:

Figure 2. Each channel's original data brainwave shape.

(a)

Figure 3. Get rid of the fake brainwave shape.
When

analyzing

EEG

signals,

the

(b)

potential

activities of electrodes at different spatial positions have
a correlation law, which reflects the synchronous and
asynchronous electrical activity of cerebral cortex
potential. Therefore, the spatial characteristics are very
useful to analyze features of EEG signals. EEG are
multiple time series of different spatial locations
measured on the scalp. The spatial characteristics of EEG
signals can be obtained by predicting the mapping
position of the electrodes from three-dimensional space
to two-dimensional surface. The mapping method uses
Equidistant Projection proposed by Azimuthal, namely
. The distance from the center of projection to any

(c)
Figure 4. AEP 3-D spatial position is converted to

other point can be preserved by azimuthal equidistant

2-D position. (a)The position of electrodes in 3-d space.

projection.

(b) AEP orthogonal projection. (c) Electrode coordinate.

AEP

[15]

4

Research on the key technologies of motor imagery EEG signal based on deep learning
We use the Clough-Tocher scheme[16] to estimate

channels is represented as a matrix R of size N × T,

the value of electrodes. Repeating this process for θ band,

where T represents the number of samples in each
= 1,Q,W
channel in a single experiment,

α band and β band respectively will produce three
corresponding brain topographic maps. And then

corresponds to three tasks EEG signals respectively. The
normalized covariance matrix u of the three types of

merging the three brain topographic maps together to
form a color image similar to RGB. (three Parameters:

data is calculated as:

height, width, and color depth). Where the color

u =

indicates different band, the width and height of the
image indicate the spatial distribution of activity on the

where

cerebral cortex corresponding to the electrode of Emotiv,

(3)

, = 1,Q,W,

is the trace operation. The mixed space

covariance matrix is as follow:

which retains the spatial characteristics of EEG signals.

u = u1

The temporal evolution of brain activity is calculated by
image sequences derived from continuous-time windows,

where u

which retains the temporal characteristics of EEG signals.

(4)

uW ,

uQ

= 1,Q,W is the average covariance matrix of

multiple experiments for three tasks. The eigenvalue

The color image is shown in Figure 5:

decomposition of R is :

u= t

(5)

,

Where U and V represent the eigenvector matrix of

R and the eigenvalue diagonal matrix respectively. The
eigenvalue diagonal array is arranged in descending
order. Whitening matrix P is:
1

= t− Q

Figure 5. Combination of brain activity maps into
two-dimensional images of θ, α, and β ranges.

When using OVR-CSP calculates the projection

2.2 Common spatial pattern feature extraction
method

matrices, one of them is classified into one category, and
the

other two categories
represented by u'1 :

The most commonly used feature extraction method
of detecting ERD/ERS phenomenon is the Common

u'1 = uQ

Spatial Pattern (CSP) algorithm, which is a spatial
filtering method. The basic principle is to identify
features by constructing a spatial filter to make the

with

higher

resolution.

In

another

category,

uW ,

(7)

new classification are whitened to:

variance in the other type of features is the smallest and
eigenvectors

are

The two types of signal covariance matrices of the

variance in one type of features is the largest, while the
get

(6)

,

h1 =

the

multi-classification problem, the One-Versus-Rest CSP

1 u1 1

hQ =

'
1 u1 1

(8)

,

In the above transformation, h1 is a class of
covariance, and hQ is classified into another class,
which can be written as h1 = 1 t1 1 ,hQ = 1 t'1 1 ,

(OVR-CSP)[17] method implements multi-classification
feature extraction through the binarization of multi-class
problems and count the majority vote of the binary

where

classifier to determine the class label for each test

1 is

a common eigenvector Matrix. t1

t'1 =

(unit matrix), when one of the types of eigenvalues is the

sample.

largest, the other type of eigenvalue is the smallest.

In data set 1, OVR-CSP divides three types of motor
imagery tasks into binary tasks, obtaining three

1

projection matrices and three sets of corresponding
spatial features. A given single EEG test set with N

5

= l1

Q

= lQ

,

(9)

Zhuozheng Wang, Zhuo Ma, Xiuwen Du, et al.
Table 1. Left hand, right hand and right foot motion

According to the size of the eigenvalues, the first m
columns of the eigenvectors are formed into a new
matrix l1 , and the remaining columns have constituted
a matrix lQ . l1 , lQ and the whitening matrix together
form a spatial filter namely F= 1 , Q . A new signal
i

=

imaging tasks for ERD/ERS
Motion
Imaging

transformation. We get the eigenvalue of the signal from
the following algorithm:

= th

where

var i Q
W
Q
1 var i

,

C4

Cz

Left hand

ERS

ERD

/

Right hand

ERD

ERS

/

Right foot

ERS

ERS

ERD

Tasks

is obtained by spatial filter projection

×

C3

(10)

is the characteristic coefficient.

The data set is preprocessed to obtain the EEG

Table 2. Classification performance of dataset 1

signals after filtering out the noise. The EVR/ERS

Serial

feature of the α-band and β-band of EEG signals is

Number

extracted by the OVR-CSP method. Combined with
multifarious

classifiers

to

complete

the

three-classification tasks, then we take the category of
the maximum probability by voting. Counting the
ERD/ERS phenomenon of the left hand, right hand and
right foot motor imagery tasks in the data set 1. As
shown

Table

in

1.

The

EEG

monitoring

process begins by locating the sites for electrode
placement based on the international 10–20

system[18].

The motor imagery task is mainly related to the channels
C3, Cz and C4, so only consider these three channels.
For classification, classical machine learning methods
such as support vector machines (SVMs), linear

from

different

0.7346

0.8753

0.8117

al

0.8232

0.6875

0.8671

0.7926

av

0.8074

0.6723

0.8426

0.7741

aw

0.7562

0.6214

0.7923

0.7233

ay

0.7935

0.6541

0.8537

0.7671

Mean

0.8011

0.674

0.8462

Mean

The application of deep learning for human activity
recognition

cross-validation, the average accuracy of different
obtained

0.8253

learning, which is suitable for increasing data volume.

specific

parameters obtained by the experiment with 5-fold
categories

aa

deep learning is the realization of end-to-end data

small data volume, so we choose the data set 1 to test.
performance

Mean

traditional machine learning, the biggest improvement of

classifier is suitable for data sets with small subjects and
classification

LDA

Compared to feature extraction and classification of

algorithms have been commonly used[19]. The traditional

average

Bayes

Deep learning has evolved from machine learning.

discriminant analysis (LDA), and naive Bayes (NB)

The

Naive

SVM

has

been

effective

in

extracting

discriminative features from raw input sequences

classification

acquired

algorithms and experiments of each subject are shown in

from

body-worn

sensors.

Researchers

have been adopting deep-learning methods for activity

Table 2.

recognition[20]. Deep learning is a learning-based method
using a neural network structure with multi hidden
layers[21]. The network structure of deep learning
designed in this paper are built under the deep learning
framework of Keras. There are many deep-learning
algorithms. Mainstream deep-learning algorithm includes
CNN, RNN, and LSTM.

6

Research on the key technologies of motor imagery EEG signal based on deep learning
Convolutional Neural Networks (CNN)[22] is the

In principle, RNN can handle such long-term

most popular network algorithm in deep learning. A

dependency problems. After the network receives the
input
at time t, the value of the hidden layer is h ,

CNN is a neural network that uses convolution operation
instead of traditional matrix multiplication in at least one

the output value is

layer of the network[23]. This paper adopted the method

time (t+1) is

, the final result of the network at

1 , which is the result of the current

of classifying EEG signal into "video frames" to convert

input and all history. This realizes the process of

motor imagery EEG signal into image form and applying

continuous transmission of the RNN of time sequence.

it to deep learning networks. Firstly, from the network

However, In an RNN, increasing the data length may

layer structure, CNN is divided into convolutional layer,

induce a gradient error, or a gradient explosive may

pooling layer and fully connected layer, which form a

occur when error parameters are back-propagated. The

complete network structure with feature extraction and

gradient explosion phenomenon does not meet the

classification function through stacking. The two most

training objectives, and a typical RNN does not provide

important features of CNN are local association and

satisfactory results[25]. The long short-term memory

parameter sharing. The convolution operation of the

network proposed by Hochreiter and Schmidhuber[26] can

convolutional layer can be seen as a mathematical

effectively solve this problem.

operation

For

Long short-term memory (LSTM) is a variant

one-dimensional convolution, it is often used in signal

of

two

structure of RNN, which replaces the summation unit of

processing to calculate the delay accumulation of signal.

the

For

is

memory block, which is better at storing and accessing

represented by the pixels of a two-dimensional matrix.
∈ u ∗ , convolution
That means given an image

long dependencies in data. Each memory block contains

two-dimensional

kernel parameters

mutation

convolution,

∗h

functions.

the

image

hidden

layer

with

a

recursive

substructure

an input gate, a forget gate and an output gate in the

and y =WX+b. Where X is

original architecture. In an LSTM unit, the cell state

the input of the CNN, W is the weight of the convolution

controls the discarding and adding of information

kernel. When the convolution kernel is convolved, the

through the gate to achieve forgetting and memorizing

related input region is called the receptive field, and the

functions[27]. It can automatically forget or retain the

related output result is called the feature map, the

memory of the unit. Using the current input

∈u

number of feature map is also called depth.
Recurrent Neural Network (RNN)

[24]

−1

LSTM and the
is a neural

get four states:

network with short-term memory ability, which is often

z=

used for sequence modeling. In addition to input
,
RNN also has a previous node h −1 of input hidden

layer. The output of each layer of RNN is the result of

h

w

z =σ w

combining the two inputs with matrix W and activation
function. The input of RNN is the hidden state of the

z =σ w

sequence data x and the last round of the calculated
output. Assuming the weight matrix of the hidden layer
of the RNN is W, and the hidden state is S. Expanding

zh = σ wh

the RNN on the time axis, the first layer of the RNN is
the input layer. And the input features are passed to the

Where

first hidden layer by the neurons of the first layer. The
output layer predicts the current time h with the weight

−1

−1

−1

，

passed from the previous state to

(11)

,

−1

of

(12)

,
,

(13)

,

(14)

，

h

are multiplied by the splicing

vector and then converted to a value between 0 and 1 by

matrix V. The probability value can be predicted by

a sigmoid activation function as a gating state. And z is

softmax. The parameters W required for each hidden

the value converting the result to a value between -1 and

layer calculation are shared parameters.

1 through a tanh activation function. There are three

7

main phases within LSTM:

Zhuozheng Wang, Zhuo Ma, Xiuwen Du, et al.
(1) The stage of forgetting. The calculated

(f

where t

follow:

(i represents information). Adding the

= ∇ θ −1 ,

results obtained in the above two steps, we can get the
.

the ordinary RNN, the output
change of

=

0

⊙

−1

calculated as follows:

is often obtained by the

=

⋅

(15)

⊙ ,

=

(16)

,

,

,

to

.

, while
and z
0
, z controls the

paper:
(1) Learning rate. Learning rate is a very important

minimum. If it is set too large, the loss function value
loss will "explode", and if it is set too small, the training

Q,

(23)

/ 1−

=

−1

Q

1

,

(24)

,

(25)

,

∗

−

are as follows:

(26)

,

/

,

/

,

t

,

,

(27)
(28)

determined by fitting the curve. Batch size is often set to

The formula for the gradient descent method is:

32, 64, 128, etc.

(18)

(4) Activation function and weight. The commonly
used activation function is RELU. LRELU and ELU are

The above formula can update the weight ω. Where

developed on the basis of the RELU function. They are

α is the learning rate, and the initial learning rate α=

expressed as follows:

0.001 in this experiment.

Re

(2) Optimizer selection. The stochastic gradient
descent (SGD) algorithm is as follows:

∇L W ,

(22)

(3) Batch size and epoch. The value of the epoch is

convergence algorithm is widely used in deep learning.

= t

=

=

fit takes too long. At present, a gradient descent

1

/ 1−

= tt

converge to a local minimum and when it converges to a

t

Q

,

get the Adabound optimizer:

which determines whether the objective function can

thhh ω ,

1

Applying the following operations on Adam we can

hyper parameter during the network training process,

=ω−α

1−

−1

Finally:

We set some hyperparameters as follows in this

∗

Q

and the corrected

=

The updated values are controlled by z， ， ， .
In LSTM, there are two iterative values,
and
.z
degree of expression of

1−

−1

rate, usually close to 1. Deviation correction for

0

control the degree of update of

1

where M0 is initialized to 0, β1 is the exponential decay

(17)

controls the degree of forgetting of

(21)

The exponential moving average of the gradient is

. Similar to

. The state changes are as follows:

= z ⊙ tanh
=

0

is the network weight in

the gradient. Calculating the gradient of the t-time as

previously calculated z. The selected gating signal is

(3) Output stage. It is controlled by

1

Adam is an optimizer based exponential decay of

. The current input is represented by the

next state

is the updated value of the network weight

1

the t+1th iteration.

(2) Select the memory phase. Select the memory

controlled by

(20)

1,

−t

in the t+1th iteration, and

and forget.

from input

=

1

represents the forget) is the forget gate to control the
previous state c −1 , and decide which ones need to stay

(19)

u

8

=
=

0

>0
,
≤0

(29)
>0
,
≤0

(30)

Research on the key technologies of motor imagery EEG signal based on deep learning

where

exp

x>0
,
x≤0

−1

is the characteristic of the input and

analysis. This paper adopted the EEGnet shallow

(31)

network, and used one-dimensional convolution to
classify time-domain EEG signals. We only extract the

is the

single-dimensional features of EEG signals. The data

coefficient of the activation.

size is (N, T), where N is the number of channels and T is

(5) Batch Normalization(BN). Satisfy the following

the number of samples. The first layer of convolutional

equation:

layer we use a size with N×1 one-dimensional
−

=

0.01

⋅h

t

,

h

convolution kernel to extract the spatial channel features.

(32)

Convolution kernels are set 40. The second layer of
convolutional layer we use 1×16, the size of each feature

(6) Dropout. In this paper, the dropout values are set

map obtained is 1×8. Convolution kernels are set 80. The

to 0.25, 0.5, and 0.75 respectively. The experimental

third layer is a fully connected layer, and the neuron

results show that the network training is better at 0.5.

format is set to 256. The fourth layer is the output layer,

(7) Positive and negative sample ratio. In this paper,

which contains 4 neurons, which represents the

the positive and negative samples of the data set are 1:1,

four-class task.

and the batch method is used for training.

CNN-2net network model framework is shown in

(8) Gird Search. The number of iterations epoch

Table 3:

and batch size can be determined by Gird Search. The

Table 3. CNN-2net network model framework

final epoch set in this paper is 500 to 1000, and the batch

CNN-2net

size is 128.

4 weight layers

In this paper, the classification accuracy (ACC)[28]
combined with the cross-entropy loss function (Loss) are

Conv5-32

used to evaluate the experimental criteria. ACC is

Maxpool

calculated as:

Conv3-64

,

tt =

Maxpool

(33)

FC-1024

where TP is true positive, FP is false positive, TN is true

FC-num_classes

negative, FN is false negative. The higher the accuracy,

Softmax

the better the classifier. The cross-entropy loss function L

There

is calculated as:

=

,

where

=1

are

two

layers

in

the

structure

of

convolutional layer, and the size of the convolution

log

1−

is the desired output,

log 1 −

kernel can be set casually. The size of the convolution
kernel in CNN-2net is 5×5, and the number of

(34)

convolutions generally increases with the number of
network layers. The activation function used in
convolutional neural networks is RELU[30]. The adopted

is the actual output.

optimizer Adam optimizer which most commonly used.

The greater the loss, the larger the gradient.

The number of neurons and parameters of each layer are

In order to find the optimal classification method,

adjusted as follows:

this paper designs four network structures, namely

The first layer: the input layer inputs a picture

EEGnet, CNN-2net, min-VGGnet and min-VGG-LSTM

corresponding to an array of size 28×28×3.

-net.

The second layer: the convolution layer, which uses

Vernon J. Lawhern[29] of Columbia University of

32 convolution kernels of size 5 × 5 × 3 to convolve the

America proposed two EEGnet structures, which directly

maps of the input layer, so it contains 32 × 5 × 5 × 3 =

apply convolutional neural networks to EEG signals

2400 weight parameters. After convolution, the length of

9

Zhuozheng Wang, Zhuo Ma, Xiuwen Du, et al.
the picture is (28-5+1)/1 = 24, including 32 × 24 × 24 ×

FC-512

3 = 55296 neurons.

FC-num_classes

The third layer: the pooling layer, samplings each

Softmax

2×2 area of the previous layer, and selects the maximum

Three sets of comparative experiments were

value of each area. This layer has no parameters. After

performed, the difference is the number of layers of the

sampling, the length and width of each map become half

convolution kernel. All convolution kernel sizes are 3×3.

of the original.

Experiment A was a 6-layer structure. The first layer is a

The fourth layer: the convolution layer, which uses

stacking of two convolutional layers (Conv3-32), the

32 × 64 convolution kernels of size 5 × 5 × 3 to convolve

second layer is further combined with stacking of two

each map of the previous layer, so it contains 32 × 64 × 5

convolution layers (Conv3-64), the third layer is

× 5 × 3 = 153600 weight parameters. After convolution,

maxpool layer. Experiment B is added a convolution

the length of the picture is (12-5+1)/1 = 8, including

layer on the basis of A (Conv3-128). Experiment C

64×8×8×3=12288 neurons.

differed from B in that the first layer of convolutional

The fifth layer: the pooling layer, 8 × 8 × 3 map

layer is stacked with four-layer convolution kernels. The

downsampling to 4 × 4 × 3 map. This layer has no

experimental results show that the optimal network

parameters.

structure diagram is the structure of experimental A. The

The sixth layer: the fully connected layer, which
connects all the neurons of the output of the pooling
layer.

This

layer

has

1024

neurons,

parameters involved in the network structure and training
process are described below.

and

64×4×4×3×1024=3145728 weight parameter.

The first layer is the convolution layer, which uses
32 two-layer convolution kernel stack structure with the

The seventh layer: the fully connection layer, which

size of [3 × 3]. The step size padding is set to the mode

function is similar to the previous fully connection layer.

of "same", and the step size determines the distance

This layer has num_classes neurons, which are related to

moved in the direction of the gradient drop during each

the task category and 1024×num_classes corresponding

iteration. Normally step size is set to 1. Processing input

parameters.

data uses batch standardization, and the training set

The eighth layer: the Softmax layer, which is to
achieve classification and normalization operations.
The min-VGGnet network is obtained by adjusting

sample is convoluted. RELU is adopted as the activation
function, and the feature map has the same size at the
input and output.

the number of the convolution layers and the number of

The second layer is the pooling layer. This layer

convolution kernels in the VGG network structure. Its

uses the maximum pooling function with a size of [2×2]

structure is shown in Table 4:

namely maxpool to pool the output of the convolution.

Table 4. Evaluation of the optimal convolution
network min-VGGnet

The third layer is the convolution layer. This layer
uses 64 two-layer convolution kernel stack structure with

A

B

C

6 weight-layers

7 weight-layers

9 weight-layers
Conv3-32

a size of [3×3] to further extract deeper features.
The fourth layer is also the pooling layer, that still
uses the largest pooling function, namely maxpool

Conv3-32

Conv3-32

Conv3-32

The fifth layer is the fully connected layer, which is

Conv3-32

Conv3-32

Conv3-32

a tiled structure. The feature becomes a vector with a size

Conv3-32

of 1"×" 512 through a fully connected layer. The fully
connected layer is a highly purified feature.

maxpool
Conv3-64

Conv3-64

Conv3-64

The sixth layer is also a fully connected layer,

Conv3-64

Conv3-64

Conv3-64

whose purpose is to complete the final classification and
determine the final classification according to the

maxpool
Conv3-128
maxpool

Conv3-128

number of categories num_classes required by the
sample label.

10

Research on the key technologies of motor imagery EEG signal based on deep learning
The seventh layer is the Softmax layer, namely the

= h tanh

activation function is "Softmax". The final classification

， ，h ，

is completed.
Long short-term memory network (LSTM) is an
improved RNN, which can process long-time sequence
information better. Therefore, LSTM is introduced for
hybrid network design. The design idea is to use the
min-VGGnet structure with better performance in the

,

(41)

and

represent input gate, forget gate,

output gate and long unit activation vectors, and short
unit activation vectors, respectively. The improved
feature extraction and classification method of the
min-VGGnet and LSTM hybrid structures named
min-VGG-LSTMnet in this paper. As shown in Figure 6:

previous section. In this paper, the total number of
parameters in a network with a lower number of neurons
in the fully connected layer are retained. Dropout is set to
0.5, we can get the last two fully connected layers. In this
hybrid model, the output of per-layer convolutional layer
of min-VGGnet performs maximum pooling. Applying
one-dimensional

convolution

and

one-dimensional

pooling to the output of the convolutional layer, and
sending the output after maximum pooling to the LSTM
layer. LSTM can capture features of different time
patterns. The LSTM takes the input x=( 1 , , ) through

a form of sequence and calculates the vector sequence of
the hidden layer h= h1 , ,hT and the output vector y =
1 , ,y . The iteration of t=1 to T is:

=

,

=

(35)

,

−1

(36)

vector

and

the

hidden

layer

function

respectively. The hidden layer function of LSTM is
calculated by the following equations:

=

−1

=

,

h =
h ,

, (37)

−1

−1

,

=

network min-VGG-LSTMnet
The hybrid structure still uses the structure of
min-VGGnet, but the convolutional layer in the

where W, b, and H represent the weight matrix, the
deviation

Figure 6. CNN combined with LSTM hybrid

min-VGGnet is included in the three-layer stack structure.
The first layer is a two-layer stack structure of 32
convolution kernel sizes [3×3], denoted as C1. The
second layer is a two-layer stack structure of 64
convolution kernel sizes [3×3], denoted as C2. The third
layer is a single-layer structure of 128 convolution kernel
sizes [3×3], denoted as C3. LSTM needs to capture

−1

(38)

different time-mode features across multiple frames,
corresponding to three structures of time unit. The inputs
at t-1, t, and t+1 are from the features of shallow, deeper,

−1
h

and

tanh
h

−1
−1

h

−1

(39)

deep

layers

of

the

min-VGGnet

structure,

respectively. Each layer in min-VGGnet passes through
the largest pooling layer and is transformed into a vector
through the reshape layer as the structure of input of the

(40)

LSTM network, which realizes serial fusion. Finally,
LSTM layer and the layer formed by 128 cells get
the best results. In the model, a 1-D Conv layer should be
added after the output of min-VGGnet. Then

11

Zhuozheng Wang, Zhuo Ma, Xiuwen Du, et al.
parallelizing the output of the 1-D Conv layer with the

classification.

3. Results

output of LSTM. Changing the dimension of the input
data through the reshape layer, without the dimension of

To make the comparison of classification results

the sample number (batch size). After fusion, putting

more intuitive, this paper summarized the values of best

them together into the fully connected layer. The fully

cross-entropy loss and classification accuracy of all the

connection layer still adopts a two-layer stack structure.

above

The first layer is a tile structure, which becomes a 1×512

performed on the same computer, which operating

vector through a fully connected layer. According to the

system is Win10, 64 bit, CPU is 1.80GHz, RAM is 8GB.

number of num_classes required by the sample label,

The comparison of the results of the network model of

determining the final number of classifications. Finally

the four- classification task of motor imagery is shown in

entering the Softmax layer and completing the final

Table 5:

classification

models. All

experiments

are

Table 5. Performance comparison of different classification models under four classification tasks
Network model

Training Loss

Val Loss

Training ACC

Val ACC

Time(h)

EEGnet

0.5979

0.5965

0.6317

0.6776

2.32

CNN-2net

0.4018

0.5307

0.8291

0.7754

3.54

min-VGGnet

0.4177

0.5262

0.9908

0.8312

3.91

min-VGG-LSTMnet

0.3458

0.4974

1.0

0.9130

4.16

As

can

be

seen

from

Table

5,

the

hybrid network model takes more time, but the

min-VGG-LSTMnet has better performance in the

difference is not big in general.

four-classification task, and the classification accuracy of

In order to verify the effectiveness of the proposed

the training set and the verification set is higher. The

method, this paper compared the previous method with

results show that the accuracy of the proposed method is

the method proposed in this paper. The results are shown

at least 8.18% higher than that of the traditional deep

in Table 6:

learning method. When the epoch takes 1000 times, the
Table 6. Comparison of different classification models under four classification tasks
Maximum

Classification Method

Data Set

References Fisher+SVM

BCI Competition III

References CSP+SVM

Accuracy

Self-collected four-class
task data set

proposed method

collected four-class task

min-VGG-LSTMnet

data set

It can be seen from the above table that the
proposed

method

min-VGG-LSTMnet

has

Average Accuracy

85.7%

80.95%

86.3%

80.66%

88.56%

81.52%

is at least 2.26% higher than the method in the literature.

a

Two-dimensional time-frequency analysis combined

classification accuracy of 88.56% on the test set, which

with Fisher analysis is used to extract the features of the

12

Research on the key technologies of motor imagery EEG signal based on deep learning
imaginary movements of the left hand, right hand, foot

there are enough data to adjust a large number of

and tongue in the BCI competition data set, and SVM is

parameters. However, when the data set is small, there

used to recognize, which achieves an accuracy rate of

will be overfitting problem. It is hoped that in the future,

85.7%. A self-collected dataset, which contains the EEG

high-precision classification of small data sets can be and

features of the four types of motor imagery tasks of the

realized.

upper, lower, left and right spheres of the ball. Feature

(4) The classification task could not be performed in

extraction and classification of four types of motor

real time in this paper. Because the collected data need

imagery EEG signals use CSP combined with SVM. The

preprocessing and feature extraction offline. Due to the

highest accuracy is 86.3%. The dataset of this paper is a

high complexity of the algorithm, it is impossible to

self-collected data set of four types of motions:

achieve real-time at present, which is one of the

left-handed lifting, right-hand lifting, left-foot lifting and

important directions for future research. Real-time

right-foot lifting. The min-VGG-LSTMnet network

pre-processing software integration is required to achieve

model is used to identify and predict four types of tasks.

real-time classification.

The highest accuracy is 88.56%.

References

In summary, the min-VGG-LSTMnet hybrid deep
learning network designed in this paper not only realized
the four-classification task of motor imagery EEG

1.

Validating

signal, but also improved the classification accuracy by

method.

for the realization of the brain-computer interface

2.

imagery EEG signals, which has great research
significance and application value in the fields of

3.

online

JJ Shih; Krusienski; Dean J; et al. Brain-computer

rehabilitation

and

new

1257-1260.
4.

paper are as follows:
future,

the

complexity

Trans Neural Syst Rehabil Eng 2001; 9(3):
283-288.
5.

to obtain more representative motor imagery EEG signal,

Tianjin University 2010; 43(10): 895-900.
6.

simpler model, the advantage of deep learning is that

Feature

extraction

and

Blankertz B; Müller KR. The BCI competition
2003.

IEEE

Transactions

on

Biomedical

Engineering 2004; 51(6): 1044-1051.
8.

Michel Cotsaftis. The autonomous intelligence
challenge. Journal of Autonomous Intelligence

(3) At present, the deep learning network is not very
good at classifying small data sets. Compared with the

N.

2017; 37(06): 18-22.
7.

limited to the feature extraction of motor imagery EEG
types of EEG signal.

Wang

of Posts and Telecommunications (Social Science)

(2) The EEG signal is very weak, and it is necessary

signal, but also suitable for feature extraction of other

X;

motion imagination. Journal of Nanjing University

discriminate between different classification tasks.

a better method of feature extraction. It is not only

Xu

classification of EEG signals in four kinds of

and the classification algorithm should be enhanced to

to continue to explore its intrinsic properties and find

Wan B; Liu Y. Multi-pattern motor imagery
recognition based on EEG features. Journal of

of

multi-classification tasks can be further studied in order

Obermaier B; Neuper C. Information transfer rate
in a five-classes brain-computer interface. IEEE

generation

The main recommendations and prospects of this

Pfurtscheller G. Functional brain imaging based on
ERD/ERS. Vision Research 2001; 41(10-11):

human-computer interaction.

the

for

2012; 87: 268–279.

through the feature extraction and classification of motor

In

networks

interfaces in medicine. Mayo Clinic Proceedings

This paper provides an important technical support

(1)

neural

signals. Sensors 2019; 19(1): 210.

4. Discussion

medical

deep

decoding of motor imagery movements from EEG

at least 8.18%, and reduced the loss value by at least
0.0288 compared with the mainstream deep-learning

Zied Tayeb; Juri Fedjaev; Nejla Ghaboosi; et al.

2018; 1(1): 1-1.
9.

13

Manu

Mitra.

Neural

processor

in

artificial

Zhuozheng Wang, Zhuo Ma, Xiuwen Du, et al.
intelligence advancement. Journal of Autonomous

20. Okita T; Inoue S. Activity recognition: Translation

Intelligence 2018; 1(1): 2-14.

across sensor modalities using deep learning. In

10. Delorme A; Makeig S. EEGLAB: an open source

Proceedings of the 2018 ACM International Joint

toolbox for analysis of single-trial EEG dynamics

Conference and 2018 International Symposium on

including

Pervasive and Ubiquitous Computing and Wearable

independent

component

analysis.

J

Neurosci Methods 2004; 134(1): 9-21.

Computers 2018; 1462–1471.

11. Ahmad A; Xavier J. 3D to 2D bijection for
spherical

objects

projection.

under

Computer

equidistant
Vision

and

21. Ha K-W; Jeong J-W. Motor imagery EEG

fisheye

classification using capsule networks. Sensors 2019;

Image

Understanding 2014; 125: 172-183.

19: 2854.
22. Nicolas-Alonso; Luis F; Gomez-Gil J. Brain

12. Jiaqing Chen; Xiaohui Mu; Yinglei Song; et al.

computer interfaces, a review. Sensors 2012; 12:

Flame recognition in video images with color and
dynamic features of flames. Journal of Autonomous

1211–1279.
23. Kim

Intelligence 2019; 1(1): 11-29.

D-W;

Lee

J-C;

Park

Y-M;

et

al.

Auditory brain-computer interfaces (BCIs) and their

13. Weide Li, Juan Zhang. An innovated integrated

practical

model using singular spectrum analysis and support

applications.

Biomedical

Engineering

Letters 2012; 2: 13–17.

vector regression optimized by intelligent algorithm

24. Michel Cotsaftis. Autonomous intelligence: An

for rainfall forecasting. Journal of Autonomous

advance level in modern technology. Journal of

Intelligence 2019; 1(1): 30-45.

Autonomous Intelligence 2018; 1(1): 44-44.

14. Krizhevsky A; Sutskever I. Imagenet classification

25. Yongzhong Lu; Min Zhou; Shiping Chen; et al. A

with deep convolutional neural networks. Advances

perspective

in Neural Information Processing Systems 2012;

optimization techniques in maximum likelihood

1097-1105.

parameter estimation. Journal of Autonomous

15. Cho K; Van Merriënboer B. Learning phrase
representations using RNN encoder-decoder for

of

conventional

and

bioinspired

Intelligence 2018; 2(1): 1-12.
26. Lotte F; Bougrain L; Cichocki A; et al. A review of

statistical machine translation. arXiv preprint arXiv

classification algorithms for EEG-based brain-com

2014; 1406.

-puter interfaces: A 10-year update. Journal of

16. Graves A; Fernández S. Bidirectional LSTM

Neural Engineering 2018; 15: 031005.

networks for improved phoneme classification and

27. Park J; Min K; Kim H; et al. Road surface

recognition. International Conference on Artificial

classification using a deep ensemble network with

Neural Networks 2005; 799-804.

sensor feature selection. Sensors 2018; 18: 4342.

17. Lawhern VJ; Solon AJ. EEGNet: A compact

28. Zhao R; Yan R; Wang J; et al. A hybrid CNN –

convolutional neural network for EEG-based brain

LSTM algorithm for online defect recognition of

– computer

CO2 welding. Sensors (Basel) 2017; 17(2).

interfaces.

Journal

of

Neural

Engineering 2018; 15(5): 056013.

29. Gao M; Shi G; Li S. Online prediction of

18. Ordóñez F; Roggen D. Deep convolutional and

ship behavior with automatic identification system

LSTM recurrent neural networks for multimodal

sensor data using bidirectional long short-term

wearable activity recognition. Sensors 2016; 16:

memory recurrent neural network. Sensors 2018; 18:

115.

4211.

19. Yao S; Hu S; Zhao Y; et al. Deepsense: A unified

30. Liu C; Wang Y; Kumar K; et al. Investigations on

deep learning framework for time-series mobile

speaker adaptation of LSTM RNN models for

sensing data processing. In Proceedings of the 26th

speech

International Conference on World Wide Web,

International Conference on Acoustics, Speech and

International

Signal Processing 2016; 5020–5024.

World

Wide

Web

Conferences

Steering Committee 2017; 351–360.

14

recognition.

In

Proceedings

of

the

