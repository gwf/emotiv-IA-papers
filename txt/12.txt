Medicinski
podmladak

Medical
Youth

Review article
DEEP LEARNING APPROACHES FOR HUMAN ACTIVITY
RECOGNITION USING WEARABLE TECHNOLOGY

CrossMark

PRISTUPI DUBOKOG UČENJA ZA PREPOZNAVANJE
AKTIVNOSTI LJUDI PRIMENOM ODEVNE TEHNOLOGIJE
Milica Janković 1, Andrej Savić 1,2 , Marija Novičić 1, Mirjana Popović 1
1
2

University of Belgrade, School of Electrical Engineering, Belgrade, Serbia
Tecnalia Serbia; Belgrade, Serbia

Correspondence: piperski@etf.rs

Abstract

Keywords:
deep learning,
human activity monitoring,
human machine interface,
wearable sensors,
smart sensors,
multimodal interface

The need for long-term monitoring of individuals in their natural environment has
initiated the development of a various number of wearable healthcare sensors for a wide range of applications: medical monitoring in clinical or home environments, physical activity
assessment of athletes and recreators, baby monitoring in maternity hospitals and homes etc.
Neural networks (NN) are data-driven type of modelling. Neural networks learn from experience, without knowledge about the model of phenomenon, but knowing the desired „output” data for the training „input” data. The most promising concept of machine learning that
involves NN is the deep learning (DL) approach. The focus of this review is on approaches of
DL for physiological activity recognition or human movement analysis purposes, using wearable technologies. This review shows that deep learning techniques are useful tools for health condition prediction or overall monitoring of data, streamed by wearable systems. Despite
the considerable progress and wide field of applications, there are still some limitations and
room for improvement of DL approaches for wearable healthcare systems, which may lead to
more robust and reliable technology for personalized healthcare.

Janković M. et al. MedPodml 2018, 69(3):14-24
©
The authors declare no conflicts of interest.

doi: 10.5937/mp69-18039
Editorial board: podmladak.med.bg@gmail.com
e-ISSN: 2466-5525

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

Sažetak

Ključne reči:
duboko učenje,
praćenje ljudske aktivnosti,
čovek-mašina interfejs,
odevni senzori,
pametni senzori,
multimodalni interfejs

Potreba za dugotrajnim praćenjem osoba u njihovom svakodnevnom okruženju
inicirala je razvoj velikog broja nosivih senzora (integrisanih u delove garderobe) s različitom primenom, kao što su medicinsko praćenje u kliničkim i kućnim uslovima, procena
fizičke aktivnosti sportista i rekreativaca, praćenje beba u porodilištima i kućama i sl.
Neuralne mreže (NM) predstavljaju tip modelovanja zasnovan na velikom broju podataka. Ove mreže uče na osnovu iskustva, bez poznavanja modela fenomena, ali znajući šta
su željeni „izlazni” podaci za obučavajuće „ulazne” podatke. Koncept mašinskog učenja
koji najviše obećava i uključuje NM jeste duboko učenje (DU). Fokus ovog preglednog
rada je u pristupima DU u cilju prepoznavanja fizioloških aktivnosti i analize ljudskih
pokreta primenom “odevne tehnologije”. Ovaj rad pokazuje da su tehnike dubokog učenja
korisne alatke za predikciju zdravstvenih stanja ili celokupno praćenje podataka koji se
šalju sa “odevnih” senzora. Uprkos značajnom napretku i obećavajućoj oblasti primene, i
dalje postoje ograničenja i prostor za unapređenje pristupa DU za “odevne” zdravstvene
sisteme koji će dovesti do njihove pouzdane primene i omogućiti personalizovanu zdravstvenu zaštitu.

Introduction
In the last two decades, the development of technology and computer science has enabled the miniaturization of electronic components and sensors, their integration into clothes or jewelry for continuous healthcare or
behavior monitoring and sharing acquired data using
Internet of Things (IoT) concepts (Figure 1) (1-3).
Wearable healthcare devices integrate: 1) sensor with analog front-end (conditioning circuitry); 2) microcontroller
unit for data acquisition; 3) wireless module for data transmission (Bluetooth, ZigBee, GPRS, GSM etc.); and 4)
battery cell for independent power supply of the device.
Acquired data could be stored on the local medium (SD
memory card), the local computer device (laptop, tablet,

smartphone) or on the secured cloud. Basic non-compliant processing could be performed by AFE and microcontroller in the wearable device, but more complex data
science (advanced signal processing, data mining, machine learning, decision support etc.) are usually performed offline.
The results of measuring by wearable devices could
be used for monitoring of vital parameters of the human
body, improving diagnostics by medical experts, or as a
feedback information for the user.
The need for long-term monitoring of individuals
in their natural environment has initiated the development of a various number of wearable sensors for a wide
range of applications: medical monitoring in clinical or

Figure 1. Wearable system – data acquisition and transmission concept, AFE – analog front-end

Medicinski podmladak / Medical Youth

15

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

home environments, physical activity assessment of athletes
and recreators, baby monitoring in maternity hospitals and
homes (4). Wearable technology combines several disciplines: electronics, biomedical engineering, fashion, smart
textile and flexible-stretchable-printable electronics, with
the aim to design unobtrusive sensing devices for human
activity monitoring (5,6). Also, an emerging trend of simultaneous recording using different wearable devices, so-called
multimodal interfacing, is present in the literature (7).
Examples of various wearable devices developed by
research university teams and R&D companies are presented
in Figure 2. Paradiso et al. (8) produced a Wearable Wellness
System (WWS) for real-time monitoring of 1-lead ECG (electrocardiogram) and respiration rate. Textile ECG electrodes
are placed on the thorax, and textile piezoresistive sensor
(breathing sensor) is placed above them in the middle (9).
Emotiv EPOC® neuroheadset is a wearable 14-channel EEG
system, validated as brain computer interface (BCI) device
(10,11), used in the research of event-related potential (ERP)
studies (12,13) and emotion recognition experiments (14,15).
Myo armband® is a hand gesture controller that integrates
eight segments with electromyography (EMG) sensors (each
segment includes one EMG amplifier with bar electrodes),
and one segment additionally includes a three-axis accelerometer and a three-axis gyroscope (16). This device could be
used as a substitution of computer mouse, providing individuals without hand or forearm to make human- computer

control, but also supports other applications of humanmachine interface. Djurić-Jovičić et al. (17) developed
SENSY system of interactive shoes inertial measurement
units (IMU) that measure force distribution and stride
parameters in gait analysis. Moodmetric® ring measures
electro dermal activity of the skin, as an indicator of
sympathetic activation (18) and the appropriate application, estimates the level of physiological and psychological arousal (19).
Mobile eye tracking devices in the form of ordinary glasses frames, with storing and real-time processing capabilities, have expanded the research and the
application field of gaze gestures in daily life environment like (20).
Development of wearable minimally-invasive
glucose monitor sensors has made the revolution in continuous diabetes treatment and significantly improved
the quality of life of diabetics (21). Such wearable sensors insert a needle in the subcutaneous tissue of the abdomen or the arm and measures in real-time (every
1-5 min) the electrical current of glucose-oxidase reaction, proportional to the glucose concentration. Zheng et
al. developed a prototype of armband for 24-hour blood
pressure (BP) monitoring that indirectly measure BP
using pulse transit time obtained from ECG and photoplethysmogram (PPG) (22).

Figure 2. a) Wearable Wellness System from (8), b) Emotiv EPOC® neuroheadset, c) Myo armband® hand gesture
controller, d) SENSY system for gait analysis (17), e) Moodmetric® ring for stress follow, f) Tobii® eye tracker glasses
form (20), g) Medtronic® continuous glucose monitor form (21), h) A prototype of wearable 24-hour blood pressure
device form (22)
16

Medicinski podmladak / Medical Youth

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

function is a linear combination of products of inputs x_i
and weight coefficients w_i, Eq. (1):

Deep Learning algorithms
Data science is a “concept to unify statistics, data
analysis, machine learning and their related methods” in order to “understand and analyze actual phenomena” with
data (23). Machine learning (ML) is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and act like humans do, based on experience rather than based on strictly defined algorithms. An
individual measurable representation of a phenomenon being observed is called a feature (24). The performance of ML
algorithms depends on the features that are chosen, and this
is the most important step for the various ML algorithms.
One of the growing fields of ML is Deep Learning (DL).
It solves the main issue of ML by expressing complex representation in terms of other, simpler representations, allowing
the computer to build complex concept out of simpler concepts (25). Principles of several deep learning algorithms:
feedforward neural networks (FNN), convolutional neural
networks (CNN) and recurrent neural networks (RNN) will
be briefly explained in this chapter. The data processing in
those artificial neural networks (NN) is very similar to decision making procedure in biological neural structure.
Neural networks learn from experience without knowledge
about the model of phenomenon but knowing what the desired reaction is (“output” data) for the appropriate training
“input” data. Based on the given input/output data, they develop their own knowledge, which allows them to make
conclusions during testing on new datasets.
The basic NN unit is a perceptron or artificial neuron,
Figure 3. The perceptron combines several inputs using and
produces a single output. It consists of two parts: net function and activation function. Net function summarizes information from m external sources or other neurons. Net

The activation function (threshold, linear, sigmoid
etc.) is applied to the output of net function. The output
value of the perceptron is defined as the output of activation function.
Feedforward deep learning is based on feedforward
neural networks (multi-layered perceptron – MLP).
These neural networks (Figure 4) consist of large number of highly connected perceptron grouped into
layers (26). The number of layers defines depth of neural
network. Number of neurons in one layer defines width
of model. First layer is called input layer and the last one
is called output layer. Layers between input and output
layer are called hidden layers. These networks are called
feedforward because the information flows from the input layer, through hidden layers, to the output layer, which means that there is no feedback from the output to the
input. During the training phase, learning algorithm updates weight factors depending on the difference between
current outputs and desired outputs and when the difference becomes satisfactory small, learning algorithm
stops. Estimated weight factors are stored for the testing
phase. During the training phase, over fitting should be
avoided and NN must generalize well with unknown inputs too. Autoencoder is a type of NN where the number
of input and output nodes is the same. Deep Belief
Network (DBN) is composed of layers of Restricted
Boltzmann Machines (RBMs) for the pre-train phase and
then a feed-forward network for the fine-tune phase.

Figure 3. A description of how perceptron (artificial neuron) works

Figure 4. An example of feedforward neural network
Medicinski podmladak / Medical Youth

17

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

Convolutional neural networks (CNN) are specialized neural networks for processing data that has grid-like
topology (time-series data or images). They have sparse
interactions, which is accomplished by using the kernel
smaller than the input (27). For example, if the input data
have thousands or millions of samples, local features could
be detected using kernels that occupies only a dozen or a
hundred of samples. Efficiency of CNN is improved compared to FNN and memory requirements are reduced.
Using classic FNN, an input neuron affects all outputs neurons, while in CNN an input neuron only affects several
output neurons (number is defined by kernel width). The
typical layer of CNN consists of three stages (Figure 5).
The first stage performs several convolutions in parallel to
produce linear activation. In the second, detector stage,
each linear activation is run through nonlinear activation
function. The last, third stage uses pooling function to
make the output invariant to the noise and disorder.
The best performances of CNN are achieved for
two-dimensional image topology, while for processing of
one-dimensional time series data, it is best to use RNN.
Each output of RNN depends on the previous outputs (28),
Figure 6. RNN shares their weight factors through a very
deep computation graph. Long Short Term Memory
(LSTM) is a type of RNN that uses special units to include
a ‘memory cell’ that can maintain information in memory
for long periods of time.

Deep Learning applications in wearable
healthcare systems
Several comprehensive reviews about the rise of wearable sensors and the significance of using data science
methods for improving wearable healthcare information
systems could be found in the literature (29-32). They
emphasize the increasing trend of continual multimodal
sensing for early diagnosis of diseases, prevention of chronic conditions, quick response in emergencies, physiological activity monitoring. Gravina et al. (33) have published
a global overview about multi-sensor fusion of information in body sensor networks. Banaee et al. (34) presented
the data mining review for healthcare and wearable sensors
for the following vital signals: electrocardiogram, heart
rate, blood pressure, respiratory rate, oxygen saturation,
photoplethysmography and blood glucose. In this chapter,
we will focus on approaches of DL for physiological activity recognition or human movement analysis purposes. The
general concept of the DL approach for wearable sensor
data is presented in Figure 7. The starting point in DL
approaches is the acquisition of raw data from different
wearable sensors. The next step is data preprocessing (filtering, de-noising, normalization, all data synchronization
etc.) followed by the feature extraction (in time or frequency domain or nonlinear features) and the selection of the
most informative features for DL training/testing. The results of feature extraction and selection and additional

Figure 5. The structure of convolutional neural network

Figure 6. The structure of recurrent neural network

Figure 7. The integration of data from wearable sensors in DL approaches

18

Medicinski podmladak / Medical Youth

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

knowledge (expert opinion, patient metadata, study metadata etc.) are inputs for training/testing DL algorithm that
will finally make a decision about the medical phenomenon of interest (detection, prediction etc.).
The summary of possible DL applications in wearable healthcare approaches is presented in Table 1. with the
comparison of their accuracy.
Sarkar et al. (35) proposed a framework utilizing
deep learning that recognizes human cognitive activities
in real time via fusion of multiple EEG sensors in an unconstrained environment and selects a smaller sensor suite
appropriate for wearable systems. Classification performances for two major activities “listening” and “watching”
was high using DBN and CNN approaches (91.15% and
91.63%, respectively).

Langkvist et al. (36) tested a two-layer DBN with
200 hidden units in both layers. They report that the DBN
method increased the accuracy of sleep scoring (91.33%)
by approximately 3%, when compared with the manual
methods. Authors concluded that, for multimodal data, it
is favorable to utilize separate DBNs for each of the signals
and then combine their outputs with a secondary DBN.
Zhang et al. (37) applied the sparse version of DBN
(SDBN) for sleep stage classification. They also used a voting principle based on classification entropy using SDBN
and combination of classifiers including Support Vector
Machine (SVM), k-nearest neighbors (KNN) and Hidden
Markov Model (HMM), attaining 91.31% accuracy.
Dong et al. (38) have used LST network for sequential data learning to optimize classification performance

Table 1. Summary of different deep learning methods possible for wearable healthcare. Acc – accuracy,
P – precision, BA – Bland Altman slope (systematic error)

Data
EEG

Application
Network type
Cognitive activity recognition DBN
CNN
Sleep stage scoring
DBN
LSTM
DBN

Anomaly detection
Classification of motor
imagery

EMG
ECG

PPG

Motion

CNN
Autoencoder
Frequency DBN
CNN

Motion-onset Visual Evoked
Potential feature extraction
Hand movement classification DBN
Arrhythmia classification
Abnormal ECG recognition
Biometric user identification
Diabetes detection
Monitoring and detecting of
atrial fibrillation
Biometric user identification
Blood pressure monitoring
Human activity recognition
Closed loop for human
activity recognition
Mobile applications for
activity recognition
Movement disorder

40

Results
Acc: 91.15%
Acc: 91.63%
Acc: 91.33%
Acc: 91.31%
Acc: 85.92%
P: 0.1920
high performance
Acc: 77.6%

41
42

Acc: 84%
Acc: 87.5%

43

Acc: 66.59%
(healthy)
38.09% (amputees)
Acc: 98.83%
Acc: 85.52%
Acc: 99.54%
Acc: 95.1%
Acc: 91.8%

35
36
37
38
39

DBN
DNN
CNN-LSTM
CNN
DBN

45
47
48
49
50

DBN
CNN, LSTMRNN
CNN, LSTM
DBN

51
52

DBN
CNN

55
56
57

CNN

58

53
54

Medicinski podmladak / Medical Youth

Acc: 96.t1%
BA: 0.47 (systolic)
0.16 (diastolic)
Acc: 95.8%
Acc: 90%
Acc: 73-94%
Acc: 95.75%
Acc: 91.5-98.2%
Acc:90.9%
19

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

with one-channel EEG. Authors have tested single-channel
EEG options on the forehead (F4-EOG left and Fp2-EOG
left). Evaluation of data from 62 people and 494 hours of
sleep demonstrated better performance of their algorithm
than existing approaches with vertex or occipital electrode
placements. The classification accuracy using LST network
was 85.92% and it was higher than using SVM (79.7%),
Random Forest (RF, 81.67%) or MLP (81.43%).
Wulsin et al. (39) applied DBN in a semi-supervised
paradigm to model EEG waveforms for classification and
anomaly detection i.e. small group of isolated waveform
patterns, such as spikes, seizures, eye blinks and other artifacts/noise. Their results show that DBN performance was
comparable to standard classifiers (decision trees, SVM,
KNN), and classification time was found to be 1.7 to 103.7
times faster than the other high-performing classifiers.
Authors suggested that DBNs with raw data inputs may be
more effective for online automated anomaly recognition
in the EEG than other common techniques.
Tabar et al. (40) have used deep learning approach to
improve classification of EEG motor imagery for BCI.
They employed CNN and Autoencoder network to classify
motor imagery from EEG. They proposed a new deep
network in which the features that are extracted by CNN
are classified through the Autoencoder network. The averaged classification error was 77.6%. They report 9% improvement over the winner algorithm of BCI competition
IV (Berlin, 2008).
Lu et al. (41) estimated frequency domain representations of EEG signals for motor imaginary obtained via
fast Fourier transform (FFT) and wavelet package decomposition (WPD) to train three RBMs, which were stacked
up with an additional output layer to form a four-layer neural network, which is named the Frequential DBN
(FDBN). The output layer used Softmax regression for classification and the conjugate gradient method and backpropagation were used to fine tune the FDBN. Results on
benchmark datasets, showed statistically significant improvement in classification, using FDBN over other selected state-of-the-art methods (84% vs. 73-80%).
Ma et al. (42) combined DBN with compressed sensing to extract discriminative Motion-onset Visual Evoked
Potentials (mVEP) information for improving the BCI
performance. The deep learning and compressed sensing
approach generated the multi-modality features which improved BCI performance with approximately 3.5% accuracy incensement. Deep learning and compressed sensing
approach yielded higher classification accuracy (87.5% vs.
84%), against using conventional mVEP features, and were
effective for subjects with relatively poor performance.
Atzori et al. (43) used CNN to classify 50 hand movements using surface EMG signals. Authors used Ninapro
open database (44) of 78 subjects: 67 health subjects and 11
subjects with trans radial amputee. The average classification accuracy using simple CNN and classical classification methods (SVM, KNN, random forest, linear discriminant analysis) were comparable (66.59% vs. 62.06% for
dataset 1 of health subjects, 60.27% vs. 60.28% for dataset 2
20

of health subjects, 38.09% vs. 38.82% for amputees).
Yan et al. (45) used standard MIT-BIH database (46)
of ECG signals to train RBMs. Half of the data was used for
RBMs training, 30% was used for fine-tuning of DBN and
20% was used for testing. It is shown that by combining the
two ECG-lead the accuracy, sensitivity and specificity reached to 98.83%, 99.83% and 96.05%, respectively.
Ripol et al. (47) compared the efficacy of DBN recognition of abnormal 12-lead ECG in a large group of patients (1390 patients from Hospital Clinic in Barcelona)
against several algorithms: SVM, KNN, Extreme Learning
Machines (ELM) and professional algorithm of dedicated
cardiology system. Both SVM (accuracy 84.76% and specificity 73.46%) and DBN (accuracy 85.52% and specificity
78.27%) resulted by better accuracy and specificity than
other methods.
Page et al. (48) applied deep neural network (DNN)
on identified QRS segments of 90 subjects in resting state
to biometrically identify them. The best results were obtained using a single hidden layer while deeper networks had
overfitting problems. The accuracy of applied NN was
99.54%, sensitivity was 99.49% and specificity was 99.55%.
Swapna et al. (49) applied CNN-LSTM on heart rate
extracted from ECG signals to detect diabetes, with the accuracy of 95.1%. This seems to be a promising method for
non-invasive detection of diabetes.
Shashikumar et al. (50) performed real-time detection of atrial fibrillation in patients. They used continuous
wavelet transform of the PPG signal recorded by Simband
smart watch to extract features for training of CNN. The
obtained accuracy was 91.8% and comparable to ECGbased approaches.
Jindal et al. (51) compared the performance of DBN
approach with classic KNN and fuzzy classifier in biometric user identification. The DBN approach included the
clustering step to subgroups before pre-training by RBMs
and DBN fine tuning. The combined clustering and DL
method had 96.1% accuracy in biometric authorization,
which was more than 10% higher than by classic methods.
Ruiz-Rodrıíguez et al. (52) simultaneously recorded
blood pressure invasively (by radial artery catheter) and
non-invasively (by photoplethysmograph). The RBM was
trained to assess blood pressure using PPG signals in the
group of 572 patients with stable blood pressure. A systematic error (Bland-Altman slope) was 0.47 and 0.16 for
systolic and diastolic arterial pressure, respectively.
Wearable DL systems for the recognition of physical
human activity were considered by different authors. The
input signals for DL training in such systems are from motion sensors (accelerometers, gyroscopes). Ordóñez et
al. (53) showed that the combination of CNN and RNN
was effective in human activity recognition of 18 gesture
tasks with the accuracy of 95.8%. The robustness of activity
recognition could be improved using closed loop concept
introduced by Saeedi et al. (54) and the accuracy of activity
recognition could reach 90%. Several authors presented
frameworks for activity recognition using mobile devices
indicating the possibilities of commercial applications

Medicinski podmladak / Medical Youth

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

(55-57). Bhattacharya et al. (55) presented a simple RBM
solution that could work on smart watch processor
(Qualcomm Snapdragon 400). The smart watch prototype
included following sensors: accelerometer, gyroscope, barometer, magnetometer, light and temperature. Three different RBM architectures were tested to support three
types of daily scenarios: gestures, transportation and physical activities, and transition between indoor/outdoor environments. Classification results by RBM method had higher accuracy in comparison to conventional methods
(SVC, RF, decision trees). The results of testing the battery
life were between 6 and 52 hours, depending on the RBM
model. Ronao et al. (56) presented results on the study of
30 volunteers that performed different physical activities (walking, sitting, standing, laying) while the smart
phone was in their pockets, collecting accelerometer and
gyroscope data. They report the classification accuracy of
95.75% for human activity recognition by CNN. Also, one
solution for CNN efficient implementation of human activity recognition (walking, jogging, cycling etc.) on a
low-power device was introduced by Ravi et al. (57).
Eskofier et al. (58) explained the clinical application and
superiority of deep CNN in recognition of bradykinesia in
Parkinson’s patients (based on data from accelerometers
positioned on the forearm) in comparison with classic
methods (SVM, KNN, PART, Ada Boost M1), 90.9% vs.
85.6%, 67.1%, 81.7% and 86.3%, respectively.
Limitations and future directions
We have presented the summary of 23 papers with
DL methods possible for wearable healthcare application
and compared the results of their accuracy. Most of them
use DBN or CNN concepts as DL methods, Table 1. Also,
we have cited 5 review papers in the wider field of data
science methods applied for wearable healthcare.
Deep Learning techniques have high computational
complexity, but also high accuracy in various types of
applications, because of which they are promising approaches for extraction and/or classification of data in health
informatics. However, before their expansion in usage, the
following questions should be resolved (59-61): 1) standardization of data acquisition, normalization and preprocessing procedures and collecting of huge amount of data for
the homogenous groups of subjects related to the phenomenon of interest – this is the key condition for the validity
of data driven modelling; 2) designing of DL approaches for
longitudinal studies; 3) developping sequrity models for
data acquisition and delivery of results/feedback; 4) including expert knowledge in DL process; and 5) finding a way
to rationalize neural predictions.
Wearable systems for analyzing state of the user have
been developed and tested for wide area of application:
motion analysis, human machine interaction (HMI), detection (and/or prediction) of different type of seizures,
drowsiness monitoring (for example during driving), sleep
monitors, emotion recognition, etc. Significant number of
studies explore their applicability in the area of neurorehabilitation and feedback and show progress in improving

communication, mobility and environment control in severely disabled users. This review shows that DL techniques are useful tools for health condition prediction or
overall monitoring of data streamed by wearable systems.
Nowadays, DL is present in commercial systems for speech
recognition and computer vision and it is expected to have
an important role in smart healthcare in the future. It is
expected that wearable healthcare systems with DL approaches will be successfully integrated in mobile systems (5264). The direct consequence of the application of such
systems, in both home and clinical practice, will be decreasing expenses for home and clinical healthcare, or supervising athletes. Despite the considerable progress, there is
still room for improvement of DL approaches for wearable
healthcare systems, which will lead to more trustable and
reliable application and personalized healthcare.

Acknowledgement
This research was partly supported by the Ministry
for Education, Science and Technology Development of
Serbia, Belgrade, Serbia (OS 175016).

References
1. Rodgers MM, Pai VM, Conroy RS. Recent advances in wearable sensors for health monitoring. IEEE
Sensors Journal, 2015; 15(6): 3119-3126.
2. Bonato P. Wearable sensors and systems. IEEE
Engineering in Medicine and Biology Magazine.
2010; 29(3): 25-36.
3. Vukićević S, Stamenković Z, Murugesan S, Bogdanović
Z, Radenković B. A new telerehabilitation system based on internet of things. Facta Universitatis, Series:
Electronics and Energetics, 2015; 29(3): 395-405.
4. Bloss, R. Wearable sensors bring new benefits to continuous medical monitoring, real time physical activity assessment, baby monitoring and industrial applications. Sensor Review, 2015; 35(2): 141-145.
5. Zheng YL, Ding XR, Poon CCY, Lo BPL, Zhang H,
Zhou XL et al. Unobtrusive sensing and wearable devices for health informatics. IEEE Transactions on
Biomedical Engineering, 2014; 61(5): 1538-1554.
6. Stoppa M, Chiolerio A. Wearable electronics and
smart textiles: a critical review. Sensors. 2014; 14(7):
11957-11992.
7. Kumari P, Mathew L, Syal P. Increasing trend of wearables and multimodal interface for human activity
monitoring: A review. Biosensors and Bioelectronics.
2017; 90: 298-307.
8. Paradiso R, Bianchi AM, Lau K, Scilingo EP. PSYCHE:
Personalised monitoring systems for care in mental
health. In: Annual international conference of the
IEEE Engineering in Medicine and Biology Society
(EMBC). August 31-September 4, Buenos Aires,
Argentina. 2010; p. 3602-3605.
9. Scilingo EP, Gemignani A, Paradiso R, Taccini N,

Medicinski podmladak / Medical Youth

21

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

10.

11.

12.

13.

14.

15.

16.

17.

18.

19.

20.
21.

22

Ghelarducci B, De Rossi D. Performance evaluation of sensing fabrics for monitoring physiological
and biomechanical variables. IEEE Transactions on
information technology in biomedicine. 2005; 9(3):
345-352.
Liu Y, Jiang X, Cao T, Wan F, Mak PU, Mak PI et al.
Implementation of SSVEP based BCI with Emotiv
EPOC. In: IEEE International Conference on Virtual
Environments Human-Computer Interfaces and
Measurement Systems (VECIMS). 2-4 July, Tianjin,
China, 2017; p. 34-37.
Taylor GS, Schmidt C. Empirical evaluation of the
Emotiv EPOC BCI headset for the detection of mental actions. In: Proceedings of the Human Factors and
Ergonomics Society Annual Meeting. 22-26 October,
Boston, Massachusetts, USA, 2012; 56(1): 193-197.
Duvinage M, Castermans T, Petieau M, Hoellinger T,
Cheron G, Dutoit T. Performance of the Emotiv Epoc
headset for P300-based applications. Biomedical engineering online. 2013; 12(1): 56.
Badcock NA, Mousikou P, Mahajan Y, De Lissa P,
Thie J, McArthur G. Validation of the Emotiv EPOC®
EEG gaming system for measuring research quality
auditory ERPs. PeerJ. 2013; 1: e38.
Ramirez R, Vamvakousis Z. Detecting emotion
from EEG signals using the emotive epoc device.
In: International Conference on Brain Informatics.
December 4-7, Macao, China, 2012; p. 175-184.
Pham TD, Tran D. Emotion recognition using the
emotiv epoc device. In: International Conference on
Neural Information Processing. 12-15 November,
Doha, Qatar, 2012; p. 394-399.
Lu Z, Chen X, Li Q, Zhang X, Zhou P. A hand gesture
recognition framework and wearable gesture-based
interaction prototype for mobile devices. IEEE transactions on human-machine systems. 2014; 44(2):
293-299.
Milica Djurić-Jovičić. Inertial Sensors Signal
Processing Methods For Gait Analysis Of Patients
With Impaired Gait Patterns, PhD thesis, University
of Belgrade – School of Electrical Engineering,
Belgrade, 2012.
Torniainen J, Cowley B, Henelius A, Lukander K,
Pakarinen S. Feasibility of an electrodermal activity ring prototype as a research tool. In: 37th Annual
International Conference of the Engineering in
Medicine and Biology Society (EMBC), 25-29 August,
Milano, Italy, 2015; p. 6433-6436.
Suoja K, Liukkonen J, Jussila, J, Salonius H, Venho N,
Sillanpää V et al. Application for pre-processing and
visualization of electrodermal activity wearable data.
In: EMBEC & NBC. 11-15 June, Tampere, Finland,
2017; p. 93-96.
Bulling A, Gellersen H. Toward mobile eye-based human-computer interaction. IEEE Pervasive
Computing, 2010; 9(4): 8-12.
Cappon G, Acciaroli G, Vettoretti M, Facchinetti
A. Sparacino G. Wearable Continuous Glucose

22.

23.

24.
25.
26.

27.

28.
29.

30.

31.

32.
33.

34.

35.

36.

Monitoring Sensors: A Revolution in Diabetes
Treatment. Electronics. 2017; 6(3): 65.
Zheng YL, Yan BP, Zhang YT, Poon CC. An armband
wearable device for overnight and cuff-less blood pressure measurement. IEEE transactions on biomedical
engineering. 2014; 61(7): 2179-2186.
Hayashi C. What is Data Science? Fundamental
Concepts and a Heuristic Example. In: Data Science,
Classification, and Related Methods. Studies in
Classification, Data Analysis, and Knowledge
Organization. Toky: Springer; 1998.
Bishop C. Pattern recognition and machine learning.
Berlin: Springer; 2006.
Goodfellow I, Bengio Y, Courville A. Deep Learning.
Cambridge:The MIT Press; 2016.
Chin-Teng L, George Lee CS. Feedforward neural
networks - Neural Fuzzy Systems: A Neuro-Fuzzy
Synergism to Intelligent Systems. New York: Prentice
Hall; 1996.
Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional neural networks.
In: Advances in neural information processing
systems. 3-8 December, Lake Tahoe, Harrahs and
Harveys, 2012; p. 1097-1105.
Lipton ZC, Berkowitz J, Elkan C. A critical review
of recurrent neural networks for sequence learning.
arXiv preprint arXiv:1506.00019. 2015.
Redmond SJ, Lovell NH, Yang GZ, Horsch A,
Lukowicz P, Murrugarra L, Marschollek M. What
does big data mean for wearable sensor systems?:
Contribution of the IMIA wearable sensors in healthcare WG. Yearbook of medical informatics, 2014;
9(1): 135-142.
Hansen MM, Miron-Shatz T, Lau AYS, Paton C. Big
data in science and healthcare: a review of recent literature and perspectives: contribution of the IMIA
social media working group. Yearbook of medical informatics, 2014; 9(1): 21-26.
Andreu-Perez J, Leff DR, Ip HM, Yang GZ. From wearable sensors to smart implants-–toward pervasive
and personalized healthcare. IEEE Transactions on
Biomedical Engineering. 2015; 62(12): 2750-2762.
Simpao AF, Ahumada LM, Gálvez JA, Rehman MA.
A review of analytics and clinical informatics in health care. Journal of medical systems. 2014; 38(4): 1-7.
Gravina R, Alinia P, Ghasemzadeh H, Fortino G.
Multi-sensor fusion in body sensor networks: Stateof-the-art and research challenges. Information
Fusion. 2017; 35: 68-80.
Banaee H, Ahmed MU, Loutfi A. Data mining for
wearable sensors in health monitoring systems: a review of recent trends and challenges. Sensors. 2013;
13(12): 17472-17500.
Sarkar S, Reddy K, Dorgan A, Fidopiastis C, Giering
M. Wearable EEG-based activity recognition in
PHM-related service environment via deep learning.
Int. J. Progn. Health Manag, 2016; 7: 1-10.
Längkvist M, Karlsson L, Loutfi A. Sleep stage

Medicinski podmladak / Medical Youth

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

37.

38.

39.

40.
41.

42.

43.

44.

45.

46.

47.
48.

classification using unsupervised feature learning.
Advances in Artificial Neural Systems. 2012; 2012:1-9.
Zhang J, Wu Y, Bai J, Chen F. Automatic sleep stage classification based on sparse deep belief net and
combination of multiple classifiers. Transactions of
the Institute of Measurement and Control. 2016; 38:
435-451.
Dong H, Supratak A, Pan W, Wu C, Matthews PM,
Guo Y. Mixed neural network approach for temporal sleep stage classification. IEEE Transactions on
Neural Systems and Rehabilitation Engineering.
2018; 26: 324-333.
Wulsin D, Gupta J, Mani R, Blanco J, Litt B, Modeling
electroencephalography waveforms with semi-supervised deep belief nets: fast classification and anomaly
measurement. Journal of neural engineering. 2011;
8(3): 1-28.
Tabar YR, Halici U. A novel deep learning approach for classification of EEG motor imagery signals.
Journal of neural engineering. 2016; 14:016003.
Lu N, Li T, Ren X, Miao H. A deep learning scheme
for motor imagery classification based on restricted
boltzmann machines. IEEE transactions on neural
systems and rehabilitation engineering. 2017; 25:
566-576.
Ma T, Li H, Yang H, Lv X, Li P, Liu T, et al. The extraction of motion-onset VEP BCI features based on
deep learning and compressed sensing. Journal of neuroscience methods. 2017; 275: 80-92.
Atzori M, Cognolato M, Müller H. Deep learning
with convolutional neural networks applied to electromyography data: a resource for the classification
of movements for prosthetic hands. Frontiers in neurorobotics. 2016; 10(9): 1:8.
Atzori M, Gijsberts A, Heynen S, Hager AGM, Deriaz
O, Van Der Smagt et al. Building the Ninapro database: A resource for the biorobotics community. In:
4th IEEE RAS & EMBS International Conference on
Biomedical Robotics and Biomechatronics (BioRob).
24-27 June, Rome, Italy, 2012; p. 1258-1265.
Yan Y, Qin X, Wu Y, Zhang N, Fan J, Wang L. A restricted Boltzmann machine based two-lead electrocardiography classification. In: 12th International
Conference on Wearable and Implantable Body
Sensor Networks (BSN). 9-12 June, Cambridge,
Massachusetts, 2015; p. 1-9.
Goldberger AL, Amaral LA, GlassL, Hausdorff JM,
Ivanov PC, Mark RG et al. Physiobank, physiotoolkit,
and physionet: components of a new research resource for complex physiologic signals. Circulation. 2000;
101(23): e215-e220.
Ripoll VJR, Wojdel A, Romero E, Ramos P, Brugada J.
ECG assessment based on neural networks with pretraining. Applied Soft Computing, 2016; 49: 399-406.
Page A, Kulkarni, A, Mohsenin T, Utilizing deep
neural nets for an embedded ECG-based biometric authentication system. In: Biomedical Circuits
and Systems Conference (BioCAS), 22-24 October,

Atlanta, GA, USA, 2015. p. 1-4.
49. Ashiquzzaman A, Tushar AK, Islam MR, Shon D, Im
K, Park JH et al. Reduction of Overfitting in Diabetes
Prediction Using Deep Learning Neural Network.
In: IT Convergence and Security 2017. Singapore:
Sringer; 2018; p. 35-43.
50. Shashikumar SP, Shah AJ, Li Q, Clifford GD, Nemati
S, A deep learning approach to monitoring and detecting atrial fibrillation using wearable technology. In:
IEEE EMBS International Conference of Biomedical
& Health Informatics (BHI), 4-7 March, Las Vegas,
Nevada, USA, p. 141-144.
51. Jindal V, Birjandtalab J, Pouyan MB, Nourani M, An
adaptive deep learning approach for PPG-based identification. In: 38th Annual International Conference
of the Engineering in Medicine and Biology Society
(EMBC), 17-20 August, Lake Buena Vista, Orlando,
USA, 2016. p. 6401-6404.
52. Ruiz-Rodríguez JC, Ruiz-Sanmartín A, Ribas V,
Caballero J, García-Roche A, Riera J et al. Innovative
continuous non-invasive cuffless blood pressure monitoring based on photoplethysmography technology.
Intensive care medicine. 2013; 39(9): 1618-1625.
53. Ordóñez FJ, Roggen D. Deep convolutional and lstm
recurrent neural networks for multimodal wearable
activity recognition. Sensors. 2016; 16(1): 1-25.
54. Saeedi R, Norgaard S, Gebremedhin AH. A closed-loop deep learning architecture for robust activity recognition using wearable sensors. In: IEEE International
Conference on Big Data. 11-14 December, Boston,
MA, USA, 2017; p. 473-479.
55. Bhattacharya S, Lane ND. From smart to deep:
Robust activity recognition on smartwatches using
deep learning. In: IEEE International Conference
on Pervasive Computing and Communication
Workshops (PerCom Workshops). 14-18 March,
Sydney, Australia, 2016; pp. 1-6.
56. Ronao CA, Cho SB. Human activity recognition
with smartphone sensors using deep learning neural
networks. Expert Systems with Applications. 2016;
59: 235-244.
57. Ravi D, Wong C, Lo B, Yang GZ. cs. In: 13th
International Conference on Wearable and
Implantable Body Sensor Networks (BSN). 14-17
June, San Francisco, CA, USA, 2016; p. 71-76.
58. Eskofier BM, Lee SI, Daneault JF, Golabchi FN,
Ferreira-Carvalho G, Vergara-Diaz G. et al. Recent
machine learning advancements in sensor-based
mobility analysis: deep learning for Parkinson’s disease assessment. In: IEEE 38th Annual International
Conference of the Engineering in Medicine and
Biology Society (EMBC). 17-20 August, Lake Buena
Vista, Orlando, USA, 2016; p. 655-658.
59. Ravì D, Wong C, Deligianni F, Berthelot M, AndreuPerez J, Lo B, Yang GZ. Deep learning for health informatics. IEEE journal of biomedical and health informatics, 2017; 21(1): 4-21.
60. Miotto R, Wang F, Wang S, Jiang X, Dudley JT. Deep

Medicinski podmladak / Medical Youth

23

Janković M. et al. Deep learning approaches for human activity recognition using wearable technology. MedPodml 2018, 69(3):14-24

learning for healthcare: review, opportunities and
challenges. Briefings in bioinformatics. 2017; 1-11.
61. Faust O, Hagiwara Y, Hong TJ, Lih OS, Acharya UR.
Deep learning for healthcare applications based on
physiological signals: a review. Computer methods
and programs in biomedicine. 2018; 1-31.
62. Lane ND, Georgiev P. Can deep learning revolutionize mobile sensing? In: Proceedings of the 16th
International Workshop on Mobile Computing
Systems and Applications. 12-13 February, Santa Fe,
NM, USA, 2015; p. 117-122.
63. Yao S, Hu S, Zhao Y, Zhang A, Abdelzaher T.

24

Deepsense: A unified deep learning framework
for time-series mobile sensing data processing. In:
Proceedings of the 26th International Conference on
World Wide Web. 3-7 April, Perth, Australia, 2017; p.
351-360.
64. Lane ND, Bhattacharya S, Georgiev P, Forlivesi C, Jiao
L, Qendro L, Kawsar F. Deepx: A software accelerator
for low-power deep learning inference on mobile devices. In: 15th ACM/IEEE International Conference
on Information Processing in Sensor Networks
(IPSN). 11-14 April, Vienna, Austria, 2016; p. 1-12.

Medicinski podmladak / Medical Youth

