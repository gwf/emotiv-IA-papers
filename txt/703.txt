Institut für Visualisierung und Interaktive Systeme
Universität Stuttgart
Universitätsstraße 38
D–70569 Stuttgart

Fachstudie Nr. 161

Evaluation der Möglichkeiten
aktueller
Brain-Computer-Interfaces
Christoph Haag

Sascha Meusel

Frieder Schüler

Studiengang:

Softwaretechnik

Prüfer:

Prof. Dr. Albrecht Schmidt

Betreuer:

Dipl.-Inf. Bastian Pfleging
M. Sc. Alireza Samahi

begonnen am:

18. Juni 2012

beendet am:

18. Dezember 2012

CR-Klassifikation:

H.5.2

Kurzfassung
Im Rahmen der Weiterentwicklung der Interaktion zwischen Menschen und Computern
werden immer neue sogenannte Brain-Computer-Interfaces (BCI) entwickelt die es ermöglichen sollen, mittels Elektroenzephalografie (EEG), Steuersignale direkt vom Gehirn zu einem
Computer zu übertragen. Diese Arbeit vergleicht zwei für den Endverbraucher bestimmten
Brain-Computer-Interfaces und testet ihre Eignung in einem praxisnahen Anwendungsszenario.

3

Inhaltsverzeichnis
1
2

Einleitung
Anwendungsbereiche von Brain-Computer-Interfaces

2.1
2.2
2.3
3

3.3

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

Das EIToolkit . . . . . . . . . . . . . . . . . . . . . .
Integration des Emotiv Epoc in das EIToolkit . . . .
Integration des Neurosky Mindset in das EIToolkit
5.3.1 Überlegungen . . . . . . . . . . . . . . . . . .
5.3.2 Umsetzung . . . . . . . . . . . . . . . . . . .
5.3.3 Daten des Neurosky Mindset . . . . . . . . .

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

Emotiv SDK . . . . . . . . . . .
ThinkGear Connector . . . . . .
4.2.1 Dokumentation . . . . .
4.2.2 Verfügbare Programme
4.2.3 Plattform-Abhängigkeit

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

23
24
24
25
25
27

27
27
30
30
31
32
33

Vergleichsbasis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
Anwendungsszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
Fazit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35

Fazit und Ausblick

7.1
7.2

15
19
19
19
21
23

.
.
.
.
.

Evaluation in einem Anwendungsszenario

6.1
6.2
6.3
7

.
.
.
.
.

Integration in das EIToolkit

5.1
5.2
5.3

6

15

Emotiv Epoc . . . . . . . . . . . . . . . . .
ThinkGear von NeuroSky . . . . . . . . .
3.2.1 eSense Meters . . . . . . . . . . . .
3.2.2 MindSet von NeuroSky . . . . . .
Vergleich der Fähigkeiten der Hardware .

Software

4.1
4.2

5

11

Neuroprothesen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
Endverbraucher-Elektronik . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
Software und Unterhaltungsmedien . . . . . . . . . . . . . . . . . . . . . . . . . 12

Hardware

3.1
3.2

4

9

37

Fazit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
Ausblick . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

5

Literaturverzeichnis

6

39

Abbildungsverzeichnis
3.1
3.2
3.3

Bild des Emotiv Epoc Headsets . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
Elektrodenverteilung des Emotiv Epoc Neuroheadsets . . . . . . . . . . . . . . 17
Bild des Neurosky Mindset Headsets . . . . . . . . . . . . . . . . . . . . . . . . 20

6.1
6.2

Screenshot von Supertux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
Emotiv SDK: Verlauf der affektiven Zustände nach der Zeit . . . . . . . . . . . 36

Verzeichnis der Listings
5.1
5.2
5.3
5.4
5.5

Emotiv SDK: Kognitive Aktionen . . . . . . .
Emotiv SDK: Expressive Aktionen . . . . . .
Emotiv SDK: Affektive Zustände . . . . . . .
Verbindungsmöglichkeiten zum Emotiv SDK
Mindset: über das EIToolkit gesendete Daten

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

28
28
29
30
32

7

1 Einleitung
Im Rahmen der Weiterentwicklung der Interaktion zwischen Menschen und Computern
geht die Forschung inzwischen weit über traditionelle Eingabegeräte wie Tastatur und
Maus hinaus. Immer neuere Geräte werden eingesetzt, mit deren Hilfe dem Anwender eine
einfachere und intuitivere Interaktion mit elektronischen Geräten ermöglicht werden soll.
Einer der neueren Trends ist hierbei die Verwendung von Brain-Computer-Interfaces (BCI).
Diese versprechen eine direkte Abbildung der gemessenen Elektroenzephalografiedaten
(EEG) auf im Computer verwendbare Steuersignale. So können Steuersignale ohne die
Aktivierung des peripheren Nervensystems, wie zum Beispiel das Bewegen einer Extremität,
erzeugt werden.
Ziel dieser Fachstudie ist die Untersuchung verschiedener Brain-Computer-Interfaces im
Konsumentenbereich. Im Einzelnen werden dabei das “Emotiv Epoc” und das “Neurosky
Mindset” näher untersucht. Die einzelnen Geräte werden dabei unter verschiedenen Gesichtspunkten untersucht: Es werden sowohl die technischen Daten der Geräte miteinander
verglichen, als auch die Qualität und Quantität der Daten und damit die Möglichkeiten der
Erfassung von verschiedenen Interaktionen, sowie die Einbindung dieser Interaktionen in
ein Anwendungsszenario.
Um die Benutzung und den Vergleich beider Geräte zu vereinfachen, werden beide Geräte in
das bereits zur Verfügung stehende EIToolkit der Universität Stuttgart eingebunden. Dieses
Toolkit ermöglicht eine einfachere Handhabung, eine bessere Visualisierung über zusätzliche
Software und die Verteilung der Daten über ein Netzwerk. So können die von den beiden
BCI-Geräten erhaltenen Daten auf eine gemeinsame Basis gebracht werden und diese dann
an Hand des Anwendungsszenarios evaluiert werden. Das Anwendungsszenario besteht aus
der Steuerung einer Spielfigur in einem Jump’n’Run Spiel, wobei die Tastatureingaben des
Spielers ganz oder teilweise durch die von den BCI-Geräten erhaltenen Steuerungsbefehlen
ersetzt werden.

9

1 Einleitung

Gliederung
Die Arbeit ist in folgender Weise gegliedert:
Kapitel 1 – Einleitung: enthält die Einleitung und den Überblick über die Gliederung
Kapitel 2 – Anwendungsbereiche von Brain-Computer-Interfaces: geht auf die bisherigen

Anwendungsbereiche und die Verbreitung von BCIs ein.
Kapitel 3 – Hardware: stellt die beiden zu vergleichenden BCI-Geräte vor. Anschließend wer-

den die Geräte miteinander verglichen und auf Unterschiede sowie Gemeinsamkeiten
untersucht.
Kapitel 4 – Software: untersucht die Möglichkeiten der mit den BCI-Geräten mitgelieferten

Software. Dabei werden die einzelnen Werkzeuge und Anwendungen hinsichtlich ihres
Funktionsumfangs und Nutzens untersucht.
Kapitel 5 – Integration in das EIToolkit: behandelt die Integration der Geräte in das von der

Universität Stuttgart zur Verfügung gestellte EIToolkit
Kapitel 6 – Evaluation in einem Anwendungsszenario: stellt zuerst das Anwendungsszena-

rio vor, in dem die beiden Geräte evaluiert werden. Anschließend wird die Umsetzung
des Szenarios mit beiden Geräten beschrieben. Zum Schluss werden die Ergebnisse
der Evaluation zusammengefasst.
Kapitel 7 – Fazit und Ausblick fasst die Ergebnisse der Arbeit zusammen und stellt Anknüp-

fungspunkte vor.

10

2 Anwendungsbereiche von
Brain-Computer-Interfaces
Brain-Computer-Interfaces (BCI) werden bereits in zahlreichen verschiedene Szenarien eingesetzt. Allerdings unterscheiden sich die Nutzungsszenarien von BCIs hinsichtlich Komplexität und Einsatzzweck deutlich. Besonders verbreitet ist der Einsatz von BCIs bei der
Unterstützung von behinderten Menschen, da diesen Menschen der Einsatz des peripheren
Nervensystems, wie zum Beispiel die Nutzung der Extremitäten, nur eingeschränkt oder gar
nicht möglich ist.
Es gibt allerdings auch andere Anwendungsbereiche wie Endverbraucher-Elektronik oder
Unterhaltungsmedien wie Filme oder Computerspiele. Die Verbreitung von BCIs ist hier
allerdings deutlich geringer, da konventionelle Eingabemethoden zum jetzigen Zeitpunkt
meist einfacher, schneller, genauer und nicht zuletzt erheblich günstiger sind. In den folgenden Abschnitten wird kurz auf die Verwendung von BCIs in den einzelnen Bereichen
eingegangen.
Bei wieder anderen Einsatzbereichen wie die Bedienung von großen Maschinen wie zum
Beispiel Traktoren[GGSJGNAAG11] ist zweifelhaft, dass diese Systeme schon den entsprechenden Sicherheitsanforderungen genügen.

2.1 Neuroprothesen
Unter Neuroprothesen sind Geräte und Maschinen zu verstehen, die in direkter Weise mit
dem Nervensystem des Menschen interagieren. Unter den zwei Klassen “sensorische Neuroprothesen” und “motorische Neuroprothesen” werden BCI hauptsächlich für motorische
Prothesen verwendet, die durch Impulse aus dem Nervensystem direkt gesteuert werden.
Beispiele für einen diesbezüglichen Einsatz von BCIs in Verbindung mit PCs sind die
Steuerung des Mauszeigers[GNC+ ] oder gar der Tastatureingaben.
Des Weiteren ermöglichen es BCIs körperlich stark behinderten bzw. querschnittsgelähmten
Menschen die Bedienung von Rollstühlen oder anderen Maschinen.

11

2 Anwendungsbereiche von Brain-Computer-Interfaces

2.2 Endverbraucher-Elektronik
BCIs werden auch für elektronische Artikel eingesetzt, die für Endverbraucher konzipiert
sind. Über viele solcher Systeme sind wissenschaftliche Arbeiten veröffentlicht worden.
Ein Bereich der Forschung ist die Steuerung von humanoiden Robotern[TKS10] [GDK+ 11]
zum Beispiel zur Anwendung für “Telepräsenz”. Eines der Projekte, die sich mit dieser Form
der Interaktion mit Robotern beschäftigen, ist das VERE Project1 , von dem auch der Artikel
[GDK+ 11] ausgeht (Der Artikel ist ein Bericht über den aktuellen Stand der Forschung des
Projekts). Dieses Projekt verwendet allerdings mit dem g.BCIsys2 ein sehr professionelles
BCI-System.
Weitere Beispiele für die Anwendung von BCIs für Endverbraucher sind Modellbau-Artikel
wie Modellhelikopter oder Lego Mindstorms. Einer der vielversprechenden SoftwareEntwickler in diesem Bereich ist Puzzlebox mit dem Programm “Puzzlebox Brainstorms”3 ,
das für die Steuerung von Modellhubschraubern, Lego Mindstorms Robotern, Ferngesteuerten Modellautos und elektrischen Rollstühlen eingesetzt werden kann. Dabei unterstützt die
Software Neurosky Mindset, Neuroset Mindwave und das Emotiv Epoc BCI. Das Software
Paket ist unter aktiver Entwicklung. So wurde im Dezember 2012 mit großem Erfolg die
Finanzierung eines eigenen Modellhubschrauber-Modells mittels der Projektfinanzierungsplattform Kickstarter gesichert4 .

2.3 Software und Unterhaltungsmedien
Eine weitere Anwendungsmöglichkeit ist der Bereich der Unterhaltungsmedien wie Filme
oder Computerspiele.[SVT10]
Die Firma Neurosky, die eines der in dieser Arbeit verglichenen BCIs herstellt, arbeitet mit
der Firma Myndplay zusammen. Myndplay vermarktet unter anderem einen Mediaplayer
in Verbindung mit Videos und Filmen, die sich je nach Gemütszustand des Betrachters
verändern5 .
Sowohl Neurosky selbst als auch Emotiv vermarkten Softwareprodukte. Beispiele für die
von Emotiv vermarktete Software sind Fotobetrachter, Spiele und die Barrierefreiheit unterstützende Software6 . Beispiele für die von Neurosky vermarktete Software sind “mentale
Trainingsprogramme” und Spiele7 .

1 http://www.vereproject.eu/
2 http://www.gtec.at/Products/Complete-Solutions/g.BCIsys-Specs-Features
3 http://brainstorms.puzzlebox.info/static.php?page=downloads
4 http://www.kickstarter.com/projects/puzzlebox/puzzlebox-orbit-brain-controlled-helicopter
5 http://www.myndplay.com/videos.php
6 http://www.emotiv.com/store/#app
7 http://store.neurosky.com/collections/applications

12

2.3 Software und Unterhaltungsmedien

Emotiv unterstützt zudem aktiv die Forschung mit BCIs und bewirbt auf ihrer Webseite
zahlreiche Veröffentlichungen zu BCIs allgemein8 sowie zu Veröffentlichungen, die speziell
das Emotiv Epoc BCI verwenden9 .

8 http://www.emotiv.com/ideas/eeg.php
9 http://www.emotiv.com/ideas/epoc.php

13

3 Hardware
Die zu untersuchende BCI-Hardware entstammt dem Endverbrauchermarkt und ist im freien
Handel erhältlich. Damit unterscheidet sie sich von Speziallösungen, wie sie zum Beispiel
im medizinischen Bereich verwendet werden, hinsichtlich Verfügbarkeit, Genauigkeit und
Preis.

3.1 Emotiv Epoc
Das Emotiv Epoc Headset ist ein BCI, das mit 14 mit einer Salzlösung angefeuchteten Sensoren, sowie zwei Referenzsensoren arbeitet. Die Verteilung der Sensoren mit den StandardEEG-Bezeichnungen ist in Abbildung 3.2 dargestellt.
Eine Version mit trockener Signalabnahme ist in Planung, aber zur Zeit dieser Fachstudie
noch nicht fertig gestellt.
Zusätzlich zu den EEG-Sensoren ist in das Epoc Headset ein Gyroskop eingebaut, das alle
möglichen Kopfbewegungen erkennt und zum Beispiel die Steuerung eines Mauszeigers
erleichtert.
Bei der Übertragung des Signals an den Computer findet ein proprietäres, verschlüsseltes
Funkprotokoll Verwendung, so dass der mitgelieferte USB-Dongle benötigt wird, um das
Headset zu verwenden.
Tabelle 3.1 zeigt die vollständige von Emotiv angegebene Spezifikation1 der Hardware.

1 http://www.emotiv.com/upload/manual/sdk/EPOCSpecifications.pdf

15

3 Hardware

Abbildung 3.1: Bild des Emotiv Epoc Headsets
Quelle:http://www.emotiv.com/upload/media/1_big.jpg

16

3.1 Emotiv Epoc

Abbildung 3.2: Elektrodenverteilung des Emotiv Epoc Neuroheadsets
Quelle: Emotiv-Forum:
http://www.emotiv.com/bitrix/components/bitrix/forum.interface/
show_file.php?fid=1529

17

3 Hardware

Number of channels
Channel names (International 10-20 locations)
Sampling method
Sampling rate
Resolution
Bandwidth
Filtering
Dynamic range (input referred)
Coupling mode
Connectivity
Power
Battery life (typical)
Impedance Measurement

Tabelle 3.1: Spezifikation des Emotiv Epoc

18

14 (plus CMS/DRL references, P3/P4
locations)
AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8,
FC6, F4, F8, AF4
Sequential sampling. Single ADC
128 SPS (2048 Hz internal)
14 bits 1 LSB = 0.51µV (16 bit ADC, 2
bits instrumental noise floor discarded)
0.2 - 45Hz, digital notch filters at 50Hz
and 60Hz
Built in digital 5th order Sinc filter
8400µV (pp)
AC coupled
Proprietary wireless, 2.4GHz band
LiPoly
12 hours
Real-time contact quality using patented
system

3.2 ThinkGear von NeuroSky

3.2 ThinkGear von NeuroSky
Die folgenden Informationen zum ThinkGear sind überwiegend aus der NeuroSky Mindest
Instruction Manual2 entnommen (Vgl. Kapitel 2: NeuroSky Technology Overview und
Kapitel 3: Setting Up Yout MindSet).
Die Technologie von NeuroSky hat den Namen ThinkGear. ThinkGear-Geräte haben im
wesentlichen gemeinsam, dass sie einen Sensor an der Stirn sowie Referenz- und Kontaktpunkte am Ohr haben. Die Sensoren und Kontakte funktionieren alle auf trockener Basis, die
Sensoren und Kontakte werden also nicht befeuchtet. Die Geräte berechnen die EEG-Daten
und die sogenanten eSense Meters, welche dann üblicherweise über Bluetooth diese Daten
versenden, wie bei den uns vorliegenden Geräten MindSet von NeuroSky und BrainBand
von MyndPlay.
Das BrainBand wird in dieser Arbeit nicht näher betrachtet. Bezüglich der BCI-Technologie
ist es von der Funktionalität mit dem MindSet gleichwertig, das BrainBand hat aber keine
Nicht-BCI-Funktionalität wie ein Mikrofon und Kopfhörer beim MindSet. Eventuell ist
außerdem die Qualität der gelieferten EEG- und eSense-Daten anders.

3.2.1 eSense Meters
Bei den eSense Meters handelt es sich um Werte, die über einen Algorithmus von NeuroSky
namens eSense berechnet werden. ThinkGear verfügt über zwei verschiedene eSense Meters:
Attention und Meditation. Der Attention-Wert soll den ungefähren Konzentrationsgrad, der
Meditation-Wert soll den ungefähren Entspannungswert des Benutzers wiedergeben.

3.2.2 MindSet von NeuroSky
Das MindSet ist ein Headset, welches anstatt eines Mikrofon-Armes einen Sensor-Arm in
ungefähr der Höhe der Stirn des menschlichen Kopfes hat. Am Ende des Armes ist ein
einzelner Sensor für die Messungen der Gehirnwellen angebracht. Auf einer KopfhörerMuschel sind drei Ohr-Kontakte angebracht, die für die Gehirnwellenmessung benötigt
werden. Außerdem besitzt das MindSet ein Mikrofon an einer der Kopfhörer-Muscheln,
wodurch das MindSet auch zusätzlich als gewöhnliches Headset genutzt werden kann. Diese
Headset-Funktionalität wurde in dieser Arbeit aber nicht weiter betrachtet.

2 http://developer.neurosky.com/docs/doku.php?id=mindset

19

3 Hardware

Abbildung 3.3: Bild des Neurosky Mindeset Headsets
Quelle:http://www.ballantinespr.com/NeuroTemp/Media/Mindset/
NeuroSky_MindSetWhiteEnviron.jpg
20

3.3 Vergleich der Fähigkeiten der Hardware

3.3 Vergleich der Fähigkeiten der Hardware
Das MindSet ist in der Verwendung deutlich unkomplizierter als das Emotiv Epoc. Das
MindSet ist dank seiner Headset-Form intuitiv nutzbar und besitzt außerdem wie ein
gewöhnliches Headset Mikrofon und Kopfhörer. Allerdings gibt es nur einen Sensor für die
Gehirnwellen, wodurch fraglich ist, wie hoch die Qualität der so erhaltenen Daten ist.
Das Emotiv Epoc hat keine Headset-Funktionalität und ist durch die vielen Elektroden
ungewohnt zu tragen. Die Elektroden müssen vor jeder Benutzung mit einer Art Kochsalzlösung angefeuchtet werden und müssen richtig auf dem Kopf des Benutzers positioniert
werden. Dabei handelt es sich um eine Feinjustierung, die grobe Position der Elektroden
ist durch die Bauform des Gerätes schon vorgegeben. Hauptsächlich muss man bei der
Feinjustierung die Haare zwischen Elektroden und Kopfhaut wegbewegen und mit Hilfe des
EmotivControlPanel überprüfen, ob das Signal der Elektroden schon gut genug ist. Wenn
dies noch nicht der Fall ist, muss man die jeweiligen Elektroden etwas herumbewegen bis die
gewünschte Signal-Qualität erreicht ist. Dadurch ist das Emotiv Epoc deutlich aufwändiger
in der Benutzung als das MindSet. Allerdings könnten durch die höhere Elektrodenanzahl
die vom Emotiv Epoc gelieferten Daten brauchbarer sein als beim MindSet.
Einen sinnvollen Vergleich der Daten-Qualität auf EEG-Ebene konnten wir aufgrund fehlendem Fachwissen im Bereich von EEG-Daten nicht durchführen. Da die beiden Geräte aber
auch eigene Werte auf Basis der EEG-Daten berechnen, können wir diese berechneten Werte
betrachten und einschätzen, inwiefern die Werte jeweils für sich genommen nützlich sind.

21

4 Software
4.1 Emotiv SDK
Das Emotiv SDK kommt mit einer 76-seitigen Anleitung mit ausführlicher Dokumentation
der vier enthaltenen Hilfsprogramme und der API. Zudem enthält es Prgrammierbeispiele
in den Programmiersprachen C++ (unter der Verwendung von Qt) und Java (unter der
Verwendung des JNI Wrappers für native Bibliotheken).
Das Emotiv SDK enthält folgende Programme:
• TestBench - Ein Programm, das die Daten des Epoc Headsets (EEG, Gyroskop, etc.)
ausführlich darstellt.
• Emokey - Ein Emulator für Maus- und Tastatureingaben, auf die man die verschiedenen
Outputs des Epoc Headsets mappen kann.
• EmoComposer - Ein Emulator, mit dem Programme einfach getestet werden können,
die mit dem Emotiv SDK entwickelt wurden.
• EmotivControlPanel - Ein zentrales Verwaltungsinstrument, um Trainingsdaten zu
erstellen, zu testen und mit dem Emotiv SDK erstellten Programmen zur Verfügung
zu stellen.
Leider ist das Emotiv SDK laut inoffizieller Aussage im Emotiv Forum aufgrund der verwendeten Mathematik-Bibliotheken nur als 32-Bit Version verfügbar.1
Das Emotiv SDK besteht aus Programmierersicht aus zwei umfangreichen C++ Bibliotheken
und mehreren Header-Dateien. Werden diese beiden Bibliotheken gegen die eigene Software gelinkt, steht der gesamte Funktionsumfang des Emotiv SDK und der mitgelieferten
Hilfsprogramme zur Verfügung.
Das Emotiv SDK übernimmt in großem Maße die Signalverarbeitung der einzelnen Sensoren.
Es bietet ein Mapping von Signalen auf kognitive Aktionen wie “Push”, “Pull”, “Left”
oder “Right” an. Der Programmierer kann den Trainingsschritt, der für das erstellen dieses
Mappings notwendig ist, durch das Emotiv Control Panel durchführen oder direkt dafür
vom Emotiv SDK angebotene Funktionen benutzen. Das Emotiv Control Center verwaltet
diese Trainingsdaten anschließend auch (Anlegen, Speichern, Zuordnen zu verschiedenen
Benutzern, etc.) und führt eventuelle langfristige Anpassungen und Kalibrierungen durch.

1 http://emotiv.com/forum/messages/forum4/topic97/message14143/#message14143

23

4 Software

Desweiteren ermittelt das Emotiv SDK ohne Trainingsschritt affektive Zustände wie unter
Anderem “Meditation” und “Excitement/Boredom”, expressive Aktionen wie Gesichtsausdrücke, sowie die Daten des Gyroskops.

4.2 ThinkGear Connector
Der ThinkGear Connector ist eine von NeuroSky bereitgestellte Software, welche die über
Bluetooth empfangenen MindSet-Daten über eine Network-Socket-Verbindung sendet. Dies
ist grundsätzlich sehr praktisch, da viele Programmiersprachen und Plattformen NetworkSockets unterstützen.

4.2.1 Dokumentation
Informationen zur Funktionsweise des ThinkGear Connector kann man auf der entsprechenden Webseite2 von NeuroSky finden. Dort gibt es drei PDF-Dateien:
• ThinkGear Connector Development Guide
• ThinkGear Connector User’s Guide
• ThinkGear Socket Protocol
ThinkGear Connector Development Guide

Der ThinkGear Connector Development Guide ist sehr kurz gehalten und verweist auf den
User’s Guide sowie auf das Socket Protocol. Es wird kurz das Prinzip der Socket-Schnittstelle
erklärt und es werden die nötigen Verbindungsdaten für die Socket-Verbindung erwähnt:
• IP Adresse: 127.0.0.1
• Port: 13854
• Protokoll: TCP
Ansonsten finden sich noch Informationen für Flash-Anwendungen, auf die wir nicht weiter
eingehen werden.
ThinkGear Connector User Guide

Der ThinkGear Connector User Guide ist für insbesondere für die Endverbraucher des
MindSets gedacht. Die Anleitung erklärt, wie der ThinkGear Connector zu benutzen ist. So
wird dazu geraten, zuerst das MindSet per Bluetooth mit dem Betriebssystem zu verbinden,
und dann erst den Connector zu starten. Danach kann man dann Software verwenden, die
den ThinkGear Connector nutzt.
2 http://developer.neurosky.com/docs/doku.php?id=thinkgear_connector_tgc

24

4.2 ThinkGear Connector
ThinkGear Socket Protocol

Die PDF ThinkGear Socket Protocol beschäftigt sich mit dem Format der Daten, die der
ThinkGear Connector sendet. Der ThinkGear Connector überträgt die Daten entweder in
einem Binär-Paket-Format oder in einem JSON-Format. Über das Socket-Protokoll kann der
Client per Socket-Verbindung konfigurieren, in welchem Format der ThinkGear Connector
die Daten an den Client senden soll.

4.2.2 Verfügbare Programme
Auf der ThinkGear Connector Webseite von NeuroSky finden sich auch Links zu den ausführbaren ThinkGear-Connector-Dateien der beiden Plattformen Windows und Mac sowie Links
zu den benötigten Frameworks .NET Framework 3.5 für Windows und MonoFramework für
Mac.
Die Seite verweist für Linux-Entwickler auch auf den ThinkGear Emulator vom Entwickler Puzzlebox. Der ThinkGear Emulator scheint nach der Beschreibung auf der verlinkten
Puzzlebox-Webseite3 die Funktionalität des ThinkGear Connectors abzubilden. Der ThinkGear Emulator von Puzzlebox wird aber nicht mehr als eigenständiges Programm zum
Download angeboten. Stattdessen sind auf der Internet-Präsenz von Puzzlebox4 die Programme Puzzlebox Synapse und Puzzlebox Brainstorms verfügbar.
Puzzlebox Synapse5 soll unter anderem die Funktionalität des ThinkGear Connector abbilden.
Das Programm ist für Windows, Linux (als RPM-Package) und als Quellcode verfügbar.
Puzzlebox Brainstorms6 ist ein Programm zur Steuerung von ferngesteuerten Helikoptern,
elektrischen Rollstühlen und Roboter-Fahrzeugen wie zum Beispiel von LEGO Mindstorms.
Das Programm verwendet bei NeuroSky-Geräten je nach Wahl des Benutzers entweder
Puzzlebox Synapse oder den ThinkGear Connector als EEG-Daten-Quelle. Brainstorms ist
für Windows, Linux (als RPM-Package), Macintosh OS X und als Quellcode verfügbar.

4.2.3 Plattform-Abhängigkeit
Der ThinkGear Connector hat bezüglich der Plattform-Unabhängigkeit zwei Nachteile.
Erstens ist der ThinkGear Connector nur auf den Systemen Windows und Mac verfügbar.
Zweitens nimmt der ThinkGear Connector wohl nur Socket-Verbindungen von Localhost
an, also Verbindungen vom gleichen Rechner. Aus Gründen der Sicherheit und Datenschutz
mag dies sinnvoll sein. Leider ist es aber so nicht ohne weiteres möglich, den ThinkGear

3 http://brainstorms.puzzlebox.info/index.php?entry=entry100802-202304
4 http://brainstorms.puzzlebox.info/static.php?page=downloads
5 http://brainstorms.puzzlebox.info/index.php?entry=Puzzlebox-Synapse-version-0.4.2-released
6 http://brainstorms.puzzlebox.info/index.php?entry=Puzzlebox-Brainstorms-0.6.0-Released

25

4 Software

Connector auf einem Windows- oder Mac-Betriebssystem laufen zu lassen und dann von
einem anderem Betriebssystem wie zum Beispiel Linux die MindSet-Daten zu nutzen.
Über Umwege lässt sich der ThinkGear Connector eventuell trotzdem auf anderen Plattformen nutzen. So wäre es denkbar, über Netzwerk-Tools für den ThinkGear Connector
die Socket-Anfragen anderer Rechner wie Localhost-Anfragen aussehen zu lassen. Dies
wäre wahrscheinlich über einen SSH-Tunnel machbar. Außerdem könnte man auf LinuxBetriebssystemen über Wine den ThinkGear Connector ausführen. Dabei muss man darauf
achten, dass die Bluetooth-Kommunikation an den über Wine ausgeführten ThinkGear
Connector weitergeleitet wird.
Bei den Puzzlebox-Programmen sind wir bei der Benutzung unter Linux auf Probleme
gestoßen und konnten wegen der unzureichenden Dokumentation nicht herausfinden, wieso
die Probleme auftraten.

26

5 Integration in das EIToolkit
5.1 Das EIToolkit
Das EI-Toolkit ist ein Framework, dass von der Universität Stuttgart entwickelt wurde.
Es dient der Entwicklung von lose gekoppelten Prototypen für Pervasive-ComputingAnwendungen. Dazu bietet es eine Plattform für die Kommunikation von verschiedenen
Geräten und Softwaresystemen über ein Netzwerk.
Hierfür bietet es kompakte und leicht verständliche Schnittstellen an, die verschiedene
Programmiersprachen unterstützen. Es existieren Implementierungen für C++, C# und Java.
Durch diese Schnittstellen ergeben sich kaum Einschränkungen für die eingesetzte Soft- oder
Hardware.
Das Toolkit ist darauf ausgelegt Nachrichten von verschiedenen Sendern und Empfängern
mit möglichst geringer Latenz und einem hohen Datendurchsatz zu versenden. Durch die
zusätzliche Abstraktionsschicht des Toolkits spielt die Art des Transportmediums keine
Rolle. Es können Nachrichten über LANs oder WLANs versendet werden, aber auch das
Versenden über Bluetooth ist möglich.
Die einzelnen Geräte können dabei Metadaten bereitstellen die eine Identifizierung ermöglicht und weitere Informationen über das Gerät beinhalten.

5.2 Integration des Emotiv Epoc in das EIToolkit
Das Emotiv SDK stellt die folgenden kognitiven Aktionen zur verfügung, von denen typischerweise nur 3-5 Aktionen trainiert werden, da für jede weiter Aktion die Abgrenzung
zwischen den Aktionen schwieriger wird.

27

5 Integration in das EIToolkit

Listing 5.1 Emotiv SDK: Kognitive Aktionen
typedef enum EE_CognitivAction_enum {
COG_NEUTRAL
COG_PUSH
COG_PULL
COG_LIFT
COG_DROP
COG_LEFT
COG_RIGHT
COG_ROTATE_LEFT
COG_ROTATE_RIGHT
COG_ROTATE_CLOCKWISE
COG_ROTATE_COUNTER_CLOCKWISE
COG_ROTATE_FORWARDS
COG_ROTATE_REVERSE
COG_DISAPPEAR

=
=
=
=
=
=
=
=
=
=
=
=
=
=

0x0001,
0x0002,
0x0004,
0x0008,
0x0010,
0x0020,
0x0040,
0x0080,
0x0100,
0x0200,
0x0400,
0x0800,
0x1000,
0x2000

} EE_CognitivAction_t;

Weitere Aktionen, die das Emotiv SDK anbietet sind expressive Aktionen:
Listing 5.2 Emotiv SDK: Expressive Aktionen
typedef enum EE_ExpressivAlgo_enum {
EXP_NEUTRAL
EXP_BLINK
EXP_WINK_LEFT
EXP_WINK_RIGHT
EXP_HORIEYE
EXP_EYEBROW
EXP_FURROW
EXP_SMILE
EXP_CLENCH
EXP_LAUGH
EXP_SMIRK_LEFT
EXP_SMIRK_RIGHT

=
=
=
=
=
=
=
=
=
=
=
=

0x0001,
0x0002,
0x0004,
0x0008,
0x0010,
0x0020,
0x0040,
0x0080,
0x0100,
0x0200,
0x0400,
0x0800

} EE_ExpressivAlgo_t;

Die dritte Klasse von Werten, die das Emotiv SDK anbietet, sind affektive Zustände.

28

5.2 Integration des Emotiv Epoc in das EIToolkit

Listing 5.3 Emotiv SDK: Affektive Zustände
typedef enum EE_AffectivAlgo_enum {
AFF_EXCITEMENT
AFF_MEDITATION
AFF_FRUSTRATION
AFF_ENGAGEMENT_BOREDOM

=
=
=
=

0x0001,
0x0002,
0x0004,
0x0008

} EE_AffectivAlgo_t;

Das Hauptaugenmerk dieser Fachstudie soll auf der Evaluierung des BCI liegen. Dafür sind
einerseits die kognitiven Aktionen sehr gut geeignet, andererseits sind eben diese kognitiven
Aktionen auch ein Alleinstellungsmerkmal des Emotiv SDK. Für einen Vergleich mit dem
BCI von Neurosky sind dagegen die affektiven Zustände geeignet, da diese vom Neurosky
Headset in ähnlicher Form angeboten werden.
Für diese Fachstudie wurden die sowohl die kognitiven Aktionen als auch die affektiven
Zustände in das EIToolkit integriert.
Auslesen der Daten Emotiv Epoc Headsets

Wie in der Auflistung der Emotiv Programme im Abschnitt 4.1 angesprochen, gibt es neben
dem direkten Verbinden mit dem Emulator zwei Möglichkeiten, die Daten des Emotiv Epoc
auszulesen.
1. Das Auslesen der Daten durch eine direkte Verbindung mit der “EmoEngine”
2. Das Auslesen der Daten durch eine Verbindung mit dem “Emotiv Control Panel”
Das Verbinden mit der EmoEngine ermöglicht eine tiefe Integration in die eigene Software,
erfordert aber auch relativ viel Aufwand, da zum Beispiel das Usermanagement und die
Trainingsdaten verwaltet werden müssen.
Das Verbinden mit dem Emotiv Control Panel bietet einerseits die Vorteile, dass der Verwaltungsaufwand vollständig externalisiert wird und nur noch die eigentlichen Aktionen
integriert werden müssen, andererseits ist hierbei die stetige Ausführung einer weiteren
Software neben der eigenen Software erforderlich.
Wir haben uns für die Arbeit mit dem Emotiv Control Panel entschieden, um den Programmieraufwand für diese Fachstudie nicht zu groß werden zu lassen.
Das Emotiv Control Panel und der EmoComposer bieten den Zugriff über die Funktion
EE_EngineRemoteConnect an, die EmoEngine dagegen wird direkt in die Software integriert.
Auf sie kann deshalb direkt mit EE_EngineConnect zugegriffen werden.
Das Emotiv SDK bietet die Daten des Epoc Headsets in Form von EmoEngineEventHandle
an. Leider bietet das SDK keine Methode, blockierend auf das nächste Event zu warten.
Der Aufruf von EE_EngineGetNextEvent(eEvent) kehrt stattdessen mit einem Status ungleich

29

5 Integration in das EIToolkit

Listing 5.4 Verbindungsmöglichkeiten zum Emotiv SDK
EE_EngineRemoteConnect("127.0.0.1", 1726) //EmoComposer
EE_EngineRemoteConnect("127.0.0.1", 3008) //EmotivControlPanel
EE_EngineConnect() //EmoEngine

“EDK_OK” zurück, wenn keine neuen Events vorliegen. Um die Prozessorauslastung nicht
auf 100% zu halten, muss also darauf geachtet werden, nicht so schnell wie möglich nach
neuen Events zu pollen.
Daten zum affektiven Status werden mit jedem Event geliefert, Daten zu kognitiven Aktionen
aber nicht notwendigerweise.
Mittels ES_CognitivGetCurrentAction(eState) wird die kognitive Aktion aus dem Headset ausgelesen, mittels ES_CognitivGetCurrentActionPower(eState) wird die zugehörige “Stärke” der
Aktion ausgelesen.
Die beiden für den Vergleich der Headsets verwendeten Werte werden über folgende
Funktionen ausgelesen:
• ES_AffectivGetMeditationScore(eState)
• ES_AffectivGetEngagementBoredomScore(eState)
In der konkreten Implementation des Emotiv Epoc Stubs wird als Sender Name “Emotiv
SDK Connector” verwendet.
Der bezeichnende String einer Emotiv Aktion bzw. eines Emotiv Zustandes (z.B.
“COG_NEUTRAL” oder AFF_MEDITATION) wird als Schlüssel für vom EIToolkit versendeten Nachrichten verwendet. Die “Stärke” der Aktion wird als Wert im Schlüssel-Wert-Paar
gesendet.

5.3 Integration des Neurosky Mindset in das EIToolkit
5.3.1 Überlegungen
Für die Integration des Mindset in das EIToolkit wollten wir zuerst die vom ThinkGear
Connector gesendeten Daten selber parsen. Da wir die Programmiersprache Java vergleichsweise gut beherrschen und die Socket-Schnittstelle in Java einfach umzusetzen ist, wollten
wir für die Integration Java nutzen. Für das EIToolkit gibt es auch einen Java-Wrapper, die
Integration in Java ist also möglich.

30

5.3 Integration des Neurosky Mindset in das EIToolkit

5.3.2 Umsetzung
Die Implementierung war nicht so einfach, wie es zuerst schien. So gab es Probleme dabei,
den ThinkGear Connector auf das Format JSON zu konfigurieren. Die Dokumentation war
auch nicht ausreichend hilfreich, um alle Probleme zu lösen. Außerdem entdeckten wir,
dass wir die Socket-Verbindung nicht zwischen zwei unterschiedlichen Rechnern aufbauen
konnten. Wir haben dann beschlossen, das Programm auf Windows weiterzuentwickeln.
Wir fanden im Internet praktischerweise ein Java-Programm1 , welches die ThinkGearConnector-Daten parsen kann. Das Programm ist von einem Autor namens Andreas Borg
entwickelt worden und nennt sich ThinkGear Java socket. Die Anwendung ist nach unserer
Interpretation des Quellcodes eigentlich dazu gedacht, über eine weitere Schnittstelle2 in
andere Java-Programme als Bibliothek eingebunden zu werden. Die Schnittstelle wollten wir
jedoch nicht verwenden und haben deshalb nur die für das Parsen zuständigen Code-Teile
in unser Programm übertragen.
Nun galt es, die EIToolkit-Funktionalität in unserem Programm zu verwenden. Das Ziel
war es, die Daten des ThinkGear Connectors, welche grundsätzlich als Schlüssel-Wert-Paare
vorlagen, über das EIToolkit ebenfalls in Form von Schlüssel-Wert-Paaren zu versenden. Um
dies umzusetzen, musste man lediglich jedes Mal, wenn der Parser ein Schlüssel-Wert-Paar
erkennt, über die EIToolkit-API das entsprechende erkannte Schlüssel-Wert-Paar senden.
Wirklich problematisch bei der EIToolkit-Integration war eigentlich nur unsere Unerfahrenheit mit der JNI-Technologie von Java. Bei dem Java-Wrapper für das EIToolkit handelt es
sich um eine JAR-Datei, deren Klassen wir in unserem Programm leicht verwenden konnten.
Der Java-Wrapper selbst benötigt auf Windows zwei für Windows kompilierte, also native
EIToolkit-Bibliotheken (eitoolkit_java.dll und EIToolkit.dll). Der Java-Wrapper nutzt über JNI
die Funktionalität der beiden Bibliotheken.
Die Probleme traten dann beim Ausführen von unserem Programm auf. Bei der Wahl des
JDK mussten wir beachten, dass wir eine 32-Bit-Version verwenden, das Problem war aber
schnell erkannt. Das nächste Problem waren unerfüllte Abhängigkeiten der Bibliotheken.
Das Tool Dependency Walker3 hat bei der Untersuchung der Datei eitoolkit_java.dll das
Fehlen von drei Bibliotheken festgestellt.
Eine der Abhängkeiten wurde durch die Installation vom Microsoft Visual C++ 2010 Redistributable Package (x86)4 behoben. Die anderen Abhängigkeiten sind sogenannte delay-load
dependencies. Im Rahmen unserers Programmes mussten diese Abhängigkeiten nicht erfüllt
werden.
Stattdessen musste darauf geachtet werden, dass zur Ausführungszeit das Betriebssystem
die beiden DLL-Dateien vom EIToolkit findet. Als Entwicklungsumgebung haben wir Eclipse verwendet und im Project-Ordner die DLL-Dateien und JAR-Dateien in einem Ordner
1 https://github.com/borg/ThinkGear-Java-socket
2 https://code.google.com/p/processing/
3 http://www.dependencywalker.com/
4 http://www.microsoft.com/de-de/download/details.aspx?id=5555

31

5 Integration in das EIToolkit

namens lib gespeichert. Der Ordner lib wurde in Eclipse bei der Library eitoolkit_java_jni.jar
auch als Ordner für native Bibliotheken eingetragen. Dies hat aber nicht zur Lösung der Fehlermeldungen ausgereicht. Ein Kopieren der beiden DLL-Dateien in das Wurzel-Verzeichnis
des Eclipse-Projektes behob aber die Fehlermeldungen.

5.3.3 Daten des Neurosky Mindset
Die Daten, die der ThinkGear Connector bereitstellt, kann man in der ThinkGear Socket Protocol Spezifikation nachlesen. Die Daten werden mit den Bezeichnungen über das EIToolkit
gesendet, wie sie im Listing 5.5 zu finden sind.
Listing 5.5 Mindset: über das EIToolkit gesendete Daten
PoorSignal
Attention
Meditation
EEG_Delta
EEG_Theta
EEG_LowAlpha
EEG_HighAlpha
EEG_LowBeta
EEG_HighBeta
EEG_LowGamma
EEG_HighGamma

Die Erweiterung der gesendeten Daten um RawEEG und die Zwinkererkennung ist dann
trivial.

32

6 Evaluation in einem Anwendungsszenario
6.1 Vergleichsbasis
Die NeuroSky BCIs berechnen mit den eSense1 Algorithmen die beiden Werte “attention”
und “meditation” als Integer in einem Wertebereich von [0,100] wobei der spezielle Wert 0
für ein unzureichendes Signal steht.
Dabei bewertet Neurosky die Werte zwischen [1,20] als niedrig, die Werte zwischen [20,40]
als leicht niedrig, die Werte zwischen [40,60] als neutral, die Werte zwischen [60-80] als leicht
erhöht und die Werte zwischen [80,100] als erhöht. Zudem passt sich das Neurosky SDK
mittels lernenden Algorithmen an individuelle Abweichungen von dieser Skala an.
Das Emotiv SDK bietet mit der “affective suite” die entsprechenden Werte “AFF_MEDITATION”
und “AFF_ENGAGEMENT_BOREDOM” als Float Werte zwischen [0,1] an. Die bedeutung
der Höhe der Werte wird zwar nicht genauer beschrieben, es kann aber davon ausgegangen
werden, dass sie vergleichbar mit den Werten des Neurosky SDK sind.

6.2 Anwendungsszenario
Für die Evaluierung der Brain-Computer-Interfaces sollte ein Anwendungsszenario entwickelt werden, in welchem die Brain-Computer-Interfaces zur Steuerung benutzt werden.
Dabei ist zu beachten, dass die Geräte unterschiedlich in ihrer Funktionalität sind. Der
Umfang der Funktionalität des Neurosky Mindsets ist abgesehen von EEG-Daten auf zwei
Parameter begrenzt, dabei handelt es sich um die Werte Attention und Meditation.
Für das Szenario wurde das an Super Mario angelehnte Jump’n’Run Spiel “SuperTux”
verändert, so dass es durch das EIToolkit Eingaben von BCIs entgegennehmen kann.
Der in das Spiel integrierte Empfänger nimmt Nachrichten von Sendern mit Namen “Emotiv
SDK Connector” und “NeuroSky Sender” entgegen. Die Werte des Emotiv SDK werden mit
10 multipliziert und die Werte des NeuroSky Mindset werden durch 10 dividiert. Nachdem
die beiden Ergebnisse in Integer umgewandelt wurden, liegen sie im selben Wertebereich
[0,10], der für unser Szenario ausreichend ist.
Zwei Fragen müssen behandelt werden:

1 http://developer.neurosky.com/docs/doku.php?id=esenses_tm

33

6 Evaluation in einem Anwendungsszenario

Abbildung 6.1: Screenshot von Supertux
1. Wann wird eine Aktion ausgelöst?
2. Welche Aktion wird zum entsprechenden Zeitpunkt ausgelöst?
Der minimale Wert, ab dem eine Aktion ausgelöst werden soll, sollte nicht zu niedrig liegen,
um nicht unabsichtlich Aktionen auszulösen und er sollte nicht zu hoch liegen, um das
Auslösen einer Aktion nicht zu schwierig zu machen. Der untere Wert, ab dem NeuroSkys
eSense Werte als signifikant erhöht betrachtet - 0,8 bzw. 8 im Szenario - wurde als Schranke
gewählt, die sich als sinnvoll herausgestellt hat.
Da “Attention” die einfacher zu erreichende Aktion schien, wurde diese mit der Aktion
“nach rechts laufen” verknüpft.
Für das Szenario wurde ein einfaches Spielfeld erstellt, auf dem die Aktionen angewandt
werden müssen.
Die Implementierung von SuperTux verwendet einen Main-Loop, in dem auf Tastendrücke
gewartet wird. Dies ist mit Polling an die SDL Bibliothek gelöst, die alle Eingaben verwaltet.

34

6.3 Fazit

Die Integration mit dem EIToolkit wurde umgesetzt, indem bei jeder Ankunft eines Pakets am EIToolkit ein SDL_EVENT vom Typ SDL_KEYDOWN bzw. SDL_KEYUP mittels
SDL_PushEvent(&event) in die SDL Bibliothek eingefügt wird. Die SDL_KEYUP Events
werden benötigt, da die Eingaben von SuperTux so umgesetzt sind, dass ein Tastendruck
(“KEY_DOWN”) erhalten bleibt, bis er wieder aufgehoben wird.
Wann ein SDL_KEYUP Event eingefügt werden muss, wird entschieden, indem jeweils für
jede kognitive Aktion bzw. jeden affektiven Zustand der Wert der letzten Aktion bzw. des
letzten Zustands gespeichert wird. Wird vom EIToolkit eine neue Aktion bzw. ein neuer
Zustand empfangen, der unter der Schranke liegt, wird überprüft, ob die letzte Aktion
bzw. der letzte Zustand über der Schranke lag. In diesem Fall wird ein SDL_KEYUP Event
eingefügt. Andernfalls wird es ignoriert.

6.3 Fazit
Durch die größeren Anzahl und besseren Verteilung der Sensoren des Emotiv Epoc liefert es
qualitativ hochwertigere Daten, die weniger zufälligen Schwankungen unterliegen.
Es hat sich herausgestellt, dass die Werte “AFF_MEDITATION” und “AFF_ENGAGEMENT_BOREDOM”
für das Szenario ungeeignet sind. Das Emotiv SDK erzeugt gleichmäßig, weiche Veränderungen dieser Werte statt schneller Änderungen wie in Abbildung 6.2 gezeigt wird.
Dadurch vergehen bis zu 30 Sekunden, bis bei anhaltend starker Konzentration der Wert
“AFF_ENGAGEMENT_BOREDOM” auf ein signifikant hohes Level steigt. Vermutlich sind
die affektiven Zustände dafür vorgesehen, als langfristige Informationsquelle wie Statistiken
verwendet zu werden. Für andere Szenarien wie zum Beispiel semi-automatische Flugsimulatoren, in denen lange, weite Kurven geflogen werden, sind die affektiven Zustände aber
eventuell Nutzbar.
Das NeuroSky Mindset reagiert zwar relativ schnell auf bewusste Änderungen der Konzentration, allerdings unterliegt der Wert starken Schwankungen und verhält sich oft nicht
nachvollziehbar.
Das Emotiv Epoc SDK ist darauf ausgerichtet, dass die kognitiven Aktionen wie “Pull” und
“Push” verwendet werden, um Aktionen auszulösen. Wenn diese Aktionen gut trainiert sind,
sind diese auch schnell einsetzbar. Allerdings ist für eine gute Genauigkeit viel Training
erforderlich.

35

6 Evaluation in einem Anwendungsszenario

Abbildung 6.2: Emotiv SDK: Verlauf der affektiven Zustände nach der Zeit

36

7 Fazit und Ausblick
7.1 Fazit
Das Emotiv Epoc BCI ist in der Anschaffung teurer als die Neurosky Geräte. Das Emotiv
Epoc kostet in der Endanwender-Version ca. 300 Dollar und in der Developer-Version ca. 800
Dollar. Das Neurosky Mindset kostet ca. 200 Dollar. Weitere Produkte von Neurosky wie das
Neurosky MindWave sind mit ca. 100 Dollar noch günstiger.
Das Emotiv Epoc ermittelt dank der größeren Anzahl und besseren Verteilung der Sensoren
Daten von besserer Qualität. Durch das Emotiv Control Panel erhält der Benutzer zudem
eine sehr gute Unterstützung beim optimalen Positionieren der Sensoren. Die Neurosky
BCIs geben zu der Positionierung eine Rückmeldung in Form des PoorSignal-Wertes wieder,
welcher zwischen 200 und 0 liegt.
Das Alleinstellungsmerkmal des Emotiv Epoc ist die Softwareunterstützung durch das SDK
und das Emotiv Control Panel als Front-End für das SDK. Das Halbautomatisierte Lernen
von EEG-Mustern, die auf kognitive Aktionen gemappt werden können, ermöglicht eine
weitreichendere Nutzung des BCI, da nicht nur emotionale Zustände, sondern auch mehrere
willentlich steuerbare Aktionen ausgelöst werden können.

7.2 Ausblick
In dieser Fachstudie wurden nur die Möglichkeiten evaluiert, die die beiden SDKs direkt
bereitstellen. In einem nächsten Schritt könnten die Rohdaten der BCI Headsets verglichen
werden.
Das Neurosky Headset liefert als weitere Datenchannel die EEG-Power-Daten delta, theta,
lowAlpha, highAlpha, lowBeta, highBeta, lowGamma und highGamma.
Aus dem Emotiv SDK können die EEG-Werte Delta, Theta, Alpha und Beta abgelesen
werden.
Hier könnte also die Qualität der einzelnen Messungen verglichen werden, wenn zum
Beispiel beide Headsets gleichzeitig getragen werden.

37

Literaturverzeichnis
[GDK+ 11]

P. GERGONDET, S. DRUON, A. KHEDDAR, C. HINTERMULLER, M. S.
C. GUGER. USING A BRAIN-COMPUTER INTERFACE TO STEER A
HRP-2 HUMANOID ROBOT. IEEE International Conference on Robotics
and Biomimetics (ROBIO), 2011. (Zitiert auf Seite 12)

[GGSJGNAAG11] J. Gomez-Gil, I. San-Jose-Gonzalez, L. Nicolas-Alonso, S. Alonso-Garcia.
Steering a Tractor by Means of an EMG-Based Human-Machine Interface.
Sensors, 11, 7110-7126, 2011. (Zitiert auf Seite 11)
[GNC+ ]

T. J. A. Gilja, V. A. Nuyujukian, P. A. Chestek, C. A. A. Cunningham,
J. P. A. Yu, B. M. A. Fan, J. M. A. Churchland, M. M. A. Kaufman, M. T. A.
Kao, J. C. A. Ryu, S. I. A. Shenoy. Krishna V TI - A high-performance
neural prosthesis enabled by control algorithm design JA - Nat Neurosci
PY - 2012/12//print VL - 15 IS - 12 SP - 1752 EP - 1757 PB - Nature
Publishing Group. URL http://dx.doi.org/10.1038/nn.3265. (Zitiert
auf Seite 11)

[SVT10]

A. SHERSTYUK, D. VINCENT, A. TRESKUNOV. Towards Virtual Reality
games. IEEE Computer Graphics and Applications, vol. 30, no. 2, pp. 93-9,
2010. (Zitiert auf Seite 12)

[TKS10]

A. THOBBI, R. KADAM, W. SHENG. Achieving Remote Presence using
a Humanoid Robot Controlled by a Non-Invasive BCI Device. ICGST
International Journal on Automation, Robotics and Autonomous Systems, Vol
10, Issue I, page 41-45, 2010. (Zitiert auf Seite 12)

Alle URLs wurden zuletzt am 17. 12. 2012 geprüft.

39

Erklärung

Wir versichern, diese Arbeit selbstständig
verfasst zu haben. Wir haben keine anderen als
die angegebenen Quellen benutzt und alle
wörtlich oder sinngemäß aus anderen Werken
übernommene Aussagen als solche
gekennzeichnet. Weder diese Arbeit noch
wesentliche Teile daraus waren bisher
Gegenstand eines anderen Prüfungsverfahrens.
Wir haben diese Arbeit bisher weder teilweise
noch vollständig veröffentlicht. Das
elektronische Exemplar stimmt mit allen
eingereichten Exemplaren überein.

(Christoph Haag

Sascha Meusel

Frieder Schüler)

