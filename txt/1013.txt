Kent Academic Repository
Full text document (pdf)
Citation for published version
Yuvaraj, Rajamanickam and Murugappan, Murugappan and Ibrahim, Norlinah Mohamed and
Omar, Mohd Iqbal and Sundaraj, Kenneth and Mohamad, Khairiyah and Palaniappan, Ramaswamy
and Satiyan, Marimuthu (2014) Emotion classification in Parkinson's disease by higher-order
spectra and power spectrum features using EEG signals: A comparative study. Journal of Integrative

DOI
http://doi.org/10.1142/S021963521450006X

Link to record in KAR
http://kar.kent.ac.uk/48273/

Document Version
Author's Accepted Manuscript

Copyright & reuse
Content in the Kent Academic Repository is made available for research purposes. Unless otherwise stated all
content is protected by copyright and in the absence of an open licence (eg Creative Commons), permissions
for further reuse of content should be sought from the publisher, author or other copyright holder.

Versions of research
The version in the Kent Academic Repository may differ from the final published version.
Users are advised to check http://kar.kent.ac.uk for the status of the paper. Users should always cite the
published version of record.

Enquiries
For any further enquiries regarding the licence status of this document, please contact:
researchsupport@kent.ac.uk
If you believe this document infringes copyright then please contact the KAR admin team with the take-down
information provided at http://kar.kent.ac.uk/contact.html

March 4, 2014

12:16:14pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

Journal of Integrative Neuroscience, Vol. 13, No. 1 (2014) 1â€“32
c Imperial College Press
Â°
DOI: 10.1142/S021963521450006X

Emotion classiÂ¯cation in Parkinson's disease
by higher-order spectra and power spectrum
features using EEG signals: A comparative study
R. Yuvaraj*,Â§, M. Murugappan*, Norlinah Mohamed Ibrahimâ€ ,
Mohd Iqbal Omar*, Kenneth Sundaraj*, Khairiyah Mohamadâ€ ,
R. Palaniappanâ€¡ and M. Satiyan*
*School

of Mechatronic Engineering, University Malaysia Perlis (UniMAP), Malaysia

â€ 

Neurology Unit, Department of Medicine, UKM Medical Center
Kuala Lumpur, Malaysia
â€¡Faculty

of Science and Engineering, University of Wolverhampton, United Kingdom
yuva2257@gmail.com

Â§

[Received 4 January 2014; Accepted 6 February 2014; Published ]
DeÂ¯cits in the ability to process emotions characterize several neuropsychiatric disorders and
are traits of Parkinson's disease (PD), and there is need for a method of quantifying emotion,
which is currently performed by clinical diagnosis. Electroencephalogram (EEG) signals, being
an activity of central nervous system (CNS), can reÂ°ect the underlying true emotional state of a
person. This study applied machine-learning algorithms to categorize EEG emotional states in
PD patients that would classify six basic emotions (happiness and sadness, fear, anger, surprise
and disgust) in comparison with healthy controls (HC). Emotional EEG data were recorded
from 20 PD patients and 20 healthy age-, education level- and sex-matched controls using
multimodal (audio-visual) stimuli. The use of nonlinear features motivated by the higher-order
spectra (HOS) has been reported to be a promising approach to classify the emotional states. In
this work, we made the comparative study of the performance of k-nearest neighbor (kNN) and
support vector machine (SVM) classiÂ¯ers using the features derived from HOS and from the
power spectrum. Analysis of variance (ANOVA) showed that power spectrum and HOS based
features were statistically signiÂ¯cant among the six emotional states (p < 0:0001). ClassiÂ¯cation results shows that using the selected HOS based features instead of power spectrum based
features provided comparatively better accuracy for all the six classes with an overall accuracy
of 70:10%  2:83% and 77:29%  1:73% for PD patients and HC in beta (13â€“30 Hz) band using
SVM classiÂ¯er. Besides, PD patients achieved less accuracy in the processing of negative
emotions (sadness, fear, anger and disgust) than in processing of positive emotions (happiness,
surprise) compared with HC. These results demonstrate the eÂ®ectiveness of applying machine
learning techniques to the classiÂ¯cation of emotional states in PD patients in a user independent
manner using EEG signals. The accuracy of the system can be improved by investigating the
other HOS based features. This study might lead to a practical system for noninvasive assessment of the emotional impairments associated with neurological disorders.
Keywords: EEG; emotion; Parkinson's disease; bispectrum; power spectrum; pattern
classiÂ¯cation.

1

March 4, 2014

12:16:14pm

WSPC/179-JIN

2

1450006

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

1. Introduction
An increasing body of evidence demonstrates the importance of eÂ®ective social
relationships for the health and well-being of older adults (Cohen & Janicki-Deverts,
2009; Gow et al., 2007). Accurately recognizing the emotional states of others is a
crucial component of successful social interaction, with comprehension (as well as
production) of emotional voice and facial expressions essential for eÂ®ective communication in social and interpersonal relationships (Blair, 2003). Cumulating evidence
indicates that individuals with Parkinson's disease (PD) have deÂ¯cits in recognizing
emotions from prosody (Dara et al., 2008; Paulmann & Pell, 2010; Pell & Leonard,
2003; Yip et al., 2003), facial expressions (Clark et al., 2008; Dujardin et al., 2004;
Sprengelmeyer et al., 2003) and show reduced startle reactivity to highly arousing
unpleasant pictures (Bowers et al., 2006; Miller et al., 2009). There is sparse event
related potential (ERP) evidence that early processing of emotional prosody (mismatch negativity; Schrâ‚¬
oder et al., 2006) and faces (early posterior negativity; Wieser
et al., 2012) may be aÂ®ected in PD. A number of studies have failed to Â¯nd deÂ¯cits
in emotion recognition (Adolphs et al., 1998; Madeley et al., 1995; Pell & Leonard,
2005); others have documented speciÂ¯c deÂ¯cits in recognizing at least some basic
emotions (Lawrence et al., 2007; Suzuki et al., 2006). Finally, although some studies
have documented deÂ¯cits in recognizing emotion both facial displays and prosody
(Ariatti et al., 2008), others have documented deÂ¯cits in recognizing emotion only in
one stimulus modality (Clark et al., 2008; Kan et al., 2004). Altogether, experimental
evidence so far supports the view of deÂ¯cits in emotion processing in PD patients.
Much of the research in this area focused on the patients behavioral responses (i.e.,
participants asked to match, to identify or to rate the emotional stimuli) and
physiological measures of emotional experience (e.g., startle eye blink and ERPs).
The existing literature mentioned above used traditional statistical analysis tools for
the investigation of emotion processing in PD. There is no quantitative objective
measurement that correlates with the aÂ®ective impairment in neurological disorder
patients compared to healthy controls (HC). This underlines the need for an objective quantitative measure of emotional processing that can identify and quantify
subtle changes in aÂ®ect and hence help in a group based comparative analysis between patients and HC, thereby enabling the assessment of emotional impairment
treatment eÂ±cacy and progression of the disease.
Lately, numerous studies on computational approaches to automatic emotion
recognition have been published, although research in that Â¯eld is relatively new
compared to the long history of emotion research in psychology and psychophysiology. The approaches used for the automatic emotion recognition in HC, mainly
focusing on the audioâ€“visual channels of emotional expression such as facial expression (Cohen et al., 2000), speech signals (Kim, 2007) and gestures (Kessous et al.,
2010). Though these modalities are researched widely and have produced better
results, they are all susceptible to social masking. Emotions that are not expressed,
emotions expressed diÂ®erently (an angry person may smile) or minor emotional

March 4, 2014

12:16:14pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

3

changes that are invisible to the natural eye, cannot be tracked by using these
modalities (Bailenson et al., 2008). These limitations direct the way to recognizing
emotion through physiological signals (often called \biosignals"). Physiological signals reÂ°ects the inherent activity of the autonomous nervous system (ANS) or central
nervous system (CNS), inhibiting any conscious or intentional control by the person
(Kim & Andre, 2008). It is noninvasive, subjective, complex and diÂ±cult to uniquely
map physiological signals to diÂ®erent emotions. However, it is reliable as it can
identify the emotional state of the person. It also provides an opportunity to track
minute emotional changes that may not be perceived visually (Kim et al., 2004; Rani
& Sarkar, 2006).
Biosignals used in most of the studies were recorded from ANS in the periphery,
such as electrocardiogram (ECG), skin conductance (SC), electromyogram (EMG),
respiration rate (RR), pulse, etc. (Haag et al., 2004; Rani & Sarkar, 2006). In addition
to these periphery biosignals, signals captured from the CNS, such as electroencephalogram (EEG), magnetoencephalogram (MEG), positron emission tomography
(PET) and functional magnetic resonance imaging (fMRI) have been proved to
provide informative characteristics in response to emotional states. Toward such a
more reliable emotion recognition procedure, EEG (Murugappan et al., 2010; Petrantonakis & Hadjileontiadis, 2010, 2011) appears to be less invasive and the one
with best time resolution than the other three (MEG, PET and fMRI). EEG has been
used in cognitive neuroscience to investigate the regulation and processing of emotion
for the past decades. Power spectra of the EEG were often assessed in several distinctive frequency bands, such as delta (: 1â€“4 Hz), theta (: 4â€“8 Hz), alpha ( : 8â€“
13 Hz), beta ( : 13â€“30 Hz) and gamma (: 30â€“49 Hz), to examine their relationship
with the emotional states (Aftanas et al., 2004; Davidson, 2004). Frontal midline
theta power modulation is suggested to reÂ°ect aÂ®ective processing during audio
stimuli (Sammler et al., 2007). The alpha-power asymmetry on the prefrontal cortex
has been proposed as an index for the discrimination between positively and negatively valenced emotions (Davidson, 2004). Beta activity has been associated with
emotional arousal modulation (Aftanas et al., 2006). Finally, gamma band is mainly
related to arousal eÂ®ects (Balconi & Lucchiari, 2008).
In the recent years, researchers have been using non-linear approaches in various
areas of biosignal processing for estimating heart rate, nerve activity, renal blood
Â°ow, arterial pressure and stress using signals such as EEG, ECG, HRV, EMG and
RR (Kannathal et al., 2004; Melillo et al., 2011). Non-linear analysis based on chaos
theory helps in identifying the apparently irregular behaviors that are present in the
system (Gao et al., 2011). Several nonlinear features such as correlation dimension
(CD), approximate entropy (APEN), largest lyapunov exponent (LLE), higher-order
spectra (HOS) and Hurst exponent (H ) has been used widely (Balli & Palaniappan,
2010; Chua et al., 2011; Kannathal et al., 2005) to characterize the EEG signal. In
general, any analysis technique that can detect and compute some aspect of nonlinear mechanisms, may better reÂ°ect the dynamics and the characteristics of the
EEG signal, and provide more realistic information about the physiological and

March 4, 2014

12:16:14pm

WSPC/179-JIN

4

1450006

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

pathological state of the CNS, the phenomenon of non-linearity and deviations of the
signal from Guassianity (Shen et al., 2000). HOS are known to have the ability to
detect non-linearity and deviations from Guassianity. Motivated by these, a set of
HOS based parameters were proposed as features to study six emotional state
(happiness, sadness, fear, anger, surprise and disgust) changes in PD patients compared with HC using EEG signals. Recently, Hosseini (2012) achieved 82.32% accuracy in recognizing emotions (neutral and negative) from EEG signals using HOS
and this clearly indicates that HOS can be used to seek emotional information from
biosignals. In this work, we made a comparative study of the performance of
k-nearest neighbor (kNN) and support vector machine (SVM) classiÂ¯ers using the
emotional features derived from HOS and from the power spectrum. Our results
indicate the presence of more emotional information in HOS based features compared
to the power spectrum based features in PD patients and HC. The classiÂ¯er-based
framework that we propose for determining subtle emotional changes in general and
applicable to group-wise analysis of all aÂ®ect-related disorder, against HC.
The rest of the paper is structured as follows: In Sec. 2, we provide a brief description of the participant's characteristics, experimental protocol and EEG-signal
recording. In Sec. 3, we discussed the methodology which includes preprocessing,
feature extraction (power spectrum based features and HOS based features) and
classiÂ¯cation algorithms used in this work. In Sec. 4, experimental results of the work
are presented and discussed in Sec. 5. Finally, Sec. 6 presents the limitations of the
present study and concludes in Sec. 7. To our knowledge, no study has yet been
conducted to explore the correspondence between emotional states and EEG frequency bands in PD patients.

2. Materials
2.1. Ethics statement
This study was approved by the ethics committee of the Hospital University Kebangsaan
Malaysia (HUKM) and written informed consent was obtained according to the
Declaration of Helsinki. Participants were Â¯nancially compensated (50 Malaysian
Ringgits) for their time.
2.2. Participants
Twenty PD patients (10 men and 10 women) and 20 HC (9 men and 11 women)
matched for age (range from 40â€“65 years), education level and sex participated in the
study. The PD patients were recruited through the Neurology Unit outpatient service at the Department of Medicine of the HUKM medical center in Kuala Lumpur,
Malaysia. All of them had been diagnosed with Idiopathic PD by a neurologist.
Patients who had coexisting neurological disturbances (e.g., epilepsy) or who had
undergone deep brain stimulation were not included in the study. The control participants were recruited through the hospital community and/or from relatives of PD

March 4, 2014

12:16:16pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

5

patients. Exclusion criteria for controls included any current psychiatric or neurological disorder. Exclusion criteria for both groups were dementia or depression as
indicated by a score of 24 or lower on the mini-mental state examination (MMSE)
(Folstein et al., 1975; Wieser et al., 2012) or 18 or higher on the Beck Depression
Inventory (BDI) (Beck et al., 1961; Schrâ‚¬oder et al., 2006). All participants were righthanded as determined by self-report and conÂ¯rmed by Edinburgh Handedness Inventory (EHI) (OldÂ¯eld, 1971). This test consisted of 10 questions asking for the
preferred hand for a series of activities (e.g., writing, throwing, using scissors, etc).
All participants reported normal or corrected-to-normal vision.
2.3. Participants characteristics
Demographic and clinical characteristic of patients with PD and HC are presented in
Table 1. Patients and controls were comparable in demographic variables such as age
(PD: mean age Â¼ 59:05  5:64 years; HC: mean age Â¼ 58:10  2:95 years), tÃ°38Ãž Â¼
0:667, p Â¼ 0:509, gender distribution (PD: 10 men, HC: 9 men), x 2 Ã°1; N Â¼ 40Ãž
Â¼ 0:100, p Â¼ 0:752 and education level (PD: 10:45  4:8 years; HC: 11:05  3:34
years), tÃ°38Ãž Â¼ 0:455, p Â¼ 0:652. Furthermore, PD patients and HC did not diÂ®er
in mean MMSE scores, mean BDI scores as well as mean EHI scores.
The severity of motor symptoms corresponded to the Stages 1 to 3 (mild unilateral
to moderate bilateral disability) of the Hoehn and Yahr scale (Hoehn & Yahr, 1967)
and to an average score of 17:05  3:15 in the motor scale of the uniÂ¯ed Parkinson's
disease rating scale (UPDRS) (Fahn et al., 1987). Motor symptoms were characterized as left dominant (nÂ¼11) and right dominant (n Â¼ 9). Duration of the disease
varied between 1â€“12 years, with a mean of 5:75  3:52 years. All of the patients
were undergoing dopamine replacement therapy and were tested while being administered their anti-parkinsonian medication (i.e., during their \on" state), distributed as follows: d2-agonist (n Â¼ 18); carbidopa/L-dopa (n Â¼ 13), monoamine

Table 1.

Demographic and clinical characteristics of patients with PD and HC participants.

Variable

PD (n Â¼ 20)

HC (n Â¼ 20)

Test's Value

Statistical Result

Age (years)
Gender
Education (years)
MMSE (0â€“30)
Hoehn and Yahr scale (I/II/III)
Motor UPDRS
Disease duration (years)
BDI (0â€“21)
EHS (1â€“10)

59.05  5.64
10F/10M
10.45  4.86
26.90  1.51
2.25  0.63
17.05  3.15
5.75  3.52
5.80  2.87
9.55  0.76

58.10  2.95
11F/9M
11.05  3.34
27.15  1.63

t Â¼ 0:667
x 2 Â¼ 0:100
t Â¼ 0:455
t Â¼ 0:502

p Â¼ 0:509
p Â¼ 0:752
p Â¼ 0:652
p Â¼ 0:619

5.45  2.18
9.84  0.72

t Â¼ 0:433
t Â¼ 0:818

p Â¼ 0:667
p Â¼ 0:403

Note: n Â¼ number of participants, PD Â¼ Parkinson's disease, HC Â¼ healthy controls, M Â¼ male,
F Â¼ female, MMSE Â¼ mini mental state examination, UPDRS Â¼ unified Parkinson's disease rating
scale, BDI Â¼ Beck depression inventory, EHS Â¼ Edinburg handedness inventory. Data presented as
mean  SD.

March 4, 2014

12:16:16pm

WSPC/179-JIN

1450006

6

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

oxidase B (MAO-B) inhibitor (n Â¼ 7), catechol-O-methyltransferase (COMT)
inhibitor (n Â¼ 5), amantadine (n Â¼ 5) or anticholinergics (n Â¼ 3).
2.4. The modeling and classiÂ¯cations of emotions
In addition to the cognitive theory, several theories of emotions have developed over
the past century (Cornelius, 1996). These diÂ®erent views gave rise to diÂ®erent models
of emotions. The most commonly used are the dimensional and discrete models of
emotions. The discrete model includes six basic emotions (happiness, sadness, fear,
anger, surprise and disgust) that are universally accepted. All other emotions are
considered to be a part of these basic emotions (Ekman & Friesen, 1987). The dimensional model, as in Fig. 1, speciÂ¯es emotions on the basis of two main dimensions
i.e., arousal and valence. Valence stands for one's judgment about a situation as
positive or negative and arousal spans from calmness to excitement, expressing
degrees of one's excitation. All emotions can be plotted on the valence-arousal plot
(Lang, 1995). In addition to the two-dimensional model, researchers are also proposed a three-dimensional model of emotions which takes into account the attentionrejection property (Kim & Andre, 2008). In this work, six basic emotions (happiness,
sadness, fear, anger, surprise and disgust) based on discrete emotional modal were
considered.
2.5. Stimulus material
Until now, most studies on emotion recognition in PD have used only facial stimuli,
prosodic stimuli or music stimuli (Gray & Tickle-Degnen, 2010; Lima et al., 2013;
Peron et al., 2012). In addition, a wide range of elicitation methods have been applied
in HC: images (e.g., IAPS described below) (Petrantonakis & Hadjileontiadis, 2010,

Fig. 1.

Two-dimensional emotional model by valence and arousal (Kim & Andre, 2008).

March 4, 2014

12:16:17pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

7

2011), sounds (e.g., music and IADS described below) (Hadjidimitriou & Hadjileontiadis, 2012; Kim & Andre, 2008; Lin et al., 2010), movies (Davidson et al., 1990;
Gross & Levenson, 1995), multimodal approach (i.e., combination of audio and visual) (Baumgartner et al., 2006; Jerritta et al., 2013; Kim et al., 2004; Murugappan
et al., 2009; Yuvaraj et al., 2013) and so on. Among all these stimuli modalities
researchers have identiÂ¯ed that multimodal stimuli induce target emotions better
(Gross & Levenson, 1995; Kim et al., 2004; Murugappan et al., 2009; Wang & Guan,
2008) compared to other modalities. Hence, in this work emotions were induced by
multimodal approach.
The emotional stimuli we used were taken from diÂ®erent sources such as the
International AÂ®ective Picture System (IAPS) database (Lang et al., 1993), International AÂ®ective Digitized Sounds (IADS) (Bradley & Lang, 2007) database and
video clips (e.g., funny animals, wonder activities by humans etc) collected from
various resources on the internet (e.g., YouTube, Facebook and others) (Jerritta et
al., 2013). The elicitation of emotions such as sadness, fear and disgust was attained
by using aÂ®ective pictures from IAPS and sounds from IADS databases. Various
psychological and psychophysiological experiments have revealed that these stimuli
sets have great potential in the investigation of sad, fear and disgust emotions
(Baumgartner et al., 2006; Brown et al., 2011). Additionally, Mikels (Mikels et al.,
2005) & Redondo et al., (Redondo et al., 2008) provided a more complete characterization of the categorical structure of the IAPS and IADS stimulus set, with the
objective of identifying images and sounds that elicit one discrete emotion more than
other emotions. The IAPS picturesa [disgust: valence- mean Ã°SDÃž Â¼ 2:43 (1.51),
arousal mean Ã°SDÃž Â¼ 5:90 (2.25); fear: valence mean Ã°SDÃž Â¼ 3:80 (1.89), arousal
mean Ã°SDÃž Â¼ 5:85 (2.12); sad: valence- mean Ã°SDÃž Â¼ 2:74 (1.57), arousal mean Ã°SD
Ãž Â¼ 5:00 (2.08)] and IADS soundb [disgust: valence mean Ã°SDÃž Â¼ 4:00 (1.72), arousal
mean Ã°SDÃž Â¼ 5:82 (1.93); fear: valence mean Ã°SDÃž Â¼ 4:00 (1.72), arousal mean Ã°SD
Ãž Â¼ 5:82 (1.93); sad: valence mean Ã°SDÃž Â¼ 3:28 (1.65), arousal mean Ã°SDÃž Â¼ 6:61
(1.89)] were selected and combined together according to their arousal and valence
values provided in the databases. For example, a negative/high aroused sound was
matched with a negative/high aroused image.
On the other hand, the emotions happiness, surprise and anger were elicited using
video clips. In order to select eÂ±cient video clips, that would elicit the target emotions better, a pilot was conducted. For this, around 30 video clips per emotional
a The

following pictures in the database were used for emotion induction: Disgust: 1945, 2352.2, 3000, 3010, 3015,
3030, 3051, 3060, 3061, 3071, 3080, 3110, 3120, 3130, 3140, 3150,3160, 3250, 3400, 7360, 7361, 7380, 8230, 9040, 9042,
9181, 9290, 9300, 9320, 9330, 9373, 9390, 9405, 9490, 9570, 9830; Fear: 1019, 1022, 1030, 1040, 1050, 1051, 1052, 1070,
1080, 1090, 1110, 1111, 1113, 1120, 1200, 1201, 1220, 1230, 1240, 1280, 1274, 1300, 1301, 1302, 1321, 1390, 1930, 1931,
3280, 5970, 5971, 5972, 6370, 9584, 9594, 9592; Sad: 2205, 2271, 2276, 2490, 2520, 2590, 2700, 2800, 2900, 3220, 3230,
3300, 3301, 3350, 6570, 6838, 8010, 9000, 9041, 9050, 9120, 9190, 9210, 9220, 9331, 9410, 9415, 9470, 9520, 9530, 9561,
9611, 9910, 9911, 9920, 9921.
b The following sounds in the database were used for emotion induction: Disgust: 134, 115, 251, 262, 284, 698, 702,
711, 712, 713, 714, 720, 728, 729, 730, 732, 812, 813; Fear: 106, 133, 170, 171, 275, 276, 277, 279, 291, 312, 378, 380,
424, 425, 500, 626, 627, 699, 817; Sad: 115, 150, 260, 261, 278, 280, 285, 286,290, 293, 295, 310, 311, 368, 403, 420, 422,
501, 600, 625.

March 4, 2014

12:16:17pm

WSPC/179-JIN

1450006

8

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

Fig. 2.

Experimental protocol.

state were collected. Thirty volunteers in the mean age of 26.4 years (ranging from 24
to 45 years) participated in the pilot study to rate the emotions they experienced
when watching the video clips. All of them were psychology teachers or students of
the UKM medical center, Kuala Lumpur. Thirty video clips (ten for each emotion)
with the highest rating were chosen for data collection experiment.
2.6. Experimental protocol
The protocol used in this experiment is shown in Fig. 2. The protocol had two
sessions with break of 10â€“15 min between the sessions. Each session had three trials
with neutral images displayed for 10 s between the trials. The break between sessions
and trials would help the participant to relax during the experiment and to avoid any
feedback from the previous emotional stimuli. The multimodal stimulus pertaining to
all the six emotional states (happiness, sadness, fear, anger, surprise and disgust)
were played in each trail in predetermined random fashion. Each combination of
picture and sound was presented for six seconds (Kim, 2007). To maximize the
participants' emotional response, each clip block consisted of six combinations of the
same emotional category and lasted for 36 s. In addition, each of the video clips varied
from 36â€“45 s in duration, depending on the length of the clip. Besides, a 15 s rating
interval (Hamdi et al., 2012) was provided between the clips in which participants
answered a Â¯ve point self-assessment scale. Each session of the protocol lasted for
30 min approximately.
2.7. Procedure
The set-up of the experiment is shown in Fig. 3. The experiment procedure took
place in a laboratory environment, under dim lighting conditions, to avoid visual

March 4, 2014

12:16:17pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

Fig. 3.

9

Experiment setup.

disturbance. In order to obtain a good physiological data, the participants were
requested to relax before the start of the experiment and concentrate on the emotional stimuli. At the end of each clip, the participants Â¯lled a self-assessment
questionnaire where they identiÂ¯ed/experienced the emotional state when watching
the clips. They also rated the intensity of the emotional state on a Â¯ve point scale
(1 Â¼ very low, 2 Â¼ low, 3 Â¼ medium, 4 Â¼ high and 5 Â¼ very high). These ratings
were then used to understand the intensity of the emotional state they experienced.
An example of the self-assessment questionnaire is as shown in Fig. 4. However,
despite the intensity levels, all the emotional data was taken into considerations.
2.8. EEG-signal recordings
EEG recordings were conducted using the Emotive EPOC 14 channel EEG wireless
recording headset (Emotive Systems, Inc., San Francisco, CA) (Hadjidimitriou &
Hadjileontiadis, 2012). The electrode scheme was arranged according to the international 10â€“20 system and included active electrodes at AF3, F7, F3, FC5, T7, P7,
O1, O2, P8, T8, FC6, F4, F8 and AF4 positions, referenced to the common mode
sense (CMS-left mastoid)/driven right leg (DRL-right mastoid) ground as shown in
Fig. 5. The acquired data were digitized using the embedded 16-bit ADC with 128 Hz

Fig. 4.

Self-assessment questionnaire.

March 4, 2014

12:16:18pm

WSPC/179-JIN

10

1450006

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

Fig. 5. Emotiv EPOCs electrode positioning, according to the 10â€“20 system, used for EEG-signal
recordings.

sampling frequency per channel and sent to the computer via wireless technology,
which utilizes a proprietary USB dongle to communicate using the 2.4 GHz band.
Sample EEG recordings of PD patient and HC corresponding for six emotional states
are given in Figs. 6(a) and 6(b), respectively.

(a)
Fig. 6.

(b)

Sample recordings of EEG signals corresponding to six emotional states (a) PD patients (b) HC.

March 4, 2014

12:16:19pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

11

3. Methodology
A block diagram of the proposed emotion recognition system is illustrated in Fig. 7.
After the data recording, all signals were preprocessed i.e., Â¯ltered and segmented.
Then, the most signiÂ¯cant features were extracted. Finally, features were classiÂ¯ed
using machine learning methods. A brief description on each block is given below.
3.1. Preprocessing
The raw EEG data was split as per the emotional states according to the participant's self-assessment. Then, the EEG signals were band-passed Â¯ltered in the frequency range of 1â€“49 Hz (IIR Butterworth 6th order Â¯lter with zero-phase shift). The
focus was to obtain the Â¯ve traditional EEG frequency bands: delta (1â€“4 Hz), theta
(4â€“8 Hz), alpha (8â€“13 Hz), beta (13â€“30 Hz) and gamma (30â€“49 Hz), thus, features
were estimated for each of these bands. A study published by Kim (2007) proposed
the use of diÂ®erent epoch size that depends on modality, e.g., 2â€“6 s for speech, and 3â€“
15 s for biosignals (Kim, 2007). In this study, the EEG signals were segmented into 6 s
epoch corresponding to the duration of each multimodal stimuli projection.
3.2. Feature extraction
3.2.1. Power spectrum-based features
Power spectral analysis is typically performed with EEG epochs by computing the
discrete Fourier transform (DFT). DFT of the given signal EEG signal xÃ°nÃž is given

Fig. 7.

Block diagram representing the proposed recognition system.

March 4, 2014

12:16:20pm

WSPC/179-JIN

1450006

12

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

by
N
X1



2
XÃ°kÃž Â¼
kn ;
xÃ°nÃž exp j
N
nÂ¼0

k Â¼ 0; 1; 2; . . . ; N

1;

Ã°1Ãž

where N is the number of EEG samples taken for analysis. The DFT is typically
computed using the Fast Fourier Transform (FFT) algorithm which computes the
Fourier transform coeÂ±cients XÃ°kÃž quickly. Power values are calculated using FFT
which are then used for further analysis. These features are explained below.
(i) Mean of spectral magnitude:
Mavg Â¼

1 NX1
jX j;
N kÂ¼0 k

where Xk is the FFT of input signal.
(ii) Spectral entropy 1:
X
pk log pk ;
P1 Â¼

Ã°2Ãž

Ã°3Ãž

k

kj
where pk Â¼ P jX
N
kÂ¼1

jXk j

.

(iii) Spectral entropy 2:
P2 Â¼

X

qk log qk ;

Ã°4Ãž

k

kj
where qk Â¼ P jX
N

2

jXk j 2
kÂ¼1

.

In this work, epochs of 768 samples of EEG signals, corresponding to 6 s are used for
computing the averaged Fourier spectrum and its magnitudeâ€“squared, the power
spectrum. From the power spectrum above three features are extracted for our
analysis.
3.2.2. HOS-based features
HOS (also known as polyspectra) are the spectral representations of higher-order
moments or cumulants of a signal. In particular, this paper studies feature related to
the third-order statistics of a signal, and the corresponding HOS, namely the bispectrum. The bispectrum BÃ°f1 ; f2 Ãž of a signal is the Fourier transform of the thirdorder correlation of the signal. It is given by
BÃ°f1 ; f2 Ãž Â¼ EÂ½XÃ°f1 ÃžXÃ°f2 ÃžX  Ã°f1 Ã¾ f2 ÃžÂŠ;

Ã°5Ãž

where XÃ°f Ãž is the DFT of the EEG signal xÃ°nT Ãž, X  Ã°f1 Ã¾ f2 Ãž denotes complex conjugate and EÂ½ÂŠ stands for expectation operator.
The frequency f may be normalized by the Nyquist frequency to be between 0
and 1. The bispectrum, given by Eq. (5), is a complex-valued function of two frequencies. The bispectrum which is the product of three Fourier coeÂ±cients, exhibits

March 4, 2014

12:16:20pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

13

Fig. 8. Non-redundant region ( ) of computation of the bispectrum for real-valued signals. Features
are calculated from this region.

symmetry and was computed in non-redundant region. This termed as , the principle domain or the non-redundant region (i.e., the triangle region in Fig. 8) (Nikias &
Petropulu, 1993). The extracted bispectral based features are:
(i) Mean of bispectral magnitude:
Mavg Â¼

1 X
jBÃ°f1 ; f2 Ãžj;
L

where L is the number of points within the region.
(ii) Bispectral entropy (BE1):
X
pk logÃ°pk Ãž;
P1 Â¼

Ã°6Ãž

Ã°7Ãž

k

1 ;f2 Ãžj
where pk Â¼ PjBÃ°fjBÃ°f
,
;f Ãžj

Â¼ the region as in Fig. 8.

1 2

(iii) Bispectral entropy (BE2):
P2 Â¼

X

qn logÃ°qn Ãž;

Ã°8Ãž

n

2

1 ;f2 Ãžj
,
where qn Â¼ PjBÃ°fjBÃ°f
;f Ãžj 2

Â¼ the region as in Fig. 8.

1 2

In order to calculate bispectral features, we used epochs of 768 samples with an
overlap of 384 point (i.e., 50%) and Hanning window, corresponding to six seconds at
the given sampling rate. These epochs were taken from each record of 1024 point.
3.3. Machine learning-based emotion classiÂ¯cation methodology
and algorithms
We have constructed classiÂ¯ers for PD patients and HC group under six basic
emotions (i.e., PDÃ°happy vs: sad vs: fear vs: anger vs: surprise vs: disgustÃž and HCÃ°happy vs: sad vs: fear
vs: anger vs: surprise vs: disgustÃž ) across delta, theta, alpha, beta, gamma and ALL (refers
to combination of Â¯ve EEG frequency bands) frequency bands. The classiÂ¯cation

March 4, 2014

12:16:21pm

WSPC/179-JIN

1450006

14

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

approach adopted in this study was user independent i.e., classiÂ¯cation was performed on the complete dataset of six emotions, created from PD patients and HC
group EEG responses. Two classiÂ¯ers are employed namely kNN, and SVM for the
classiÂ¯cation of emotional states and their brief description of these are given below.
We also tested other classiÂ¯cation techniques such as LDA, PNN and Naive Bayes.
However, these results are not superior to those obtained with other methods and
hence are not reported.
3.3.1. k-nearest neighbor
The kNN classiÂ¯cation is one of the simplest classiÂ¯cation methods. In this algorithm, k nearest training samples for a test sample is found. Then, test sample is
assigned to particular class which is most frequent class among k nearest training
data. This algorithm only requires an integer value for k and a metric to measure
closeness (Han & Kamber, 2006). One of the most common and popular choices to
measure the distance for this algorithm is Euclidean measure (Eq. (9)); as such, we
have used the Euclidean distance as a metric for measuring the adjacency of neighboring input. In this work, diÂ®erent values of \k" between 1 and 10 are tested and we
have obtained better classiÂ¯cation accuracy when k Â¼ 5.
Euclidean measure:
sï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒï¬ƒ
p
X
di Ã°xi ; xj Ãž Â¼
Ã°9Ãž
Ã°xip xjp Ãž 2 ;
kÂ¼1

where, xi is an input sample with p features Ã°xi1 ; xi2 ; . . . ; xip Ãž, xj is a sample in the
training data set with p features Ã°xj1 ; xj2 ; . . . ; xjp Ãž and dj Ã°xi ; xj Ãž is the Euclidean distance between sample xi and xj Ã°j Â¼ 1; 2; 3; . . . ; nÃž with n is the total number of
samples in the training data set.
3.3.2. Support vector machine
In recent years, SVM classiÂ¯ers have demonstrated excellent performance in a variety
of pattern recognition problems (Burgees, 1998). SVM maps samples to points in a
space in such a way that samples belonging to separate category (i.e., classes) are
divided or separated by a very clear gap that is as wide as possible. When the new test
data are applied, they will be mapped to the same space. The decision on the class
of test data is made based on which side of the gap the data maps. Hyperplane is
used to classify two classes and a set of hyperplanes are used to classify multiclass
problem. The best hyperplane yields the largest separation or margin between
the two classes. SVM classiÂ¯er transforms nonlinear data to a separable form with
help of various kernel functions (Muller et al., 2001). The radial basis function (RBF)
and polynomial kernels are commonly used (Christianini & Taylor, 2000). With the
use of kernels, an explicit transformation of the data to the feature space is not
required. In this experiment, we used the RBF kernel function with a one-against-all
algorithm to classify six emotional states. The performance parameters of SVM-RBF

March 4, 2014

12:16:22pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

15

(regularization constant [C ] and width [] of the kernel) are found out by using the
grid search approach as suggested by (Hsu et al., 2003). In this work, we achieved
improved classiÂ¯cation accuracy using C Â¼ 108 and  Â¼ 2:434.
3.3.3. ClassiÂ¯cation evaluation procedure
In this work, 10-fold cross validation schemes are used to prove the reliability of the
classiÂ¯cation results, where the extracted feature vectors are divided randomly into
10 sets and training is repeated for 10 times. A total of 4320  42 [20 participant's 
6 emotions  6 trails  6 segments per channel 3 features  14 channels] datasets
were used training and testing with 720 datasets from each of the six emotional states
under each group for delta, theta, alpha, beta and gamma frequency band. These
4320 datasets were subdivided into 10 equal parts (roughly). During each fold, 432
datasets were used for testing. This process is repeated for 9 more times. The overall
performance of the classiÂ¯er is evaluated by taking the average and standard deviation of 10 folds. The standard deviation of the classiÂ¯cation clearly demonstrates the
consistency of the classiÂ¯er results.
4. Experimental Results
4.1. Self-assessment report
Table 2 shows the results of self-assessment classiÂ¯cation accuracy (in percentage) of
the six basic emotions for PD patients and HC obtained from confusion matrix. The
results of analysis of variance (ANOVA) on the self-assessment report did not show
any signiÂ¯cant diÂ®erences (p > 0:05) on PD patients and HC among the six emotional states. Overall, the happiness emotion was recognized better on both participants with a maximum accuracy (PD Â¼ 93:42%, HC Â¼ 92:50%) and disgust
emotion was recognized poorest with a least accuracy (PD Â¼ 72:67%, HC Â¼ 66:50%).
Table 2. Self-assessment classiÂ¯cation accuracy (in percentage) of the six basic emotions for PD
patients and HC.
Emotions

Happiness (%)

Sadness (%)

Fear (%)

Anger (%)

Surprise (%)

Disgust (%)

(a) PD patients
Happy
94.33
Sad
0
Fear
0
Anger
0
Surprise
12.00
Disgust
0

0
75.00
2.56
4.79
0
24.89

0
1.83
80.33
11.56
0
0

0
4.45
7.92
78.00
0
2.44

5.67
0
3.48
0
88.00
0

0
18.72
5.71
5.65
0
72.67

(b) Healthy controls
Happy
92.50
Sad
0
Fear
0
Anger
0
Surprise
3.33
Disgust
0

0
84.67
1.49
0
0
18.42

0
0
77.50
15.32
0
8.12

0
2.77
12.56
82.67
0
6.96

7.60
0
0
0
96.67
0

0
12.56
8.45
2.01
0
66.50

March 4, 2014

12:16:22pm

WSPC/179-JIN

1450006

16

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

4.2. Emotional EEG data
The statistical signiÂ¯cance of the extracted features from PD patients and HC across
delta, theta, alpha, beta, gamma and ALL frequency bands on both the feature
extraction methods was studied using ANOVA with a threshold of p < 0:05.
Table 3 shows the range of spectral based features used for emotion classiÂ¯cation
across diÂ®erent EEG frequency bands for PD patients and HC. These features show
very low p-value (p < 0:0001) indicating that they are statistically signiÂ¯cant among
six emotional states feature values. HOS based features are reported in Table 4.
Again, these features show very low \p-value" (p < 0:0001) indicating that they are
statistically signiÂ¯cant. These results also ensure the probability of achieving better
classiÂ¯cation accuracy. Furthermore, we also obtained signiÂ¯cant diÂ®erence from the
condition ALL frequency bands among six emotional states (p < 0:05). In general,
emotional feature values decrease from HC participants to PD patients during
emotion information processing in both spectral and HOS based features.
Tables 5(a) and 5(b) shows the classiÂ¯cation results of SVM and kNN classiÂ¯er
with power spectral based features. We can observe that the classiÂ¯cation performance of beta frequency band features evidently performs better than other frequency bands. The SVM classiÂ¯er classiÂ¯es six emotional states with maximum
average accuracies of 66:70%  1:29% and 70:51%  1:30% for PD patients and HC,
respectively. The kNN classiÂ¯er gives a maximum average classiÂ¯cation rate of
64:26%  1:59% and 67:84%  2:34% for PD patients and HC on classifying six
emotional states, respectively. Similarly, the results of the classiÂ¯ers with HOS based
features are given in Tables 6(a) and 6(b). Again, the HOS based features on beta
frequency band gives a maximum average emotion classiÂ¯cation rate on PD and HC
compared to other frequency bands. For the case of SVM classiÂ¯er with HOS based
features, the maximum average classiÂ¯cation accuracies of 70:10%  2:83% and 77:
29%  1:73% for PD patients and HC emotional EEGs, respectively. Therefore, there
is an average of 3.40% and 6.78% improvement over the case of spectral based
classiÂ¯er in PD patients and HC emotional state classiÂ¯cation. For the case of kNN
classiÂ¯er with HOS based features, the maximum average classiÂ¯cation accuracies of
68:54%  1:90% and 73:40%  1:72% for PD patients and HC emotional EEGs,
respectively. In this case, there is an average of 4.28% and 5.56% improvement over
the case of spectral based emotional classiÂ¯cation in PD patients and HC. Figure 9
shows the beta band classiÂ¯cation accuracy of PD patients and HC across six emotional states for HOS based features applied to SVM classiÂ¯er (maximum classiÂ¯cation rate achieved for six emotional states).
In all combination of features set, the emotional classiÂ¯cation accuracy of
PD patients is lower than HC, suggesting that emotional impairments associated
with PD patients. Notably, this experimental result indicates that PD patients
achieved less pattern classiÂ¯cation accuracy in the processing of negative emotions
(sadness, fear, anger and disgust) than in processing of positive emotions (happiness,
surprise).

March 4, 2014

Range of various spectral based features (in mean  standard deviation) of the six emotions for PD patients (p < 0:0001) and HC (p < 0:0001).

Mavg
P1
P2

Theta band

Mavg

P2
Mavg
P1
P2
Mavg
P1
P2
Gamma band

Mavg
P1
P2

Sad
10 4

10 4

Fear
10 4

10 4

Anger
10 4

10 3

Surprise
10 4

10 4

Disgust
10 4

4:56 
 1:89 
3:34 
 2:54 
4:89 
 2:78 
3:89 
 2:46 
4:79 
 3:78 
4:64  10 4  2:85  10 4
4
5
5
5
5
5
5
5
5
5
4:99  10  3:89  10 5:89  10  3:83  10 5:20  10  4:49  10 4:75  10  2:89  10 5:91  10  4:78  10 6:78  10 5  4:89  10 5
0.523  0.045
0.568  0.044
0.545  0.047
0.589  0.049
0.523  0.043
0.599  0.048
0.623  0.031
0.645  0.037
0.687  0.039
0.684  0.031
0.682  0.034
0.699  0.032
0.445  0.063
0.498  0.067
0.412  0.068
0.401  0.069
0.489  0.063
0.490  0.069
0.479  0.019
0.505  0.018
0.489  0.017
0.499  0.016
0.589  0.017
0.578  0.016
5:17  10 4  2:25  10 5 6:48  10 4  3:86  10 5 5:39  10 4  3:19  10 5 4:68  10 4  2:34  10 5 5:80  10 4  2:60  10 5 5:31  10 4  2:39  10 5
5:24  10 4  4:97  10 5 7:82  10 4  6:59  10 5 6:94  10 4  5:61  10 5 4:97  10 4  3:60  10 5 6:01  10 4  8:45  10 5 8:76  10 4  8:91  10 5
0.663  0.032
0.684  0.034
0.684  0.033
0.674  0.032
0.661  0.031
0.682  0.035
0.680  0.032
0.691  0.033
0.685  0.035
0.682  0.033
0.680  0.034
0.694  0.033
0.504  0.077
0.515  0.107
0.527  0.108
0.536  0.108
0.545  0.093
0.526  0.106
0.544  0.019
0.545  0.018
0.547  0.017
0.546  0.016
0.548  0.017
0.547  0.016
3:01  10 4  1:44  10 5 2:85  10 4  1:08  10 5 2:29  10 4  1:89  10 5 2:47  10 4  1:06  10 5 4:07  10 4  1:02  10 5 2:74  10 4  1:03  10 5
3:38  10 4  2:08  10 5 3:13  10 4  2:78  10 5 3:68  10 4  2:25  10 5 2:67  10 4  1:94  10 5 4:48  10 4  4:59  10 5 4:23  10 4  3:89  10 5
0.678  0.026
0.658  0.026
0.699  0.027
0.643  0.027
0.685  0.027
0.623  0.026
0.698  0.027
0.699  0.027
0.700  0.029
0.693  0.028
0.690  0.028
0.699  0.029
0.568  0.015
0.566  0.016
0.563  0.017
0.567  0.016
0.563  0.015
0.554  0.015
0.571  0.014
0.572  0.016
0.576  0.016
0.579  0.013
0.574  0.016
0.579  0.015
2:64  10 4  5:36  10 5
3:65  10 4  2:26  10 5
0.780  0.009
0.784  0.010
0.702  0.011
0.707  0.010
5:89  10 6  4:87  10 5
7:89  10 6  3:45  10 4
0.821  0.032
0.857  0.031
0.698  0.027
0.782  0.029

3:54  10 4  3:95  10 5
4:53  10 4  2:00  10 5
0.781  0.010
0.788  0.012
0.704  0.011
0.708  0.020
4:17  10 6  3:98  10 6
6:23  10 6  4:78  10 7
0.801  0.041
0.882  0.011
0.704  0.018
0.756  0.039

3:67  10 4  2:08  10 4
4:25  10 4  1:89  10 4
0.783  0.010
0.787  0.012
0.704  0.019
0.709  0.013
4:67  10 6  4:98  10 3
7:34  10 6  5:78  10 7
0.824  0.104
0.831  0.019
0.704  0.013
0.792  0.010

4:04  10 4  1:12  10 5
4:81  10 4  3:70  10 5
0.785  0.010
0.784  0.010
0.707  0.010
0.708  0.012
3:57  10 6  1:94  10 5
6:12  10 6  7:12  10 7
0.845  0.103
0.871  0.100
0.800  0.091
0.823  0.049

3:32  10 4  1:14  10 5
4:88  10 4  3:34  10 5
0.783  0.098
0.789  0.012
0.701  0.0111
0.710  0.036
4:19  10 6  4:98  10 5
7:23  10 6  6:87  10 6
0.825  0.098
0.867  0.014
0.701  0.015
0.791  0.020

17

3:21  10 4  2:90  10 5
3:96  10 4  2:08  10 5
0.785  0.010
0.787  0.010
0.707  0.011
0.709  0.009
3:89  10 6  3:67  10 5
4:78  10 6  4:23  10 6
0.810  0.024
0.882  0.024
0.683  0.056
0.701  0.005

2nd Reading

Beta band

10 3

ISSN: 0219-6352

Alpha band

Happy

1450006

P1

PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC

Type of Emotion

WSPC/179-JIN

Delta band

PSD
Parameters Group

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

Frequency
Band

12:16:30pm

Table 3.

March 4, 2014

Mavg
P1
P2
Mavg
P1

Mavg
P1

Beta band

Mavg
P1
P2

Gamma band

Mavg
P1
P2

10 6

Fear
10 8

10 6

Anger
10 8

10 6

Surprise
10 8

10 6

Disgust
10 8

3:67 
 2:24 
5:78 
 6:13 
4:89 
 3:98 
5:72 
 3:13 
4:15 
 4:67 
4:29  10 6  5:14  10 8
4:24  10 7  5:90  10 8 4:89  10 9  2:98  10 10 4:89  10 7  4:87  10 8 4:87  10 7  7:98  10 9 6:96  10 7  4:98  10 9 4:76  10 7  3:87  10 9
0.678  0.047
0.643  0.071
0.689  0.049
0.691  0.041
0.674  0.028
0.645  0.039
0.689  0.034
0.698  0.052
0.706  0.043
0.725  0.065
0.791  0.012
0.767  0.036
0.589  0.024
0.528  0.025
0.561  0.026
0.548  0.022
0.589  0.014
0.574  0.016
0.598  0.015
0.594  0.013
0.589  0.018
0.632  0.016
0.636  0.020
0.601  0.020
1:11  10 6  1:52  10 7 6:53  10 7  1:73  10 9 2:51  10 7  8:87  10 8 6:53  10 6  1:34  10 8 2:23  10 6  4:29  10 7 5:61  10 6  1:20  10 8
3:37  10 7  7:18  10 8 1:49  10 9  3:95  10 10 3:68  10 7  6:14  10 8 1:71  10 8  3:65  10 9 1:88  10 8  4:77  10 9 1:45  10 8  3:11  10 9
0.792  0.025
0.763  0.022
0.783  0.026
0.772  0.025
0.793  0.028
0.762  0.025
0.799  0.025
0.788  0.027
0.793  0.025
0.790  0.025
0.799  0.016
0.788  0.026
0.632  0.013
0.598  0.012
0.629  0.011
0.628  0.013
0.634  0.023
0.622  0.012
0.636  0.015
0.624  0.013
0.636  0.018
0.632  0.016
0.636  0.020
0.632  0.020
1:65  10 4  3:74  10 5 1:32  10 6  3:53  10 7 3:64  10 4  5:80  10 5 1:12  10 5  2:83  10 6 2:22  10 4  4:82  10 5 2:00  10 4  3:78  10 5
2:94  10 4  4:53  10 5 4:29  10 6  8:98  10 7 8:91  10 6  2:10  10 8 3:46  10 5  6:68  10 6 5:51  10 4  1:26  10 7 1:43  10 6  2:38  10 7
0.801  0.022
0.791  0.019
0.790  0.023
0.791  0.023
0.802  0.019
0.782  0.021
0.803  0.023
0.801  0.023
0.802  0.024
0.802  0.023
0.804  0.024
0.802  0.024
0.654  0.019
0.638  0.013
0.639  0.012
0.644  0.020
0.661  0.020
0.639  0.014
0.666  0.011
0.654  0.016
0.656  0.015
0.656  0.016
0.664  0.010
0.656  0.019
2:20  10 5  5:04  10 7 1:42  10 5  2:07  10 6 1:66  10 5  4:30  10 8 1:68  10 5  3:87  10 7 6:86  10 5  1:07  10 7 2:10  10 5  3:21  10 6
9:74  10 6  1:78  10 7 2:71  10 7  6:47  10 8 7:98  10 7  1:31  10 7 7:28  10 6  1:19  10 7 1:53  10 7  3:41  10 8 2:48  10 6  4:84  10 7
0.836  0.012
0.831  0.014
0.833  0.013
0.839  0.014
0.836  0.013
0.832  0.013
0.849  0.014
0.846  0.013
0.842  0.014
0.843  0.014
0.848  0.014
0.841  0.014
0.729  0.024
0.698  0.022
0.702  0.025
0.706  0.0333
0.709  0.032
0.710  0.032
0.733  0.035
0.712  0.036
0.714  0.031
0.722  0.036
0.731  0.036
0.723  0.032
4:56  10 7  4:12  10 5 3:23  10 7  3:14  10 7 2:89  10 7  3:78  10 7 4:23  10 7  2:78  10 6 6:13  10 7  4:78  10 4 4:56  10 7  2:67  10 5
5:67  10 8  3:56  10 5 5:78  10 8  5:78  10 4 5:23  10 8  3:67  10 7 3:89  10 8  7:64  10 2 7:23  10 8  2:67  10 4 3:34  10 8  2:67  10 6
0.856  0.012
0.896  0.014
0.872  0.013
0.895  0.014
0.875  0.013
0.890  0.013
0.878  0.014
0.900  0.013
0.889  0.014
0.903  0.014
0.898  0.014
0.921  0.014
0.779  0.037
0.776  0.033
0.793  0.029
0.754  0.032
0.772  0.022
0.718  0.049
0.798  0.045
0.800  0.051
0.798  0.044
0.767  0.062
0.784  0.025
0.745  0.048

2nd Reading

P2

Sad
10 6

ISSN: 0219-6352

Alpha band

10 6

R. YUVARAJ ET Al.

P2

Happy

1450006

Theta band

PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC

Type of Emotion

WSPC/179-JIN

Delta band

HOS
Features Group

12:16:38pm

Frequency
Band

18

Table 4. Range of various HOS based features (in mean  standard deviation) of the six emotions for PD patients (p < 0:0001) and HC (p < 0:0001).

March 4, 2014

Beta
Gamma














1.34
2.45
2.56
3.81
3.54
4.70
3.58
3.77
2.45
3.00
4.22
5.45

40.27
48.52
51.58
62.86
60.82
68.28
69.78
73.26
38.56
45.23
65.19
70.25














2.90
2.76
1.53
3.52
2.03
3.64
3.37
5.41
3.23
1.98
6.42
5.03

Fear (%)
43.98
49.34
62.11
64.57
61.07
67.47
62.11
67.14
50.23
55.67
66.36
70.08














1.56
2.35
3.60
2.67
4.92
2.57
1.66
3.60
3.23
3.34
5.60
6.61

Anger (%)
40.65
46.65
51.07
59.24
59.49
62.78
63.71
68.93
42.99
34.88
65.92
70.56














2.32
2.37
2.93
1.60
4.51
5.64
2.57
3.74
1.78
4.23
4.39
3.81

Surprise (%)

Disgust (%)

54.20
60.67
72.28
74.78
69.53
69.07
70.31
69.35
53.78
60.97
66.01
66.53

39.45
46.56
54.21
66.64
58.50
66.21
62.38
68.43
45.23
57.34
63.69
68.17














1.32
3.45
3.66
3.84
3.67
2.61
1.58
2.77
2.98
1.56
3.82
6.35














2.39
2.54
1.21
4.97
1.42
2.80
3.50
1.36
4.78
3.06
5.29
7.71

Average ClassiÂ¯cation
Rate (%)
45.15
51.70
59.49
66.35
64.61
68.93
66.70
70.51
47.90
52.37
66.53
69.47














The condition ALL represents the combination of Â¯ve EEG frequency bands and numbers in bold represents the highest average performance.

2.01
1.45
1.33
2.26
2.26
1.30
1.29
1.30
2.89
2.05
1.68
3.31

2nd Reading

All

52.34
58.45
65.64
70.06
78.24
79.82
71.92
75.99
56.56
60.10
72.03
71.28

Sadness (%)

ISSN: 0219-6352

Alpha

PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC

Happiness (%)

1450006

Theta

Group

WSPC/179-JIN

Delta

Type of Emotion

12:16:40pm

EEG Frequency
Band

Percentage of classiÂ¯cation results (  standard deviation) of SVM classiÂ¯er with spectral features (P1 , P2 , Mavg ).

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

Table 5(a).

19

March 4, 2014
WSPC/179-JIN

Delta

Beta

All

49.20
51.34
63.75
75.83
68.75
75.42
79.03
79.58
50.77
57.78
78.47
77.33














2.67
3.12
6.56
5.23
4.51
5.00
3.61
4.95
1.89
2.85
4.25
5.39

Sadness (%)
35.56
38.25
52.28
56.36
62.08
61.83
56.67
59.03
40.29
35.99
68.89
65.00














3.20
1.89
4.43
5.13
3.84
4.40
3.88
7.00
2.67
2.56
6.64
4.99

Fear (%)
36.24
45.23
51.47
57.92
58.33
58.06
63.75
63.14
45.12
52.65
55.06
62.50














2.76
1.45
4.86
5.42
3.39
3.21
7.27
3.49
2.80
2.08
6.73
6.20

Anger (%)
38.45
43.23
50.97
53.06
57.50
59.47
59.56
65.72
45.64
45.34
57.36
66.08














1.54
1.34
4.90
4.91
4.68
6.00
3.54
5.33
1.12
3.12
6.25
2.93

Surprise (%)

Disgust (%)

54.34
57.20
68.42
77.00
77.22
74.56
69.58
73.56
55.23
67.34
73.03
71.67

35.23
49.12
59.67
58.75
53.89
57.08
56.94
61.97
35.23
50.34
52.78
63.50














3.54
2.00
4.26
3.22
2.64
4.62
3.90
2.84
3.01
1.56
4.70
4.59














3.12
1.34
5.08
5.04
4.71
2.78
4.76
3.21
3.27
3.06
3.99
4.57

Average ClassiÂ¯cation
Rate (%)
41.50
47.40
57.42
63.15
62.96
64.40
64.26
67.84
45.48
51.58
64.26
67.68














1.61
2.11
1.51
1.91
1.30
1.27
1.59
2.34
2.05
1.96
2.06
1.58

The condition ALL represents the combination of Â¯ve EEG frequency bands and numbers in bold represents the highest average performance.

2nd Reading

Gamma

PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC

Happiness (%)

ISSN: 0219-6352

Alpha

Group

R. YUVARAJ ET Al.

Theta

Type of Emotion

1450006

EEG Frequency
Band

12:16:41pm

20

Table 5(b). Percentage of classiÂ¯cation results ( standard deviation) of kNN classiÂ¯er with spectral features (P1 , P2 , Mavg ).

March 4, 2014

Beta
Gamma














2.12
1.67
3.02
3.97
7.28
4.81
5.40
7.14
3.05
2.67
4.50
4.18

45.23  1.923
53.12  3.89
60.28  3.55
66.36  4.44
63.89  5.15
71.25  5.29
64.04  7.14
71.31  5.07
42.57  4.75
40.23  2.89
67.75  6.19
72.78  3.19

Fear (%)
48.34
50.12
57.47
67.92
62.22
76.25
66.50
73.72
54.90
60.34
61.67
73.67














2.12
4.34
6.59
4.30
4.94
2.74
5.49
5.32
5.87
2.76
4.71
5.08

Anger (%)
46.12
56.23
58.97
63.06
61.11
65.97
65.28
74.06
39.99
54.99
64.53
69.28














4.99
2.45
3.94
6.18
4.98
4.19
5.99
4.49
2.66
1.08
3.28
5.40

Surprise (%)

Disgust (%)

59.23
65.23
77.42
78.00
79.03
79.17
76.50
82.47
60.11
61.45
76.47
74.11

44.12
50.23
59.67
67.75
60.00
64.42
68.19
76.36
40.23
47.63
63.97
77.50














2.45
2.45
2.60
5.59
5.16
4.94
5.90
5.09
1.54
2.56
2.80
6.61














1.23
2.54
4.14
5.67
4.40
4.96
7.72
7.19
3.74
2.89
4.19
5.44

Average ClassiÂ¯cation
Rate (%)
50.34  2.33
56.59  3.87
65.44  1.46
70.47  2.14
68.36  1.73
73.90  1.88
70.10  2.83
77.29  1.73
49.73  3.38
56.20  1.87
69.48  1.42
74.90  2.92

The condition ALL represents the combination of Â¯ve EEG frequency bands and numbers in bold represents the highest average performance.

2nd Reading

All

58.98
64.56
78.83
79.75
83.89
86.39
80.14
85.83
60.54
72.56
82.50
82.06

Sadness (%)

ISSN: 0219-6352

Alpha

PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC

Happiness (%)

1450006

Theta

Group

WSPC/179-JIN

Delta

Type of Emotion

12:16:43pm

EEG Frequency
Band

Percentage of classiÂ¯cation results ( standard deviation) of SVM classiÂ¯er with HOS features (P1 , P2 , Mavg ).

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

Table 6(a).

21

March 4, 2014
WSPC/179-JIN

Delta

Beta

All

52.34
58.34
71.64
74.31
80.56
78.47
80.28
86.94
65.23
69.34
79.58
76.67

 1.56
 5.34
 3.71
 3.93
 4.28
 6.18
 3.41
 3.83
 2.45
 1.89
 3.43
 4.48

Sadness (%)
42.23
37.45
60.50
60.00
65.56
64.44
63.89
68.44
38.57
45.20
66.81
69.44














1.45
2.56
5.43
2.84
4.18
5.74
3.01
6.47
3.89
1.34
4.70
4.55

Fear (%)
40.89
40.45
62.64
60.69
61.25
63.19
62.92
69.97
44.55
50.24
59.72
64.17














1.67
2.90
5.17
3.88
3.30
3.16
3.53
5.98
3.29
1.45
2.70
4.03

Anger (%)
46.23
45.78
62.78
68.19
60.36
64.22
68.47
71.86
40.12
52.75
64.58
65.97














3.45
2.78
3.81
4.63
3.67
3.96
2.81
3.07
1.67
4.40
4.78
3.22

Surprise (%)

Disgust (%)

63.45
77.78
70.03
77.92
76.06
75.56
69.03
77.08
65.23
68.23
66.25
67.64

38.23
54.34
61.17
61.67
63.33
70.67
66.67
66.11
44.29
44.85
60.97
62.08














4.23
2.00
4.59
3.53
4.57
4.57
3.48
4.39
2.45
2.79
3.60
3.65














4.45
2.45
4.50
3.72
3.77
2.72
3.93
5.20
2.23
1.34
3.49
3.21

Average ClassiÂ¯cation
Rate (%)
47.23
52.36
64.80
67.10
67.86
69.43
68.54
73.40
49.66
55.11
66.32
67.66














3.64
1.09
1.24
1.70
1.46
1.09
1.90
1.72
3.38
2.43
1.27
1.10

The condition ALL represents the combination of Â¯ve EEG frequency bands and numbers in bold represents the highest average performance.

2nd Reading

Gamma

PD
HC
PD
HC
PD
HC
PD
HC
PD
HC
PD
HC

Happiness (%)

ISSN: 0219-6352

Alpha

Group

R. YUVARAJ ET Al.

Theta

Type of Emotion

1450006

EEG Frequency
Band

12:16:45pm

22

Table 6(b). Percentage of classiÂ¯cation results ( standard deviation) of kNN classiÂ¯er with HOS features (P1 , P2 , Mavg ).

March 4, 2014

12:16:46pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

23

Fig. 9. Emotion classiÂ¯cation accuracy (beta band) of PD patients and HC across six emotional states
for HOS based features applied to SVM classiÂ¯er. The bars on the top of each emotion represent the
standard deviation.

Tables 7(a) and 7(b) show average confusion matrices of the PD patients and HC
obtained for the power spectrum-based features and HOS-based features for all the
six emotional states applied to SVM classiÂ¯er using beta band. The confusion matrix
from the tables in both groups indicates that the features were classiÂ¯ed as surprise or
sadness instead of happiness; disgust, fear or anger instead of sadness. Also, a signiÂ¯cant number of disgust features were wrongly classiÂ¯ed as sadness. The emotion
misclassiÂ¯cation is mainly due to the subjective nature of emotions where the intensity and valence of emotion induced vary from person to person. It also infers the
Table 7(a). Average confusion matrix for power spectrum-based process
obtained by SVM using beta band (that achieved highest average accuracy
for six emotional states in PD group and HC).
Output
Input

Happiness

(a) PD patients
Happiness
52
Sadness
0
Fear
3
Anger
2
Surprise
12
Disgust
2
(b) Healthy controls
Happiness
55
Sadness
1
Fear
0
Anger
2
Surprise
16
Disgust
0

Sadness

Fear

Anger

Surprise

Disgust

3
50
6
6
1
14

1
3
45
5
2
10

1
1
11
46
3
11

8
1
3
6
51
3

0
9
8
7
0
45

7
53
2
12
1
12

4
5
49
5
3
5

1
2
4
50
2
5

14
0
0
2
51
0

2
7
4
6
0
50

March 4, 2014

12:16:47pm

WSPC/179-JIN

1450006

24

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.
Table 7(b). Average confusion matrix for HOS-based process obtained by
SVM using beta band (that achieved highest average accuracy for six
emotional states in PD group and HC),
Output
Input

Happiness

(a) PD patients
Happiness
58
Sadness
0
Fear
0
Anger
0
Surprise
15
Disgust
0
(b) Healthy controls
Happiness
62
Sadness
1
Fear
0
Anger
2
Surprise
7
Disgust
2

Sadness

Fear

Anger

Surprise

Disgust

2
47
6
10
5
13

0
2
48
10
5
6

1
3
8
47
5
7

6
0
1
0
55
1

0
11
5
6
0
49

3
52
6
10
0
7

1
4
53
1
2
3

0
6
8
54
0
3

11
0
1
0
60
1

1
10
5
1
0
55

presence of multiple emotions in the participants which has to be dealt with
appropriately.
5. Discussions
We have presented a framework for classifying six basic emotions in PD patients
based on computerized pattern analysis, against HC. In the self-assessment data, no
signiÂ¯cant diÂ®erences were found for PD patients and HC among the six emotional
states. It is noteworthy that these Â¯ndings are not due to small data set size in
statistical testing since PD patients were descriptively even better in recognizing
stimuli happiness, fear and disgust compared to HC (see Table 2).
DiÂ®erent researchers made use of the fact that HOS is capable of analyzing hidden
characteristics of EEG which standard spectral estimation cannot for diÂ®erent EEG
processing applications. A HOS based BIS index (i.e., bispectral index) monitoring
method is probably one of the most popular commercially available anesthesia
monitoring methods (Myles et al., 2004). Huang et al. (2004) used a method called
third-order recursive (TOR) to estimate the bispectrum of scalp EEG from rats
obtained during ischemia (Huang et al., 2007). They were able to achieve 91.67%
accuracy in performing injury assessment with the derived features namely weighted
center of bispectrum (WCOB) and bicoherence index. In other work, the moments of
HOS analysis were used to classify EEG signals corresponding to left/right-hand
motor imagery (Zhou et al., 2008). The feature set included parameters derived from
moments of the power spectrum and moments based on the bispectrum of the EEG
signals. Experimental results have shown that based on the proposed features, the
LDA classiÂ¯er, SVM classiÂ¯er and NN classiÂ¯er achieved better classiÂ¯cation results

March 4, 2014

12:16:48pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

25

than those of the BCI-competition 2003 winner (Blankertz et al., 2004; Schlogl,
2003).
In this study, we made use of HOS as features (Mavg , P1 and P2 ) for emotional
state classiÂ¯cation in PD patients in comparison with HC. Furthermore, EEGs are
very complex signals with possible non-linearity interaction among its frequency
components and perhaps some form of phase coupling. These \random" signals
cannot be fully described by second-order measures (i.e., power spectrum). Our experimental result shows that the classiÂ¯ers with the HOS based features perform
better than the classiÂ¯er with second-order measures (see Tables 5(a), 5(b), 6(a) and
6(b)). Higher-order spectra information is able to reveal some information about nonlinearity and deviation of Guassianity which could likely be present in emotional
EEGs. Hence, HOS based features become more discriminative than those of secondorder measures from power spectrum.
A number of research works have been done to classify emotional states using EEG
signals in user independent way. For HC, the highest accuracy for six emotional
states were: 85:83%  7:14% for happiness, 71:31%  5:07% for sadness, 73:72% 
5:32% for fear, 74:06%  4:49% for anger, 82:47%  5:09% for surprise and 76:36% 
7:19% for disgust (see Table 6(a)). It is diÂ±cult to compare the obtained accuracy of
emotional states with previous research works in HC, since number of targeted
emotional states varied from study to study. Therefore, the overall classiÂ¯cation
accuracy of the emotional states is compared. So far, a maximum average classiÂ¯cation accuracy of 85.17% has been achieved on recognizing six emotions (happiness,
surprise, anger, fear, disgust and sadness) in user independent approach (Petrantonakis & Hadjileontiadis, 2010). Similarly, 82.29% and 93.5% has been obtained for
detecting four emotions (joy, anger, sadness and pleasure) and two emotions (happiness and sadness), respectively in user independent approach (Li & Lu, 2009; Lin
et al., 2010). Recently, Hosseini (2012) achieved an average accuracy of 82.32% for
only two emotional states (neutral and negative) on image-induced EEG emotional
dataset using HOS. In contrast to previous report in emotion recognition with young
adults, this present study achieved 77:29%  1:73% in older adult HC participants on
classifying six emotions in a user independent way by using nonlinear feature HOS.
Since we examined considerably older adult participants (mean age of 58:10  2:95
years) than all previous studies, this lower average accuracy is most likely due to the
participants' age. Age is known to be associated with a decline in cognitive functions
(Friedman, 2003; Orgeta, 2009; RuÂ®man et al., 2008). In a comparable way, age may
be associated with a decline in emotional processing.
For PD patients, the better classiÂ¯cation accuracy for six emotional states were:
80:14%  5:40% for happiness, 64:04  7:14% for sadness, 66:50%  5:49% for fear,
65:28%  5:99% for anger, 76:50%  5:90% for surprise and 68:19%  7:72% for
disgust (see Table 6(a)). This provided a diÂ®erent viewpoint and new insights into
emotional responses to PD patients. So far, no related work that speciÂ¯cally
attempted the EEG frequency bands based emotion recognition in PD patients using
machine learning techniques has been reported in the literature and therefore, it was

March 4, 2014

12:16:48pm

WSPC/179-JIN

1450006

26

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

diÂ±cult for the acquired results to be discussed. In addition, the better results were
achieved through the activity of beta band, which have been suggested to reÂ°ect
emotional phenomenon (Aftanas et al., 2006). In general, a direct comparison between
the classiÂ¯cation accuracy and self-assessment evaluation for emotions reveals that
happiness followed by surprise (with highest accuracy) was the easiest to identify and
disgust followed by sadness (with lowest accuracy) was the most diÂ±cult, with anger
and fear being of intermediate diÂ±culty to identify from the PD patients results.
In the group of HC, the highest average accuracy of classiÂ¯ed six emotional states
in the frequency band was: 56:59%  3:87% for delta, 70:47%  2:14% for theta,
73:90%  1:88% for alpha, 77:29%  1:73% for beta, 56:20%  1:87% for gamma and
74:90%  2:92% for all condition (see Table 6(a)). Notably, in the PD patient's only
highest accuracy of 50:34%  2:33% for delta, 65:44%  1:46% for theta, 68:36% 
1:73% for alpha, 70:10%  2:83% for beta, 49:73%  3:38% for gamma and 69:48% 
1:42% for all condition was obtained (see Table 6(a)). The values across the frequency bands clearly indicate that the classiÂ¯cation accuracy of PD patient's emotional state EEG is lower than HC during emotion processing, suggesting that
emotional impairments associated with PD patients. This Â¯nding indicates the
neuropathological evidence that PD could be associated with the slowing of oscillatory brain activity (Neufeld et al., 1988; Yeager et al., 1966). This slowing of brain
activity exhibits a signiÂ¯cant correlation with progression of Hoehn & Yahr stages in
PD (Morita et al., 2009). Although our PD participants were tested on dopaminergic
medication, they still revealed signs of dopamine deÂ¯ciency as indicated by a mean
value of 17.05 in the motor part of the UPDRS. In addition, we also observed that PD
patients achieved less pattern classiÂ¯cation accuracy in the processing of negative
emotions (sadness, fear, anger and disgust) than in processing of positive emotions
(happiness, surprise). As many researchers have suggested, individuals with PD may
be particularly impaired in recognizing negative emotions because of dysfunction in
speciÂ¯c neural circuits (Adolphs et al., 1996; Bouchard et al., 2008; Lawrence et al.,
2007; Sprengelmeyer et al., 2003; Suzuki et al., 2006; Tessitore et al., 2002). Recent
evidence points to neuropathological changes in PD in many brain areas which are
assumed to play key roles in emotion processing (Kober et al., 2008). These include
limbic structures such as the amygdala, and the ventral striatum, which is centrally
located within the basal ganglia's limbic loop.
6. Limitations of this Study
Several limitations of the present study have to be considered. First, our Â¯ndings are
limited by the fact that patients with severe PD were not included in the study (H &
Y 4â€“5), which might be a possible explanation for the impairments of emotion recognition in PD patients. Second, all PD patients were under dopamine replacement
therapy (i.e., medication), which might also aÂ®ect the performance in the emotion
processing (Tessitore et al., 2002) and future research is required with unmedicated
patients to reveal the actual eÂ®ects on PD (Sprengelmeyer et al., 2003). Finally,

March 4, 2014

12:16:48pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

27

human emotions are dependent on number of variables such as: room temperature,
time of the day, mental activity level of the participant before recording, hormone
levels, circadian rhythms, verbalization and breathing conditions (Jerritta et al.,
2013). Though much care was to exclude these issues by allowing the participant to
choose their own free time for participating in the experiment and relax by means of
breathing exercise before start of the experiment, more care should be taken to
consider these diÂ®erences. The impact of these diÂ®erences on the emotional state of
the person also needs to be studied.
7. Conclusion
This study indicates that machine learning methods can aid the detection of
emotional impairment in PD patients based on EEG signals. The design of emotion elicitation protocol for inducing six basic emotional states (happiness, sadness,
fear, anger, surprise and disgust) and the data acquisition methodology were
explained in detail. EEG signals are very noise-like and complex in nature and the
required information is diÂ±cult to extract. HOS techniques are advantageous in
gaining information about the nonlinear dynamics of the system. In this work, we
made a comparative study to classify six emotional states EEG signal (PD patients
and HC) with features derived from higher-order statistics and features derived
from second-order power spectrum. The performances of the derived features were
analyzed using two classiÂ¯ers namely kNN and SVM. The HOS based features
yields better results of 70:10%  2:83% for PD patients and 77:29%  1:73% for
HC through beta band activity using SVM classiÂ¯er. Besides, PD patients
achieved less accuracy in the processing of negative emotions (sadness, fear, anger
and disgust) than in processing of positive emotions (happiness, surprise) compared with HC.
Future research has to be performed to investigate other HOS features to improve
the performance of the system with respect to HC. Additional investigation pertaining to feature selection could also improve the classiÂ¯cation performance, while
reducing computational time.
Acknowledgments
The research was Â¯nancially supported by Ministry of Science and Technology
(MOSTI), Malaysia. Grant Number: 9005-00053. The authors would like to thank
Dr. Mohamad Fadli, Dr. Siva Rao Subramanian and Dr. Shahrul Azmin for their
assistance with recruitment of PD participants. Also we would like to thank all of the
individuals who participated in this study.
REFERENCES
Adolphs, R., Damasio, H., Tranel, D. & Damasio, A.R. (1996) Corticle systems for the
recognition of emotion in facial expressions. J. Neurosci., 16, 7678â€“7687.

March 4, 2014

12:16:48pm

28

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

Adolphs, R., Schul, R. & Tranel, D. (1998) Intact recognition of facial emotion in Parkinson's
disease. Neuropsychology., 12, 253â€“258.
Aftanas, L.I., Reva, N.V., Savotina, L.N. & Makhnev, V.P. (2006) Neurophysiological correlates of induced discrete emotions in humans: An individually oriented analysis.
Neurosci. Behav. Physiol., 36(2), 119â€“130.
Aftanas, L.I., Reva, N.V., Varlamov, A.A., Pavlov, S.V. & Makhnev, V.P. (2004) Analysis of
evoked EEG synchronization and desynchronization in emotional activation in humans:
Temporal and topographic characteristics. Neurosci. Behav. Physiol., 34, 859â€“867.
Ariatti, A., Benuzzi, F. & Nichelli, P. (2008) Recognition of emotions from visual and prosodic cues in Parkinson's disease. Neurol. Sci., 29, 219â€“227.
Bailenson, J.N., Pontikakis, E.D., Mauss, I.B., Gross, J.J., Jabon, M.E., Hutcherson, C.A.C.,
Nass, C. & John, O. (2008) Real-time classiÂ¯cation of evoked emotions using facial feature
tracking and physiological responses. Int. J. Hum. Comput. Stud., 66, 303â€“317.
Balconi, M. & Lucchiari, C. (2008) Consciousness and arousal eÂ®ects on emotional face
processing as revealed by brain oscillations. A gamma band analysis. Int. J. Psychophysiol., 67, 41â€“46.
Balli, T. & Palaniappan, R. (2010) ClassiÂ¯cation of biological signals using linear and nonlinear features. Physiol. Meas., 31, 903â€“920.
Baumgartner, T., Esslen, M. & Jancke, L. (2006) from emotion perception to emotion
experience: Emotions evoked by pictures and classical music. Int. J. Psychophysiol., 60,
34â€“43.
Beck, A.T., Ward, C.H., Mendelson, M., Mock, J. & Erbaugh, J. (1961) An inventory for
measuring depression. Arch. Gen. Psychiatry, 4, 561â€“571.
Blair, R.J.R. (2003) Facial expressions, their communicatory functions and neuro-cognitive
substrates. Philos. Trans. R Soc. Lond, B Biol. Sci., 358, 561â€“572.
Blankertz, B., Muller, K.-R., Curio, G., Vaughan, T.M., Schalk, G., Wolpaw, J.R., Schlogl,
A., Neuper, C., Pfurtscheller, G., Hinterberger, T., Schroder, M. & Birbaumer, N. (2004)
The BCI competition 2003: Progress and perspectives in detection and discrimination of
EEG single trials. IEEE Trans. Biomed. Eng., 51, 1044â€“1051.
Bouchard, T.P., Malykhin, N., Martin, W.R., Hanstock, C.C., Emery, D.J., Fisher, N.J. &
Camicioli, R.M. (2008) Age and dementia-associated atrophy predominates in the hippocampal head and amygdala in Parkinson's disease. Neurobiol. Aging, 29, 1027â€“1039.
Bowers, D., Miller, K., Mikos, A., Kirsch-Darrow, L., Springer, U., Fernandez, H., Foote, K.
& Okun, M. (2006) Startling facts about emotion in Parkinson's disease: Blunted reactivity to aversive stimuli. Brain, 129, 3356â€“3365.
Bradley, M.M. & Lang, P.J. (2007) International aÂ®ective digitized sounds (2nd Edition;
IADS-2): AÂ®ective ratings of sounds and instruction manual. Technical Report B-3
University of Florida, Gainesville, FL.
Brown, L., Grundlehner, B. & Penders, J. (2011) Towards wireless emotional valence detection from EEG. Conf. Proc. IEEE Eng. Med. Biol. Soc., 2188â€“2191.
Burgees, C.J.C. (1998) A tutorial on support vector machines for pattern recognition. Data
Min. Knowl. Disc., 2, 1â€“47.
Christianini, N. & Taylor, J. (2000) Support Vector Machines and Other Kernel-Based
Learning Methods. Cambridge: Cambridge University Press.
Chua, K.C., Chandran, V., Acharya, U.R. & Lim, C.M. (2011) Application of higher order
spectra to identify epileptic EEG. J. Med. Syst., 35, 1563â€“1571.

March 4, 2014

12:16:48pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

29

Clark, U.S., Neargarder, S. & Cronin-Golomb, A. (2008) SpeciÂ¯c impairments in the recognition of emotional facial expressions in Parkinson's disease. Neuropsychologia, 46, 2300â€“
2309.
Cohen, I., Garg, A. & Huang, T.S. (2000) Emotion recognition from facial expressions using
multilevel HMM, In: Conf. Proc. in Neural Information Processing Systems.
Cohen, S. & Janicki-Deverts, D. (2009) Can we improve our physical health by altering our
social networks? Perspect. Psychol. Sci., 4, 375â€“378.
Cornelius, R.R. (1996) The Science of Emotion. Upper Saddle River, NJ: Prentice Hall.
Dara, C., Monetta, L. & Pell, M.D. (2008) Vocal emotion processing in Parkinson's disease:
Reduced sensitivity to negative emotions. Brain Res., 1188, 100â€“111.
Davidson, R.J. (2004). What does the prefrontal cortex \do" in aÂ®ect: Perspectives on frontal
EEG asymmetry research. Biol. Psychol., 67, 219â€“233.
Davidson, R.J., Ekman, P., Saron, C.D., Senulis, J.A. & Friesen, W.V. (1990), ApproachWithdrawal and cerebral asymmetry: Emotional expression and brain physiology. J. Pers.
Soc. Psychol., 58, 330â€“341.
Dujardin, K., Blairy, S., Defebvre, L., Duhem, S., NoÃ«l, Y., Hess, U. & Destee, A. (2004)
DeÂ¯cits in decoding emotional facial expressions in Parkinson's disease. Neuropsychologia,
42, 239â€“250.
Ekman, P. & Friesen, W.V. (1987) Universals and cultural diÂ®erences in the judgments of
facial expressions of emotion. J. Pers. Soc. Psychol., 53, 712â€“714.
Fahn, S., Elton, R.L. & Committee, M. (1987) UniÂ¯ed Parkinson's disease rating ccale. In: C.
D. Marsden, D.B. Calne, M. Goldstein and D.B. Clane, eds. Recent Developments in
Parkinson's Disease. Florham Park: Macmillan Health Care Information., pp. 153â€“163.
Folstein, M.F., Folstein, S.E. & Mchugh, P.R. (1975) Mini-mental state examination: A
practical method for grading the cognitive state of patients. Psychol. Res., 12, 189â€“198.
Friedman, M.F. (2003) Cognition and aging: A highly selective overview of event related
potential (ERP) data. J. Clin. Exp. Neuropsychol., 25, 702â€“720.
Gao, J., Hu, J. & Tung, W. (2011) Facilitating joint chaos and fractal analysis of biosignals
through nonlinear adaptive Â¯ltering. Plos One, 6, 1â€“8.
Gow, A.J., Pattie, A., Whiteman, C.M., Whalley, L.J. & Deary, J.I. (2007), Social support
and successful aging: Investigating the relationships between lifetime cognitive change and
life satisfaction. J. Ind. DiÂ®er., 28, 103â€“115.
Gray, H.M. & Tickle-Degnen, L. (2010) A meta-analysis of performance on emotion recognition tasks in Parkinson's disease. Neuropsychology, 24, 176â€“191.
Gross, J.J. & Levenson, R.W. (1995) Emotion elicitation using Â°ims. Cogn. Emotion, 9,
87â€“108.
Haag, A., Goronzy, S., Schaich, P. & Williams, J. (2004) Emotion recognition using biosensors: First steps towards an automatic system. In: E. Andre, L. DybkjÃ¦r, W. Minker
and P. Heisterkamp, eds. AÂ®ective Dialogue Systems. Springer: Heidelberg., pp. 36â€“48.
Hadjidimitriou, S.K. & Hadjileontiadis, L.J. (2012) Toward an EEG-based recognition of
music liking using time-frequency analysis. IEEE Trans. Biomed. Eng., 59, 3498â€“3510.
Hamdi, H., Richard, P., Suteau, A. & Allain, P. (2012) Emotion assessment for aÂ®ective
computing based on physiological responses. In: Conf. Proc. Fuzzy Systems (FUZZ-IEEE),
IEEE International Conference on, World Congress Computational Intelligence (WCCI),
pp. 1â€“8, 10â€“15 June 2012.

March 4, 2014

12:16:49pm

30

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

Han, J. & Kamber, M. (2006) Data Mining: Concepts and Techniques, 2nd edn. Morgan
Kaufmann.
Hoehn, M.M. & Yahr, M.D. (1967) Parkinsonism: Onset, progression and mortality.
Neurology, 17, 427â€“442.
Hosseini, S.A. (2012) ClassiÂ¯cation of brain activity in emotional states using HOS analysis.
Int. J. Image, Graph. Signal Process., 1, 21â€“27.
Hsu, C.W., Chang, C.C. & Lin, C.J. (2003) A practical guide to support vector classiÂ¯cation.
Technical Report, Department of Computer Science, National Taiwan University.
Huang, L., Zhao, J., Singare, S., Wang, J. & Wang, Y. (2007), Discrimination of cerebral
ischemic states using bispectrum analysis of EEG and artiÂ¯cial neural network. Med. Eng.
Phys., 29, 1â€“7.
Jerritta, S., Murugappan, M., Wan, K. & Yaacob, S. (2013) ClassiÂ¯cation of emotional states
from electrocardiogram signals: A non-linear approach based on Hurst. Biomed. Eng.
Online, 12, 44â€“62.
Kan, Y., Mimura, M., Kamijima, K. & Kawamura, M. (2004) Recognition of emotion from
moving facial and prosodic stimuli in depressed patients. J. Neurol. Neurosurg. Psychiatry,
75, 1667â€“1671.
Kannathal, N., Acharya, U.R., Lim, C.M. & Sadasivam, P.K. (2005) Characterization of
EEG
A comparative study. Comput. Meth. Progr. Biomed., 80, 17â€“23.
Kannathal, N., Rajendra, U.R., Alias, F., Tiboleng, T. & Puthusserypady, S.K. (2004)
Nonlinear analysis of EEG signals at diÂ®erent mental states. Biomed. Eng. Online, 3, 1â€“11.
Kessous, L., Castellano, G. & Caridakis, G. (2010), Multimodal emotion recognition in
speech-based interaction using facial expression, body gesture and acoustic analysis. J.
Multimodal User Interf., 3, 33â€“48.
Kim, J. (2007) Bimodal emotion recognition using speech and physiological changes. Technical Report.
Kim, J. & Andre, E. (2008) Emotion recognition based on physiological changes in music
listening. IEEE Trans. Pattern Anal. Mach. Intell., 30, 2067â€“2083.
Kim, K.H., Bang, S.W. & Kim, S.R. (2004) Emotion recognition system using short-term
monitoring of physiological signal. Med. Biol. Eng. Comput., 42, 419â€“427.
Kober, H., Barrett, L.F., Joseph, J., Bliss-Moreau, E., Lindquist, K. & Wagera, T.D. (2008)
Functional grouping and corticalâ€“subcortical interactions in emotion: A meta-analysis of
neuroimaging studies. NeuroImage, 42, 998â€“1031.
Lang, P.J. (1995) The emotion probe: Studies of motivation and attention. Am. Psychol., 50
(5), 372â€“385.
Lang, P.J., Greenwald, M.K., Bradley, M.M. & Hamm, A.O. (1993) Looking at the pictures:
AÂ®ective, facial, visceral, and behavioral reactions. Psychophysiology, 30, 261â€“273.
Lawrence, A.D., Goerendt, I.K. & Brooks, D.J. (2007) Impaired recognition of facial
expression of anger in Parkinson's disease patients acutely withdrawn from dopamine
replacement therapy. Neuropsychologia, 45, 65â€“74.
Li, M. & Lu, B.L. (2009) Emotion classiÂ¯cation based on gamma band EEG. In: Conf.
Proc. IEEE Eng. Med. Biol. Soc. IEEE Engineering in Medicine and Biology Society
(IEMBS), pp. 1323â€“1326.
Lima, C.F., Garrett, C. & Castro, S.L. (2013) Not all the sounds sound the same: Parkinson's
disease aÂ®ects diÂ®erently emotion processing in music and in speech prosody. J. Clin. Exp.
Neuropsychol., 35, 373â€“392.

March 4, 2014

12:16:49pm

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

EMOTION CLASSIFICATION IN PD BY HIGHER-ORDER SPECTRA

31

Lin, Y.P., Wang, C.H., Wu, T.L., Jeng, S.K., Duann, J.R. & Chen, J.H. (2010) EEG-based
emotion recognition in music listening. IEEE Trans. Biomed. Eng., 57, 1798â€“1806.
Madeley, P., Ellis, A. & Mindham, R. (1995) Facial expressions and Parkinson's disease.
Behav. Neurol., 8, 115â€“119.
Melillo, P., Bracale, M. & Pecchia, L. (2011) Nonlinear heart rate variability features for reallife stress detection. Case study: Students under stress due to university examination.
Biomed. Eng. Online, 10, 1â€“13.
Mikels, J., Fredrickson, B., Larkin, G., Lindberg, C., Maglio, S. & Reuter-Lorenz, P. (2005)
Emotional category data on images from the international aÂ®ective picture system. Behav.
Res. Methods, 37, 630â€“636.
Miller, K.M., Okun, M.S., Marsiske, M., Fennell, E.B. & Bowers, D. (2009) Startle reÂ°ex
hyporeactivity in Parkinson's disease: An emotion-speciÂ¯c or arousal-modulated deÂ¯cit?
Neuropsychologia, 47, 1917â€“1927.
Morita, A., Kamei, S., Serizawa, K. & Mizutani, T. (2009) The relationship between
slowing EEGs and the progression of Parkinson's disease. J. Clin. Neuropsychol., 26,
426â€“429.
Muller, K.R., Mika, S., Ratsch, G., Tsuda, K. & Scholkopf, B. (2001) An introduction to
kernal based learning algorithms. IEEE Trans. Neural Netw., 12, 181â€“201.
Murugappan, M., Nagarajan, R. & Yaacob, S. (2010) Combining spatial Â¯ltering and wavelet
transform for classifying human emotions using EEG signals. J. Med. Biol. Eng., 31,
45â€“51.
Murugappan, M., Rizon, M., Nagarajan, R. & Yaacob, S. (2009) An investigation on visual
and audiovisual stimulus based human emotion recognition using EEG. IJMEI, 1, 342â€“
356.
Myles, P.S., Leslie, K., McNeil, J., Forbes, A. & Chan, M.T. V. (2004) Bispectral index
monitoring to prevent awareness during anesthesia: The B-Aware randomized controlled
trial. Lancet, 363, 1757â€“1763.
Neufeld, M.Y., Inzelberg, R. & Korczyn, A.D. (1988) EEG in demented and non-demented
parkinsonian patients. Acta Neurol. Scand., 78, 1â€“5.
Nikias, C.L. & Petropulu, A. (1993) Higher-Order Apectral Analysis: A Nonlinear Signal
Processing Framework. Englewood CliÂ®s, NJ: Prentice Hall.
OldÂ¯eld, R.C. (1971) The assessment and analysis of handedness: The Edinburgh inventory.
Neuropsychologia, 9, 97â€“113.
Orgeta, V. (2009) SpeciÂ¯city of age diÂ®erences in emotion regulation. Aging Ment. Health.,
13, 818â€“826.
Paulmann, S. & Pell, M.D. (2010) Dynamic emotion processing in Parkinson's disease as a
function of channel availability. J. Clin. Exp. Neuropsychol., 32, 822â€“835.
Pell, M.D. & Leonard, C.L. (2003) Processing emotional tone from speech in Parkinson's
disease: A role for the basal ganglia. Cogn. AÂ®ect. Behav. Neurosci., 3, 275â€“288.
Pell, M.D. & Leonard, C.L. (2005) Facial expression decoding in early Parkinson's disease.
Cogn. Brain Res., 23, 327â€“340.
Peron, J., Dondaine, T., Jeune, F.L., Grandjean, D. & Verin, M. (2012) Emotional processing
in Parkinson's disease: A systematic review. Mov. Disord, 27, 186â€“199.
Petrantonakis, P.C. & Hadjileontiadis, L.J. (2010) Emotion recognition from brain signals
using hybrid adaptive Â¯ltering and higher order crossings analysis. IEEE Trans. AÂ®ect.
Comput., 1, 81â€“96.

March 4, 2014

12:16:49pm

32

WSPC/179-JIN

1450006

ISSN: 0219-6352

2nd Reading

R. YUVARAJ ET Al.

Petrantonakis, P.C. & Hadjileontiadis, L.J. (2011) A novel emotion elicitation index using
frontal brain asymmetry for enhanced EEG-based emotion. IEEE Trans. Inf. Technol.
Biomed., 15, 737â€“746.
Rani, P. & Sarkar, N. (2006) A new approach to implicit human-robot interaction using
aÂ®ective cues. In L. Aleksandar, ed. Mobile Robots: Towards New Applications. I-Tech
Education and Publishing.
Redondo, J., Fraga, I., Padron, I. & Pineiro, A. (2008) AÂ®ective ratings of sound stimuli.
Behav. Res. Methods, 40, 784â€“790.
RuÂ®man, T., Henry, J.D., Livingstone, V. & Phillips, L.H. (2008) A meta-analytic review of
emotion recognition and aging: Implications for neuropsychological models of aging.
Neurosci Biobehav. Rev., 32, 863â€“881.
Sammler, D., Grigutsch, M., Fritz, T. & Koelsch, S. (2007) Music and emotion: Electrophysiological correlates of the processing of pleasant and unpleasant music. Psychophysiology, 44, 293â€“304.
Schlogl, A. (2003) Outcome of the BCI-competition 2003 on the Graz data set, Available at:
http://citeseerx.ist.psu.edu/viewdoc/download?doiÂ¼10.1.1.139.5555&rep Â¼rep1&typeÂ¼pdf.
oder, C., Mobes, J., Schutze, M., Szymanowski, F., Nager, W., Bangert, M., Munte, T.F.
Schrâ‚¬
& Dengler, R. (2006) Perception of emotional speech in Parkinson's disease. Mov. Disord.,
21, 1774â€“1778.
Shen, M., Chan, F.H.Y., Sun, L. & Beadle, F.J. (2000) Parametric bispectral estimation of
EEG signals in diÂ®erent functional states of the brain, In: IEE Proc. Sci. Meas Technol.,
147(6), 374â€“377.
Sprengelmeyer, R., Young, A.W., Mahn, K., Schroeder, U., Woitalla, D., BÃ¼ttner, T., Kuhn,
W. & Przuntek, H. (2003) Facial expression recognition in people with medicated and
unmedicated Parkinson's disease. Neuropsychologia, 41, 1047â€“1057.
Suzuki, A., Hoshino, T., Shigemasu, K. & Kawamura, M. (2006) Disgust-speciÂ¯c impairment
of facial expression recognition in Parkinson's disease. Brain, 129, 707â€“717.
Tessitore, A., Hariri, A., Fera, F., Smith, W., Chase, T., Hyde, T., Weinberger, D. & Mattay,
V. (2002) Dopamine modulates the response of the human amygdala: A study in Parkinson's disease. J. Neurosci., 22, 9099â€“9103.
Wang, Y. & Guan, L. (2008) Recognizing human emotional state from audiovisual signals.
IEEE Trans. Multimedia, 10, 659â€“668.
Wieser, M.J., Klupp, E., Weyers, P., Pauli, P., Weise, D., Zeller, D., Classen, J. & Muhlberger, A. (2012) Reduced early visual emotion discrimination as an index of diminished
emotion processing in Parkinson's disease?
Evidence from event-related brain potentials. Cortex, 48, 1207â€“1217.
Yeager, C.L., Alberts, W.W. & Denature, L.D. (1966) EÂ®ect of stereotaxic surgery upon
electroencephalographic status of parkinsonian patients. Neurology, 16, 904â€“910.
Yip, J.T., Lee, T.M., Ho, S.L., Tsang, K.L. & Li, L.S. (2003) Emotion recognition in patients
with idiopathic Parkinson's disease. Mov. Disord., 18, 1115â€“1122.
Yuvaraj, R., Murugappan, M., Omar, M.I., Norlinah, M.I., Sundaraj, K., Khairiyah, M. &
Satiyan, M. (2013) Emotion processing in Parkinson's disease: An EEG spectral power
study. Int. J. Neurosci., 22, 1â€“12.
Zhou, S.M., Gan, J.Q. & Sepulveda, F. (2008) Classifying mental tasks based on features of
higher order statistics from EEG signals in brain computer interface. Inf. Sci., 178, 1629â€“1640.

