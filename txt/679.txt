Entertainment Computing 5 (2014) 391–399

Contents lists available at ScienceDirect

Entertainment Computing
journal homepage: ees.elsevier.com/entcom

Comparing interaction techniques for serious games through
brain–computer interfaces: A user perception evaluation study q
Fotis Liarokapis a,d,⇑, Kurt Debattista b, Athanasios Vourvopoulos c, Panagiotis Petridis d, Alina Ene d
a

Human Computer Interaction Laboratory, Masaryk University, Faculty of Informatics, Botanická 554/68a, Brno, Czech Republic
WMG, University of Warwick, Gibbet Hill Road, Coventry CV32 5LD, UK
c
Madeira Interactive Technologies Institute, University of Madeira, Funchal, Portugal
d
Serious Games Institute, Coventry Innovation Village, Coventry University Technology Park, Cheetah Road, Coventry, West Midlands CV1 2TL, UK
b

a r t i c l e

i n f o

Article history:
Received 11 April 2014
Revised 25 September 2014
Accepted 10 October 2014
Available online 22 October 2014
Keywords:
Serious games
Brain–computer interfaces
Virtual environments
Human–machine interaction

a b s t r a c t
This paper examines the application of commercial and non-invasive electroencephalography (EEG)based brain–computer (BCIs) interfaces with serious games. Two different EEG-based BCI devices were
used to fully control the same serious game. The ﬁrst device (NeuroSky MindSet) uses only a single
dry electrode and requires no calibration. The second device (Emotiv EPOC) uses 14 wet sensors requiring
additional training of a classiﬁer. User testing was performed on both devices with sixty-two participants
measuring the player experience as well as key aspects of serious games, primarily learnability,
satisfaction, performance and effort. Recorded feedback indicates that the current state of BCIs can be
used in the future as alternative game interfaces after familiarisation and in some cases calibration.
Comparative analysis showed signiﬁcant differences between the two devices. The ﬁrst device provides
more satisfaction to the players whereas the second device is more effective in terms of adaptation and
interaction with the serious game.
Ó 2014 Elsevier B.V. All rights reserved.

1. Introduction
The past decade has seen a huge proliferation of commercial
interaction devices for video games. Each of these new devices
offers a diverse way of interacting with games and computer generated simulations. Typical technologies that these devices use
include: optical, auditory, magnetic and inertia sensors. Some can
operate as autonomous controllers while others work in hybrid
mode (with standard I/O devices such as mouse and keyboard).
However, only the hybrid approaches appear to be functional, the
rest require a lot of physical effort. This restricts users’ expressive
capabilities as well as the information transferred from the user to
the computer [1]. Nowadays, non-invasive brain–computer interfaces (BCIs) are getting a lot of attention as alternative human–
computer interaction devices for games and virtual environments
[2,3].

q

This paper has been recommended for acceptance by Christos Gatzidis, Ph.D.

⇑ Corresponding author at: Human Computer Interaction Laboratory, Masaryk
University, Faculty of Informatics, Botanická 554/68a, Brno, Czech Republic. Tel.:
+420 549493948.
E-mail addresses: liarokap@ﬁ.muni.cz (F. Liarokapis), K.Debattista@warwick.ac.
uk (K. Debattista), athanasios.vourvopoulos@m-iti.org (A. Vourvopoulos),
PPetridis@cad.coventry.ac.uk (P. Petridis), enea@uni.coventry.ac.uk (A. Ene).
http://dx.doi.org/10.1016/j.entcom.2014.10.004
1875-9521/Ó 2014 Elsevier B.V. All rights reserved.

Non-invasive BCIs operate by recording the brain activity from
the scalp with Electroencephalography (EEG) sensors attached to
the head on an electrode cap or headset without being surgically
implanted. However, they still have a number of problems and
they cannot function as accurately as other natural user interfaces
(NUIs) and traditional input devices such as the standard keyboard
and mouse [4]. The Information Transfer Rate (ITR) of this kind of
BCIs is still around 25 bits per minute [5], which makes them much
slower compared to traditional input devices such as keyboard
(which have typical speed of over 300 characters per minute,
roughly 400 bits per minute) [6]. The main reasons behind this
are due to bad classiﬁcation, long training procedures, latency
issues and cumbersome hardware [7]. Also, because of lack of
training and accessibility in using BCI devices, some people ﬁnd
it difﬁcult to use at all [8].
The majority of BCI studies are performed in laboratory environments under controlled conditions. However this is not always
possible in real-life applications and makes current BCI technology
not quite suitable for practical applications and widespread use [9].
Game designers and researchers must make sure that BCIs used for
gaming environments should not become a barrier in terms of the
interaction [10] but on the contrary a more effective medium.
Although non-invasive BCI technologies seem to have the potential
of providing an environment where ‘‘thoughts are not constrained

392

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399

by what is physically possible’’ [7], they are still not ready for commercial use.
The main aim of the paper is to examine the effectiveness of
two different BCI devices for fully controlling an avatar inside a
serious game. The objectives of the paper are threefold. Firstly, to
enable a user to fully control an avatar in real-time using only
EEG data. Secondly, to qualitatively examine the behaviour and different reactions of the users while playing the game and, thirdly, to
test each device in terms of: learnability of the interface using the
game, satisfaction of the player, performance of the interfaces and
effort expended by the player. Two different EEG-based BCI devices
were used; one which requires no calibration (NeuroSky MindSet)
and another one that requires the training of the classiﬁers (Emotiv
EPOC). The user is visually stimulated by fully controlling an avatar
in the serious game (see Section 3). Two different types of EEGbased BCIs were used: the NeuroSky MindSet and the Emotiv EPOC.
All tests (N = 62) were conducted using the same serious game,
which was integrated with the devices; participants were divided
equally across the devices.
The rest of the paper is structured as follows. Section 2 provides
background information for serious games and BCIs. Section 3, presents the serious game that was used as a case study called Roma
Nova. Section 4 demonstrates how the two different BCI devices
were used for controlling the same serious game. Finally, Section 5
presents the evaluation results and Section 6 the conclusions and
future work.

2. Background
Early non-invasive BCI research methods for serious games
interaction were usually oriented towards the medical domain
rather than entertainment. This kind of research was targeting
locked-in patients where haptic and linguistic interfaces fail. The
ﬁrst BCI game was created in 1977. In this game, the user could
move in four directions in a maze by ﬁxating on one of four diamond-shaped points periodically ﬂashed. The methodology used
was far ahead of its time using online artefact rejection and adaptive classiﬁcation. The information transfer rate (ITR) was remarkable even for today’s standards being above 170 bits/min [11].
Two survey papers regarding BCI systems have been recently
published [12,13]. In another recent paper the opportunities and
challenges posed by neuroscientiﬁc methods when capturing user
feedback and using the data to create greater user adaptivity in
game are explored [35]. Berta et al. [36] provides an electroencephalogram and physiological signal analysis for assessing ﬂow in
games. The paper deﬁnes ﬂow in games as a measure of keeping
the player fully immersed and engaged in the process of activity
within the game. The evaluation of ﬂow involves a 4 electrode
EEG, using the low beta frequency bands for discriminating among
gaming conditions. Using simple signals from the peripheral nervous system three levels of user states were branded using a Support Vector Machine classiﬁer. The user states where identiﬁed
using 3 levels of a simple plane battle game identifying states of
boredom, ﬂow and anxiety. The paper argues that a personalised
system could be implemented in a consumer context allowing
for more ﬂowing gameplay in consumer games.
Moreover, there are a number of experimental applications of
using BCIs with computer games. Some of these prototypes are
very simplistic and just allow the users to select 3D objects in
games based on their attention levels [9]. Nowadays, many
different techniques are currently used in BCI systems for user
interaction and control. Steady State Visual Evoked Potentials
(SSVEP) using ﬂashing lights for visual stimulation, the P300 BCI
is measuring the brain evoked response after stimulus onset with
a positive curve on the EEG after 300 ms and the ERS/ERD

which stands for event related synchronisation/desynchronisation
through the imaginary limp movement.
An example of BCI-based input devices using motor-control is
the mu (l) rhythm based ﬁrst person shooter game proposed by
Pineda et al. [14] which uses information from the motor cortices
of the brain to steer left/right, while forward/backwards movement
is controlled by physical buttons. Another similar BCI system by
Krepki [15] uses motor-control based on lateralized readiness
potential (LRP) – a slow negative shift in the EEG over the activated
motor cortex – for controlling the Pacman game. An example of
P300 based games are Bayliss virtual driving task and a virtual
apartment [16], [17] with highlighted red objects evoking a P300
when the user wants to make a selection.
Another recent P300 game is Finkes MindGame [18] were the
P300 events are translated into movements of a character on a
three-dimensional game board. SSVEP based games have been also
designed based on subjects’ attention to a visual stimulus. In the
Mind Balance game [19], a SSVEP is evoked by two different checkerboards with the participant’s attention focused in one of the two
checkerboards to balance an avatar on a piece of string. An advantage of SSVEP over induced BCI paradigms is the multiple option
selection by focusing attention on a stimulus. An example is the
2D racing game using SSVEP to control four different directional
movements [20] in a similar way to how the FPS game was controlled in SSVEP BCI [21].
There are a lot of prototypes that use a multimodal approach by
combining BCIs with other gaming controllers (i.e. keyboard,
mouse, Wii controller, etc) [7]. A typical example of multimodal
BCI system is the Bacteria Hunt game where the goal is of ‘eating’
as many bacteria as possible [22]. The user avatar is controlled
using the keyboard whereas the amoeba is modulated by the user’s
alpha activity (higher alpha results in more control). In the game
‘FindingStar’, users control the entities of the game using emotional
signals coming from the BCI and use the mouse and the keyboard to
defeat monsters and solve puzzles [23]. The ‘NeuroWander’ game
uses the emotional and attentional states of the users to perform
various quests and the navigation is performed using mouse and
keyboard [24].
‘Affective Pacman’ was developed to investigate the frustration
of users while playing a BCI game [25]. The game is controlled with
two buttons that rotate Pacman. Frustration is caused by malfunctioning controls of the game. In another study, a steady-state visual
evoked potential (SSVEP) based BCI, was used to control an avatar
in the game ‘World of Warcraft’ [26]. To control the avatar, users
had to control four icons. Three were used to have the avatar turn
left, turn right and move forward and an-other one to perform certain actions such as grasping objects and attacking other objects.
In another study, researchers used BCI technology to interact
with mobile games [10]. A maze game with three different levels
utilising meditative and attentive states was tested with 22 participants. Results indicated that the use of BCI technology with
mobile games has the potential to offer new and exciting ways of
game interaction. The MindFlex game is a commercial EEG-based
BCI game played as a social activity at home [27]. The aim of the
game is to interact with a ﬂoating ball around an obstacle course
assembled on the game board. While these kinds of BCI techniques
for controlling games are quite interesting, most of the games so
far are proofs of concept. The interaction with these games is really
slow, often with decreased game-play speed to allow for BCI control. This has an obvious impact on the average gamer, resulting
in potential frustration and loss of engagement and interest.
3. The Roma Nova serious game
The aim of the Rome Reborn project was to create highly realistic 3D representations illustrating the urban development of

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399

ancient Rome from the ﬁrst settlement in the late Bronze Age (ca.
1000 B.C.) to the depopulation of the city in the early Middle Ages
(ca. A.D. 550) [28]. The project includes hundreds of buildings,
thirty-two of which are highly detailed monuments reconstructed
on the basis of reliable archaeological evidence. The remainder of
the 25–30 km2 model are ﬁlled with procedurally-generated buildings based on accurate historical knowledge. Fig. 1 (left image)
illustrates the northern side of the Roman Forum with the Curia
Iulia in the foreground, next to which is the Basilica Aemilia. In
the distance is seen the Temple of the Divine Julius Caesar on the
east side of the Forum plaza. The Curia was the principal place
where the Senate met.
The interactive game (Fig. 1, right image) is built upon Rome
Reborn and it is termed the Roma Nova project. It builds on previous work at Coventry University [29,30] and it is a serious game
that aims at teaching history to children (11–14 years old). The
game allows for exploratory learning by immersing the learner/
player inside a virtual heritage environment where they learn different aspects of history through their interactions with a crowd of
virtual Roman avatars. The game was built on the ‘Unity 3D’ game
engine using parts of the realistic reconstruction of ancient Rome.
For the purpose of this work, both navigation and interaction is
performed using brain-wave technology from the two headsets.
Players can interact with the serious game in three different
ways according to the Levels of Interaction (LoI) framework
[29,30]. LoI aims in simplifying the interactions between the
players and automated ‘non-player’ characters. The ﬁrst level of
interaction offers a living background enhancing the player’s experience and immersion. At the second level of interaction characters
are automatically provided with a more realistic graphic representation and more complex behaviours. Finally, at the last level of
interaction, a conversational agent at the dialogue level appears
as a more traditional way to teach the learner [30].
The implementation of the Roma Nova game that was integrated and tested with the two BCI systems includes: (a) a crowd
of Roman characters in the Forum and (b) a highly detailed set of
buildings that belong to the Rome Reborn model. Intelligent agents
were wandering around in the gaming environment between
predeﬁned points of interest, whereas the player is able to move
freely and is controlled via the BCI devices. To interact with the
intelligent agents, the BCI-controlled player needs to approach
them. Then, the intelligent agents change their current target to
the position of the player, and hence start walking towards the
player. When the intelligent agent is close enough to enter the dialogue level, a series of actions are triggered by the engine [30]: (a)
an animation is triggered to change the camera from a wide angle
to a close-up perspective; (b) the smoothed highly detailed version
of the Roman character mesh is loaded to replace the low polygon
version, along with the corresponding animations and (c) the steering controller attributed to every background character is dropped
and replaced by a straightforward engine developed to play the
scenario.

393

4. BCI interactions
This section presents the two different BCI devices that were used
(NeuroSky MindSet and the Emotiv), the hardware conﬁguration as
well as the methods used for interacting with the serious game.
4.1. Hardware conﬁguration
In terms of the hardware conﬁguration, both prototypes used
off-the-shelf hardware components. For the ﬁrst prototype a laptop with a 64 bit Intel(R) Core(TM) 2 Duo processor T6600 at
2.2 GHz and 4 GB of memory was used in conjunction with the
NeuroSky MindSet neuro-headset (i.e. one electrode at the FP1
position). The laptop was equipped with an NVIDIA GeForce GT
240 M graphics card. Standard laptop display technology, a 160
inch wide LCD has been used to display the serious game. The NeuroSky MindSet device is a complete headset with speakers and
microphone transmitting data on Bluetooth. It allows extracting
the ‘Attention’ and ‘Meditation’ levels of the user called ‘‘eSense
Meters’’ [31] through the different EEG frequency bands by a
black-boxed NeuroSky algorithm into an integer range of 0–100.
The Attention is extracted through the modulation of the frequency band that is triggered by the intensity of a user’s level of
mental ‘‘focus’’ when user focuses on a single thought or an external object and decreases when distracted. On the other hand, Meditation levels increase when the user relaxes his/her mind and
decreases when he/she is uneasy or stressed. The NeuroSky headset uses a single dry sensor attached to the forehead outside the
cerebral cortex in the frontal lobe of the brain being responsible
for the attention level and short-term memory tasks [32]. As soon
as a connection between the Roma Nova game and the headset is
established, it initiates a connection with the avatar and the simulation to send movement instructions.
Similar hardware components were used for the second prototype – with the main component being the Emotiv EPOC neuroheadset. A laptop with a 64-bit Intel(R) Core(TM) 2 Duo processor
T7700 at 2.4 GHz and 4 GB of memory was used for the evaluation
study. The laptop is equipped with an NVIDIA GeForce 8700 M GT
graphics card. The Emotiv headset is a neuro-signal acquisition and
processing wireless neuro-headset with 14 wet sensors (and 2 reference sensors) which is capable of detecting brain signals as well
user’s facial expressions [33]. This requires a unique user proﬁle to
be created and train a classiﬁer for the movement of the four directions based on user’s brain-patterns. The prototype system uses a
combination of Cognitive and Facial/Muscular functions. The Emotiv Development Kit was used connecting the Emotiv EPOC headset
to the Emotiv control panel to create and train a new user proﬁle.
The user is visually stimulated by controlling an avatar in the serious game (Roma Nova). The raw data is calculated on the headset’s
chip and sent to the dedicated computer in a 128 Hz frequency.
Afterwards the software generates the keystroke events moving
the player based on the users’ brain-activity and facial expressions.

Fig. 1. Left image: Rome Reborn reconstruction [28], Right image: Roma Nova game in action.

394

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399

4.2. Avatar interaction
Both systems are capable of fully controlling the avatar even if
they have a completely different conﬁguration and numbers of
sensors. As mentioned before, the NeuroSky MindSet uses only
one sensor so that main challenge was to ‘map’ the output of the
device to the standard movements of an avatar within a computer
game. Moreover, even if no prior training is required to capture
data from the device, new users need to familiarise themselves
with the device, to control their attention and meditation. As soon
as the Roma Nova serious game establishes connection with the
headset it initiates the simulation. Both ends of the connection
can ‘open’ input and output streams and read/write data. The
headset sends two integer values (in the range 0–100) to the game
with a frequency of 128 Hz depending on the attention and meditation levels of the user. The meditation component indicates the
level of a user’s mental ‘calmness’ or ‘relaxation’. Table 1 illustrates
how these values were mapped to represent direction and speed of
the avatar.
Players control the avatar by changing cognitive states such as
meditation and attention. For example, to go right, they will try
to concentrate as hard as possible, while to take a left, users have
to defocus their attention. Going straight ahead is possible only
by maintaining a balance between the two states. High levels of
meditation will prompt the avatar to run, medium levels will cause
it to walk, low levels will make it go backwards and extremely low
levels of meditation will cause it to stand still Table 1 illustrates
the values that were assigned for controlling the direction and
the speed of the players.
On the other hand, the Emotiv prototype (Fig. 2) requires prior
training to operate the device. Training an effective new user proﬁle takes approximately 30–60 min depending on the adaptability
of the user. However, training the proﬁle is not an easy task and
requires practise and familiarisation, especially when the user
needs to train more than two actions as it is easy to get distracted
from outside stimuli and ‘confuse’ the training process of the user’s
real ‘intentions’. In a training session of no more than 1 h, the

Table 1
Controlling the direction and speed of the player (avatar).
Attention (0–100)

Direction

0–40
40–75
75–100

Turn left
Go straight ahead
Turn right

Meditation (0–100)
0–30
30–50
50–70
70–100

Speed
Stand still
Go backwards
Walk
Run

classiﬁer can be trained adequately for the forward & backward
movements by using the Emotiv control panel [34].
New players can gain control over a single action quite quickly.
Learning to control multiple actions typically requires practise and
becomes progressively harder as additional actions are added. As
players learn to train reproducible mental states for each action,
the detection becomes increasingly precise. Most players typically
achieve their best results after training each action several times.
Overtraining can sometimes produce a decrease in accuracy –
although this may also indicate a lack of consistency and mental
fatigue. Practise and experience will help determine the ideal
amount of training required for each individual user to successfully
interact with the serious game [34]. As soon as the proﬁle is created, then the combination of Cognitive and Facial/Muscular functions were used to control the avatar in the Roma Nova game. In
particular to go forwards or backwards cognitive functions were
used. To turn left or right the Facial/Muscular functions were used
such as eye blinking.
5. User study
This section presents the procedure followed for the evaluation
together with the qualitative and quantitative results of both
studies as well as a comparative study.
5.1. Participants and procedure
The testing was performed in open-space laboratory conditions
and conference demonstration areas. Sixty-two participants took
part in the user study. It was ensured that each participant was
comfortable and at ease prior to the start of the experiment. Even
if pulse rates or stress levels were not evaluated, each participant
was asked to sit-down and a brieﬁng was provided allowing them
to be as calm and relaxed as possible.
For the NeuroSky prototype participants were allowed ﬁve minutes to accommodate with controlling the avatar and around three
minutes to complete the task of arriving at a particular destination.
The prototype was used by 31 users, across the span of two months
(see Fig. 2). In particular, it was tested at Coventry University computer games laboratory, at the third Phoenix Partner Annual conference (which took place at Coventry University) as well as at
the Archeovirtual 2012 International conference (which took place
at Paestum, Italy, 15–18 November 2012). The participants were
selected via random sampling to generate a non-biased set of
results from a section that is more representative of the population. The dominant age group of the sample was 18–25 (74.19%
of the total sample), consisting of 60.65% male participants and
39.35% females.
For the Emotiv prototype, 31 users were asked to provide comments on a questionnaire anonymously after playing the serious

Fig. 2. Ability to control events using the Emotiv device.

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399

game. The testing was performed an open-space environment at
two locations at Coventry University: the Serious Games Institute
(SGI) and the Department of Computing. Summarising the data
samples from the users, descriptive statistics have been generated
to quantify the experience. The sample consisted of 67.7% male and
32.3% females with a dominant age group of 18–25. The questionnaire used a Likert scale ranging from 1 to 5.
All users were given a participant information leaﬂet to read
beforehand and a consent form to ﬁll in and sign. The user survey
was designed to gather both quantitative and qualitative data.
Quantitative data has been collected on questions that require
the participants to answer using a Likert scale, whereas qualitative
data was gathered through the means of open-ended questions.
After going through the gaming scenario, each user was asked to
rate their experience taking into consideration learnability of the
interface using the game, satisfaction of the player, performance
of the interfaces and effort put by the player. These questions were
closely followed by open-ended questions that aim to collect data
on the overall experience and potentially suggest improvements.
5.2. Qualitative results
All participants were asked to provide detailed comments on
the questionnaire anonymously. Also an unstructured short interview took place in a light mood after the trial. These comments/
suggestions may contribute towards future improvements of BCI.
With respect to the ﬁrst prototype, participants were drawn by
the ease of use of the BCI device for controlling the virtual character (avatar) via EEG technology. They viewed the concept as an
interesting approach for future gaming scenarios, categorising
the whole experience as challenging, enjoyable and engaging. In
particular, most participants were immediately engaged with the
game and they wanted not only to perform the task (move from
one position to another), but to explore the whole virtual city of
the Roma Nova game and interact with the artiﬁcial intelligent
agents (which were controlled by the computer) to become more
knowledgeable about the history of Rome.
Even though the game-play was generally seen as ‘fun and fascinating’, some were dissatisﬁed with the avatar movement accuracy, and this affected learnability. It is worth-mentioning that
some participants were able to recognise some movement types
better than others. Turning left and right (switching from a strong
state of concentration to a more relaxed state) was reported as
the most difﬁcult part to manage. Some reported a lag of around
2–3 s between their intentions and the actual output. While some
participants had some difﬁculty with estimating the degree to
which they reached their goal, others were running the test later
during the day compared to people playing the game in the
morning hours which may have affected their ability to concentrate fully.
Some participants mentioned the need for an initial training,
user-proﬁling period and in-game guide. They found it easy to

395

use the device but much harder to adapt to it and felt it was hard
to ‘train’ their brains to concentrate and meditate. Going backwards was not seen as a popular movement type amongst players
and its removal was advocated. Seeing relevant feedback on the
screen, apart from the actual character movement, was suggested
as being highly beneﬁcial to the experience. Also, they wanted
the interface to show the actual measured data, to get real-time
feedback and know what to do to attempt self-regulating the
attention/meditation levels. A couple proposed the introduction
of hotkeys that should facilitate what attention can measure and
last but not least, the implementation of the concept using a different game was advised.
For the second prototype a very useful suggestion was made
about the Graphical User Interface (GUI) of the game. Participants
found it easier to focus on the GUI components instead of the
virtual character to perform the required action. This might be a
result of the training trial, in which the users had to push/pull a virtual cube and when entering the virtual environment they had to
re-adapt to the new elements. This can be conﬁrmed by reports
that it was easier to move the avatar by concentrating on the cube
from the training trial, than actually visualising the character
movement through space.
In contradiction to NeuroSky, navigating into the game was
much easier. It is a clear indication that it would be better for
the training trial to include the components from the game for
the user to get familiarised. Alternatively, assistive GUI components might be a useful addition. Overall the experience was
reported as quite engaging and interesting regardless of certain
issues of response time and accuracy that other Natural User Interfaces (NUI’s) might have. As soon as the participants had an ‘effective’ trained proﬁle, then the level interaction was very satisfactory
thus improving the learning process in respect to the serious game.
Furthermore, it was reported that people with more experience in
computer games will have an easier time learning to use the interface due to the simulation and interaction required for a computer
game. That experience makes it much easier to learn how to operate the interface.
In terms of possible improvements participants did not feel very
conﬁdent with the initial training of the device to create a personalised user-proﬁle. Some found it hard to train, especially when
using the cognitive functions. This was expected since the Emotiv
device requires training but it varies on the effectiveness of each
person. Another issue that was reported had to do with the contact
of the sensors in relation to the user’s heads. Moreover, some participants reported that after a few minutes of interaction they were
getting tired. The tiredness increased after more than 30 min of
usage. Some participants proposed the introduction of hotkeys that
should facilitate what attention and meditation can measure and
last but not least, the implementation of the concept using a different game was advised. Additional recommendations comprise of
the incorporation of more sensors and maybe eye tracking technology in order to enhance movement accuracy (see Fig. 3).

Fig. 3. User testing at archeovirtual, Paestum, Italy 2012.

396

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399

5.3. Quantitative results
In this section the results of testing each device in terms of:
learnability of the interface using the game (Learnability), satisfaction of the player (Satisfaction), performance of the interfaces
(Performance) and effort required by the player (Effort) are presented. Table 2 presents an overview of all the relevant statistics
which are presented in further detail below.

Table 2
Relevant statistics for the NeuroSky and Emotiv based on questionnaire response.

Mann–Whitney U
z
P
Mean NeuroSky
Mean Emotiv

Learnability

Satisfaction

Performance

Effort

185.0
4.376
<0.001
2.5161
3.6774

207.5
4.046
<0.001
4.4516
3.4516

211.5
3.957
<0.001
2.4516
3.5806

259.5
3.271
<0.01
3.8065
3.1290

Fig. 4 shows distribution of responses for Learnability. For Learnability, Kolmogorov–Smirnov was signiﬁcant for both groups
D(31) = 0.25, p < 0.001, for NeuroSky and D(31) = 0.21, p < 0.001
for Emotiv indicating a non-normal distribution. Due to the lack
of normal distribution and the relatively low number of samples
(N = 62) the non-parametric Mann–Whitney test was used to test
for signiﬁcance in this case and those below (Kolmogorov–Smirnov
is reported for all cases). For Learnability the NeuroSky data
(mean = 2.561) was considered signiﬁcantly different from Emotiv
data (mean = 3.667) U = 185, z = 4.376, p < 0.001. Emotiv is
considered to be performing better in this case by a signiﬁcant
amount.
Fig. 5 shows distribution of responses for Satisfaction. For Satisfaction, Kolmogorov–Smirnov was again signiﬁcant for both
groups D(31) = 0.25, p < 0.001 for NeuroSky and D(31) = 0.25,
p < 0.001 for Emotiv indicating the distribution of this variable
was not normal. For Satisfaction the NeuroSky data (mean = 4.451)
was considered signiﬁcantly different from Emotiv data (mean =

Fig. 4. Learnability of the interface using the game (left NeuroSky, right Emotiv).

Fig. 5. Player satisfaction (left NeuroSky, right Emotiv).

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399

3.451) U = 207.5, z = 4.046, p < 0.001. For Satisfaction the
NeuroSky performs better.
Fig. 6 demonstrates the distribution of responses for Performance. For Performance, Kolmogorov–Smirnov was signiﬁcant
D(31) = 0.23, p < 0.05 for NeuroSky and D(31) = 0.26, p < 0.001 for
Emotiv, indicating the data did not belong to a normal distribution.
For Performance the NeuroSky data (mean = 2.451) was considered
signiﬁcantly different from Emotiv data (mean = 3.580) U = 211.5,
z = 3.957, p < 0.001. For Performance, these results indicate that
the Emotiv per-forms signiﬁcantly better than the NeuroSky.
Fig. 7 illustrates the distribution of responses for Effort.
For Effort, Kolmogorov–Smirnov was signiﬁcant D(31) = 0.30,
p < 0.001 for NeuroSky and D(31) = 0.27, p < 0.001 for Emotiv, indicating the data was not normally distributed. For Effort the NeuroSky data (mean = 3.807) was considered signiﬁcantly different
from Emotiv data (mean = 3.129) U = 259.5, z = 3.271, p < 0.01.
For Effort, the participants considered the NeuroSky to require
signiﬁcantly more effort in the overall.

397

6. Conclusions and future work
This paper presented two different ways of fully interacting
with the same serious game using non-invasive BCIs. Two different
EEG-based BCI devices were used, one single dry electrode which
requires no calibration and a second that needs some calibration
classiﬁer training in order to create a user proﬁle using also 14
wet electrodes. Overall the results indicate that both BCI technologies offer the potential of being used as alternative game interfaces
prior to some familiarisation with the device and in some cases
some sort of calibration. It was clear that the Emotiv device was
better for gaining knowledge about the History of Rome (which
is the goal of the serious game) and thus preferred for serious
games.
Speciﬁcally, as far as the qualitative feedback is concerned, both
categories of participants enjoyed the interaction experience. They
were all in favour of using EEG technology for controlling and
interacting with games even if they stated that the technology is

Fig. 6. Performance of the interface (left NeuroSky, right Emotiv).

Fig. 7. Effort put by the player (left NeuroSky, right Emotiv).

398

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399

not as accurate as alternative interaction devices (i.e. keyboard,
mouse, joystick, etc). NeuroSky users found it easier to use the
device but much harder to adapt to it. They felt it was hard to
‘train’ their brains to concentrate and meditate at their ﬁrst
attempt. However, after some self-training it is possible to improve
performance considerably. This varies according to the user and
more studies need to be performed on this issue. On the contrary,
the Emotiv device was easier to perform the training procedure
and control the avatar more accurately, but takes a lot more time
due to the increased complexity. Also, setup (which includes
creating a user proﬁle) is much more complicated compared to
the NeuroSky.
In terms of the quantitative analysis, the Emotiv device proved
to be more effective for controlling the avatar into the serious
game and for learning on how to use the interaction device,
whereas the NeuroSky device performed better in terms of satisfaction of the player. There were signiﬁcant differences between
the two devices for the four aspects of the questionnaire reported.
Controlling the character using the Emotiv was considered less
effort as expected due to the increased sensitivity of the Emotiv
compared to the NeuroSky. The performance was also better for
the Emotiv for similar reasons. The NeuroSky was considered more
satisfying perhaps owing to the immediate use of it due to the lack
of setup as compared to the Emotiv. Learnability was also
considered better for Emotiv likely due to the same reasons as
Performance and Effort.
Moving towards to out-of-the-box BCI Games, training and
adaptation is required for both the user and the machine for a successful interaction. It is an iterative learning process in which two
entities (humans and computers) are adapting in a closed loop
with the serious game for optimising the following: (a) interaction
experience from the human side and (b) predeﬁned desired result
on the computer side. We can construct this as three different
parts: (a) the user, (b) the machine where the data acquisition
and translation is taking place, and (c) game/virtual environment
where actions are visualised and adapted to the internal elements
of the game based on the inputs, closing the loop. From one side,
while the user learns to operate the interface the game is adapted
based on user performance and proﬁciency, on the other hand the
translated electrophysiological data must be used in a meaningful
way, minimising random actions that could trigger false feedback
back to the user. Over time, the skill is honed; hence, the feedback
must reﬂect the user’s task in an appropriate way. As it was mentioned before, all current brain controlled games are proof of concepts and they do not satisfy the requirements to be treated
equally as any other games. In order to be able to create a serious
game controlled with such a unique interface, we have to create
mechanisms that will ensure a successful interaction. This can be
achieved through game design principles modiﬁed for braincontrol, adaptive gameplay based on user performance, and
mechanisms for engaging the participants to the process.
As a future step, further prototype developments could also
include an analysis into how certain audio tracks can stimulate
concentration/attention and inherently affect game-play. Additional recommendations comprise of the incorporation of more
sensors and maybe eye tracking technology to enhance movement
accuracy. More sophisticated non-invasive BCI devices equipped
with more electrodes and sensors will be also used followed by
another comparative study. This will allow for a further analysis
based on the combination of different readings.
Acknowledgements
The authors would like to thank the Human Computer Interaction Laboratory at Masaryk University, the WMG at the Warwick
University as well as the Serious Games Institute (SGI) at Coventry

University members for their support and inspiration. Two
videos that demonstrate both systems in operation can be found
online at: <http://www.youtube.com/watch?v=L6t4Ji5yu7k> and
<http://www.youtube.com/watch?v=5Y_clGGoO4Y>.

References
[1] H. Gürkök, G. Hakvoort, M. Poel, Modality switching and performance in a
thought and speech controlled computer game, in: Proceedings of the 13th
International Conference on Multimodal Interfaces, ACM Press, 2011, pp. 41–
48.
[2] A. Lécuyer, F. Lotte, R.B. Reilly, R. Leeb, M. Hirose, M. Slater, Brain–computer
interfaces, virtual reality and video games, IEEE Comput. 41 (10) (2008) 66–72.
[3] A. Nijholt, B. Reuderink, D. Plass-Oude Bos, Turning shortcomings into
challenges: brain–computer interfaces for games, Entertainment Comput. 1
(2) (2009) 85–94.
[4] D.P.O. Bos, H. Gürkök, B. Reuderink, M. Poel, Improving BCI performance after
classiﬁcation, in: Proceedings of the 14th ACM International Conference on
Multimodal Interaction, ACM Press, 2012, pp. 587–594.
[5] J.R. Wolpaw, N. Birbaumer, D.J. McFarland, G. Pfurtscheller, T.M. Vaughan,
Brain–computer interfaces for communication and control, Clin. Neurophysiol.
113 (6) (2002) 767–791.
[6] T.M. Cover, J.A. Thomas, Joy Elements of Information Theory, second ed.,
Springer, Berlin, 2006.
[7] D.P.O. Bos, B. Reuderink, et al., Human–computer interaction for BCI games:
usability and user experience, in: Proceedings of the 2010 Int’l Conference on
Cyberworlds, Springer, 2010, pp. 277–281.
[8] A. Nijholt, D. Tan, Brain–computer interfacing for intelligent systems, IEEE
Intell. Syst. IEEE Comput. Soc. 23 (3) (2008) 72–79.
[9] F. Lotte, Brain–computer interfaces for 3D games: hype or hope?, in:
Proceedings of the 6th Int’l Conference on Foundations of Digital Games,
ACM Press, 2011, pp 325–327.
[10] P. Coulton, C.G. Wylie, W. Bamford, Brain interaction for mobile games, in:
Proceedings of the 15th Int’l Academic MindTrek Conference. Envisioning
Future Media Environments, ACM Press, 2011, pp. 37–44.
[11] J.J. Vidal, Real-time detection of brain events in EEG, Proc. IEEE 65 (5) (1977)
633–641.
[12] L.F. Nicolas-Alonso, J. Gomez-Gil, Brain computer interfaces, a review, Sensors
12 (2) (2012) 1211–1279.
[13] L. Bi, X.A. Fan, Y. Liu, EEG-based brain-controlled mobile robots: a survey, IEEE
Trans. Hum. Mach. Syst. IEEE Comput. Soc. 43 (2) (2013) 161–176.
[14] J.A. Pineda, D.S. Silverman, A. Vankov, J. Hestenes, Learning to control brain
rhythms: making a brain–computer interface possible, IEEE Trans. Neural Syst.
Rehabil. Eng. 11 (2) (2003) 181–184.
[15] R. Krepki, B. Blankertz, G. Curio, K. Muller, The Berlin brain–computer interface
(BBCI) – towards a new communication channel for online control in gaming
applications, Multimedia Tools Appl. 33 (1) (2007) 73–90.
[16] J.D. Bayliss, Use of the evoked potential P3 component for control in a virtual
apartment, IEEE Trans. Neural Syst. Rehabil. Eng. 11 (2) (2003) 113–116.
[17] J.D. Bayliss, S.A. Inverso, A. Tentler, Changing the P300 brain computer
interface, Cyberpsychol. Behav. 7 (6) (2004) 694–704.
[18] A. Finke, A. Lenhardt, H. Ritter, The MindGame: a P300-based brain–computer
interface game, Neural Netw. 22 (9) (2009) 1329–1333.
[19] E.C. Lalor, S.P. Kelly, C. Finucane, R. Burke, R. Smith, R.B. Reilly, G. McDarby,
Steady-state VEP-based brain–computer interface control in an immersive 3D
gaming environment, EURASIP J. Appl. Sign. Process. (2005) 3156–3164.
[20] P. Martinez, H. Bakardjian, A. Cichocki, Fully online multicommand brain–
computer interface with visual neurofeedback using SSVEP paradigm, in:
Computational Intelligence and Neuroscience, Hindawi Publishing
Corporation, 2007 (Article ID: 94561, 9 pages).
[21] M.M. Jackson, R. Mappus, E. Barba, S. Hussein, G. Venkatesh, C. Shastry, A.
Israeli (Eds.), 2009. Continuous Control Paradigms for Direct Brain Interfaces,
Human–Computer Interaction. Novel Interaction Methods and Techniques,
Lecture Notes Comput. Sci., vols. 5611, Springer-Verlag, pp. 588–595.
[22] H. Hwang, K. Kwon, C.H. Im, Neurofeedback-based motor imagery training for
brain–computer interface (BCI), Neurosci. Methods Elsevier 179 (1) (2009)
150–156.
[23] M. Ko, K. Bae, G. Oh, T. Ryu, A study on new gameplay based on brain computer
interface, in: Proceedings of DiGRA 2009, Brunel University, London, UK, 2009.
[24] M.S. Yoh, J. Kwon, S. Kim, NeuroWander: a BCI game in the form of interactive
fairy tale, in: Proceedings of the 12th Int’l Conference Adjunct Papers on
Ubiquitous Computing, ACM Press, 2010, pp. 389–390.
[25] B. Reuderink, A. Nijholt, M. Poel, Affective Pacman: a frustrating game for
brain–computer interface experiments, in: Proceedings of INTETAIN 2009,
Springer, 2009, pp. 221–227.
[26] C. Kapeller, C. Hintermüller, C. Guger, Augmented control of an avatar using an
SSVEP based BCI, in: Proceedings of the 3rd Augmented Human Int’l
Conference, Article No. 27, ACM Press, 2012.
[27] K. O’Hara, A. Sellen, R. Harper, Embodiment in brain–computer interaction, in:
Proceedings of the Int’l Conference on Human Factors in Computing Systems
(CHI’11), ACM Press, Vancouver, Canada, 2011, pp. 353–362.
[28] Rome Reborn, Available at: <http://www.romereborn.virginia.edu/>, 2013
(accessed 17.03.2013).

F. Liarokapis et al. / Entertainment Computing 5 (2014) 391–399
[29] D. Panzoli, A. Qureshi, et al., Levels of interaction (LoI): a model for scaffolding
learner engagement in an immersive environment, intelligent tutoring
systems, Lect. Notes Comput. Sci. 6095 (2010) (2010) 393–395.
[30] D. Panzoli, C. Peters, et al., A level of interaction framework for exploratory
learning with characters in virtual environments, in: Intelligent Computer
Graphics, in: Studies in Computational Intelligence, vol. 321, Springer-Verlag,
Berlin, Heidelberg, 2010, pp. 123–143.
[31] NeuroSky’s eSense™ Meters and Detection of Mental State, Available at:
<http://company.neurosky.com/ﬁles/neurosky_esense_whitepaper.pdf>, 2013
(accessed 17.03.2013).
[32] A. Vourvopoulos, F. Liarokapis, Robot navigation using brain–computer
interfaces, in: Proceedings of the 11th Int’l Conference on Ubiquitous
Computing and Communications (IUCC-2012), IEEE Comput. Soc., Liverpool,
UK, 2012, pp. 1785–1792.

399

[33] Emotiv EPOC Software Development Kit, Available at: <http://
www.emotiv.com/store/hardware/299/>, 2013. (accessed 17.03.2013).
[34] A. Vourvopoulos, F. Liarokapis, P. Petridis, Brain-controlled serious games for
cultural heritage, in: Proceedings of the 18th Int’l Conference on Virtual
Systems and Multimedia Virtual Systems in the Information Society, IEEE
Comput. Soc., Milan, Italy, 2012, pp. 291–298.
[35] M. Ninaus, S.E. Kober, et al., Neurophysiological methods for monitoring brain
activity in serious games and virtual environments: a review, Int. J. Technol.
Enhanced Learning 6 (1) (2014) 78–103.
[36] R. Berta, F. Bellotti, et al., Electroencephalogram and physiological signal
analysis for assessing ﬂow in games, IEEE Trans. Comput. Intell. AI Games 5 (2)
(2013) 164–175.

