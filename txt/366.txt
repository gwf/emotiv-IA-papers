del R. Millan, J., Rupp, R., Muller-Putz, G., Murray-Smith, R.,
Giugliemma, C., Tangermann, M., Vidaurre, C., Cincott, F., K"ubler, A.,
Leeb, R., Neuper, C., Muller, K.R. and Mattia, D. (2010) Combining
brain-computer interfaces and assistive technologies: state-of-the-art and
challenges. Frontiers in Neuroprosthetics, 4 . p. 161.
http://eprints.gla.ac.uk/34259/
Deposited on: 04 August 2010

Enlighten – Research publications by members of the University of Glasgow
http://eprints.gla.ac.uk

Combining Brain-Computer Interfaces and Assistive
Technologies: State-of-the-Art and Challenges
J.d.R. Millán1 , R. Rupp2 , G.R. Müller-Putz3 , R. Murray-Smith4 ,
C. Giugliemma5 , M. Tangermann6 , C. Vidaurre6 , F. Cincotti7 , A. Kübler8 ,
R. Leeb1 , C. Neuper3 , K.R. Müller6 , and D. Mattia7
1

Defitech Chair in Non-Invasive Brain-Machine Interface,
School of Engineering, Ecole Polytechnique Fédérale de Lausanne,
Lausanne, Switzerland
2
Stiftung Orthopädische Universitätsklinik Heidelberg, Heidelberg, Germany
3
Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery,
Graz University of Technology, Graz, Austria
4
Deptartment of Computing Science, Glasgow University, Glasgow, Scotland
5
QualiLife S.A., Paradiso-Lugano, Switzerland
6
Chair Machine Learning, Technical University of Berlin, Berlin, Germany
7
Clinical Neurophysiology, Fondazione Santa Lucia, Rome, Italy
8
Lehrstuhl für Psychologie I, Universität Würzburg, Würzburg, Germany
July 14, 2010
Abstract
In recent years, new research has brought the field of EEG-based Brain-Computer Interfacing (BCI) out of its infancy and into a phase of relative maturity through many demonstrated prototypes such as brain-controlled wheelchairs, keyboards, and computer games.
With this proof-of-concept phase in the past, the time is now ripe to focus on the development of practical BCI technologies that can be brought out of the lab and into real-world
applications. In particular, we focus on the prospect of improving the lives of countless
disabled individuals through a combination of BCI technology with existing assistive technologies (AT). In pursuit of more practical BCIs for use outside of the lab, in this paper,
we identify four application areas where disabled individuals could greatly benefit from
advancements in BCI technology, namely,“Communication & Control”, “Motor Substitution”, “Entertainment”, and “Motor Recovery”. We review the current state of the art and
possible future developments, while discussing the main research issues in these four areas. In particular, we expect the most progress in the development of technologies such
as hybrid BCI architectures, user-machine adaptation algorithms, the exploitation of users’
mental states for BCI reliability and confidence measures, the incorporation of principles in
human-computer interaction (HCI) to improve BCI usability, and the development of novel
BCI technology including better EEG devices.

1

1

Introduction

Imagine being able to control a robot or other machine using only your thoughts— this fanciful notion has long since captured the imagination of humankind, and, within the past decade,
the ability to actually bypass conventional channels of communication (i.e. muscles or speech)
between a user’s brain and a computer has become a demonstrated reality. Known as BrainComputer Interfaces (BCI), the field has already seen several early prototypes [135, 114, 206,
201, 42, 2]. A BCI monitors the user’s brain activity and translates their intentions into commands without activating any muscle or peripheral nerve. BCI as a proof-of-concept has already been demonstrated in several contexts; driving a robot or wheelchair [121, 120, 55, 118],
operating prosthetic devices [147, 148, 126, 127], selecting letters from a virtual keyboard
[12, 41, 115, 142, 120, 164, 125, 167, 203], internet browsing [79, 124], navigating in virtual
realities [8, 99, 96], and controlling computer games [115, 87, 140, 183].
Such a kind of BCI is a natural way to augment human capabilities by providing a new
interaction link with the outside world and is particularly relevant as an aid for disabled people.
The central tenet of a BCI is the capability to distinguish different patterns of brain activity, each
being associated to a particular intention or mental task. Hence adaptation is a key component
of a BCI because users must learn to modulate their brainwaves so as to generate distinct brain
patterns. In some cases, user training is complemented with machine learning techniques to
discover the individual brain patterns characterizing the mental tasks executed by the user.
With the field now entering a more mature phase of development, the time is ripe to focus
on the development of practical BCI applications aimed at improving the lives of physicallydisabled individuals1 . Furthermore, if our goal is to offer solutions to these people, and to
augment their capabilities, then BCIs must be combined with existing assistive technologies
(AT), especially those they already utilize.
Most BCIs for human subjects rely on non-invasive electroencephalogram (EEG) signals;
i.e., the electrical brain activity recorded from electrodes placed on the scalp. The reason is that
EEG is a practical modality if we want to bring BCI technology to a large population2 . For this
reason, in this review, we focus on EEG-based BCIs and how to combine them with AT. We
also identify and review some principles and research challenges that we consider fundamental
to bring BCI technology out of the lab. These principles include the development of hybrid
BCI architectures, the design of user-machine adaptation algorithms, the exploitation of users’
mental states for BCI reliability and confidence measures, the incorporation of principles in
human-computer interaction (HCI) to improve BCI usability, and the development of novel
BCI technology including better EEG devices. Note, however, that most of the principles we
put forward here can also be applied to other types of BCI, either invasive (single-unit activity
[25, 69], electrocorticogram [102, 151]) or non-invasive (MEG [81, 111], fMRI [200, 209],
1

That is, people with different degrees of stabilized motor disability as a consequence of traumatic lesions
(spinal cord injury), cerebrovascular diseases (stroke), or degenerative neuromuscular diseases (muscular dystrophies and motorneuron disorders such as amyotrophic lateral sclerosis and spinal muscular atrophies) that are
characterized by a progressive loss of muscular activity. In all these cases, however, cognitive functions are spared
to a large, if not complete, extent.
2
Besides electrical activity, neural activity also produces other types of signals, such as magnetic and metabolic,
that can be also measured non-invasively. Magnetic fields can be recorded with magnetoencephalography (MEG),
while brain metabolic activity —reflected in changes in blood flow— can be observed with positron emission tomography (PET), functional magnetic resonance imaging (fMRI), and optical imaging (NIRS). Unfortunately, such
alternative techniques require sophisticated equipment that can be operated only in special facilities. Moreover,
techniques for measuring blood flow have long latencies and thus are less appropriate for interaction.

2

NIRS [30, 177]).
In this paper, we identify four application areas where BCI assistive technology can have
a real, measurable impact for people with motor disabilities; namely “Communication & Control”, “Motor Substitution”, “Entertainment”, and “Motor Recovery”. The remainder of the
paper is organized as follows. The rest of this section is devoted to the research challenges
currently faced by BCI-based assistive technology. Then, in Sections 2-5, each application
area is discussed, and the current state-of-the-art of each is reviewed. Finally, in Section 6, we
summarize the main message of this review paper.

1.1

Hybrid BCI

What kind of assistance can BCI actually offer to disabled persons? Despite progress in AT,
there is still a large number of people with severe motor disabilities who cannot fully benefit
from AT due to their limited access to current assistive products (AP). For them, BCI is the
solution. However, notwithstanding the impressive demonstrations of BCI technology around
the world, today’s state-of-the-art is such that BCI alone cannot make patients interact with
and control assistive devices over long periods of time and without expert assistance. But this
doesn’t mean that there is no place for BCI. The solution is to use BCI as an additional channel. Such a hybrid approach, where conventional APs (operated using some residual muscular
functionality) are enhanced by BCI technology, leads to what we call hybrid BCI (hBCI).
As a general definition, a hBCI is a combination of different signals including at least one
BCI channel. Thus, it could be a combination of two BCI channels but, more importantly, also a
combination of BCI and other biosignals (such as EMG, etc.) or special AT input devices (e.g.,
joysticks, switches, etc.). The control channels (BCI and other modalities) can operate different
parts of the assistive device or all of them could be combined to allow users to smoothly switch
from one control channel to the other depending on their preference and performance. An
example of the former case is a neuroprostheses that uses residual movements for reaching
objects and BCI for grasping. In the latter case, a muscular dystrophy patient may prefer to
speak in the morning and switch to BCI in the afternoon when fatigue prevents him from being
able to speak intelligibly. Moreover, in the case of progressive loss of muscular activity (as
in muscular dystrophy, amyotrophic lateral sclerosis and spinal muscular atrophies) early BCI
training while the user can still exploit her/his residual motor functions will increase long-term
use of APs by smoothing the transition between the hybrid assistive device and pure BCI when
muscular activity is too weak to operate the APs.
An effective way for a hBCI to combine all the control channels is to merge their individual decisions —i.e., the estimation of the user’s intent— by weighting the contribution of each
modality. These weights reflect the reliability of the channel, or confidence/certainty the system
has regarding its output. The weights can be estimated from supervision signals such as mental states (e.g., fatigue, error potentials) and physiological parameters (e.g., muscular fatigue).
Another source to derive the weights is to analyze the performance of the individual channels
in achieving the task at hand (e.g., stability over time).
There exist a few examples of hybrid BCIs. Some are based on multiple brain signals. One
of such hBCIs is the combination of motor imagery (MI)-based BCI with error potential (ErrP)
detection and correction of false mental commands [49]. A second example is the combination
of MI with steady state visual evoked potentials (SSVEP) explored in some offline studies
[1, 22]. Other hBCIs combine brain and other biosignals. For instance, Scherer et al. [165]
3

combined a standard SSVEP BCI with an on/off switch controlled by heart rate variation. Here
the focus is to give users the ability to use the BCI only when they want or need to use it.
Alternatively, and following the idea of enhancing people’s residual capabilities with a BCI,
Leeb et al. [100] fused electromyographic (EMG) with EEG activity, so that the subjects could
achieve a good control of their hBCI independently of their level of muscular fatigue. Finally,
EEG signals could be combined with eye gaze [34]. Pfurtscheller et al. [146] have recently
reviewed preliminary attempts, and feasibility studies, to develop hBCIs combining multiple
brain signals alone or with other biosignals. Finally, hybrid BCIs could exploit several brain
imaging techniques simultaneously; i.e. EEG together with MEG, fMRI, NIRS and even TMS.
As mentioned above, our focus in this review paper is on principles to develop hBCI that, when
coupled with existing AT used by disabled people, can effectively improve their quality of life.

1.2

Adaptation

The kind of switch mentioned above offers a first level of self-adaptation, in that the user can
dynamically choose the best interaction channel at any time. To the best of our knowledge, this
is a aspect of BCI that has not been addressed before. A second level of self-adaptation concerns
the choice of the EEG phenomena that each user better controls, which can range from evoked
potentials like P300 [45, 137] or SSVEP [181, 57, 22] to spontaneous signals like slow cortical
potentials [12] and rhythmic activity [6, 207, 149, 119, 15]. This necessitates the development
of novel training protocols to determine the optimal EEG phenomenon for each user, building
upon work on psychological factors in BCI [131, 136].
Still another aspect of self-adaptation is the need for online calibration of the decoding
module (which translates EEG activity into external actions) to cope with the inherent nonstationarity of EEG signals. Recently, a number of papers have studied how EEG signals
change during BCI sessions [172, 179, 194, 197]. This non-stationarity can be addressed in
three different ways. First, by rejecting the variation of the signals and retaining the stationary part as in [82, 197]. In these works, different methods to design robust BCI systems against
non-stationarities are described. Second, by choosing features from the EEG that carry discriminative information and, more importantly, that are stable over time [54, 55]. Third, by applying
adaptation techniques. This adaptation can, as well, be carried out at different modules of the
BCI: in the feature extraction (for example with the use of adaptive autoregressive coefficients
or time domain parameters, [166, 193]) in the spatial filtering [210, 192] or at the classifier side.
Adaptation of any of the modules can be done in a supervised way (when the task to perform is
known beforehand) or in an unsupervised manner (no class labels are used to adapt the system).
Although not very common, supervised adaptation of the classifier has been explored in several studies [116, 24, 172, 195, 117]. Recently, some groups have also performed unsupervised
adaptation of the features [166, 193] and of the classifier. Unsupervised classifier adaptation
has also been applied to P300 data [106] and to motor imagery data [17, 179, 194].
Regardless whether adaptivity is applied in one or more modules of the BCI, it allows the
simultaneous co-adaptation of the BCI to the user and vice versa. A recent study with healthy
volunteers [192] who either had no experience or had not been able to control a BCI with
sufficient level of control for a communication application (70 % of accuracy in a two class
system) has shown the advantage of this approach. During the BCI session, of approximately
2 hours, some users could develop SMR. This is a big step forward in BCI research, because
at least 25–30 % of all users are not able to use a BCI with sufficient level of control [62]. We
4

hypothesize that selection of stable discriminant features and BCI adaptation could facilitate
and accelerate subject training. Indeed, these techniques increase the likelihood of providing
stable feedback to the user, a necessary condition for people to learn to modulate their brain
activity.

1.3

Human-Computer Interaction

A related issue is how to improve the performance and reliability of current BCIs, which are
characterized by noisy and low-bit-rate outputs. A promising possibility is the use of modern human-computer interaction (HCI) principles to explicitly take into account the noisy and
lagged nature of the BCI control signals to adjust the dynamics of the interaction as a function
of the reliability of user’s control capabilities. Such a HCI approach can also include the ability
to “degrade gracefully” as the inputs become increasingly noisy [202].
HCI principles can lead to a new generation of BCI assistive devices by designing more
suitable and comfortable interfaces that will speed up interaction, as demonstrated by the recent virtual keyboard ‘Hex-O-Spell’ [125, 203]. Regarding interaction and control of complex
devices like neuroprostheses and mobile robots (or wheelchairs), it has recently been shown
how shared autonomy techniques can drastically enhance the performance and robustness of a
brain-controlled wheelchair [190, 55, 118]. In a shared autonomy framework, the outputs of the
BCI are combined with the information about the environment (obstacles perceived by the robot
sensors) and the robot itself (position and velocities) to better estimate the user’s intent. Some
broader issues in human–machine interaction are discussed in [52], where the H-Metaphor is
introduced, suggesting that interaction should be more like riding a horse, with notions of “loosening the reins”, allowing the system more autonomy.
Shared autonomy (or shared control) is a key component of future hybrid BCI as it will
shape the closed-loop dynamics between the user and the brain-actuated device such that tasks
are able to be performed as easily as possible. As mentioned above, the idea is to integrate
the user’s mental commands with the contextual information gathered by the intelligent brainactuated device so as to help the user to reach the target or override the mental commands in
critical situations. In other words, the actual commands sent to the device and the feedback to
the user will adapt to the context and inferred goals. In such a way, shared control can make
target-oriented control easier, can inhibit pointless mental commands, and can help determine
meaningful motion sequences (e.g., for a neuroprostheses). Examples of shared control applications are neuroprostheses such as robots and wheelchairs [121, 190, 55, 118, 186], as well as
smart virtual keyboards [125, 204, 203] and other AT software with predictive capabilities.
The issue of improving the user interface is not a new problem; in addition some of the
issues such as error rate and time taken to make a selection are not new in the general area of
assistive technologies. The emphasis has mainly been on improving controllability and accuracy. Applications designed for BCI should be able to use different methods of BCI control,
account for individual differences, optimize the user interface and incorporate artificial intelligence techniques. Simulation techniques can provide helpful information about the expected
usability of a system. For instance, [14] describes a simulator which incorporates models of the
application, interface and user to predict the performance of assistive technology devices.
Finally, until fairly recently, the focus of software design and evaluation has been on usability and functionality in what are referred to as instrumental qualities. Current trends emphasise
non-instrumental aspects of interface design and evaluation. These can be separated into the
5

3 categories; hedonics (concerned with [un]pleasant sensations), aesthetics, and pleasure/fun
[107]. This development might be seen as attempting to establish the basics first before finetuning the details later. Nevertheless, [188] demonstrates that the perception of how usable
a system is increases as visual aesthetics of the system increases, although its actual usability remains unchanged. A valid question to ask, then, is whether BCI application design and
evaluation can and should follow the same pattern of developing usable systems first before
“targeting” the non-instrumental qualities. Given the current limitations of BCIs, how much
of the existing knowledge of HCI design and evaluation can be applied to BCIs? It depends
on the purpose of the application and how much control is required for the application to be
used. Computer applications for BCI might be divided into 3 broad categories —programs
for communication, tools for functional control, and entertainment applications. Entertainment
programs can further be subdivided into games, tools for creativity and interactive media. The
focus of evaluation for communication and functional applications should be on usability and
functionality, while the focus of entertainment applications should be on pleasure and entertainment.

1.4

Mental States

A fourth area where BCI assistive technology can benefit from recent research is in the recognition of the user’s mental states (mental workload, stress level, tiredness, attention level) and
cognitive processes (awareness to errors made by the BCI), which could facilitate interaction
and reduce the user’s cognitive effort by making the BCI assistive device react to the user. This
is again another aspect of self-adaptation: for instance, in case of high mental workload or
stress level, the dynamics and complexity of the interaction will be simplified or it will trigger
the switch to stop brain interaction and move on to muscle-based interaction (see above). As
another example, in the case of detection of excessive fatigue, the mobile robot would take over
complete control and move autonomously to its base station close to the user’s bed. Pioneering
work in this area deals with the recognition of mental states (such as mental workload [86],
attention levels [65] and fatigue [189]) and cognitive processes (such as error-related potentials
[16, 47, 48, 49] and anticipation [56]) from EEG. In the latter case, Ferrez & Millán [48, 49]
have shown that errors made by the BCI can be reliably recognized and corrected, thus yielding
significant improvements in performance.
Also, as mentioned before, mental states can provide useful information to estimate the
reliability of the individual channels. For instance, in the case of a high attention level, we
could assign a large weight to the EEG channel, while this weight would be small in the case of
high mental workload. Also, repetitive error-related potentials should reduce the weight of the
channels that mainly contributed to the estimation of the user’s intent.

1.5

New EEG Devices

The fifth and final area of necessary progress surrounds the development of a new class of BCI
devices based on easy-to-use and aesthetic EEG equipment. So far, laboratory experimentation
has never required attention to issues like portability, aesthetic design, conformity, certification,
etc. Many current BCI applications exist in the form of software running on a personal computer; but many users will not accept the burden of a desktop PC and its screen to utilize a BCI.
In addition, there is a need for a common implementation architecture to facilitate commercial
6

take-up —and the field is taking steps towards standardization in the design of BCI [28]. The
merger of aesthetic and engineering design is a key issue that any practical BCI for disabled
people must overcome. Users don’t want to look unusual— therefore, social acceptability is a
key concern for them3 . For this reason we expect new EEG technology based on dry electrodes
and aesthetic wireless helmets. Different teams have recently developed some prototypes of dry
electrodes that overcome the need of gel, one of the main limitations of current EEG technology
[153]. Moreover, different companies like Quasar Inc. (San Diego, US) [168], Emotiv Systems
Inc. (San Francisco, US), NeuroSky Inc. (San Jose, US) [180] and Starlab (Barcelona, Spain)
[160] are now commercializing dry electrodes, mainly for gaming. Although some doubts exist about the kind of physiological signals these systems actually exploit for control, they are
definitely pushing the field forward.

1.6

Discussion

In summary, time is ripe to develop a new generation of hybrid BCI assistive technology for
people with physical disabilities that will advance the state of the art in a number of ways:
• Conventional AP will be enhanced by BCI technology: the incorporation of a brain channel can provide an additional degree of freedom, enhance the robustness of the control
signals by combining EEG and other AT, or be the only means of interaction. BCI will
expand the range of opportunities available to AT teams worldwide for building flexible
and personalized solutions for their clients needs.
• BCI assistive devices will be endowed with novel self-adaptive capabilities: this will be
achieved through the incorporation of fusion techniques for combining EEG with other
signals, automatic choice of EEG phenomena, on-line adaptation to changing EEG signals, the use of modern HCI principles for shaping the interaction, and recognition of
user’s mental states and cognitive processes.
• Brain-computer interaction will become more robust: combination of EEG with other
signals allow users to become more autonomous and interact over long periods of time.
• Brain-computer interaction will increase its performance and reliability significantly: the
use of modern HCI and shared autonomy principles will make it possible.
• Brain-computer interaction will reduce user’s cognitive effort: this will be possible because of the use of modern HCI as well as the recognition of user’s mental states and
cognitive processes.
• Brain-computer interaction will be easier: the design of efficient training protocols will
accelerate, improve and make more intuitive user’s mastering of the BCI assistive technology; also, the development of new electrodes and aesthetic helmets will facilitate operation of BCI by laypeople.
• Novel BCI designs will ensure the outcome follows standard BCI assistive technology:
past lack of coordination in BCI research has thus far impeded the creation of a shared
model and standards among BCI groups.
3

Clearly, all these issues (from standardization to aesthetics) are relevant to any kind of BCI, regardless of the
kind of brain signal in use.

7

2

Communication & Control

BCI have the potential to enable severely disabled individuals to communicate with other people
and to control their environment. Communication functions consist mainly of sending/receiving
emails, chatting, using VoIP phones and surfing the web. During the last 10 years, it has been
proven in the labs that persons, even those suffering of severe disabilities, may interact with
computers by only using their brain —in the extreme case using the brain channel as a single
switch, just like a computer mouse.
There is also a commercial system that, in principle, allows BCI communication and control.
Brain Actuated Technologies introduced ‘Cyberlink’ in 1996, a system that records electrical
signals from 3 electrodes integrated into a headband on the subject’s forehead [77]. Because of
the location of the electrodes, users mainly use subtle facial muscles activity and eye movement
for control, although the electrodes can also measure brain activity in the usual theta, alpha and
beta frequency bands. Recently OCZ Technology Inc. (San Jose, US) acquired the company
and is now commercializing the ‘Neural Impulse Actuator (NIA)’, the first consumer device
that can be used for controlling standard video games without using mouse or joystick. OCZ is
available since 2008 at a cost of about 300 USD.

2.1

BCI-Driven Spelling Devices

In 1999, the Tübingen BCI group developed the Thought-Translation-Device (TTD) [12], a
system that could be operated by patients suffering from amyotrophic lateral sclerosis (ALS)
through the modulation of brain rhythms. Binary decisions made by the BCI were used to select
letters in a procedure where the alphabet was iteratively split into halves. The achieved spelling
rate was about 0.5 char/min. Since then, other groups have developed BCI-driven spelling devices based on the detection of voluntarily patterns of activity in the spontaneous EEG. These
systems can operate synchronously [12, 142] or asynchronously [115, 120, 164, 125, 203]. Interestingly, one patient suffering from severe cerebral palsy could operate the Graz system at
about 1 char/min. In the case of Millán’s approach, trained subjects have taken 22.0 seconds on
average to select a letter, including recovery from errors, with peak performances of 7.0 seconds
per letter. Particularly relevant is the spelling system developed by the Berlin group in cooperation with the University of Glasgow, called Hex-o-Spell [203], which illustrates how a normal
BCI can be significantly improved by state-of-the-art human-computer interaction principles.
The idea for Hex-o-Spell was taken from the Hex system which was designed for use on mobile devices augmented with accelerometers, where tilt control was used to maneuver through
a hexagonal tessellation. The text entry system is controlled by the two mental states imagined
right hand movement and imagined right foot movement. Expert subjects achieved typing speed
of up to 7.5 char/min. A recent development in the field of HCI, inspired by a similar approach
to Hex, is the Nomon selection system, based on the use of phase angle in clock-like displays
[21]. Still another speller designed upon efficient HCI principles is DASHER [204].
Most BCI spelling devices, especially those actually used by disabled people, are based on
the detection of potentials that are evoked by external stimuli rather than spontaneous mental
states. The most prominent is the approach that elicits a P300 component [41]. In this approach,
all characters are presented in a matrix, and the symbol which the user focuses her/his attention
on can be predicted from the brain potentials that are evoked by random flashing of rows and
columns. Similar P300-based spelling devices have since been extensively investigated and

8

developed (e.g., [167, 137, 173]).

2.2

BCI Control of Web Browsers

The history of providing internet access to ALS patients dates back to 1999 when the TTD
developed in Tübingen was used to operate a standard web browser. In a first implementation,
called ‘Descartes’ [79], the web window was shown for a certain amount of time (about 120s),
then a navigation screen would present the links from the current web page as leaves in a tree. A
more advanced prototype, called ‘Nessi’ [10], allowed a more flexible selection of links thanks
to a better user interface, again highlighting how BCI operation can be facilitated and improved
by better HCI principles. More recently, this group has developed another browser based on
P300 [124]. Theoretically, a browser with P300 control can enable selection from as many
links as the elements in the P300 matrix (for a 6x6 matrix, 36), and the selection of a link
could be completed in one step, although reliable recognition requires several iterations of the
presentations of row/columns.

2.3

BCI and Assistive Technology

BCI technology can be seen as a special Assistive technology in the area of Information and
Communication Technologies (AT ICT), which is defined the Class 22 of ISO 9999:2007 (Assistive products for communication and information):
“AT ICT products are understood to be devices for helping a person to receive, send, produce and/or process information in different forms. Included are, e.g., devices for seeing, hearing, reading, writing, telephoning, signalling and alarming, and information technology.”
A large variety of assistive technology is available today, providing the opportunity for
nearly all people to access ICT. However, an individual with proper assistive technology has no
guarantee of access. ICT products must be designed and created in ways that allow all users
to access them, including those who need assistive technologies. It is for this reason that BCI
must be combined with state-of-the-art AT ICT.
The standard user interface of a personal computer is powerful and flexible, but this flexibility is often a barrier to accessibility for many people with disabilities: many small icons,
multiple open windows on a complex desktop, drag-and-drop, and so on. This kind of interface
makes using a PC difficult and confusing for many people, like people with physical disabilities
or first time users such as elderly people. A common approach to assisting people in using ICT
is to add some assistive technology on top of the standard interface, such as text-to-speech or
screen magnifiers. This approach has provided considerable benefit to specific user groups, but
it does not remove the main limitation of standard user interfaces. The solution is then to design
simpler user interfaces from scratch whose interaction principles and graphical appearance is
uniform across applications. One of the few commercial state-of-the-art AT ICT products is
‘QualiWORLD’ by QualiLife Inc. (Paradiso-Lugano, CH).

9

3
3.1

Motor Substitution
Grasping

In Europe alone, an estimated number of 300,000 people are suffering from a spinal cord injury
(SCI) with 11,000 new injuries per year. Forty percent of the total population of the SCI patients
are tetraplegics. Loss of motor functions, especially grasping, leads to a life-long dependency
on care-givers and to a dramatic decrease in quality of life [4].
Beside SCI persons, other neurological patients also suffer from paralysis of the upper extremities and the related restrictions in terms of independence and life quality. In Germany,
60 % of the 150,000 patients affected by a stroke for the first time survive the first year, one
third of them with a hemiplegia. In Germany, 10 % of the annual 250,000 traumatic brain injury
patients live with motor deficits at the upper extremities.
Today, if surgery is not an option, functional electrical stimulation (FES) is the only possibility for partially restoring lost motor functions [68]. In this context, the term neuroprostheses is
used to describe FES systems aiming at the restoration of a weak or lost grasping function of the
hand. Some of these neuroprostheses are based on surface electrodes for external stimulation of
muscles of the hand and forearm. Examples are the commercially available NESS-H200 System (Bioness Inc, Valencia, US) [73] and other more sophisticated research prototypes [185],
[110]. The Freehand system (NeuroControl, Cleveland, US), an implantable neuroprostheses,
overcomes the limitations of surface stimulation electrodes concerning selectivity and reproducibility [83]. All FES systems for grasp restoration have in common the fact that they can
only be used by patients with preserved voluntary shoulder and elbow function, which is the
case in patients with an injury of the spinal cord below C5. Only two groups have dealt with
the problem of restitution of elbow and shoulder movement. Memberg et al. [112] used an
extended Freehand system, while Handa’s group [78] developed a system based on intramuscular electrodes. Both systems represent exclusive FES systems, which stimulate the appropriate
muscle groups not only for dynamic movements but also for maintaining a static posture. Due
to the weight of the upper limb and the non-physiologic synchronous activation of the paralyzed muscles through external electrical pulses, rapid muscle fatiguing occurs. An alternative
is, as for the case of standing and walking neuroprosthesis, to use a combination of FES with
a mechanical orthosis [60, 85]. A passive, but lockable orthosis stabilises the knee joint during the stance phase without the need for a continuous co-contraction of antagonistic muscle
groups. For the restoration of an elbow function much less torque has to be generated and held,
thus supporting the idea that a passive, lockable orthosis combined with a FES-system will be
successful in restoration of upper limb function. Up to now such a system does not exist.
Current neuroprosthesis for the restoration of forearm function (hand, finger and elbow) require the use of residual movements not directly related to the grasping process. Traditional APs
like head, mouse, or control devices using tongue or eye movements have not been accepted by
patients for control of neuroprosthesis, because these APs hinder their communication ability,
which is most important to patients for participation in normal social activities, and the design
is not aesthetic. It is for this reason that recently some groups have started to explore BCI approaches in the case where no, or only minor, residual motor control is available. For a review
see [127].
Pioneering work by the groups in Heidelberg and Graz showed for the first time the feasibility of the combination of BCI and a FES-system with surface electrodes [148]. In this study
the restoration of a lateral grasp was achieved in a spinal cord injured subject, who suffers from
10

a complete motor paralysis with missing hand and finger function. The patient is able to trigger
sequential grasp phases by the imagination of foot movements. After many years of training
and use of his BCI, the patient is able to control the system even during conversation with other
persons. The same groups did a short-term BCI training of another tetraplegic patient who was
provided with a Freehand system in the year 2000. After three days of training the patient was
able to control the grasp sequence of the implanted neuroprosthesis sufficiently [126]. More
recently, they introduced a new method for the control of the grasp and elbow function by a
BCI [128]. The idea is to use a low number of pulse-width coded brain patterns to control
sequentially more degrees of freedom. Millán’s group used the motor imagery of hand movements to stimulate the same hand for a grasping and writing task [184], so the subjects thought
about moving the right arm and the system stimulated the right arm. Furthermore, they used an
adaptable passive hand orthosis, which evenly synchronizes the grasping movements and applied forces on all fingers. This orthosis also avoids fatigue in long-term stimulation situations
by locking the position of the fingers and switching the stimulation off [97].
It’s worth noting that Fetz’s group [123] has recently described an invasive approach to
brain-controlled orthosis conceptually similar to previous attempts based on non-invasive BCI
mentioned above. In this experiment, a monkey, paralyzed via a nerve block, can regain control
of its forearm by using FES and single cell recordings of the motor cortex. This brings us to an
important underlying issue in the development of neuroprosthesis, namely the choice of the kind
of mental task to use for control. In most work in non-invasive BCI, people use imagination
of different limbs (right/left hand, feet) to deliver different commands to the neuroprosthesis
for, say, the right hand. However, it seems more natural to rely on the recognition of different
imagined movements of the same limb the neuroprosthesis controls. Initial evidence for such a
possibility has been recently provided in an offline study where subjects imagined the execution
of different wrist movements [61].
Finally, a BCI-controlled FES orthosis can be also relevant for motor recovery of the upper
extremities in stroke patients. Despite the fact that there is no literature available on the use of
such a type of device in this patient population, some studies on the topic of FES training have
emerged recently. For example, Hara [66] claims that user-driven electrical muscle stimulation
—but not machine-paced electrical muscle stimulation— improves the motor function of the
hemiparetic arm and hand. A new hybrid FES therapy comprising proportional EMG-controlled
FES and motor point block for antagonist muscles have been applied with good results in an
outpatient rehabilitation clinic for patients with stroke. Additionally, Hara et al. [67] have
shown that a daily task-oriented FES home therapy program can effectively improve wrist and
finger extension and shoulder flexion. Furthermore, proprioceptive sensory feedback might
play an important role in this kind of therapy. The results of the single-case study from Page
[144] supports these promising results. Moreover, another recent single-case study supports the
benefit of a combination of FES and BCI [32]. However, this use of BCI plus FES in the field
of motor recovery has to be investigated more extensively.

3.2

Assistive Mobility

A second area where BCI technology can support motor substitution is in assisting user’s mobility, either directly through brain-controlled wheelchairs (e.g., [118]) or by mentally driving
a telepresence mobile robot —equipped with sensors for obstacle detection as well as with a
camera and a screen— to join relatives and friends located elsewhere and participate in their
11

activities [186]. Several commercial platforms already exist for allowing this kind of interaction: e.g. peoplebot (Mobile Robots Inc., Amherst, US), iRobot (iRobot Corp., Bedford, US),
robotino (Festo AG, Dietikon, CH).
Underlying all assistive mobility scenarios, there is the issue of shared autonomy. The crucial design question for a shared control system is: who —man, machine or both— gets control
over the system, when, and to what extent? Several approaches have been developed, in particular for intelligent wheelchairs. A common aspect in all these approaches is the presence of
different assistance modes. These modes can either be different levels of autonomy or different
algorithms for different maneuvers. Based on these modes, existing approaches can be classified into two categories. Firstly, there are approaches where mode changes are triggered by a
user’s action through the operation of an extra switch or button. Examples of smart wheelchairs
of this category are SENARIO [80], OMNI [71], MAid [155], Wheelesley [208], VAHM [18],
and SmartChair [145]. However, those explicit interventions can be difficult and tiring for the
users. These users have problems operating a conventional interface, and adding buttons or
functionality for mode selection makes this interface only more complex to operate and less
user-friendly. Secondly, there are approaches with implicit mode changes where the shared
control system automatically switches from one mode to another without the need for a manual
user intervention. The NavChair [103, 176] and the Bremen Autonomous Wheelchair [158] are
examples of this second category. The problem with all these approaches is, however, that the
switching is hard-coded and independent of the individual user and his specific handicap. An
extensive literature overview of intelligent wheelchair projects can also be found in [175].
In the case of brain-controlled robots and wheelchairs, Millán’s group has lead the development of a shared autonomy approach in the framework of the European MAIA project that
solves the two problems mentioned above. This approach estimates the user’s mental intent
asynchronously and provides appropriate assistance for navigation of the wheelchair. This approach has shown to drastically improve BCI driving performance [190, 55, 118, 186]. Despite
that asynchronous spontaneous BCIs seem to be the most natural and suitable alternative, there
are a few examples of evoked BCIs for the control of wheelchairs [156, 74]. Both systems are
based on P300, a potential evoked by an awaited infrequent stimulus. To evoke the P300, the
system flashes the possible predefined target destinations several times in a random order. The
subject’s choice is the stimulus that elicits the largest P300. Then, the intelligent wheelchair
reaches the selected target autonomously. Once there, it stops and the subject can select another destination —a process that takes around 10 seconds. A similar P300 approach has been
followed to control a humanoid robot [9].

4

Entertainment

The area of entertainment has typically had a lower priority in BCI work, compared to more
“functional” activities such as basic communication or control tasks. For the purposes of this
survey, entertainment encompasses everything from video games, to interaction with collections
of media to control of ambient features, such as wall displays, lighting and music. In tasks such
as music or images, the feedback from even a “wrong” selection is usually pleasant (assuming
the user likes the music or images in their collection), and interaction techniques can be focused
on more exploratory approaches to browsing collections. This is sometimes called hedonic
interaction in distinction from utilitarian interaction, and it leads to a need for a more broad set
of metrics for evaluation of user experience. In this context, a BCI will facilitate activities such
12

as browsing digital photo collections or music collections, where the control might be at the
level of specifying a mood or genre. Such systems might also provide opportunities for users to
express their emotional state, or desires to a caregiver more rapidly and expressively than using
written language.
As an example of this BCI approach to entertainment, very recent work has begun to gather
experience with synchronous and asynchronous BCI “painting” applications which allow the
user creative expression. Preliminary results indicate that the application provides pleasure to
patients, healthy volunteers, and artists [88, 64].

4.1

Gaming

Although gaming has not been the main focus of BCI research, there exist some prototypes
that demonstrate the feasibility of games controlled by a BCI[115, 92, 87, 140, 183, 51, 138].
Such BCI games could allow severely disabled persons to not only experience a little bit of
entertainment, but to also to improve their quality of life, mainly through social interaction. For
instance, Tangermann et al. [183] shows evidence that real-time BCI control of a physical game
machine is possible with little subject training. The gaming machine studied (a standard pinball
machine) required only two classes for control with fast and precise reaction; predictive behavior and learning are mandatory. Games can be either competitive (requiring fast responses) or
strategic (usually slower).
These BCI games are based on different BCI protocols, from spontaneous EEG [115, 87,
183] to evoked EEG potentials [92, 51], where the user delivers (as usual for a BCI) mental
commands to control some aspect of the game. Another alternative is to determine the user’s
mental or affective state from their EEG and to use this information to adapt the dynamics of the
game to the user’s affective state [140]. As stated in [139], “Measuring brain activity for gamers
can be used so that the game environment (1) knows what a subject experiences and can adapt
game and interface in order to keep the gamer “in the flow” of the game, and (2) allows the
gamer to add brain control commands to the already available control commands for the game.”
This perspective matches well that described in [202] when discussing a general framework for
interaction design.
It is usually assumed that, because of the huge yearly turnovers of the game industry, once
BCI games reach the mass market, BCI technology would become so cheap that every disabled
person would be able to afford it for functional interaction. Some support this view. For instance, commercial ‘BCI’ sensors are coming into the mainstream gaming world (e.g. Emotiv
and Neurosky). Also, as Nijholt [138] points out: “There are also other reasons that make
games, gamers and the game industry interesting. Gamers are early adaptors. They are quite
happy to play with technology, to accept that strong efforts have to be made in order to get
minimal advantage, and they are used to the fact that games have to be mastered by training,
allowing them to go from one level to the next level and to get a higher ranking than their competitors”. However, we cannot take for granted that the kind of BCI technology (sensors and
brain signals) that the game industry would eventually develop will automatically be appropriate for functional interaction. This is the case for current ‘BCI’ game sensors that are limited
in number and position over the users head (normally just over the forefront, where there is no
hair).
One concern with the mass-produced BCI games is proper evaluation; namely, how to prove
that the user’s brainwaves are the actual control signals driving the game. Of course, from a hy13

brid BCI perspective, gamers can (and must) also use other physiological signals and interaction
modalities. The point, however, is to demonstrate that users have a sufficient degree of mental control for those aspects of the game that require so, as advertised. This issue also raises
the question of how to evaluate games as a whole to ensure that they provide a valuable and
enjoyable experience. In this respect, the Fun of Gaming (FUGA) project advocates a multidimensional evaluation using self-reports, behavioural observations and psychophysiological
measures as each in itself is insufficient to get the full picture [72]. Much of the research in
pleasure and satisfaction in entertainment focusses on gaming but some might be applied to
entertainment in general. For example, “fun” in a game includes challenge, curiosity, fantasy,
and Csikszentmihalyi’s theory of flow (level of engagement that one is completely absorbed in
the current activity and enjoys it in itself without any need for future benefit), but these can also
apply to interactive art and creativity (and by extension interactive media, [29]). Only such a
kind of evaluation will prove beneficial for BCI games in general, and for disabled people in
particular. Otherwise, BCI games will be just another “fast-food toy” that customers buy and
stop using quickly, thus risking to seriously damage the credibility of the BCI field —such a
blow that early in its development stage could cripple the field, by projecting a negative image
to the public, other industrial sectors, and to funding agencies.

4.2

Virtual Reality

Because BCI are a closed-loop systems, feedback is an important component. Various methods
of providing feedback can inform the participant about success or failure of an intended act.
Thus, feedback either supports reinforcement during the learning/training process or in controlling the application. In particular, the use of virtual reality (VR) has been proven to be an
interesting and promising way to realize such feedback.
Several prototypes have enabled users to navigate in virtual scenes solely by means of their
oscillatory cerebral activity, recorded on the scalp via EEG electrodes. Healthy participants
were exploring virtual spaces [99, 101, 159, 163], were manipulating virtual objects [95], and
a spinal-cord injured patient was controlling a wheelchair through a virtual street [96]. Additionally, evoked potentials (P300 [8] and SSVEPs [93]) have been used to control VR feedback
as well. In these studies, BCI users who use immersive Virtual Environments (VEs) make
fewer errors, report that BCIs are easier to learn and use, and state that they enjoy BCI use
more [99, 98, 159]. These benefits may occur because VEs enhance vividness and mental
effort, which may lead to more distinct brain patterns and improve pattern recognition performance. Nevertheless, VR technologies provide motivating, safe, and controlled conditions that
enable improvement of BCI learning as well as the investigation of the brain responses and
neural processes involved, meanwhile testing new virtual prototypes.

4.3

Music Browsing

Since the introduction of mp3 compression technology and easy-to-use mobile music players
(such as Apple’s iPod player, and iTunes software), there has been an explosion in the use of
computers for listening to music. For example, listeners can create ‘playlists’ of their favourite
tracks to listen to, burn tracks to CDs, or share with friends. In many cases, though, typical
users find that this requires too much effort. Recently a lot of publicity has been given to the
‘Genius’ feature on Apple’s widely used iTunes software, although a range of alternatives have
14

been in existence for some time (e.g. websites such as last.fm, pandora.com, www.spotify.com).
Moodplayer is an application that lets you create playlists on the go based on your mood and the
mood of songs in your music library, and which can be installed on iPhones or Nokia phones.
This is a natural application area for BCI. Although no BCI music browser has been developed
yet, some BCI for music composition [122] do exist.

4.4

Photo Browsing

Existing research has focused on determining what kinds of photographs people have, what
tasks they perform with them (and what tasks they would like to perform but cannot), and what
structure the collections have. In particular, [53, 84] examine how users utilize their personal
digital photographs. Both noted the general lack of organization of digital photographs, and the
use of very simple exploration techniques. Complex searching activities were not found to be
of particular benefit to users when dealing with their personal archives. Rodden et. al. [157]
also examined digital photograph activities, observing a distinct lack of annotation activity and
the utility of temporal structuring in exploration of photo archives. An individual picking up
an interactive photo display often does not have a clear idea of what images he or she wishes
to see. This partially explains why many sophisticated and powerful organization and query
interfaces are not widely adopted. Few users know what they want to see before they begin;
fewer still are able to distill those intents into meaningful queries across the attributes of images
which the system observes. Photo journalists, archivists or other workers with very specific and
well-defined needs may benefit from such interactions. This use case, however, is exceedingly
rare among home users exploring personal photograph collections.
Although users may not have a definite idea of what images they would be interested in
seeing, or are unable to communicate their preferences given the available metadata attributes,
they may instead be able to iteratively refine selections to find images of interest. The presentation of a sample from a large set of images can stimulate memories; user can then follow
paths through photo space by indicating that they would like to see more images “similar” to
one or more of those displayed. Using rich similarity metrics is essential in obtaining effective
navigation by this means. This style of interaction has much in common with Bates’ “berry
picking” model of information retrieval [7]. In this model, users wander through an information
space, finding results and modifying their queries as they go. The final goal of the user adapts
as they bounce through the results from each previous query. This approach is well-suited to
develop BCI tools for photo browsing. The idea is to combine BCI with simple image search
techniques. Users will mentally select pictures representing possible categories in their photo
archives with a P300-based BCI, and image search techniques will provide similar pictures. In
fact, there is some preliminary work that follow this P300 approach [187]. Also of interest is
the use of rapid serial visual presentation (RSVP) paradigms for image triage [59]. In this approach, users watch many images presented a high rate (say, 4 Hz) and the presence of a P300
evoked potential indicates images of interest that are ranked on top of the final selection.

5

Motor Recovery

Motor impairment after stroke is the major cause of permanent disability. Recovery of hand
motor function is crucial in order to perform activities of daily living, but is often variable
and incomplete [44]. Indeed, stroke rehabilitation efficacy is limited [35, 43] with 30 % to
15

60 % of patients unable to use their more affected arms functionally after discharge [90, 91].
Currently, neuroscience-based rehabilitation seeks to stimulate spontaneous functional motor
recovery by capitalizing on the inherent potential of the brain for plastic reorganization after
stroke [26, 130, 152, 50, 31, 39, 199, 58, 141].
In this regard, evidence from animal studies encourage the parallelism between plasticity
mechanisms in the developing nervous system and those taking place in adult brain after stroke
[129]. On the other hand, understanding the effect of rehabilitative practices on brain plasticity
has the potential to provide a neural substrate to underpin rehabilitation and hence, in developing
novel rehabilitation strategies [104].
Rehabilitative interventions aimed at functional motor recovery in stroke patients are based
mainly on active movement training such as constraint-induced therapy and/or passive mobilization [104, 161, 205]. Recent clinical trials have provided new insights into the methods to
assist motor recovery after stroke [40, 94, 178]. A recurrent theme is that interventions emphasizing intense active repetitive task-oriented movements are of high value in this regard. To
promote the effects of training and practice, biomedical engineers, neuroscientists and clinicians
have started an intense joint collaboration over the past 10 years. This technological approach
holds a promise for enhancing traditional post-stroke recovery in different ways: exercise in
virtual environments could provide feedback to aid skills learning [75, 70, 113]; robotic assistive devices with sensory feedback for repetitive practice could provide therapy for a long
periods of time, in a consistent and measurable manner [196, 182]; functional electrical stimulation of muscles might enable movements not otherwise possible during the practice of tasks
such as reaching to grasp an object [3]. These are only a part of the increasing technological
developments which have been recently applied in sample of stroke patients and showed the
feasibility in providing a clear incremental reduction of motor impairments offering, therefore
the opportunity to build a better outcome for patients.
These treatments are based on the ability of the patients to perform actions with the affected
hand or arm and therefore, require residual motor ability. Many patients however, are prevented
from training based on the above treatments due to having no residual hand motor functions.
In case of moderate to severe motor deficits, motor imagery (MI) represents an intriguing new
“backdoor” approach to access the motor system and rehabilitation at all stages of stroke recovery [143, 170, 169, 171]. MI can be defined as a dynamic state during which the representation
of a specific motor action is internally rehearsed without any overt motor output, and that is governed by the principles of central and peripheral motor control [37, 76, 11, 105]. This is likely
the reason why mental practice using MI training results in motor performance improvements
(for a review in athletes, see [46, 38]). In addition, MI training can independently improve motor
performance and produce similar cortical plastic changes [105], providing a useful alternative
when physical training is not possible.
Despite this evidence, imagery training of movements combined with conventional physiotherapy of the hand has been reported in few structured clinical trials including subacute to
chronic stroke patients and they demonstrated a greater improvement of hand function with the
additional mental practice [143, 20, 109, 174, 191]. Up to now, no definite conclusions can
be drawn, except that further research using a clear definition of mental practice content and
standard outcome measurements are needed. As for the first point, it follows from the definition
of motor imagery that because of its concealed nature, a subject may surreptitiously use alternative cognitive strategies that, if not screened for, could confound investigations and produce
conflicting results. Because the aim of motor imagery is to activate the motor networks, it is
16

crucial that subjects perform the mental task from the 1st person perspective (so called kinesthetic MI), in contrast to 3rd person perspective or visual imagery [36, 133]. In this regard, a
recent fMRI study on MI [63] has looked at this issue by assessing subjects’ imagery abilities
using well-established psychological, chronometric, and new physiological measures from the
autonomic nervous system. The results suggest that visual and kinesthetic imagery are mediated through separate neural systems, which contribute differently during processes of motor
learning and neurological rehabilitation.
Beyond these overall considerations, the challenge neurorehabilitators are faced with is
clear: to modulate the sensorimotor experience of stroke patients to induce specific form of
plasticity to boost relearning processes. Pulling all previous evidence together, a promising and
challenging approach is to deploy BCI technology as a tool to tackle the challenge in the field
of functional motor recovery after stroke. Indeed, the inherent BCI training paradigms will be
exploited as a behavioral, controlled strategy to recruit and/or reinforce patient’s sensorimotor
experience (like MI and/or residual motor ability) during functional motor recovery after stroke
and, thus to enhance those physiological plasticity phenomena which are the substrate for the
functional motor recovery itself. The feasibility and effectiveness of a BCI-based neurofeedback paradigm will be enhanced by combining motor imagery with motor action observation;
this latter cognitive strategy will be allowed via technology such as visual representation and
functional electrical stimulation of the hand. Moreover, a multimodal brain imaging approach
will provide detailed knowledge of how the brain encodes and processes information when it
imagines the control or actually controls a peripheral device. This knowledge will, in turn,
unravel to what extent long-term use of BCI “per se” affects the brain activity of the user.
The BCI community has a long-standing experience with one of the employed strategies for
operating EEG-based BCI systems— the modulation of sensorimotor EEG reactivity induced
by movement imagery tasks [150, 134, 27, 89, 132]. This makes possible the development of
flexible and affordable BCI tools to objectify and to monitor individual MI execution both in
terms of performance (relation between subject MI performance and subject level of accuracy
in controlling BCI-operated basic applications) and compliance (identification of a correct MI
task which is needed to achieve BCI-system control).
Within the BCI community, the opportunity to use BCI protocols to promote recovery of
motor function by encouraging and guiding plasticity phenomena occurring after stroke (or
more generally after brain injury) is at a very preliminary stage (for review see [33, 13, 108]).
Discussion is currently underway over several factors including: the extent to which patients
have detectable brain signals that can support training strategies; which brain signal features
are best suited for use in restoring motor functions and how these features can be used most
effectively; and what the most effective formats are for the BCIs aimed at improving motor
functions (for instance, what guidance should be provided to the user to maximize training
that produces beneficial changes in brain signals). So far, preliminary findings are promising:
Scherer and colleagues [162] suggested that event-related EEG activity time-frequency maps
of event-related EEG activity and their classification are proper tools to monitor motor imagery
related brain activity in stroke patients and to contribute to quantify the effectiveness of motor
imagery. Buch et al. [23] have shown that six out of eight chronic stroke patients suffering from
a handplegia learned to control a magnetoencephalography-based BCI by motor imagery. In all
these cases, the best signals were depicted over the ipsilateral (unaffected hemisphere). Other
attempts to use non-invasive BCI for rehabilitation include [5, 154]. Finally, the idea that BCI
technology can induce neuroplasticity has received remarkable support from the communicty
17

based on invasive detection of brain electrical signals (for recent review see [198]).
As mentioned above, a general consensus from the clinical point of view is still lacking on
the content, dose and strategy of the motor imagery intervention in stroke rehabilitation. What’s
more, there is no evidence so far, that one intervention protocol can be more effective with respect to another, for the mental practice of motor actions. According to the extensive review by
Sharma et al. [170] only few studies have paid attention to the previous issues and the conclusion can be summarized as follows: i) motor imagery training has to be provided in addition to
a background rehabilitation therapy; ii) motor imagery tasks should be practiced in the patient’s
functional context to be most effective; in this regard, the motor imagery tasks can be chosen
from activities of daily life (i.e. reaching for and grasping a cup or other objects, turning page
in a book, proper use of writing tool) from the content of the occupational therapy [143]. A
more recent approach suggests motor imagery interventions to be tailored on specific individual
possibilities, skills and needs of the patient in accordance with evidence-based practice [19].
Finally, the measurement of the impact of new rehabilitative interventions on patient motor
impairment is another issue of utmost importance. One valuable instrument which can offer
a solid way to generalize results obtained from clinical/research trials, is represented by International Classification of Functioning (ICF). In a recent study, the effectiveness of a mental
practice-based training on post-stroke rehabilitation has been evaluated by considering primary
and secondary outcome measures according to the ICF domains (impairment; activity; participation and quality of life) [191].

6

Summary

As shown in this review, recent progress in brain-computer interfaces seems to indicate that
time is ripe for developing practical technology for brain-computer interaction; i.e., BCI prototypes combined with other assistive technologies that will have a real impact in improving the
quality of life of disabled people. This is particularly the case for four application areas, namely
‘Communication & Control’, ‘Motor Substitution’, ‘Entertainment’, and ‘Motor Recovery’. We
expect further progress during the next years driven by new research and developments in key
areas such as design of hybrid BCI architectures, conception of adaptation algorithms, exploitation of mental states, incorporation of human-computer interaction principles, and development
of novel BCI technology and EEG devices.

Acknowledgements
This work is supported by the European ICT Programme Project FP7-224631. This paper only
reflects the authors’ views and funding agencies are not liable for any use that may be made of
the information contained herein.

References
[1] B.Z. Allison, C. Brunner, V. Kaiser, G.R. Müller-Putz, C. Neuper, and G. Pfurtscheller.
Toward a hybrid brain-computer interface based on imagined movement and visual attention. J. Neural Eng., 7, 2010.
18

[2] B.Z. Allison, E.W. Wolpaw, and J.R. Wolpaw. Brain-computer interface systems:
Progress and prospects. Expert Rev. Med. Devices, 4:463–474, 2007.
[3] G. Alon, A.F. Levitt, and P.A. McCarthy. Functional electrical stimulation enhancement
of upper extremity functional recovery during stroke rehabilitation: A pilot study. Neurorehabil. Neural Repair, 21:207–215, 2007.
[4] K.D. Anderson. Targeting recovery: Priorities of the spinal cord-injured population.
Neurotrauma, 21:1371–1383, 2004.
[5] K.K. Ang, C. Guan, K.S.G. Chua, B.T. Ang, C. Kuah, C. Wang, K.S. Phua, Z.Y. Chin,
and H. Zhang. A clinical study of motor imagery-based brain-computer interface for
upper limb robotic rehabilitation. In Proc. 31th A. Int. Conf. IEEE Eng. Med. Biol. Soc.,
2009.
[6] F. Babiloni, F. Cincotti, L. Lazzarini, J.d.R. Millán, J. Mouriño, M. Varsta, J. Heikkonen,
L. Bianchi, and M.G. Marciani. Linear classification of low-resolution EEG patterns
produced by imagined hand movements. IEEE Trans. Neural. Syst. Rehabil. Eng., 8:186–
188, 2000.
[7] M.J. Bates. The design of browsing and berrypicking techniques for the online search
interface. Online Review, 13:407–424, 1989.
[8] J.D. Bayliss. Use of the evoked potential P3 component for control in a virtual apartment.
IEEE Trans. Neural. Syst. Rehabil. Eng., 11:113–116, 2003.
[9] C.J. Bell, P. Shenoy, R. Chalodhorn, and R.P.N. Rao. Control of a humanoid robot by a
noninvasive brain-computer interface in humans. J. Neural Eng., 5:214–220, 2008.
[10] M. Bensch, A.A. Karim, J. Mellinger, T. Hinterberger, M. Tangermann, M. Bogdan,
W. Rosenstiel, and N. Birbaumer. Nessi: An EEG-controlled web browser for severely
paralyzed patients. Comp. Int. Neurosci., 2007.
[11] A. Berthoz. The role of inhibition in the hierarchical gating of executed and imagined
movements. Cogn. Brain Research, 3:101–113, 1996.
[12] N. Birbaumer, N. Ghanayim, T. Hinterberger, I. Iversen, B. Kotchoubey, A. Kübler,
J. Perelmouter, E. Taub, and H. Flor. A spelling device for the paralysed. Nature,
398:297–298, 1999.
[13] N. Birbaumer, A.R. Murguialday, and L. Cohen. Brain-computer interface in paralysis.
Cur. Opinion Neurology, 21:634–638, 2008.
[14] P. Biswas and P. Robinson. Simulation to predict performance of assistive interfaces. In
Proc. 9th Int. ACM SIGACCESS Conf. Comp. & Accessib., 2007.
[15] B. Blankertz, D. Dornhege, M. Krauledat, K.R. Müller, and G Curio. The non-invasive
Berlin brain-computer interface: Fast acquisition of effective performance in untrained
subjects. NeuroImage, 37:539–550, 2007.

19

[16] B. Blankertz, G. Dornhege, C. Schäfer, R. Krepki, J. Kohlmorgen, K-R. Müller, V. Kunzmann, F. Losch, and G. Curio. Boosting bit rates and error detection for the classification
of fast-paced motor commands based on single-trial EEG analysis. IEEE Trans. Neural
Systems Rehabil. Eng., 11:127–131, 2003.
[17] J. Blumberg, J. Rickert, S. Waldert, A. Schulze-Bonhage, A. Aertsen, and C. Mehring.
Adaptive classification for brain computer interfaces. In Proc. 29th A. Int. Conf. IEEE
Eng. Med. Biol. Soc., pages 2536–2539, 2007.
[18] G. Bourhis and Y. Agostini. The Vahm robotized wheelchair: System architecture and
human-machine interaction. J. Int. Rob. Syst., 22:39–50, 1998.
[19] S. Braun, M. Kleynen, J. Schols, T. Schack, A. Beurskens, and D. Wade. Using mental
practice in stroke rehabilitation: A framework. Clinical Rehabil., 22:579–591, 2008.
[20] S.M. Braun, A.J. Beurskens, P.J. Borm, T. Schack, and D.T. Wade. The effects of mental
practice in stroke rehabilitation: A systematic review. Arch. Phys. Med. Rehabil., 87:842–
852, 2006.
[21] T. Broderick and D.J.C. MacKay. Fast and flexible selection with a single switch. PLoS
ONE, 4:e7481, 2009.
[22] C. Brunner, B.Z. Allison, D.J. Krusienski, V. Kaiser, G.R. Müller-Putz, C. Neuper, and
G. Pfurtscheller. Improved signal processing approaches in an offline simulation of a
hybrid brain-computer interface. J. Neurosci. Methods, 188:165–173, 2010.
[23] E. Buch, C. Weber, L.G. Cohen, C. Braun, M.A. Dimyan, T. Ard, J. Mellinger, A.Caria,
S. Soekadar, A. Fourkas, and N. Birbaumer. Think to move: A neuromagnetic braincomputer interface (BCI) system for chronic stroke. Stroke, 39:910–917, 2008.
[24] A. Buttfield, P.W. Ferrez, and J.d.R. Millán. Towards a robust BCI: Error recognition and
online learning. IEEE Trans. Neural Sys. Rehabil. Eng, 14:164–168, 2006.
[25] J.M. Carmena, M.A. Lebedev, R.E. Crist, J.E. O’Doherty, D.M. Santucci, D.F. Dimitrov,
P.G. Patil, C.S. Henriquez, and M.A.L. Nicolelis. Learning to control a brain-machine
interface for reaching and grasping by primates. PLoS Biol., 1:193–208, 2003.
[26] F. Chollet, V. DiPiero, R.J. Wise, D.J. Brooks, R.J. Dolan, and R.S. Frackowiak. The
functional anatomy of motor recovery after stroke in humans: A study with positron
emission tomography. Ann. Neurology, 29:63–71, 1991.
[27] F. Cincotti, D. Mattia, C. Babiloni, F. Carducci, S. Salinari, L. Bianchi, M.G. Marciani,
and F. Babiloni. The use of EEG modifications due to motor imagery for brain-computer
interfaces. IEEE Trans. Neural. Syst. Rehabil. Eng., 11:131–133, 2003.
[28] F. Cincotti, E.J.M. Schreuder, L. Bianchi, C. Breitwieser, M. Tavella, R. Leeb, G.R.
Müller-Putz, M. Tangemann, A. Kübler, and J.d.R. Millán. Fostering BCI interoperability. In Proc. 4th Int. BCI Meeting, 2010.
[29] B. Costello and E. Edmonds. A study in play, pleasure and interaction design. In Proc.
2007 Conf. Design. Pleasur. Prod. & Int., 2007.
20

[30] S.M. Coyle, T.E. Ward, and C.M. Markham. Brain-computer interface using a simplified
functional near-infrared spectroscopy system. J. Neural Eng., 4:219–226, 2007.
[31] S.C. Cramer. Functional imaging in stroke recovery. Stroke, 35:2695–2698, 2004.
[32] J. Daly, R. Cheng, J. Rogers, K. Litinas, K. Hrovat, and M. Dohring. Feasibility of a
new application of noninvasive brain computer interface (BCI): A case study of training
for recovery of volitional motor control after stroke. J. Neurol. Phys. Ther., 33:203–211,
2009.
[33] J.J. Daly and J.R. Wolpaw. Brain-computer interfaces in neurological rehabilitation.
Lancet Neurology, 7:1032–1043, 2008.
[34] M. Danoczy, S. Fazli, C. Grozea, K.R. Müller, and F. Popescu. Brain2robot: A grasping
robot arm controlled by gaze and asynchronous EEG BCI. In Proc. 4th Int. BCI Workshop
& Train. Course, 2008.
[35] J. de Pedro-Cuesta, L. Widen-Holmqvist, and P. Bach-y-Rita. Evaluation of stroke rehabilitation by randomized controlled studies: A review. Acta Neurologica Scandinavica,
86:433–439, 1992.
[36] J. Decety and J. Grezes. Neural mechanisms subserving the perception of human actions.
Trends in Cogn. Sciences, 3:172–178, 1999.
[37] J. Decety and M. Jeannerod. Mentally simulated movements in virtual reality: Does
Fitts’s law hold in motor imagery? Behav. Brain Research, 72:127–134, 1995.
[38] R. Dickstein and J.E. Deutsch. Motor imagery in physical therapist practice. Physical
Therapy, 87:942–953, 2007.
[39] B.H. Dobkin. Neurobiology of rehabilitation. Ann. N. Y. Acad. Sci., 1038:148–170, 2004.
[40] B.H. Dobkin. Training and exercise to drive poststroke recovery. Nat. Clin. Pract. Neurol., 4:76–85, 2008.
[41] E. Donchin, K.M. Spencer, and Wijesinghe R. The mental prosthesis: Assessing the
speed of a P300-based brain-computer interface. IEEE Trans. Neural. Syst. Rehabil.
Eng., 8:174–179, 2000.
[42] G. Dornhege, J.d.R. Millán, T. Hinterberger, D.J. McFarland, and K.R. Müller, editors.
Towards Brain-Computing Interfacing. Cambridge, MA: MIT Press, 2007.
[43] P.W. Duncan. Synthesis of intervention trials to improve motor recovery following stroke.
Topics in Stroke Rehabil., 3:1–20, 1997.
[44] P.W. Duncan, L.B. Goldstein, D. Matchar, G.W. Divine, and J. Feussner. Measurement of
motor recovery after stroke. Outcome assessment and sample size requirements. Stroke,
23:1084–1089, 1992.
[45] L.A. Farwell and E. Donchin. Talking off the top of your head: Toward a mental prosthesis utilizing event related brain potentials. Clin. Neurophysiol., 70:510–523, 1988.
21

[46] D. L. Feltz and D. M. Landers. The effects of mental practice on motor skill learning and
performance: A meta-analysis. J. Sport Psychol., 5:25–57, 1983.
[47] P.W. Ferrez and J.d.R. Millán. You are wrong!—Automatic detection of interaction errors
from brain waves. In Proc. 19th Int. Joint Conf. Artif. Intel., 2005.
[48] P.W. Ferrez and J.d.R. Millán. Error-related EEG potentials generated during simulated
brain-computer interaction. IEEE Trans. Biomed. Eng., 55:923–929, 2008.
[49] P.W. Ferrez and J.d.R. Millán. Simultaneous real-time detection of motor imagery and
error-related potentials for improved BCI accuracy. In Proc. 4th Int. BCI Workshop &
Train. Course, 2008.
[50] A. Feydy, R. Carlier, A. Roby-Brami, B. Bussel, F. Cazalis, L. Pierot, Y. Burnod, and
M.A. Maier. Longitudinal study of motor recovery after stroke: Recruitment and focusing of brain activation. Stroke, 33:1610–1617, 2002.
[51] A. Finke, A. Lenhardt, and H. Ritter. The MindGame: A P300-based brain-computer
interface game. Neural Networks, 22:1329–1333, 2009.
[52] O. Flemisch, A. Adams, S.R. Conway, K.H. Goodrich, M.T. Palmer, and P.C. Schutte.
The H-Metaphor as a guideline for vehicle automation and interaction. Technical Report
NASA/TM–2003-212672, NASA, 2003.
[53] D. Frohlich, A. Kuchinsky, C. Pering, A.D., and S. Ariss. Requirements for photoware.
In Proc. 2002 ACM Conf. Comp. Sup. Coop. Work (CSCW02), pages 166–175, 2002.
[54] F. Galán, P.W. Ferrez, F. Oliva, J. Guardia, and J.d.R. Millán. Feature extraction for
multi-class BCI using canonical variates analysis. In Proc. IEEE Int. Symp. Int. Sig.
Proc., 2007.
[55] F. Galán, M. Nuttin, E. Lew, P.W. Ferrez, G. Vanacker, J. Philips, and J.d.R. Millán.
A brain-actuated wheelchair: Asynchronous and non-invasive brain-computer interfaces
for continuous control of robots. Clin. Neurophysiol., 119:2159–2169, 2008.
[56] G. Gangadhar, R.. Chavarriaga, and J.d.R. Millán. Fast recognition of anticipation related
potentials. IEEE Trans. Biomed. Eng., 56:1257–1260, 2009.
[57] X. Gao, X. Dingfeng, M. Cheng, and S. Gao. A BCI-based environmental controller for
the motion-disabled. IEEE Trans. Neural Sys. Rehab. Eng., 11:137–140, 2003.
[58] C. Gerloff, C. Braun, M. Staudt, Y.L. Hegner, J. Dichgans, and I. Krägeloh-Mann. Coherent corticomuscular oscillations originate from primary motor cortex: Evidence from
patients with early brain lesions. Human Brain Mapping, 27:789–798, 2006.
[59] A.D. Gerson, L.C. Parra, and P. Sajda. Cortically-coupled computer vision for rapid
image search. EEE Trans. Neural. Syst. Rehabil. Eng., 14:174–179, 2006.
[60] M. Goldfarb and W.K. Durfee. Design of a controlled-brake orthosis for FES-aided gait.
IEEE Trans. Neural. Syst. Rehabil. Eng., 4:13–24, 1996.

22

[61] Y. Gu, K. Dremstrup, and D. Farina. Single-trial discrimination of type and speed of
wrist movements from EEG recordings. Clin. Neurophysiol., 120:1596–1600, 2009.
[62] C. Guger, G. Edlinger, W. Harkam, I. Niedermayer, and G. Pfurtscheller. How many
people are able to operate an EEG-based brain-computer interface (BCI)? IEEE Trans.
Neural. Syst. Rehabil. Eng., 11:145–147, 2003.
[63] A. Guillot, C. Collet, V.A. Nguyen, F. Malouin, C. Richards, and J. Doyon. Brain activity during visual versus kinesthetic imagery: An fMRI study. Human Brain Mapping,
30:2157–2172, 2008.
[64] S. Halder, A. Furdea, R. Leeb, G. Müller-Putz, A. Hösle, and A. Kübler. Implementation
of SMR based brain painting. Poster at COST Neuromath Workshop, 2009.
[65] B. Hamadicharef, H.H. Zhang, C.T. Guan, C.C. Wang, K.S. Phua, K.P. Tee, and K.K.
Ang. Learning EEG-based spectral-spatial patterns for attention level measurement. In
Proc. 2009 IEEE Int. Symp. Circuits Syst., 2009.
[66] Y. Hara. Neurorehabilitation with new functional electrical stimulation for hemiparetic
upper extremity in stroke patients. J. Nippon Med. Sch., 75:4–14, 2008.
[67] Y. Hara, S. Ogawa, K. Tsujiuchi, and Y. Muraoka. A home-based rehabilitation program
for the hemiplegic upper extremity by power-assisted functional electrical stimulation.
Disabil. Rehabil., 30:296–304, 2008.
[68] V. Hentz and C. Le Clercq, editors. Surgical Rehabilitation of the Upper Limb in
Tetraplegia. W. B. Saunders Ltd., 2002.
[69] L.R. Hochberg, M.D. Serruya, G.M. Friehs, J.A. Mukand, M. Saleh, A.H. Caplan,
A. Branner, D. Chen, R.D. Penn, and J.P. Donoghue. Neuronal ensemble control of
prosthetic devices by a human with tetraplegia. Nature, 442:164–171, 2006.
[70] M. K. Holden, T.A. Dyar, L. Schwamm, and E. Bizzi. Virtual-environment-based telerehabilitation in patients with stroke. Presence Teleoper. Virtual Environ., 14:214–233,
2005.
[71] H. Hoyer. The OMNI wheelchair. Service Robot: An Int. Journal, 1:26–29, 1995.
[72] W. IJsselsteijn, W. van den Hoogen, C. Klimmt, Y. de Kort, C. Lindley, K. Mathiak,
K. Poels, N. Ravaja, M. Turpeinen, and P. Vorderer. Measuring the experience of digital
game enjoyment. In Proc. Measuring Behavior, pages 88–89, 2008.
[73] M.J. Ijzermann, T.S. Stoffers, M.A. Klatte, G. Snoeck, J.H. Vorsteveld, and R.H. Nathan.
The NESS handmaster orthosis: Restoration of hand function in C5 and stroke patients
by means of electrical stimulation. J. Rehabil. Science, 9:86–89, 1996.
[74] I. Iturrate, J. Antelis, and J. Minguez. Synchronous EEG brain-actuated wheelchair with
automated navigation. In Proc. 2009 IEEE Int. Conf. Robot. Autom., 2009.
[75] D. Jack, R. Boian, A. S. Merians, M. Tremaine, G. C. Burdea, S. V. Adamovich,
M. Recce, and H. Poizner. Virtual reality-enhanced stroke rehabilitation. IEEE Trans.
Neural. Syst. Rehabil. Eng., 9:308–318, 2001.
23

[76] M. Jeannerod and V. Frak. Mental imaging of motor activity in humans. Curr. Opin.
Neurobiol., 9:735–739, 1999.
[77] A.M. Junker, J.R. Wegner, and T. Sudkamp. Cyberlink brainfingers for people with no
means of access, NIH study results. In Proc. 17th A. Int. Conf. Techn. & Persons with
Disabilities, 2002.
[78] J. Kameyama, Y. Handa, N. Hoshimiya, and M. Sakurai. Restoration of shoulder movement in quadriplegic and hemiplegic patients by functional electrical stimulation using
percutaneous multiple electrodes. Tohoku J. Exp. Med., 187:329–337, 1999.
[79] A.A. Karim, T. Hinterberger, J. Richter, J. Mellinger, N. Neumann, H. Flor, A. Kübler,
and N. Birbaumer. Neural internet: Web surfing with brain potentials for the completely
paralyzed. Neurorehabil. Neural Repair, 20:508–515, 2006.
[80] N.I. Katevas, N.M. Sgouros, S.G. Tzafestas, G. Papakonstantinou, P. Beattie, J.M.
Bishop, P. Tsanakas, and D. Koutsouris. The autonomous mobile robot SENARIO: A
sensor aided intelligent navigation system for powered wheelchairs. IEEE Robot. & Autom. Mag., 4:60–70, 1997.
[81] L. Kauhanen, T. Nykopp, and M. Sams. Classification of single MEG trials related to
left and right index finger movements. Clin. Neurophysiol., 117:430–439, 2006.
[82] M. Kawanabe, C. Vidaurre, S. Schöller, B. Blankertz, and K-R. Müller. Robust common
spatial filters with a maxmin approach. In Proc. 31st A. Int. Conf. IEEE Eng. Med. Biol.
Soc., pages 2470–2473, 2009.
[83] M.W. Keith and H. Hoyen. Indications and future directions for upper limb neuroprostheses in tetraplegic patients: A review. Hand Clin., 18:519–528, 2002.
[84] D. Kirk, A. Sellen, C. Rother, and K.Wood. Understanding photowork. In Proc. SIGCHI
Conf. Human Factors in Computing Systems (CHI ’06), pages 761–770, 2006.
[85] R. Kobetic, E.B. Marsolais, R.J. Triolo, D.T. Davy, R. Gaudio, and S. Tashman. Development of a hybrid gait orthosis: A case report. J. Spinal Cord Med., 26:254–258,
2003.
[86] J. Kohlmorgen, G. Dornhege, M. Braun, B. Blankertz, K.R. Müller, G. Curio, K. Hagemann, A. Bruns, M. Schrauf, and W. Kincses. Improving human performance in a real
operating environment through real-time mental workload detection. In G. Dornhege,
J.d.R. Millán, T. Hinterberger, D. McFarland, and K.R. Müller, editors, Toward BrainComputer Interfacing, pages 409–422. MIT press, Cambridge, MA, 2007.
[87] R. Krepki, B. Blankertz, G. Curio, and K.R. Müller. The Berlin brain-computer interface
(BBCI): Towards a new communication channel for online control in gaming applications. J. Multimedia Tools App., 33:73–90., 2007.
[88] A. Kübler, A. Furdea, S. Halder, and A. Hösle. Brain painting—BCI meets art. In Proc.
4th Int. BCI Workshop & Train. Course, pages 361–366, 2008.

24

[89] A. Kübler, F. Nijboer, J. Mellinger, T.M. Vaughan, H. Pawelzik, G. Schalk, D.J. McFarland, N. Birbaumer, and J.R. Wolpaw. Patients with ALS can use sensorimotor rhythms
to operate a brain-computer interface. Neurology, 64:1775–1777, 2005.
[90] G. Kwakkel, B.J. Kollen, and R.C. Wagenaar. Therapy impact on functional recovery in
stroke rehabilitation: A critical review of the literature. Physioth.-J. Chart. Soc. Physiotherapy, 85:377–391, 1999.
[91] S.-M. Lai, S. Studenski, P.W. Duncan, and S. Perera. Persisting consequences of stroke
measured by the Stroke Impact Scale. Stroke, 33:1840–1844, 2002.
[92] E. Lalor, C. Kelly, S.P. adn Finucane, R. Burke, R. Smith, R.B. Reilly, and G. McDarby.
Steady-state VEP-based brain computer interface control in an immersive 3-D gaming
environment. J. Appl. Sig. Proc., 19:3156–3164, 2005.
[93] E.C. Lalor, S.P. Kelly, C. Finucane, R. Burke, R. Smith, R.B. Reilly, and G. McDarby.
Steady-state vep-based brain computer interface control in an immersive 3-d gaming
environment. EURASIP J. Applied Signal Processing, 19:3156–3164, 2005.
[94] P. Langhorne, F. Coupar, and A. Pollock. Motor recovery after stroke: A systematic
review. Lancet Neurol., 8:741–54, 2009.
[95] A. Lecuyer, F. Lotte, R.B. Reilly, R. Leeb, M. Hirose, and M. Slater. Brain-computer
interfaces, virtual reality, and videogames. Computer, 41:66–72, 2008.
[96] R. Leeb, D. Friedman, G. R. Müller-Putz, R. Scherer, M. Slater, and G. Pfurtscheller.
Self-paced (asynchronous) BCI control of a wheelchair in virtual environments: A case
study with a tetraplegics. Comp. Int. Neurosci., 2007.
[97] R. Leeb, M. Gubler, M. Tavella, H. Miller, and J.d.R. Millán. On the road to a neuroprosthetic hand: A novel hand grasp orthosis based on functional electrical stimulation.
In Proc. 32th A. Int. Conf. IEEE Eng. Med. Biol. Soc., 2010.
[98] R. Leeb, C. Keinrath, D. Friedman, C. Guger, R. Scherer, C. Neuper, M. Garau,
A. Antley, A. Steed, M. Slater, and G. Pfurtscheller. Walking by thinking: the brainwaves are crucial, not the muscles! Presence: Teleoperators and Virtual Environments,
15:500–514, 2006.
[99] R. Leeb, F. Lee, C. Keinrath, R. Scherer, H. Bischof, and G. Pfurtscheller. Braincomputer communication: Motivation, aim and impact of exploring a virtual apartment.
IEEE Trans. Neural. Syst. Rehabil. Eng., 15:473–482, 2007.
[100] R. Leeb, H. Sagha, R. Chavarriaga, and J.d.R. Millán. Multimodal fusion of muscle and
brain signals for a hybrid-BCI. In Proc. 32th A. Int. Conf. IEEE Eng. Med. Biol. Soc.,
2010.
[101] R. Leeb, V. Settgast, D.W. Fellner, and G. Pfurtscheller. Self-paced exploring of the
Austrian National Library through thoughts. Int. J. Bioelectromag., 9:237–244, 2007.
[102] E.C. Leuthardt, G. Schalk, J.R. Wolpaw, J.G. Jemann, and D.W. Oran. A brain-computer
interface using electrocorticographic signals in humans. J. Neural Eng., 1:63–71, 2004.
25

[103] S.P. Levine, D.A. Bell, L.A. Jaros, R.C. Simpson, Y. Koren, and J. Borenstein. The
navchair assistive wheelchair navigation system. IEEE Trans. Neural. Syst. Rehabil.
Eng., 7:443–451, 1999.
[104] J. Liepert, H. Bauder, H.R. Wolfgang, W.H. Miltner, E. Taub, and C. Weiller. Treatmentinduced cortical reorganization after stroke in humans. Stroke, 31:1210–1216, 2000.
[105] M. Lotze and U. Halsband. Motor imagery. J. Physio., 99:386–395, 2006.
[106] S. Lu, C. Guan, and H. Zhang. Unsupervised brain computer interface based on intersubject information and online adaptation. IEEE Trans. Neural Systems Rehabil. Eng.,
17:135–145, 2009.
[107] S. Mahlke. Understanding users’ experience of interaction. In Proc. 2005 A. Conf. Eur.
Asso. Cog. Ergonomics, 2005.
[108] J. Mak and J. Wolpaw. Clinical applications of brain-computer interfaces: current state
and future prospects. EEE Rev. Biomed. Eng., 2:187–199, 2010.
[109] F. Malouin, C.L. Richards, A. Durand, and J. Doyon. Clinical assessment of motor
imagery after stroke. Neurorehabil. Neural Repair, 22:330–340, 2008.
[110] T. Mangold, S.and Keller, A. Curt, and V. Dietz. Transcutaneous functional electrical
stimulation for grasping in subjects with cervical spinal cord injury. Spinal Cord, 43:1–
13, 2005.
[111] J. Mellinger, G. Schalk, C. Braun, H. Preissl, W. Rosenstiel, N. Birbaumer, and
A. KŸbler. An MEG?based brain?computer interface (BCI). Neuroimage, 36:581–593,
2007.
[112] W.D. Memberg, P.E. Crago, and M.W. Keith. Restoration of elbow extension via functional electrical stimulation in individuals with tetraplegia. J. Rehabil. Res. Dev., 40:477–
486, 2003.
[113] A.S. Merians, H. Poizner, R. Boian, G. Burdea, and S. Adamovich. Sensorimotor training in a virtual reality environment: Does it improve functional recovery poststroke?
Neurorehabil. Neural Repair, 20:252–267, 2006.
[114] J.d.R. Millán. Brain-computer interfaces. In M.A. Arbib, editor, Handbook of Brain
Theory and Neural Networks, 2nd Ed., pages 178–181. The MIT Press, 2002.
[115] J.d.R. Millán. Adaptive brain interfaces. Comm. ACM, 46:74–80, 2003.
[116] J.d.R. Millán. On the need for on-line learning in brain-computer interfaces. In Proc. Int.
Joint Conf. Neural Networks, 2004.
[117] J.d.R. Millán, A. Buttfield, C. Vidaurre, M. Krauledat, A. Schögl, P. Shenoy,
B. Blankertz, R.P.N. Rao, R. Cabeza, G. Pfurtscheller, and K.R. Müller. Adaptation
in brain-computer interfaces. In G. Dornhege, J.d.R. Millán, T. Hinterberger, D. McFarland, and K.R. Müller, editors, Toward Brain-Computer Interfacing, pages 303–325.
MIT press, Cambridge, MA, 2007.
26

[118] J.d.R. Millán, F. Galán, D. Vanhooydonck, E. Lew, J. Philips, and M. Nuttin. Asynchronous non-invasive brain-actuated control of an intelligent wheelchair. In Proc. 31st
A. Int. Conf. IEEE Eng. Med. Biol. Soc., 2009.
[119] J.d.R. Millán, J. Mouriño, M. Franzé, F. Cincotti, M. Varsta, J. Heikkonen, and F. Babiloni. A local neural classifier for the recognition of EEG patterns associated to mental
tasks. IEEE Trans. Neural Networks, 13:678–686, 2002.
[120] J.d.R. Millán, F. Renkens, J. Mouriño, and W. Gerstner. Brain-actuated interaction. Artif.
Intell., 159:241–259, 2004.
[121] J.d.R. Millán, F. Renkens, J. Mouriño, and W. Gerstner. Non-invasive brain-actuated
control of a mobile robot by human EEG. IEEE Trans. Biomed. Eng., 51:1026–1033,
2004.
[122] E.R. Miranda. Brain-computer music interface for composition and performance. Int. J.
Dis. Human Dev., 5:119–125, 2006.
[123] C.T. Moritz, S.I. Perlmutter, and E.E. Fetz. Direct control of paralysed muscles by cortical neurons. Nature, 456:639–642, 2008.
[124] E. Mugler, M. Bensch, S. Halder, W. Rosenstiel, M. Bogdan, N. Birbaumer, and
A. Kübler. Control of an internet browser using the P300 event-related potential. Int.
J. Bioelectromag., 10:56–63, 2008.
[125] K.R. Müller and B. Blankertz. Toward noninvasive brain-computer interfaces. IEEE
Signal Proc. Mag., 23:125–128, 2006.
[126] G.R. Müller-Putz, R. Scherer, G. Pfurtscheller, and R. Rupp. EEG-based neuroprosthesis
control: A step towards clinical practice. Neurosci. Lett, 382:169–174, 2005.
[127] G.R. Müller-Putz, R. Scherer, G. Pfurtscheller, and R. Rupp. Brain-computer interfaces
for control of neuroprostheses: From synchronous to asynchronous mode of operation.
Biomed. Technik, 51:57–63, 2006.
[128] G.R. Müller-Putz, R. Scherer, G. Pfurtscheller, and R. Rupp. Control of a two-axis
artificial limb by means of a pulse width modulated. In Proc. 9th Eur. Conf Advan.
Assist. Techn., 2007.
[129] T.H. Murphy and D. Corbett. Plasticity during stroke recovery: From synapse to behaviour. Nat. Rev. Neurosci., 10:861–872, 2009.
[130] J. Netz, T. Lammers, and V. Hömberg. Reorganization of motor output in the nonaffected hemisphere after stroke. Brain, 120:1579–1586, 1997.
[131] N. Neumann and A. Kübler. Training locked-in patients: A challenge for the use of braincomputer interfaces. IEEE Trans. Neural Systems Rehabil. Eng., 11:169–172, 2003.
[132] C. Neuper, G.R. Müller-Putz, R. Scherer, and G. Pfurtscheller. Motor imagery and EEGbased control of spelling devices and neuroprostheses. Prog. Brain Research, 159:393–
409, 2006.
27

[133] C. Neuper, R. Scherer, M. Reiner, and G. Pfurtscheller. Imagery of motor actions: Differential effects of kinesthetic and visual-motor mode of imagery in single-trial EEG. Cogn.
Brain Research, 25:668–677, 2005.
[134] C. Neuper, A. Schlögl, and G. Pfurtscheller. Enhancement of left-right sensorimotor EEG
differences during feedback-regulated motor imagery. Clin. Neurophysiol., 16:373–382,
1999.
[135] M.A.L. Nicolelis. Actions from thoughts. Nature, 409:403–407, 2001.
[136] F. Nijboer, A. Furdea, I. Gunst, J. Mellinger, D.J. McFarland, N. Birbaumer, and
A Kübler. An auditory brain-computer interface (BCI). J. Neurosci. Met., 167:43–50,
2007.
[137] F. Nijboer, E.W. Sellers, J. Mellinger, M.A. Jordan, T. Matuz, A. Furdea, S. Halder,
U. Mochty, D.J. Krusienski, T.M. Vaughan, J.R. Wolpaw, N. Birbaumer, and A. Kübler.
A P300-based brain-computer interface for people with amyotrophic lateral sclerosis.
Clin. Neurophysiol., 119:1909–1916, 2008.
[138] A. Nijholt. BCI for games: A ‘state of the art’ survey. In Proc. 7th Int. Conf. Entertain.
Comp. (ICEC ’08), pages 225–228, 2009.
[139] A. Nijholt, J. Erp, and D.K.J. van Heylen. BrainGain: BCI for HCI and games. In Proc.
AISB Symp. Brain Computer Interfaces and Human Computer Interaction: A Convergence of Ideas, pages 32–35, Aberdeen, UK, 2008.
[140] A. Nijholt, D. Tan, B. Allison, J.d.R. Millán, B. Graimann, and M.M. Jackson. Braincomputer interfaces for HCI and games. In Proc. ACM CHI 2008, 2008.
[141] R.J. Nudo. Mechanisms for recovery of motor function following cortical damage. Curr.
Opin. Neurobiol., 16:638–644, 2006.
[142] B. Obermaier, G.R. Müller, and G. Pfurtscheller. “Virtual keyboard” controlled by spontaneous EEG activity. IEEE Trans. Neural. Syst. Rehabil. Eng., 11:422–426, 2003.
[143] S.J. Page, P. Levine, and A. Leonard. Mental practice in chronic stroke: Results of a
randomized, placebo-controlled trial. Stroke, 38:1293–1297, 2007.
[144] S.J. Page, S. Maslyn, V.H. Hermann, A. Wu, K. Dunning, and P.G. Levine. Activitybased electrical stimulation training in a stroke patient with minimal movement in the
paretic upper extremity. Neurorehabil. Neural Repair, 23:595–599, 2009.
[145] S.P. Parikh, V. Grassi, V. Kumar, and J. Okamoto. Incorporating user inputs in motion planning for a smart wheelchair. In Proc. IEEE Conf. Robotics and Automation
(ICRA’04), 2004.
[146] G. Pfurtscheller, B.Z. Allison, G. Bauernfeind, C. Brunner, T. Solis Escalante, R. Scherer,
T.O. Zander, G. Müller-Putz, C. Neuper, and N. Birbaumer. The hybrid BCI. Front.
Neurosci., 4:42. doi:10.3389/fnpro.2010.00003, 2010.

28

[147] G. Pfurtscheller, C. Guger, G. Müller, G. Krausz, and C. Neuper. Brain oscillations
control hand orthosis in a tetraplegic. Neurosci. Lett., 292:211–214, 2000.
[148] G. Pfurtscheller, G.R. Müller, J. Pfurtscheller, H.J. Gerner, and R. Rupp. Thought-control
of functional electrical stimualtion to restore hand grasp in a patient with tetraplegia.
Neurosci. Lett., 351:33–36, 2003.
[149] G. Pfurtscheller and C. Neuper. Motor imagery and direct brain-computer communication. Proc. IEEE, 89:1123–1134, 2001.
[150] G. Pfurtscheller, C. Neuper, D. Flotzinger, and M. Pregenzer. EEG-based discrimination between imagination of right and left hand movement. Electroencephalogr. Clin.
Neurophysiol., 103:642–651, 1997.
[151] T. Pistohl, T. Ball, A. Schulze-Bonhage, A. Aertsen, and C. Mehring. Prediction of
arm movement trajectories from ECoG-recordings in humans. J. Neurosci. Methods,
167:105–114, 2008.
[152] T. Platz, I.H. Kim, H. Pintschovius, T. Winter, A. Kieselbach, K. Villringer, R. Kurth, and
K.H. Mauritz. Multimodal EEG analysis in man suggests impairment-specific changes
in movement-related electric brain activity after stroke. Brain, 123:2475–2490, 2000.
[153] F. Popescu, Y. Fazli, S.and Badower, B. Blankertz, and K.R. Müller. Single trial classification of motor imagination using 6 dry EEG electrodes. PLoS ONE, 2:e637, 2007.
[154] G. Prasad, P. Herman, D. Coyle, S. McDonough, and J. Crosbie. Using motor imagery
based brain-computer interface for post-stroke rehabilitation. In Proc. 4th IEEE/EMBS
Int. Conf. Neural Eng., 2009.
[155] E. Prassler, J. Scholz, and P. Fiorini. A robotics wheelchair for crowded public environment. IEEE Robotics & Automation Mag., 8:38–45, 2001.
[156] B. Rebsamen, E. Burdet, C. Guan, H. Zhang, C.L. Teo, Q. Zeng, C. Laugier, and M.H.
Ang. Controlling a wheelchair indoors using thought. IEEE Intelligent Systems, 22:18–
24, 2007.
[157] K. Rodden and K.R. Wood. How do people manage their digital photographs? In Proc.
SIGCHI Conf. Human factors in Computing Systems (CHI ’03), pages 409–416, 2003.
[158] T. Röfer and A. Lankenau. Architecture and applications of the Bremen autonomous
wheelchair. Inform. Sci., 126:1–20, 2000.
[159] R. Ron-Angevin, A. Diaz-Estrella, and F. Velasco-Alvarez. A two-class brain computer
interface to freely navigate through virtual worlds. Biomed. Technik, 54:126–133, 2009.
[160] G. Ruffini, S. Dunne, E. Farrés, I. Cester, P.C.P. Watts, S.R.P. Silva, C. Grau,
L. Fuentemilla, J. Marco-Pallarés, and B. Vandecasteele. ENOBIO dry electrophysiology electrode; first human trial plus wireless electrode system. In Proc. 29th A. Int.
Conf. IEEE Eng. Med. Biol. Soc., 2007.

29

[161] J.D. Schaechter. Motor rehabilitation and brain plasticity after hemiparetic stroke. Prog.
Neurobiol., 73:61–72, 2004.
[162] R. Scherer, A.Mohapp, P. Grieshofer, G. Pfurtscheller, and C. Neuper. Sensorimotor
EEG patterns during motor imagery in hemiparetic stroke patients. Int. J. Bioelectromag.,
9:155–162, 2007.
[163] R. Scherer, F. Lee, R. Leeb, A.S.H. Bischof, and G. Pfurtscheller. Towards asynchronous
(uncued) brain-computer communication: Navigation through virtual worlds. IEEE
Trans. Biomed. Eng., 2007.
[164] R. Scherer, G.R. Müller, C. Neuper, B. Grainmann, and G. Pfurtscheller. An asynchronous controlled EEG-based virtual keyboard: Improvement of the spelling rate.
IEEE Trans. Biomed. Eng., 51:979–984, 2004.
[165] R. Scherer, G.R. Müller-Putz, and G. Pfurtscheller. Self-initiation of EEG-based braincomputer communication using the heart rate response. J. Neural Eng., 4:L23–L29,
2007.
[166] A. Schlögl. The Electroencephalogram and the Adaptive Autoregressive Model: Theory
and Applications. Shaker Verlag, Aachen, Germany, 2000.
[167] E.W. Sellers, D.J. Krusienski, D.J. McFarland, T.M. Vaughan, and J.R. Wolpaw. A P300
event-related potential brain-computer interface (BCI): The effects of matrix size and
inter stimulus interval on performance. Biol. Psychol., 73:242–252, 2006.
[168] E.W. Sellers, P. Turner, W.A. Sarnacki, T. Mcmanus, T.M. Vaughan, and B. Matthews. A
novel dry electrode for brain-computer interface. In Proc. 13th Int. Conf. Human-Comp.
Interact., 2009.
[169] N. Sharma, J-C. Baron, and J.B. Rowe. Motor imagery after stroke: Relating outcome to
motor network connectivity. Ann. Neurol., 66:604–616, 2009.
[170] N. Sharma, V.M. Pomeroy, and J.-C. Baron. Motor imagery: A backdoor to the motor
system after stroke? Stroke, 37:1941–1952, 2006.
[171] N. Sharma, L.H. Simmons, P.S. Jones, D.J. Day, T.A. Carpenter, V. M. Pomeroy, E.A.
Warburton, and J-C. Baron. Motor imagery after subcortical stroke: A functional magnetic resonance imaging study. Stroke, 40:1315–1324, 2009.
[172] P. Shenoy, M. Krauledat, B. Blankertz, R.P.N. Rao, and K.R. Müller. Towards adaptive
classification for BCI. J. Neural Eng., 3:13–23, 2006.
[173] S. Silvoni, C. Volpato, M. Cavinato, M. Marchetti, K. Priftis, A. Merico, P. Tonin,
K. Koutsikos, F. Beverina, and F. Piccione. P300-based brain-computer interface communication: Evaluation and follow-up in amyotrophic lateral sclerosis. Front. Neurosci.,
3:60. doi:10.3389/neuro.20.001.2009, 2009.
[174] L. Simmons, N. Sharma, J-C. Baron, and V.M. Pomeroy. Motor imagery to enhance
recovery after subcortical stroke: Who might benefit, daily dose, and potential effects.
Neurorehabil. Neural Repair, 22:458–467, 2008.
30

[175] R.C. Simpson. Smart wheelchairs: A literature review. J. Rehabil. Res. Dev., 42:423–
436, 2005.
[176] R.C. Simpson and S.P. Levine. Automatic adaptation in the navchair assistive wheelchairnavigation system. IEEE Trans. Neural. Syst. Rehabil. Eng., 7:452–463, 1999.
[177] R. Sitaram, H. Zhang, C. Guan, M. Thulasidas, Y. Hoshi, A. Ishikawa, K. Shimizu, and
N. Birbaumer. Temporal classification of multichannel near?infrared spectroscopy signals of motor imagery for developing a brain?computer interface. Neuroimage, 34:1416–
1427, 2007.
[178] S.K. Subramanian, C.L. Massie, M.P. Malcolm, and M.F. Levin. Does provision of
extrinsic feedback result in improved motor learning in the upper limb poststroke? A
systematic review of the evidence. Neurorehabil. Neural Repair, 24:113–124, 2010.
[179] M. Sugiyama, M. Krauledat, and K.R. Müller. Adaptation by importance weighted cross
validation. J. Machine Learn. Res., 8:985–1005, 2007.
[180] T.J. Sullivan, S.R. Deiss, T.P. Jung, and G. Cauwenberghs. A brain-machine interface using dry-contact, low-noise EEG sensors. In Proc. IEEE Int. Symp. on Circuits & Systems,
2008.
[181] E.E. Sutter. The brain response interface: Communication through visually-induced electrical brain response. J. Microcomput. Applicat., 15:31–45, 1992.
[182] C.D. Takahashi, L. Der-Yeghiaian, V. Le, R.R. Motiwala, and S.C. Cramer. Robot-based
hand motor therapy after stroke. Brain, 131:425–437, 2008.
[183] M.W. Tangermann, M. Krauledat, K. Grzeska, M. Sagebaum, C. Vidaurre, B. Blankertz,
and K.R. Müller. Playing pinball with non-invasive BCI. In Proc. NIPS, 2008.
[184] M. Tavella, R. Leeb, R. Rupp, and J.d.R. Millán. Towards natural non-invasive hand
neuroprostheses for daily living. In Proc. 32th A. Int. Conf. IEEE Eng. Med. Biol. Soc.,
2010.
[185] R. Thorsen, R. Spadone, and M Ferrarin. A pilot study of myoelectrically controlled FES
of upper extremity. IEEE Trans. Neural. Syst. Rehabil. Eng., 9:161–168, 2001.
[186] L. Tonin, R. Leeb, M. Tavella, S. Perdikis, and J.d.R. Millán. The role of shared-control
in BCI-based telepresence. In Proc. 29th A. Int. Conf. IEEE Syst. Man Cybern. Soc.,
2010.
[187] H. Touyama. Photo data retrieval via P300 evoked potentials. IEICE Trans. Inf. Syst.,
91:2212–2213, 2008.
[188] N. Tractinsky, A. Katz, and D. Ikar. What is beautiful is usable. Interact. with Comp.,
13:127–145, 2000.
[189] L.J. Trejo, R. Kochavi, K. Kubitz, L.D. Montgomery, R. Rosipal, and B. Matthews.
EEG-based estimation of cognitive fatigue. In Proc. SPIE vol. 5797, 2005.

31

[190] G. Vanacker, J.d.R. Millán, E. Lew, P.W. Ferrez, F. Galán, H. Philips, J.and Van Brussel,
and M. Nuttin. Context-based filtering for assisted brain-actuated wheelchair driving.
Comp. Int. Neurosci., 2007:Article ID 25130, 12 pages. doi:10.1155/2007/25130, 2007.
[191] J.A. Verbunt, H.AM. Seelen, F.P. Ramos, B.H.M. Michielsen, W.L. Wetzelaer, and
M. Moennekens. Mental practice-based rehabilitation training to improve arm function and daily activity performance in stroke patients: A randomized clinical trial. BMC
Neurol., 8:7, 2008.
[192] C. Vidaurre and B. Blankertz. Towards a cure for BCI illiteracy. Brain Topogr., 23:194–
198, 2010.
[193] C. Vidaurre, N. Krämer, B. Blankertz, and A. Schlögl. Time domain parameters as
a feature for EEG-based brain computer interfaces. Neural Networks, 22:1313–1319,
2009.
[194] C. Vidaurre, A. Schlögl, B. Blankertz, M. Kawanabe, and K-R. Müller. Unsupervised
adaptation of the LDA classifier for Brain-Computer Interfaces. In Proc. 4th Int. BCI
Workshop & Train. Course, pages 122–127, 2008.
[195] C. Vidaurre, A. Schlögl, R. Cabeza, R. Scherer, and G. Pfurtscheller. A fully on-line
adaptive BCI. IEEE Trans. Biomed. Eng., 53:1214–1219, 2006.
[196] B.T. Volpe, P.T. Huerta, J.L. Zipse, A. Rykman, D. Edwards, L. Dipietro, N. Hogan, and
H.I. Krebs. Robotic devices as therapeutic and diagnostic tools for stroke recovery. Arch.
Neurol., 66:1086–1090, 2009.
[197] P. von Bünau, F.C. Meinecke, F. Kiraly, and K.R. Müller. Finding stationary subspaces
in multivariate time series. Physics Rev. Lett., 103:214101, 2009.
[198] W. Wang, J.L. Collinger, M.A. Perez, E.C. Tyler-Kabara, L.G. Cohen, N. Birbaumer,
S.W. Brose, A.B. Schwartz, M.L. Boninger, and D.J. Weber. Neural interface technology
for rehabilitation: Exploiting and promoting neuroplasticity. Phys. Med. Rehabil. Clin.
N. Am., 21:157–178, 2010.
[199] N.S. Ward and L.G. Cohen. Mechanisms underlying recovery of motor function after
stroke. Arch. Neurology, 61:1844–1848, 2004.
[200] N. Weiskopf, K. Mathiak, S.W. Bock, F. Scharnowski, R. Veit, W. Grodd, R. Goebel,
and N. Birbaumer. Principles of a brain-computer interface (BCI) based on real-time
functional magnetic resonance imaging (fMRI). IEEE Trans. Biomed. Eng., 51:966–970,
2004.
[201] I. Wickelgren. Tapping the mind. Science, 299:496–499, 2003.
[202] J. Williamson. Continuous Uncertain Interaction. PhD thesis, Dept. of Computing Science, University of Glasgow, 2006.
[203] J. Williamson, R. Murray-Smith, B. Blankertz, M. Krauledat, and K. R. Müller. Designing for uncertain, asymmetric control: Interaction design for brain-computer interfaces.
Int. J. Hum.-Comput. Stud., 67:827–841, 2009.
32

[204] S. Wills and D. MacKay. DASHER—an efficient writing system for brain-computer
interfaces? IEEE Trans. Neural. Syst. Rehabil. Eng., 14:244–246, 2006.
[205] S.L. Wolf, C.J. Winstein, J.P. Miller, E. Taub, G. Uswatte, D. Morris, C. Giuliani, K.E.
Light, and D. Nichols-Larsen. Effect of constraint-induced movement therapy on upper
extremity function 3 to 9 months after stroke: The EXCITE randomized clinical trial.
JAMA: J. Amer. Med. Ass., 296:2095–2104, 2006.
[206] J.R. Wolpaw, N. Birbaumer, D.J. McFarland, G. Pfurtscheller, and T.M. Vaughan. Braincomputer interfaces for communication and control. Clin. Neurophysiol, 113:767–791,
2002.
[207] J.R. Wolpaw, D.J. McFarland, and T.M. Vaughan. Brain-computer interface research at
the Wadsworth center. IEEE Trans. Neural. Syst. Rehabil. Eng., 8:222–226, 2000.
[208] H.A. Yanco. Wheelesley, a robotic wheelchair system: Indoor navigation and user interface. In V.O. Mittal, H.A. Yanco, J. Aronis, and R. Simspon, editors, Assist. Techn. &
Artif. Intell., Lect. Not. Comp. Sci., pages 256–268. Springer-Verlag, 1998.
[209] S.S. Yoo, T. Fairneny, N.K. Chen, S.E. Choo, L.P. Panych, H. Park, S.Y. Lee, and F.A.
Jolesz. Brain-computer interface using fMRI: Spatial navigation by thoughts. Neuroreport, 15:1591–1595, 2004.
[210] H. Zhang, C. Wang, and C. Cuan. Time-variant spatial filtering for motor imagery classification. In Proc. 29th A. Int. Conf. IEEE Eng. Med. Biol. Soc., 2007.

33

