REPORT DOCUMENTATION PAGE

Form Approved OMB NO. 0704-0188

The public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instructions,
searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments
regarding this burden estimate or any other aspect of this collection of information, including suggesstions for reducing this burden, to Washington
Headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson Davis Highway, Suite 1204, Arlington VA, 22202-4302.
Respondents should be aware that notwithstanding any other provision of law, no person shall be subject to any oenalty for failing to comply with a collection
of information if it does not display a currently valid OMB control number.
PLEASE DO NOT RETURN YOUR FORM TO THE ABOVE ADDRESS.

1. REPORT DATE (DD-MM-YYYY)

2. REPORT TYPE

3. DATES COVERED (From - To)
-

New Reprint
4. TITLE AND SUBTITLE

5a. CONTRACT NUMBER

Real-World Neuroimaging Technologies

W911NF-09-1-0510
5b. GRANT NUMBER
5c. PROGRAM ELEMENT NUMBER
611102
5d. PROJECT NUMBER

6. AUTHORS
Shao-Wei Lu, W. David Hairston, Shih-Yu Li, Kaleb Mcdowell, ChinTeng Lin, Kelvin S. Oie, Tzyy-Ping Jung, Stephen Gordon, Keith W.
Whitaker

5e. TASK NUMBER
5f. WORK UNIT NUMBER

7. PERFORMING ORGANIZATION NAMES AND ADDRESSES
University of California - San Diego
9500 Gilman Drive
MC 0934
La Jolla, CA

8. PERFORMING ORGANIZATION REPORT
NUMBER

92093 -0934
9. SPONSORING/MONITORING AGENCY NAME(S) AND ADDRESS
(ES)

10. SPONSOR/MONITOR'S ACRONYM(S)
ARO
11. SPONSOR/MONITOR'S REPORT
NUMBER(S)

U.S. Army Research Office
P.O. Box 12211
Research Triangle Park, NC 27709-2211

56490-CS.23

12. DISTRIBUTION AVAILIBILITY STATEMENT
Approved for public release; distribution is unlimited.
13. SUPPLEMENTARY NOTES
The views, opinions and/or findings contained in this report are those of the author(s) and should not contrued as an official Department
of the Army position, policy or decision, unless so designated by other documentation.
14. ABSTRACT

Decades of heavy investment in laboratory-based brain imaging and neuroscience have led to foundational insights
into how humans sense, perceive, and interact with the external world. However, it is argued that fundamental
differences between laboratory-based and naturalistic human behavior may exist. Thus, it remains unclear how well
the current knowledge of human brain function translates into the highly dynamic real world. While some
demonstrated successes in real-world neurotechnologies are observed, particularly in the area of brain-computer
interaction technologies, innovations and developments to date are limited to a small science and technology
15. SUBJECT TERMS
Behavioral science biomarkers, body sensor networks, brain computer interactionbrain, computer interfaces, data acquisition,
electroencephalography monitoring, translational research, wearable sensors

16. SECURITY CLASSIFICATION OF:
a. REPORT b. ABSTRACT c. THIS PAGE
UU
UU
UU

17. LIMITATION OF
ABSTRACT
UU

15. NUMBER 19a. NAME OF RESPONSIBLE PERSON
OF PAGES
Tzyy-Ping Jung
19b. TELEPHONE NUMBER

858-366-8914
Standard Form 298 (Rev 8/98)
Prescribed by ANSI Std. Z39.18

Report Title
Real-World Neuroimaging Technologies
ABSTRACT
Decades of heavy investment in laboratory-based brain imaging and neuroscience have led to foundational insights
into how humans sense, perceive, and interact with the external world. However, it is argued that fundamental
differences between laboratory-based and naturalistic human behavior may exist. Thus, it remains unclear how well
the current knowledge of human brain function translates into the highly dynamic real world. While some
demonstrated successes in real-world neurotechnologies are observed, particularly in the area of brain-computer
interaction technologies, innovations and developments to date are limited to a small science and technology
community. We posit that advancements in realworld neuroimaging tools for use by a broad-based workforce will
dramatically enhance neurotechnology applications that have the potential to radically alter human-system
interactions across all aspects of everyday life. We discuss the efforts of a joint government-academic-industry team
to take an integrative, interdisciplinary, and multi-aspect approach to translate current technologies into devices that
are truly fieldable across a range of environments. Results from initial work, described here, show promise for
dramatic advances in the field that will rapidly enhance our ability to assess brain activity in real-world scenarios.

REPORT DOCUMENTATION PAGE (SF298)
(Continuation Sheet)
Continuation for Block 13

ARO Report Number 56490.23-CS
Real-World Neuroimaging Technologies

...

Block 13: Supplementary Note
© 2013 . Published in IEEE Access, Vol. Ed. 0 1, (0) (2013), (, (0). DoD Components reserve a royalty-free, nonexclusive and
irrevocable right to reproduce, publish, or otherwise use the work for Federal purposes, and to authroize others to do so
(DODGARS §32.36). The views, opinions and/or findings contained in this report are those of the author(s) and should not be
construed as an official Department of the Army position, policy or decision, unless so designated by other documentation.

Approved for public release; distribution is unlimited.

Received February 1, 2013, accepted April 2, 2013, published May 10, 2013.
Digital Object Identifier 10.1109/ACCESS.2013.2260791

Real-World Neuroimaging Technologies
KALEB MCDOWELL (Senior Member, IEEE)1 , CHIN-TENG LIN (Fellow, IEEE)2 , KELVIN S. OIE1 ,
TZYY-PING JUNG (Senior Member, IEEE)3 , STEPHEN GORDON (Member, IEEE)4 ,
KEITH W. WHITAKER1 , SHIH-YU LI2 , SHAO-WEI LU2 , and W. DAVID HAIRSTON1
1 Translational

Neuroscience Branch, U.S. Army Research Laboratory, Aberdeen Proving Ground, MD 21005, USA
of Electrical Engineering and the Brain Research Center, National Chiao Tung University, Hsinchu 30010, Taiwan
3 Swartz Center for Computational Neuroscience, Institute for Neural Computation, University of California at San Diego, La Jolla, CA 92093, USA
4 DCS Corporation, Alexandria, VA 22310, USA
2 Department

Corresponding author: K. McDowell (kgm8@cornell.edu)
This work was supported by the U.S. Army Research Laboratory and, in part, under Cooperative Agreement W911NF-10-2-0022.

ABSTRACT Decades of heavy investment in laboratory-based brain imaging and neuroscience have led
to foundational insights into how humans sense, perceive, and interact with the external world. However,
it is argued that fundamental differences between laboratory-based and naturalistic human behavior may
exist. Thus, it remains unclear how well the current knowledge of human brain function translates into
the highly dynamic real world. While some demonstrated successes in real-world neurotechnologies are
observed, particularly in the area of brain-computer interaction technologies, innovations and developments
to date are limited to a small science and technology community. We posit that advancements in realworld neuroimaging tools for use by a broad-based workforce will dramatically enhance neurotechnology
applications that have the potential to radically alter human–system interactions across all aspects of
everyday life. We discuss the efforts of a joint government-academic-industry team to take an integrative,
interdisciplinary, and multi-aspect approach to translate current technologies into devices that are truly
fieldable across a range of environments. Results from initial work, described here, show promise for
dramatic advances in the field that will rapidly enhance our ability to assess brain activity in real-world
scenarios.
INDEX TERMS Behavioral science, biomarkers, body sensor networks, brain computer interfaces, brain
computer interaction, data acquisition, electroencephalography, monitoring, translational research, wearable
sensors.

I. INTRODUCTION

Understanding human behavior and, at its core, the
human brain has long been considered critical to creating
revolutionary technologies. Over the past three decades, significant developments in novel laboratory-based experimental neurotechnologies have led to meaningful and nuanced
insights into the connection between human experience and
nervous system structure and function; a connection that
is considered to be the foundation for understanding how
we sense, perceive, and interact with the external world
[1], [2]. However, both theoretical and experimental evidence suggests that there may be fundamental differences
in how the human brain functions to control behavior when
it is situated in ecologically-valid environments (i.e., situated cognition) versus that observed in highly-controlled
laboratory environments. This generalizability issue defines
the need to expand the capability of neuroimaging
VOLUME 1, 2013

2169-3536/$31.00

technologies beyond the laboratory and into real-world environments where natural human, task, and environmental
interactions can be studied. Further, such an extension of
neurotechnologies is expected to have a dramatic impact
on the rise of novel brain-computer interaction technologies
(BCITs; see for discussion: [3], [4]). BCITs are potentially
revolutionary technologies that are moving human-systems
communication beyond the mere transmission of information
between man and machine and toward the capability for
mutually-derived data analysis, interpretation, and prediction.
The latter is a core capability that has the potential to radically
alter human–system interactions across all aspects of everyday life.
This article discusses the current state of neuroimaging
technologies and the lack of any laboratory-grade system
specifically designed for real-world neuroimaging. In large
part, real-world neurotechnology development is limited by
2013 IEEE

131

K. McDowell et al.: Real-World Neuroimaging Technologies

the fact that only a relatively small circle of scientists and
technology developers are focused on these issues and, related
to that, the relative inaccessibility of current neuroimaging tools to the broad-based workforce. Here we discuss
efforts undertaken by the Army Research Laboratory’s (ARL)
Translational Neuroscience Branch in forming a governmentacademic-industry team focused on developing real-world
neuroimaging tools that support broad-based scientific and
applied pursuits. We highlight the specific translational goals
of this effort and numerous advancements of this unique,
multidisciplinary team.
II. BACKGROUND

‘‘Brain imaging . . . will become even more powerful when
high-resolution neural data are gathered from participants
moving freely and interacting in natural ways.’’ - Executive
Office of the President, National Science and
Technology Council [1]
Neuroimaging techniques (e.g., electroencephalography
[EEG], functional magnetic resonance imaging, functional
near-infrared spectroscopy, magnetoencephalography, and
positron emission tomography) have unveiled deep insights
into brain structures and functions and how mental representations and behavior are generated. However, many of the
recent insights into the human brain have been gained from
research conducted only with highly-controlled laboratory
tasks and environments that are not representative of the
real world. Although this approach has advanced our basic
understanding of the brain, the extent to which controlled
laboratory-based research generalizes to brain function under
the complex and dynamic environments of the real world
is not well understood. In fact, it has been argued that the
consequences of failing to extend neuroimaging approaches
to more realistic environments may be far worse than failing to generalize to natural environments; they may generate fundamental misunderstandings of real-world brain function [5]. For example, it has been argued both experimentally
and theoretically that the complexity of the human brain’s
estimated quadrillion neural connections allows (or even
requires) not only different individuals to process information differently, but also the same individuals may engage
different brain regions to cognitively process similar information, particularly in response to contextual changes [2],
[6]. These concepts suggest that there may be fundamental
differences in situated cognition relative to that observed in
highly controlled laboratory environments, supporting the
need for more ecological approaches [7] focusing on human,
task, and environmental interactions [8]. Our primary motivation for attempting neuroimaging in real-world environments
is based on the potential impact that answering these open
fundamental scientific questions would have on translating
basic neuroscience to technology development.
Initial attempts at real-world neuroimaging were focused
on controlling and replicating aspects of naturally occurring human behaviors within the laboratory [9]–[14].
132

More recently, attempts have been made to extend neuroimaging to more complex environments previously thought to
be unapproachable even with state-of-the-art methodologies
[15]–[19]. These efforts have generally adapted laboratorybased neuroimaging technologies to suit specific and unique
measurement requirements. While they have made significant steps forward, the overall field is still quite limited;
researchers are forced to balance between studying wellcontrolled, potentially unnatural, behavior and performing
studies that generalize to ecologically relevant situations. In
large part, the research is limited by the technological gap
between the neuroimaging tools that currently exist and the
tools needed to appropriately conduct neuroimaging research
in real-world environments. The development of such tools
will require more than a mere extension of current laboratorybased technologies due to the complex dynamics and uncertainties inherent to real-world environments combined with
an overwhelming number of influences that limit signalto-noise ratio [15], [19]–[21]. Recently, significant progress
has been made in novel technologies that have the potential
to radically advance real-world neuroimaging (for reviews,
see [4], [22]). While these advancements are enabling
preliminary system designs, true real-world neuroimaging
will require further development in four critical technology
areas: Neuroimaging Hardware including multi-aspect sensors arrays, power, and on-board processing capabilities that
meet the wearability and usability requirements for real-world
research and application; Algorithms addressing issues ranging from signal-to-noise ratios to multi-aspect sensor integration enabling the joint interpretation of neural signals, human
behavior, and environmental context; Interfaces that both
facilitate highly multidisciplinary research amongst scientists
from varying fields of study and enable effective data collection by naïve participants; and Experimentation, Testing, and
Validation including novel paradigms for neuroimaging under
uncertainty and technologies for validating new hardware and
algorithms.
III. TRANSLATIONAL RESEARCH TOOLS

‘‘Agencies should continue to develop new tools and
techniques for research and ensure the broadest
dissemination possible for those tools.’’ - Executive Office of
the President, National Science and Technology Council [1]
ARL’s Translational Neuroscience Branch has formed a
government-academic-industry team to develop a wide variety of novel tools to enable real-world neuroimaging systems
across a wide variety of operationally-relevant environments
and in support of neurotechnologies, such as BCITs. Such
tools will directly support enhancing human-system integration with the potential for broad-based impacts across
almost all aspects of everyday life. However, traditional neuroscience approaches to tool development have the potential
for creating the same translational risks that have hindered the
transition of neuroscience research in the past. For example,
the broad variability in technical system requirements for
VOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

different applications (e.g., temporal and spatial resolution;
amounts, types, and sources of data; acceptable signal-tonoise ratios) combined with the sheer complexity of the nervous system and the uncertainty of the signals being detected
can lead to an abundance of research results and developed
tools that, while important in and of themselves, ultimately
cannot be effectively combined into singular functional systems. Furthermore, the development and application of neurotechnologies remains limited to a relatively small circle of
scientists and technology developers and has not achieved
a broader focus within the greater science and technology
(S&T) development community. Complicating this, the large
majority of existing tools are expensive and/or require scientists with an extensive knowledge base to use them appropriately. As long as the tools and knowledge needed to develop
neurotechnologies remains inaccessible to the broad-based
workforce within the S&T community, innovation and development will remain limited, especially with regards to BCITs.
To mitigate these issues, it is critical to take a multidisciplinary approach in which scientists and engineers from
a wide-range of backgrounds work together to push neuroimaging systems into the real world in both scientific
and applied pursuits. We focus on coupling the creation of
functional systems targeted at narrow specific aims along
with the development of tools targeted at enabling a multidisciplinary team to bridge the scientific and technological
gaps between neuroscientists, signal processing experts, and
technology innovators, among others [23]. We posit that the
results from these kinds of functional systems, even when
narrowly focused on specific questions and applications, have
the potential to dramatically change how we conceive of
human brain functioning and its interactions with real-world
technologies, providing insights that will directly influence
the types and functionality of the real-world neuroimaging
tools being developed.
With this in mind, ARL has developed two translational
research objectives, described below, that target developing capabilities to answer fundamental scientific questions
in real-world environments and applying that knowledge to
proof-of-principle neurotechnologies. Both objectives will
require wireless, high-resolution, ruggedized, wearable hardware and software tools that disentangle and differentiate
brain signal, human behavior, environmental events, and artifacts. However, the relative requirements for each objective are very different. Pursuing these objectives is a team
comprised of members from different collaborative programs
(e.g., Cognition and Neuroergonomics Collaborative Technology Alliance (CaN CTA; [24]), the Institute for Collaborative Biotechnologies (ICB), Small Business Innovation
Research Awards (SBIR), and internal research programs,
among others).
A. OBJECTIVE 1: LABORATORY GRADE REAL-WORLD
NEUROIMAGING

Our first objective is the creation of a toolkit that can support
basic research on fundamental questions underlying neural
VOLUME 1, 2013

MINDO64 (MINDO)
Electroencephalography

BioHarness 3
(Zephyr)

Electrocardiogram (ECG), Respiration rate,
Posture, Movement

Q Sensor 2 (Affectiva)
Electrodermal Activity (EDA),
Movement, Skin Temperature
TM

Custom Android Software

FIGURE 1. Prototype Real-World Neuroimaging System. Four components
are illustrated, an Android device for data collection and integration, a
laboratory grade, dry electrode, wirelesss, high resolution EEG system, a
Bioharness 3, and an Affectiva Qsensor. Android screenshots depict some
examples of activity logging components, such as a start/stop logger
(left), two self-assessment surveys (middle), and a visuomotor continuous
tracking task (right).

functions within real-world environments (e.g., see Figure 1).
In the near-term, the development of this hardware and software toolkit targets specific questions regarding how the
interrelated factors of stress, fatigue, and circadian rhythms
impact persons within real-world office environments. As
compared to state-of-the-art laboratory neuroimaging tools,
the characteristics of the target system include: similar temporal and spatial resolution neural data; the capacity for
extensive multi-aspect sensor integration, including physiological, behavioral, and environmental sensing to help build
a rich characterization of context; extended duration of data
acquisition system wearability; greater ruggedization; limited
set-up time requirements; usability by both subject matter
experts and trained participants; functionality in office type
environments; efficient data storage, transfer, and handling;
and complex, often computationally-intensive offline data
133

K. McDowell et al.: Real-World Neuroimaging Technologies

analysis by scientists from a variety of neuroscience and
engineering backgrounds.
B. OBJECTIVE 2: REAL-TIME NEUROIMAGING FOR BCIT

The second objective is to develop a hardware and software toolkit that can support the development, assessment,
and application of BCITs in real-world settings. Near-term
objectives focus on designing a system specifically in support
of the development and assessment of fatigue-based performance decrements and target-identification brain-computer
interaction technologies in real-time. Compared to state-ofthe-art laboratory neuroimaging tools, in the near-term the
development of this hardware and software toolkit will target:
more narrowly defined neural signals to support application
functionality; the capability for multi-aspect sensor integration to help build context; greatly extended duration of data
acquisition system wearability to meet expected application
use; full ruggedization; limited to no set-up time requirements; usability by technicians with limited experience and
naïve participants; functionality across the wide variety of
environments in which the applications are expected to be
deployed; and capability for real-time analysis with efficient
storage, transfer, and handling of raw data to enable further
application R&D.
IV. REAL-WORLD NEUROIMAGING SYSTEMS

The conceptual and theoretical foundations for the realworld neuroimaging approach we are advocating here can be
found in scientific disciplines ranging from artificial intelligence and robotics [25] to embedded and embodied or
situated cognition [26] to ecological psychology [27]–[29].
The growing importance of these concepts is reflected in an
increasing appreciation that human mental processes are intimately bound with our interactions with the world [30], [31].
Considering this perspective, ARL and its partners advocate an approach to real-world neuroimaging that leverages technological advancements across a broad array of
sensors that sample not only the human brain, but human
physiology and behavior, in addition to task and environmental conditions [20], [32], [33]. A fundamental element
of this multi-aspect approach to neuroimaging is to place
information about brain function into the context of when
it occurs. In typical laboratory settings, this is accomplished
through control of the participant’s actions and environment;
however, such control is infeasible in real-world environments and situations.
Over the past five years, there have been tremendous
advancements in sensor and communication technologies that
are enabling our vision of real-world neuroimaging. Perhaps
the most significant, direct advancements have occurred in
the area of dry and wireless EEG systems. Of the array
of existing classes of neuroimaging technologies, EEG has
shown the most promise as a near-term solution in terms of
quality, mobility, and wearability within real-world environments and, as such, has seen the most commercial development in this domain. A second area of advancement has
134

been in EEG analysis software that is much more broadly
available, ranging from commercial ventures (e.g., BESA,
MidWare Technologies, Neuroscan) to freely available toolboxes available from academic research groups (e.g. FieldTrip, BrainStorm, EEGLab, ERPLab), to academic software
which contains real-time analysis and classification capabilities (e.g., BCILAB toolbox developed by the University of
California, San Diego (UCSD); [34], [35] or BCI2000 from
the Wadsworth Center of the New York State Department of
Health; [36]), as well as sophisticated approaches to extracting neural signals in complex and noisy environments (e.g.,
see DETECT and EEGVIS toolboxes developed by the University of Texas at San Antonio (UTSA) in collaboration with
ARL; [37]–[39]). These advancements in neuroimaging technologies provide a strong basis for leveraging the broad ranging sensor advancements that have occurred in other domains
to create multi-aspect systems that meet our team’s objectives.
A. LABORATORY GRADE REAL-WORLD NEUROIMAGING

Laboratory-grade systems designed specifically for realworld neuroimaging do not exist to our knowledge.
Current laboratory-grade hardware solutions are bulky and
not designed for comfort or ease-of-use. For example, wired
systems with as many as 256 sensor leads are awkward to
wear, take long set-up times of up to an hour, and can cause
participant discomfort when worn over extended durations
(Figure 2). The typical wet electrodes found in laboratory
equipment can begin to dry out within 30-minutes to 2 hours,
which directly influences signal quality [40]. High-bandwidth
data transmission requirements typically force participants to
be tethered to computing systems or to carry relatively heavy
hardware, such as batteries, amplifiers, and laptop computers
[16]. These hardware constraints limit the naturalistic behaviors that can be observed, as well as the types of contexts that
may be investigated.
Despite these limitations, there have been several recent
efforts to understanding brain function in real-world conditions using actual laboratory systems. One approach has been
to take laboratory-grade EEG systems into relatively wellcontrolled, real-world task environments, such as on-road
vehicle driving [41], learning marksmanship [21], [42] or
even flying a plane [43]. These types of research efforts allow
the study of the rich task dynamics and behavioral contexts of
real-world conditions, while taking advantage of behaviors
that do not generally require a lot of bodily movements that
would induce excessive motion and/or muscle-related signal
artifacts that negatively affect the quality of the recorded
raw EEG signals. However, the constraints imposed by the
hardware necessarily limit this approach to a very narrow
scope of tasks and experimental durations. Further, even in
these real-world environments, participants are so constrained
by the systems that it is unclear how effective the results
will be in generalizing to other types of naturalistic human
behavior.
An alternative approach has been to take laboratory-grade
measurement and tasks into environments that reflect releVOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

and depth of real-world neuroimaging, they demonstrate the
plausibility of extracting traditional neural signatures in the
face of significant artifact.
Starting from these initial studies, our group has continued to build towards more fully realized real-world neuroimaging capabilities. First, by extending our efforts into
more complex task environments through the use of complex
and behaviorally-sophisticated virtual reality simulations
(cf., [45]–[47]), we have shown that it is possible to successfully extend current neuroscience research paradigms to
better capture and reflect the subtle complexities of realworld, embedded, interaction. Second, by developing more
mobile and user-friendly measurement systems we hope to
both minimize the burden on the experimenter and to alleviate
intrusiveness on the participant, thereby encouraging more
naturalistic behavior.
1) OVERVIEW: STRESS AND FATIGUE NEUROIMAGING
SYSTEM V1.0

FIGURE 2. State-of-the Art Laboratory Grade EEG System made ‘‘Mobile.’’
Participant wears a high-density wet-electrode cap which is wired to a
laptop and amplifiers in a backpack. This system takes approximately 1
hour to set-up, and can become uncomfortable in minutes.

vant aspects of real-world settings. For example, ARL studied standard auditory event-related potentials (ERP) while
participants stood, walked, or ran on a treadmill or sat
on a six-degree-of-freedom ride motion simulator (RMS)
during increasingly dynamic ride-motion conditions [19].
The motion conditions of this study extended the behavioral environments where ERP responses were previously
observed far beyond typical laboratory conditions, while
still structuring the environment in ways consistent with
controlled-laboratory research: the treadmill allowed the control of walking or running speed; the RMS ensured that
all participants experienced the exact same ride motions.
Except under the most extreme motion conditions, the results
demonstrated that even when large body movements induced
significant motion- and muscle-related signal artifacts, wellknown temporal (e.g., latencies of N100 and P300 peaks) and
spatial (e.g., increased P300 amplitudes from anterior to posterior electrode sites) patterns of ERP responses seen in the
laboratory can be recovered. In a similar fashion, team partners at the University of Michigan (UM) and UCSD also
demonstrated that visual ERPs could similarly be recovered during treadmill walking using Independent Component
Analysis (ICA) techniques [15]. UM further collaborated
with ARL to show that visual event-related activity could
be observed using artifact-resistant functional connectivity
metrics [44]. Though these experiments lack the richness
VOLUME 1, 2013

Currently, ARL and its partners, National Chiao Tung
University (NCTU) in Taiwan and DCS Corporation (DCS)
are collaborating to implement a first-of-its-kind, wearable,
high-density, real-world neuroimaging system for studying
stress and fatigue in the workplace [48]. This laboratorygrade Stress and Fatigue Neuroimaging (SFN) System V1.0
has been specifically designed to overcome several of the
limiting issues for real-world neuroimaging. The prototype
is comprised of an Android device, a Samsung Galaxy
S3 in the current implementation, which monitors, records,
and synchronizes data streamed from three physiological monitoring devices: a high-density MINDO EEG system (Hsinchu, Taiwan), a multifunction Zephyr Bioharness
3 lightweight chest strap (Annapolis, MD, USA), and a
multifunction Affectiva QSensor wrist-watch style device
(Waltham, MA, USA); as well as obtaining user inputs
(Figure 1). All three of these physiological systems use drytype electrodes for faster set-up and longer-term wearability. The complete system weighs approximately 406 grams
(0.9 pounds; MINDO-64: 200g, Bioharness 3: 50g, QSensor:
22.7g, Samsung Galaxy S3: 133g). The numerous components of the prototype system have been integrated and the
system is undergoing initial phases of use-case testing.
As this system is designed for scientific pursuits, the
primary analysis software will be offline, where the Android
based physiological data and behavioral data can be combined with contextual information from additional sources,
such as the user’s calendar, user annotations, or questionnaire
responses (see below for more detailed description). State-ofthe-art offline-analyses programs, such as EEGLAB, will be
used for data processing.
2) LONG-TERM, WEARABLE NEURAL DATA ACQUISITION
SYSTEM

The centerpiece of SFN System V1.0 is the NCTU-developed
64-channel wireless EEG system (MINDO-64), which is
designed to address issues of: high-resolution laboratory135

K. McDowell et al.: Real-World Neuroimaging Technologies

grade data acquisition, long-term comfortable wear, quick
user set-up, and high portability. The use of high-bandwidth
wireless data transmission overcomes the constraints of physically tethering participants to computing systems or having them carry the equipment with them during the experiment. The MINDO-64 system uses both Bluetooth and WiFi
modules to transmit EEG signal during recording, offering a
maximum 512Hz sampling rate with 24-bit resolution and is
the first wireless EEG system integrated into a form factor
with a flexible printed circuit board inside, a novel head
circumference adaptable mechanical design for improved stability, and active dry sensors that amplify signals at a very
early stage to improve signal-to-noise ratios and avoid the
need for skin preparation and gel application. The system also
stores raw data on-board for use in off-line processing to help
mitigate critical issues surrounding wireless transmission.
Through the integration of active sensor and power control on
the main circuit, the system enables long-term wear of up to
10 consecutive hours of operation time. The system’s wireless
technologies, light weight (200g), and dry sensor designs also
support comfort, fast set-up, and portability.
3) UNDERSTANDING CONTEXT

One of the most critical assumptions in our vision of
real-world neuroimaging is that developing a rich multidimensional characterization of context will be critical to the
accurate and meaningful interpretation of measured neural
activity. As outlined above, most previous attempts at neuroimaging, both traditional and mobile, have relied on controlling context through environmental, behavioral, and task
constraints, which can sacrifice naturalistic human behavior. By contrast, we posit that meaningful interpretation
of observed real-world neural signals will result from the
characterization and understanding of statistical relationships
between broadly defined contextual events (to include behavioral, physiological, task, and environmental events across
multiple timescales) and the observed neural activity that
supports our behavior.
Working in collaboration, ARL and DCS developed a
range of applications on the Android platform to enable an
observational, multi-aspect measurement approach targeted
at building a context to interpret the neural activity related to
stress and fatigue. In building the context of the internal state
of the user, the system integrates the Bioharness for ECG
and respiration rate; the QSensor to provide skin conductance (a form of electrodermal activity) and skin temperature
data; and subjective reports related to stress and fatigue. To
build a context of the user’s activities, the system integrates
3-axis accelerometers from both the Bioharness and
QSensor with incident reports (e.g., voluntary annotation of
a stressful event), start and end times of defined user activities (eating, drinking, meetings, exercise, etc.) questionnaire
responses, and other user annotations.
Off-line software will be used to further integrate the
Android-based data with information from the user’s calendar
and other information gathered by the experimenters. EEG
136

analysis software has also been used to isolate and interpret EEG activity that is traditionally discarded as artifact
(e.g., muscle activity; see description of artifact classifiers
by Lawhern and colleagues in Section IV). Our multi-aspect
approach advocates integrating these different sources of
information, such as artifact, to complete a contextual picture
that is sufficient to frame the moment-to-moment dynamics
of the user’s brain activity.
4) OTHER IMPORTANT ISSUES

Several other features have been designed into SFN System
V1.0 to address issues critical to real-world neuroimaging.
For example, the wearer of a real-world EEG system is going
to have more responsibility for the system and for the data
collection than in typical experiments where the experimenter
is present. Towards this end, novel user interfaces have and
continue to be designed to enable trained users to set-up the
system and troubleshoot bad sensors and periods of ineffective data collection. A second critical issue is the need to
reference observational findings to the extant literature on
stress and fatigue. To address this issue, our team developed
Android-based applications that represent laboratory tasks
including a continuous tracking task [49] and can be triggered
through a master scheduler. A third issue is the observer
effect; the concept that the act of measurement inherently
changes the phenomena being measured. While no system
can avoid the observer effect, the new technology solutions
described here help to minimize some of the most obvious
and intrusive effects that have undoubtedly affected the measurement of human behavior in previous research. Finally,
SFN System V1.0 has been designed to be highly flexible,
enabling the researcher to choose nearly any combination of
components and applications, and thus weigh the costs and
benefits of the system to measure true naturalistic behavior in
addressing their research questions.
B. REAL-TIME NEUROIMAGING FOR BCIT

Many of the critical issues for real-world neuroimaging are
discussed above and are being addressed in the design of
SFN System V1.0. However, there are critical differences in
designing such a system for applied as opposed to scientific
pursuits. Recently, there have been tremendous advances in
commercial EEG technologies, and many systems start to
address the issues specific to applied systems. In this section
we discuss some of those advances in light of four critical
issues for applied systems:
1) BUILT FOR A NARROW PURPOSE

Scientific systems are generally intended for broad-ranging
research, where many of the specifics of the signals elicited
through their use are unknown to the system designers
a priori. As a result, systems are generally designed to maximize data availability for the user. Neuroimaging for BCIT
purposes, however, is almost exclusively framed around a
previously established target signal, or at least a specific realm
of signal types. As a result, BCIT systems can be designed
VOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

efficiently to detect the target signal, at the cost of flexibility
or maximal data availability. For example, systems could be
designed to use small numbers of electrodes placed in strategic locations, as opposed to the high-density arrays found
in laboratory-grade systems. Likewise, designers of specific
BCIT systems will have to weigh the costs and benefits of
addressing many constraints such as: a) the additional complexity required by high-precision timing accuracy or timing
integration with several other devices, b) the ability to flexibly
change the devices to which they are connected, c) the need
for additional sensory modalities to supplement EEG, and
d) the cost and effectiveness of manufacturing processes.

Mindo
FIGURE 3. An early prototype system for BCITs. The NCTU-developed
MINDO-4 system for potential BCITs that detect and mitigate
fatigue-related performance decrements during driving. System uses soft
pads (U.S. penny and pen shown for scale) that snap into a headband,
and streams data via Bluetooth for easy system integration.

How to optimally create tools that both enable the development of such narrowly focused systems and assist in
such cost/benefit analyses remains an open question. Our
team’s current research efforts focus on the development of
cost-effective, dedicated, integrated components for sensing
specific signals and developing prototypes suitable for assessing fatigue-based performance decrements, while also maintaining enough flexibility to assure easy, rapid integration
between the neuroimaging component and potential BCIT
systems. For example, one of ARL’s first partnerships in
neurotechnologies with NCTU resulted in the MINDO-4
(see Figure 3; [50], [51]).
2) REAL-TIME PROCESSING

Perhaps the most critical constraint on BCITs is the requirement for real-time or near-real time processing. Despite the
many approaches and advances in EEG analysis, real-time
signal processing for online applications is one area that still
receives relatively little attention. Currently, the most significant work in this area is coming from the groups developing
actual BCITs [52]. Our team’s efforts, described primarily in
section V, attempt to integrate and extend these efforts into a
systems-level view.
VOLUME 1, 2013

3) USABLE BY ANYONE

Future BCITs are envisioned as a core technology that can
permeate all aspects of everyday life [3]. As such, it will be
critical that the systems are usable by anyone. Consequently,
the systems must be simple to setup and troubleshoot and they
likely will have to be relatively transparent or even invisible
to the operator for compliance purposes. For example, games
such as the Star Wars Force Trainer (Uncle Milton) and the
Mindflex (Mattel) marked incredible advances in making
BCITs usable; however, they are still far from being a reliable
neuroimaging technology that people will wear regularly and
for long durations in everyday environments.
One of the critical elements is the lack of systems
and tools to enable non-specialists to develop and assess
BCITs [23]. An important step towards this goal was
the release of the commercial product, the Emotiv EPOC
(San Francisco, CA, USA). This system is relatively easy
to set-up and can allow non-specialists to use classifiers to
train the system to control keyboard keys among other things.
However, the ease of use of the system without sufficient
software for basic developer education and training can lead
to misinterpretation of system outputs and is, potentially, a
significant limiter on BCIT development [23]; current systems allow developers to make basic mistakes that will ultimately inhibit the BCIT’s applicability. Team partners at
USCD have also released an open-source BCIT toolkit for
MATLAB that aids in bridging the gaps between specialists
from different backgrounds (e.g., neuroscientists, engineers,
psychologists), BCILAB [53]. Further significant advancements are necessary to fully bridge the gap to non-specialists.

4) SAFE, ROBUST, AND COST EFFECTIVE

The real-world neuroimaging systems developed for BCITs
will need to be cost-effective, as well as safe and robust
across a wide variety of environments, including some that
are highly dynamic and potentially hazardous. While these
are issues for the scientific systems described above, as well,
there are several factors that emphasize their importance for
applied systems: Safety is a critical issue for any system with
sensors, electronics, and other components directly above the
scalp. Health and cleanliness issues must be addressed by
all system designs. In the scientific domain, constraints are
placed on experimentation to limit the risk to study participants, such as those emplaced by Institutional Review Boards.
However, as applied systems become more functional and
available, they are likely to be found in situations with the
potential for trauma-inducing head impact. As discussed in
section V, ARL and NCTU are investigating solutions to
enable safe system designs for all environments.
Systems will also have to be robust and cost-effective.
Robust systems will need to operate consistently and reliably within an environment that could be physically damaging to a sensitive unit, as well as being able to properly
deal with the noise and artifacts that will occur within the
BCIT application. For example, a system designed for use
137

K. McDowell et al.: Real-World Neuroimaging Technologies

A. NEUROIMAGING HARDWARE

Recent technological advances have greatly increased our
capabilities for data acquisition and measurement of all
manner of variables outside of the laboratory. For neuroimaging, a number of commercially-available devices are
starting to make fieldable recording of EEG data more reality
than science fiction (e.g. ABM X-series (Carlsbad, CA,
USA), Emotiv Epoc, Quasar DSI (San Diego, CA, USA)).
However, there remain several interrelated technical hurdles
that still must be overcome for real-world neuroimaging
systems to truly provide either laboratory-grade real-world
measurement capabilities or commercially-viable end-user
applications.
In the neurotechnologies field, one of the most active,
current research and development areas to meet either of
these objectives is in dry sensor designs that can provide
comparable signal quality as standard passive or active sensor
designs that require conductive gels and extended application
time [54], [55]. Generally, conductive gels serve two primary
purposes. The first is to increase the conductive nature of the
skin, by creating a moistened conductive bridge with the electrode tip, lowering the overall impedance between the internal biological source and the recording system components.
138

0
-200
-400
-1

0

1

2

3

4

5

Time (sec)

6

7

8

9

1

20

30

40

50

40

50

Frequency (Hz)
Power (dB)

200

1

40
20
0
-20
-40
0

10

1

120
100
80
60
40
20
0
0

10

0
-200

0

1

2

3

4

5

Time (sec)

6

7

8

9

400
200
0
-200
-400
-1

10

100
80
60

400

-400
-1

Dry
Wet

Power (dB)

200

20

30

Frequency (Hz)

Power (dB)

Voltage (uV)
Voltage (uV)

Normal

100
80
60
40
20
0
-20
-40
0

400

Voltage (uV)

Jaw
Clench Eye Blink

V. ENABLING TECHNOLOGIES FOR FUTURE SYSTEMS

As discussed above, major technological, scientific, and conceptual strides have been made towards developing realworld neuroimaging as a viable and legitimate approach to
research and technology application development. Still, the
creation of integrated, fieldable, wearable, multi-aspect measurement systems and the attendant capabilities to enable the
efficient handling, analysis, and modeling of real-world neuroimaging data, and the use of such data in systems designs,
will require further advancements across a wide range of
technology domains to enable a fully realized capability. This
section delineates major challenges and targeted enabling
technology capabilities for each of the four critical technical
areas identified previously: Neuroimaging Hardware, Algorithms, Interfaces, and Experimentation, and discusses recent
research and development efforts within our programs that
have started to address these challenges.

This problem, however, has generally been alleviated by the
development of ultra-high impedance amplifiers capable of
matching the conductance of dry skin [56], which can be in
excess of megaohms. Second, it provides a physical bridge to
easily penetrate hair and dead skin, ensuring a strong, reliable
connection.
One approach to dry sensor designs is to use a soft, pliable
pad which conforms to the contours of the skin, providing a
large surface area over which to collect the electrical potential and ensuring a reliable connection. Partners at NCTU
have shown that using a conductive fabric wrapped around a
pliable foam polymer (see Figure 3 for an example) allows
a consistent contact, even under motion. This design also
alleviates concerns about long-term comfort, due to the soft
nature of the material, and poses minimal injury risk (see
below; [40]). As a validation of this approach, an example
comparison between a traditional gelled wet electrode and

0

1

2

3

4

5

Time (sec)

6

7

8

9

20

30

Frequency (Hz)

40

50

Impedance Changes During Extended Wear
Impedance (Kohm)

within an off-road vehicle must be capable of functioning for
extremely long time periods when subject to vibration (e.g.,
see [19]), as well as electrical noise from the engine and other
sources. Further, the systems must be available at a cost that is
affordable to a wide range of potential users and BCIT developers. Alternative approaches to cost-effective robust EEG
measurement range from systems with very low-cost disposable sensors to higher-quality, highly-reconfigurable systems
with lower sensor density. ARL is currently working with
the Defense Advanced Research Projects Agency (DARPA)
on its efforts to advance portable, inexpensive, easy-to-use
hardware solutions to EEG (e.g., see DARPA proposed SBIR
SB131-002). In section V below, we highlight several specific
algorithmic approaches enabling robust system design.

20

10

0
0

1

2

3

4

5

Measurement Times (Hours)

FIGURE 4. Data quality for dry EEG systems are comparable to that of
conventional ‘‘wet’’ gel-based approaches for both brain and muscle
activity (top panels). Further, dry electrodes have much more stable
impedance over time as compared to gel electrodes, which tend to dry
out, increasing the contact impedance over time (bottom, adapted from
[48]).

a dry electrode pad is shown in Figure 4. The two different
kinds of electrodes were placed in contact with a subject’s
forehead, and the contact impedance was measured and monitored over an extended period of time. Aside from having
highly correlated signals, as shown both in time and frequency plots (Figure 4, top panels), the results showed that,
although impedance for the dry electrode was substantially
greater than for the wet electrode, it was still in a reasonable
range for EEG measurements. However, in contrast to the wet
electrode, which tended to dry out such that the impedance
became higher over time, the dry electrode remained stable
after several hours of recording. Note that in this comparison,
we did not perform any skin preparation for either style of
electrodes. Due to the large surface contact area, the dry pads
are able to achieve relatively low contact impedance similar
VOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

to that of traditional gel approaches. Importantly, this electrode style requires minimal preparation, is a cost-effective
solution, and in conjunction with a high-impedance amplifier,
provides signal quality approximately equivalent to that of
the classic ‘‘wet’’ electrode after preparation, and shows even
better performance than the wet style over moderate and long
time periods (Figure 4).
This technique provides comparable performance to
laboratory-grade wet electrodes on glabrous skin, with
decreases in performance when attached to hairy, nonglabrous skin [57]. To penetrate hair, several variations of
spring-loaded multi-pin style electrodes have been developed
with signal characteristics similar to that of the foam pad
electrode and equivalent functionality as gelled methods. In
this case, an array of tiny pins penetrates the hair, distributing
the connection across several individual contact points [58].
In the near-term, this approach may be more feasible for
systems designed for scientific study than for fielded applications due to cost, the potential for injury risk in some settings,
and the potential for participant discomfort over long time
periods. Additionally, because dry approaches rely solely
on mechanical connection with the scalp, there are open
questions about whether this will be a reliable, consistent
medium over time, especially in high-movement scenarios.
Given this and the potential for discomfort from the mechanical connection, NCTU, with ARL partners, are currently performing use-case evaluations and exploring novel materials
(see below) and sensor designs.
Form factor design will continue to be a critical development area, because, in order for any system to be truly fieldable, user comfort and safety must be a primary consideration.
For example, the system must be comfortable for long-term
wear; designs will need to avoid the possibility of ‘‘hot spots’’
of discomfort that can form as a result of constant pressure on
the same locations. This likely means avoiding designs that
involve semi-rigid or stiff spring-based mechanisms for holding electrodes in place, such as the Emotiv EPOC or Quasar
DSI models. These approaches require pressure behind each
electrode and could be particularly problematic for larger
head sizes, especially if used in combination with multi-pin
style dry electrodes that could place pressure on very small
contact points [59]. Similarly, systems must be as lightweight
as possible to minimize muscle fatigue, while remaining as
unobtrusive to the user as possible so as not to inhibit their
inclination to wear the unit on a regular basis. This includes
social issues, as well as usability, in order to ensure consistent
compliance across a potentially diverse user base.
Considering that these systems are worn on the head, safety
becomes critical to putting neurotechnology applications into
task environments where risks from impact (e.g. an automobile or bicycle crash) are present. Protective helmets utilize
deformable materials, which are designed to absorb energy
by deformation, thus protecting the head from trauma. This
deformation requires both time and space, and poses at least
two problems for any design involving hard components,
such as communications gear or EEG sensor mounted directly
VOLUME 1, 2013

above the scalp, which compromises the space between it and
the helmet shell. First, these components become potential
sources of direct ballistic injury to the user by transferring the
energy directly into the scalp. Secondly, rigid structures will
inhibit the intended deformation of the material, thus decreasing the helmet’s effectiveness in absorbing energy and allowing more to be transferred on to the wearer. For electronic
components to be seamlessly integrated with embedded protection devices there must be significant advances in the area
of deformable electronics in order to minimize risk to the user.
To this end, ARL has been investigating the fabrication of pliable, stretchable conductive polymer substrates
as a basis for electronics platforms that may serve as
the foundation for biological sensing [60]. While recent
advances in material sciences have allowed the development of deformable conductive polymers, one primary challenge with the current commercially available solutions is
that the conductance changes dramatically as the material
deforms. This poses a severe challenge for EEG, which
targets extremely small fluctuations in voltage against a
high-noise background. However, collaborators in ARL’s
Weapons & Materials Research Directorate have developed a
unique process that yields soft meso-scale polymer composites capable of maintaining low levels of signal attenuation
(< 3 dB) while subjected to biaxial hyperelastic stretching
(See Figure 5). Particularly, by adjusting the manufacturing
process to adjust the orientation behavior of carbon-nanotube
particulates within elastomer substrates, structures can be
formed that maintain conductivity even while being stretched
by large amounts. Meanwhile, sophisticated and unique new
electromechanical characterization techniques were recently
developed by collaborators in ARL’s Vehicle Technology
Directorate that allow us, for the first time, to make accurate
measurements of the influence that very large biaxial strains,
frequency, temperature, and material type have on stretchable
electronic signal attenuation and filtering characteristics [61].
Ongoing efforts at ARL, funded by the ARL Director’s
Research Initiative [62], combine the expertise across three of
ARL’s directorates in materials science and neurotechnology
to exploit this technology for EEG by exploring the use of
such conductive, deformable materials as a replacement for
the fixed-conductor metallic wire leads connecting electrode
tips with the primary electronics of the systems. For example,
an early prototype sample (shown in Figure 5) replicates
a typical 9-electrode 10/20 style layout, but is capable of
stretching to match different head sizes while causing minimal signal attenuation. Further iterations focus on refining
the fabrication techniques to tune the material conductance
profile, as well as identifying the appropriate methods for
characterizing and validating the efficacy of this technology
when used for the EEG domain. While one goal is integration with the reconfigurable suspension pads of a helmet,
thus alleviating the concerns mentioned above during hazardous situations, stretchable or compressive polymers could
additionally be an ideal replacement for rigid conductors
when using a multi-pin or bristle style electrode, alleviating
139

K. McDowell et al.: Real-World Neuroimaging Technologies

the concerns about long-term comfort and safety discussed
above.

FIGURE 5. Stretchable, pliable conductors for biosensing. Example
prototype 9-sensor strip of stretchable, pliable materials usable for EEG
data collection can stretch beyond 33%. This technology allows it to
easily conform for differing head sizes (left), while also providing comfort
and safety of the user when built into head protection devices.

At the systems level, some of the concerns found at
the sensor level are also relevant (e.g., weight, comfort,
ruggedization), while several additional technology advances
will be needed, such as reducing power consumption and
increasing onboard processing power and data transmission
bandwidth. All of these pervasive challenges are amplified by
the implementation of multi-aspect measurement approaches
that capture not only EEG data to measure brain activity, but
also other sensors to capture additional data that characterize
non-brain related physiological, behavioral, and contextual
variables.
The necessity for the use of multiple measures stems from
concerns that are both conceptual and pragmatic. Conceptually, the highly multi-dimensional nature of human behavior,
in general, and human brain behavior, specifically, strongly
suggests that no single available measure alone can provide
the information needed to fully characterize human cognitive
performance (cf. [20]). Moreover, given the highly integrated
nature of many of the objective signals typically employed,
such as measures of central or peripheral physiological function, specific, behaviorally-relevant states are not uniquely
mapped to specific values of these measures. This indicates
that information from other simultaneously varying measures
of state or context is needed to disambiguate the meaning of
the recorded signals. Practically, in either real-world experimental paradigms or neurotechnology application environments, performance of a given task at any given time is not
typically known, making it difficult, if not impossible, to
assign often task-dependent meanings to patterns of observed
measurements. External variables are needed for the segmentation of continuous data streams into task-relevant epochs,
which are typically well-defined in the laboratory. Choosing
the right combination of sensor technologies to adequately
characterize the relevant aspects of real-world behavior will
be a critical challenge, which is complicated for real-world
neuroimaging systems by the need to integrate and adequately synchronize these data streams under the constraints
of weight, power, data transmission, and cost.
140

B. ALGORITHMS

Once neuroimaging data, real-world or otherwise, are
acquired, extensive and often computationally-intensive processing is necessary before the data are in a form that is
easily usable and suitable for the analysis, modeling, and
interpretation of brain behavior or for the transformation
into metrics of user state or performance in brain-based
human-systems interactions. Classically, the processing and
analysis of EEG data in research settings requires extensive
effort by trained experts who must first visually inspect data
and identify non-brain-related signal artifacts or other, often
irrelevant, sources of signal variance. This process is time
consuming even in highly-controlled laboratory experiments
where task conditions are held constant for task durations that
are relatively short, the size of datasets is relatively small, and
task performance is highly constrained and well annotated in
the data streams (e.g., time-stamped event markers indicating
task, stimulus, or response onsets and offsets). However, in a
approach to real-world neuroimaging research, many of these
controls that serve to constrain the data processing and analysis problem in laboratory-based research are inapplicable.
From a scientific perspective, one possible solution to this
issue entails recording over much longer time periods than
the typical laboratory study, with concomitant increases in the
size of experimental datasets and the costs of data processing.
From an application development perspective, the emphasis for real-time or near real-time system interactions that
are central to many neurotechnology concepts obviates the
possibility to depend upon the extensive, expert-driven,
post-hoc data processing typical of the research laboratory.
However, a common need in real-world neuroimaging
research and neurotechnology development is the ability to
detect and identify salient events whose occurrence during
realistic behavior is not known a priori in either case.
Consider the ubiquitous example of events that have long
posed significant challenges in EEG analysis: the presence
of motion- and muscle-related signal artifacts (for a review,
see [63]). In laboratory experimentation, the presence of artifact components is often reduced by asking participants to
minimize their body movements, though the persistent necessity for time-consuming visual inspection and data rejection
would suggest that the effectiveness of such instructions is
far from perfect. Moreover, during real-world neuroimaging
experiments, such constraints would be counter-productive
to the observation and study of naturalistic behavior.
For user applications, it would be impractical to constrain
user movements in order to achieve reliable functionality,
leading to a potential lack of user acceptance. In either case,
an increase in the likelihood and frequency of motion- and
muscle-related artifacts in these data are expected. Our team
has achieved several advancements in algorithm development
to enhance real-world neuroimaging for both scientific and
applied pursuits.
UTSA and ARL partners have used autoregressive (AR)
modeling techniques to create type-specific artifact models.
This enables both automatic artifact detection and classificaVOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

VOLUME 1, 2013

Artifact Classification
Accuracy
100

A

Original Stimuli

Jaw
Clench
Jaw
Movement
Move
Eyebrows
Eyeblink
Eyes Left
Eyes Up
Rotate
Head

B

None

Rotate
Head

Eyes Up

Eyes Left

Eyeblink

Jaw
Clench
Jaw
Movement
Move
Eyebrows

Classified
Stimuli

0

None

PCA Weights

-2
-10

0

ensi

0

on 3

2

-2
-8

-6

-4

Dimension 2

-2

Dim

Dimension 1

tion [64] and offers a possible avenue for cleaning the data
ahead of subsequent analysis or system integration.
To derive type-specific artifact models it is necessary to
obtain labeled training instances for each artifact type. The
results of this research effort indicate that this can be done by
having the research subject undergo a quick battery (< 10 min)
of calibration tasks designed to elicit standard artifacts (e.g.
eye blinking, jaw clenching, and head turning) prior to system use. Once the type-specific AR models have been created, the parameters of the model are then used as features
to train a multi-class support vector machine (SVM) [64].
This approach has yielded remarkable average classification
results > 95% across the following artifact categories: eye
blink, jaw clench, jaw movement, head rotation, eyebrow
movement, left eye movements, upward eye movements, and
none (Figure 6). This work represents an important step in
objective artifact detection and extends previous research in
artifact classification, thus enabling artifact to be considered
as markers of salient events and a critical component of
developing the context of the neural data. Further, this is a
relatively fast computational approach that is suitable to realtime processing and applications.
The AR approach above has shown promise when exemplar artifacts are known. However, it is unrealistic to assume
that all artifacts can be captured using that approach.
An alternative method is to utilize measures that account for
differences in the dynamic nature of brain versus non-brain
signal sources and are therefore less affected by the presence
of artifacts in the EEG signal.
Recently, ARL has collaborated with UM and DCS on
work assessing phase synchronization that has shown it is
possible to detect statistically significant changes in neural dynamics during activities that would have traditionally
been ‘‘off-limits’’ due to artifact severity [65], [44], [66].
For example, Lau, et al. [44] demonstrated that a P300-like
cognitive response to a visual oddball discrimination task
could be obtained during walking using the weighted phase
lag index (WPLI), which is a measure describing the phase
synchronization between disparate neural sources recorded
at the scalp [67]. Phase synchronization is used to refer to
the tendency of two (or more) oscillators to exhibit consistent
phase locking or entrainment, in response to specific conditions, such as the establishment of a causal pathway or the
presence of a common, third-party influence [68]. By limiting
analysis to only the imaginary portion of the cross-spectrum
between two electrodes, phase analysis methods such as
the WPLI are able to strongly discount volume conduction
effects, which result in the mixture of the signals produced
by different neural and non-neural sources before they reach
the sensors located on the scalp, giving the researcher a
clearer picture of true neural dynamics. Gordon, et al. [66]
extended this approach by using the AR methods described
earlier to first model the data prior to computing phase synchronization statistics. Using this technique, the authors were
able to demonstrate further resistance to EMG artifacts by
analyzing a combination of simulated and real neural data.

-4
0

FIGURE 6. Performance of AR-based artifact identification methods.
Discrimination accuracy is extremely high for subject-specific models of 7
different type of movement artifacts (A). Independent features are easily
visualized when separated using Principle Component Analysis (first 3
components shown, B).

Importantly, the approach described here does not rely on a
priori knowledge of what the artifacts may be and are also
applicable to the low-density electrode montages expected in
many BCIT applications.
These are approaches that operate in ‘‘scalp space.’’ Over
the past several years, methods for blind source separation
(BSS) have become relatively standard for the separation
of brain and non-brain related signal components in EEG
data. Blind source separation methods, specifically, ICA
approaches developed by UCSD collaborators, work by projecting the scalp recordings, which are assumed to be a linear
mixture of a set of latent source variables, into a new source
space by maximizing statistical independence between the
source variables [69]. This approach has been shown to be
useful for both scientific and applied pursuits; however, there
are a number of practical issues when performing ICA on
EEG data. For starters, ICA requires that the number of
sources be equal to the number of electrodes. This assumption is unlikely to be true in practice and thus the source
separation problem is typically not well-posed and is often
under-determined. The sources must also be stationary and at
141

K. McDowell et al.: Real-World Neuroimaging Technologies

most one source can be Gaussian. The assumption of source
stationarity is equally unlikely, at least over extended periods
of time and/or when multiple complex tasks are being performed. Finally, to capture the source statistics, the researcher
must know a priori neural event boundaries and must possess
enough data to adequately represent the underlying processes
of interest.
Despite these issues ICA has proven to be an effective tool
for data cleaning and pre-processing [70] and has received
attention with respect to isolating various neural processes of
interest [71]. UCSD collaborators are working on a number of
extensions proposed to improve the performance of standard
ICA techniques, similar to what has been advocated by other
groups [72]. These include adding the capacity for multiple
mixture [73] and adaptive mixture models [74] that use methods, such as maximum likelihood estimation, to produce the
most likely decomposition at different time points. In addition, clustering methods and machine learning approaches
have been used to identify and group relatively stable components across task conditions and recording sessions [75],
[76]. In this way, rather than assuming all components from
a specific decomposition are unique and equally informative,
researchers are able to better identify relationships between
changes in context and changes occurring in seemingly independent neural processes.
To further combat some of the many issues related to
processing EEG, our multi-aspect approach looks beyond just
EEG. By simultaneously recording multi-aspect physiological data, researchers can better understand the subtleties of the
brain-body-behavior relationship [16]. This also facilitates
the development of more robust tools by providing secondary
sources of information that can be leveraged when and as
needed to develop the context for interpreting measured neural activity. Currently, collaboration between DCS and ARL
is underway to simultaneously record high-density EEG,
EMG of the face, neck and shoulders, eye tracking, facial
expression tracking, and upper limb motion tracking. Similar
efforts are underway at partner locations in UCSD, UM, and
NCTU. The goal of these efforts is to derive relationships that
can be used to fuel the systems-level development of neurotechnologies that then can be reliably situated in real-world
contexts.
We are also looking towards the development of more
real-time processing techniques. Low-pass and high-pass filters can be implemented in hardware or through specific
software applications. AR methods such as those previously
described can be applied quickly and efficiently and many
phase synchronization approaches have online extensions that
do not require epoching of the data, but rather use the Hilbert
transform to derive a more continuous notion of phase [77].
Our partners have also worked on hardware-based ICA applications [78].
Significant progress has been made by BCI developers,
who have viewed standard EEG processing as forms of
feature extraction that then could be used to feed stateclassification tools. These tools range from relatively stock
142

approaches, such as Linear Discriminant Analysis (LDA),
Common Spatial Patterns (CSP), or Support-Vector Machines
(SVM), that operate on minimally processed data, to more
in-depth designs, such as those from our collaborators [79],
[80], in which complex, multi-tiered pre-processing techniques and/or event-related analyses are leveraged in conjunction with standard machine learning approaches. These latter
approaches represent a significant step towards the types of
capabilities needed for current BCIT development. Rather
than taking an agnostic view of the information contained in
the EEG signals and attempting to perform state classification
on the raw or minimally processed data, these neurotechnology developers are taking a systems-level view in which
multiple components each enable the extraction of different
information from the imaged neural data. To support this
development, engineers and scientists working at UCSD have
been developing a tool, known as BCILAB, that enables rapid
deployment of a number of EEG processing pipelines coupled
with state-of-the-art classification systems [81].
C. INTERFACES

One significant, if perhaps insufficiently appreciated, challenge to the real-world neuroimaging approach will be the
research into and the design and development of interfaces
that can enable minimally-intrusive sampling of participant
behaviors while they are observed in natural conditions, and
the effective interaction of researchers and developers with
the large and complex datasets that will result from these
research efforts. Thus, the requirements for user interfaces
will be significantly altered for a real world neuroimaging
system compared to conventional neuroimaging systems. One
of the main changes will be the shift in responsibility for
monitoring the hardware and data collection from an expert
who is not wearing the system to a wearer with limited or
potentially unknown level of expertise.
In SFN System V1.0, ARL and DCS have designed a range
of applications for the Android platform on cell phones and
tablet computers. The main feature of the system is a set of
widgets on the home screen that allow the user to self-report
the start and end of pre-defined activities (eating, drinking,
meeting, conversations, etc.), as well as unexpected events
(startling sounds, forgot to log the start or end of an event,
adjusted the fit or positioning of measurement equipment,
etc.). There is also a master scheduler application, which is
nearly invisible to the user. This application can trigger the
start of self-report surveys and experimental tasks based on
a preset schedule. We have converted a number of published
self-report surveys, such as the Karolinska Sleepiness Survey
[82], the task induced fatigue scale [83], the NASA TLX
[84], [85], and visual analog scales of stress and fatigue [86],
[87], into touch-screen versions that can be completed quickly
with minimal impact on the user’s work or everyday tasks
and behavior. In the near future, we plan to enable automatic
processing of the incoming data in order to trigger and aid
in troubleshooting the physiological systems when they start
to fail. These applications, which are undergoing use-case
VOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

evaluations, all assist in transitioning data collection and
monitoring capabilities from an experimenter to the user. Data
collected with SFN System V1.0 will aid our development of
future versions of the system in which we aim to implement
automatic processing of the physiological data streams to
further remove the need to intrusively sample subjective data.
A second critical challenge is enabling an effective
interaction between scientists, engineers, and technology
innovators to analyze, interpret, and ultimately create novel
technologies from the complex multi-aspect datasets created
with these technologies. UCSD continues to evolve their
EEGLAB graphical-user interface to incorporate many of
the aforementioned advances in algorithms and to enable
EEG specialists to more readily access advanced signal processing techniques. Similarly, UTSA and ARL have partnered to implement the DETECT toolbox for MATLAB
that offers the ability for EEG specialists to access the AR
models described above [37], [38]. Finally, as described
above, UCSD’s BCILAB was specifically developed for nonEEG specialists (Christian Kothe, personal communications).
While important progress has been made, the area of interface
development for the broader community remains a significant
challenge.
D. EXPERIMENTATION, TESTING, AND VALIDATION

Above we highlighted three different initial approaches
that have been taken to extending neuroimaging into
real-world settings: examining human behavior in relatively
well-controlled real-world task environments; examining
real-world tasks under controlled laboratory conditions; and
examining laboratory tasks in more realistic task conditions.
All of these approaches enable significant advances, both
scientifically and technically, towards the real-world neuroimaging vision laid out here. However, the maturation of
enabling capabilities discussed here, as well as the growing
ubiquity of sensor-based user technologies in our everyday
lives, is opening up new possibilities for the study of human
neural behavior in its natural state. In particular, these technologies are envisioned to enable more ecological approaches
utilized in other disciplines in the human and behavioral
sciences-approaches that, by contrast, have not been prevalent
in the cognitive neurosciences-to both the observation and the
experimental study of real-world brain behavior.
From both the scientific and applied perspectives, our current efforts focus on understanding and developing technologies that are tailored to individual users. This approach is
feasible in large part due to the recent re-emergence of a
focus on individual differences in the field of cognitive neuroscience (e.g., see [88], [89]) coupled with the remarkable
advances observed in the application of machine learning and
classifications approaches to individualizing BCIT applications over the past decade. These advances are making subtle
but critical shifts in the paradigms researchers are employing
to understand brain function. To this end, we are employing
paradigms of large data collection efforts that capture both
sufficient real-world behaviors and large participant popuVOLUME 1, 2013

lations. Like many within the cognitive neuroscience community, our focus is not only on understanding similarities
between people, but also on uncovering the differences that
make people unique. We aim to further this paradigm and
focus on understanding the differences in neural processing
between events within individuals. Our primary focus is on
developing capabilities for neuroimaging in actual real-world
settings; however, one of the bridging technologies that may
further our team’s scientific objectives and enable the development of future systems is virtual reality (VR). Our general
approach outlined here, when merged with VR, will introduce new and potentially insightful cognitive neuroscience
experimental paradigms. Still, further tool development in
VR is needed to instantiate this vision. To meet these needs,
ARL has been developing a novel software framework for the
intelligent control of dynamic, complex, high-resolution VR
environments. The Graph-based Interactive Narrative (GIN)
system [46] utilizes a three-layered hierarchical graph framework that models the physical topography of the environment as a set of nodes (i.e., path intersections) and edges
(i.e., paths the user can traverse between nodes), and allows
the monitoring of the participant’s movement through the
graph and the manipulating of stimulus presentations relative
to the participant’s chosen path. The GIN system aims to:
1) provide experimental participants with an increased ability
to freely control their navigation throughout the virtual world
(i.e., increasing perceptions of agency [90]); 2) maintaining
experimental control by adapting the presentation of stimulus
events to the participants chosen path while adhering to the
requirements of the experimental design; and 3) improving the tractability of the development of VR scenarios for
experimentation by providing capabilities for automatically
controlling the placement and occurrence of stimulus events.
The primary rationale for addressing this last point stems
from the time- and labor-intensity inherent to designing,
developing, and implementing experimental VR paradigms
that capture the relevant contextual effects on human tasks,
actions, and environmental actions (cf. [45]).
As a complimentary approach, ARL partners at UCSD
have developed a new software framework, the
Simulation and Neuroscience Application Platform (SNAP)
(https://github.com/sccn/SNAP), that aims to provide new
rapid prototyping, testing, and real-time control of complex tasks and paradigms for implementation in real-world
neuroimaging experimental designs. The SNAP framework
is integrated with a commercial-grade C++ game engine,
Panda3D, to enable the efficient transition from controlling
simple 2-D psychological stimuli to running complex experimental tasks involving full, immersive 3-D visual displays.
Similar capabilities, for example implemented on portable
interface platforms (see ‘‘Interfaces,’’ above), could support
the implementation of experimental paradigms in real-world
environments.
In addition to novel paradigms, as fieldable neuroimaging
expands and new hardware approaches are developed, it will
be necessary to continually evaluate and compare the efficacy
143

K. McDowell et al.: Real-World Neuroimaging Technologies

of new technologies. For example, recent ARL tests of the
timing accuracy and variance in trigger integration associated
with several different commercial EEG systems has revealed
strong timing errors in certain products [88], [91]. Similarly,
comparisons of system design features that directly affect
overall usability, such as average application time, adaptability for different head sizes, user comfort, or electrode stability
over time, have led to a stronger understanding of which elements are most critical for application to systems targeted for
real-world use and are aiding future technology development
[59]. One of the critical issues with real-world neurotechnology testing and evaluation (T&E) is the lack of current formal
standards or procedures for EEG sensors and systems (i.e.,
no T&E standards have been adopted by IEEE or ASTM
International). The most common approaches to T&E rely
on humans to provide the native signals (e.g., see Figure 4),
which is sub-optimal due to the inherent variability and inconsistency of human EEG signals. Further, while this approach
may be acceptable for evaluating certain aspects of sensor
design, it is more problematic for evaluating entire systems.
Our team has addressed this particular problem by attempting to develop and validate an EEG ‘‘phantom’’ device, which
could be used to replace the human head as an objective
fixture to generate reference signals for these kinds of tests
(Figure 7). Specifically, the phantom serves as a standard,
known-quantity signal that can be used with a putative system, allowing an experimenter to quantify any differences
in the outputs of the recording system. The physical properties of the phantom are designed to emulate the conductive properties of brain matter, skull, and skin. And while
there currently are a number of computational models that
simulate these properties of the head, no physical models are
commercially available that also have analogous conductive
properties. Likewise, the few physical, conductive models
or ‘‘phantoms’’ discussed in the academic literature (e.g.
[95]–[98]) have not been created in an appropriate form factor for use with complete conventional EEG systems. Being
structured as such would enable a host of applications, including: use as a benchmark for typical off-the-shelf cap-based
EEG systems, assessing the impact of particular environments
on signal recording quality, and validating the efficacy of
putative signal detection or discrimination algorithms.
In order to quickly advance the development of this capability, ARL proposed and awarded an SBIR project topic
(‘‘Neurological Simulator for Applied Data Collection,’’
Army SBIR A10-066) for a phantom model that has physical
and electrical properties analogous to the human head with
multiple sources for creating EEG-like signals from distinct,
interior points. Initial prototypes developed under this program have ranged from use of simple conductive paints over
a plastic shell (Physical Optics Corp (Torrence, CA, USA);
CFD Research Corp. (Huntsville, AL, USA)), to varying mixtures of carbon nanotube polymers doped to match the mean
conductance of the human head (Physical Optics Corp [99];
Creare, Inc (Hanover, NH, USA)), and even a 3-layer realistic
model based on an MRI of an actual head with embedded
144

dipole source points (Creare, Inc, [100]). Even though the
initial attempts fall short of the necessary conductive realism
to serve as a universal standard, models developed thus far
have already been found useful for evaluating system latency
[89]. Ongoing efforts focus on improving fabrication techniques to ensure reproducibility of the device while achieving
conductive realism across the entire ‘‘head’’ structure.

FIGURE 7. Sample prototype ‘‘phantom head’’ devices developed under
the SBIR program. Models provided by CFDRC (left), POC (center), and
Creare (right) are designed to be conductively analogous to the human
head, with embedded sources to create realistic electrical dipoles
detectable at the surface.

VI. MOVING TOWARD APPLICATIONS

One of the main goals of developing real-world neuroimaging techniques is to enable the development of BCITs that
can be implemented in realistic scenarios. An example of
such efforts is an SAIC-University of California, Santa
Barbara (UCSB)-ARL collaboration that aims to demonstrate the effective extension of a rapid serial visual presentation (RSVP) based-BCIT to an operationally-relevant
context [47]. Recent advances in the application of signal
processing and classification algorithms and techniques to
EEG signals have enabled the development of an RSVP
BCIT, which lets operators rapidly review or triage visual
imagery without requiring a manual response to each image
[101]. Various groups have shown that this approach can be
used to make the process of identifying targets in large ensembles of images an order of magnitude faster than a manual
search (e.g., see efforts by ARL partners, [47]). However,
initial applications typically used obvious target objects and
the only task required of the operator was to focus on the
image presentation.
In order to quickly advance the development of this capability, ARL successfully proposed a SBIR topic (‘‘Neurological Simulator for applied Data Collection,’’ Army SBIR A10066), with three Phase I projects awarded, and one subsequent
Phase II project awarded. This project is aimed at developing
a phantom model that has physical and electrical properVOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

ties analogous to the human head, with multiple sources for
creating EEG-like signals from distinct, interior points. The
RSVP BCIT was incorporated into the simulation by having
an RSVP window pop-up at various times throughout the
mission. Operators had to switch from what they were doing
and engage the BCIT. During the RSVP presentation, each
image was sorted based on an interest score derived from the
evoked brain response. The operator was then presented with
the images that generated the highest interest score and they
manually verified which of the top scoring image(s) contained
targets.
The initial development of this simulation environment
was focused on identifying the optimal parameters and
approach for classification of the neural response in an
RSVP paradigm. This included presentation properties such
as size, eccentricity, and rate [104], as well as the effects of
changes in attentional state on classification accuracy [105].
In addition, early studies examined the effect of operator
multitasking on system performance [106]. After the optimal
design parameters were identified, a simulation environment
was developed to quantify the benefit of incorporating neural
processing techniques into a relevant operational context.
Preliminary results indicate that the RSVP neural classification scheme can dramatically reduce the target search time
while maintaining the accuracy level achieved by traditional
manual search methods. Currently, the simulation environment (called RSVP-based Adaptive Virtual Environment with
Neural-processing or RAVEN) is undergoing final implementation and testing that focuses on the effect of multitasking
and task difficulty on overall system performance.
RAVEN System

Operator Screen
Sensor Banner

fatigue-based monitoring neurotechnologies demonstrated
that high correlations could be obtained between EEG activity
and lane deviation performance on a simplified driving task
under static and motion conditions [107]–[109]. Our team
further extended this effort to demonstrate that auditory mitigations could be used to aid performance in this scenario
[110], [111]. Currently, we are systematically extending these
efforts to more complex and realistic scenarios including
adding: road, traffic, and environmental complexity; multitasking; and vehicle convoy operations.
Efforts such as the applications illustrated above aid in
understanding the practical aspects of real-world neuroimaging implementation and give insights into many of the conceptual issues discussed herein. They also just hint at the possible brain-based technologies that will allow computers, for
the first time, to generate and leverage sophisticated analyses
of the emotional and cognitive states and processes of the people using them. These analyses have the potential to radically
change our current insights into basic human brain function
and to revolutionize the basic interactions people have, not
only with the systems they use, but also with each other.
ACKNOWLEDGMENT

The authors would like to thank all of our numerous research
partners who have supported this effort over the past seven
years. Special thanks to J. Touryan for his assistance in
describing the efforts on the ICB RAVEN project, R. Mrozek
and G. Slipher for their efforts on the stretchable, pliable
conductors, B. Kellihan, J. Canady, and T.J. Doty for their
efforts in developing SFN System V1.0, S. Kerick for aiding the description of several aspects of the paper, T. Lee
(DCS Corporation) and S. Fish (The University of Texas at
Austin), who graciously spoke on our behalf in the online
videos accompanying this document, and the public affairs
offices at The University of Texas at Austin and ARL for their
assistance with video production.
REFERENCES

Mode1:
Driving

Mode 2:
Search

RSVP Window

Mode 3:
RSVP

Sensor Portal

Mission Map

FIGURE 8. RSVP-based Adaptive Virtual Environment with
Neural-processing (RAVEN) system. RAVEN system main operator screen
and RSVP window. The primary task is identification of dismounts while
the vehicle is navigating a simulated environment. Secondary tasks
include identification of potential IED locations, monitoring and
responding to communications (audio and text). The BCI component is
engaged during RSVP search (Mode 3) and top scoring images are
presented on the main operator screen.

ARL, and its partners at Teledyne Scientific & Imaging, SAIC, DCS, NCTU, UCSD, and the U.S. Army
Tank Automotive Research, Development, and Engineering
Center are attempting a similar effort to extend NCTU- and
UCSD-developed driving performance prediction and mitigation technologies into realistic driving scenarios. Early
VOLUME 1, 2013

[1] Social, Behavioral, and Economic Research in the Federal Context,
National Science and Technology Council, Subcommittee on Social,
Behavioral, and Economic Research, Executive Office of the President,
Washington DC, USA, 2009.
[2] Committee on Opportunities in Neuroscience for Future Army Applications, National Research Council, Opportunities in Neuroscience for
Future Army Applications. Washington, DC, USA: National Academies
Press, 2009.
[3] B. J. Lance, S. E. Kerick, A. J. Ries, K. S. Oie, and K. McDowell, ‘‘Brain–
computer interface technologies in the coming decades,’’ Proc. IEEE,
vol. 100, no. 5, pp. 1585–1599, May 2012.
[4] L.-D. Liao, C.-T. Lin, K. McDowell, A. E. Wickenden, K. Gramann, T.-P.
Jung, L.-W. Ko, and J.-Y. Chang, ‘‘Biosensor technologies for augmented
brain–computer interfaces in the next decades,’’ Proc. IEEE, vol. 100,
no. 5, pp. 1553–1566, May 2012.
[5] A. Kingstone, D. Smilek, J. Ristic, C. K. Friesen, and J. D. Eastwood,
‘‘Attention, researchers! It is time to take a look at the real world,’’ Current
Directions Psychol. Sci., vol. 12, no. 5, pp. 176–180, Oct. 2003.
[6] G. M. Edelman and J. A. Gally, ‘‘Degeneracy and complexity
in biological systems,’’ Proc. Nat. Acad. Sci., vol. 98, no. 24,
pp. 13763–13768, Nov. 2001.
[7] J. J. Gibson, ‘‘The theory of affordances,’’ in Perceiving, Acting, and
Knowing, Toward an Ecological Psychology, R. Shaw and J. Bransford,
Eds. New York, NY, USA: Wiley, 1977.
145

K. McDowell et al.: Real-World Neuroimaging Technologies

[8] A. Gevins, H. Leong, R. Du, M. E. Smith, J. Le, D. DuRousseau,
J. Zhang, and J. Libove, ‘‘Towards measurement of brain function in operational environments,’’ Biol. Psychol., vol. 40, nos. 1–2,
pp. 169–186, May 1995.
[9] C. Babiloni, C. Del Percio, M. Iacoboni, F. Infarinato, R. Lizio,
N. Marzano, G. Crespi, F. Dassù, M. Pirritano, M. Gallamini, and
F. Eusebi, ‘‘Golf putt outcomes are predicted by sensorimotor cerebral
EEG rhythms,’’ J. Physiol., vol. 586, no. 1, pp. 131–139, Jan. 2008.
[10] S. F. Liang, C. T. Lin, R. C. Wu, Y. C. Chen, T. Y. Huang, and T. P. Jung,
‘‘Monitoring driver’s alertness based on the driving performance estimation and the EEG power spectrum analysis,’’ in Proc. IEEE 27th Annu.
Int. Conf. Eng. Med. Biol. Soc., vol. 6. Jun. 2006, pp. 5738–5741.
[11] G. F. Wilson and C. A. Russell, ‘‘Performance enhancement in an
uninhabited air vehicle task using psychophysiologically determined
adaptive aiding,’’ Human Factors, vol. 49, no. 6, pp. 1005–1018,
Dec. 2007.
[12] G. F. Wilson, ‘‘An analysis of mental workload in pilots during flight
using multiple psychophysiological measures,’’ Int. J. Aviation Psychol.,
vol. 12, no. 1, pp. 3–18, Jan. 2002.
[13] A. J. Haufler, T. W. Spalding, D. L. Santa Maria, and B. D. Hatfield,
‘‘Neuro-cognitive activity during a self-paced visuospatial task: Comparative EEG profiles in marksmen and novice shooters,’’ Biol. Psychol.,
vol. 53, nos. 2–3, pp. 131–160, Jul. 2000.
[14] S. E. Kerick, B. D. Hatfield, and L. E. Allender, ‘‘Event-related cortical dynamics of soldiers during shooting as a function of varied task
demand,’’ Aviation Space Environ. Med., vol. 78, no. 5 pp. 153–164,
May 2007.
[15] J. T. Gwin, K. Gramann, S. Makeig, and D. P. Ferris, ‘‘Removal of
movement artifact from high–density EEG recorded during walking and
running,’’ J. Neurophysiol., vol. 103, no. 6, pp. 3526–3534, Apr. 2010.
[16] K. Gramann, J. T. Gwin, D. P. Ferris, K. Oie, T.-P. Jung,
C.-T. Lin, L.-D. Liao, and S. Makeig, ‘‘Cognition in action: Imaging
brain/body dynamics in mobile humans,’’ Rev. Neurosci., vol. 22, no. 6,
pp. 593–608, Nov. 2011.
[17] K. R. Dixon, K. Hagemann, J. Basilico, C. Forsythe, S. Rothe, M. Schrauf,
and W. E. Kincses, ‘‘Improved team performance using EEG-and contextbased cognitive-state classifications for a vehicle crew,’’ in Foundations of
Augmented Cognition. Neuroergonomics and Operational Neuroscience,
D. D. Schmorrow, I. V. Estabrooke, and M. Grootjen, Eds. Berlin, Germany: Springer-Verlag, 2009, pp. 365–372.
[18] M. Simon, E. A. Schmidt, W. E. Kincses, M. Fritzsche, A. Bruns, C. Aufmuth, M. Bogdan, W. Rosenstiel, and M. Schrauf, ‘‘EEG alpha spindle
measures as indicators of driver fatigue under real traffic conditions,’’
Clinical Neurophysiol., vol. 122, no. 6, pp. 1168–1178, Jun. 2011.
[19] S. E. Kerick, K. S. Oie, and K. McDowell, ‘‘Assessment of EEG signal
quality in motion environments,’’ US Dept. Army, Army Res. Lab.,
Aberdeen Proving Ground, Aberdeen, MD, USA, Tech. Rep. ARL-TR4866, Jun. 2009.
[20] K. S. Oie, S. Gordon, and K. McDowell, ‘‘The Multi-aspect measurement approach: Rationale, technologies, tools, and challenges for systems
design,’’ in Designing Soldier Systems, Current Issues in Human Factors.
Farnham, U.K.: Ashgate, 2012.
[21] S. E. Kerick and K. McDowell, ‘‘Understanding brain, cognition, and
behavior in complex dynamic environments,’’ in Proc. 5th Int. Conf.
Found. Augmented Cognit., 2007, pp. 35–41.
[22] S. Makeig, C. Kothe, T. Mullen, N. Bigdely-Shamlo, Z. Zhang, and
K. Kreutz-Delgado, ‘‘Evolving signal processing for brain–computer
interfaces,’’ Proc. IEEE, vol. 100, no. 5, pp. 1567–1584, May 2012.
[23] K. McDowell, K. Whitaker, W. D. Hairston, and K. S. Oie, ‘‘Concepts
for developing and utilizing crowdsourcing for neurotechnology advancement,’’ US Dept. Army, Army Res. Lab., Aberdeen Proving Ground,
Aberdeen, MD, USA, Tech. Rep. ARL-SR-088, Jan. 2013.
[24] K. S. Oie, K. McDowell, J. Metcalfe, W. D. Hairston, S. Kerick, T. Lee,
and S. Makeig, ‘‘The cognition and neuroergonomics (CaN) collaborative
technology alliance (CTA): Scientific vision, approach, and translational
paths,’’ US Dept. Army, Army Res. Lab., Aberdeen Proving Ground,
Aberdeen, MD, USA, Tech. Rep. ARL-SR-0252, 2012.
[25] R. A. Brooks, ‘‘New approaches to robotics,’’ Science, vol. 253, no. 5025,
pp. 1227–1232, 1991.
[26] M. L. Anderson, ‘‘Embodied cognition: A field guide,’’ Artif. Intell.,
vol. 149, no. 1, pp. 91–130, Sep. 2003.
[27] E. Brymer and K. Davids, ‘‘Ecological dynamics as a theoretical framework for development of sustainable behaviours towards the environment,’’ Environ. Educ. Res., vol. 19, no. 1, pp. 45–63, May 2012.

146

[28] E. K. Morris, ‘‘Behavior analysis and ecological psychology: Past,
present, and future. A review of harry heft’s ecological psychology in
context,’’ J. Exp. Anal. Behavior, vol. 92, no. 2, pp. 275–304, Sep. 2009.
[29] J. J. Gibson, ‘‘The theory of affordances,’’ in Perceiving, Acting, and
Knowing, Toward an Ecological Psychology, R. Shaw and J. Bransford,
Eds. New York, NY, USA: Wiley, 1977.
[30] D. H. Ballard, ‘‘Animate vision,’’ Artif. Intell., vol. 48, no. 1, pp. 57–86,
Feb. 1991.
[31] W. H. Warren, ‘‘The dynamics of perception and action,’’ Psychol. Rev.,
vol. 113, no. 2, pp. 358–389, Apr. 2006.
[32] K. Oie and K. McDowell, ‘‘Neurocognitive engineering for systems
development,’’ Synesis, J. Sci., Technol., Ethics, Policy, vol. 2, no. 1,
pp. 26–37, 2011.
[33] L. D. Liao, C. Y. Chen, I. J. Wang, S. F. Chen, S. Y. Li, B. W. Chen,
J. Y. Chang, and C. T. Lin, ‘‘Gaming control using a wearable and wireless
EEG-based brain-computer interface device with novel dry foam-based
sensors,’’ J. Neuroeng. Rehabil., vol. 9, no. 1, pp. 1–5, 2012.
[34] A. Delorme, C. Kothe, A. Vankov, N. Bigdely-Shamlo, R. Oostenveld,
T. O. Zander, and S. Makeig, ‘‘MATLAB-based tools for BCI research,’’
in Proc. Brain-Comput. Inter. Conf., 2010, pp. 241–259.
[35] A. Delorme, T. Mullen, C. Kothe, Z. A. Acar, N. Bigdely-Shamlo,
A. Vankov, and S. Makeig, ‘‘EEGLAB, SIFT, NFT, BCILAB, and
ERICA: New tools for advanced EEG processing,’’ Comput. Intell. Neurosci., vol. 2011, pp. 1–10, Feb. 2011.
[36] G. Schalk, D. J. McFarland, T. Hinterberger, N. Birbaumer, and J. R. Wolpaw, ‘‘BCI2000: A general-purpose brain-computer interface (BCI) system,’’ IEEE Trans. Biomed. Eng., vol. 51, no. 6, pp. 1034–1043, Jun. 2004.
[37] V. Lawhern, W. D. Hairston, and K. Robbins, ‘‘DETECT: Detection of
events in continuous time toolbox: User’s guide, examples and function
reference documentation,’’ US Dept. Army, Army Res. Lab., Aberdeen
Proving Ground, Aberdeen, MD, USA, to be published.
[38] V. Lawhern, W. D. Hairston, and K. Robbins, ‘‘A MATLAB toolbox for event detection and identification in time series, with applications to artifact detection in EEG signals,’’ PLoS ONE, vol. 8, no. 4,
p. e62944, Apr. 2013.
[39] K. A. Robbins, ‘‘EEGVIS: A MATLAB toolbox for browsing,
exploring, and viewing large datasets,’’ Front. Neuroinf., vol. 6,
2012.
[40] C. T. Lin, L. D. Liao, Y. H. Liu, I. J. Wang, B. S. Lin, and J. Y.
Chang, ‘‘Novel dry polymer foam electrodes for long-term EEG measurement,’’ IEEE Trans. Biomed. Eng., vol. 58, no. 5, pp. 1200–1207,
May 2011.
[41] C. Papadelis, C. Kourtidou-Papadeli, P. D. Bamidis, I. Chouvarda,
D. Koufogiannis, E. Bekiaris, and N. Maglaveras, ‘‘Indicators of Sleepiness in an ambulatory EEG study of night driving,’’ IEEE Eng. Med. Biol.
Soc., vol. 1, no. 1, pp. 6201–6204, Jan. 2006.
[42] S. E. Kerick, L. W. Douglass, and B. D. Hatfield, ‘‘Cerebral cortical adaptations associated with visuomotor practice,’’ Med. Sci. Sports Exercise,
vol. 36, no. 1, pp. 118–129, Jan. 2004.
[43] T. Schnell, A. Postnikov, and N. Hamel, ‘‘Neuroergonomic assessment
of simulator fidelity in an aviation centric live virtual constructive (LVC)
application,’’ in Proc. 6th Int. Conf., FAC, Held Part HCI Int., Jul. 2011,
pp. 221–230.
[44] T. M. Lau, J. T. Gwin, K. G. McDowell, and D. P. Ferris, ‘‘Weighted phase
lag index stability as an artifact resistant measure to detect cognitive EEG
activity during locomotion,’’ J. Neuroeng. Rehabil., vol. 9, no. 1, pp. 1–9,
Jul. 2012.
[45] J. Vettel, B. Lance, C. Mantueffel, M. Jaswa, M. Cannon, T. Johnson,
V. Paul, and K. Oie, ‘‘Mission-based scenario research: Experimental design and analysis,’’ US Dept. Army, Army Res. Lab., Aberdeen
Proving Ground, Aberdeen, MD, USA, Tech. Rep. ARL-RP-0352,
2012.
[46] B. Lance, J. Canady, and K. Oie, ‘‘Design and functionality of the graphical interacting narrative (Gin) system version 0.2,’’ US Dept. Army, Army
Res. Lab., Aberdeen Proving Ground, Aberdeen, MD, USA, Tech. Rep.
ARL-TR-6076, 2012.
[47] J. Touryan, L. Gibson, J. H. Horne, and P. Weber, ‘‘Real-time measurement of face recognition in rapid serial visual presentation,’’ Frontiers
Psychol., vol. 42, no. 2, pp. 1–9, Feb. 2011.
[48] B. Kellihan, T. J. Doty, W. D. Hairston, J. Canady, K. W. Whitaker,
C.-T. Lin, T.-P. Jung, and K. McDowell, ‘‘A real-world neuroimaging
system to evaluate stress. A translational approach to neurotechnology
development,’’ in Proc. Trans. Approach Neurotechnol. Develop., Symp.
Augmented Cognit., Held Part HCI Int., Apr. 2013, pp. 1–6.

VOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

[49] S. Makeig, T. P. Jung, and T. J. Sejnowski, ‘‘Awareness during drowsiness:
Dynamics and electrophysiological correlates,’’ Can. J. Exp. Psychol.,
vol. 54, no. 4, pp. 266–273, Dec. 2000.
[50] C.-T. Lin and K. McDowell, ‘‘Prolog to the section on neurotechnological
systems: The brain–computer interface,’’ Proc. IEEE, vol. 100, no. 5,
pp. 1551–1552, May 2012.
[51] C. T. Lin, L. W. Ko, C. J. Chang, Y. T. Wang, C. H. Chung, F. S. Yang, J.
R. Duann, T. P. Jung, and J. C. Chiou, ‘‘Wearable and wireless brain–
computer interface and its applications,’’ in Proc. Found. Augmented
Cognit. Neuroergonomics Oper. Neurosci. Conf., 2009, pp. 741–748.
[52] S. Makeig, C. Kothe, T. Mullen, N. Bigdely-Shamlo, Z. Zhang, and
K. Kreutz-Delgado, ‘‘Evolving signal processing for brain–computer
interfaces,’’ Proc. IEEE, vol. 100, no. 5, pp. 1567–1584, May 2012.
[53] C. A. Kothe and S. Makeig, ‘‘Estimation of task workload from EEG data:
New and current tools and perspectives,’’ in Proc. IEEE Annu. Int. Conf.
Eng. Med. Biol. Soc., Sep. 2011, pp. 6547–6551.
[54] C. Grozea, C. D. Voinescu, and S. Fazli, ‘‘Bristle-sensors–low-cost flexible passive dry EEG electrodes for neurofeedback and BCI applications,’’
J. Neural Eng., vol. 8, no. 2, pp. 025005-1–025005-3, Apr. 2011.
[55] Y. M. Chi, T.-P. Jung, and G. Cauwenberghs, ‘‘Dry-contact and noncontact biopotential electrodes: Methodological review,’’ IEEE Rev. Biomed.
Eng., vol. 3, no. 1, pp. 106–119, Jan. 2010.
[56] G. Gargiulo, R. A. Calvo, P. Bifulco, M. Cesarelli, C. Jin, A. Mohamed,
and A. van Schaik, ‘‘A new EEG recording system for passive dry
electrodes,’’ Clinical Neurophysiol., vol. 121, no. 5, pp. 686–693,
May 2010.
[57] C.-T. Lin, L.-D. Liao, Y.-H. Liu, I.-J. Wang, B.-S. Lin, and J.-Y. Chang,
‘‘Novel dry polymer foam electrodes for long-term EEG measurement,’’
IEEE Trans. Biomed. Eng., vol. 58, no. 5, pp. 1200–1207, May 2011.
[58] L. D. Liao, I. J. Wang, S. F. Chen, J. Y. Chang, and C. T. Lin, ‘‘Design,
fabrication and experimental validation of a novel dry-contact sensor
for measuring electroencephalography signals without skin preparation,’’
Sensors, vol. 11, no. 6, pp. 5819–5834, May 2011.
[59] W. D. Hairston, K. W. Whitaker, A. J. Reis, J. M. Vettel, J. C. Bradford, S.
E. Kerick, and K. McDowell, ‘‘Usability of four commercially-oriented
EEG systems,’’ J. Neural Eng., to be published.
[60] B. J. Lance, W. D. Hairston, G. Apker, K. W. Whitaker, G. A. Slipher,
R. A. Mrozek, S. E. Kerick, J. S. Metcalfe, C. Mantufel, M. Jaswa, J.
Canady, and K. McDowell, ‘‘2012 year-end report on eurotechnologies
for in-vehicle applications,’’ US Dept. Army, Army Res. Lab., Aberdeen
Proving Ground, Aberdeen, MD, USA, to be published.
[61] G. A. Slipher, R. A. Mrozek, and J. A. Shumaker, ‘‘Tunable band-pass
filters employing stretchable electronic components,’’ in Proc. ASME
Conf. Smart Mater., Adapt. Struct. Intell. Syst., 2012, pp. 1–4.
[62] G. Slipher, R. Mrozek, K. Whitaker, W. D. Hairston, and W. Nothwang,
‘‘Stretchable conductive elastomers for soldier bio-sensing applications,’’
Dept. U.S. Army Res. Lab., Univ. Aberdeen Proving Ground, Aberdeen,
MD, USA, Tech. Rep. FY13-VTD-009, 2012.
[63] R. Dhiman, J. S. Saini, and A. M. Priyanka, ‘‘Artifact removal from EEG
recordings—An overview,’’ in Proc. NCCI, 2010, pp. 1–6.
[64] V. Lawhern, W. D. Hairston, K. McDowell, M. Westerfield, and K. Robbins, ‘‘Detection and classification of subject-generated artifacts in EEG
signals using autoregressive models,’’ J. Neurosci. Methods, vol. 208,
no. 2, pp. 181–189, Jul. 2012.
[65] J. Vettel, A. Dagro, S. Gordon, S. Kerick, R. Kraft, S. Luo, S. Rawal,
M. Vindiola, and K. McDowell, ‘‘Brain structure-function couplings
(FY11),’’ US Dept. Army, Army Res. Lab., Aberdeen Proving Ground,
Aberdeen, MD, USA, Tech. Rep. ARL-TR-5893, 2012.
[66] S. M. Gordon, P. J. Franaszczuk, W. D. Hairston, M. Vindiola, and
K. McDowell, ‘‘Comparing parametric and nonparametric methods for
detecting phase synchronization in EEG,’’ J. Neurosci. Methods, vol. 212,
no. 2, pp. 247–258, Jan. 2013.
[67] M. Vinck, R. Oostenveld, M. van Wingerden, F. Battaglia, and
C. Pennartz, ‘‘An improved index of phase-synchronization for electrophysiological data in the presence of volume-conduction, noise and
sample-size bias,’’ Neuroimage, vol. 55, no. 4, pp. 1548–1565, Apr. 2011.
[68] M. G. Rosenblum, A. S. Pikovsky, and J. Kurths, ‘‘Phase synchronization
of chaotic oscillators,’’ Phys. Rev. Lett., vol. 76, no. 11, pp. 1804–1807,
Mar. 1996.
[69] S. Makeig, A. J. Bell, T.-P. Jung, and T. J. Sejnowski, ‘‘Independent component analysis of electroencephalographic data,’’ in Proc. Adv. Neural
Inf. Process. Syst. Conf., 1996, pp. 145–151.
[70] I. Winkler, S. Haufe, and M. Tangermann, ‘‘Automatic classification of
artifactual ICA-components for artifact removal in EEG signals,’’ Behavioral Brain Funct., vol. 7, no. 1, pp. 1–30, Aug. 2011.
VOLUME 1, 2013

[71] J. Onton, M. Westerfield, J. Townsend, and S. Makeig, ‘‘Imaging human
EEG dynamics using independent component analysis,’’ Neurosci. Biobehavioral Rev., vol. 30, no. 6, pp. 808–822, 2006.
[72] F. Raimondo, J. E. Kamienkowski, M. Sigman, and D. F. Slezak, ‘‘CUDAICA: GPU optimization of infomax-ICA EEG analysis,’’ Comput. Intell.
Neurosci., vol. 2012, no. 206972, pp. 1–8, 2012.
[73] T. W. Lee, M. S. Lewicki, and T. J. Sejnowski, ‘‘ICA mixture models for unsupervised classification of non-Gaussian classes
and automatic context switching in blind signal separation,’’ IEEE
Trans. Pattern Anal. Mach. Intell., vol. 22, no. 10, pp. 1078–1089,
Oct. 2000.
[74] J. A. Palmer, S. Makeig, K. K. Delgado, and B. D. Rao, ‘‘Newton method
for the ICA mixture model,’’ in Proc. IEEE Int. Conf. Acoust., Speech
Signal Process., Apr. 2008, pp. 1805–1808.
[75] N. Bigdely-Shamlo, A. Vankov, R. R. Ramirez, and S. Makeig, ‘‘Brain
activity-based image classification from rapid serial visual presentation,’’
IEEE Trans. Neural Syst. Rehabil. Eng., vol. 16, no. 5, pp. 432–441,
Oct. 2008.
[76] R. Grandchamp, C. Braboszcz, S. Makeig, and A. Delorme, ‘‘Stability of
ICA decomposition across within-subject EEG datasets,’’ in Proc. IEEE
Annu. Int. Conf. Eng. Med. Biol. Soc., Sep. 2012, pp. 6735–6739.
[77] C. J. Stam, G. Nolte, and A. Daffertshofer, ‘‘Phase lag index: Assessment of functional connectivity from multi channel EEG and MEG with
diminished bias from common sources,’’ Human Brain Mapping, vol. 28,
no. 11, pp. 1178–1193, Nov. 2007.
[78] C. T. Lin, L. W. Ko, J. C. Chiou, J. R. Duann, R. S. Huang, S. F. Liang,
T. W. Chiu, and T. P. Jung, ‘‘Noninvasive neural prostheses using
mobile and wireless EEG,’’ Proc. IEEE, vol. 96, no. 7, pp. 1167–1183,
Jul. 2008.
[79] C.-T. Lin, S.-F. Tsai, H.-C. Lee, H.-L. Huang, S.-Y. Ho, and L.-W. Ko,
‘‘Motion sickness estimation system,’’ in Proc. Int. Joint Conf. Neural
Netw., Jun. 2012, pp. 1–6.
[80] N. Bigdely-Shamlo, A. Vankov, R. R. Ramirez, and S. Makeig, ‘‘Brain
activity-based image classification from rapid serial visual presentation,’’
IEEE Trans. Neural Syst. Rehabil. Eng., vol. 16, no. 5, pp. 432–441,
Oct. 2008.
[81] C. A. Kothe and A. Delorme, ‘‘BCILAB: A new tool for braincomputer interfacing,’’ in Proc. Frontiers Human Neurosci. Conf., 2011,
pp. 1–10.
[82] T. Akerstedt and M. Gillberg, ‘‘Subjective and objective sleepiness in
the active individual,’’ Int. J. Neurosci., vol. 52, nos. 1–2, pp. 29–37,
May 1990.
[83] G. Matthews and P. A. Desmond, ‘‘Personality and multiple dimensions
of task-induced fatigue: A study of simulated driving,’’ Personality Individual Differences, vol. 25, no. 3, pp. 443–458, Sep. 1998.
[84] S. G. Hart and L. E. Staveland, ‘‘Development of NASA-TLX (Task Load
Index): Results of empirical and theoretical research,’’ in Advances in
Psychology, vol. 52, P. A. Hancock and N. Meshkati, Eds. Amsterdam,
The Netherlands: North-Holland, 1988, pp. 139–183.
[85] A. C. Trujillo, ‘‘Evaluation of electronic formats of the NASA task load
index,’’ NASA, Langley Research Center, Hampton, VA, USA, Tech. Rep.
NASA/TM-2011-217166, Aug. 2011.
[86] F. X. Lesage and S. Berjot, ‘‘Validity of occupational stress assessment using a visual analogue scale,’’ Occupational Med., vol. 61, no. 6,
pp. 434–436, Apr. 2011.
[87] T. Rutledge, E. Stucky, A. Dollarhide, M. Shively, S. Jain, T. Wolfson, M. B. Weinger, and T. Dresselhaus, ‘‘A real-time assessment of
work stress in physicians and nurses,’’ Health Psychol., vol. 28, no. 2,
pp. 194–200, Mar. 2009.
[88] W. D. Hairston, ‘‘Accounting for timing drift and variability in contemporary electroencepholography (EEG) systems,’’ US Dept. Army, Army
Res. Lab., Aberdeen Proving Ground, Aberdeen, MD, USA, Tech. Rep.
ARL-TR-5945, 2012.
[89] W. D. Hairston, S. G. Diamond, D. Kynor, and C. Stachowiak, ‘‘Procedure
for overcoming time locking variability in low-cost EEG systems and
demonstration on a realistic head phantom,’’ in Proc. Cognit. Neurosci.
Soc. Conf., Apr. 2012, pp. 1–5.
[90] M. Havranek, N. Langer, M. Cheetham, and L. Jäncke, ‘‘Perspective
and agency during video gaming influences spatial presence experience
and brain activation patterns,’’ Behavioral Brain Functions, vol. 8, no. 1,
pp. 1–34, Jul. 2012.
[91] W. D. Hairston, S. G. Diamond, D. Kynor, and C. Stachowiak, ‘‘Procedure
for overcoming time locking variability in low-cost EEG systems and
demonstration on a realistic head phantom,’’ in Proc. Cognit. Neurosci.
Soc. Conf., Chicago, IL, Apr. 2012.
147

K. McDowell et al.: Real-World Neuroimaging Technologies

[92] W. D. Hairston, ‘‘Accounting for timing drift and variability in contemporary electroencepholography (EEG) systems,’’ US Dept. Army, Army
Res. Lab., Aberdeen Proving Ground, Aberdeen, MD, USA, Tech. Rep.
ARL-TR-5945, 2012.
[93] K. W. Whitaker and W. D. Hairston, ‘‘Assessing the minimum number of
synchronization triggers necessary for temporal variance compensation
in commercial electroencephalography (EEG) systems,’’ US Dept. Army,
Army Res. Lab., Aberdeen Proving Ground, Aberdeen, MD, USA, Tech.
Rep. ARL-TN-0495, 2012.
[94] W. D. Hairston and A. J. Ries, ‘‘Adrift in a sea of data: Assessing the
effects of timing variability and drift on EEG analyses,’’ Soc. Neurosci.
Abstracts, Washington, DC, USA, 2011.
[95] L. Gavit, S. Baillet, J. F. Mangin, J. Pescatore, and L. Garnero, ‘‘A multiresolution framework to MEG/EEG source imaging,’’ IEEE Trans.
Biomed. Eng., vol. 48, no. 10, pp. 1080–1087, Oct. 2001.
[96] K. Miller, K. Chinzei, G. Orssengo, and P. Bednarz, ‘‘Mechanical properties of brain tissue in-vivo: Experiment and computer simulation,’’
J. Biomech., vol. 33, no. 11, pp. 1369–1376, Nov. 2000.
[97] C. K. Looi and Z. N. Chen, ‘‘Design of a human-head-equivalent phantom
for ISM 2.4-GHz applications,’’ Microw. Opt. Technol. Lett., vol. 47, no. 2,
pp. 163–166, Oct. 2005.
[98] R. M. Leahy, J. C. Mosher, M. E. Spencer, M. X. Huang, and J. D. Lewine,
‘‘A study of dipole localization accuracy for MEG and EEG using a human
skull phantom,’’ Electroencephalogr. Clin Neurophysiol., vol. 107, no. 2,
pp. 159–173, Aug. 1998.
[99] N. Patnekar, R. Pradhan, B. Campbell, and N. Tun, ‘‘Development of
a head-shaped neurological simulator for field EEG characterization,’’
in Proc. Conf., Jun. 2012, pp. 1–5.
[100] T. J. Collier, D. B. Kynor, J. Bieszczad, W. E. Audette, E. J. Kobylarz, and
S. G. Diamond, ‘‘Creation of a human head phantom for testing of electroencephalography equipment and techniques,’’ IEEE Trans. Biomed.
Eng., vol. 59, no. 9, pp. 2628–2634, Sep. 2012.
[101] P. Sajda, E. Pohlmeyer, J. Wang, L. C. Parra, C. Christoforou,
J. Dmochowski, B. Hanna, C. Bahlmann, M. K. Singh, and S. F. Chang,
‘‘In a blink of an eye and a switch of a transistor: Cortically coupled
computer vision,’’ Proc. IEEE, vol. 98, no. 3, pp. 462–478, Mar. 2010.
[102] P. Sajda, A. Gerson, and L. Parra, ‘‘High-throughput image search via
single-trial event detection in a rapid serial visual presentation task,’’ in
Proc. IEEE EMBS Conf. Neural Eng. Int., Mar. 2003, pp. 7–10.
[103] K. McDowell, P. Nunez, S. Hutchins, and J. S. Metcalfe, ‘‘Secure mobility and the autonomous driver,’’ IEEE Trans. Robot., vol. 24, no. 3,
pp. 688–697, Jun. 2008.
[104] L. Gibson, J. Touryan, A. J. Ries, K. McDowell, H. Cecotti, and B.
Giesbrecht, ‘‘Adaptive integration and optimization of automated and
neural processing systems-establishing neural and behavioral benchmarks
of optimized performance,’’ US Dept. Army, Army Res. Lab., Aberdeen
Proving Ground, Aberdeen, MD, USA, Tech. Rep. ARL-TR-6055,
2012.
[105] B. Giesbrecht, M. P. Eckstein, and C. K. Abbey, ‘‘Neural decoding of
semantic processing during the attentional blink,’’ J. Vis., vol. 9, no. 8,
pp. 121–124, Aug. 2009.
[106] H. Cecotti, R. W. Kasper, J. C. Elliott, M. P. Eckstein, and
B. Giesbrecht, ‘‘Multimodal target detection using single trial evoked
EEG responses in single and dual-tasks,’’ in Proc. IEEE 27th Annu. Int.
Conf., Sep. 2011, pp. 6311–6314.
[107] S. F. Liang, C. T. Lin, R. C. Wu, Y. C. Chen, T. Y. Huang, and T. P. Jung,
‘‘Monitoring driver’s alertness based on the driving performance estimation and the EEG power spectrum analysis,’’ in Proc. IEEE 27th Annu.
Int. Conf., May 2005, pp. 5738–5741.
[108] G. Yang, Y. Lin, and P. Bhattacharya, ‘‘A driver fatigue recognition model
using fusion of multiple features,’’ in Proc. IEEE Int. Conf. Syst., Man
Cybern., Oct. 2005, pp. 1777–1784.
[109] C. T. Lin, Y. C. Chen, R. C. Wu, S. F. Liang, and T. Y. Huang, ‘‘Assessment
of driver’s driving performance and alertness using EEG-based fuzzy
neural networks,’’ in Proc. IEEE Int. Symp. Circuits Syst., May 2005,
pp. 152–155.
[110] T. P. Jung, K. C. Huang, C. H. Chuang, J. A. Chen, L. W. Ko, T. W. Chiu,
and C. T. Lin, ‘‘Arousing feedback rectifies lapse in performance and
corresponding EEG power spectrum,’’ in Proc. IEEE Annu. Int. Conf.,
May 2010, pp. 1792–1795.
[111] C. T. Lin, K. C. Huang, C. F. Chao, J. A. Chen, T. W. Chiu, L. W. Ko,
and T. P. Jung, ‘‘Tonic and phasic EEG and behavioral changes induced
by arousing feedback,’’ NeuroImage, vol. 52, no. 2, pp. 633–642,
Aug. 2010.

148

KALEB MCDOWELL (SM’11) received the B.S.
degree in operations research and industrial engineering from Cornell University, Ithaca, NY, USA,
in 1992, the M.S. degree in kinesiology and the
Ph.D. degree in neuroscience and cognitive science
from the University of Maryland, College Park,
MD, USA, in 2000 and 2003, respectively.
He is currently the Chief of the Translational
Neuroscience Branch and Chair of the Neuroscience Strategic Research Area, ARL. Since joining ARL in 2003, he has contributed to over 40 peer-reviewed publications,
and has led several major research and development programs focused on
translational neuroscience, indirect vision systems and vehicle mobility.
His current research interests include translating basic neuroscience into
applications for use by healthy populations in everyday, real-world environments. He serves as an Associate Editor on the IEEE Transactions on
Neural Systems and Rehabilitation Engineering and the IEEE Transactions
on Fuzzy Systems. He was the recipient of the Department of Army Research
and Development Achievement Awards for technical excellence in 2007 and
2009 and the ARL Award for Leadership in 2011.

CHIN-TENG LIN (F’05) received the B.S. degree
in control engineering from National Chiao-Tung
University (NCTU), Hsinchu, Taiwan, in 1986, and
the M.S.E.E. and Ph.D. degrees in electrical engineering from Purdue University, West Lafayette,
IN, USA, in 1989 and 1992, respectively. Since
August 1992, he has been with the College of Electrical and Computer Engineering, NCTU, where
he is the Provost and the Chair Professor with
the Department of Electrical Engineering. He has
authored textbook Neural Fuzzy Systems (Prentice Hall). He has authored
over 174 journal papers, including about 86 IEEE transactions papers. His
current research interests include translational neuroscience, computational
intelligent technologies, brain-computer interface, smart living technology,
and robotics.
He was elevated to IEEE Fellow for contributions to biologically inspired
information systems. He was honored with Outstanding Electrical and Computer Engineer (OECE), Purdue University in 2011. He is the IEEE Distinguished Lecturer from 2003 to 2005. He is currently the Editor-in-Chief
(EIC) of the IEEE Transactions on Fuzzy Systems, the Co-EIC of the Journal
of Neuroscience and Neuroengineering, and was the Deputy EIC of the IEEE
Transactions on Circuits and Systems from 2006 to 2007. He is the General
Chair of FUZZ-IEEE 2011 held in Taipei, and was the Program Chair of
the 2006 IEEE International Conference on Systems, Man, and Cybernetics
held in Taipei. He was the president of Board of Government (BoG) of Asia
Pacific Neural Networks Assembly (APNNA) from 2004 to 2005. He has
own the Outstanding Research Award granted by National Science Council
(NSC), Taiwan, since 1997 to present, the Outstanding Professor Award
granted by the Chinese Institute of Engineering (CIE) in 2000, and the Taiwan
Outstanding Information-Technology Expert Award in 2002. He was also
elected to be one of 38th Ten Outstanding Rising Stars in Taiwan in 2000.
He is a member of Tau Beta Pi, Eta Kappa Nu, and Phi Kappa Phi honorary
societies.

VOLUME 1, 2013

K. McDowell et al.: Real-World Neuroimaging Technologies

KELVIN S. OIE
USA,
. He received the B.S.
in kinesiological sciences in 1996, the M.A. in
kinesiology in 1999, and the Ph.D. degree in neuroscience and cognitive sciences in 2006 from the
University of Maryland, College Park, MD, USA.
He is currently serving as a Research Kinesiologist with the US Army Research Laboratory
(ARL), which he joined in December 2004 as part
of the Human Research and Engineering Directorate (HRED). He has authored over 30 journal articles and other technical
publications, and is currently the Lead Scientist and Manager of a multiyear,
multi-organization, basic research program, the Cognition and Neuroergonomics Collaborative Technology Alliance, examining a broad range of
issues related to the fundamental understanding of human neurocognitive
performance in real-world environments. Previously, he has managed over
25M in Army-funded basic and applied research programs and grants, involving over 100 domestic and international scientists, engineers, and students.
His previous research examined visual and sensorimotor performance in
indirect vision operations, and adaptive processes in human multisensory
integration. He was the recipient of the graduate fellowship in 1999 from
the University of Maryland.

TZYY-PING JUNG (SM’06) received the B.S.
degree in electronics engineering from National
Chiao-Tung University, Hsinchu, Taiwan, in 1984,
and the M.S. and Ph.D. degrees in electrical engineering from The Ohio State University, Columbus, OH, USA, in 1989 and 1993, respectively.
He was a Research Associate with the Computational Neurobiology Laboratory, The Salk Institute, La Jolla, CA, USA. He is currently a Research
Scientist and the Co-Director of the Center for
Advanced Neurological Engineering, Institute of Engineering in Medicine,
University of California at San Diego (UCSD), CA. He is also an Associate
Director of the Swartz Center for Computational Neuroscience, Institute for
Neural Computation, and an Adjunct Professor of bioengineering at UCSD.
In addition, he is a Professor of Department of Computer Science, National
Chiao Tung University, Hsinchu. His current research interests include
biomedical signal processing, cognitive neuroscience, machine learning,
time-frequency analysis of human EEG, functional neuroimaging, and brain
computer interfaces and interactions.

STEPHEN GORDON (M’09) received the B.S.
degree in mechanical engineering and electrical
engineering from Tennessee Technological University, Cookeville, TN, USA, in 2003, and the
M.S. and Ph.D. degrees in electrical engineering
from Vanderbilt University in Nashville, TN, USA,
in 2005 and 2009, respectively. He is currently a
Researcher for DCS Corporation, Alexandria, VA,
USA. His current work includes signal processing
methods for EEG data as well as methods for deriving and classifying operator state using both eye tracking and EEG measures.
His current research interests include signal processing and machine learning
with a focus on state classification for use in planning and decision-making.

VOLUME 1, 2013

KEITH W. WHITAKER received the B.S. degree
in neurobiological sciences from the University of
Florida, Gainesville, FL, USA, in 2005. He was
a Lab Manager and Research Assistant at Scripps
Florida before received the Ph.D. degree in neuroscience from the Institute for Neuroscience at The
University of Texas at Austin, TX, USA.
He is currently a Biologist with the Translational
Neuroscience Branch, US Army Research Laboratory (ARL), Aberdeen Proving Grounds, MD,
USA. He has been supported by the US Department of Defense’s Science,
Mathematics and Research for Transformation (SMART) Program since
2007. His current research interests include biomarkers related to human
performance.

SHIH-YU LI
He received the B.S. degree in mechanical and
mechatronic engineering from National Taiwan
Ocean University (NTOU), Keelung, Taiwan, in
2004, the M.S. degree in aeronautics and astronautics engineering from National Cheng Kung University (NCKU), Tainan, Taiwan, in 2006, and the
Ph.D. degree from National Chiao Tung University
(NCTU), Hsinchu, Taiwan, in 2010. He is currently
a Post-Doctoral Fellow with the Brain Research
Center, National Chiao Tung University (NCTU-BRC), Hsinchu. He has
authored 22 SCI journal papers, including one IEEE transactions papers
and 18 Q1 ranking papers. His current interests include biomedical signal
processing, computational intelligence, intelligent fuzzy logic control, chaos
analysis and brain computer interface.

SHAO-WEI LU received the B.S. degree in physics
and the M.S. degree from the Institute of Molecular Medicine, National Tsing-Hua University,
Hsinchu, Taiwan, in 2007. He is currently an
Assistant Researcher with the Brain Research
Center, National Chiao-Tung University, Hsinchu,
where he is involved in electroneurophysiology
and biomedical signal processing.

W. DAVID HAIRSTON received the B.S. degree in
experimental psychology from Appalachian State
University, Boone, NC, USA, in 1999, and the
Masters degree in experimental psychology from
Wake Forest University, Winston-Salem, NC, in
2001, while working as a Technician in neurobiology, where he received the Ph.D. degree in
neurobiology and anatomy in 2006. After serving
as a Post-Doctoral Fellow in WFU Radiology and
the US Army Research Laboratory, he joined the
ARL Human Research and Engineering Directorate in 2009.
He is currently serving as a Neuroscientist for the Translational Neuroscience Branch at ARL. His current research interests include multisensory
integration, developing novel methods for validating neurophysiological
tools, and developing technologies allowing the translation of novel neuroimaging tools into usable formats for real-world environments.

149

