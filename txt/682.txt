EEG based Emotion Recognition of Image Stimuli
1

Girma Neshir Alemneh1 and Prabhat Ranjan2
Addis Ababa University, IT Doctoral Program, Ethiopia
2
Executive Director, TIFAC, New Delhi, India

Introduction
Emotion is playing a great role in our daily lives. The necessity and importance of an automatic Emotion recognition system
is getting increased. Traditional approaches of emotion recognition are based on facial images, measurements of heart rates,
blood pressure, temperatures, tones of voice/speech, etc. However, these features can potentially be changed to fake features.
Thus, to detect hidden and real features that is not controlled by the person are data measured from brain signals. There are
various ways of measuring brain waves: EEG, MEG, FMRI, etc. On the bases of cost effectiveness and performance tradeoffs, EEG is chosen for emotion recognition in this study.
The main aim of this study is to detect emotion based on EEG signal analysis recorded from brain in response to visual
stimuli. The approaches used were the selected visual stimuli were presented to 11 healthy target subjects and EEG signal
were recorded in controlled situation to minimize artefacts (muscle or/and eye movements). The signals were filtered and type
of frequency band was computed and detected.
Brain computer interface(BCI) based Emotion recognition are used in a variety of applications include advertisement, patient
treatment, depression management, music player, human computer interaction, detecting children learning disabilities, assist
disabilities with communication, game playing, automatic addition of emotional pictures during conversation, emotion enabled
avatar, neuromarketing, etc.[1].
To introduce few facts of the human brain, our brain is one of the largest and complex organs of human body. It is the center
of consciousness which enables the human to think, innovate, learn and create that makes human different from other animals.
It is quite challenging to understand how the brain functioning as it is made from million of million neuron cells (around 100
billion nerves) which in turn communicate trillions of connections (called synapses).
This research focus on the outermost layer of human brain which is the cerebral cortex (cerebrum). The cerebrum is broadly
divided in to left and right hemispheres, which are symmetrically nearly equal. Each hemisphere is in turn divided into four
lobes including Frontal lobe, Parietal lobe, Temporal lobe and Occipital lobes. These lobes get their names from the bones of
the skull that overlie them.
Human uses peripheral device such as mouse, keyboards, monitor, etc to interact with the computer whereas brain computer
interface (BCI) is a device that allows the computer to read the human brain neuro-physiological activity and processes to
perform a particular task without using traditional peripheral devices. The typical components of a BCI includes: signal
acquisition, pre-processing, feature extraction and pattern recognitions. Signal acquisition, where the brain activity is recorded,
pre-processing, where filtering, dimensionality reduction and feature extraction is carried out, pattern recognition where the
selected features are used for detecting the target concept in the application. Finally, Post processing could be performed to
instruct a particular device/system. The user might receive feedback from the device/system. For example, human can instruct
the computer to write what he wants based on just sending thought signals from the brain to the computer.
In this research, we use EEG as it is more cost effective with reasonable quality trade-off than other types of neuroimaging
approaches. The other reason is that EEG has capability to handle high temporal resolution and can directly measure the brain
activity (non-invasive) with simple and portable device [2].
The brainwave activity is broadly divided into five frequency bands. The boundary between the frequency bands is not
strict but not varying much. The frequency bands include delta(0.5-4Hz), theta(5-8Hz), alpha(9-12Hz), beta(13-30Hz) and
gamma(above 30Hz) [3]. For this study, EEG data is collected using Emotiv EPOC device with 14 electrodes located at AF3,
F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4. The electrodes are placed according to a 10-20 placement system
with sampling rate of 128Hz [4].
Problems: According to the literature, even though it is possible to measure emotion from EEG signals recorded from
1

stimulated brain in practice, the outputs of BCI related research works are quite different with same stimuli and with brain
response of same or different subjects [5]. The other problem is that parts of the brain that responds to emotion is not clearly
identified or mixed up research results. For example, emotion is responded either or both on Frontal lobe or temporal lobe.
Besides this, the brain wave contains emotion is not clearly known in that whether Alpha frequency band or gamma frequency
band. These are some of the problems to motivates us to work on it.
Research questions: This study attempts to find out answers for the following research questions: (1) What regions of the
brain are associated with visual emotion? (2) Which frequency bands of the brain waves are used for emotion recognition? (3)
How accurately the chosen features were recognizing emotions using machine learning approaches? Due to space limitation
on this report, we tried to present methods and results for answering some of this research questions.

Methods
Data Sets Preparation. We collected and prepared three image data sets for stimuli presentation and classification. These
image data sets include: 90 sample images of Geneva Affective Picture Database (GAPED), 8 Colour images and 36 Indian
company logo images. As classification algorithms require labeled data sets for building models via in supervised training,
we merged class label information for each EEG records of each image stimulus in the data sets.
Hardware and Software Tools: EMOTIV EPOC head sets, Emotiv EPOC TestBench Control panel software and EventIDE
are used for EEG brain activity recording. Emotiv headset is relatively simple to setup, it can uniformly capture brain signal
from almost all regions of cerebral cortex and it is cost effective. Saline was applied to properly hydrate electrodes and fully
contact with the scull.
EventIDE was used to record the Power Spectrum Density (PSD) of all 14 channels along with five frequency bands including:
theta, alpha, low_beta, High_beta and gamma frequency bands. Therefore, the total of 70 channels are recorded for a total
of 11 subjects for each of the three image data sets. These bands are filtered and finally, saved in .csv file format for further
processing. The proposed approach in this study has consists of six stages: image stimulus presentation, subjects, EEG Signal
recordings, Signal Filtering, feature extraction and classification. For pre-processing and building machine learning models,
Weka is used.
Results and Discussion: To answer research question 1 and 2, the top ranked features for each subject are extracted using
Relief algorithm in [6]. The brain frequency bands where it has top ranked features are counted for each subject. On the basis
of this result, 37.5% of the subjects are responded to emotional images with alpha brain waves. The brain frequency bands
and the channel numbers are counted in each of the three experiments on the three data sets. For this study, we build supervised machine learning models implemented in Weka. These includes Bayesian Network, J48(decision tree), Adaboost(meta
learner) and Random forest. After fine tuning the selected machine learning models, it predicts an emotion type (positive/negative) in response to the presented stimuli. Finally, the performance of these models are tested on test sets. The average
accuracy of machine learning algorithms (i.e. J48, Bayes Net, Adaboost and Random Forest) are 78.86, 74.76, 77.82 and
82.46 respectively. In conclusion, we tried to address three key issues. First, we empirically identified the brain regions which
more responsible for emotion. On the basis of feature evaluation result, frontal lobe is more emotionally informative than
other regions of the brain. Second, alpha and theta frequency bands are more discriminative than other brain frequency waves
for emotion recognition. Third, random forest outperformed the other three algorithms (bayes Net, J48 and adaboost) in detecting the customers’ emotion of image stimuli regardless of domain of application and gender. For real world applications,
we have also demonstrated EEG developed machine learning models in the context of neuro-marketing. The results provides
intelligence actions to detect the favourite colour preference of customers in response to the logo colour of an organization or
Service.
Conclusion: This project is an EEG based Emotion recognition of image stimuli where there are a number of challenges including the variability of emotion recognition system that in turn caused by lack of quality in the recording of EEG data due
to the variability among level of attention of subjects, the variability arise in multiple session, the variability caused by muscle
movement, the variability due to machine noise, differing physiology of subjects, differing cognitive patterns and differing
behaviour of subjects [5]. Thus, we tried handle our bests to regulate the causes of variability in EEG data recordings. For
example, besides precautions during recordings, we applied filters for removing artifacts. Thus, we recommended interested
2

researchers to work on EEG based researches in the areas of neuro-marketing, TV ads evaluation, product branding, product
preferences, disability treatment, stress management, just to name a few.

References
[1] Y. Liu, O. Sourina, and M. K. Nguyen, “Real-time eeg-based emotion recognition and its applications,” in Transactions
on computational science XII, pp. 256–277, Springer, 2011.
[2] M. Hedda Šola, “Neuromarketing–science and practice,” FIP-Financije i pravo, vol. 1, no. 1, pp. 25–34, 2013.
[3] “Neuromarketing india.” http://neuromarketing-india.blogspot.com/, 2014.
[4] J. C. Henry, “Electroencephalography: basic principles, clinical applications, and related fields,” Neurology, vol. 67,
no. 11, pp. 2092–2092, 2006.
[5] J. M. Williams, “Deep learning and transfer learning in the classification of eeg signals,” 2017.
[6] S. F. Rosario, K. Thangadurai, et al., “Relief: feature selection approach,” International journal of innovative research
and development, vol. 4, no. 11, pp. 218–224, 2015.

3

