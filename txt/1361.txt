sensors
Article

An EEG-Based Identity Authentication System with
Audiovisual Paradigm in IoT
Haiping Huang 1,2,3, * , Linkang Hu 1,2 , Fu Xiao 1,2 , Anming Du 1,2 , Ning Ye 1,2 and Fan He 1,2
1

2
3

*

College of Computer, Nanjing University of Posts and Telecommunications, Nanjing 210023, China;
1216042916@njupt.edu.cn (L.H.); xiaof@njupt.edu.cn (F.X.); 1216042915@njupt.edu.cn (A.D.);
yening@njupt.edu.cn (N.Y.); 1016041130@njupt.edu.cn (F.H.)
Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing 210023, China
College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics,
Nanjing 210016, China
Correspondence: hhp@njupt.edu.cn

Received: 27 February 2019; Accepted: 3 April 2019; Published: 8 April 2019




Abstract: With the continuous increment of security risks and the limitations of traditional modes,
it is necessary to design a universal and trustworthy identity authentication system for intelligent
Internet of Things (IoT) applications such as an intelligent entrance guard. The characteristics of
EEG (electroencephalography) have gained the confidence of researchers due to its uniqueness,
stability, and universality. However, the limited usability of the experimental paradigm and the
unsatisfactory classification accuracy have so far prevented the identity authentication system based
on EEG to become commonplace in IoT scenarios. To address these problems, an audiovisual
presentation paradigm is proposed to record the EEG signals of subjects. In the pre-processing stage,
the reference electrode, ensemble averaging, and independent component analysis methods are used
to remove artifacts. In the feature extraction stage, adaptive feature selection and bagging ensemble
learning algorithms establish the optimal classification model. The experimental result shows that
our proposal achieves the best classification accuracy when compared with other paradigms and
typical EEG-based authentication methods, and the test evaluation on a login scenario is designed to
further demonstrate that the proposed system is feasible, effective, and reliable.
Keywords: EEG; IoT; brainwaves; identity authentication; audiovisual paradigm; bagging ensemble
learning

1. Introduction
The rapid development of smart sensing devices, wireless communications, and mobile intelligent
computing has prompted potential applications of Internet of Things (IoT) [1,2]; however, security
issues have always been one of the concerns of IoT applications. Intelligent access control and identity
authentication, which benefit from the close technological convergence of novel IoT terminals and
machine learning, have emerged as indispensable components in some IoT applications such as the
smart home, intelligent building, or safeguards for the purpose of security enhancement [3,4]. For
example, the fully automatic private residence must verify the visitor’s authentication to ensure that all
the unapproved entrances are prohibited. In order to achieve such an intelligent identity authentication,
novel IoT devices and machine learning methods will be employed, which can facilitate intelligently
sensing and processing data or signals collected from the environment.
However, in traditional IoT applications, the prevalent methods for identity authentication include
user passwords, device PINs, and RF cards. These authentication methods face the risks of being easily
stolen, lost, or forgotten after passwords are updated. With the development of intelligent biometric

Sensors 2019, 19, 1664; doi:10.3390/s19071664

www.mdpi.com/journal/sensors

Sensors 2019, 19, 1664

2 of 21

authentication technologies, fingerprint recognition, gesture recognition, iris recognition, and facial
feature recognition [5–8] have successively emerged in IoT application scenarios such as the smart
home. Although these authentication methods utilize unique biometrics to improve security, they
still suffer from the following challenges: (1) biological features can be replicated, which provides
opportunities for attackers to deceive the current entrance guard system; (2) once body parts that carry
these characteristics are damaged, recognition cannot be conducted in intelligent building; (3) it has
some limitations for different types of visitors; for example, the disabled with no arms cannot use
fingerprint recognition to open a door, and the blind cannot be identified by the iris.
In order to address the above problems, researchers have begun to focus on the novel IoT devices
based on electroencephalography (EEG) signals [9], which can be used to authenticate in intelligent
entrance systems for home or industry [10]. First, EEG signals are generated from the brain, and
cannot be copied or stolen by current technologies. Second, since the individual’s brainwave is greatly
affected by specific pressures or stimuli [11], an imposter‘s brainwave activities are usually ineffective.
Furthermore, the brainwave has many special properties, such as high time resolution and high
uniqueness [12]. Therefore, the authentication method based on EEG signal devices has significant
advantages over the traditional authentication methods, and it can be applied in more reliable IoT
authentication system based on machine learning technology [13].
Currently, the studies on EEG identity authentication are mainly divided into two categories: the
methods focus on EEG signals generated by subjects who perform a simple task in a relaxed state,
and those that focus on the EEG signals when subjects are stimulated by other external signals. The
former not only brings signal interference, but also accelerates the subject’s fatigue, which causes the
authentication accuracy to be much lower than the latter. Therefore, the latter is the concern of this
paper. In addition, external stimulus signals may be single visual signals, such as images, text, and
short video; and single auditory signals, such as shouts, whistles, and music pieces. These single
stimuli signals have limitations for different types of visitors; for example, it is useless for visitors with
visual or hearing impairments. Therefore, we aim at to design an EEG-based identity authentication
system with an audiovisual paradigm including both visual and auditory signals.
The contributions of this paper can be summarized as follows:
1.

2.

3.

Aiming at the deficiency of current EEG-based identity authentication methods, it proposes an
audiovisual paradigm combining visual and auditory stimuli for an IoT application scenario. It
can increase the stimulating intensity and then improve the recognition accuracy of visitors for
an intelligent entrance system for home or industry.
Intelligent processing based on the collected EEG signals: in the pre-processing phase, aiming at
the noise signals, reference electrodes, ensemble averaging, and independent component analysis
(ICA) are adopted to remove artifacts; in the feature selection phase, an adaptive selection
method is designed to void extracting invalid feature data, and the best-first search algorithm is
performed to determine the optimal feature subset; in the classification recognition phase, the
bagging ensemble learning method is executed to establish the best classification model based on
naïve Bayes, logistic regression, and the back propagation (BP) neural network.
We evaluate the classification performance of three experimental paradigms through an analysis
and comparison of the accuracy rate, precision rate, and false positive for each subject, and we
verify the superiority of the audiovisual paradigm. Besides, our proposal is compared with other
typical EEG-based systems based on the same dataset; the experimental results show that our
proposal achieves better classification accuracy. Finally, in order to test the attack capacity of the
impostor on the identity authentication, we simulated a login scenario of the intelligent entrance
system, and the result demonstrates that our proposed EEG authentication system is feasible,
secure, and reliable.

The remainder of this paper is organized as follows. Section 2 provides an overview of related
work. Section 3 describes the test design and the experimental paradigm based on the intelligent

Sensors 2019, 19, 1664

3 of 21

entrance authentication system. The detailed system design and solution is present in Section 4,
which includes the process of signal acquisition, pre-processing, feature selection, and classification
recognition. The experimental evaluation and analysis are shown in Section 5. Finally, Section 6
concludes the whole paper.
2. Related Work
A series of experimental methods for detecting the characteristics of brainwaves under different
conditions have appeared since the 1990s, which also have been used in IoT applications such as
intelligent door monitoring and smart home. Their safety and reliability depend on the uniqueness
of brainwave characteristics. As mentioned above, the current studies on EEG-based identity
authentication can be mainly divided into two categories.
The first type is absorbed in the EEG signal’s generation, which requires subjects to carry out
simple tasks in a relaxed state. Paranjape et al. [14] proposed recording EEG signals via a simple
eyes-closed/eyes-open task in the relaxed state, and then realizing the biologic features recognition
by establishing an autoregressive model. The experimental results achieved an average classification
accuracy of 80%. Poulos et al. [15] also used an autoregressive model and the support vector
quantization of brainwaves to achieve an accuracy of 84% when subjects performed a simple task in a
relaxed state. Lan et al. [12] realized the authentication of 10 subjects for one access control system
with the feature extraction and classification method CNN (convolutional neural network). Relying on
the strong generalization and robustness of CNN, the experimental results showed that the recognition
accuracy can reach up to 88% and 86% for eyes-closed (EC) and eyes-open (EO) tasks, respectively.
Maiorana et al. [16] took a different approach by focusing on the analysis of a longitudinal database
which is composed of the EEG traits in a resting state with both EC and EO; the results achieved an
average classification accuracy of 85.6%.
The second EEG signal’s collection is based on the stimulus of external signals to subjects.
Chen et al. [9] proposed an EEG login system based on rapid visual presentation. The tests let
subjects quickly browse the randomly selected target images, and then classification was achieved
through shrinkage discriminant analysis. The test results showed that the average classification
accuracy could reach to 77.5 ± 5.9%. Gui et al. [17] proposed an experimental paradigm that required
the subjects to silently read the correct words, wrong words, acronyms, and their own names. It
extracted frequency features through wavelet packet decomposition and achieved classification via
neural networks; it obtained an average accuracy of 90%. Palaniappan et al. [18] used visual evoked
potentials to identify users with 90% average classification accuracy. They designed an experimental
task where the images were presented in grayscale, and then analyzed the power variation in the
gamma band.
According to previous studies, the recognition efficiency relying on the visual paradigm is better
than that relying on the eyes-closed/eyes-open task, which is most likely because it will increase the
signal noise when performing the eyes-closed/eyes-open task. However, these visual paradigms
still have some defects in highly reliable IoT applications. For example, as to the experimental
method of silent reading proposed by Gui et al., visual presentation cannot be realized if the
authenticated user has dyslexia. In the rapid visual presentation experiment proposed by Chen et al.,
the identity authentication cannot be performed if the visitor is an achromate. In view of the above
problems, an intelligent EEG identity authentication system based on audiovisual paradigm will be
proposed, and these problems will be addressed well through intelligent data processing and machine
learning algorithms.
3. Test Design and Experimental Paradigm
As shown in Figure 1, the automatic entrance authentication system used in intelligent building
is one of the most appropriate IoT application scenarios to verify the EEG-based design with an
audiovisual paradigm. This scenario needs advanced brainwave signal devices that support Bluetooth

Sensors 2019, 19, x FOR PEER REVIEW
Sensors 2019, 19, 1664

4 of 20

4 of 21

Bluetooth 4.0 wireless communication [19], which is suitable for houses and buildings due to the
characteristics
of short-range[19],
andwhich
low-power
consumption.
The buildings
entrance due
authentication
system can
4.0 wireless communication
is suitable
for houses and
to the characteristics
also
support the
signal
receivers.The
In entrance
addition,authentication
the machinesystem
learning
model
will be
of short-range
andBluetooth
low-power
consumption.
can also
support
integrated
in the
IoTreceivers.
scenario In
in addition,
order to the
achieve
precise
EEGmodel
feature
and in
satisfactory
the Bluetooth
signal
machine
learning
willmatching
be integrated
the IoT
scenario in order
to achieve precise EEG feature matching and satisfactory authentication accuracy.
authentication
accuracy.

Figure
(EEG)-based
authentication
systemsystem
in Internet
of Thingsof(IoT)
scenario.
Figure1.1.Electroencephalography
Electroencephalography
(EEG)-based
authentication
in Internet
Things
(IoT)

scenario.

In this scenario, the individual authentication of visitors depends on the high uniqueness of
brainwave signals. However, it is difficult to extract the distinctive features of brainwaves. In order
In this scenario, the individual authentication of visitors depends on the high uniqueness of
to address this problem, we design the following experimental paradigm for an individual subject
brainwave signals. However, it is difficult to extract the distinctive features of brainwaves. In order
(visitor): induce the generation of the subject’s brainwave signals through watching their own face
to address this problem, we design the following experimental paradigm for an individual subject
images and listening to the voice of their own name.
(visitor):
the generation
the subject’s
brainwave
signalsbythrough
watching
own face
At induce
the initialization
phase,ofthree
target sources
are selected
the subject,
and 12their
non-target
images
and
to the
voice by
of their
own name.
sources
arelistening
randomly
selected
the entrance
system from the material library. Each target
At
the
initialization
phase,
three
target
sources
selected
by their
the subject,
and while
12 non-target
source consists of the subject’s own face image
and are
a voice
calling
own name,
each
sources
are randomly
selected
by the
entrance
system
material
library.the
Each
target
source
non-target
source involves
another
arbitrary
subject’s
facefrom
imagethe
and
a voice calling
other
arbitrary
consists
of
the
subject’s
own
face
image
and
a
voice
calling
their
own
name,
while
each
non-target
subject’s name.
sourceAccording
involves another
arbitrary
subject’s face
image[20],
and the
a voice
calling
theprobability
other arbitrary
subject’s
to studies
of event-related
potentials
lower
that the
of a target
name.
stimulus appears, the greater the positive amplitude of the generated brainwave will be. Therefore, in
According
to the
studies
of event-related
[20], the
lowerare
that
the probability
of aown
target
order
to enhance
stimulation
intensity ofpotentials
the experiment,
subjects
required
to select their
face image
for different
periods
the target
stimuli. After
that,
the subject
needs to wait
start
stimulus
appears,
the greater
theaspositive
amplitude
of the
generated
brainwave
will for
be. the
Therefore,
of the
experiment.
will be intensity
a short break
at the
end of eachsubjects
experimental
paradigm,
each
insign
order
to enhance
the There
stimulation
of the
experiment,
are required
to and
select
their
break
consists
two
phases.periods
During as
thethe
firsttarget
phase,
the subject
askedthe
to subject
enter theneeds
number
of target
own
face
imageof
for
different
stimuli.
Afteris that,
to wait
for the
sources
theyexperiment.
count. This phase
merely
improving
but not
using
start
signthat
of the
There iswill
be aaimed
short at
break
at the the
endsubject’s
of eachattention,
experimental
paradigm,
theeach
input
to doconsists
any further
analysis.
During
thethe
second
phase, the
the subject
subject can
enjoytoscenery
pictures
and
break
of two
phases.
During
first phase,
is asked
enter the
number
and
have
a
30-s
rest
with
eyes
closed
at
the
end
of
each
paradigm,
in
order
to
relieve
the
fatigue
causedbut
of target sources that they count. This phase is merely aimed at improving the subject’s attention,
byusing
the large
number
of stimuli
fromanalysis.
images and
voice.
thephase,
subjectthe
can
close their
eyes scenery
for a
not
the input
to do
any further
During
theThen,
second
subject
can enjoy
moment
until
hearing
the
sound
of
“bi”.
When
the
end
sign
is
observed,
the
experiment
is
over.
pictures and have a 30-second rest with eyes closed at the end of each paradigm, in order to This
relieve
experimental paradigm is implemented by the psychology experiment software E-Prime2.0, and data
the fatigue caused by the large number of stimuli from images and voice. Then, the subject can close
analysis is carried out via the EEGLAB toolbox.

their eyes for a moment until hearing the sound of “bi”. When the end sign is observed, the
experiment
over. Design
This experimental
4. DetailedisSystem
and Solutionparadigm is implemented by the psychology experiment
software E-Prime2.0, and data analysis is carried out via the EEGLAB toolbox.
Based on the experimental scenario of the audiovisual-inducing paradigm in Figure 1, the
system may be composed of a registration subsystem, login subsystem,
4.entrance
Detailedauthentication
System Design
and Solution
and authentication subsystem, whose functions are shown in Figure 2.

Based on the experimental scenario of the audiovisual-inducing paradigm in Figure 1, the
entrance authentication system may be composed of a registration subsystem, login subsystem, and
authentication subsystem, whose functions are shown in Figure 2.
In the registration phase, the first step is to acquire the signals. The subject selects the target
source stimuli as a password, records the EEG signals that respond to the target source stimulus via
the EEG device, and sends the EEG signal data to the terminal via a wireless Bluetooth module for
further processing. The EEG signals are divided into target sources and non-target sources. Then, the

classified according to their respective source tags (A, B,..., G) and the machine learning model. Both
processes of pre-processing and feature extraction are the same as those in the registration phase.
After that, these signals with tags need to be grouped into a target source and non-target source.
In the authentication phase, according to the above grouping, the extracted target features will
be matched
Sensors
2019, 19,with
1664 the registered user’s target features in the database. If it matches successfully, access
5 of 21
is granted; otherwise, access is denied.

Figure 2. Three subsystems contained in the entrance authentication system.
Figure 2. Three subsystems contained in the entrance authentication system.

In the registration phase, the first step is to acquire the signals. The subject selects the target
4.1. Signal Acquisition
source stimuli as a password, records the EEG signals that respond to the target source stimulus via
The device,
raw EEG
signals
from
30 to
adult
subjects (18
and Bluetooth
12 females,module
their ages
the EEG
and
sendsare
thecollected
EEG signal
data
the terminal
via males
a wireless
for
range from
21 to 45,The
the EEG
average
age are
is 27.97,
andinto
the target
average
deviation
is 6.49), who
will become
further
processing.
signals
divided
sources
and non-target
sources.
Then, the
visitors
to the intelligent
building
entrance
system. None
of them has aand
case
history
of brain injury
or
target
features
and non-target
features
are extracted
by pre-processing
feature
extraction.
In order
brain
disease.
a subjectofisthe
being
authenticated,
29 other
subjects
can be randomly
selected
as
to
evaluate
theWhen
performance
system,
some of these
features
are considered
as training
feature
impostors.
As shown
in the
bottom
leftsets.
corner
of Figure
1, thefeature
“EMOTIV
EPOC+
EEG” head-worn
sets,
and others
are used
as test
feature
Finally,
the target
data set
and source
tag will be
device in
is employed
as a novel IoT device, which has a total of 14 channels, namely: AF3, AF4, F3, F4,
stored
the database.
F7, F8,
FC6,phase,
T7, T8,EEG
P7, signals
P8, O1, responding
and O2. Thetosampling
is 128
Hz,
the signals
can
In FC5,
the login
multiple frequency
source stimuli
will
beand
recorded
and then
generate 128
sampletopoints
per second
per channel.
Compared
64-channel
EEGmodel.
head-worn
classified
according
their respective
source
tags (A, B,...,
G) andto
thethe
machine
learning
Both
device, theofequipment
usedand
in the
experimental
is lighter,
simple
to registration
wear, easierphase.
to use,After
and
processes
pre-processing
feature
extractionscenario
are the same
as those
in the
easier
to
popularize.
Figure
1
also
shows
the
software
interface
for
brain
signal
processing.
that, these signals with tags need to be grouped into a target source and non-target source.
In the authentication phase, according to the above grouping, the extracted target features will be
4.2. Pre-Processing
and Data Analysis
matched
with the registered
user’s target features in the database. If it matches successfully, access is
granted; otherwise, access is denied.
4.2.1. EEG Signal Denoising
4.1. Signal Acquisition
Due to the noise interference from raw EEG signals, such as EOG (electrooculography), power
frequency,
EMG
and 30
ECG
(electrocardiography),
ensemble
average
and
The raw
EEG (electromyography),
signals are collected from
adult
subjects (18 males and
12 females,
their ages
independent
analysisage
(ICA)
are adopted
to pre-process
theiscollected
EEG
signals
in the
range
from 21component
to 45, the average
is 27.97,
and the average
deviation
6.49), who
will
become
experiment.
visitors
to the intelligent building entrance system. None of them has a case history of brain injury or
is theWhen
most aobvious
noise
affecting EEG
In the experiment,
the AF3
and AF4
brainEOG
disease.
subject blink
is being
authenticated,
29signals.
other subjects
can be randomly
selected
as
channels are
tothe
thebottom
blink ofleft
thecorner
subjects,
so these
two“EMOTIV
channels EPOC+
are usedEEG”
as the
reference
impostors.
Assensitive
shown in
of Figure
1, the
head-worn
channelisfor
blink detection.
The
signal
whose
maximum
value
thenamely:
threshold
value
of F3,
75 uV
device
employed
as a novel
IoT
device,
which
has a total
of 14exceeds
channels,
AF3,
AF4,
F4,
willF8,
be FC5,
excluded,
so as
reduce
theand
disturbance
by frequency
blink. However,
this and
traditional
method
F7,
FC6, T7,
T8,toP7,
P8, O1,
O2. The caused
sampling
is 128 Hz,
the signals
can
generate 128 sample points per second per channel. Compared to the 64-channel EEG head-worn
device, the equipment used in the experimental scenario is lighter, simple to wear, easier to use, and
easier to popularize. Figure 1 also shows the software interface for brain signal processing.
4.2. Pre-Processing and Data Analysis
4.2.1. EEG Signal Denoising
Due to the noise interference from raw EEG signals, such as EOG (electrooculography),
power frequency, EMG (electromyography), and ECG (electrocardiography), ensemble average and

Sensors 2019, 19, 1664

6 of 21

independent component analysis (ICA) are adopted to pre-process the collected EEG signals in
the experiment.
EOG is the most obvious blink noise affecting EEG signals. In the experiment, the AF3 and AF4
channels are sensitive to the blink of the subjects, so these two channels are used as the reference
channel for blink detection. The signal whose maximum value exceeds the threshold value of 75 uV
will be excluded, so as to reduce the disturbance caused by blink. However, this traditional method
based on peak amplitude is unsuitable, because the change of the baseline voltage may cause the false
and missed report. To address this issue, a peak-to-peak amplitude detection method is proposed,
which measures the difference between the maximum and the minimum within the signal segment,
and then compares the peak-to-peak voltage with the threshold voltage. This method is less likely
to be distorted by the slow change of baseline voltage, which improves the sensitivity of the artifact
correction process.
Secondly, for the interference caused by the power frequency and non-experimental stimulus, we
adopt the ensemble averaging method to average the amplitudes [21]. The trend of the acquired EEG
signal is a deterministic process, and that of the noise signal is an independent non-stationary process.
It can be seen that after n times of stacking, the EEG-evoked potential value remains unchanged, while
the noise signal is approximately zero. The calculation process is shown in Equation (1):
x (t) =

1 n
1 n
xi (t) = e(t) + ∑ Ni (t) = e(t)
∑
n i =1
n i =1

√
SNR =

σ2 /

p

σ2 /n =

√

n

(1)

(2)

In Equation (1), e(t) is the denoised EEG signal set, Ni(t) is the noise signal, and x(t) is the ensemble
average of the actual observed EEG signals xi (t) for n times. In Equation (2), SNR is the signal-to-noise
ratio, σ2 is the variance of each observation signal, σ2 /n is the ensemble average evoked response
√
variance, and the signal-to-noise ratio is increased by n times.
Although the ensemble average is a simple signal processing method, it is efficient because the
standard deviation of noise after the average is obviously reduced. In the experiment, the EEG signals
is ensemble averaged eight times, and the SNR is increased by a factor of 2.8.
Both EMG and ECG signals are the most unique and intractable noise signals. Therefore, the
independent component analysis (ICA) method is employed to deal with them [22]. In this process,
independent signal sources are mixed by the mixing matrix to obtain actual observation records of
EEG signals. However, in practice, we only know the observed signals, while the mixing matrix and
independent signal sources are unknown. ICA can separate components of independent signal sources
from observed signals under the premise that the mixed matrix and independent signal sources are
unknown. Therefore, pure EEG signals, EMG signals, and ECG signals can be distinguished. ICA can
be achieved via the EEGLAB toolbox.
Figure 3a gives three segments of the original EEG waveforms within one sampling period. We
can see that the raw EEG signals contain a lot of noise, since the signals change rapidly. Figure 3b
shows the curves after ensemble averaging. It can be seen that the averaged signals are much smoother
than the raw data.
4.2.2. Differential Analysis of EEG Data
We completed the above experimental paradigm analysis on all of the subjects (visitors) where
one impostor is randomly selected for each subject. Due to the space limitations, we only show the
experimental results of two subjects and their corresponding impostors. The valid subjects a, b and
their impostors fa, fb respectively perform the above-mentioned experiment, in which a, b select their
own information as the target source, while the impostors fa, fb select the information of a, b as their
target sources. The two types of event-related potentials can be obtained from Figures 4 and 5, where
the brainwave activity mappings of target and non-target source stimulation from valid subjects and

Both EMG and ECG signals are the most unique and intractable noise signals. Therefore, the
independent component analysis (ICA) method is employed to deal with them [22]. In this process,
independent signal sources are mixed by the mixing matrix to obtain actual observation records of
EEG signals. However, in practice, we only know the observed signals, while the mixing matrix and
Sensors 2019, 19, 1664
7 of 21
independent
signal sources are unknown. ICA can separate components of independent signal
sources from observed signals under the premise that the mixed matrix and independent signal
sources
are unknown.
Therefore,
EEG
signals,
signals,
and
signals
can be
their corresponding
impostors
can be pure
depicted
through
theEMG
EEGLAB
tool. In
fact,ECG
by the
observation
of
distinguished.
ICA
can
be
achieved
via
the
EEGLAB
toolbox.
the brainwave activity mapping, the color change of the gradient pole (i.e., vertical bar in Figure 4) can
Figure 3aThe
gives
three segments
of thewave
original
EEG
waveforms
sampling period.
be recorded.
amplitude
of the brain
in the
current
region,within
whichone
is represented
by the We
red
can
see
that
the
raw
EEG
signals
contain
a
lot
of
noise,
since
the
signals
change
rapidly.
Figure 3b
color, shows a high-value state. On the contrary, the blue color represents the state in which amplitude
shows
curves
afterthe
ensemble
canfigures
be seen
that the the
averaged
are much
is low. the
Among
which
number averaging.
at the top ofItthe
represents
currentsignals
timestamp
of the
Sensors 2019, 19, x FOR PEER REVIEW
7 of 20
smoother
than
the
raw
data.
Sensors
2019,
19,
x
FOR
PEER
REVIEW
7 of 20
brainwave activity mapping.

Amplitude(uV)

Amplitude(uV)

own
as the target source, while the impostors
fa,
10
50 as the target source, while the impostors
own information
information
fa, fb
fb select
select the
the information
information of
of a,
a, bb as
as their
their
0
0
target
sources.
The
two
types
of
event-related
potentials
can
be
obtained
from
Figures
4
and
5,
where
target sources.-50
The
two
types
of0.6event-related
potentials
-10 can be obtained from Figures 4 and 5, where
0
0.2
0.4
0.8
1
0 source
0.2
0.4
0.6
0.8
1
the
the brainwave
brainwave activity
activity mappings
mappings of
of target
target and
and non-target
non-target
source stimulation
stimulation from
from valid
valid subjects
subjects and
and
50
10
0
0 the EEGLAB tool. In fact, by the observation
their
corresponding
impostors
can
be
depicted
through
-10
their corresponding
impostors
can
be
depicted
through
the
EEGLAB
tool.
In
fact,
by
the
observation
-50
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4 pole
0.6 (i.e.,
0.8 vertical
1
of
activity
mapping,
the
color
change of the
gradient
bar in Figure 4)
of the
the brainwave
brainwave
50 activity mapping, the color change of10the gradient pole (i.e., vertical bar in Figure 4)
0 The amplitude of the brain wave in the
0 current region, which is represented by the
can
be
recorded.
can be recorded.
-10 current region, which is represented by the
-50 The amplitude of the brain wave in the
0 a high-value
0.2
0.4
0.6
0.8On the
1
0the blue
0.2
0.4
0.6
0.8
1 the state in which
red
color,
shows
state.
contrary,
color
represents
Time(s) represents the state in which
Time(s)state. On the contrary, the blue color
red color, shows a high-value
amplitude
which
number
of
the
represents
the
current
(a) Among
the
original
EEGthe
waveforms
(b)top
EEG
ensemble
average
amplitude is
is low.
low.
Among
which
the
number at
at the
the
top
ofwaveforms
the figures
figuresafter
represents
the
current timestamp
timestamp
of
the
brainwave
activity
mapping.
of the brainwave activity mapping.
Figure
Figure 3.
3. Comparison
Comparison of
of the
the original
original brain
brain wave
wave and
and denoising
denoising brain
brain wave.

4.2.2. Differential Analysis of EEG Data
We completed the above experimental paradigm analysis on all of the subjects (visitors) where
one impostor is randomly selected for each subject. Due to the space limitations, we only show the
experimental results of two subjects and their corresponding impostors. The valid subjects a, b and
their impostors fa, fb respectively perform the above-mentioned experiment, in which a, b select their
(a) Brainwave activity mapping from valid subject a (b) Brainwave activity mapping from impostor fa
(a) Brainwave activity mapping from valid subject a (b) Brainwave activity mapping from impostor fa
Figure 4. Brainwave activity mapping of target and non-target source stimulation from subject a and
Figure
Figure 4.
4. Brainwave activity mapping of target and non-target source stimulation from
from subject
subject aa and
and
his corresponding impostor fa.
his
his corresponding
corresponding impostor
impostor fa.
fa.

(a) Brainwave activity mapping from valid subject b (b) Brainwave activity mapping from impostor fb
(a) Brainwave activity mapping from valid subject b (b) Brainwave activity mapping from impostor fb
Figure 5. Brainwave activity mapping of target and non-target source stimulation from subject b and
Figure 5. Brainwave activity mapping of target and non-target source stimulation from subject b and
his corresponding
corresponding impostor
impostor fb.
fb.
his corresponding impostor fb.

As
shown in
in Figures44and
and 5,the
the brainwaves
of valid
subjects ba,have
b have different
responsesthe
to
As
As shown
shown in Figures
Figures 4 and 5,
5, the brainwaves
brainwaves of
of valid
valid subjects
subjects a,
a, b have different
different responses
responses to
to the
the
target sources
and non-target
the non-target sources.
On the contrary,
althoughimpostors
the impostorsfamiliar
are familiar
target
target sources
sources and
and the
the non-target sources.
sources. On
On the
the contrary,
contrary, although
although the
the impostors are
are familiar with
with
with
the
target
source
information
of
the
valid
subjects,
their
brainwaves
have
no
significant
difference
the
the target
target source
source information
information of
of the
the valid
valid subjects,
subjects, their
their brainwaves
brainwaves have
have no
no significant
significant difference
difference
between
the target
sources and
non-target sources.
In view
of this,this,
event-related potentials
can be used
between
between the
the target
target sources
sources and
and non-target
non-target sources.
sources. In
In view
view of
of this, event-related
event-related potentials
potentials can
can be
be
as
the
basis
for
feature
extraction.
used
as
the
basis
for
feature
extraction.
used as the basis for feature extraction.
4.3.
Pre-Processing and
Data Analysis
4.3.
4.3. Pre-Processing
Pre-Processing and
and Data
Data Analysis
Analysis
For
the
classification
of
EEG
signals, the
concern
is to
extract highly
reliable feature
data
from
For
the
of
EEG
the
concern
highly
feature
data
For channels
the classification
classification
ofintervals.
EEG signals,
signals,
theneurophysiologic
concern is
is to
to extract
extract
highly reliable
reliable
feature caused
data from
from
selected
and
time
Due
to
phenomena,
the
potentials
by
selected
channels
and
time
intervals.
Due
to
neurophysiologic
phenomena,
the
potentials
caused
by
selected
channels
and
time
intervals.
Due
to
neurophysiologic
phenomena,
the
potentials
caused
by
the
self-sourced
and
non-self-sourced
stimuli
may
appear
significant
differences
in
amplitude
from
a
the
self-sourced
and
non-self-sourced
stimuli
may
appear
significant
differences
in
amplitude
from
the
self-sourced
and
non-self-sourced
stimuli
may
appear
significant
differences
in
amplitude
from
sampling
point.
However,
due to
thetounpredictability
of the cerebral
cortex,
there
may there
exist differences
aa sampling
point.
However,
due
unpredictability
of
the
cerebral
cortex,
may
sampling
point.
However,
due
to the
the
unpredictability
ofthis
theissue,
cerebral
cortex,
there correlation
may exist
exist
for
each
channel
and
each
time
interval.
In
order
to
overcome
the
point
biserial
differences
for
each
channel
and
each
time
interval.
In
order
to
overcome
this
issue,
the
point
biserial
differencesmethod
for eachischannel
and
each
time interval.
In order channels
to overcome
issue,
the point
biserial
coefficient
adopted
toadopted
determine
the brainwave
andthis
time
intervals
for specific
correlation
coefficient
method
is
to
determine
the
brainwave
channels
and
time
intervals
for
correlation
coefficient
method
is
adopted
to
determine
the
brainwave
channels
and
time
intervals
for
subjects
[23].
specific
subjects
[23].
specific subjects [23].

4.3.1.
4.3.1. Calculation
Calculation of
of the
the Point
Point Biserial
Biserial Correlation
Correlation Coefficient
Coefficient
It
can
be
seen
from
Figure
6
that
there
is
a
significant
It can be seen from Figure 6 that there is a significant difference
difference between
between the
the target
target feature
feature and
and
the
the non-target
non-target feature,
feature, and
and the
the point
point biserial
biserial correlation
correlation coefficient
coefficient can
can accurately
accurately reflect
reflect the
the

r (t ) =

n1n2 m1 (t ) − m2 (t )
⋅
n1 + n2
S (t )

(3)

where T is the length of each trial (t∈{1,...,T}), and n1 and n2 represent the number of samples of
the target
trials
Sensors
2019, 19,
1664and non-target trials, respectively. m1(t) and m2(t) represent the mean values of
8 ofthe
21
potentials of all the target trials and those of all the non-target trials at time t, respectively. S(t)
represents the standard deviation (the total sum of distance of each potential deviating from the
4.3.1.
mean)Calculation
at time t. of the Point Biserial Correlation Coefficient
tofrom
Equation
the larger
value is an
important
metricthe
for target
selecting
the and
channel
ItAccording
can be seen
Figure(3),
6 that
there isr(t)
a significant
difference
between
feature
the
and time interval.
For the
eachpoint
channel,
thecorrelation
mean square
value ofcan
r(t)accurately
in T time reflect
interval
be sorted in
non-target
feature, and
biserial
coefficient
thewill
discrimination
descending
order.sample
Then, the
channels
will be
In ourthe
experiments,
F3,time
F4, FC5,
FC6,
between
the target
andtop
theeight
non-target
sample.
Inselected.
order to select
channels and
intervals
P7,
P8,
O1,
and
O2
are
selected
as
the
electrode
channels.
The
event-related
potential
waveforms
are
with more obvious discrimination, this method was applied to the screening of brainwave channels
shown
Figure 6.
and
timeinintervals.
P7

Amplitude(uV)

15
10
5
0
-5
0

500

P8

1000

15
10
5
0
-5
0

O2
15
10
5
0
-5
0

500

500

500

1000

F3

1000

15
10
5
0
-5
0

FC5
15
10
5
0
-5
0

O1
15
10
5
0
-5
0

500

1000

F4

500

1000

15
10
5
0
-5
0

500

1000

FC6

1000

15
10
5
0
-5
0

500

Time(ms)

1000

Figure
Figure6.6. EEG-related
EEG-related potentials
potentialswith
withtarget
targetand
andnon-target
non-targetstimulation.
stimulation.

The
biserial
coefficient
time t) can
be calculated
as shown
Equation
(3):
Thepoint
r(t) values
ofcorrelation
each sample
point canr(t)
be(at
calculated
according
to Equation
(3).inThe
r(t) values
of each current sample point together with√its subsequent five sample points will be superposed and
n1 n2 m1 ( t ) − m2 ( t )
averaged. When the r(t) value of the
sample
r (t)current
=
· point is larger than the average value within(3)T
n1 + n2
S(t)
time interval and the duration interval is more than 195 ms (for a total of 25 sampling points), the
featureTdata
is extracted
interval.
time interval
for each
where
is the
length of from
each this
trialtime
(t∈{1,
..., T}),The
andcorresponding
n1 and n2 represent
the number
of electrode
samples
channel
is
selected
by
our
experiment,
as
shown
in
Table
1:
of the target trials and non-target trials, respectively. m1 (t) and m2 (t) represent the mean values of
the potentials of all the target trials and those of all the non-target trials at time t, respectively. S(t)
Table
1. total
Selected
and time
intervals.
represents the standard deviation
(the
sumchannels
of distance
of each
potential deviating from the mean)
at time t.
Channel Time interval (ms) Channel Time interval (ms)
According to Equation
(3), the 195–609
larger r(t) value isF3an important273–648
metric for selecting the channel
P7
and time interval. ForP8
each channel,242–625
the mean square F4
value of r(t) in289–703
T time interval will be sorted in
descending order. Then,
the
top
eight
channels
will
be
selected.
In
our
experiments, F3, F4, FC5, FC6,
O1
258–515
FC5
328–585
P7, P8, O1, and O2 are
electrode channels.
O2selected as the
242–562
FC6 The event-related
281–539potential waveforms are
shown in Figure 6.
r(t) values
of each
sample
point can be calculated according to Equation (3). The r(t) values
4.3.2.The
Optimal
Feature
Subset
Selection
of each current sample point together with its subsequent five sample points will be superposed and
In order
to describe
the characteristics
EEG signals,
statistical
see Table
averaged.
When
the r(t) value
of the currentofsample
point isseven
larger
than thefeatures
average(f1–f7,
value within
T
2)
are
extracted
from
the
training
set
and
the
test
set
for
each
subject.
The
reason
for
choosing
time interval and the duration interval is more than 195 ms (for a total of 25 sampling points),these
the
seven features in the experiment is that the mean value can reflect the central tendency of a sample
feature data is extracted from this time interval. The corresponding time interval for each electrode
data set; the median, although it cannot represent the whole sample, reflects the median level of the
channel is selected by our experiment, as shown in Table 1:
data; the standard deviation and the entropy can reflect the degree of dispersion of the sample; the
maximum and the minimumTable
are 1.used
to describe
distribution
Selected
channels the
and time
intervals.range of the sample, and the
skewness can describe the degree of the sample data deviating from the mean. These features form
Channel

Time Interval (ms)

Channel

Time Interval (ms)

P7
P8
O1
O2

195–609
242–625
258–515
242–562

F3
F4
FC5
FC6

273–648
289–703
328–585
281–539

Sensors 2019, 19, 1664

9 of 21

4.3.2. Optimal Feature Subset Selection
In order to describe the characteristics of EEG signals, seven statistical features (f1–f7, see Table 2)
are extracted from the training set and the test set for each subject. The reason for choosing these seven
features in the experiment is that the mean value can reflect the central tendency of a sample data set;
the median, although it cannot represent the whole sample, reflects the median level of the data; the
standard deviation and the entropy can reflect the degree of dispersion of the sample; the maximum
and the minimum are used to describe the distribution range of the sample, and the skewness can
describe the degree of the sample data deviating from the mean. These features form together a set
of feature vectors, but not all of the features are task-related. Therefore, a method combining feature
search with performance evaluation is proposed to select the optimal feature subset.
Table 2. Statistical features.
Feature

Feature Description

Feature

Feature Description

f1
f2
f3
f4

Standard deviation
Skewness
Entropy
Maximum

f5
f6
f7

Minimum
Mean
Median

The best-first method is used to search the feature subsets based on greedy hill-climbing
augmented with a backtracking facility [24]; then, the correlation-based variable selection is used to
assess the performance of the feature subset [25]. By comparing the EEG features of subjects, standard
deviations and medians are selected as the optimal feature subset, which is denoted as Fs2. In order to
verify the classification performance of this optimal feature subset, the other feature subset Fs1 will be
compared, which includes all seven statistical features.
In the previous experiments, 54 target trials have been obtained, and eight channels have a total of
432 target trials. We can obtain 432 seven-dimensional target feature vectors and 432 two-dimensional
target feature vectors from Fs1 and Fs2, respectively.
4.4. Classification Method
In order to obtain higher accuracy, the machine learning model adopts the bagging ensemble
learning method, which needs to choose suitable base learners. An overview of some classic EEG
schemes based on biometric systems is given in Table 3 in order to achieve the optimal choice of
base learners.
In Table 3, the performance is represented by two metrics: CRR (the correct recognition rate) and
HTER (the half total error rate). Considering the two metrics of these classifiers, the performances of
the neural network, naïve Bayes, and logistic regression are better than the others.
The main task of bagging is to reduce the variance of samples, so it is effective on the neural
network learner that is susceptible to sample perturbation. At the same time, neural network is a
nonlinear classifier and has always been a frequently used classification model in Brain Computer
Interface (BCI) applications. In order to improve the generalization ability of the ensemble learning
model, two linear classifiers—naïve Bayes and logistic regression—can present a better parallelization
relationship. It is convincing that choosing these three classifiers in the experiments will achieve the
satisfactory experimental results.
Firstly, we need to evaluate the performance of three classifiers. Then, we adjust the bagging
algorithm according to the evaluation results. Besides, before training the classifier, the feature data set
needs to be normalized. This is to avoid excessive influence on the result when a certain feature value
is much larger than the other feature values.

Sensors 2019, 19, 1664

10 of 21

Table 3. Overview of some classic EEG schemes based on biometric systems. CRR: correct recognition
rate, HTER: half total error rate.
Paper

Protocol

The Number
of Subjects

Channels

Features

Classifier

Performance

Gui et al.
[17]

Read silently
the words

32

6 (Fpz, Cz, Pz,
O1, O2, Oz)

wavelet packet
decomposition

Neural
Network

CRR = 90%

Yeom et al.
[23]

Visual
evoked
potentials

10

18

dynamic feature

Support Vector
Machine

CRR = 86.1%

He et al. [26]

Motion tasks

4

19

Multi-variate
autoregressive
(mAR) features

Naïve Bayes

HTER = 8.1%

Subasi et al.
[27]

24-h EEG
recorded

wavelet
transform
analysis

Neural
Network

CRR = 92%

5

4 (F7-C3,
F8-C4, T5-O1,
T6-O2)

Logistic
Regression

CRR = 89%

Marcel and
Millan [11]

Word
generation

8
centro-parietal

Gaussian
mixture model

Maximum A
Posteriori
(MAP) model
adaptation

HTER = 12.1%

9

4.4.1. Naïve Bayes
The naïve Bayes classifier [26] is based on the naïve Bayes formula:
P ( c |d) =

p ( c ) p (d| c )
p (d)

(4)

In Equation (4), p(c) is a priori probability, p(d|c) represents the conditional probability of sample
d relative to class c, and p(d) is the evidence factor used for normalization.
In order to estimate the posterior probability p(c|d), the naïve Bayes classifier makes use of the
“attribute conditional independence” assumption for the target and non-target samples. Since the
attributes are independent of each other, Equation (4) can be rewritten as:
j

P ( c |d) =

P ( c ) P (d| c )
P(c)
=
P ( di | c )
P (d)
P(d) i∏
=1

p ( di | c ) = √

1
2πσc,i

exp(−

(di − uc,i )2
)
2σc,i 2

(5)

(6)

In Equations (5) and (6), j represents the feature number of the feature set Fs1 or Fs2, di is the
value of one of the samples d on the i-th feature, and uc,i and σ2 c,i are respectively the mean and the
variance of the i-th feature value of the two type samples.
4.4.2. Logistic Regression
Logistic regression expects to establish a regression equation for the classification boundary line
based on the existing feature data set Fs1 and Fs2, in order to find the best-fit parameter set [27]. It
aims at classifying the target features and non-target features. The core functions of the classifier are
shown as follows:
logit( p) = ln(

n
p
) = β 0 + β 1 w1 + · · · + β n w n = β 0 + ∑ β i w i
1− p
i =1

(7)

Sensors 2019, 19, 1664

11 of 21

n

p ( y = 1 | w1 , w2 , . . . , w n ) =

e

β 0 + ∑ β i wi
i =1

n

1+e

β 0 + ∑ β i wi

(8)

i =1

In Equations (7) and (8), w1 , w2 , ..., wn are vectors of input features, and y is the corresponding
class label that can be either zero or one, representing the target or non-target feature, respectively. P is
the probability of occurrence of the event that y = 1. The relative event probability P(y = 0|w1 , w2 , ...,
wn ) can be calculated as 1 – P(y = 1|w1 , w2 , ..., wn ). β0 is the intercept as a constant, β1 , β2 , ..., βn are
the regression coefficients related to the independent variables w1 , w2 , ..., wn in a regression gradient
rise optimization algorithm.
4.4.3. BP Neural Network
The BP neural network model [28] consists of three layers: the input layer, the hidden layer, and
the output layer, which are composed of neurons. The neurons of each layer are fully interconnected
with those of the next layer, and there are no same-layer and cross-layer connections between neurons.
The steps of the BP algorithm are described as follows:
1.
2.
3.
4.

Input samples are first provided to the neurons in the input layer, and then the signals are
forwarded layer by layer until the neurons in the output layer get results.
According to the results, the error of the output layer will be calculated and back propagated to
the hidden layer neurons.
Adjust the connection weights and thresholds between neurons based on the error in the
hidden layer.
The loop iterates until it reaches the termination condition.

In the experiment, in the Fs1 feature set, there are seven neurons in the input layer, two neurons
in the output layer, and four neurons in the hidden layer. In Fs2, there are two neurons in the input
layer, two neurons in the output layer, and two neurons in the hidden layer. The training error is set
as 0.01 (the selection of the training error is determined by comparison analysis between multiple
measurements in the experiment).
4.4.4. Bagging Ensemble Learning
Bagging is the most famous representative of the parallel-integrated learning method. The
execution steps designed in our proposal are as follows:
1.

2.

3.

Acquire the sample data set through the self-sampling method. The feature set extracted from
this experiment contains 860 feature samples; 660 of them are randomly selected as training set
D, and the remaining 200 samples are used as test sets. Every time, one sample is randomly
selected from D and put it into the new sample set D’, and then put it back into D. The process is
repeatedly executed 660 times to obtain a new sample set D’ with a total sample number of 660.
Repeat the above self-sampling process to obtain multiple sample sets, select one classifier for
each sample set, and then perform training to obtain a base learner. Finally, all of the base learners
will be integrated as a strong learner.
Bagging also uses a voting method for the classification task. The final prediction result is
determined by the most counts of positive cases or negative cases provided by each base learner.
If there are two classes receiving the same number of votes during the classification prediction,
then one of them is selected randomly.

Sensors 2019, 19, 1664

12 of 21

4.5. Performance Evaluation
The classifier performance can be evaluated using the precision rate Tpr (i.e., true positive
rate), the false positive rate Fpr, and the accuracy rate Acc, which can be derived from
Equations (9)–(11), respectively:
TP
T pr =
(9)
TP + FN
FP
FP + TN

(10)

TP + TN
TP + FN + FP + TN

(11)

Fpr =
Acc =

TP stands for the number of target samples predicted to target samples, FN represents the number
of target samples predicted to non-target samples, FP is the number of non-target samples predicted to
target samples, and TN is the number of non-target samples predicted to non-target samples.
5. Experimental Test Results and Analysis
5.1. Selection of Optimal Classifier
Firstly, the three classifiers mentioned above are separately adopted to verify the performance of
the two training feature sets (Fs1 and Fs2). Three classifiers use 10-fold cross-validation for performance
evaluation so as to select high quality base learners for bagging ensemble learning. The respective
classification results of the three classifiers for the feature set Fs1 and the feature set Fs2 are respectively
shown in Tables 4 and 5. We randomly selected seven subjects to show the classification results.
Table 4. The classification results based on the seven-feature set (Fs1). ACC: accuracy rate, TPR: true
positive rate, FPR: false positive rate.
Subject
a
b
c
d
e
f
g
Average

Acc(%)
78.02
78.84
81.40
74.42
77.79
78.14
77.09
77.96

Naïve Bayes
Tpr(%)
75.11
77.21
76.74
76.74
75.12
76.05
73.02
75.71

Fpr(%)
19.07
19.53
13.95
27.9
19.53
19.76
18.84
19.80

Logistic Regression
Acc(%)
Tpr(%)
Fpr(%)
78.49
77.67
20.7
82.56
83.72
18.6
85.12
83.72
11.16
77.90
75.35
19.53
80.23
69.77
9.30
82.56
81.40
13.95
84.30
81.63
12.09
81.59
79.04
15.05

BP Neural Networks
Acc(%)
Tpr(%)
Fpr(%)
79.07
74.42
16.28
84.88
90.70
20.93
86.51
84.18
13.49
77.91
81.40
25.58
81.98
78.14
14.19
83.72
81.40
16.28
84.76
83.49
13.89
82.69
81.96
17.38

Table 5. The classification results based on the two-feature set (Fs2). BP: back propagation.
Subject
a
b
c
d
e
f
g
Average

Acc(%)
85.00
84.42
87.67
75.93
82.56
83.95
84.07
83.37

Naïve Bayes
Tpr(%)
92.79
92.56
90.70
71.86
89.77
91.16
91.16
88.57

Fpr(%)
22.79
23.72
15.35
20.00
24.65
23.26
23.02
21.83

Logistic Regression
Acc(%)
Tpr(%)
Fpr(%)
86.40
85.11
12.32
86.40
84.65
11.86
89.30
87.91
9.30
78.72
77.21
19.77
85.23
83.26
12.33
87.44
85.81
10.93
86.60
88.14
10.93
85.73
84.58
12.49

BP Neural Networks
Acc(%)
Tpr(%)
Fpr(%)
87.91
86.05
10.23
86.98
85.58
11.63
89.65
92.33
13.02
80.93
77.67
15.81
85.47
82.33
11.86
88.26
88.37
11.86
88.16
80.93
8.60
86.77
84.75
11.86

In Tables 4 and 5, because of the difference in the state and concentration of each subject, there
exist differences in the quality of the collected EEG signals, which might cause the classification
accuracy of one subject to be higher than that of another. In addition, the classification performance of
the selected optimal feature subset Fs2 (standard deviation and median) is significantly better than the

Sensors 2019, 19, 1664

13 of 21

set Fs1, which involved all of the extracted features through the respective verification of naïve Bayes,
logistic regression (a.b. LR), and BP neural network classifiers.
At the same time, from Tables 4 and 5, the classification performance of naïve Bayes is
unsatisfactory compared with that of logistic regression and the BP neural network. In order to ensure
the accuracy of the ensemble learner, the naïve Bayes model with poor classification performance was
removed from the experiments. At the same time, considering that the number of base learners should
not be too much and the voting method requires an odd number of base learners, the experimental
choice combines three BP neural network base learners with two logistic regression ones into one
strong classifier in the experiments.
The performance of the classifier can be evaluated by the ROC curve and the AUC area, which are
defined further in this paragraph. The ROC curve is called the “receiver operating characteristic curve”,
which means that samples are sorted in ascending order according to the learner’s predicted results.
All of the samples will be traversed and marked one by one in this order, and the current sample
together with those marked samples will be regarded as positive samples to predict the remaining
ones. The values of Tpr and Fpr are calculated and plotted on the vertical and horizontal coordinates,
respectively.
comparing
Sensors 2019, 19,When
x FOR PEER
REVIEWthe learners’ performance, if the ROC curve of one learner is completely
13 of 20
enveloped by the curve of another learner, the performance of the latter can be judged to be superior
be former.
superior
to the ifformer.
if the
thetwo
ROC
curvesintersect,
of the two
learners
intersect,
a more
to the
Besides,
the ROCBesides,
curves of
learners
a more
reasonable
criterion
is to
reasonable
is tothe
compare
the area
ROC
curve,
thecurve).
AUC (area under the
compare
thecriterion
area under
ROC curve,
that under
is, the the
AUC
(area
underthat
the is,
ROC
ROCFigure
curve).7 presents the comparisons of ROC curves for the three classifiers from the selected
7 presents
theFigure
comparisons
ROC
curves
for the three
classifiers
from thefrom
selected
sevenFigure
subjects
a–g, and
8 showsofthe
AUC
surrounded
by the
three learners
the seven
same
subjects
a–g, and Figure 8 shows the AUC surrounded by the three learners from the same seven
seven
subjects.
subjects.
1

0.8
0.6
0.4
0.2
0
0

0.2

0.4
0.6
False Positive Rate

LR
BP
Bagging
0.8
1

True Positive Rate

True Positive Rate

1

0.8
0.6
0.4
0.2
0
0

0.2

(a) User a

(b) User b
1

0.6
0.4
0.2
0.2

0.4
0.6
False Positive Rate

LR
BP
Bagging
0.8
1

True Positive Rate

True Positive Rate

1
0.8

0
0

0.8
0.6
0.4
0.2
0
0

0.2

(c) User c
1
True Positive Rate

0.8

0.8

0.6

0.6

0.4

0.4
0.2
0.2

0.4
0.6
False Positive Rate

LR
BP
Bagging
0.8
1

0.2
0
0

(e) User e
1
True Positive Rate

True Positive Rate

0.4
0.6
False Positive Rate

LR
BP
Bagging
0.8
1

(d) User d

1

0
0

0.4
0.6
False Positive Rate

LR
BP
Bagging
0.8
1

0.2

0.4
0.6
False Positive Rate

(f) User f
Figure 7. Cont.

0.8
0.6
0.4
0.2
0

LR
BP
Bagging

LR
BP
Bagging
0.8
1

True Positiv

True Positive

0.6

0.6

0.4

0.4

LR
BP
Bagging
0.8
1

0.2
0

0
Sensors 2019, 19, 1664

0.2

0.4
0.6
False Positive Rate

0.2
0
0

0.2

0.4
0.6
False Positive Rate

(e) User e

LR
BP
Bagging
0.8
1

14 of 21

(f) User f

True Positive Rate

1
0.8
0.6
0.4
0.2
0
0

0.2

0.4
0.6
False Positive Rate

LR
BP
Bagging
0.8
1

(g) User g
Figure 7. Comparisons of receiver operating characteristic (ROC) curves for the three classifiers from
Figure 7. Comparisons of receiver operating characteristic (ROC) curves for the three classifiers from
14 of 20
subjects a–g.

Area Under ROC Curve

Sensors
2019, 19,
x FOR PEER REVIEW
subjects
(a–g).

0.9
0.85
0.8
LR
BP
Bagging

0.75
0.7

a

b

c

d
e
Subject Id

f

g

Figure
Figure 8.
8. The area under the
the ROC
ROC curve
curve (AUC)
(AUC) surrounded
surrounded by
by the
the three
threelearners
learnersof
ofsubjects
subjectsa–g.
a~g.

ItIt can
can be
be seen
seen that
that the
the proposed
proposed bagging
bagging ensemble
ensemble learning
learning algorithm
algorithm achieves
achieves aa better
better
classification
effect
whether
from
Figure
7
or
Figure
8,
followed
by
BP
neural
network
and
classification
whether from Figure 7 or Figure 8, followed by BP neural network and logistic
logistic
regression.
regression.
5.2.
5.2. Comparison
Comparison of
of Experimental
Experimental Paradigms
Paradigms

Authentication Accuracy

Based
above
experiments,
the proposed
feature
selection
methodmethod
togethertogether
with the with
bagging
Basedon
onthe
the
above
experiments,
the proposed
feature
selection
the
classification
method
forms
the
best
combination,
which
will
be
used
to
evaluate
the
performance
of
bagging classification method forms the best combination, which will be used to evaluate the
the
audiovisual
paradigm,
the
single
visual
paradigm,
and
the
single
auditory
paradigm,
respectively.
performance of the audiovisual paradigm, the single visual paradigm, and the single auditory
Similar
to the
audiovisualSimilar
paradigm,
the single
visual paradigm
single
auditory
paradigm
paradigm,
respectively.
to the
audiovisual
paradigm,and
thethe
single
visual
paradigm
andwill
the
be
conducted
according
to
the
experimental
scenario
in
Section
3.
Particularly,
during
the
selection
single auditory paradigm will be conducted according to the experimental scenario in Section of
3.
stimuli
source,
only the
visual
or auditory
stimuli
are only
selected.
Except
for this,
the selection
of optimal
Particularly,
during
selection
of stimuli
source,
visual
or auditory
stimuli
are selected.
Except
channels,
optimal
time
and optimal
feature
areand
all based
onfeature
our proposal.
Each
for this, the
selection
of intervals,
optimal channels,
optimal
timesubsets
intervals,
optimal
subsets are
all
subject
performs
the
same
experiment
several
times
to
obtain
mathematical
expectation.
Aiming
at 30
based on our proposal. Each subject performs the same experiment several times to obtain
subjects,
after 100
experiments,
Figures
respectively
the average classification
rate,
mathematical
expectation.
Aiming
at 9–11
30 subjects,
after show
100 experiments,
Figures 9–11accuracy
respectively
precision
(true classification
positive rate),accuracy
and falserate,
positive
rate ofrate
the three
show therate
average
precision
(true paradigms.
positive rate), and false positive
From
the
comparison
of
the
accuracy
rates
of
the
three
experimental
paradigms, the audiovisual
rate of the three paradigms.
paradigm achieves the best classification effect. Based on the analysis of the true positive rate and
the false positive100
rate, although the true positive rate Visual
of the
audiovisual
paradigm
has no obvious
& Auditory
Visual Only
Auditory Only
advantage over the other two paradigms, its false positive rate is significantly lower than the other two.
95
For the entrance identity
authentication system for a smart building or house, the false positive rate is
an important metric to prevent identity authentication attacks from impostors. It can be seen that the
90
combination of visual and auditory paradigms can actually increase the stimulation intensity compared
with the single visual
85 paradigm and the single auditory paradigm, ensuring that the extracted feature
data is more reliable while obtaining better authentication effectiveness. At the same time, single
80
75
70
65
0

5

10

15

20

25

30

performance of the audiovisual paradigm, the single visual paradigm, and the single auditory
paradigm, respectively. Similar to the audiovisual paradigm, the single visual paradigm and the
single auditory paradigm will be conducted according to the experimental scenario in Section 3.
Particularly, during the selection of stimuli source, only visual or auditory stimuli are selected. Except
for
this,
the19,selection
of optimal channels, optimal time intervals, and optimal feature subsets are
Sensors
2019,
1664
15 ofall
21
based on our proposal. Each subject performs the same experiment several times to obtain
mathematical expectation. Aiming at 30 subjects, after 100 experiments, Figures 9–11 respectively
visual the
or single
auditory
paradigms
can also
achieve
desirable
identity
authentication
thepositive
visitors
show
average
classification
accuracy
rate,
precision
rate (true
positive
rate), andfor
false
with
only
visual
or
auditory
impairments.
rate of the three paradigms.
100

Visual & Auditory

Visual Only

Auditory Only

Authentication Accuracy

95
90
85
80
75
70
65
0

5

10

15

20

Subject Id

25

30

Sensors 2019, 19, x FOR PEER REVIEW
Sensors 2019, 19, xFigure
FOR PEER
REVIEW
9. Comparison
of average classification accuracy of the three paradigms.

Figure 9. Comparison of average classification accuracy of the three paradigms.
95
95

Visual & Auditory
Visual & Auditory

Visual Only
Visual Only

15 of 20
15 of 20

Auditory Only
Auditory Only

True
TruePositive
PositiveRate
Rate

90
90
85
85
80
80
75
75
70
70
65
65
60
60

5
5

10
10

15

15
Subject
Id
Subject Id

20
20

25
25

30
30

Figure 10. Comparison
Comparison of
of the
the precision rate
rate of the
the three paradigms.
paradigms.
Figure
Figure 10.
10. Comparison of
the precision
precision rate of
of the three
three paradigms.
40
40

Visual & Auditory
Visual & Auditory

Visual Only
Visual Only

Auditory Only
Auditory Only

35
35

False
FalsePositive
PositiveRate
Rate

30
30
25
25
20
20
15
15
10
10
5
5
0
0

5
5

10
10

15
15 Id
Subject
Subject Id

20
20

25
25

30
30

Figure 11. Comparison of the false positive rate of the three
three paradigms.
paradigms.
Figure 11. Comparison of the false positive rate of the three paradigms.

From the comparison of the accuracy rates of the three experimental paradigms, the audiovisual
From the comparison of the accuracy rates of the three experimental paradigms, the audiovisual
paradigm achieves the best classification effect. Based on the analysis of the true positive rate and the
paradigm achieves the best classification effect. Based on the analysis of the true positive rate and the
false positive rate, although the true positive rate of the audiovisual paradigm has no obvious
false positive rate, although the true positive rate of the audiovisual paradigm has no obvious
advantage over the other two paradigms, its false positive rate is significantly lower than the other
advantage over the other two paradigms, its false positive rate is significantly lower than the other
two. For the entrance identity authentication system for a smart building or house, the false positive
two. For the entrance identity authentication system for a smart building or house, the false positive

Sensors 2019, 19, 1664

16 of 21

5.3. Comparison of Experimental Methods
The first compared method was proposed by Gui et al. [17] based on wavelet packet decomposition
and artificial neural network. In this experiment, the EEG signals were first ensemble averaged. After
that, a 60-Hz low-pass filter was adopted to remove the noise out of the major range of the EEG signals.
Then, the four-level wavelet packet decomposition is performed on each data set. After that, EEG
signals can be separated into five major frequency bands signals: 0–4 Hz, 4–8 Hz, 8–15 Hz, 15–30 Hz,
and 30–60 Hz. Then, the mean, the standard deviation, and the entropy of these frequency bands
signals are calculated to form the feature data set. Finally, the feature data set is input into the artificial
neural network for classification and authentication.
The second compared method was proposed by Chen et al. [9] based on the non-overlapping
time window and shrinkage discriminant analysis. For the Event-related potential (ERP) analysis,
the EEG data was low-pass filtered by a Chebyshev digital filter with a passband of 40 Hz and a
stopband at 49 Hz. Features were calculated from 16 electrode channels by averaging voltages in nine
non-overlapping time windows with a width of 100 ms, starting from 100 ms to 1000 ms with respect
to stimulus onset. This resulted in 16 × 9 = 144 dimensional feature vectors. Then, the feature vectors
are input into the shrinkage discriminant analysis classifier for classification recognition.
The third compared method was proposed by Wen et al. [29] based on boosting for transfer
learning. They proposed a novel framework TrAdaBoost for transferring knowledge from one
distribution to another by boosting a basic learner. They used support vector machines as the basic
learners in TrAdaBoost. The basic idea is to select the most effective diff-distribution instances as
additional training data for predicting the labels of the same distribution.
The first two methods above only pay attention to feature extraction while ignoring the further
assessment and selection for the given features. Besides, only one classifier is employed by both.
Although the third one is a kind of ensemble learning method, boosting takes advantage of
the relevance of the base learner, and the next learner utilizes the previous result, so it can only be
sequential but not parallel, and finally it can be achieved by updating the weight of the training sample.
In order to verify the validity of our proposal based on bagging ensemble learning, the experiment
selected seven subjects to collect their EEG data based on the audiovisual paradigm; these data will be
regarded as the experimental data set for the fair comparisons. In the experiment, the data set must be
pre-processed according to our proposal and the above three methods, respectively. After that, feature
extraction and classification recognition are completed separately. Finally, 100 experiments for each
subject are performed, and the average classification accuracy of the four methods is shown in Table 6.
Table 6. Performance comparisons with the existing methods.
Authors

Methods

Our proposal

Bagging with
adaptive feature
selection

Gui et al. [17]

Chen et al. [9]
Wen et al. [29]

Artificial Neural
Networks (ANNs)
with Wavelet packet
decomposition (WPD)
Shrinkage Linear
Discriminant
Analysis (LDA)
Boosting for
transfer learning

Classification Accuracy Rate (%)
a

b

c

d

e

f

g

Average

91.91

91.98

93.65

89.93

90.23

92.26

90.16

91.45

87.31

85.74

86.10

88.81

84.12

85.02

86.95

86.30

85.23

85.14

84.45

87.14

83.90

86.95

83.64

85.21

88.61

89.32

91.28

89.46

85.81

88.18

87.35

90.56

As can be clearly seen from Table 6, the accuracy of our proposal for the seven selected subjects is
higher than that of the three other methods. That means the adaptive feature selection and bagging

Sensors 2019, 19, 1664

17 of 21

ensemble learning method designed in this paper have more satisfactory performance compared with
the traditional feature extraction and classification recognition methods.
5.4. Simulating Login in IoT scenario
In order to test the attack capacity of the impostor on the entrance authentication system of an
intelligent building or residence, we deploy a well-trained ensemble learning model to a test server,
and we can acquire and send the subject’s EEG signals through Bluetooth and use the test server as
an intelligent gateway to implement entrance access control. There are 10, 30, and 100 subjects to
perform simulated login; each of them will try to log into the authentication system and randomly
select another subject as an impostor. As mentioned above, both the valid subject’s and the impostor’s
target features are extracted under the valid subject’s self-source stimulation. Then, the target features
of the valid subject and that of the impostor in the login stage will be respectively matched with that of
the valid subject in the registration phase.
In the experiment, mathematics expectations can be achieved by carrying out 10 experiments for
each subject. Figure 12 shows the legal success rate (the probability of the valid subject passing the
authentication) and the illegal success rate (the probability of the impostor passing the authentication)
of the subjects. The legal success rate of 10, 30, and 100 subjects are 92.4%, 92.13%, and 92.42%,
respectively, and the illegal success rate of 10, 30, and 100 subjects are 2.9%, 3.2%, 3.17%, respectively.
From the perspective of security, the higher legal success rate and the lower illegal success rate are
expected by the entrance authentication system, which verifies the reliability and effectiveness of the
authentication system.
5.5. Discussion
Through the above simulation experiments and analysis, our proposal based on the “EMOTIV
EPOC+” EEG device still has a certain failure rate; we summarize the main reasons as below.
In our experiments, the subjects perform the visual and auditory paradigm in a open environment
due to the constrains of experimental conditions, so there are many uncertainties in the test process:
(1) the mental state of the subject may be bad; (2) the subject cannot correctly follow the authentication
instructions of the experimental paradigm; (3) improperly wearing the EEG device can cause
inaccuracies in the data acquisition; or (4) the surrounding noises may interfere with the subject.
Furthermore, we find that the 64-electrode EEG devices may achieve the higher precision but they are
expensive; for example, the price of the NeuroScan device is between $13,000–15,000. In contrast, the
cost of our proposed EEG device is not very high; therefore, the accuracy of the collected data has a
certain limitation.
Based on the above analysis, some difficulties exist in popularizing brainwave-based authentication
methods. We suggest the following solutions to achieve more satisfactory experimental results.
First, the subject needs to be fully acquainted with the workflow of the audiovisual paradigm and
strictly perform the instructions.
Second, the subject needs to be in a confined space and comfortable state to avoid the
surrounding interference.
Finally, promoting the accuracy of data collection by continuously improving the experimental
paradigm under the premise of controllable cost. Optionally, we may also adopt more high-precision
data acquisition devices if not counting the cost.

Legal or illegal success rate

authentication) and the illegal success rate (the probability of the impostor passing the
authentication) of the subjects. The legal success rate of 10, 30, and 100 subjects are 92.4%, 92.13%,
and 92.42%, respectively, and the illegal success rate of 10, 30, and 100 subjects are 2.9%, 3.2%, 3.17%,
respectively. From the perspective of security, the higher legal success rate and the lower illegal
success
rate
and
Sensors
2019,
19, are
1664expected by the entrance authentication system, which verifies the reliability
18 of
21
effectiveness of the authentication system.
100
90
80
70
60
50
40
30
20
10
0

legal
illegal

0

2

4

6
Subject Id

8

10

Legal or illegal success rate

(a) total 10 subjects
100
90
80
70
60
50
40
30
20
10
0

legal
illegal

0

10

20

30

Subject Id

Sensors 2019, 19, x FOR PEER REVIEW

18 of 20

(b) total 30 subjects

Legal or illegal success rate

100
90
80
70
60
50

legal

40

illegal

30
20
10
0
0

20

40

60

80

100

Subject Id

(c) total 100 subjects
Figure 12. The legal and illegal success rate of the valid subjects and impostors.
impostors.

5.5. Discussion
Through the above simulation experiments and analysis, our proposal based on the “EMOTIV
EPOC+” EEG device still has a certain failure rate; we summarize the main reasons as below.
In our experiments, the subjects perform the visual and auditory paradigm in a open
environment due to the constrains of experimental conditions, so there are many uncertainties in the

Sensors 2019, 19, 1664

19 of 21

6. Conclusions and Future Work
The development of IoT device and artificial intelligence (AI) technology enables the traditional
scenario to emerge for promising individual/industrial applications. This paper focuses on the security
of an intelligent entrance guard for a smart home or building, and proposes an EEG-based identity
authentication system that combines both visual and auditory presentations. Among which, the
stimulus source including self and non-ego face images and voice can stimulate the subject to produce
unique brainwave activity.
Based on the collected EEG signals, various well-designed methods were selected to achieve
artifact removal and construction of the optimal feature subset. Then, base learners that were selected
from naïve Bayes, logistic regression, and BP neural network were integrated to a strong learner
using the bagging ensemble algorithm for the classification performance evaluation of feature subsets.
Furthermore, lots of experimental analyses were carried out to verify the feasibility, effectiveness,
and reliability of our proposed identity authentication system in order to satisfy the requirements of
IoT applications.
The proposed EEG-based identity authentication system has characteristics that cannot be forged
or replaced, which is even appropriate for the special visitor whose brain activity is normal but has
poor eyesight or hearing such as a blind person or deaf person. However, how to achieve higher
classification accuracy and more reliable authentication efficiency has become the concern of our future
work. We will combine our proposal with other biometric technologies to form a more effective and
secure authentication system.
Author Contributions: Conceptualization, H.H.; methodology, H.H. and L.H.; data investigation, F.X.;
experiments, L.H., H.H. and A.D.; data analysis, A.D. and F.X.; writing: original draft preparation, H.H. and L.H.;
writing: review and editing, F.H. and N.Y.; supervision, N.Y.
Funding: This work was supported by the National Key Research and Development Program
(No. 2018YFB0803403), the National Natural Science Foundation of P. R. China (No. 61672297), the Key Research
and Development Program of Jiangsu Province (Social Development Program, No. BE2017742), The Sixth Talent
Peaks Project of Jiangsu Province (No. DZXX-017), Jiangsu Natural Science Foundation for Excellent Young
Scholar (No. BK20170039), and the Postgraduate Research & Practice Innovation Program of Jiangsu Province
(No. SJCX17_0235).
Acknowledgments: The authors would like to thank the anonymous reviewers of this paper for his/her objective
comments and helpful suggestions while at the same time helping us to improve the English spelling and grammar
throughout the manuscript.
Conflicts of Interest: The authors declare no conflict of interest.
Data Availability Statement: All data used in this manuscript are collected from subjects by the electrical
equipment of “Emotiv Epoc+”. The data sets generated and analyzed during the current study are available from
the corresponding author on reasonable request.

References
1.
2.
3.
4.
5.
6.

Zhu, H.; Xiao, F.; Sun, L.; Wang, R.; Yang, P. R-TTWD: Robust Device-Free Through-The-Wall Detection of
Moving Human with WiFi. IEEE J. Sel. Areas Commun. 2017, 35, 1090–1103. [CrossRef]
Xu, J.; Zhang, X.; Zhou, M. A High-Security and Smart Interaction System Based on Hand Gesture
Recognition for Internet of Things. Secur. Commun. Netw. 2018, 2018. [CrossRef]
Tian, W.; Guangxue, Z.; Anfeng, L. A secure IoT service architecture with an efficient balance dynamics
based on cloud and edge computing. IEEE Internet Things J. 2018, 2018. [CrossRef]
Mathieu, B.; Dinh, T.B.; Richard, D. Future spaces: reinventing the home network for better security and
automation in the IoT era. Sensors 2018, 18, 2986–3008.
Cao, K.; Yang, X.; Chen, X.; Zang, Y.; Liang, J.; Tian, J. A novel ant colony optimization algorithm for
large-distorted fingerprint matching. Pattern Recognit. 2012, 45, 151–161. [CrossRef]
Zhang, H.; Nasrabadi, N.M.; Zhang, Y. Joint dynamic sparse representation for multi-view face recognition.
Pattern Recognit. 2012, 45, 1290–1298. [CrossRef]

Sensors 2019, 19, 1664

7.
8.

9.

10.
11.
12.
13.
14.

15.

16.
17.

18.
19.
20.
21.

22.

23.
24.
25.

26.

27.

20 of 21

Al-Zubi, R.; Darabkh, K.A.; Jararweh, Y. A Powerful Yet Efficient Iris Recognition Based on Local Binary
Quantization. Inf. Technol. Control 2014, 43, 244–251. [CrossRef]
González-Ortega, D.; Díaz-Pernas, F.J.; Martínez-Zarzuela, M. Real-time hands, face and facial features
detection and tracking: Application to cognitive rehabilitation tests monitoring. J. Netw. Comput. Appl. 2010,
33, 447–466. [CrossRef]
Chen, Y.; Atnafu, A.D.; Schlattner, I.; Weldtsadik, W.T.; Roh, M.-C.; Kim, H.-J.; Lee, S.-W.; Blankertz, B.;
Fazli, S. A high-security EEG-based login system with RSVP stimuli and dry electrodes. IEEE Trans. Inf.
Forensics Secur. 2016, 11, 2635–2647. [CrossRef]
Tian, W.; Guangxue, Z.; Alam, B.Z. A novel trust mechanism based on fog computing in Sensor-Cloud
System. Future Gener. Comput. Syst. 2018, 5, 49–59.
Marcel, S.; Millan, J.D.R. Person Authentication Using Brainwaves (EEG) and Maximum A Posteriori Model
Adaptation. IEEE Trans. Anal. Mach. Intell. 2007, 29, 743–752. [CrossRef] [PubMed]
Ma, L.; Minett, J.W.; Blu, T.; Wang, W.S.-Y. Resting State EEG-based biometrics for individual identification
using convolutional neural networks. Conf. Proc. IEEE Eng. Med. Biol. Soc. 2015, 2015, 2848–2851.
Im, C.-H.; Hwang, H.-J. EEG-based real-time dynamic neuroimaging. Conf. Proc. IEEE Eng. Med. Biol. Soc.
2009, 2009, 5385–5388. [PubMed]
Paranjape, R.B.; Mahovsky, J.; Benedicenti, L. The electroencephalogram as a biometric. In Proceedings of
the Canadian Conference on Electrical & Computer Engineering, Toronto, ON, Canada, 13–16 May 2001;
pp. 1363–1366.
Poulos, M.; Rangoussi, M.; Chrissikopoulos, V. Person identification based on parametric processing of the
EEG. In Proceedings of the IEEE International Conference on Electronics, Pafos, Cyprus, 5–8 September 1999;
pp. 283–286.
Maiorana, E.; Rocca, D.L.; Campisi, P. On the permanence of EEG signals for biometric recognition. IEEE
Trans. Inf. Forensics Secur. 2015, 11, 163–175. [CrossRef]
Gui, Q.; Jin, Z.; Xu, W. Exploring EEG- based biometrics for user identification and authentication.
In Proceedings of the Signal Processing in Medicine and Biology Symposium, Philadelphia, PA, USA,
13 December 2014; pp. 1–6.
Palaniappan, R.; Raveendran, P. Individual identification technique using visual evoked potential signals.
Electron. Lett. 2002, 38, 1634. [CrossRef]
Vi, C.; Subramanian, S. Detecting error-related negativity for interaction design. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems, Austin, TX, USA, 5–10 May 2012; pp. 493–502.
Luck, J. An Introduction to the Event-Related Potential Technique; MIT Press: Cambridge, MA, USA, 2005;
pp. 1–374.
Kamel, N.; Malik, A.; Jatoi, M.A. Ensemble averaging subspace-based approach for ERP extraction. In
Proceedings of the ICME International Conference on Complex Medical Engineering, Beijing, China, 25–28
May 2013; pp. 547–550.
Jafari, A.; Gandhi, S.; Konuru, S.H. An EEG artifact identification embedded system using ICA and
multi-instance learning. In Proceedings of the 2017 IEEE International Symposium on Circuits and Systems
(ISCAS), Baltimore, MD, USA, 28–31 May 2017; pp. 1–4.
Yeom, S.-K.; Suk, H.-I.; Lee, S.-W. Person authentication from neural activity of face-specific visual
self-representation. Pattern Recognit. 2013, 46, 1159–1169. [CrossRef]
Zarei, R.; He, J.; Siuly, S.; Zhang, Y. A PCA aided cross-covariance scheme for discriminative feature extraction
from EEG signals. Comput. Methods Progr. Biomed. 2017, 146, 47–57. [CrossRef] [PubMed]
Ye, F.; Zhang, Z.; Chakrabarty, K.; Gu, X. Information-Theoretic Syndrome Evaluation, Statistical Root-Cause
Analysis, and Correlation-Based Feature Selection for Guiding Board-Level Fault Diagnosis. IEEE Trans.
Comput. Des. Integr. Circuits Syst. 2015, 34, 1014–1026. [CrossRef]
He, C.; Lv, X.; Wang, J. Hashing the mar coefficients from EEG data for person authentication. In Proceedings
of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, Taipei, Taiwan, 26
May 2009; pp. 1445–1448.
Subasi, A.; Ercelebi, E. Classification of EEG signals using neural network and logistic regression. Comput.
Methods Progr. Biomed. 2005, 78, 87–99. [CrossRef] [PubMed]

Sensors 2019, 19, 1664

28.
29.

21 of 21

Oğulata, S.N.; Sahin, C.; Erol, R. Neural network-based computer-aided diagnosis in classification of primary
generalized epilepsy by EEG signals. J. Med. Syst. 2009, 33, 107–120. [CrossRef] [PubMed]
Dai, W.Y.; Yang, Q. Boosting for transfer learning. In Proceedings of the 24th International Conference on
Machine Learning, Corvalis, OR, USA, 20–24 June 2007; pp. 193–200.
© 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).

