ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

Results of a 3 Year Study of a BCI-Based Communicator for Patients with Severe
Disabilities

Pasquale Fedele, Myriam Gioia

Fabio Giannini, Alessandra Rufa

Liquidweb s.r.l.
Siena,Italy
e-mail: {p.fedele, m.gioia}@liquidweb.it

University of Siena
Siena,Italy
e-mail: {fabio.giannini, rufa}@unisi.it

Abstract— The Brain-Computer Interface (BCI) technology
can convert brain electrical signals into commands able to
control external devices without the need of any voluntary
movement. This can be an innovative solution that allows
interaction, especially for patients with pathologies such as
Amyotrophic Lateral Sclerosis, Multiple Sclerosis, Muscular
Dystrophy or ischemic/traumatic injuries, unable to use
standard Augmentative Alternative Communication (AAC)
devices because of the loss of limbs movements, gaze control or
ophthalmological disorders. Among different approaches of
signal analysis, a recent BCI device, Braincontrol Basic
Communicator, based on event related desynchronization
(ERD) produced by motor imagery (MI), has been recently
developed by Liquidweb s.r.l. and used in the current study to
overcome physical issues of these patients. The aim of this
study was to verify the efficacy of the Braincontrol as an AAC
device and to validate the training methodology with regards
to patients in locked-in state (LIS). The study was conducted,
from 2012 to 2015, on two groups: 42 patients with
communication and motility disorder (of these 13 were in LIS
and 10 in condition similar to the complete locked-in state,
with no feedback and unknown cognitive status) and 63
healthy users. The results of this observation confirm that the
device, after the first phase training, is efficient and robust for
patients. Trainings have been completed successfully for all the
healthy users and patients in initial and severe stage of the
disease, only 2 out 42 patients failed the training. In particular,
the 2 patients were in the condition similar to the complete
locked-in state (CLIS). After this study, 17 locked-in patients
have continued to use the system as a unique tool for
communication.

If rudimentary control of at least one muscle is present,
we speak of Locked-in State (LIS). The principal assistive
technologies for LIS patients include residual movement
controlled systems [16]-[17], voice-controlled systems, eyetracking and brain computer interface (BCI). Braincomputer interface technology interprets electrical signals
corresponding to a specific brain activity and allows the
control of a computer or other external devices [1]-[13][18]
(See Figure 1).
The interaction methods of BCI are classified on the
identification and collection of the signal: there are Invasive,
Partially Invasive and Noninvasive BCI.
The invasive category needs a neurosurgical implant of
the sensors on the cerebral cortex, the partially invasive one
requires the application of the sensors on the epidural or
subdural space to record Electrocorticographic (ECoG)
signal, while the noninvasive category uses external surface
sensors in contact with the scalp permitting to record
different kinds of signals, like Electroencephalography
(EEG), Magnetoencephalography (MEG) and functional
Magnetic Resonance Imaging (fMRI).
A different signal analysis, approaching to the EEGBCI, includes Event-Related (P300) Potentials, Slow
Cortical Potentials, Steady State Visual Evoked Potentials
(SSVEP), Sensorimotor Rhythms (SMRs), and the Event
Related Desynchronization or Synchronization (ERD/ERS)
produced by Motor Imagery (MI).

Keyword-Brain-Computer Interface (BCI); Augmentative and
Alternative Communication (AAC); Assistive Technologies;
Amyotrophic Lateral Sclerosis (ALS).

I. INTRODUCTION
Motor neuron diseases and degenerative neuromuscular
disorders are characterized by a gradual loss of muscular
function while usually retaining complete cognitive
functions.
The progressive neurodegeneration induces progressive
loss of upper and lower motor neurons, causing a
progressive complete destruction of the peripheral and
central motor system. The resulting condition is called
Completely Locked-in State (CLIS).

Copyright (c) IARIA, 2016.

ISBN: 978-1-61208-468-8

Figure 1. BCI Technology

84

ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

Most of projects detects P300 Potentials or Visual
Evoked Potentials but due to the need of sight in order to
concentrate on the desired object, there are many patients
who cannot use this technology. Furthermore, the weak
electrical signal created by P300 requires gel-based EEG
sensors, which means more time and hassle to prepare
before use and clean after use.
Braincontrol system, instead, based on Motor Imagery,
was developed by Liquidweb s.r.l. around the needs of CLIS
and can also be used by blind people.
The first prototype, able to recognize 6 imagined
movements, pull/push, top/bottom, left/right, was released
in the fall of 2010 [14]. It has been continuously
implemented between 2010 and 2012 and tested in the same
period with more than 30 healthy volunteers providing
excellent results and encouraging the development. The first
version, Braincontrol “Basic Communicator”, was
completed in the middle of 2013. It fills a technological void
for CLIS patients who cannot use eye-tracking systems or
other assistive technologies.
Future versions of BrainControl, which are currently
under development, will include advanced communication
and entertainment (virtual keyboard, text-to-speech, social
networks, email,), home automation (lights, temperature,
etc.), control of a wheelchair and robotics (See Figure 2).

terms of targets roadmap, sessions timing and number of
sessions, with regards to patients in locked-in state, in
particular using feedbacks and advices from the healthy
control group. The interaction system used is a sensorimotor
rhythm (SMR) based BCI on top of a neurological process
known as Event-Related Desynchronization (ERD). The
ERD is detectable as a decrease in power in the β-frequency
band on corresponding motor cortices. It has to be adapted
to person-specific by the use of machine learning
techniques. The heart of Braincontrol is a proprietary
classifier of EEG patterns based on neural network
technology and combined with an adaptive Bayesian
algorithm for customizing different needs in different
patients. The EEG headset, by Emotiv Inc. [19], detects and
transfers the signals to the computer through wireless
technology. The electrodes simply need to be dampened
using a saline solution, instead of a special gel required from
other headsets. It works like a mental joystick, detecting 6
types of imagined movements (IM), allowing a computer or
other external devices to be controlled (See Figure 3).

Figure 3. BraincontrolArchitecture

Figure 2. Roadmap

Working prototypes of all these functionalities have
been developed and one of these, in robotic field, is
BrainHuRo, a research project that applies BCI to humanoid
robots [15].
The rest of the paper is structured as follows. Section II
explains the aims of this study and the research protocol
with Braincontrol. Section III reports the results of the
study, concerning the percentage of success, while Section
IV draws conclusions about the results.

The device used for the study includes a “Yes/No/Don’t
know“ Selector (See Figure 4) and a “Sentence Finder” (See
Figure 5). The user interface uses a scanning mode to move
between available options and utilizes just one movementrelated thought to select the desired choice.

II. AIM AND METHOD
The first aim of this study was to verify the efficacy of
Braincontrol as an effective AAC communicator in patients
with communicative and motility disorder. This aim will be
evaluated on performing specific tasks described below. The
secondary aim was to validate the trainings methodology in

Copyright (c) IARIA, 2016.

ISBN: 978-1-61208-468-8

Figure 4. Yes/No/Don’t Know Selector

85

ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

After this first training phase the work is focused on the
improvement of performances, by increasing the scanning
speed and reducing the time of selection, in order to have a
fast and efficient interaction.
III.

RESULTS

In the period of August 2012 – June 2015 we carried out
sessions of training with two groups of users:

Figure 5. Sentence Finder

The trainings have been carried out in four remote
sessions (video conference with remote desktop control) of
one hour each, planned in one month period for each user,
from August 2012 to June 2015, with two groups of users:
I.
63 healthy volunteers
II. 42 patients with communicative and motility
impairment.
The sample of healthy users was considered as a control
group, to improve the quality of trainings through advices
and to verify eventual differences on the roadmap.
During the first training, the trainer explains to the
patient how the system works, its functionalities and the
training purpose, then he starts with multiple iterative
sessions of calibration and testing. During the calibration
phase (See Figure 6), the software records the EEG data
from the user which was asked to stay focused for a few
seconds on the movement-related thought that will be used
for controlling the system.
The test phases consist of asking the patients to select
predefined sequences of choices.
This iterative session is conducted for 30-40 minutes and
is replicated in the followings 3 sessions during the first
month. If the user selects at least 4 predefined choices
without errors during the test phase, the training is
considered successful.

I.
63 healthy volunteers
II. 42 patients with communicative and motility
impairment
A.
19 in initial or severe stage of the disease
B.
23 locked-in (10 of these are in a
condition similar to the complete locked-in state, with
no possibility to give feedback).
The group of healthy volunteers, as the group IIA (19
initial and severe patients), completed successfully the
training phase representing the 100% of the efficacy of the
device.
Also in the LIS group (IIB) 21 out of 23 patients
overcame the training phase (with a percent of 91% of
success). The two, in particular, were in similar CLIS, in
which cognitive abilities were unknown, and no kind of
feedbacks was possible.
These results were stable over time, after the first phase
of training. In patients who achieved the objectives it was
possible to continue with the training and make them
keen and able to use the device independently as a
communicator.
IV.

CONCLUSION

The aim of this study was to verify the efficacy and the
effectiveness of Braincontrol as an AAC, improving training
methodology with regards to patients in locked-in state. The
study was conducted from 2012 to 2015, on a group of 63
healthy users and on 42 patients with communication or
mobility impairment, planning four trainings in a one month
period. The results of this observation confirm that the
device, after the first phase training, is efficient and robust.
Trainings have been completed successfully for all the
healthy users and for patients in initial and severe stage of
the disease. Only 2 out of 42 patients located in the lockedin group failed the training. In particular, these patients were
in similar CLIS, in which cognitive status information where
unknown. Seventeen locked-in patients, who really need this
technology, are presently using the system as a
communicator.
ACKNOWLEDGMENT

Figure 6. Calibration

Copyright (c) IARIA, 2016.

ISBN: 978-1-61208-468-8

BrainHuro project has been realized between 2013 and
2015, partially funded by the Italian region of Tuscany
(POR-CREO Fesr 2007-2013 – Le ali alle tue idee) and

86

ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

involved the University of Siena, Liquidweb s.r.l., Humanot
s.r.l., Massimi Sistemi s.r.l. and Micromec s.r.l.

[8]

[9]

DECLARATION OF INTEREST STATEMENT
The authors disclose they have the following financial or
other interests in objects or entities mentioned in this paper:
•
•

Pasquale Fedele is founder and CEO of Liquidweb
s.r.l., the company producer of the BrainControl;
Myriam Gioia is a speech therapist, employee in
Liquidweb s.r.l. with trainer role.

[10]
[11]
[12]

[13]

REFERENCES
[1]

[2]

[3]
[4]

[5]

[6]

[7]

T. Carlson, G. Monnard, and J. del R. Millán, "Vision-Based
Shared Control for a BCI Wheelchair," International Journal
of Bioelectromagnetism, vol. 13, no. 1, 2011, pp. 20-21.
J. Carmena et al., “Learning to control a brain-machine
interface for reaching and grasping by primates,” PLoS
Biology, Vol. 1, 2003, E42.
N. Birbaumer et al., “A spelling device for the paralysed,”
Nature, 1999, pp. 297-298, 398.
A. Buttfield, P. W. Ferrez, and J. del R. Millán, “Towards a
robust BCI: error potentials and online learning,” IEEE Trans
Neural Sys Rehab, 2006; vol.14, pp. 164–168.
N. Birbaumer, "Breaking the silence: Brain-computer
interfaces (BCI) for communication and motor control,"
Psychophysiology, vol. 43, 2006, pp. 517-532.
M. A. Lebedev and M. L. Nicolelis, "Brain-machine
interfaces: past, present and future," Trends in Neurosciences,
vol. 29, no 9, 2006, pp. 536–546.
R. Sitaram, A. Caria and N. Birbaumer, "Hemodynamic
brain–computer interfaces
for communication and
rehabilitation", Neural Networks, 2009.

[14]

[15]

[16]

[17]

[18]

[19]

Copyright (c) IARIA, 2016.

ISBN: 978-1-61208-468-8

B. Z. Allison, E. W. Wolpaw and J. R. Wolpaw, "Braincomputer interface systems: progress and prospects", Expert
Review of Medical Devices, vol. 4, no. 4, , 2007, pp. 463-474
G. Dornhege, J. del R. Millán, T. Hinterberger and K. R.
Müller, "Toward Brain-Computer Interfacing", MIT Press,
2007.
M. Van Gerven et al., "The brain–computer interface cycle",
J. Neural Eng., vol. 6, 2009.
G. Pfurtscheller et al., "The Hybrid BCI", Frontiers in
Neuroprosthetics, vol. 2-3, 2010.
T. O. Zander and C. Kothe, "Towards passive brain–computer
interfaces: applying brain-computer interface technology to
human–machine systems in general", Journal of Neural
Engineering, vol. 8, 2011.
L. George and A. Lécuyer, "An overview of research on
“passive” brain-computer interfaces for implicit humancomputer interaction", International Conference on Applied
Bionics and Biomechanics (ICABB), 2010.
P. Fedele and M. Tavanti, “Braincontrol project“ poster and
demo, Mind Force conference, Centre for the Study of
Complex Systems, University of Siena, 2010.
A. Casals, P. Fedele, T. Marek, R. Molfino, G. G. Muscolo,
C. T. Recchiuto, “A robotic suit controlled by the human
brain for people suffering from quadriplegia,” TAROS 2013.
14th Towards Autonomous Robotic, vol. Springer Lecture
Notes in Artificial Intelligence.
T. Carlson and Y. Demiris, “Human-wheelchair collaboration
through prediction of intention and adaptive assistance,” IEEE
International Conference on Robotics and Automation, 2008,
pp. 3926-3931.
T. Carlson, G. Monnard, R. Leeb and J del R. Millán,
“Evaluation of Proportional and Discrete Shared Control
Paradigms for Low Resolution User Inputs,” IEEE Intl. Conf.
on Systems, Man, and Cybernetics, 2011, pp. 1044-1049.
L. Tonin, T. Carlson, R. Leeb, J del R. Millán, “BrainControlled Telepresence Robot by Motor-Disabled People,”
33rd Annual International Conference of the IEEE
Engineering in Medicine and Biology Society, 2011, pp.
4227-4230.
Emotiv Inc. website: www.emotiv.com [accessed March
2016]

87

