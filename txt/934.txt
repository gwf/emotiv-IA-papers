TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

ROM-based Inference Method Built on Deep
Learning for Sleep Stage Classification
Mohamed H. AlMeer, Hanadi Hassen, Naveed Nawaz
Computer Science & Engineering Dept, Qatar University, POB 2713, Doha, Qatar
Abstract â€“ We used a classical deep feedforward
neural network (DFFNN) for an automatic sleep stage
scoring based on a single-channel EEG signal. We
used an open-available dataset, randomly selecting one
healthy young adult for both training (â‰ˆ5%) and
evaluation (â‰ˆ95%). We also augmented the validation
by using 5-fold cross validations for the result
comparisons. We introduced a new method for
inferring the trained network based on a ROM module
(memory concept), so it would be faster than directly
inferring the trained Deep Neural Network (DNN). The
ROM content is filled after the DNN network is trained
by the training set and inferred using the testing set.
An accuracy of 97% was achieved in inferring the test
datasets using ROM when compared to the classic
trained DNN inference process.
Keywords â€“ PSG, Sleep stages, Deep Neural
Networks, DNN, FFNN.

1. Introduction
Sleep is essential to human health, and when a
person undergoes a reduced sleep period, abnormal
sleep patterns, or suffers a sleep illness such as
desynchronized circadian rhythms, he will face
cognitive, somatic, and cognitive symptoms [1].
There exists a relation between abnormal sleep
patterns and neuro diseases [2]. Recent research
shows that the detection of all sleep abnormalities,
DOI: 10.18421/TEM81-04
https://dx.doi.org/10.18421/TEM81-04
Corresponding author: Mohamed H. AlMeer,
Computer Science & Engineering Dept, Qatar University,
Doha, Qatar
Email: almeer@qu.edu.qa
Received: 02 February 2019.
Accepted: 23 February 2019.
Published: 27 February 2019.
Â© 2019 Mohamed H. AlMeer, Hanadi Hassen,
Naveed Nawaz; published by UIKTEN. This work is
licensed under the Creative Commons AttributionNonCommercial-NoDerivs 3.0 License.
The article is published
at www.temjournal.com

28

with

Open

Access

such as circadian disruption, could be a clear
indicator of a risk potential for the early stages of
neurodegenerative illnesses such as Alzheimer and
Parkinson diseases [3]. Sleep experts judge sleep
quality using electrical sensors attached to the
different parts of a personâ€™s body. Those signals
comprise an electroencephalogram (EEG), an
electrooculogram (EOG), an electromyogram
(EMG), and an electrocardiogram (ECG). A
polysomnogram (PSG) is the name for the entire set
of those related signals recorded through these
sensors.
The PSG data segments all recordings into 30second epochs, and the sleep stage experts assign
different stages according to Rechtschaffen and
Kalesâ€™ (R&K) [4] sleep manual as well as the
American Academy of Sleep Medicine (AASM) [5].
The process is a time-consuming and labor-intensive
full-manual approach, with multiple sensors having a
100 HZ sampling rate responsible for increasing the
amount of data collected. Human experts doing the
manual scoring demand specialized training, which
makes them expensive to hire. Additionally, the
rating quality depends on the raterâ€™s experience, and
the accuracy is less than 90% in most cases [6].
According to the R&K rules, in each 30-second
epoch, the sleep EEG signals were annotated as
belonging to one of five stages: WA, NREM1 (N1),
NREM2 (N2), NREM3 (N3) and NREM4 (N4; or
SWS), and REM. Not every epoch is a 100% fit in a
specific stage. A neurologist specialized in sleep
analysis is assigned to assess these stages. In detail,
the Wake stage (WA) is considered the normal body
function stage. The NREM1 is believed to be the
beginning of sleep where the eyes are closed. While
in the NREM2 stage, the light sleep stage, both heart
rate and body temperature are slowed down. In
NREM3, the person falls into the deep sleep stage,
during which the body repairs and regrows tissues.
Finally, the REM sleep period, called the dream
period, is characterized by faster brain activity,
breathing, and heart rate. In this study, we altered the
Rechtschafen and Kales sleep staging criteria [4],
merging the criteria for N1 and N2 into N1 and
merging N3 and N4 into a single stage (N2). The
WA and REM stages are unchanged.

TEM Journal â€“ Volume 8 / Number 1 / 2019.

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

Several studies attempting to develop automated
scoring methods for sleep stages based on multiple
biosignals (EOG, EEG, and EMG) have emerged
recently. They incorporate methods that extract the
frequency-domain, time-domain, or frequency-timedomain features from each recorded epoch. In many
of the studies using such multiple signals, the
different features concatenate into a single feature
vector composing the training features of the epochs
[7], [8], [9].
In this study, we present a novel, classic DFFNN
framework for automatic sleep stage scoring using a
single channel of EEG, and then we evaluate it. The
single EEG channel within the PSG signals and their
spectral components for the estimation of sleep
features is solely used. Four normalized power
frequency spectrums are extracted from the 500temporal data (5 seconds long acquired EEG signal),
constituting both training and testing epochs.
Most researches have used the classical method of
training a single or a mix of the following deep
networks (feedforward, convolutional neural
network, recurrent neural network, or long-shortterm memories) or a combination for basic training
and inference operations. However, instead of
inferring the same-trained network, we will
alternatively accomplish the inference of a fulltrained DNN for sleep stage classification, using a
concept of basic storage memory (or simply a ROM).
The content of every location within the ROM is
labeled with the corresponding sleep stage class, but
its indices are identified from a prior training process
acting on the proposed network.
We compared the performance of the built neural
network model with that of the ROM model. We
achieved a state of-the-art accuracy of 81% (97%
resemblance) but had some difficulty comparing the
results to other studies, since, to our knowledge,
there was absolutely no such previous usage of this
new inference.
2. PSG Data Set
The data used to train, test, and evaluate the
model is a publicly available Sleep-EDF database
from the Physionet repository [10]. All the subjectâ€™s
signals are whole-night polysomnographic sleep
recordings embedding EEG_Fpz-Cz and EEG_Pz-Oz
electrodes, EOG_horizontal, and a submental EMG
chin signal, besides other signals related to breathing
rate, oxygen concentration, and body movements.
The PSG recordings for the PSG_SC_4002E subject
in particular is obtained from a healthy Caucasian
male volunteer taking no medication; this subject
was randomly selected for the research. Additionally,
it is worth noting that all signals were technically
digitized using a 100 Hz sampling rate.
TEM Journal â€“ Volume 8 / Number 1 / 2019.

Although the original PSG-EEG data was divided
into 30s epochs adequate for offline analysis, we
have rearranged it to 5s epochs instead. This
increased the number of features generated x6 while
preserving the feature representation of the
hypnogramsâ€™ 5 stages, as will be shown in the results
section. The EEG data collected consists of 16,947
sets, each 500 samples long (8,503,974 samples
stored in a 132,908 MB file). Randomly selected sets
from the PSG_SC_4002E subject were used to form
the training batches, which are composed of 4.7% of
the total epochs (800 epochs), while the remaining
constitutes the test set. Table 2. presents a summary
of the data for this subject. The record was acquired
for the whole day for both the WA and other sleep
stages. See Figure 3. for the training to testing to
validation ratios.
3. System Description
In this section, an overall system architecture is
presented in detail. The system was divided into a
training module and a deployment module. The
system architecture is shown in Figure 1.
DNN Training Module: The objective of the modeltraining module is to find an accurate prediction of a
DNN that can take the EEG signal as input and
intelligently generate a sequence of the sleep stages
using one stage label assigned to each 5-second
epoch. To generate such a prediction algorithm, we
rely on the model-training module to extract features
from the EEG data and then find classification
algorithms to identify the best feature and algorithm
configuration. Model training is described in sections
5.2 and 6.
Independent Inference Modules (Non-DNN or ROMBased Module): After the same pattern goes through
a feature extraction process, it is mapped to a binary
discretized integer or index known as a memory
address. Those addresses are applied to a memory
module, where classification labels are stored
representing the sleep stages (numbered between 0â€“
3). When the deployment process finishes, a direct
substitution in the memory module produces a direct
prediction. The inference model is described in
sections 5.3 through 5.4.
4. Deep Feed Forward Neural Network
(DFFNN)
Artificial neural networks inspired by biological
neurons to solve some prediction in many
classification and recognition application, such as for
instance, vision, voice, and natural language. With
their recent successor, the Deep Neural Networks or

29

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

(DNN), they have achieved close to 100% success in
different pattern recognition fields in recent years.
DNN has an architecture of multiple layers, input
layer with a descriptor X l , L hidden layers, and an
output layer to enforce a prediction. Multi-layer feed
forward neural networks consist of neurons into
layers. Neurons on all layers are fully connected to
all neurons to adjacent layer. In each layer all
neurons use the same activation function. The input
to neurons of the other layers is the output
(activation) of the previous layerâ€™s neurons, except
for the input layer.
Figure 4. [11] shows a multilayer feedforward
neural network. The input of this network is shown
below, with its weights matrix and bias vectors. The
Figure shows the multilayer neural network in which
every layer contains a weight matrix W beside a bias
vector b beside the output vector y as shown in
equation 1.
ğ‘¥1
â¡ğ‘¥2â¤
â¢ â¥
..
ğ‘¥ = â¢ â¥,
â¢ .. â¥
â¢ .. â¥
â£ğ‘¥ğ‘›â¦
ğ‘1
â¡ğ‘2â¤
â¢ â¥
..
ğ‘=â¢ â¥
â¢ .. â¥
â¢ .. â¥
â£ğ‘ğ‘›â¦

ğ‘¤1,1 ğ‘¤1,2 â€¦ . . ğ‘¤1, ğ‘š
â¡ ğ‘¤2,1 ğ‘¤2,2 â€¦ . . ğ‘¤2, ğ‘š â¤
â¢
â¥
..
â¥,
ğ‘Š=â¢
..
â¢
â¥
..
â¢
â¥
â£ğ‘¤ğ‘›, 1 ğ‘¤ğ‘›, 2 â€¦ . . ğ‘¤ğ‘›, ğ‘š â¦

TANH
RELU
Leaky ReLU
Softmax

30

5. Methodology
In this study, we present a novel approach to
automatically inferring a trained DNN to detect the
WAKE, NREM1â€“2, NREM3â€“4, and REM of sleep
classes within a single EEG record. A Feed Forward
Deep Neural Network (FFDNN) model is trained
with the four sets and inferred using a ROM module.
Figure 2. shows a graphical representation of the
approach.
5.1 Pre-processing

(1)

No preprocessing is applied here, except for the
manual selection of trained epochs, to ensure they
contained no deformed signals or severe noiseâ€”a
precaution to ensure correct training. Although the
generic data presented in the Sleep-EDF database has
WAKE and REM stages in more length than other
classes, the current study used the complete number
of sets without trimming.
5.2 Training Pattern Matrix Construction

Each of the m components of the input vector x =
{x1, x2, . . ., xm} feeds forward to the n neurons. The
first hidden layer generates an output as 1Y = 1f (1W Â·
X + 1b), and the final output of the network is given
by 2Y = 2f (2W Â· 1Y + 2b). It passes through the
activation function that could be a sigmoidal, a tan
sigmoidal (TANH), a hyperbolic tangent function
(ReLU), a Leaky ReLU, or a Softmax, all defined as
shown below:
Sigmoida,

The output of these functions is linearly combined
with weights into a network output f(x). The strategy
of how this network processes information is deeply
dependent on its building architecture and the
number of neurons as well as the correct choice of
the transfer functions, and their diversities among
layers has the biggest impact for training.

ğ‘“(ğ‘¥) =

ğ‘“(ğ‘¥) =

1
1+ğ‘’ ğ‘¥

1âˆ’ğ‘’ âˆ’ğ‘¥
1+ğ‘’ âˆ’ğ‘¥

ğ‘“(ğ‘¥) = max(0, ğ‘¥)

ğ‘“(ğ‘¥) = ax, x < 0, , = 0, x â‰¥ 0
ğœ(ğ‘§) =

ğ‘’ âˆ’ğ‘§ğ‘—
ğ‘§ğ‘˜
âˆ‘ğ¾
1 ğ‘’

ğ‘“ğ‘œğ‘Ÿ ğ‘— = 1, â€¦ , ğ¾

The classification of sleep stages was based on
time segments 5s long, and the neurologist specified
the target classes. The frequency content of PSGEEG channels advised by the specific literature was
adopted for this current study and used for
classification [13]. The physiological nature of the
signals dictates the selection of those frequencies,
and they covered a range from [0.5, 20] Hz.
Specifically, the delta (0.5â€“4Hz), theta (4â€“8Hz),
alpha (8â€“12Hz), and sigma (12â€“20Hz) bands were
taken. The normalized image of the 4-frequency
power density is utilized as feature vectors.
To extract those frequency-domain features
successfully, we first segment each 5-second epoch
into 500-long readings of the temporal subpatterns.
Then, we estimate the power spectral density of each
subepoch, resulting in 250 frequency bins covering
the range from 0 Hz to 50 Hz, each 5 bins
representing 1 Hz. We then normalize these power
estimates over a total power range of 0â€“20Hz. The
next formula shows the relative spectral feature FS of
a signal segment, which the Discrete Fourier
Transform evaluates, resulting in a relative power in
the specified frequency band [fc1, fc2] by relation:

TEM Journal â€“ Volume 8 / Number 1 / 2019.

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

ğ¹ğ‘† =

âˆ‘ğ‘˜âˆˆğœƒ|ğ‘Œ(ğ‘˜)|2

,
ğ‘
2 |ğ‘Œ(ğ‘˜)|2
âˆ‘ğ‘˜=0
â€²

ğ‘âˆ’1

2ğœ‹

ğ‘Œ(ğ‘˜) = ï¿½ ğ‘¦(ğ‘›)ğ‘’ âˆ’ğ‘—ğ‘˜ğ‘› ğ‘

Where Î¸ is the indices group for the frequency
values fk= k/N, fs belongs to [fc1, fc2]. This will
form a 2D training pattern of four columns (vectors)
by Q rows, where Q denotes the number of training
epochs. For every feature vector, the corresponding
sleep class specified by the neurologist is appended.

Where F1, F2, F3, and F4 represents the four
normalized spectrum values. This process finally
generates a memory space of 1,048,576 (1M)
different storages; each holds one 4-class symbol
while simply being addressed by the above index of
equation 2. This index supposedly points to the class
level. In this way, we have totally converted the
inference process of a fully trained DNN to a simple
memory address-content problem.

5.3 ROM-based Inference Process

5.4 Memory Content Generation Process

The main objective of this part of the data
preparation process is to convert the four-spectrum
bands to a 20-bit integer index used to infer a
memory module for class content. First, every fivesecond interval of the EEG signal (or 500 EEG
readings) is extracted and labeled in accordance with
the sleep states the SPG_SC_4002E subject
undergoes. Second, the Fast Fourier Transform (FFT)
is applied to the time series, set by set, and 250frequency vector bins are generated, covering a range
of 0â€“50 Hz. The sampling frequency is 100 Hz, with
every 1 Hz represented by 5 frequency readings, each
0.2 Hz. Third, the four different frequency bands
identified with the notations (alpha, beta, theta, and
sigma) are then computed, as shown in equation 1.
Fourth, the power densities are then normalized over
the total power content from 0â€“20 Hz, resulting in a
normalized or relative power density pattern
distribution across a 2D matrix.
Figure 5. shows the four snapshots of four sets of
EEG signals covering the four stages of sleep for a
random subject. It shows a frequency content of 250
Hz. The spectrum plots show the density of power
near 0 Hz, which drops sharply as the frequency
approaches 15 Hz, eventually reaching zero-close
values around 250 Hz. Based on this observation, 7bit is assigned to represent the first two bands, alpha
and beta, since their content is highly dense; 4-bit
and 2-bit are assigned to the remaining other two
bands, theta and sigma, respectively, since their
contents are less dense.
Next, each of the four relative frequency power
densities, F4 (sigma), F3 (theta), F2 (beta), and F1
(alpha), are converted to an integer ranging from 0 to
22-1, 24-1, 27-1, and 27-1, respectively, and finally
rounded. This process results in an integer from 0â€“3,
0â€“15, 0â€“127, and 0â€“127, expressing values for the
frequency spectrum bands, F4, F3, F2, and F4,
respectively. All four integers are extracted and
substituted in the weighting formula below to form a
single large-range integer value most suitable for a
memory module index (address).

Here in this data preparation stage, we use the
reverse engineering concept to effectively compute
the corresponding features of 4 frequency bands
synthetically resulting from a given index value. We
start using an index from 1 to (220-1) or the so-called
full-memory address range. The calculation of the 4
synthetic frequency bands, each represented by
different binary bits, is generated when substituted in
next formulae:

ğ‘›=0

(2)

Index = F4*4*(218) + F3*16*(214) + F2*128*(27) + F1*128,

TEM Journal â€“ Volume 8 / Number 1 / 2019.

Synthetic Band_4 = Shift_Right
(0xC0000), 18-bit) / 4.0

(Index

&&

Synthetic Band_3 = Shift_Right
(0x3C000), 14-bit) / 16.0

(Index

&&

Synthetic Band_2 = Shift_Right
(0x03F80), 7-bit) / 128.0

(Index

&&

Synthetic Band_1 = Index && (0x0007F) / 128.0
This should generate a 2D matrix of four values
representing a normalized synthetic power spectrum,
repeated over the full range of a 20-bit binary
address, or 1,048,576.
This 1M-by-4 memory matrix is prepared for
inference (or in other words, for testing the network).
This network is supposedly the same network, which
is trained using the subjectâ€™s training patterns
prepared earlier, as explained in section 3. The
inferred or predicted classification classes from the
previous operation are used as a content to fill the
memory module using next simple formula:
MEMORY[Index] = Prediction_Class.
This should prepare the inference operation
separately from the DNN used for training and
enable a faster inference operation. Figure 7. shows
ROM content when training patterns are firstly
mapped in (800 sets), and after it is fully mapped
with the generated synthetically from the inference
process (524287 sets).

31

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

6. DNN Architecture and Training Parameters
All kernels or parameters reported in this study are
settled after some trial-and-error attempts. Figure 2.
illustrates the graphical representation of the DNN
structure with normalized 4 frequency bands chosen
as input samples. This proposed DNN architecture
encompasses one input layer, followed by two fully
connected hidden layers, and finishes with one output
layer. The activation functions used in the input and
the two hidden layers are the TANH function, while
the one used in the output layer is the SOFTMAX
function. The weight initialization algorithm used is
XAVIER, while the regularization used to overcome
overfitting was l2(1e-4). The loss function used in
the
output
layer
was
chosen
to
be
NEGATIVELOGLIKELIHOOD.
A conventional backpropagation training algorithm
is employed to train the DNN, with a batch size of
800. In the training algorithm, the batch size is used
to denote the number of epochs or the number of
signals used for each training update of the networkâ€™s
parameters. Here, the batch size is taken to be equal
to the number of sets used in training.
Backpropagation calculates the gradient of the loss
function with respect to the weights. Error signals
emerging from each pass are passed backward
through the network during training to update the
weights. The batch size of 100 was used in this
work. The learning rate was commonly tested from
10-1 to 10âˆ’3 for the Adam optimizer. The
implementation is based on the DeepLearning4J Java
framework, especially designed for creating, testing,
and adjusting hyperparameters of different deep
neural architectures [12].
7. Results
The proposed DNN is implemented on a ThinkPad
Laptop IntelÂ® Coreâ„¢ i7-5600U CPU@ 2.6 GHz
with 8 GB RAM using the MATLAB programming
software to simulate the ROM inference model and
DeepLearning4J Java framework model. It took
about 15 minutes to complete all epochs of training
with 30,000 iterations.
The confusion matrix across all stages is
represented in Table 1. We found that 85% of the
EEG signals are normal and correctly classified as
WAKE signals. Small percentages of 4.4%, 4.7%,
and 5.2%, of the normal EEG signals are wrongly
classified as N1â€“2, N3â€“4, and REM, respectively;
62% of the EEG signals are correctly classified as
NREM1â€“2 signals; 1.4% of the EEG signals were
wrongly classified as WA, NREM3â€“4 (18%), and
REM (17.6%); 89% of the EEG signals are correctly
classified as NREM3â€“4, with 1.4% wrongly
classified as WA, NREM1â€“2 (9.2%), and REM

32

(0.1%). The performance (Accuracy, Precision, and
F1-score) of the proposed model can be seen in Table
3. for Subject PSG_SC_4002E when the
DeepLearning4J model is used for tested inference.
Moreover, when the same test patterns undergo the
proposed ROM inference model, a close resemblance
in results is reached: 79.6% from 81%, or 98.3% of
the expected accuracy. Table 2. shows the accuracies
for the DeepLearning4J platform and ROM model as
well as the relative resemblance rate. Figure 6. lists
the results of testing the two models, the DNN and
ROM-based, using 95.3% of the subject sets. Clearly,
the resemblance between the responses of the two
models is imminent and reaches 98%.
Table 4. shows the cross-validation done using the
MATLAB Classification Learner Tool with 5-folds
validation when the full-set of the 16,974 subject sets
is tested. Different classifiers used included Trees,
Ensembles, Support Vector Machine (SVM), and KNearest Neighbors (KNN). The best accuracy
reached was for SVM (Final grain Gaussian) at
89.8% besides the KNN (medium grained) algorithm
for 89.2%.
8. Discussion
Table 5. represents a summary of the conducted
studies in an automated detection of sleep stages
during the last decade. According to [14], around 50â€“
70 million adults in the United States are affected by
sleep disorders such as parasomnias, disorders, and
hypersomnia. The overnight PSG is used to diagnose
sleep disorders including brain monitoring using
EEG. Trained technologists conventionally conduct
the PSG analysis. Recently, the PSG analysis has
been automated with the help of machine-learning
algorithms trained using physiological datasets. The
EEG signal is not limited to the sleep study; it is also
applied in many other studies such as happy and
unhappy emotions studies, as in [13] where they first
registered the EEG signal using 14-channels wireless
EMOTIV. After filtering the signal, they decompose
it, using a window of 1 s, to 5 frequency bands
resulting in 70 features normalized by scaling
between 0 and 1. Then, the SVM is used to classify
the happy and unhappy emotions.
One of the tools deployed for the automatic
annotation of sleep staging is SLEEPNET proposed
by [15]. They apply a deep Recurrent Neural
Network (RNN) for automatic sleep staging
annotation and achieved a performance comparable
to the human level. Three types of EEG features were
used: the raw waveform, the spectrogram, and
expert-defined features. To evaluate the system,
conventional classifiers such as Logistic Regression,
Tree Boosting, and Multilayer Perceptron were
compared to deep learning-based classifiers, an

TEM Journal â€“ Volume 8 / Number 1 / 2019.

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

RNN, and a Convolutional Neural Network (CNN)
[17]. The RNN achieved the best accuracy for sleep
stages classification. Another research applying an
RNN for sleep stages classification is proposed by
[13]. They train the RNN using energy features that
are calculated by taking the summation of the
magnitudes of the squared components of the signal.
Instead of using handcrafted features, the deep
learning is recently employed as a successful
unsupervised feature learning method. In [18], the
EEG, EOG, and EMG signals are filtered then
divided into segments of 30 s with zero overlaps.
These signals are then passed to a three-layer Sparse
Deep Belief Network for features extraction. The
classification of the extracted features was achieved
by combining multiple classifiers, in particular, the
Hidden Markov Model (HMM), SVM, and KNN.
The combination of these classifiers with the
application of classification entropy voting resulted
in a 91% accuracy.
Another research employing deep belief nets
(DBNs) for features extraction was presented in [25].
The DBNs were trained using a dataset of EEG,
EOG, and EMG signals. All signals were first
preprocessed by notch filtering, then three different
experiments were run using these filtered signals. In
the first experiment (feat-GOHMM experiment), 28
handcrafted features were used to train a Gaussian
observation hidden Markov model (GOHMM). The
feature set was reduced using a Principle Component
Analysis (PCA). In the second experiment (feat-DBN
experiment), they trained the DBNs using the 28
handcrafted features, then the HMM was used on top
of the DBNs. In the last experiment (raw-DBN), the
DBN used raw data instead of handcrafted features,
then the HMM was built on top of it. The
comparative analysis between the three experiments
showed that the feat-DBN performs better than the
raw-DBN and feat-GOHMM.
The Quantization Bidirectional Long Short-Term
Memory (qBi-LSTM) was applied in [22] for the
classification of sleep stages. After filtering the EEG,
EOG, and EMG signals, 28 handcrafted features
were extracted and normalized. In addition to the
qBi-LSTM, the authors applied BLSTM and a DBN.
The performance of the qBi-LSTM outperformed the
other two models.
A deep learning approach for both the feature
extraction and classification of sleep stages was
proposed in [23]. They employed two CNNs for
extracting time-invariant features from raw EEG.
Each CNN consists of 4 convolutional layers and 2
max-pooling layers. The temporal information of the
sleep stages transitions was encoded using Bi-LSTM.
They evaluated their model using two datasets: the
first was Montreal Archive of Sleep Studies (MASS)
and the second was Sleep-EDF.

TEM Journal â€“ Volume 8 / Number 1 / 2019.

Recently, the CNNs successful in many computer
vision tasks have been applied to the task of sleep
stage classification. A CNN with two convolutional
and pooling layers, two fully connected layers, and a
SoftMax layer was implemented in [19] to achieve
sleep stage scoring using a PSG dataset. They
compared CNN results with their previous study [20]
in which they performed a time-frequency-based
analysis by using Morlet wavelets for feature
extraction. The classification was achieved using a
special type of neural network, stacked sparse
autoencoders (SAE). Their results showed that the
SAE model outperforms the end-to-end CNN
training using a PSG dataset.
Another application of CNNs on sleep staging is
proposed by [24]. Using single-channel EEG raw
signals, the CNNs were used to learn features and
perform the classification of sleep stages. The
proposed network consists of 12 convolutional layers
followed by 2 fully connected layers trained on Sleep
Heart Health Study (SHHS) data. The proposed
network achieved an accuracy of 0.87 and Cohen
kappa of 0.81.
Instead of using only single-channel EEG, the
authors in [25] proposed the use of a CNN with
multiple-channel signals. The CNN model they built
is based on a VGG network proposed by [26]. It
consists of 17 convolutional layers separated by maxpooling layers followed by two fully connected
layers for the classification of the features extracted
by the previous convolutional structure. The data
used is Sleep-EDF Database and Synthetic data.
Compared to [6], which employs the CNN with
single-channel EEG, this multiple-channel approach
with a much deeper network achieved a better
performance even after testing the network with
single-channel EGG data.
A Bayesian Neural Network classifier was
implemented in [27] to achieve sleep stages
classification. The proposed two-layer network was
trained on a database of 184 PSG. The preprocessing
of the signals included noise filtering and artifact
removal. Two types of features were extracted: in the
first, five energy features were extracted from the
single EEG channel, and in the second, twelve
energy features were extracted from three
multimodal (EEG, EOG, breathing [Flow]) channels.
The classification accuracy on the multimodal
channels is higher than that on the single channel.
In this work, the main novelty is the
implementation of a DNN to automate the
classification of combined four sleep stages using a
single EEG channel into WAKE, NREM1 and
NREM2, NREM3 and NREM4, and REM stages. A
classic DFFNN is adopted to train 4.7% of a subject
set. By using the techniques of reverse engineering,
524,287 of testing sets are synthetically generated for

33

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

inferring the trained network. When done, the
corresponding class predicted is stored in a ROM
module. This module is separately used to infer the
DNN for the remaining 95.3% of the subjectâ€™s data
set.
More speed is expected when inferring a DNN
using this model than with the network used for
training; therefore, we expect this method to be more
suitable for real-time applications. We estimate that,
for embedded systems characterized for small
memory capacity and low power computation, this
technique would be efficient in implementing
extrahuge DNNs.
9. Conclusion
The proposed model is introducing a solution for
inferring a fully trained network for sleep stage
classification from a single-source brain EEG signal

by using a ROM model instead of the trained
network. Features have been extracted from the 500sample epoch set when the FFT operation is applied,
resulting in a four-spectrum power density for the
alpha, beta, theta, and sigma regions. An average
accuracy of 81% for the DeepLearning4J model and
79.6% for the deployment ROM model was reached
when test sets were performed, even though a
reduction of the input features was 500-to-4. The
trained pattern constituted of 4.7% (800 sets) of the
PSG_SC_4002E subject undergoing this experiment,
while the test set was 95.3% (16,174 sets). The new
ROM model used a trained set to fill 524,287 classes,
covering the entire range of the anticipated fourfrequency spectrum. The advantage of the proposed
model presented in this paper, however, is the
separate intake for the inference process away from
the trained DNN network.

Figure 1. Overview of the proposed Approach

Figure 2. Illustration of the DNN architecture

34

TEM Journal â€“ Volume 8 / Number 1 / 2019.

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

Figure 3. The allocation of the EEG data used for training and testing the proposed algorithm

Figure 4. Multilayer Perceptron Network [11].

Figure 5. Example of EEG frequency spectrum of the four sleep stages belonging to PSG_SC_4002E subject. Upper left,
upper right, lower left, and lower right will be for sleep stage â€œWakeâ€, â€œNREM 1,2â€, â€œNREM 3,4â€, and â€œREMâ€
respectively

TEM Journal â€“ Volume 8 / Number 1 / 2019.

35

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

Figure 6. (a) Target sleep classes forming desired DNN output; (b) Resulting classes emerging from DNN-trained
DeepLEarning4J Java inference model; (c) Resulting classes emerging from DNN-trained ROM-based inference model

36

TEM Journal â€“ Volume 8 / Number 1 / 2019.

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

Figure 7. Comparison between the ROM content with the training set filled (upper image) and when filled after the
network is inferred with total range of 524,287 sets (lower image)
Table 1. Sleep stage EEG confusion matrix for DeepLearning4J Java model

Original

Prediction
NREM 1-2
499
1631
164
320

W
9685
37
25
77

W
NREM 1-2
NREM 3-4
REM

NREM 3-4
534
466
1591
42

REM
592
458
2
851

Table 2. Sleep stage epoch distribution with accuracies for original data, DL4J model, and ROM model
Sleep Stages
W
NREM 1-2
NREM 3-4
REM
Total

Number of
Epochs
11,310
2,592
1,782
1,290
16,974

Percentage
66.6%
15.3%
10.5%
7.6%
100%

DL4 Stage
Acc.
85.6%
62.9%
89.2%
65.9%
81%

ROM Stage
Acc.
90.6%
47.9%
83.1%
41.3%
79.6%

ROM/DL4J %
105.8%
76.1%
93.2%
62.6%
98.3%

Table 3. Results for inference for subject PSG_CS_4002E using DeepLearning4J model
Accuracy
81%

Precession
66.5%

Recall
76%

F1 Score
70%

Table 4. Matlab Classifier Learner accuracies for different classification algorithms for subject PSG_SC_4002E
with 16,974 sets.
Classification learner

Prediction accuracy (%)

Trees
Fine Tree
Medium Tree
Coarse Tree
SVM (Support Vector Machine)
SVM linear
SVM final gaussian
SVM Coarse Gaussian
Ensembles
Ensemble Boosted Trees
Ensemble Bagged Trees
Subspace Discriminant
Subspace KNN
RUS Boosted Trees
KNNs (K- Nearest Neighborhood)
Fine
Medium KNN
Coarse

TEM Journal â€“ Volume 8 / Number 1 / 2019.

84.8
78.1
73.8
88.2
89.8
88.7
83.9
89
66.1
75.7
79.6
86
89.2
88.5

37

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.
Table 5. Summary of Sleep Stages Classification Related Work.
Reference

Title

Dataset

[16]

SLEEPNET:
Automated Sleep
Staging System
via
Deep
Learning

PSGs of 10,000
patients from the
Massachusetts
General
Hospital
(MGH)
Sleep Laboratory.

[13]

Real-Time EEGBased Happiness
Detection System

EEG recording using
14-channels wireless
EMOTIV.
600
samples
per participant

Happy
and
unhappy
emotions
classification

[18]

A
Recurrent
Neural
SleepStage Classifier
Using Energy
Features of EEG
Signals
Automatic sleep
stage
classification
based on sparse
deep belief net
and
combination of
multiple
classifiers
Automatic Sleep
Stage
Scoring
with
SingleChannel
EEG
Using
Convolutional
Neural Networks
Automatic sleep
stage
scoring
using
timefrequency
analysis
and
stacked
sparse
autoencoders
Bi-directional
Long Short-Term
Memory
using
Quantized data of
Deep
Belief
Networks
for
Sleep
Stage
Classification
DeepSleepNet: A
Model
for
Automatic
Sleep
Stage
Scoring Based on
Raw
Single-Channel
EEG

Sleep-EDF database

Sleep
Stage
Classification
Using
Unsupervised
Feature Learning
A convolutional
neural network
for sleep stage
scoring from raw
single-channel
EEG
Deep
Sleep:
Convolutional
Neural Networks
for Predictive
Modeling
of
Human
Sleep
Time-Signals

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

38

Purpose of the
Study
Sleep
stages
classification.

Features

Classifier

Results

- Raw EEG
Features.
Spectrogram
features
Expert
defined
features
Power
Spectral
Density (PSD)

- CNN
- RNN
- RNN-CNN

Sleep
Stages
Classification

energy
features
extracted on 30s
epochs
from
EEG signals

Recurrent
Neural Classifier

Using RNN
-Average accuracy
of 85.76%
-Algorithm-expert
inter-rater
agreement (IRA) of
Îº = 79.46%
accuracy of subjectdependent model
75.62%
and
subjectindependent model
65.12%
Average
classification
accuracy 87.2%

UCD
database

Sleep
Stages
Classification

Deep
Belief
Network
features

Combination of
HMM,
KNN,
and SVM

91.31%.

sleep PSG dataset

sleep
scoring

stage

convolutional
neural networks
(CNNs)

convolutional
neural networks
(CNNs)

overall accuracy:
74%
F1-score: 81%

sleep PSG dataset

sleep
scoring

stage

time-frequencybased analysis
using
Morlet
wavelets

Stacked Sparse
Autoencoders

Overall
78%
Mean
84%

SVM

Accuracy:
F1-score:

Vincentâ€™s University
Hospital / University
College
Dublin's
Sleep
Apnea
Database.

sleep
scoring

stage

28 handcrafted
features.

Quantization Bidirectional Long
Short-Term
Memory (qBiLSTM)

Precision: 86%
Recall:72.1%
F-Measure:75.27%

Montreal Archive of
Sleep
Studies
(MASS) and SleepEDF.

sleep
scoring

stage

Deep learning
features

CNN
BLSTM

Vincentâ€™s University
Hospital
and
University
College Dublin

Sleep
Stage
Classification

DBNs Features

HMM

MASS:
Overall
Accuracy:86.2%
macro
F1-score:
81.7
Sleep-EDF:
Overall Accuracy:
82.0%
Macro
F1-score:
76.9
Accuracy (mean Â±
std) : 72.2 Â± 9.7

data from the Sleep
Heart Health Study
(SHHS)
(Single Channel)

sleep scoring

CNN

CNN

Accuracy:
kappa: 0.81

-Sleep-EDF
Database.
-Synthetic data.

sleep
stages
classification

CNN

CNN

overall
classification
accuracy
of 81%

and

0.87

TEM Journal â€“ Volume 8 / Number 1 / 2019.

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.

[27]

[17]

Multi-Class Sleep
Stage Analysis
and Adaptive
Pattern
Recognition
The use of neural
networks in the
analysis of sleep
stages and the
diagnosis
of
narcolepsy

database of 184
polysomnography
overnight
observations

sleep
stages
classification

References
[1]. Medic, G., Wille, M., & Hemels, M. E. (2017). Shortand long-term health consequences of sleep
disruption. Nature and science of sleep, 9, 151.
[2]. Abbott, S. M., & Videnovic, A. (2016). Chronic sleep
disturbance
and
neural
injury:
links
to
neurodegenerative disease. Nature and science of
sleep, 8, 55.
[3]. Wulff, K., Gatti, S., Wettstein, J. G., & Foster, R. G.
(2010). Sleep and circadian rhythm disruption in
psychiatric and neurodegenerative disease. Nature
Reviews Neuroscience, 11(8), 589-599.
[4]. Hori, T., Sugita, Y., Koga, E., Shirakawa, S., Inoue,
K., & Uchida, S. (2001). Sleep Computing Committee
of the Japanese Society of Sleep Research Society
Proposed supplements and amendments to'A Manual
of Standardized Terminology, Techniques and
Scoring System for Sleep Stages of Human Subjects',
the
Rechtschaffen
&
Kales
(1968)
standard. Psychiatry Clin Neurosci, 55(3), 305-310.
[5]. Berry, R. B., Brooks, R., Gamaldo, C. E., Harding, S.
M., Marcus, C. L., & Vaughn, B. V. (2012). The
AASM manual for the scoring of sleep and associated
events. Rules,
Terminology
and
Technical
Specifications, Darien, Illinois, American Academy of
Sleep Medicine, 176.
[6]. Rosenberg, R. S., & Van Hout, S. (2013). The
American Academy of Sleep Medicine inter-scorer
reliability program: sleep stage scoring. Journal of
clinical sleep medicine, 9(01), 81-87.
[7]. Lajnef, T., Chaibi, S., Ruby, P., Aguera, P. E.,
Eichenlaub, J. B., Samet, M., ... & Jerbi, K. (2015).
Learning machines and sleeping brains: automatic
sleep stage classification using decision-tree multiclass
support
vector
machines. Journal
of
neuroscience methods, 250, 94-105.
[8]. Huang, C. S., Lin, C. L., Ko, L. W., Liu, S. Y., Su, T.
P., & Lin, C. T. (2014). Knowledge-based
identification of sleep stages based on two forehead
electroencephalogram
channels. Frontiers
in
neuroscience, 8, 263.
[9]. GÃ¼neÅŸ, S., Polat, K., & Yosunkaya, Å. (2010).
Efficient sleep stage recognition system based on
EEG signal using k-means clustering based feature
weighting. Expert Systems with Applications, 37(12),
7922-7928.

TEM Journal â€“ Volume 8 / Number 1 / 2019.

5
energy
features and 12
energy features

Bayesian Neural
Network
Classifier

Mean classification
accuracy on single
channel: 88.7%
On
Multimodal
channels: 98.6%

Convolutional
(CNN)
and
recurrent (RNN)
neural networks

[10]. PhysioNet: The Sleep-EDF database Expanded,
Retrieved from:
http://www.physionet.org/physiobank/database/sleepedfx/.
[accessed: 05 January 2019].
[11]. Siddique, N., & Adeli, H. (2013). Computational
intelligence: synergies of fuzzy logic, neural networks
and evolutionary computing. John Wiley & Sons.
[12]. Team, D. (2016). Deeplearning4j: Open-source
distributed deep learning for the jvm. Apache
Software Foundation License, 2.
[13]. Hsu, Y. L., Yang, Y. T., Wang, J. S., & Hsu, C. Y.
(2013). Automatic sleep stage recurrent neural
classifier using energy features of EEG
signals. Neurocomputing, 104, 105-114.
[14]. Hillman, D. R., Murphy, A. S., Antic, R., &
Pezzullo, L. (2006). The economic cost of sleep
disorders. Sleep, 29(3), 299-305.
[15]. Biswal, S., Kulas, J., Sun, H., Goparaju, B.,
Westover, M. B., Bianchi, M. T., & Sun, J. (2017).
SLEEPNET: automated sleep staging system via deep
learning. arXiv preprint arXiv:1707.08262.
[16]. Jatupaiboon, N., Pan-ngum, S., & Israsena, P.
(2013). Real-time EEG-based happiness detection
system. The Scientific World Journal.
[17]. Stephansen, J. B., Ambati, A., Leary, E. B., Moore,
H. E., Carrillo, O., Lin, L., ... & Pizza, F. (2017). The
use of neural networks in the analysis of sleep stages
and the diagnosis of narcolepsy. arXiv preprint
arXiv:1710.02094.
[18]. Zhang, J., Wu, Y., Bai, J., & Chen, F. (2016).
Automatic sleep stage classification based on sparse
deep belief net and combination of multiple
classifiers. Transactions of the Institute of
Measurement and Control, 38(4), 435-451.
[19]. Tsinalis, O., Matthews, P. M., Guo, Y., & Zafeiriou,
S. (2016). Automatic sleep stage scoring with singlechannel
EEG
using
convolutional
neural
networks. arXiv preprint arXiv:1610.01683.
[20]. Tsinalis, O., Matthews, P. M., & Guo, Y. (2016).
Automatic sleep stage scoring using time-frequency
analysis and stacked sparse autoencoders. Annals of
biomedical engineering, 44(5), 1587-1597.
[21]. Yulita, I. N., Fanany, M. I., & Arymuthy, A. M.
(2017). Bi-directional Long Short-Term Memory
using Quantized data of Deep Belief Networks for
Sleep Stage Classification. Procedia Computer
Science, 116, 530-538.

39

TEM Journal. Volume 8, Issue 1, Pages 28-40, ISSN 2217-8309, DOI: 10.18421/TEM81-04, February 2019.
[22]. Supratak, A., Dong, H., Wu, C., & Guo, Y. (2017).
DeepSleepNet: a model for automatic sleep stage
scoring based on raw single-channel EEG. IEEE
Transactions on Neural Systems and Rehabilitation
Engineering, 25(11), 1998-2008.
[23]. LÃ¤ngkvist, M., Karlsson, L., & Loutfi, A. (2012).
Sleep stage classification using unsupervised feature
learning. Advances in Artificial Neural Systems,
2012, 5.
[24]. Sors, A., Bonnet, S., Mirek, S., Vercueil, L., &
Payen, J. F. (2018). A convolutional neural network
for sleep stage scoring from raw single-channel eeg.
Biomedical Signal Processing and Control, 42, 107114.

40

[25]. Paisarnsrisomsuk, S., Sokolovsky, M., Guerrero, F.,
Ruiz, C., & Alvarez, S. A. (2018). Deep Sleep:
Convolutional Neural Networks for Predictive
Modeling of Human Sleep Time Signals.
[26]. Simonyan, K., & Zisserman, A. (2014). Very deep
convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556.
[27]. ProchÃ¡zka, A., KuchyÅˆka, J., VyÅ¡ata, O., Cejnar, P.,
ValiÅ¡, M., & MaÅ™Ã­k, V. (2018). Multi-Class Sleep
Stage
Analysis
and
Adaptive
Pattern
Recognition. Applied Sciences, 8(5), 697.

TEM Journal â€“ Volume 8 / Number 1 / 2019.

