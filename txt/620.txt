Mental Workload Assessment for UAV Traﬃc
Control Using Consumer-Grade BCI Equipment
Federica Bazzano(B) , Paolo Montuschi, Fabrizio Lamberti, Gianluca Paravati,
Silvia Casola, Gabriel Ceròn, Jaime Londoño, and Flavio Tanese
Dip. di Automatica e Informatica, Politecnico di Torino,
Corso Duca degli Abruzzi, 24, 10129 Turin, Italy
{federica.bazzano,paolo.montuschi,fabrizio.lamberti,gianluca.paravati,
silvia.casola,gabriel.ceron,jaime.londono,flavio.tanese}@polito.it

Abstract. The increasing popularity of unmanned aerial vehicles
(UAVs) in critical applications makes supervisory systems based on the
presence of human in the control loop of crucial importance. In UAVtraﬃc monitoring scenarios, where human operators are responsible for
managing drones, systems ﬂexibly supporting diﬀerent levels of autonomy are needed to assist them when critical conditions occur. The assessment of UAV controllers’ performance thus their mental workload may
be used to discriminate the level and type of automation required. The
aim of this paper is to build a mental-workload prediction model based on
UAV operators’ cognitive demand to support the design of an adjustable
autonomy supervisory system. A classiﬁcation and validation procedure
was performed to both categorize the cognitive workload measured by
ElectroEncephaloGram signals and evaluate the obtained patterns from
the point of view of accuracy. Then, a user study was carried out to identify critical workload conditions by evaluating operators’ performance in
accomplishing the assigned tasks. Results obtained in this study provided
precious indications for guiding next developments in the ﬁeld.
Keywords: Adjustable autonomy · Mental workload
Supervisory control · Learning model

1

Introduction

In recent years, the unmanned aerial vehicle (UAV) applications domain has
seen a rapid growing interest in the development of systems able to assist human
beings in critical operations [1–3]. Examples of such applications include security
and surveillance, monitoring, search and rescue, disaster management, etc. [4].
Systems able to ﬂexibly support diﬀerent levels of autonomy (LOAs) according to both humans’ cognitive resources and their performance in accomplishing
Work reported has been partially funded by TIM JOL Connected Robotics
Applications LaB (CRAB).
c The Author(s) 2017

P. Horain et al. (Eds.): IHCI 2017, LNCS 10688, pp. 60–72, 2017.
https://doi.org/10.1007/978-3-319-72038-8_6

Mental Workload Assessment for UAV Traﬃc Control

61

critical tasks, may be exploited to determine situations in which system intervention may be required [5–7]. The human’s cognitive resources and the ability
of the system to dynamically change the LOA according to the considered context are generally termed as “cognitive or mental workload ” [8] and “adjustable
or sliding autonomy” [9], respectively.
In literature, several criteria have been investigated to evaluate human’s
cognitive load. The main measurement techniques have been historically classiﬁed into three categories: physiological, subjective, and performance-based [10].
Physiological measurements are cognitive load assessment techniques based on
the physical response of the body. Subjective measurements are used to evaluate humans’ perceived mental workload by exploiting rankings or scales. Performance or objective measurements are used to evaluate humans’ ability to
perform a given task.
By moving from the above considerations, the aim of this paper is to build a
classiﬁcation and prediction model of UAV operators’ mental workload to support the design of an adaptive autonomy system able to adjust its level of autonomy accordingly. An ElectroEncephaloGram (EEG) signals was used as physiological technique for assessing operators’ mental workload and a Support Vector
Machine (SVM) was leveraged as learning and classiﬁcation model [11–13].
A 3D simulation framework was exploited in this work to both experiment
diﬀerent ﬂying scenarios of a swarm of autonomous drones ﬂying in an urban
environment and test the operator’s performance in UAV-traﬃc management.
A user interface was also used to show the 2D visualization of experimented
environment and allow human operators to interact with UAVs by issuing ﬂight
commands.
A user study was carried out with several volunteers to both evaluate operators’ performance in accomplishing supervision tasks of a growing number of
drones and gather diﬀerent workload measurements under critical conditions.
The rest of the paper is organized as follows. In Sect. 2, relevant works concerning workload measurements are reviewed. In Sect. 3, the device exploited
in the study is described. Sections 4 and 5 provide an overview of the overall
simulation framework and report details of the user interface considered in this
work, respectively. Sections 6 and 7 introduce the methodology that has been
adopted to perform the experimental tests and discuss data analysis and the
classiﬁcation procedure. Lastly, Sect. 8 discusses obtained results and concludes
the paper by providing possible directions for future research activities in this
ﬁeld.

2

Related Work

Many studies have investigated the relationship between tasks performed by an
individual and its cognitive load. In literature, diﬀerent techniques have been
proposed for mental workload assessment [10].
For instance, concerning subjective measurements techniques, [14,15] have
exploited the NASA-TLX questionnaire to evaluate users’ perceived workload in

62

F. Bazzano et al.

gaze-writing and robotic manipulation tasks, respectively. Similarly, Squire et al.
[16] have investigated the impact of self-assessed mental workload in simulated
game activities.
Despite, these measurements have been proved to be a reliable way to assess
humans’ mental workload [17], they often require annoying or repetitive interactions to the users by asking them to ﬁll diﬀerent rankings or scales.
In parallel to these studies, other works have evaluated physiological measurements as mental workload assessment techniques. As a matter of example,
Wilson et al. [18] exploited EEG channels, electrocardiographic (ECG), electrooculographic (EOG), and respiration inputs as cognitive workload evaluation
in air traﬃc control tasks. Functional Near-Infrared Spectroscopy (fNIRS) and
Heart Rate Variability (HRV) techniques were exploited in [19] and [20] to assess
the human’s mental workload in n-back working memory tasks and ship simulators, respectively. Besserve et al. [21] studied the relation between EEG data and
reaction time (RT) to characterize the level of performance during a cognitive
task, in order to anticipate human mistakes.
Although these studies have provided evidences to improve accuracy in workload measurements, they traditionally exploit bulky and expensive equipment
virtually uncomfortable to use in real application scenarios [22]. Data about suitability of alternative devices in physiological measurements are actually required
in order to properly support next advancements in the ﬁeld. Some activities in
this direction have been already carried out. For instance, Wang et al. [12] have
R
can be sucproved that a small device, as a 14-channel EMOTIVHeadset,
cessful used to characterize the mental workload in a simple memory n-back
task.
The goal of the present paper is to study on results reported in [12] a diﬀerent
application scenario exploiting EEG signals to build a UAV operators’ mental
workload prediction model in drones monitoring tasks.

3

Emotiv Epoc Headset

R1
This section brieﬂy describes the brain wearables devise EMOTIV Epoc+
considered in this study by illustrating its hardware and software features. More
speciﬁcally, the EMOTIV Epoc+ (Fig. 1a) is a wireless Brain Computer Interface (BCI) device manufactured by Emotiv. The headset consists of 14 wireless
EEG signal acquisition channels at 128 samples/s (Fig. 1b). The recorded EEG
signal is transmitted to an USB dongle for delivering the collected information
to the host workstation. A subscription software, named Pure·EEG is provided
by Emotiv to gather both the raw EEG data and the dense spatial resolution
array containing data at each sampling interval.

4

Simulation Framework

The basic idea inspiring the design of the present framework is to test diﬀerent UAV ﬂying scenarios in an urban environment. Such scenarios simulate
1

https://www.emotiv.com/epoc/.

Mental Workload Assessment for UAV Traﬃc Control

63

Fig. 1. Emotiv EPOC headset (a) and its 14 recorder positions (b).

potentially critical situations in which drones could be involved in. The logical components that were assembled to implement the proposed framework are
illustrated in Fig. 2. By digging more in details, the UAVs Simulator is the module responsible for simulating swarm of autonomous drones ﬂying in the 3D
virtual environment. It consists of three diﬀerent modules, namely: Autopilot,
Physics Simulation and Ground Control Station (GCS).

Fig. 2. Logical components of the simulation framework.

The Autopilot module is responsible for running drones ﬂight stability software without any speciﬁc hardware. More speciﬁcally, it exploits the SoftwareIn-The-Loop (SITL)2 simulator to run the PX4 Autopilot Flightcode3 - an open
source UAV ﬁrmware of a wide range of vehicle types. The Physics Simulation
module is the block devoted to load the 3D urban environment and execute the
drone ﬂight simulation in it. Gazebo4 physics engine was exploited in this block
2
3
4

http://ardupilot.org/dev/docs/sitl-simulator-software-in-the-loop.html.
https://px4.io.
https://gazebosim.org.

64

F. Bazzano et al.

for modeling and rendering the 3D models of drones with their physic properties, constraints and sensors (e.g. laser, camera). In particular, Gazebo runs
on Robot Operating System (ROS)5 , which is a software framework developed
for performing robotics tasks. Then, the Ground Control Station (GCS) module
contains the software used for setting drones’ starting locations, planning missions and getting real-time ﬂight information. The communication between the
Autopilot Flightcode and the GCS module is provided by the Micro Air Vehicle
ROS (MAVROS) node with the MAVLink communication protocol (Fig. 2).
Since drones communicate or transmit information through the network, low
bandwidth coverage areas could lead to loss of communication and thus to potentially critical conditions. Hence, a Bandwidth Simulator is developed to estimate,
in the experimented city, the maximum amount of data the network can transmit in the unit of time. The network transmission rate is assumed to depend
on population density of the city sites (parks, stadiums, schools, etc.) and the
network coverage.
Lastly, the Alert Module is the block devoted to determine the level of risk
(later referred to as “Alert”) of each drone by gathering data from both UAVs
and Bandwidth Simulators. Speciﬁcally, as in [23,24], the UAVs Simulator provides drone information regarding both their battery level and their distance
from obstacles (e.g. buildings). The Bandwidth Simulator sends the estimated
network transmission rate in the areas around drones’ positions. The mapping
between these parameters and each drone’s “Alert” is performed through a function deﬁned as follows: y = (b − 1)−1 ∗ (o − 1)−1 ∗ (n − 1)−1 , where b represents
the drone’s battery level, o is its distance from obstacles, n is the estimated
bandwidth coverage around its position and y is its level of risk. Three diﬀerent “Alert” levels are proposed in this work, namely: “Safe”, “Warning” and
“Danger”.

5

User Interface

In this section, the user interface devised for showing the 2D visualization of
experimented environment and useful information allowing human operators to
interact with UAVs is presented.
As illustrated in Fig. 3a, a wide region of the operator’s display is covered
with the 2D map of the city in which the real-time drones’ locations are shown. A
colored marker is used to depict the drone’s GPS position as well as its current
status. Three diﬀerent colors are used to illustrate the drone’s level of risk:
green (“Safe”), yellow (“Warning”) and red (“Danger”). On the right side of
the interface an extensive visual summary for each drone regarding its unique
name, its battery level, the bandwidth coverage of the area around its location
and its ﬂying altitude, is shown (Fig. 3b). Right below the map ﬁve buttons
allowing operators to issue ﬂight commands or show general information about
the map or drones are placed (Fig. 3c). More speciﬁcally, the “Start” button
is used to run the 3D simulation, whereas the “Options” button to show or
5

https://www.ros.org.

Mental Workload Assessment for UAV Traﬃc Control

65

Fig. 3. Monitoring interface (a), UAVs summary (b) and control buttons (c).
(Color ﬁgure online)

hide the bandwidth coverage of the city and the drones’ paths. The other three
buttons are used by the human operator to land, hover or change the drone’s
path, respectively. In this scenario, it is worth observing that EEG signals could
be aﬀected by the movement of human operators for pressing the above buttons.
Thus, an artifact removal stage is needed in order to remove all undesired signals
as detailed in Sect. 7.1.

6

User Tasks

The goal of this paper is to exploit EEG signals to build a prediction model of the
UAV operators’ mental workload in order to train a system able to autonomously
predict operators’ performance in UAVs monitoring operations. To this aim, an
SVM classiﬁcation algorithm was exploited to learn the ability of operators to
carry out assigned drone-traﬃc-control tasks in diﬀerent ﬂying scenarios. Four
monitoring tasks were experimented in this work, namely: M1, M2, M3 and M4.
In particular, M1 consisted of a single ﬂying drone whose path was designed for
avoiding obstacles on its route. No operator’s action was necessary to successfully
complete the mission. M2 was meant to evaluate the operator’s performance in
monitoring two drones at risk of colliding. Collisions were speciﬁcally designed
distant over time in order to allow the operator to be virtually able to deal with
them by keeping the eﬀort to complete the mission relatively low. Mission M3
consisted of ﬁve drones, three of which at high risk of colliding. This mission was
intentionally created to be very diﬃcult to complete even though theoretically
still manageable. Lastly, M4 consisted of six drones, each of which required
operator’s interventions to successfully complete the mission. It was devised to
be hardly to complete.

66

F. Bazzano et al.

Furthermore, a mission is considered “successfully completed” when all drones
landed in the intended positions or “failed” when at least one drone crashed.
The number of drones in each mission was also deﬁned relying on a preliminary
experiment which proved no signiﬁcance diﬀerence in operators’ mental workload
in monitoring three or four UAV. Data collected during mission M1 were used
as a mental workload baseline whereas those recorded in M4 as high mental
workload reference.

7

Data Analysis and Classiﬁcation

This section details the data analysis and classiﬁcation procedure performed in
this work. It entails the following steps: data pre-processing, feature extraction
and classiﬁcation.
7.1

Pre-processing

The EEG consists of recording electric signals produced by the activation of
thousands of neurons in the brain. These signals are gathered by electrodes
located over the scalp of a person. However, some spurious signals may aﬀect
the EEG data due the presence of noise or artifacts. In particular, the artifacts
which are signals with no cerebral origin can be divided in two groups. The ﬁrst
group is related to physiological sources such as eye blinking, ocular movement
and heart beating. The second group consists of mechanical artifacts, such as
the movement of electrodes or cables during data collection [25]. Thus, a preprocessing stage is needed to remove all undesired signals and noise. It consists
of three diﬀerent phases, namely: ﬁltering, oﬀset removal and artifact removal.
The EEGlab toolbox under the Matlab environment [26] was exploited in this
phase.
Since the EEG signals frequencies are within 0.5 and 45 Hz, the ﬁltering
phase implements a Finite Impulse Response (FIR) passband ﬁlter to remove
signals with high frequencies and increase signal to noise ratio. The oﬀset removal
phase eliminates potential oﬀset residues after the ﬁltering phase. The last
stage exploits the Artifact Subspace Reconstruction (ASR) algorithm for artifact
removal [27].
7.2

Feature Extraction

Given the preprocessed data, relevant features have to be extracted to train the
classiﬁcation model. For this purpose, temporal ranges of the signals containing
relevant events to be analyzed are deﬁned. In this work, the signal was split
in diﬀerent time windows as follows: 15 s after the start of the EEG recording
and 15 s before the ﬁrst failure, divided in 5 s windows. Data recorded during
the idle drone’s takeoﬀ phase was ignored to avoid exploiting related mental
workload measurements as baseline reference in the UAV monitoring experiment.
Data in the range just before and after the ﬁrst failure were not recorded since

Mental Workload Assessment for UAV Traﬃc Control

67

they may be aﬀected of biases due to the operator’s frustration for failing the
assigned task. For each window the following features were calculated channel
by channel: Power Spectral Density, Mean, Variance, Skewness, Kurtosis, Curve
length, Average non-linear energy and Number of peaks [12]. These features were
then concatenated in order to make each window corresponds to a row of features
appearing in order of channel. Each row was then assigned to a label that states
whether the operator failed or not the task for that particular mission.
7.3

Classification

The aim of this step is to train the classiﬁcation system considered in this study
with the operators’ mental workload for predicting their performance in UAVs
monitoring operations. Three diﬀerent models were exploited in this work: two
classiﬁers for predicting the outcome of each mission for each single subject; in
the third one, overall data gathered from all operators were used, in order to
understand whether a generalized model may be also employed.
A procedure dealing with feature scaling, hyperparameter optimization,
results validation and learning model design, was proposed in order to judge
the model considered from the point of view of accuracy.
Feature Scaling. An important issue in signal processing ﬁeld, and in particular with the EEG data is the high variability of the features extracted from each
subject thus their diﬀerent ranges. An appropriate scaling method is needed in
order to normalize all data into the same range. A z-score scaler was used as
normalization method for subtracting mean values from all measured signals and
then dividing the diﬀerence by the population standard deviation [28].
Hyperparameter Optimization and Validation Methodology. Since the
aim of the classiﬁcation methodology is to have a good accuracy on unseen data,
an appropriate validation method becomes necessary in order to measure the
generalization error of the implemented model. For this purpose, a k-fold cross
validation technique was used to both ﬁnd the best model with the optimal
parameters and test its performance on new unseen data. It consists of samples
subdivision in k folds, where k − 1 are used in each iteration to train the model,
and the remaining one is used to evaluate the results.
According to this validation methodology, data were divided into three different groups, namely training set, validation set, and test set as follows: 20% as
test set, and the other 80% as training and validation sets. A ten-fold cross validation is then performed on training and validation sets as follows: samples are
divided in ten folds, nine of which are used in each iteration to train the model,
and the other one is used to evaluate the results. This procedure is then iterated
until all folds are used one time as validation set. The training accuracy is then
evaluated as the mean of all the obtained results in the diﬀerent iterations. The
parameters leading to the best model performance called “Hyperparameters” are
then selected [29]. Lastly, the model is evaluated using the test set.

68

F. Bazzano et al.

Learning Model. A Support Vector Machine (SVM), which is a learning model
able to infer a function from labeled training data, is exploited in this phase to
deduce from the operator’s EEG workload his ability to succeed or not a mission.
It is implemented with two diﬀerent kernels: linear and Radial Basis Function
(RBF). The former is used to ﬁnd the best hyperplane separation in binary
classiﬁcation problems by tuning the regularization parameter C. The latter is
generally used in problems that are not linearly separable and require to ﬁnd
also the best value of the γ parameter [13].
The C parameter is used to regularize and control the bias variance tradeoﬀ. The γ parameter is used to deﬁne the variance of the Radial Basis Function
(RBF). A grid search using powers of ten from 10−2 to 102 was used to tune the
C parameter through the cross-validation phase. For the γ parameter, powers of
ten from 10−4 to 10 were used by considering that bigger values lead to adjust
better the model to the training set but bring possible problems of variance or
over-ﬁtting. Smaller values may bring bias or under-ﬁtting problems.

8

Results and Discussion

As anticipated, the goal of this paper is to build a UAV operators’ mental workload prediction model in order to train a system able to autonomously predict
operators’ performance in UAVs monitoring operations. To this aim, mental
workload data have been collected through a user study.
The study involved 10 participants (8 males and 2 females, aged between
19 to 24), selected from the students of Politecnico di Torino. After a brief
training, participants were invited to perform the four tasks M1, M2, M3 and
M4 in sequence through the user interface. Such tasks have been speciﬁcally
designed to test operators’ performance in UAVs monitoring operations with an
increasing drones’ level of risk. Each task, whose length was strictly depending
on the operator’s piloting choices, took from 2 to 7 min. During each experiment
(i.e., all tasks performed), physiological measurements gathered by the EEG
R
were recorded. The EEG signal
signal through the EMOTIV Epoc+Headset
was split in diﬀerent time windows as detailed in Sect. 7.2. For each window,
the following features were calculated: Power Spectral Density, Mean, Variance,
Skewness, Kurtosis, Curve length, Average non-linear energy and Number of
peaks. These features were then concatenated in order to make each window
correspond to a row of features appearing in order of channel. Each row was then
assigned to a label that states whether the operator failed or not the task for that
particular mission. This procedure was performed to generate an heterogeneous
population in order to build a classiﬁer able to autonomously predict the label
from operators’ mental workload measured by EEG signals.
Results obtained in terms of classiﬁcation algorithm accuracy are reported
in Table 1 specifying the hyperparameters used to train each single model. The
ﬁrst ten rows of the table represent the obtained results in the individual model
trained using single subject data. The last row shows the overall results using all
the collected data. By digging more in details, as shown in Table 1, the ﬁfth and

Mental Workload Assessment for UAV Traﬃc Control

69

Table 1. Results concerning the accuracy of the classiﬁcation algorithm for the
individual and overall models.
Participant ID Model
SVM - linear kernel
SVM - RBF kernel
C
Accuracy
Accuracy C γ
Accuracy
Accuracy
(validation set) (test set)
(validation set) (test set)
1

0.01 0.949

0.933

100 0.0001 0.949

0.933

2

100 0.923

0.973

100 0.0001 0.934

0.973

3

0.01 0.965

1

100 0.0001 0.965

1

4

0.01 0.851

0.965

10

0.93

5

*

*

*

*

*

*

*

6

0.1

0.885

0.895

10

0.001

0.899

0.864

7

*

*

*

*

8

0.01 0.944

0.0001 0.851

*

*

0.969

100 0.0001 0.936

0.969

*
0.864

9

0.01 0.986

0.927

10

0.001

0.897

10

0.01 0.995

1

10

0.001

0.995

1

Overall

0.1

0.839

10

0.001

0.872

0.856

0.852

seventh rows present corrupted data that have been discarded for the validation
purpose. In those cases, participants only completed one mission successfully,
making it very diﬃcult to train the model due to class skewness. As a result, no
individual model was trained using those data. However, they were used in the
overall model.
The accuracy scores obtained with the ten-fold cross-validation phase
(Sect. 7.3) are reported in Table 1 as “Accuracy (Validation set)”. The obtained
accuracy with new unseen data is reported as “Accuracy (Test set)”. It is worth
observing that the accuracy scores in these two columns for the same row are not
largely diﬀerent. This observation allows to conclude, that the proposed model
is not aﬀected by problems of variance thus performs well if tested with other
participants under the same conditions.
Results regarding the accuracy of the test sets show that the linear kernel
always perform better or equal than the RBF kernel for individual models. On
the contrary, the RBF kernel performs better than linear kernel for the overall
model. Speciﬁcally, the SVM with the linear kernel is able to predict the operator’s performance outcomes thus the level of his/her mental workload with an
average accuracy equal to 95.8% and 83.9% when the model is trained on a single
user and on all collected data, respectively. Whereas, an accuracy equal to 94.1%
and 85.6% is reached with the SVM - RBF kernel when the model is trained
using the single user and overall data, respectively. This may be reasonably due
to the fact that individual models trained using single subject data are simpler
classiﬁcation problems than those with all collected data.

70

F. Bazzano et al.

In this work, the data analysis and classiﬁcation procedure was performed
oﬄine on the data collected through the user study. Future works will be aimed
to address alternative procedures in order to allow online evaluation of the data.

References
1. Kopeikin, A., Clare, A., Toupet, O., How, J., Cummings, M.: Flight testing a
heterogeneous multi-UAV system with human supervision. In: AIAA Guidance,
Navigation, and Control Conference, p. 4825 (2012)
2. Parasuraman, R., Miller, C.: Delegation interfaces for human supervision of multiple unmanned vehicles: theory, experiments, and practical applications. In: Cooke,
N.J., Pringle, H.L., Pedersen, H.K., Connor, O. (eds.) Human Factors of Remotely
Operated Vehicles, pp. 251–266. Emerald Group Publishing Limited, Bingley
(2006)
3. Wickens, C.D., Dixon, S.: Workload demands of remotely piloted vehicle supervision and control: (1) single vehicle performance. Technical report, DTIC Document
(2002)
4. Sarris, Z., Atlas, S.: Survey of UAV applications in civil markets. In: Proceedings
of the 9th Mediterranean Conference on Control and Automation, pp. 1–11 (2001)
5. Freedy, A., Sert, O., Freedy, E., McDonough, J., Weltman, G., Tambe, M.,
Gupta, T., Grayson, W., Cabrera, P.: Multiagent adjustable autonomy framework
(MAAF) for multi-robot, multi-human teams. In: International Symposium on
Collaborative Technologies and Systems, CTS 2008, pp. 498–505. IEEE (2008)
6. Côté, N., Canu, A., Bouzid, M., Mouaddib, A.I.: Humans-robots sliding collaboration control in complex environments with adjustable autonomy. In: Proceedings
of the 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence
and Intelligent Agent Technology, vol. 2, pp. 146–153. IEEE Computer Society
(2012)
7. Heger, F.W., Singh, S.: Sliding autonomy for complex coordinated multi-robot
tasks: analysis & experiments (2006)
8. Cain, B.: A review of the mental workload literature. Technical report, DTIC
Document (2007)
9. Goodrich, M.A., Schultz, A.C.: Human-robot interaction: a survey. Found. Trends
Hum. Comput. Interact. 1(3), 203–275 (2007)
10. Miller, S.: Workload measures. National Advanced Driving Simulator, Iowa City,
USA (2001)
11. Lim, W.L., Sourina, O., Liu, Y., Wang, L.: EEG-based mental workload recognition
related to multitasking. In: 2015 10th International Conference on Information,
Communications and Signal Processing (ICICS), pp. 1–4. IEEE (2015)
12. Wang, S., Gwizdka, J., Chaovalitwongse, W.A.: Using wireless eeg signals to assess
memory workload in the n-back task. IEEE Trans. Hum. Mach. Syst. 46(3), 424–
435 (2016)
13. Walter, C., Schmidt, S., Rosenstiel, W., Gerjets, P., Bogdan, M.: Using cross-task
classiﬁcation for classifying workload levels in complex learning tasks. In: 2013
Humaine Association Conference on Aﬀective Computing and Intelligent Interaction (ACII), pp. 876–881. IEEE (2013)
14. Hayashi, T., Kishi, R.: Utilization of NASA-TLX for workload evaluation of gazewriting systems. In: 2014 IEEE International Symposium on Multimedia (ISM),
pp. 271–272. IEEE (2014)

Mental Workload Assessment for UAV Traﬃc Control

71

15. Cannon, D., Siegel, M.: Perceived mental workload and operator performance of
dexterous manipulators under time delay with master-slave interfaces. In: 2015
IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA), pp. 1–6. IEEE
(2015)
16. Squire, P., Parasuraman, R.: Eﬀects of automation and task load on task switching during human supervision of multiple semi-autonomous robots in a dynamic
environment. Ergonomics 53(8), 951–961 (2010)
17. Hart, S.G., Staveland, L.E.: Development of NASA-TLX (task load index): results
of empirical and theoretical research. Adv. Psychol. 52, 139–183 (1988)
18. Wilson, G.F., Monett, C.T., Russell, C.A.: Operator functional state classiﬁcation
during a simulated ATC task using EEG. In: Proceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 41, p. 1382. Sage Publications,
Los Angeles (1997)
19. Berivanlou, N.H., Setarehdan, S.K., Noubari, H.A.: Quantifying mental workload
of operators performing n-back working memory task: toward fNIRS based passive
BCI system. In: 2016 23rd Iranian Conference on Biomedical Engineering and
2016 1st International Iranian Conference on Biomedical Engineering (ICBME),
pp. 140–145. IEEE (2016)
20. Sugimoto, I., Kitamura, K., Murai, K., Wang, Y., Wang, J.: Study on relation
between operator and trainee’s mental workload for ship maneuvering simulator
exercise using heart rate variability. In: 2016 IEEE International Conference on
Systems, Man, and Cybernetics (SMC). IEEE (2016). ISSN 000768–000772
21. Besserve, M., Philippe, M., Florence, G., Laurent, F., Garnero, L., Martinerie, J.:
Prediction of performance level during a cognitive task from ongoing eeg oscillatory
activities. Clin. Neurophysiol. 119(4), 897–908 (2008)
22. Lin, C.T., Ko, L.W., Chang, M.H., Duann, J.R., Chen, J.Y., Su, T.P., Jung, T.P.:
Review of wireless and wearable electroencephalogram systems and brain-computer
interfaces-a mini-review. Gerontology 56(1), 112–119 (2010)
23. Madgwick, S., Turner, C., Harwin, W.: Adaptation of an commercially available
stabilised R/C helicopter to a fully autonomous surveillance UAV. In: Bristol International Unmanned Air Vehicle Systems (U4 JS) Conference (2009)
24. Gageik, N., Müller, T., Montenegro, S.: Obstacle detection and collision avoidance
using ultrasonic distance sensors for an autonomous quadrocopter. University of
Würzburg, Aerospace Information Technology, Würzburg, Germany, September
2012
25. Bulea, T.C., Kilicarslan, A., Ozdemir, R., Paloski, W.H., Contreras-Vidal, J.L.:
Simultaneous scalp electroencephalography (EEG), electromyography (EMG), and
whole-body segmental inertial recording for multi-modal neural decoding. JoVE (J.
Visual. Exp.) 26(77), e50602 (2013)
26. Delorme, A., Makeig, S.: EEGLAB: an open source toolbox for analysis of singletrial EEG dynamics including independent component analysis. J. Neurosci. Methods 134(1), 9–21 (2004)
27. Kothe, C.: The artifact subspace reconstruction method (2013)
28. Kawintiranon, K., Buatong, Y., Vateekul, P.: Online music emotion prediction
on multiple sessions of EEG data using SVM. In: 2016 13th International Joint
Conference on Computer Science and Software Engineering (JCSSE), pp. 1–6.
IEEE (2016)
29. James, G., Witten, D., Hastie, T.: An Introduction to Statistical Learning:
With Applications in R. Springer, New York (2014). https://doi.org/10.1007/
978-1-4614-7138-7

72

F. Bazzano et al.

Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will
need to obtain permission directly from the copyright holder.

